[09/16 01:59:09 visual_prompt]: Rank of current process: 0. World size: 1
[09/16 01:59:09 visual_prompt]: Environment info:
-------------------  ----------------------------------------------------
Python               3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              1.7.1
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  ----------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[09/16 01:59:09 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '100', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-dtd', 'DATA.NUMBER_CLASSES', '47', 'SOLVER.BASE_LR', '5.0', 'SOLVER.WEIGHT_DECAY', '0.0001', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir/seed42'], train_type='')
[09/16 01:59:09 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/16 01:59:09 visual_prompt]: Training with config:
[09/16 01:59:09 visual_prompt]: {'CUDNN_BENCHMARK': False,
 'DATA': {'BATCH_SIZE': 64,
          'CLASS_WEIGHTS_TYPE': 'none',
          'CROPSIZE': 224,
          'DATAPATH': 'visual_prompt_tuning/data_path',
          'FEATURE': 'sup_vitb16_imagenet21k',
          'MULTILABEL': False,
          'NAME': 'vtab-dtd',
          'NO_TEST': False,
          'NUMBER_CLASSES': 47,
          'NUM_WORKERS': 4,
          'PERCENTAGE': 1.0,
          'PIN_MEMORY': True},
 'DBG': False,
 'MODEL': {'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'}),
           'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}),
           'MLP_NUM': 0,
           'MODEL_ROOT': 'visual_prompt_tuning/model_root',
           'PROMPT': {'CLSEMB_FOLDER': '',
                      'CLSEMB_PATH': '',
                      'DEEP': True,
                      'DEEP_SHARED': False,
                      'DROPOUT': 0.1,
                      'FORWARD_DEEP_NOEXPAND': False,
                      'INITIATION': 'random',
                      'LOCATION': 'prepend',
                      'NUM_DEEP_LAYERS': None,
                      'NUM_TOKENS': 100,
                      'PROJECT': -1,
                      'REVERSE_DEEP': False,
                      'SAVE_FOR_EACH_EPOCH': False,
                      'VIT_POOL_TYPE': 'original'},
           'SAVE_CKPT': False,
           'TRANSFER_TYPE': 'prompt',
           'TYPE': 'vit',
           'WEIGHT_PATH': ''},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/seed42/vtab-dtd/sup_vitb16_imagenet21k/lr5.0_wd0.0001/run1',
 'RUN_N_TIMES': 1,
 'SEED': None,
 'SOLVER': {'BASE_LR': 5.0,
            'BIAS_MULTIPLIER': 1.0,
            'DBG_TRAINABLE': False,
            'LOG_EVERY_N': 100,
            'LOSS': 'softmax',
            'LOSS_ALPHA': 0.01,
            'MOMENTUM': 0.9,
            'OPTIMIZER': 'sgd',
            'PATIENCE': 300,
            'SCHEDULER': 'cosine',
            'TOTAL_EPOCH': 100,
            'WARMUP_EPOCH': 10,
            'WEIGHT_DECAY': 0.0001,
            'WEIGHT_DECAY_BIAS': 0}}
[09/16 01:59:09 visual_prompt]: Loading training data (final training data for vtab)...
2023-09-16 01:59:09.759618: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-09-16 01:59:09.949220: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-09-16 01:59:10.957514: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-16 01:59:10.957598: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-16 01:59:10.957608: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-09-16 01:59:13.308339: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-16 01:59:13.308453: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-16 01:59:13.308472: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
[09/16 01:59:13 visual_prompt]: Constructing vtab-dtd dataset trainval...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/dtd/3.0.1
[INFO: dataset_builder.py:  510]: Reusing dataset dtd (visual_prompt_tuning/data_path/dtd/3.0.1)
2023-09-16 01:59:13.431681: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset dtd for split train[:800]+validation[:200], from visual_prompt_tuning/data_path/dtd/3.0.1
[09/16 01:59:16 visual_prompt]: Number of images: 1000
[09/16 01:59:16 visual_prompt]: Number of classes: 47 / 47
[09/16 01:59:16 visual_prompt]: Loading validation data...
[09/16 01:59:16 visual_prompt]: Constructing vtab-dtd dataset val...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/dtd/3.0.1
[INFO: dataset_builder.py:  510]: Reusing dataset dtd (visual_prompt_tuning/data_path/dtd/3.0.1)
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset dtd for split validation[:200], from visual_prompt_tuning/data_path/dtd/3.0.1
[09/16 01:59:17 visual_prompt]: Number of images: 200
[09/16 01:59:17 visual_prompt]: Number of classes: 47 / 47
[09/16 01:59:17 visual_prompt]: Loading test data...
[09/16 01:59:17 visual_prompt]: Constructing vtab-dtd dataset test...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/dtd/3.0.1
[INFO: dataset_builder.py:  510]: Reusing dataset dtd (visual_prompt_tuning/data_path/dtd/3.0.1)
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset dtd for split test, from visual_prompt_tuning/data_path/dtd/3.0.1
[09/16 01:59:22 visual_prompt]: Number of images: 1880
[09/16 01:59:22 visual_prompt]: Number of classes: 47 / 47
[09/16 01:59:22 visual_prompt]: Constructing models...
[09/16 01:59:25 visual_prompt]: Total Parameters: 86756399	 Gradient Parameters: 957743
[09/16 01:59:25 visual_prompt]: tuned percent:1.104
[09/16 01:59:27 visual_prompt]: Device used for model: 0
[09/16 01:59:27 visual_prompt]: Setting up Evalutator...
[09/16 01:59:27 visual_prompt]: Setting up Trainer...
[09/16 01:59:27 visual_prompt]: 	Setting up the optimizer...
[09/16 01:59:27 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/16 01:59:36 visual_prompt]: Epoch 1 / 100: avg data time: 7.39e-02, avg batch time: 0.5444, average train loss: 3.9374
[09/16 01:59:38 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1420, average loss: 3.9032
[09/16 01:59:38 visual_prompt]: Classification results with val_vtab-dtd: top1: 3.50	top5: 16.50	
[09/16 01:59:45 visual_prompt]: Inference (test):avg data time: 4.13e-03, avg batch time: 0.1856, average loss: 3.9429
[09/16 01:59:45 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.07	top5: 11.81	
[09/16 01:59:45 visual_prompt]: Best epoch 1: best metric: 0.035
[09/16 01:59:45 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.5
[09/16 01:59:53 visual_prompt]: Epoch 2 / 100: avg data time: 5.90e-02, avg batch time: 0.4623, average train loss: 3.9451
[09/16 01:59:54 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1422, average loss: 3.8581
[09/16 01:59:54 visual_prompt]: Classification results with val_vtab-dtd: top1: 4.00	top5: 15.00	
[09/16 02:00:01 visual_prompt]: Inference (test):avg data time: 2.84e-03, avg batch time: 0.1853, average loss: 3.8601
[09/16 02:00:01 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.18	top5: 15.21	
[09/16 02:00:01 visual_prompt]: Best epoch 2: best metric: 0.040
[09/16 02:00:01 visual_prompt]: Training 3 / 100 epoch, with learning rate 1.0
[09/16 02:00:09 visual_prompt]: Epoch 3 / 100: avg data time: 6.64e-02, avg batch time: 0.4677, average train loss: 3.9395
[09/16 02:00:10 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.1423, average loss: 3.9463
[09/16 02:00:10 visual_prompt]: Classification results with val_vtab-dtd: top1: 5.00	top5: 10.50	
[09/16 02:00:17 visual_prompt]: Inference (test):avg data time: 4.73e-03, avg batch time: 0.1872, average loss: 3.9308
[09/16 02:00:17 visual_prompt]: Classification results with test_vtab-dtd: top1: 4.73	top5: 11.17	
[09/16 02:00:17 visual_prompt]: Best epoch 3: best metric: 0.050
[09/16 02:00:17 visual_prompt]: Training 4 / 100 epoch, with learning rate 1.5
[09/16 02:00:25 visual_prompt]: Epoch 4 / 100: avg data time: 6.58e-02, avg batch time: 0.4659, average train loss: 3.8902
[09/16 02:00:27 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1427, average loss: 3.7669
[09/16 02:00:27 visual_prompt]: Classification results with val_vtab-dtd: top1: 9.50	top5: 25.50	
[09/16 02:00:34 visual_prompt]: Inference (test):avg data time: 5.58e-03, avg batch time: 0.1874, average loss: 3.8207
[09/16 02:00:34 visual_prompt]: Classification results with test_vtab-dtd: top1: 7.34	top5: 20.53	
[09/16 02:00:34 visual_prompt]: Best epoch 4: best metric: 0.095
[09/16 02:00:34 visual_prompt]: Training 5 / 100 epoch, with learning rate 2.0
[09/16 02:00:41 visual_prompt]: Epoch 5 / 100: avg data time: 4.88e-02, avg batch time: 0.4529, average train loss: 3.7955
[09/16 02:00:43 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1428, average loss: 3.5338
[09/16 02:00:43 visual_prompt]: Classification results with val_vtab-dtd: top1: 8.50	top5: 32.00	
[09/16 02:00:50 visual_prompt]: Inference (test):avg data time: 2.04e-03, avg batch time: 0.1881, average loss: 3.6807
[09/16 02:00:50 visual_prompt]: Classification results with test_vtab-dtd: top1: 7.23	top5: 27.71	
[09/16 02:00:50 visual_prompt]: Training 6 / 100 epoch, with learning rate 2.5
[09/16 02:00:58 visual_prompt]: Epoch 6 / 100: avg data time: 5.59e-02, avg batch time: 0.4630, average train loss: 3.7601
[09/16 02:00:59 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1431, average loss: 3.5481
[09/16 02:00:59 visual_prompt]: Classification results with val_vtab-dtd: top1: 11.00	top5: 32.00	
[09/16 02:01:06 visual_prompt]: Inference (test):avg data time: 5.41e-03, avg batch time: 0.1880, average loss: 3.6193
[09/16 02:01:06 visual_prompt]: Classification results with test_vtab-dtd: top1: 8.56	top5: 30.80	
[09/16 02:01:06 visual_prompt]: Best epoch 6: best metric: 0.110
[09/16 02:01:06 visual_prompt]: Training 7 / 100 epoch, with learning rate 3.0
[09/16 02:01:14 visual_prompt]: Epoch 7 / 100: avg data time: 6.18e-02, avg batch time: 0.4626, average train loss: 3.3172
[09/16 02:01:16 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.1432, average loss: 3.5300
[09/16 02:01:16 visual_prompt]: Classification results with val_vtab-dtd: top1: 14.00	top5: 41.00	
[09/16 02:01:23 visual_prompt]: Inference (test):avg data time: 5.77e-03, avg batch time: 0.1872, average loss: 3.7499
[09/16 02:01:23 visual_prompt]: Classification results with test_vtab-dtd: top1: 10.27	top5: 32.55	
[09/16 02:01:23 visual_prompt]: Best epoch 7: best metric: 0.140
[09/16 02:01:23 visual_prompt]: Training 8 / 100 epoch, with learning rate 3.5
[09/16 02:01:30 visual_prompt]: Epoch 8 / 100: avg data time: 6.39e-02, avg batch time: 0.4635, average train loss: 2.7021
[09/16 02:01:32 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.1431, average loss: 3.0708
[09/16 02:01:32 visual_prompt]: Classification results with val_vtab-dtd: top1: 16.50	top5: 57.50	
[09/16 02:01:39 visual_prompt]: Inference (test):avg data time: 4.69e-03, avg batch time: 0.1877, average loss: 3.3021
[09/16 02:01:39 visual_prompt]: Classification results with test_vtab-dtd: top1: 17.98	top5: 48.30	
[09/16 02:01:39 visual_prompt]: Best epoch 8: best metric: 0.165
[09/16 02:01:39 visual_prompt]: Training 9 / 100 epoch, with learning rate 4.0
[09/16 02:01:47 visual_prompt]: Epoch 9 / 100: avg data time: 5.69e-02, avg batch time: 0.4582, average train loss: 2.6116
[09/16 02:01:48 visual_prompt]: Inference (val):avg data time: 3.74e-05, avg batch time: 0.1430, average loss: 2.2012
[09/16 02:01:48 visual_prompt]: Classification results with val_vtab-dtd: top1: 37.50	top5: 70.50	
[09/16 02:01:55 visual_prompt]: Inference (test):avg data time: 4.71e-03, avg batch time: 0.1888, average loss: 2.5142
[09/16 02:01:55 visual_prompt]: Classification results with test_vtab-dtd: top1: 29.68	top5: 63.78	
[09/16 02:01:55 visual_prompt]: Best epoch 9: best metric: 0.375
[09/16 02:01:55 visual_prompt]: Training 10 / 100 epoch, with learning rate 4.5
[09/16 02:02:03 visual_prompt]: Epoch 10 / 100: avg data time: 4.38e-02, avg batch time: 0.4482, average train loss: 2.6453
[09/16 02:02:04 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1433, average loss: 3.3142
[09/16 02:02:04 visual_prompt]: Classification results with val_vtab-dtd: top1: 23.50	top5: 59.00	
[09/16 02:02:11 visual_prompt]: Inference (test):avg data time: 4.29e-03, avg batch time: 0.1868, average loss: 3.5577
[09/16 02:02:11 visual_prompt]: Classification results with test_vtab-dtd: top1: 21.44	top5: 52.13	
[09/16 02:02:11 visual_prompt]: Training 11 / 100 epoch, with learning rate 5.0
[09/16 02:02:19 visual_prompt]: Epoch 11 / 100: avg data time: 6.37e-02, avg batch time: 0.4670, average train loss: 2.8601
[09/16 02:02:21 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1434, average loss: 2.9840
[09/16 02:02:21 visual_prompt]: Classification results with val_vtab-dtd: top1: 30.50	top5: 57.50	
[09/16 02:02:28 visual_prompt]: Inference (test):avg data time: 5.66e-03, avg batch time: 0.1893, average loss: 3.4490
[09/16 02:02:28 visual_prompt]: Classification results with test_vtab-dtd: top1: 25.64	top5: 49.95	
[09/16 02:02:28 visual_prompt]: Training 12 / 100 epoch, with learning rate 4.998477067547739
[09/16 02:02:36 visual_prompt]: Epoch 12 / 100: avg data time: 6.22e-02, avg batch time: 0.4650, average train loss: 2.1702
[09/16 02:02:37 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1431, average loss: 1.6786
[09/16 02:02:37 visual_prompt]: Classification results with val_vtab-dtd: top1: 55.00	top5: 85.50	
[09/16 02:02:44 visual_prompt]: Inference (test):avg data time: 3.36e-03, avg batch time: 0.1878, average loss: 2.2125
[09/16 02:02:44 visual_prompt]: Classification results with test_vtab-dtd: top1: 41.38	top5: 75.27	
[09/16 02:02:44 visual_prompt]: Best epoch 12: best metric: 0.550
[09/16 02:02:44 visual_prompt]: Training 13 / 100 epoch, with learning rate 4.993910125649561
[09/16 02:02:52 visual_prompt]: Epoch 13 / 100: avg data time: 6.94e-02, avg batch time: 0.4707, average train loss: 1.3151
[09/16 02:02:54 visual_prompt]: Inference (val):avg data time: 3.54e-05, avg batch time: 0.1432, average loss: 1.3819
[09/16 02:02:54 visual_prompt]: Classification results with val_vtab-dtd: top1: 64.00	top5: 87.50	
[09/16 02:03:01 visual_prompt]: Inference (test):avg data time: 6.82e-03, avg batch time: 0.1886, average loss: 2.3324
[09/16 02:03:01 visual_prompt]: Classification results with test_vtab-dtd: top1: 44.04	top5: 76.49	
[09/16 02:03:01 visual_prompt]: Best epoch 13: best metric: 0.640
[09/16 02:03:01 visual_prompt]: Training 14 / 100 epoch, with learning rate 4.986304738420683
[09/16 02:03:08 visual_prompt]: Epoch 14 / 100: avg data time: 5.76e-02, avg batch time: 0.4628, average train loss: 1.0462
[09/16 02:03:10 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1433, average loss: 0.9147
[09/16 02:03:10 visual_prompt]: Classification results with val_vtab-dtd: top1: 69.50	top5: 95.50	
[09/16 02:03:17 visual_prompt]: Inference (test):avg data time: 3.74e-03, avg batch time: 0.1879, average loss: 2.2975
[09/16 02:03:17 visual_prompt]: Classification results with test_vtab-dtd: top1: 48.46	top5: 78.94	
[09/16 02:03:17 visual_prompt]: Best epoch 14: best metric: 0.695
[09/16 02:03:17 visual_prompt]: Training 15 / 100 epoch, with learning rate 4.975670171853926
[09/16 02:03:25 visual_prompt]: Epoch 15 / 100: avg data time: 6.14e-02, avg batch time: 0.4618, average train loss: 0.7623
[09/16 02:03:26 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1434, average loss: 0.3569
[09/16 02:03:26 visual_prompt]: Classification results with val_vtab-dtd: top1: 89.50	top5: 99.00	
[09/16 02:03:33 visual_prompt]: Inference (test):avg data time: 7.38e-03, avg batch time: 0.1899, average loss: 2.4055
[09/16 02:03:33 visual_prompt]: Classification results with test_vtab-dtd: top1: 51.22	top5: 81.91	
[09/16 02:03:33 visual_prompt]: Best epoch 15: best metric: 0.895
[09/16 02:03:33 visual_prompt]: Training 16 / 100 epoch, with learning rate 4.962019382530521
[09/16 02:03:41 visual_prompt]: Epoch 16 / 100: avg data time: 5.75e-02, avg batch time: 0.4606, average train loss: 0.4880
[09/16 02:03:43 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1435, average loss: 0.2956
[09/16 02:03:43 visual_prompt]: Classification results with val_vtab-dtd: top1: 89.50	top5: 100.00	
[09/16 02:03:50 visual_prompt]: Inference (test):avg data time: 4.61e-03, avg batch time: 0.1878, average loss: 2.1753
[09/16 02:03:50 visual_prompt]: Classification results with test_vtab-dtd: top1: 54.52	top5: 84.95	
[09/16 02:03:50 visual_prompt]: Training 17 / 100 epoch, with learning rate 4.945369001834514
[09/16 02:03:57 visual_prompt]: Epoch 17 / 100: avg data time: 5.93e-02, avg batch time: 0.4614, average train loss: 0.3228
[09/16 02:03:59 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1433, average loss: 0.3573
[09/16 02:03:59 visual_prompt]: Classification results with val_vtab-dtd: top1: 89.50	top5: 100.00	
[09/16 02:04:06 visual_prompt]: Inference (test):avg data time: 2.27e-03, avg batch time: 0.1839, average loss: 2.4468
[09/16 02:04:06 visual_prompt]: Classification results with test_vtab-dtd: top1: 52.07	top5: 82.18	
[09/16 02:04:06 visual_prompt]: Training 18 / 100 epoch, with learning rate 4.925739315689991
[09/16 02:04:14 visual_prompt]: Epoch 18 / 100: avg data time: 6.19e-02, avg batch time: 0.4639, average train loss: 0.2545
[09/16 02:04:15 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1433, average loss: 0.3049
[09/16 02:04:15 visual_prompt]: Classification results with val_vtab-dtd: top1: 90.00	top5: 99.50	
[09/16 02:04:22 visual_prompt]: Inference (test):avg data time: 4.12e-03, avg batch time: 0.1884, average loss: 2.8242
[09/16 02:04:22 visual_prompt]: Classification results with test_vtab-dtd: top1: 54.20	top5: 82.93	
[09/16 02:04:22 visual_prompt]: Best epoch 18: best metric: 0.900
[09/16 02:04:22 visual_prompt]: Training 19 / 100 epoch, with learning rate 4.903154239845797
[09/16 02:04:30 visual_prompt]: Epoch 19 / 100: avg data time: 5.56e-02, avg batch time: 0.4622, average train loss: 0.3086
[09/16 02:04:32 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1434, average loss: 0.1637
[09/16 02:04:32 visual_prompt]: Classification results with val_vtab-dtd: top1: 95.00	top5: 100.00	
[09/16 02:04:38 visual_prompt]: Inference (test):avg data time: 4.57e-03, avg batch time: 0.1896, average loss: 2.5071
[09/16 02:04:38 visual_prompt]: Classification results with test_vtab-dtd: top1: 52.93	top5: 82.02	
[09/16 02:04:38 visual_prompt]: Best epoch 19: best metric: 0.950
[09/16 02:04:38 visual_prompt]: Training 20 / 100 epoch, with learning rate 4.877641290737884
[09/16 02:04:46 visual_prompt]: Epoch 20 / 100: avg data time: 6.44e-02, avg batch time: 0.4668, average train loss: 0.2200
[09/16 02:04:48 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1432, average loss: 0.1753
[09/16 02:04:48 visual_prompt]: Classification results with val_vtab-dtd: top1: 94.00	top5: 100.00	
[09/16 02:04:55 visual_prompt]: Inference (test):avg data time: 3.65e-03, avg batch time: 0.1882, average loss: 2.8868
[09/16 02:04:55 visual_prompt]: Classification results with test_vtab-dtd: top1: 52.13	top5: 81.97	
[09/16 02:04:55 visual_prompt]: Training 21 / 100 epoch, with learning rate 4.849231551964771
[09/16 02:05:02 visual_prompt]: Epoch 21 / 100: avg data time: 4.54e-02, avg batch time: 0.4471, average train loss: 0.2225
[09/16 02:05:04 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.1438, average loss: 0.1447
[09/16 02:05:04 visual_prompt]: Classification results with val_vtab-dtd: top1: 95.50	top5: 100.00	
[09/16 02:05:11 visual_prompt]: Inference (test):avg data time: 4.60e-03, avg batch time: 0.1861, average loss: 2.6314
[09/16 02:05:11 visual_prompt]: Classification results with test_vtab-dtd: top1: 55.27	top5: 83.94	
[09/16 02:05:11 visual_prompt]: Best epoch 21: best metric: 0.955
[09/16 02:05:11 visual_prompt]: Training 22 / 100 epoch, with learning rate 4.817959636416969
[09/16 02:05:19 visual_prompt]: Epoch 22 / 100: avg data time: 6.00e-02, avg batch time: 0.4630, average train loss: 0.3005
[09/16 02:05:20 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1431, average loss: 0.1416
[09/16 02:05:20 visual_prompt]: Classification results with val_vtab-dtd: top1: 96.00	top5: 99.00	
[09/16 02:05:27 visual_prompt]: Inference (test):avg data time: 3.38e-03, avg batch time: 0.1871, average loss: 2.4004
[09/16 02:05:27 visual_prompt]: Classification results with test_vtab-dtd: top1: 55.48	top5: 82.93	
[09/16 02:05:27 visual_prompt]: Best epoch 22: best metric: 0.960
[09/16 02:05:27 visual_prompt]: Training 23 / 100 epoch, with learning rate 4.783863644106502
[09/16 02:05:35 visual_prompt]: Epoch 23 / 100: avg data time: 6.03e-02, avg batch time: 0.4630, average train loss: 0.1992
[09/16 02:05:37 visual_prompt]: Inference (val):avg data time: 1.30e-04, avg batch time: 0.3401, average loss: 0.1801
[09/16 02:05:37 visual_prompt]: Classification results with val_vtab-dtd: top1: 95.50	top5: 100.00	
[09/16 02:05:44 visual_prompt]: Inference (test):avg data time: 2.14e-03, avg batch time: 0.1857, average loss: 2.7969
[09/16 02:05:44 visual_prompt]: Classification results with test_vtab-dtd: top1: 53.51	top5: 82.45	
[09/16 02:05:44 visual_prompt]: Training 24 / 100 epoch, with learning rate 4.7469851157479175
[09/16 02:05:52 visual_prompt]: Epoch 24 / 100: avg data time: 4.53e-02, avg batch time: 0.4503, average train loss: 0.2708
[09/16 02:05:53 visual_prompt]: Inference (val):avg data time: 3.84e-05, avg batch time: 0.1431, average loss: 0.2032
[09/16 02:05:53 visual_prompt]: Classification results with val_vtab-dtd: top1: 94.00	top5: 100.00	
[09/16 02:06:00 visual_prompt]: Inference (test):avg data time: 7.08e-03, avg batch time: 0.1885, average loss: 2.5919
[09/16 02:06:00 visual_prompt]: Classification results with test_vtab-dtd: top1: 55.80	top5: 83.62	
[09/16 02:06:00 visual_prompt]: Training 25 / 100 epoch, with learning rate 4.707368982147317
[09/16 02:06:08 visual_prompt]: Epoch 25 / 100: avg data time: 4.29e-02, avg batch time: 0.4471, average train loss: 0.2922
[09/16 02:06:10 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1433, average loss: 0.1991
[09/16 02:06:10 visual_prompt]: Classification results with val_vtab-dtd: top1: 92.50	top5: 100.00	
[09/16 02:06:17 visual_prompt]: Inference (test):avg data time: 5.57e-03, avg batch time: 0.1874, average loss: 2.5315
[09/16 02:06:17 visual_prompt]: Classification results with test_vtab-dtd: top1: 53.30	top5: 80.85	
[09/16 02:06:17 visual_prompt]: Training 26 / 100 epoch, with learning rate 4.665063509461097
[09/16 02:06:24 visual_prompt]: Epoch 26 / 100: avg data time: 4.88e-02, avg batch time: 0.4535, average train loss: 0.3270
[09/16 02:06:26 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1434, average loss: 0.2056
[09/16 02:06:26 visual_prompt]: Classification results with val_vtab-dtd: top1: 93.50	top5: 100.00	
[09/16 02:06:33 visual_prompt]: Inference (test):avg data time: 6.38e-03, avg batch time: 0.1893, average loss: 2.5590
[09/16 02:06:33 visual_prompt]: Classification results with test_vtab-dtd: top1: 54.79	top5: 80.80	
[09/16 02:06:33 visual_prompt]: Training 27 / 100 epoch, with learning rate 4.620120240391064
[09/16 02:06:41 visual_prompt]: Epoch 27 / 100: avg data time: 6.53e-02, avg batch time: 0.4699, average train loss: 0.2193
[09/16 02:06:42 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.1434, average loss: 0.3309
[09/16 02:06:42 visual_prompt]: Classification results with val_vtab-dtd: top1: 91.00	top5: 99.50	
[09/16 02:06:49 visual_prompt]: Inference (test):avg data time: 5.00e-03, avg batch time: 0.1887, average loss: 2.9863
[09/16 02:06:49 visual_prompt]: Classification results with test_vtab-dtd: top1: 50.11	top5: 80.43	
[09/16 02:06:49 visual_prompt]: Training 28 / 100 epoch, with learning rate 4.572593931387604
[09/16 02:06:57 visual_prompt]: Epoch 28 / 100: avg data time: 5.84e-02, avg batch time: 0.4600, average train loss: 0.1446
[09/16 02:06:59 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1433, average loss: 0.1145
[09/16 02:06:59 visual_prompt]: Classification results with val_vtab-dtd: top1: 95.50	top5: 100.00	
[09/16 02:07:06 visual_prompt]: Inference (test):avg data time: 5.17e-03, avg batch time: 0.1897, average loss: 2.6316
[09/16 02:07:06 visual_prompt]: Classification results with test_vtab-dtd: top1: 52.98	top5: 82.39	
[09/16 02:07:06 visual_prompt]: Training 29 / 100 epoch, with learning rate 4.522542485937368
[09/16 02:07:14 visual_prompt]: Epoch 29 / 100: avg data time: 6.15e-02, avg batch time: 0.5116, average train loss: 0.1568
[09/16 02:07:16 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1434, average loss: 0.0900
[09/16 02:07:16 visual_prompt]: Classification results with val_vtab-dtd: top1: 97.50	top5: 100.00	
[09/16 02:07:23 visual_prompt]: Inference (test):avg data time: 2.77e-03, avg batch time: 0.1884, average loss: 2.5337
[09/16 02:07:23 visual_prompt]: Classification results with test_vtab-dtd: top1: 57.13	top5: 83.19	
[09/16 02:07:23 visual_prompt]: Best epoch 29: best metric: 0.975
[09/16 02:07:23 visual_prompt]: Training 30 / 100 epoch, with learning rate 4.4700268840168045
[09/16 02:07:30 visual_prompt]: Epoch 30 / 100: avg data time: 4.72e-02, avg batch time: 0.4520, average train loss: 0.1353
[09/16 02:07:32 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1434, average loss: 0.2629
[09/16 02:07:32 visual_prompt]: Classification results with val_vtab-dtd: top1: 93.00	top5: 100.00	
[09/16 02:07:39 visual_prompt]: Inference (test):avg data time: 2.15e-03, avg batch time: 0.1876, average loss: 2.8424
[09/16 02:07:39 visual_prompt]: Classification results with test_vtab-dtd: top1: 53.24	top5: 81.38	
[09/16 02:07:39 visual_prompt]: Training 31 / 100 epoch, with learning rate 4.415111107797445
[09/16 02:07:46 visual_prompt]: Epoch 31 / 100: avg data time: 4.61e-02, avg batch time: 0.4505, average train loss: 0.1631
[09/16 02:07:48 visual_prompt]: Inference (val):avg data time: 4.21e-05, avg batch time: 0.1471, average loss: 0.1236
[09/16 02:07:48 visual_prompt]: Classification results with val_vtab-dtd: top1: 95.00	top5: 99.50	
[09/16 02:07:55 visual_prompt]: Inference (test):avg data time: 4.26e-03, avg batch time: 0.1872, average loss: 2.5647
[09/16 02:07:55 visual_prompt]: Classification results with test_vtab-dtd: top1: 54.89	top5: 82.34	
[09/16 02:07:55 visual_prompt]: Training 32 / 100 epoch, with learning rate 4.357862063693486
[09/16 02:08:03 visual_prompt]: Epoch 32 / 100: avg data time: 6.29e-02, avg batch time: 0.4685, average train loss: 0.1529
[09/16 02:08:04 visual_prompt]: Inference (val):avg data time: 3.46e-05, avg batch time: 0.1484, average loss: 0.1651
[09/16 02:08:04 visual_prompt]: Classification results with val_vtab-dtd: top1: 95.50	top5: 99.50	
[09/16 02:08:11 visual_prompt]: Inference (test):avg data time: 4.43e-03, avg batch time: 0.1875, average loss: 2.8352
[09/16 02:08:11 visual_prompt]: Classification results with test_vtab-dtd: top1: 50.59	top5: 80.80	
[09/16 02:08:11 visual_prompt]: Training 33 / 100 epoch, with learning rate 4.298349500846628
[09/16 02:08:19 visual_prompt]: Epoch 33 / 100: avg data time: 5.96e-02, avg batch time: 0.4631, average train loss: 0.1555
[09/16 02:08:21 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1435, average loss: 0.2467
[09/16 02:08:21 visual_prompt]: Classification results with val_vtab-dtd: top1: 94.00	top5: 100.00	
[09/16 02:08:28 visual_prompt]: Inference (test):avg data time: 3.23e-03, avg batch time: 0.1891, average loss: 2.9215
[09/16 02:08:28 visual_prompt]: Classification results with test_vtab-dtd: top1: 52.23	top5: 80.90	
[09/16 02:08:28 visual_prompt]: Training 34 / 100 epoch, with learning rate 4.236645926147493
[09/16 02:08:35 visual_prompt]: Epoch 34 / 100: avg data time: 5.69e-02, avg batch time: 0.4607, average train loss: 0.2083
[09/16 02:08:37 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1437, average loss: 0.0738
[09/16 02:08:37 visual_prompt]: Classification results with val_vtab-dtd: top1: 98.50	top5: 100.00	
[09/16 02:08:44 visual_prompt]: Inference (test):avg data time: 3.74e-03, avg batch time: 0.1873, average loss: 2.5449
[09/16 02:08:44 visual_prompt]: Classification results with test_vtab-dtd: top1: 56.28	top5: 82.82	
[09/16 02:08:44 visual_prompt]: Best epoch 34: best metric: 0.985
[09/16 02:08:44 visual_prompt]: Training 35 / 100 epoch, with learning rate 4.172826515897146
[09/16 02:08:52 visual_prompt]: Epoch 35 / 100: avg data time: 6.44e-02, avg batch time: 0.4650, average train loss: 0.1112
[09/16 02:08:53 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.1433, average loss: 0.0372
[09/16 02:08:53 visual_prompt]: Classification results with val_vtab-dtd: top1: 99.50	top5: 100.00	
[09/16 02:09:00 visual_prompt]: Inference (test):avg data time: 4.49e-03, avg batch time: 0.1864, average loss: 2.3410
[09/16 02:09:00 visual_prompt]: Classification results with test_vtab-dtd: top1: 58.78	top5: 83.78	
[09/16 02:09:00 visual_prompt]: Best epoch 35: best metric: 0.995
[09/16 02:09:00 visual_prompt]: Training 36 / 100 epoch, with learning rate 4.106969024216348
[09/16 02:09:08 visual_prompt]: Epoch 36 / 100: avg data time: 5.69e-02, avg batch time: 0.4880, average train loss: 0.1038
[09/16 02:09:10 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1434, average loss: 0.0349
[09/16 02:09:10 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:09:17 visual_prompt]: Inference (test):avg data time: 4.92e-03, avg batch time: 0.1869, average loss: 2.3835
[09/16 02:09:17 visual_prompt]: Classification results with test_vtab-dtd: top1: 57.23	top5: 83.09	
[09/16 02:09:17 visual_prompt]: Best epoch 36: best metric: 1.000
[09/16 02:09:17 visual_prompt]: Training 37 / 100 epoch, with learning rate 4.039153688314146
[09/16 02:09:25 visual_prompt]: Epoch 37 / 100: avg data time: 5.38e-02, avg batch time: 0.4944, average train loss: 0.0803
[09/16 02:09:27 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1433, average loss: 0.1000
[09/16 02:09:27 visual_prompt]: Classification results with val_vtab-dtd: top1: 95.50	top5: 100.00	
[09/16 02:09:34 visual_prompt]: Inference (test):avg data time: 2.09e-03, avg batch time: 0.1879, average loss: 2.5182
[09/16 02:09:34 visual_prompt]: Classification results with test_vtab-dtd: top1: 56.97	top5: 83.14	
[09/16 02:09:34 visual_prompt]: Training 38 / 100 epoch, with learning rate 3.969463130731183
[09/16 02:09:41 visual_prompt]: Epoch 38 / 100: avg data time: 6.00e-02, avg batch time: 0.4685, average train loss: 0.1087
[09/16 02:09:43 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1433, average loss: 0.0795
[09/16 02:09:43 visual_prompt]: Classification results with val_vtab-dtd: top1: 98.50	top5: 100.00	
[09/16 02:09:50 visual_prompt]: Inference (test):avg data time: 4.14e-03, avg batch time: 0.1857, average loss: 2.4112
[09/16 02:09:50 visual_prompt]: Classification results with test_vtab-dtd: top1: 55.37	top5: 82.07	
[09/16 02:09:50 visual_prompt]: Training 39 / 100 epoch, with learning rate 3.897982258676867
[09/16 02:09:58 visual_prompt]: Epoch 39 / 100: avg data time: 6.27e-02, avg batch time: 0.4653, average train loss: 0.0797
[09/16 02:09:59 visual_prompt]: Inference (val):avg data time: 5.13e-05, avg batch time: 0.1435, average loss: 0.0730
[09/16 02:09:59 visual_prompt]: Classification results with val_vtab-dtd: top1: 98.00	top5: 100.00	
[09/16 02:10:07 visual_prompt]: Inference (test):avg data time: 3.00e-03, avg batch time: 0.1886, average loss: 2.0980
[09/16 02:10:07 visual_prompt]: Classification results with test_vtab-dtd: top1: 60.05	top5: 85.16	
[09/16 02:10:07 visual_prompt]: Training 40 / 100 epoch, with learning rate 3.824798160583012
[09/16 02:10:14 visual_prompt]: Epoch 40 / 100: avg data time: 5.51e-02, avg batch time: 0.4603, average train loss: 0.0607
[09/16 02:10:16 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1434, average loss: 0.1136
[09/16 02:10:16 visual_prompt]: Classification results with val_vtab-dtd: top1: 97.50	top5: 99.50	
[09/16 02:10:23 visual_prompt]: Inference (test):avg data time: 4.27e-03, avg batch time: 0.1887, average loss: 2.3466
[09/16 02:10:23 visual_prompt]: Classification results with test_vtab-dtd: top1: 58.35	top5: 82.93	
[09/16 02:10:23 visual_prompt]: Training 41 / 100 epoch, with learning rate 3.75
[09/16 02:10:31 visual_prompt]: Epoch 41 / 100: avg data time: 5.64e-02, avg batch time: 0.4587, average train loss: 0.0917
[09/16 02:10:32 visual_prompt]: Inference (val):avg data time: 4.03e-05, avg batch time: 0.1435, average loss: 0.1102
[09/16 02:10:32 visual_prompt]: Classification results with val_vtab-dtd: top1: 96.50	top5: 99.50	
[09/16 02:10:39 visual_prompt]: Inference (test):avg data time: 2.61e-03, avg batch time: 0.1872, average loss: 2.3376
[09/16 02:10:39 visual_prompt]: Classification results with test_vtab-dtd: top1: 56.49	top5: 82.87	
[09/16 02:10:39 visual_prompt]: Training 42 / 100 epoch, with learning rate 3.673678906964727
[09/16 02:10:47 visual_prompt]: Epoch 42 / 100: avg data time: 4.39e-02, avg batch time: 0.4486, average train loss: 0.0760
[09/16 02:10:48 visual_prompt]: Inference (val):avg data time: 3.78e-05, avg batch time: 0.1433, average loss: 0.0405
[09/16 02:10:48 visual_prompt]: Classification results with val_vtab-dtd: top1: 99.00	top5: 100.00	
[09/16 02:10:55 visual_prompt]: Inference (test):avg data time: 4.22e-03, avg batch time: 0.1907, average loss: 2.3540
[09/16 02:10:55 visual_prompt]: Classification results with test_vtab-dtd: top1: 58.09	top5: 82.82	
[09/16 02:10:55 visual_prompt]: Training 43 / 100 epoch, with learning rate 3.5959278669726933
[09/16 02:11:03 visual_prompt]: Epoch 43 / 100: avg data time: 4.44e-02, avg batch time: 0.4522, average train loss: 0.0619
[09/16 02:11:04 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1432, average loss: 0.0174
[09/16 02:11:04 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:11:11 visual_prompt]: Inference (test):avg data time: 3.68e-03, avg batch time: 0.1862, average loss: 2.1252
[09/16 02:11:11 visual_prompt]: Classification results with test_vtab-dtd: top1: 58.19	top5: 84.31	
[09/16 02:11:11 visual_prompt]: Training 44 / 100 epoch, with learning rate 3.516841607689501
[09/16 02:11:19 visual_prompt]: Epoch 44 / 100: avg data time: 6.28e-02, avg batch time: 0.4672, average train loss: 0.0688
[09/16 02:11:21 visual_prompt]: Inference (val):avg data time: 4.52e-05, avg batch time: 0.1435, average loss: 0.0482
[09/16 02:11:21 visual_prompt]: Classification results with val_vtab-dtd: top1: 98.50	top5: 100.00	
[09/16 02:11:28 visual_prompt]: Inference (test):avg data time: 2.18e-03, avg batch time: 0.1854, average loss: 2.1429
[09/16 02:11:28 visual_prompt]: Classification results with test_vtab-dtd: top1: 58.78	top5: 83.62	
[09/16 02:11:28 visual_prompt]: Training 45 / 100 epoch, with learning rate 3.4365164835397803
[09/16 02:11:35 visual_prompt]: Epoch 45 / 100: avg data time: 6.80e-02, avg batch time: 0.4714, average train loss: 0.4380
[09/16 02:11:37 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1440, average loss: 0.1703
[09/16 02:11:37 visual_prompt]: Classification results with val_vtab-dtd: top1: 95.00	top5: 100.00	
[09/16 02:11:44 visual_prompt]: Inference (test):avg data time: 3.57e-03, avg batch time: 0.1877, average loss: 2.2042
[09/16 02:11:44 visual_prompt]: Classification results with test_vtab-dtd: top1: 54.68	top5: 81.81	
[09/16 02:11:44 visual_prompt]: Training 46 / 100 epoch, with learning rate 3.3550503583141724
[09/16 02:11:52 visual_prompt]: Epoch 46 / 100: avg data time: 5.39e-02, avg batch time: 0.4578, average train loss: 0.1508
[09/16 02:11:53 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1438, average loss: 0.0902
[09/16 02:11:53 visual_prompt]: Classification results with val_vtab-dtd: top1: 97.50	top5: 100.00	
[09/16 02:12:00 visual_prompt]: Inference (test):avg data time: 3.98e-03, avg batch time: 0.1888, average loss: 2.1390
[09/16 02:12:00 visual_prompt]: Classification results with test_vtab-dtd: top1: 58.09	top5: 83.94	
[09/16 02:12:00 visual_prompt]: Training 47 / 100 epoch, with learning rate 3.2725424859373686
[09/16 02:12:08 visual_prompt]: Epoch 47 / 100: avg data time: 5.80e-02, avg batch time: 0.4604, average train loss: 0.1034
[09/16 02:12:10 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1435, average loss: 0.0468
[09/16 02:12:10 visual_prompt]: Classification results with val_vtab-dtd: top1: 98.50	top5: 100.00	
[09/16 02:12:16 visual_prompt]: Inference (test):avg data time: 3.61e-03, avg batch time: 0.1861, average loss: 2.1637
[09/16 02:12:16 visual_prompt]: Classification results with test_vtab-dtd: top1: 57.71	top5: 83.78	
[09/16 02:12:16 visual_prompt]: Training 48 / 100 epoch, with learning rate 3.1890933895424975
[09/16 02:12:24 visual_prompt]: Epoch 48 / 100: avg data time: 4.99e-02, avg batch time: 0.4529, average train loss: 0.0527
[09/16 02:12:26 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1436, average loss: 0.0291
[09/16 02:12:26 visual_prompt]: Classification results with val_vtab-dtd: top1: 99.50	top5: 100.00	
[09/16 02:12:33 visual_prompt]: Inference (test):avg data time: 4.09e-03, avg batch time: 0.1888, average loss: 2.1292
[09/16 02:12:33 visual_prompt]: Classification results with test_vtab-dtd: top1: 59.31	top5: 84.57	
[09/16 02:12:33 visual_prompt]: Training 49 / 100 epoch, with learning rate 3.104804738999169
[09/16 02:12:41 visual_prompt]: Epoch 49 / 100: avg data time: 5.97e-02, avg batch time: 0.4632, average train loss: 0.0432
[09/16 02:12:42 visual_prompt]: Inference (val):avg data time: 4.59e-05, avg batch time: 0.1453, average loss: 0.0122
[09/16 02:12:42 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:12:49 visual_prompt]: Inference (test):avg data time: 5.11e-03, avg batch time: 0.1877, average loss: 1.9291
[09/16 02:12:49 visual_prompt]: Classification results with test_vtab-dtd: top1: 61.49	top5: 85.32	
[09/16 02:12:49 visual_prompt]: Training 50 / 100 epoch, with learning rate 3.019779227044398
[09/16 02:12:57 visual_prompt]: Epoch 50 / 100: avg data time: 5.62e-02, avg batch time: 0.4656, average train loss: 0.0224
[09/16 02:12:59 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1433, average loss: 0.0257
[09/16 02:12:59 visual_prompt]: Classification results with val_vtab-dtd: top1: 99.00	top5: 100.00	
[09/16 02:13:06 visual_prompt]: Inference (test):avg data time: 4.52e-03, avg batch time: 0.1874, average loss: 1.9228
[09/16 02:13:06 visual_prompt]: Classification results with test_vtab-dtd: top1: 61.38	top5: 84.89	
[09/16 02:13:06 visual_prompt]: Training 51 / 100 epoch, with learning rate 2.934120444167326
[09/16 02:13:13 visual_prompt]: Epoch 51 / 100: avg data time: 6.38e-02, avg batch time: 0.4661, average train loss: 0.0207
[09/16 02:13:15 visual_prompt]: Inference (val):avg data time: 3.64e-05, avg batch time: 0.1436, average loss: 0.0162
[09/16 02:13:15 visual_prompt]: Classification results with val_vtab-dtd: top1: 99.50	top5: 100.00	
[09/16 02:13:22 visual_prompt]: Inference (test):avg data time: 2.33e-03, avg batch time: 0.1867, average loss: 1.8815
[09/16 02:13:22 visual_prompt]: Classification results with test_vtab-dtd: top1: 61.81	top5: 85.37	
[09/16 02:13:22 visual_prompt]: Training 52 / 100 epoch, with learning rate 2.8479327524001636
[09/16 02:13:30 visual_prompt]: Epoch 52 / 100: avg data time: 4.71e-02, avg batch time: 0.4498, average train loss: 0.0133
[09/16 02:13:31 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1433, average loss: 0.0055
[09/16 02:13:31 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:13:38 visual_prompt]: Inference (test):avg data time: 4.12e-03, avg batch time: 0.1899, average loss: 1.7607
[09/16 02:13:38 visual_prompt]: Classification results with test_vtab-dtd: top1: 60.85	top5: 86.54	
[09/16 02:13:38 visual_prompt]: Training 53 / 100 epoch, with learning rate 2.761321158169134
[09/16 02:13:46 visual_prompt]: Epoch 53 / 100: avg data time: 5.35e-02, avg batch time: 0.4562, average train loss: 0.0065
[09/16 02:13:48 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1432, average loss: 0.0085
[09/16 02:13:48 visual_prompt]: Classification results with val_vtab-dtd: top1: 99.50	top5: 100.00	
[09/16 02:13:55 visual_prompt]: Inference (test):avg data time: 7.36e-03, avg batch time: 0.1900, average loss: 1.7403
[09/16 02:13:55 visual_prompt]: Classification results with test_vtab-dtd: top1: 63.51	top5: 86.38	
[09/16 02:13:55 visual_prompt]: Training 54 / 100 epoch, with learning rate 2.6743911843603128
[09/16 02:14:02 visual_prompt]: Epoch 54 / 100: avg data time: 5.42e-02, avg batch time: 0.4584, average train loss: 0.0060
[09/16 02:14:04 visual_prompt]: Inference (val):avg data time: 3.50e-05, avg batch time: 0.1435, average loss: 0.0037
[09/16 02:14:04 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:14:11 visual_prompt]: Inference (test):avg data time: 6.60e-03, avg batch time: 0.1909, average loss: 1.6360
[09/16 02:14:11 visual_prompt]: Classification results with test_vtab-dtd: top1: 63.72	top5: 87.61	
[09/16 02:14:11 visual_prompt]: Training 55 / 100 epoch, with learning rate 2.5872487417562526
[09/16 02:14:19 visual_prompt]: Epoch 55 / 100: avg data time: 4.90e-02, avg batch time: 0.4564, average train loss: 0.0039
[09/16 02:14:20 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1436, average loss: 0.0032
[09/16 02:14:20 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:14:27 visual_prompt]: Inference (test):avg data time: 3.07e-03, avg batch time: 0.1860, average loss: 1.5966
[09/16 02:14:27 visual_prompt]: Classification results with test_vtab-dtd: top1: 64.04	top5: 87.50	
[09/16 02:14:27 visual_prompt]: Training 56 / 100 epoch, with learning rate 2.5
[09/16 02:14:35 visual_prompt]: Epoch 56 / 100: avg data time: 6.33e-02, avg batch time: 0.4665, average train loss: 0.0035
[09/16 02:14:37 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1433, average loss: 0.0030
[09/16 02:14:37 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:14:44 visual_prompt]: Inference (test):avg data time: 3.66e-03, avg batch time: 0.1870, average loss: 1.5689
[09/16 02:14:44 visual_prompt]: Classification results with test_vtab-dtd: top1: 63.99	top5: 87.50	
[09/16 02:14:44 visual_prompt]: Training 57 / 100 epoch, with learning rate 2.4127512582437483
[09/16 02:14:51 visual_prompt]: Epoch 57 / 100: avg data time: 5.44e-02, avg batch time: 0.4582, average train loss: 0.0036
[09/16 02:14:53 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1435, average loss: 0.0032
[09/16 02:14:53 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:15:00 visual_prompt]: Inference (test):avg data time: 4.04e-03, avg batch time: 0.1877, average loss: 1.5391
[09/16 02:15:00 visual_prompt]: Classification results with test_vtab-dtd: top1: 64.36	top5: 87.87	
[09/16 02:15:00 visual_prompt]: Training 58 / 100 epoch, with learning rate 2.325608815639687
[09/16 02:15:08 visual_prompt]: Epoch 58 / 100: avg data time: 5.92e-02, avg batch time: 0.4616, average train loss: 0.0038
[09/16 02:15:09 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.1436, average loss: 0.0034
[09/16 02:15:09 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:15:16 visual_prompt]: Inference (test):avg data time: 4.57e-03, avg batch time: 0.1874, average loss: 1.5138
[09/16 02:15:16 visual_prompt]: Classification results with test_vtab-dtd: top1: 64.41	top5: 87.93	
[09/16 02:15:16 visual_prompt]: Training 59 / 100 epoch, with learning rate 2.2386788418308665
[09/16 02:15:24 visual_prompt]: Epoch 59 / 100: avg data time: 6.15e-02, avg batch time: 0.4644, average train loss: 0.0040
[09/16 02:15:26 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1434, average loss: 0.0035
[09/16 02:15:26 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:15:33 visual_prompt]: Inference (test):avg data time: 3.17e-03, avg batch time: 0.1876, average loss: 1.4923
[09/16 02:15:33 visual_prompt]: Classification results with test_vtab-dtd: top1: 64.47	top5: 88.14	
[09/16 02:15:33 visual_prompt]: Training 60 / 100 epoch, with learning rate 2.1520672475998373
[09/16 02:15:40 visual_prompt]: Epoch 60 / 100: avg data time: 6.52e-02, avg batch time: 0.4659, average train loss: 0.0043
[09/16 02:15:42 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1432, average loss: 0.0037
[09/16 02:15:42 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:15:49 visual_prompt]: Inference (test):avg data time: 5.43e-03, avg batch time: 0.1889, average loss: 1.4725
[09/16 02:15:49 visual_prompt]: Classification results with test_vtab-dtd: top1: 64.84	top5: 88.40	
[09/16 02:15:49 visual_prompt]: Training 61 / 100 epoch, with learning rate 2.0658795558326744
[09/16 02:15:56 visual_prompt]: Epoch 61 / 100: avg data time: 4.12e-02, avg batch time: 0.4482, average train loss: 0.0045
[09/16 02:15:58 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1435, average loss: 0.0038
[09/16 02:15:58 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:16:05 visual_prompt]: Inference (test):avg data time: 3.30e-03, avg batch time: 0.1891, average loss: 1.4551
[09/16 02:16:05 visual_prompt]: Classification results with test_vtab-dtd: top1: 65.00	top5: 88.30	
[09/16 02:16:05 visual_prompt]: Training 62 / 100 epoch, with learning rate 1.980220772955602
[09/16 02:16:13 visual_prompt]: Epoch 62 / 100: avg data time: 6.23e-02, avg batch time: 0.4653, average train loss: 0.0047
[09/16 02:16:14 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1434, average loss: 0.0039
[09/16 02:16:14 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:16:21 visual_prompt]: Inference (test):avg data time: 5.10e-03, avg batch time: 0.1882, average loss: 1.4381
[09/16 02:16:21 visual_prompt]: Classification results with test_vtab-dtd: top1: 64.84	top5: 88.56	
[09/16 02:16:21 visual_prompt]: Training 63 / 100 epoch, with learning rate 1.895195261000831
[09/16 02:16:29 visual_prompt]: Epoch 63 / 100: avg data time: 6.43e-02, avg batch time: 0.4677, average train loss: 0.0048
[09/16 02:16:31 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1434, average loss: 0.0040
[09/16 02:16:31 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:16:38 visual_prompt]: Inference (test):avg data time: 4.11e-03, avg batch time: 0.1867, average loss: 1.4233
[09/16 02:16:38 visual_prompt]: Classification results with test_vtab-dtd: top1: 65.21	top5: 88.40	
[09/16 02:16:38 visual_prompt]: Training 64 / 100 epoch, with learning rate 1.8109066104575022
[09/16 02:16:46 visual_prompt]: Epoch 64 / 100: avg data time: 6.28e-02, avg batch time: 0.4658, average train loss: 0.0049
[09/16 02:16:47 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1434, average loss: 0.0041
[09/16 02:16:47 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:16:54 visual_prompt]: Inference (test):avg data time: 4.36e-03, avg batch time: 0.1876, average loss: 1.4116
[09/16 02:16:54 visual_prompt]: Classification results with test_vtab-dtd: top1: 65.69	top5: 88.51	
[09/16 02:16:54 visual_prompt]: Training 65 / 100 epoch, with learning rate 1.7274575140626316
[09/16 02:17:02 visual_prompt]: Epoch 65 / 100: avg data time: 4.49e-02, avg batch time: 0.4501, average train loss: 0.0049
[09/16 02:17:03 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.1435, average loss: 0.0041
[09/16 02:17:03 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:17:10 visual_prompt]: Inference (test):avg data time: 3.91e-03, avg batch time: 0.1908, average loss: 1.4010
[09/16 02:17:10 visual_prompt]: Classification results with test_vtab-dtd: top1: 65.21	top5: 88.51	
[09/16 02:17:10 visual_prompt]: Training 66 / 100 epoch, with learning rate 1.6449496416858285
[09/16 02:17:18 visual_prompt]: Epoch 66 / 100: avg data time: 5.95e-02, avg batch time: 0.4605, average train loss: 0.0049
[09/16 02:17:20 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1432, average loss: 0.0041
[09/16 02:17:20 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:17:27 visual_prompt]: Inference (test):avg data time: 3.99e-03, avg batch time: 0.1872, average loss: 1.3901
[09/16 02:17:27 visual_prompt]: Classification results with test_vtab-dtd: top1: 65.00	top5: 89.04	
[09/16 02:17:27 visual_prompt]: Training 67 / 100 epoch, with learning rate 1.5634835164602199
[09/16 02:17:34 visual_prompt]: Epoch 67 / 100: avg data time: 4.34e-02, avg batch time: 0.4502, average train loss: 0.0050
[09/16 02:17:36 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1439, average loss: 0.0041
[09/16 02:17:36 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:17:43 visual_prompt]: Inference (test):avg data time: 3.89e-03, avg batch time: 0.1888, average loss: 1.3830
[09/16 02:17:43 visual_prompt]: Classification results with test_vtab-dtd: top1: 65.74	top5: 89.04	
[09/16 02:17:43 visual_prompt]: Training 68 / 100 epoch, with learning rate 1.4831583923104998
[09/16 02:17:51 visual_prompt]: Epoch 68 / 100: avg data time: 6.72e-02, avg batch time: 0.4710, average train loss: 0.0049
[09/16 02:17:52 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1433, average loss: 0.0040
[09/16 02:17:52 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:17:59 visual_prompt]: Inference (test):avg data time: 1.84e-03, avg batch time: 0.1862, average loss: 1.3748
[09/16 02:17:59 visual_prompt]: Classification results with test_vtab-dtd: top1: 65.90	top5: 88.94	
[09/16 02:17:59 visual_prompt]: Training 69 / 100 epoch, with learning rate 1.4040721330273063
[09/16 02:18:07 visual_prompt]: Epoch 69 / 100: avg data time: 5.24e-02, avg batch time: 0.4535, average train loss: 0.0050
[09/16 02:18:08 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1437, average loss: 0.0040
[09/16 02:18:08 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:18:15 visual_prompt]: Inference (test):avg data time: 3.89e-03, avg batch time: 0.1868, average loss: 1.3668
[09/16 02:18:15 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.12	top5: 89.20	
[09/16 02:18:15 visual_prompt]: Training 70 / 100 epoch, with learning rate 1.3263210930352738
[09/16 02:18:23 visual_prompt]: Epoch 70 / 100: avg data time: 5.91e-02, avg batch time: 0.4622, average train loss: 0.0049
[09/16 02:18:25 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1434, average loss: 0.0040
[09/16 02:18:25 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:18:32 visual_prompt]: Inference (test):avg data time: 4.05e-03, avg batch time: 0.1868, average loss: 1.3643
[09/16 02:18:32 visual_prompt]: Classification results with test_vtab-dtd: top1: 65.85	top5: 89.10	
[09/16 02:18:32 visual_prompt]: Training 71 / 100 epoch, with learning rate 1.2500000000000004
[09/16 02:18:40 visual_prompt]: Epoch 71 / 100: avg data time: 6.80e-02, avg batch time: 0.4694, average train loss: 0.0048
[09/16 02:18:41 visual_prompt]: Inference (val):avg data time: 3.80e-05, avg batch time: 0.1475, average loss: 0.0040
[09/16 02:18:41 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:18:48 visual_prompt]: Inference (test):avg data time: 3.36e-03, avg batch time: 0.1874, average loss: 1.3573
[09/16 02:18:48 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.33	top5: 89.31	
[09/16 02:18:48 visual_prompt]: Training 72 / 100 epoch, with learning rate 1.175201839416988
[09/16 02:18:56 visual_prompt]: Epoch 72 / 100: avg data time: 5.94e-02, avg batch time: 0.4691, average train loss: 0.0048
[09/16 02:18:58 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1433, average loss: 0.0039
[09/16 02:18:58 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:19:05 visual_prompt]: Inference (test):avg data time: 2.32e-03, avg batch time: 0.1874, average loss: 1.3537
[09/16 02:19:05 visual_prompt]: Classification results with test_vtab-dtd: top1: 65.85	top5: 88.94	
[09/16 02:19:05 visual_prompt]: Training 73 / 100 epoch, with learning rate 1.1020177413231333
[09/16 02:19:12 visual_prompt]: Epoch 73 / 100: avg data time: 5.74e-02, avg batch time: 0.4619, average train loss: 0.0048
[09/16 02:19:14 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1434, average loss: 0.0038
[09/16 02:19:14 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:19:21 visual_prompt]: Inference (test):avg data time: 3.98e-03, avg batch time: 0.1916, average loss: 1.3524
[09/16 02:19:21 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.06	top5: 89.41	
[09/16 02:19:21 visual_prompt]: Training 74 / 100 epoch, with learning rate 1.0305368692688175
[09/16 02:19:28 visual_prompt]: Epoch 74 / 100: avg data time: 4.21e-02, avg batch time: 0.4474, average train loss: 0.0047
[09/16 02:19:30 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1435, average loss: 0.0038
[09/16 02:19:30 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:19:37 visual_prompt]: Inference (test):avg data time: 5.52e-03, avg batch time: 0.1894, average loss: 1.3511
[09/16 02:19:37 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.12	top5: 89.04	
[09/16 02:19:37 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.9608463116858543
[09/16 02:19:45 visual_prompt]: Epoch 75 / 100: avg data time: 5.57e-02, avg batch time: 0.4621, average train loss: 0.0046
[09/16 02:19:46 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1434, average loss: 0.0037
[09/16 02:19:46 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:19:53 visual_prompt]: Inference (test):avg data time: 5.52e-03, avg batch time: 0.1888, average loss: 1.3505
[09/16 02:19:53 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.17	top5: 89.10	
[09/16 02:19:53 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.8930309757836516
[09/16 02:20:01 visual_prompt]: Epoch 76 / 100: avg data time: 6.17e-02, avg batch time: 0.4636, average train loss: 0.0046
[09/16 02:20:03 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1435, average loss: 0.0037
[09/16 02:20:03 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:20:10 visual_prompt]: Inference (test):avg data time: 5.80e-03, avg batch time: 0.1872, average loss: 1.3436
[09/16 02:20:10 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.22	top5: 89.10	
[09/16 02:20:10 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.8271734841028553
[09/16 02:20:18 visual_prompt]: Epoch 77 / 100: avg data time: 6.56e-02, avg batch time: 0.4687, average train loss: 0.0046
[09/16 02:20:19 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1431, average loss: 0.0036
[09/16 02:20:19 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:20:26 visual_prompt]: Inference (test):avg data time: 3.60e-03, avg batch time: 0.1880, average loss: 1.3458
[09/16 02:20:26 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.12	top5: 88.83	
[09/16 02:20:26 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.7633540738525066
[09/16 02:20:34 visual_prompt]: Epoch 78 / 100: avg data time: 6.80e-02, avg batch time: 0.4697, average train loss: 0.0045
[09/16 02:20:36 visual_prompt]: Inference (val):avg data time: 4.39e-05, avg batch time: 0.1433, average loss: 0.0036
[09/16 02:20:36 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:20:43 visual_prompt]: Inference (test):avg data time: 4.22e-03, avg batch time: 0.1857, average loss: 1.3442
[09/16 02:20:43 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.17	top5: 89.04	
[09/16 02:20:43 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.7016504991533725
[09/16 02:20:50 visual_prompt]: Epoch 79 / 100: avg data time: 5.94e-02, avg batch time: 0.4624, average train loss: 0.0045
[09/16 02:20:52 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1432, average loss: 0.0035
[09/16 02:20:52 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:20:59 visual_prompt]: Inference (test):avg data time: 3.79e-03, avg batch time: 0.1859, average loss: 1.3438
[09/16 02:20:59 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.17	top5: 88.88	
[09/16 02:20:59 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.6421379363065141
[09/16 02:21:07 visual_prompt]: Epoch 80 / 100: avg data time: 5.30e-02, avg batch time: 0.4685, average train loss: 0.0044
[09/16 02:21:08 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1433, average loss: 0.0034
[09/16 02:21:08 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:21:15 visual_prompt]: Inference (test):avg data time: 5.30e-03, avg batch time: 0.1868, average loss: 1.3400
[09/16 02:21:15 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.49	top5: 89.10	
[09/16 02:21:15 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.5848888922025552
[09/16 02:21:23 visual_prompt]: Epoch 81 / 100: avg data time: 5.53e-02, avg batch time: 0.4588, average train loss: 0.0044
[09/16 02:21:25 visual_prompt]: Inference (val):avg data time: 3.44e-05, avg batch time: 0.1435, average loss: 0.0034
[09/16 02:21:25 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:21:32 visual_prompt]: Inference (test):avg data time: 4.78e-03, avg batch time: 0.1871, average loss: 1.3397
[09/16 02:21:32 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.38	top5: 89.15	
[09/16 02:21:32 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.5299731159831953
[09/16 02:21:40 visual_prompt]: Epoch 82 / 100: avg data time: 6.61e-02, avg batch time: 0.4668, average train loss: 0.0043
[09/16 02:21:41 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1435, average loss: 0.0033
[09/16 02:21:41 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:21:48 visual_prompt]: Inference (test):avg data time: 3.86e-03, avg batch time: 0.1857, average loss: 1.3402
[09/16 02:21:48 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.12	top5: 89.04	
[09/16 02:21:48 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.47745751406263165
[09/16 02:21:56 visual_prompt]: Epoch 83 / 100: avg data time: 6.38e-02, avg batch time: 0.4654, average train loss: 0.0043
[09/16 02:21:58 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1432, average loss: 0.0033
[09/16 02:21:58 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:22:04 visual_prompt]: Inference (test):avg data time: 3.78e-03, avg batch time: 0.1880, average loss: 1.3417
[09/16 02:22:04 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.54	top5: 89.20	
[09/16 02:22:04 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.42740606861239594
[09/16 02:22:12 visual_prompt]: Epoch 84 / 100: avg data time: 6.28e-02, avg batch time: 0.4642, average train loss: 0.0042
[09/16 02:22:14 visual_prompt]: Inference (val):avg data time: 5.02e-05, avg batch time: 0.1432, average loss: 0.0033
[09/16 02:22:14 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:22:21 visual_prompt]: Inference (test):avg data time: 4.71e-03, avg batch time: 0.1872, average loss: 1.3364
[09/16 02:22:21 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.54	top5: 89.04	
[09/16 02:22:21 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.3798797596089351
[09/16 02:22:28 visual_prompt]: Epoch 85 / 100: avg data time: 6.21e-02, avg batch time: 0.4633, average train loss: 0.0041
[09/16 02:22:30 visual_prompt]: Inference (val):avg data time: 3.76e-05, avg batch time: 0.1434, average loss: 0.0032
[09/16 02:22:30 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:22:37 visual_prompt]: Inference (test):avg data time: 6.16e-03, avg batch time: 0.1896, average loss: 1.3392
[09/16 02:22:37 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.76	top5: 89.10	
[09/16 02:22:37 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.33493649053890323
[09/16 02:22:45 visual_prompt]: Epoch 86 / 100: avg data time: 6.13e-02, avg batch time: 0.4684, average train loss: 0.0041
[09/16 02:22:47 visual_prompt]: Inference (val):avg data time: 4.57e-05, avg batch time: 0.1434, average loss: 0.0032
[09/16 02:22:47 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:22:53 visual_prompt]: Inference (test):avg data time: 4.58e-03, avg batch time: 0.1870, average loss: 1.3400
[09/16 02:22:53 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.76	top5: 89.15	
[09/16 02:22:53 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.29263101785268253
[09/16 02:23:01 visual_prompt]: Epoch 87 / 100: avg data time: 5.64e-02, avg batch time: 0.4587, average train loss: 0.0040
[09/16 02:23:04 visual_prompt]: Inference (val):avg data time: 3.75e-04, avg batch time: 0.3538, average loss: 0.0032
[09/16 02:23:04 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:23:11 visual_prompt]: Inference (test):avg data time: 2.08e-03, avg batch time: 0.1868, average loss: 1.3395
[09/16 02:23:11 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.81	top5: 89.10	
[09/16 02:23:11 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.25301488425208296
[09/16 02:23:19 visual_prompt]: Epoch 88 / 100: avg data time: 6.67e-02, avg batch time: 0.4782, average train loss: 0.0041
[09/16 02:23:20 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1433, average loss: 0.0032
[09/16 02:23:20 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:23:27 visual_prompt]: Inference (test):avg data time: 4.20e-03, avg batch time: 0.1873, average loss: 1.3391
[09/16 02:23:27 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.70	top5: 89.04	
[09/16 02:23:27 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.21613635589349756
[09/16 02:23:35 visual_prompt]: Epoch 89 / 100: avg data time: 4.28e-02, avg batch time: 0.4489, average train loss: 0.0040
[09/16 02:23:36 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1438, average loss: 0.0032
[09/16 02:23:36 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:23:43 visual_prompt]: Inference (test):avg data time: 1.43e-03, avg batch time: 0.1865, average loss: 1.3390
[09/16 02:23:43 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.49	top5: 88.99	
[09/16 02:23:43 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.18204036358303172
[09/16 02:23:51 visual_prompt]: Epoch 90 / 100: avg data time: 5.64e-02, avg batch time: 0.4606, average train loss: 0.0040
[09/16 02:23:53 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1437, average loss: 0.0032
[09/16 02:23:53 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:24:00 visual_prompt]: Inference (test):avg data time: 6.17e-03, avg batch time: 0.1876, average loss: 1.3399
[09/16 02:24:00 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.70	top5: 89.15	
[09/16 02:24:00 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.1507684480352292
[09/16 02:24:07 visual_prompt]: Epoch 91 / 100: avg data time: 5.24e-02, avg batch time: 0.4558, average train loss: 0.0039
[09/16 02:24:09 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1434, average loss: 0.0032
[09/16 02:24:09 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:24:16 visual_prompt]: Inference (test):avg data time: 2.38e-03, avg batch time: 0.1861, average loss: 1.3401
[09/16 02:24:16 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.65	top5: 89.15	
[09/16 02:24:16 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.12235870926211617
[09/16 02:24:24 visual_prompt]: Epoch 92 / 100: avg data time: 6.35e-02, avg batch time: 0.4667, average train loss: 0.0040
[09/16 02:24:25 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1436, average loss: 0.0031
[09/16 02:24:25 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:24:32 visual_prompt]: Inference (test):avg data time: 2.85e-03, avg batch time: 0.1878, average loss: 1.3400
[09/16 02:24:32 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.76	top5: 89.04	
[09/16 02:24:32 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.09684576015420276
[09/16 02:24:40 visual_prompt]: Epoch 93 / 100: avg data time: 5.79e-02, avg batch time: 0.4607, average train loss: 0.0040
[09/16 02:24:42 visual_prompt]: Inference (val):avg data time: 3.82e-04, avg batch time: 0.2233, average loss: 0.0031
[09/16 02:24:42 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:24:49 visual_prompt]: Inference (test):avg data time: 5.89e-03, avg batch time: 0.1880, average loss: 1.3390
[09/16 02:24:49 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.86	top5: 89.15	
[09/16 02:24:49 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.07426068431000882
[09/16 02:24:57 visual_prompt]: Epoch 94 / 100: avg data time: 4.85e-02, avg batch time: 0.4975, average train loss: 0.0038
[09/16 02:24:59 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1434, average loss: 0.0031
[09/16 02:24:59 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:25:06 visual_prompt]: Inference (test):avg data time: 3.31e-03, avg batch time: 0.1895, average loss: 1.3382
[09/16 02:25:06 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.86	top5: 89.15	
[09/16 02:25:06 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.05463099816548578
[09/16 02:25:13 visual_prompt]: Epoch 95 / 100: avg data time: 5.33e-02, avg batch time: 0.4581, average train loss: 0.0040
[09/16 02:25:15 visual_prompt]: Inference (val):avg data time: 3.58e-05, avg batch time: 0.1433, average loss: 0.0031
[09/16 02:25:15 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:25:22 visual_prompt]: Inference (test):avg data time: 4.86e-03, avg batch time: 0.1896, average loss: 1.3388
[09/16 02:25:22 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.81	top5: 89.10	
[09/16 02:25:22 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.03798061746947995
[09/16 02:25:30 visual_prompt]: Epoch 96 / 100: avg data time: 6.08e-02, avg batch time: 0.4625, average train loss: 0.0039
[09/16 02:25:31 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1434, average loss: 0.0031
[09/16 02:25:31 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:25:38 visual_prompt]: Inference (test):avg data time: 3.08e-03, avg batch time: 0.1860, average loss: 1.3394
[09/16 02:25:38 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.81	top5: 88.99	
[09/16 02:25:38 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.024329828146074095
[09/16 02:25:46 visual_prompt]: Epoch 97 / 100: avg data time: 5.93e-02, avg batch time: 0.4617, average train loss: 0.0039
[09/16 02:25:48 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1433, average loss: 0.0031
[09/16 02:25:48 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:25:55 visual_prompt]: Inference (test):avg data time: 5.19e-03, avg batch time: 0.1891, average loss: 1.3395
[09/16 02:25:55 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.81	top5: 88.99	
[09/16 02:25:55 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.013695261579316775
[09/16 02:26:02 visual_prompt]: Epoch 98 / 100: avg data time: 6.25e-02, avg batch time: 0.4655, average train loss: 0.0039
[09/16 02:26:04 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.1434, average loss: 0.0031
[09/16 02:26:04 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:26:11 visual_prompt]: Inference (test):avg data time: 4.46e-03, avg batch time: 0.2063, average loss: 1.3394
[09/16 02:26:11 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.81	top5: 88.99	
[09/16 02:26:11 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.006089874350439506
[09/16 02:26:19 visual_prompt]: Epoch 99 / 100: avg data time: 5.89e-02, avg batch time: 0.4608, average train loss: 0.0039
[09/16 02:26:21 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1440, average loss: 0.0031
[09/16 02:26:21 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:26:28 visual_prompt]: Inference (test):avg data time: 6.40e-03, avg batch time: 0.1884, average loss: 1.3394
[09/16 02:26:28 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.81	top5: 89.04	
[09/16 02:26:28 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0015229324522605947
[09/16 02:26:35 visual_prompt]: Epoch 100 / 100: avg data time: 4.53e-02, avg batch time: 0.4504, average train loss: 0.0039
[09/16 02:26:37 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1434, average loss: 0.0031
[09/16 02:26:37 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:26:44 visual_prompt]: Inference (test):avg data time: 3.04e-03, avg batch time: 0.1872, average loss: 1.3394
[09/16 02:26:44 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.81	top5: 89.04	
[09/16 02:26:52 visual_prompt]: Rank of current process: 0. World size: 1
[09/16 02:26:52 visual_prompt]: Environment info:
-------------------  ----------------------------------------------------
Python               3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              1.7.1
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  ----------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[09/16 02:26:52 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '100', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-dtd', 'DATA.NUMBER_CLASSES', '47', 'SOLVER.BASE_LR', '5.0', 'SOLVER.WEIGHT_DECAY', '0.0001', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir/seed44'], train_type='')
[09/16 02:26:52 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/16 02:26:52 visual_prompt]: Training with config:
[09/16 02:26:52 visual_prompt]: {'CUDNN_BENCHMARK': False,
 'DATA': {'BATCH_SIZE': 64,
          'CLASS_WEIGHTS_TYPE': 'none',
          'CROPSIZE': 224,
          'DATAPATH': 'visual_prompt_tuning/data_path',
          'FEATURE': 'sup_vitb16_imagenet21k',
          'MULTILABEL': False,
          'NAME': 'vtab-dtd',
          'NO_TEST': False,
          'NUMBER_CLASSES': 47,
          'NUM_WORKERS': 4,
          'PERCENTAGE': 1.0,
          'PIN_MEMORY': True},
 'DBG': False,
 'MODEL': {'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'}),
           'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}),
           'MLP_NUM': 0,
           'MODEL_ROOT': 'visual_prompt_tuning/model_root',
           'PROMPT': {'CLSEMB_FOLDER': '',
                      'CLSEMB_PATH': '',
                      'DEEP': True,
                      'DEEP_SHARED': False,
                      'DROPOUT': 0.1,
                      'FORWARD_DEEP_NOEXPAND': False,
                      'INITIATION': 'random',
                      'LOCATION': 'prepend',
                      'NUM_DEEP_LAYERS': None,
                      'NUM_TOKENS': 100,
                      'PROJECT': -1,
                      'REVERSE_DEEP': False,
                      'SAVE_FOR_EACH_EPOCH': False,
                      'VIT_POOL_TYPE': 'original'},
           'SAVE_CKPT': False,
           'TRANSFER_TYPE': 'prompt',
           'TYPE': 'vit',
           'WEIGHT_PATH': ''},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/seed44/vtab-dtd/sup_vitb16_imagenet21k/lr5.0_wd0.0001/run1',
 'RUN_N_TIMES': 1,
 'SEED': None,
 'SOLVER': {'BASE_LR': 5.0,
            'BIAS_MULTIPLIER': 1.0,
            'DBG_TRAINABLE': False,
            'LOG_EVERY_N': 100,
            'LOSS': 'softmax',
            'LOSS_ALPHA': 0.01,
            'MOMENTUM': 0.9,
            'OPTIMIZER': 'sgd',
            'PATIENCE': 300,
            'SCHEDULER': 'cosine',
            'TOTAL_EPOCH': 100,
            'WARMUP_EPOCH': 10,
            'WEIGHT_DECAY': 0.0001,
            'WEIGHT_DECAY_BIAS': 0}}
[09/16 02:26:52 visual_prompt]: Loading training data (final training data for vtab)...
2023-09-16 02:26:52.562024: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-09-16 02:26:52.731866: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-09-16 02:26:53.646013: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-16 02:26:53.646091: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-16 02:26:53.646101: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-09-16 02:26:55.728398: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-16 02:26:55.728511: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-16 02:26:55.728527: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
[09/16 02:26:55 visual_prompt]: Constructing vtab-dtd dataset trainval...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/dtd/3.0.1
[INFO: dataset_builder.py:  510]: Reusing dataset dtd (visual_prompt_tuning/data_path/dtd/3.0.1)
2023-09-16 02:26:55.753079: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset dtd for split train[:800]+validation[:200], from visual_prompt_tuning/data_path/dtd/3.0.1
[09/16 02:26:59 visual_prompt]: Number of images: 1000
[09/16 02:26:59 visual_prompt]: Number of classes: 47 / 47
[09/16 02:26:59 visual_prompt]: Loading validation data...
[09/16 02:26:59 visual_prompt]: Constructing vtab-dtd dataset val...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/dtd/3.0.1
[INFO: dataset_builder.py:  510]: Reusing dataset dtd (visual_prompt_tuning/data_path/dtd/3.0.1)
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset dtd for split validation[:200], from visual_prompt_tuning/data_path/dtd/3.0.1
[09/16 02:26:59 visual_prompt]: Number of images: 200
[09/16 02:26:59 visual_prompt]: Number of classes: 47 / 47
[09/16 02:26:59 visual_prompt]: Loading test data...
[09/16 02:26:59 visual_prompt]: Constructing vtab-dtd dataset test...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/dtd/3.0.1
[INFO: dataset_builder.py:  510]: Reusing dataset dtd (visual_prompt_tuning/data_path/dtd/3.0.1)
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset dtd for split test, from visual_prompt_tuning/data_path/dtd/3.0.1
[09/16 02:27:04 visual_prompt]: Number of images: 1880
[09/16 02:27:04 visual_prompt]: Number of classes: 47 / 47
[09/16 02:27:04 visual_prompt]: Constructing models...
[09/16 02:27:07 visual_prompt]: Total Parameters: 86756399	 Gradient Parameters: 957743
[09/16 02:27:07 visual_prompt]: tuned percent:1.104
[09/16 02:27:10 visual_prompt]: Device used for model: 0
[09/16 02:27:10 visual_prompt]: Setting up Evalutator...
[09/16 02:27:10 visual_prompt]: Setting up Trainer...
[09/16 02:27:10 visual_prompt]: 	Setting up the optimizer...
[09/16 02:27:10 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/16 02:27:19 visual_prompt]: Epoch 1 / 100: avg data time: 7.66e-02, avg batch time: 0.5540, average train loss: 3.9432
[09/16 02:27:21 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1425, average loss: 3.9140
[09/16 02:27:21 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.00	top5: 13.50	
[09/16 02:27:27 visual_prompt]: Inference (test):avg data time: 3.63e-03, avg batch time: 0.1850, average loss: 3.9468
[09/16 02:27:27 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.87	top5: 10.85	
[09/16 02:27:27 visual_prompt]: Best epoch 1: best metric: 0.020
[09/16 02:27:27 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.5
[09/16 02:27:35 visual_prompt]: Epoch 2 / 100: avg data time: 6.07e-02, avg batch time: 0.4608, average train loss: 3.9537
[09/16 02:27:37 visual_prompt]: Inference (val):avg data time: 3.89e-05, avg batch time: 0.1426, average loss: 3.8473
[09/16 02:27:37 visual_prompt]: Classification results with val_vtab-dtd: top1: 3.00	top5: 18.50	
[09/16 02:27:44 visual_prompt]: Inference (test):avg data time: 4.13e-03, avg batch time: 0.1837, average loss: 3.8906
[09/16 02:27:44 visual_prompt]: Classification results with test_vtab-dtd: top1: 3.19	top5: 12.45	
[09/16 02:27:44 visual_prompt]: Best epoch 2: best metric: 0.030
[09/16 02:27:44 visual_prompt]: Training 3 / 100 epoch, with learning rate 1.0
[09/16 02:27:52 visual_prompt]: Epoch 3 / 100: avg data time: 5.45e-02, avg batch time: 0.4563, average train loss: 3.8979
[09/16 02:27:53 visual_prompt]: Inference (val):avg data time: 3.50e-05, avg batch time: 0.1433, average loss: 3.8148
[09/16 02:27:53 visual_prompt]: Classification results with val_vtab-dtd: top1: 4.00	top5: 18.50	
[09/16 02:28:00 visual_prompt]: Inference (test):avg data time: 4.11e-03, avg batch time: 0.1879, average loss: 3.8661
[09/16 02:28:00 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 15.32	
[09/16 02:28:00 visual_prompt]: Best epoch 3: best metric: 0.040
[09/16 02:28:00 visual_prompt]: Training 4 / 100 epoch, with learning rate 1.5
[09/16 02:28:08 visual_prompt]: Epoch 4 / 100: avg data time: 5.94e-02, avg batch time: 0.4646, average train loss: 3.7482
[09/16 02:28:10 visual_prompt]: Inference (val):avg data time: 3.70e-05, avg batch time: 0.1427, average loss: 3.7552
[09/16 02:28:10 visual_prompt]: Classification results with val_vtab-dtd: top1: 3.00	top5: 18.50	
[09/16 02:28:17 visual_prompt]: Inference (test):avg data time: 2.94e-03, avg batch time: 0.1857, average loss: 3.7661
[09/16 02:28:17 visual_prompt]: Classification results with test_vtab-dtd: top1: 4.20	top5: 22.39	
[09/16 02:28:17 visual_prompt]: Training 5 / 100 epoch, with learning rate 2.0
[09/16 02:28:25 visual_prompt]: Epoch 5 / 100: avg data time: 6.05e-02, avg batch time: 0.4631, average train loss: 3.9874
[09/16 02:28:26 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1429, average loss: 3.8099
[09/16 02:28:26 visual_prompt]: Classification results with val_vtab-dtd: top1: 7.50	top5: 20.50	
[09/16 02:28:33 visual_prompt]: Inference (test):avg data time: 5.58e-03, avg batch time: 0.1874, average loss: 3.8664
[09/16 02:28:33 visual_prompt]: Classification results with test_vtab-dtd: top1: 5.48	top5: 20.69	
[09/16 02:28:33 visual_prompt]: Best epoch 5: best metric: 0.075
[09/16 02:28:33 visual_prompt]: Training 6 / 100 epoch, with learning rate 2.5
[09/16 02:28:41 visual_prompt]: Epoch 6 / 100: avg data time: 5.40e-02, avg batch time: 0.4563, average train loss: 3.7121
[09/16 02:28:43 visual_prompt]: Inference (val):avg data time: 3.61e-05, avg batch time: 0.1432, average loss: 3.4600
[09/16 02:28:43 visual_prompt]: Classification results with val_vtab-dtd: top1: 13.00	top5: 42.00	
[09/16 02:28:50 visual_prompt]: Inference (test):avg data time: 7.05e-03, avg batch time: 0.1894, average loss: 3.6710
[09/16 02:28:50 visual_prompt]: Classification results with test_vtab-dtd: top1: 9.95	top5: 33.51	
[09/16 02:28:50 visual_prompt]: Best epoch 6: best metric: 0.130
[09/16 02:28:50 visual_prompt]: Training 7 / 100 epoch, with learning rate 3.0
[09/16 02:28:58 visual_prompt]: Epoch 7 / 100: avg data time: 5.40e-02, avg batch time: 0.4728, average train loss: 3.5063
[09/16 02:29:00 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.1432, average loss: 3.2129
[09/16 02:29:00 visual_prompt]: Classification results with val_vtab-dtd: top1: 14.00	top5: 41.00	
[09/16 02:29:07 visual_prompt]: Inference (test):avg data time: 4.46e-03, avg batch time: 0.1870, average loss: 3.3785
[09/16 02:29:07 visual_prompt]: Classification results with test_vtab-dtd: top1: 14.79	top5: 40.16	
[09/16 02:29:07 visual_prompt]: Best epoch 7: best metric: 0.140
[09/16 02:29:07 visual_prompt]: Training 8 / 100 epoch, with learning rate 3.5
[09/16 02:29:14 visual_prompt]: Epoch 8 / 100: avg data time: 6.26e-02, avg batch time: 0.4673, average train loss: 2.9113
[09/16 02:29:16 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1470, average loss: 2.4754
[09/16 02:29:16 visual_prompt]: Classification results with val_vtab-dtd: top1: 30.50	top5: 68.00	
[09/16 02:29:23 visual_prompt]: Inference (test):avg data time: 2.66e-03, avg batch time: 0.1863, average loss: 2.7351
[09/16 02:29:23 visual_prompt]: Classification results with test_vtab-dtd: top1: 26.38	top5: 58.35	
[09/16 02:29:23 visual_prompt]: Best epoch 8: best metric: 0.305
[09/16 02:29:23 visual_prompt]: Training 9 / 100 epoch, with learning rate 4.0
[09/16 02:29:31 visual_prompt]: Epoch 9 / 100: avg data time: 4.38e-02, avg batch time: 0.4479, average train loss: 2.2959
[09/16 02:29:32 visual_prompt]: Inference (val):avg data time: 4.71e-05, avg batch time: 0.1432, average loss: 1.9328
[09/16 02:29:32 visual_prompt]: Classification results with val_vtab-dtd: top1: 42.50	top5: 82.00	
[09/16 02:29:39 visual_prompt]: Inference (test):avg data time: 4.85e-03, avg batch time: 0.1894, average loss: 2.3497
[09/16 02:29:39 visual_prompt]: Classification results with test_vtab-dtd: top1: 34.10	top5: 71.91	
[09/16 02:29:39 visual_prompt]: Best epoch 9: best metric: 0.425
[09/16 02:29:39 visual_prompt]: Training 10 / 100 epoch, with learning rate 4.5
[09/16 02:29:47 visual_prompt]: Epoch 10 / 100: avg data time: 6.22e-02, avg batch time: 0.4637, average train loss: 1.6319
[09/16 02:29:49 visual_prompt]: Inference (val):avg data time: 3.93e-05, avg batch time: 0.1433, average loss: 1.8000
[09/16 02:29:49 visual_prompt]: Classification results with val_vtab-dtd: top1: 50.00	top5: 81.50	
[09/16 02:29:56 visual_prompt]: Inference (test):avg data time: 4.73e-03, avg batch time: 0.1901, average loss: 2.4924
[09/16 02:29:56 visual_prompt]: Classification results with test_vtab-dtd: top1: 38.14	top5: 67.02	
[09/16 02:29:56 visual_prompt]: Best epoch 10: best metric: 0.500
[09/16 02:29:56 visual_prompt]: Training 11 / 100 epoch, with learning rate 5.0
[09/16 02:30:04 visual_prompt]: Epoch 11 / 100: avg data time: 6.80e-02, avg batch time: 0.4691, average train loss: 1.4798
[09/16 02:30:05 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1432, average loss: 1.4247
[09/16 02:30:05 visual_prompt]: Classification results with val_vtab-dtd: top1: 59.00	top5: 86.50	
[09/16 02:30:12 visual_prompt]: Inference (test):avg data time: 4.89e-03, avg batch time: 0.1873, average loss: 2.6187
[09/16 02:30:12 visual_prompt]: Classification results with test_vtab-dtd: top1: 41.49	top5: 70.80	
[09/16 02:30:12 visual_prompt]: Best epoch 11: best metric: 0.590
[09/16 02:30:12 visual_prompt]: Training 12 / 100 epoch, with learning rate 4.998477067547739
[09/16 02:30:20 visual_prompt]: Epoch 12 / 100: avg data time: 6.13e-02, avg batch time: 0.4640, average train loss: 1.6354
[09/16 02:30:22 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1432, average loss: 1.1749
[09/16 02:30:22 visual_prompt]: Classification results with val_vtab-dtd: top1: 68.00	top5: 92.50	
[09/16 02:30:29 visual_prompt]: Inference (test):avg data time: 5.50e-03, avg batch time: 0.1883, average loss: 2.1801
[09/16 02:30:29 visual_prompt]: Classification results with test_vtab-dtd: top1: 45.64	top5: 77.55	
[09/16 02:30:29 visual_prompt]: Best epoch 12: best metric: 0.680
[09/16 02:30:29 visual_prompt]: Training 13 / 100 epoch, with learning rate 4.993910125649561
[09/16 02:30:37 visual_prompt]: Epoch 13 / 100: avg data time: 6.04e-02, avg batch time: 0.4623, average train loss: 1.1860
[09/16 02:30:39 visual_prompt]: Inference (val):avg data time: 3.50e-05, avg batch time: 0.1460, average loss: 0.7234
[09/16 02:30:39 visual_prompt]: Classification results with val_vtab-dtd: top1: 79.50	top5: 98.00	
[09/16 02:30:46 visual_prompt]: Inference (test):avg data time: 3.27e-03, avg batch time: 0.1877, average loss: 1.8886
[09/16 02:30:46 visual_prompt]: Classification results with test_vtab-dtd: top1: 50.05	top5: 81.28	
[09/16 02:30:46 visual_prompt]: Best epoch 13: best metric: 0.795
[09/16 02:30:46 visual_prompt]: Training 14 / 100 epoch, with learning rate 4.986304738420683
[09/16 02:30:53 visual_prompt]: Epoch 14 / 100: avg data time: 6.15e-02, avg batch time: 0.4630, average train loss: 0.7751
[09/16 02:30:55 visual_prompt]: Inference (val):avg data time: 5.67e-05, avg batch time: 0.1434, average loss: 0.5900
[09/16 02:30:55 visual_prompt]: Classification results with val_vtab-dtd: top1: 84.00	top5: 98.50	
[09/16 02:31:02 visual_prompt]: Inference (test):avg data time: 2.83e-03, avg batch time: 0.1864, average loss: 2.5199
[09/16 02:31:02 visual_prompt]: Classification results with test_vtab-dtd: top1: 52.23	top5: 80.64	
[09/16 02:31:02 visual_prompt]: Best epoch 14: best metric: 0.840
[09/16 02:31:02 visual_prompt]: Training 15 / 100 epoch, with learning rate 4.975670171853926
[09/16 02:31:10 visual_prompt]: Epoch 15 / 100: avg data time: 6.29e-02, avg batch time: 0.4653, average train loss: 0.6003
[09/16 02:31:12 visual_prompt]: Inference (val):avg data time: 5.60e-05, avg batch time: 0.1456, average loss: 0.5146
[09/16 02:31:12 visual_prompt]: Classification results with val_vtab-dtd: top1: 85.50	top5: 99.00	
[09/16 02:31:19 visual_prompt]: Inference (test):avg data time: 5.61e-03, avg batch time: 0.1890, average loss: 2.2541
[09/16 02:31:19 visual_prompt]: Classification results with test_vtab-dtd: top1: 50.05	top5: 81.28	
[09/16 02:31:19 visual_prompt]: Best epoch 15: best metric: 0.855
[09/16 02:31:19 visual_prompt]: Training 16 / 100 epoch, with learning rate 4.962019382530521
[09/16 02:31:27 visual_prompt]: Epoch 16 / 100: avg data time: 6.32e-02, avg batch time: 0.4649, average train loss: 0.3974
[09/16 02:31:29 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1434, average loss: 0.2480
[09/16 02:31:29 visual_prompt]: Classification results with val_vtab-dtd: top1: 92.00	top5: 99.50	
[09/16 02:31:36 visual_prompt]: Inference (test):avg data time: 3.83e-03, avg batch time: 0.1887, average loss: 2.7123
[09/16 02:31:36 visual_prompt]: Classification results with test_vtab-dtd: top1: 53.88	top5: 82.39	
[09/16 02:31:36 visual_prompt]: Best epoch 16: best metric: 0.920
[09/16 02:31:36 visual_prompt]: Training 17 / 100 epoch, with learning rate 4.945369001834514
[09/16 02:31:43 visual_prompt]: Epoch 17 / 100: avg data time: 4.76e-02, avg batch time: 0.4517, average train loss: 0.3466
[09/16 02:31:45 visual_prompt]: Inference (val):avg data time: 4.02e-05, avg batch time: 0.1434, average loss: 0.1693
[09/16 02:31:45 visual_prompt]: Classification results with val_vtab-dtd: top1: 93.50	top5: 100.00	
[09/16 02:31:52 visual_prompt]: Inference (test):avg data time: 3.76e-03, avg batch time: 0.1870, average loss: 2.7992
[09/16 02:31:52 visual_prompt]: Classification results with test_vtab-dtd: top1: 52.29	top5: 81.28	
[09/16 02:31:52 visual_prompt]: Best epoch 17: best metric: 0.935
[09/16 02:31:52 visual_prompt]: Training 18 / 100 epoch, with learning rate 4.925739315689991
[09/16 02:32:00 visual_prompt]: Epoch 18 / 100: avg data time: 6.74e-02, avg batch time: 0.4708, average train loss: 0.4082
[09/16 02:32:01 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1432, average loss: 0.3688
[09/16 02:32:01 visual_prompt]: Classification results with val_vtab-dtd: top1: 91.00	top5: 98.50	
[09/16 02:32:08 visual_prompt]: Inference (test):avg data time: 5.18e-03, avg batch time: 0.1884, average loss: 2.4953
[09/16 02:32:08 visual_prompt]: Classification results with test_vtab-dtd: top1: 52.23	top5: 79.47	
[09/16 02:32:08 visual_prompt]: Training 19 / 100 epoch, with learning rate 4.903154239845797
[09/16 02:32:16 visual_prompt]: Epoch 19 / 100: avg data time: 6.77e-02, avg batch time: 0.4688, average train loss: 0.2985
[09/16 02:32:18 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1431, average loss: 0.3780
[09/16 02:32:18 visual_prompt]: Classification results with val_vtab-dtd: top1: 90.50	top5: 100.00	
[09/16 02:32:25 visual_prompt]: Inference (test):avg data time: 5.20e-03, avg batch time: 0.1865, average loss: 3.1063
[09/16 02:32:25 visual_prompt]: Classification results with test_vtab-dtd: top1: 53.14	top5: 82.55	
[09/16 02:32:25 visual_prompt]: Training 20 / 100 epoch, with learning rate 4.877641290737884
[09/16 02:32:33 visual_prompt]: Epoch 20 / 100: avg data time: 6.35e-02, avg batch time: 0.4657, average train loss: 0.2592
[09/16 02:32:35 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1432, average loss: 0.2530
[09/16 02:32:35 visual_prompt]: Classification results with val_vtab-dtd: top1: 90.00	top5: 100.00	
[09/16 02:32:42 visual_prompt]: Inference (test):avg data time: 8.09e-03, avg batch time: 0.1887, average loss: 2.4405
[09/16 02:32:42 visual_prompt]: Classification results with test_vtab-dtd: top1: 51.28	top5: 82.50	
[09/16 02:32:42 visual_prompt]: Training 21 / 100 epoch, with learning rate 4.849231551964771
[09/16 02:32:50 visual_prompt]: Epoch 21 / 100: avg data time: 6.33e-02, avg batch time: 0.4666, average train loss: 0.2917
[09/16 02:32:51 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1434, average loss: 0.4272
[09/16 02:32:51 visual_prompt]: Classification results with val_vtab-dtd: top1: 92.00	top5: 97.00	
[09/16 02:32:58 visual_prompt]: Inference (test):avg data time: 5.20e-03, avg batch time: 0.1913, average loss: 2.6781
[09/16 02:32:58 visual_prompt]: Classification results with test_vtab-dtd: top1: 51.70	top5: 81.81	
[09/16 02:32:58 visual_prompt]: Training 22 / 100 epoch, with learning rate 4.817959636416969
[09/16 02:33:07 visual_prompt]: Epoch 22 / 100: avg data time: 6.38e-02, avg batch time: 0.4988, average train loss: 0.2243
[09/16 02:33:08 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1433, average loss: 0.2812
[09/16 02:33:08 visual_prompt]: Classification results with val_vtab-dtd: top1: 94.00	top5: 100.00	
[09/16 02:33:15 visual_prompt]: Inference (test):avg data time: 2.73e-03, avg batch time: 0.1882, average loss: 2.8375
[09/16 02:33:15 visual_prompt]: Classification results with test_vtab-dtd: top1: 53.03	top5: 81.91	
[09/16 02:33:15 visual_prompt]: Best epoch 22: best metric: 0.940
[09/16 02:33:15 visual_prompt]: Training 23 / 100 epoch, with learning rate 4.783863644106502
[09/16 02:33:23 visual_prompt]: Epoch 23 / 100: avg data time: 5.92e-02, avg batch time: 0.4617, average train loss: 0.2061
[09/16 02:33:25 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.1433, average loss: 0.1437
[09/16 02:33:25 visual_prompt]: Classification results with val_vtab-dtd: top1: 95.50	top5: 100.00	
[09/16 02:33:32 visual_prompt]: Inference (test):avg data time: 4.96e-03, avg batch time: 0.1891, average loss: 2.5583
[09/16 02:33:32 visual_prompt]: Classification results with test_vtab-dtd: top1: 55.27	top5: 83.62	
[09/16 02:33:32 visual_prompt]: Best epoch 23: best metric: 0.955
[09/16 02:33:32 visual_prompt]: Training 24 / 100 epoch, with learning rate 4.7469851157479175
[09/16 02:33:40 visual_prompt]: Epoch 24 / 100: avg data time: 6.14e-02, avg batch time: 0.4641, average train loss: 0.1481
[09/16 02:33:41 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1435, average loss: 0.3371
[09/16 02:33:41 visual_prompt]: Classification results with val_vtab-dtd: top1: 89.00	top5: 100.00	
[09/16 02:33:48 visual_prompt]: Inference (test):avg data time: 3.59e-03, avg batch time: 0.1877, average loss: 2.7972
[09/16 02:33:48 visual_prompt]: Classification results with test_vtab-dtd: top1: 53.14	top5: 81.70	
[09/16 02:33:48 visual_prompt]: Training 25 / 100 epoch, with learning rate 4.707368982147317
[09/16 02:33:56 visual_prompt]: Epoch 25 / 100: avg data time: 6.29e-02, avg batch time: 0.4658, average train loss: 0.1470
[09/16 02:33:58 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1435, average loss: 0.0955
[09/16 02:33:58 visual_prompt]: Classification results with val_vtab-dtd: top1: 97.50	top5: 99.50	
[09/16 02:34:05 visual_prompt]: Inference (test):avg data time: 4.12e-03, avg batch time: 0.1885, average loss: 2.4904
[09/16 02:34:05 visual_prompt]: Classification results with test_vtab-dtd: top1: 57.02	top5: 83.19	
[09/16 02:34:05 visual_prompt]: Best epoch 25: best metric: 0.975
[09/16 02:34:05 visual_prompt]: Training 26 / 100 epoch, with learning rate 4.665063509461097
[09/16 02:34:13 visual_prompt]: Epoch 26 / 100: avg data time: 6.49e-02, avg batch time: 0.4662, average train loss: 0.1186
[09/16 02:34:14 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1432, average loss: 0.2652
[09/16 02:34:14 visual_prompt]: Classification results with val_vtab-dtd: top1: 94.00	top5: 99.00	
[09/16 02:34:21 visual_prompt]: Inference (test):avg data time: 2.44e-03, avg batch time: 0.1877, average loss: 2.7558
[09/16 02:34:21 visual_prompt]: Classification results with test_vtab-dtd: top1: 54.41	top5: 80.96	
[09/16 02:34:21 visual_prompt]: Training 27 / 100 epoch, with learning rate 4.620120240391064
[09/16 02:34:29 visual_prompt]: Epoch 27 / 100: avg data time: 6.75e-02, avg batch time: 0.4695, average train loss: 0.1750
[09/16 02:34:31 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1435, average loss: 0.1500
[09/16 02:34:31 visual_prompt]: Classification results with val_vtab-dtd: top1: 95.00	top5: 99.50	
[09/16 02:34:38 visual_prompt]: Inference (test):avg data time: 4.54e-03, avg batch time: 0.1876, average loss: 2.6714
[09/16 02:34:38 visual_prompt]: Classification results with test_vtab-dtd: top1: 54.47	top5: 81.60	
[09/16 02:34:38 visual_prompt]: Training 28 / 100 epoch, with learning rate 4.572593931387604
[09/16 02:34:46 visual_prompt]: Epoch 28 / 100: avg data time: 6.83e-02, avg batch time: 0.4721, average train loss: 0.2606
[09/16 02:34:48 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1434, average loss: 0.3225
[09/16 02:34:48 visual_prompt]: Classification results with val_vtab-dtd: top1: 93.00	top5: 99.50	
[09/16 02:34:55 visual_prompt]: Inference (test):avg data time: 3.17e-03, avg batch time: 0.1879, average loss: 2.7164
[09/16 02:34:55 visual_prompt]: Classification results with test_vtab-dtd: top1: 51.49	top5: 82.13	
[09/16 02:34:55 visual_prompt]: Training 29 / 100 epoch, with learning rate 4.522542485937368
[09/16 02:35:03 visual_prompt]: Epoch 29 / 100: avg data time: 6.45e-02, avg batch time: 0.4677, average train loss: 0.3048
[09/16 02:35:04 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1432, average loss: 0.1891
[09/16 02:35:04 visual_prompt]: Classification results with val_vtab-dtd: top1: 95.50	top5: 99.50	
[09/16 02:35:11 visual_prompt]: Inference (test):avg data time: 7.20e-03, avg batch time: 0.1884, average loss: 2.3156
[09/16 02:35:11 visual_prompt]: Classification results with test_vtab-dtd: top1: 54.79	top5: 82.87	
[09/16 02:35:11 visual_prompt]: Training 30 / 100 epoch, with learning rate 4.4700268840168045
[09/16 02:35:19 visual_prompt]: Epoch 30 / 100: avg data time: 5.77e-02, avg batch time: 0.4601, average train loss: 0.1411
[09/16 02:35:21 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1433, average loss: 0.1561
[09/16 02:35:21 visual_prompt]: Classification results with val_vtab-dtd: top1: 95.50	top5: 100.00	
[09/16 02:35:28 visual_prompt]: Inference (test):avg data time: 4.32e-03, avg batch time: 0.1878, average loss: 2.6518
[09/16 02:35:28 visual_prompt]: Classification results with test_vtab-dtd: top1: 51.44	top5: 79.26	
[09/16 02:35:28 visual_prompt]: Training 31 / 100 epoch, with learning rate 4.415111107797445
[09/16 02:35:36 visual_prompt]: Epoch 31 / 100: avg data time: 6.34e-02, avg batch time: 0.4674, average train loss: 0.1620
[09/16 02:35:38 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1435, average loss: 0.1423
[09/16 02:35:38 visual_prompt]: Classification results with val_vtab-dtd: top1: 95.50	top5: 100.00	
[09/16 02:35:45 visual_prompt]: Inference (test):avg data time: 4.80e-03, avg batch time: 0.1868, average loss: 2.6379
[09/16 02:35:45 visual_prompt]: Classification results with test_vtab-dtd: top1: 53.99	top5: 80.16	
[09/16 02:35:45 visual_prompt]: Training 32 / 100 epoch, with learning rate 4.357862063693486
[09/16 02:35:53 visual_prompt]: Epoch 32 / 100: avg data time: 6.85e-02, avg batch time: 0.4714, average train loss: 0.1687
[09/16 02:35:54 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1433, average loss: 0.1096
[09/16 02:35:54 visual_prompt]: Classification results with val_vtab-dtd: top1: 94.50	top5: 100.00	
[09/16 02:36:01 visual_prompt]: Inference (test):avg data time: 2.69e-03, avg batch time: 0.1862, average loss: 2.4414
[09/16 02:36:01 visual_prompt]: Classification results with test_vtab-dtd: top1: 55.59	top5: 82.61	
[09/16 02:36:01 visual_prompt]: Training 33 / 100 epoch, with learning rate 4.298349500846628
[09/16 02:36:09 visual_prompt]: Epoch 33 / 100: avg data time: 5.88e-02, avg batch time: 0.4596, average train loss: 0.1303
[09/16 02:36:11 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1432, average loss: 0.1486
[09/16 02:36:11 visual_prompt]: Classification results with val_vtab-dtd: top1: 97.00	top5: 99.50	
[09/16 02:36:18 visual_prompt]: Inference (test):avg data time: 3.71e-03, avg batch time: 0.1897, average loss: 2.5737
[09/16 02:36:18 visual_prompt]: Classification results with test_vtab-dtd: top1: 56.65	top5: 82.02	
[09/16 02:36:18 visual_prompt]: Training 34 / 100 epoch, with learning rate 4.236645926147493
[09/16 02:36:25 visual_prompt]: Epoch 34 / 100: avg data time: 6.68e-02, avg batch time: 0.4689, average train loss: 0.1020
[09/16 02:36:27 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.1435, average loss: 0.1043
[09/16 02:36:27 visual_prompt]: Classification results with val_vtab-dtd: top1: 95.00	top5: 100.00	
[09/16 02:36:34 visual_prompt]: Inference (test):avg data time: 6.59e-03, avg batch time: 0.1877, average loss: 2.3782
[09/16 02:36:34 visual_prompt]: Classification results with test_vtab-dtd: top1: 56.28	top5: 82.87	
[09/16 02:36:34 visual_prompt]: Training 35 / 100 epoch, with learning rate 4.172826515897146
[09/16 02:36:42 visual_prompt]: Epoch 35 / 100: avg data time: 6.26e-02, avg batch time: 0.4652, average train loss: 0.0910
[09/16 02:36:44 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1433, average loss: 0.1200
[09/16 02:36:44 visual_prompt]: Classification results with val_vtab-dtd: top1: 96.50	top5: 99.50	
[09/16 02:36:51 visual_prompt]: Inference (test):avg data time: 3.90e-03, avg batch time: 0.1862, average loss: 2.5292
[09/16 02:36:51 visual_prompt]: Classification results with test_vtab-dtd: top1: 54.15	top5: 81.06	
[09/16 02:36:51 visual_prompt]: Training 36 / 100 epoch, with learning rate 4.106969024216348
[09/16 02:36:59 visual_prompt]: Epoch 36 / 100: avg data time: 6.79e-02, avg batch time: 0.4708, average train loss: 0.0655
[09/16 02:37:00 visual_prompt]: Inference (val):avg data time: 3.32e-05, avg batch time: 0.1435, average loss: 0.0119
[09/16 02:37:00 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:37:07 visual_prompt]: Inference (test):avg data time: 3.95e-03, avg batch time: 0.1875, average loss: 2.3243
[09/16 02:37:07 visual_prompt]: Classification results with test_vtab-dtd: top1: 57.77	top5: 83.14	
[09/16 02:37:07 visual_prompt]: Best epoch 36: best metric: 1.000
[09/16 02:37:07 visual_prompt]: Training 37 / 100 epoch, with learning rate 4.039153688314146
[09/16 02:37:15 visual_prompt]: Epoch 37 / 100: avg data time: 7.01e-02, avg batch time: 0.4723, average train loss: 0.0470
[09/16 02:37:17 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1433, average loss: 0.0265
[09/16 02:37:17 visual_prompt]: Classification results with val_vtab-dtd: top1: 99.00	top5: 100.00	
[09/16 02:37:25 visual_prompt]: Inference (test):avg data time: 2.89e-03, avg batch time: 0.1958, average loss: 2.2301
[09/16 02:37:25 visual_prompt]: Classification results with test_vtab-dtd: top1: 58.56	top5: 83.78	
[09/16 02:37:25 visual_prompt]: Training 38 / 100 epoch, with learning rate 3.969463130731183
[09/16 02:37:32 visual_prompt]: Epoch 38 / 100: avg data time: 5.30e-02, avg batch time: 0.4561, average train loss: 0.0451
[09/16 02:37:34 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1432, average loss: 0.0526
[09/16 02:37:34 visual_prompt]: Classification results with val_vtab-dtd: top1: 99.00	top5: 100.00	
[09/16 02:37:41 visual_prompt]: Inference (test):avg data time: 1.98e-03, avg batch time: 0.1859, average loss: 2.2738
[09/16 02:37:41 visual_prompt]: Classification results with test_vtab-dtd: top1: 57.71	top5: 82.82	
[09/16 02:37:41 visual_prompt]: Training 39 / 100 epoch, with learning rate 3.897982258676867
[09/16 02:37:49 visual_prompt]: Epoch 39 / 100: avg data time: 6.40e-02, avg batch time: 0.4675, average train loss: 0.0329
[09/16 02:37:50 visual_prompt]: Inference (val):avg data time: 4.64e-05, avg batch time: 0.1433, average loss: 0.0172
[09/16 02:37:50 visual_prompt]: Classification results with val_vtab-dtd: top1: 99.50	top5: 100.00	
[09/16 02:37:57 visual_prompt]: Inference (test):avg data time: 4.35e-03, avg batch time: 0.1869, average loss: 2.0935
[09/16 02:37:57 visual_prompt]: Classification results with test_vtab-dtd: top1: 57.50	top5: 84.31	
[09/16 02:37:57 visual_prompt]: Training 40 / 100 epoch, with learning rate 3.824798160583012
[09/16 02:38:05 visual_prompt]: Epoch 40 / 100: avg data time: 5.83e-02, avg batch time: 0.4602, average train loss: 0.0125
[09/16 02:38:07 visual_prompt]: Inference (val):avg data time: 4.08e-05, avg batch time: 0.1434, average loss: 0.0108
[09/16 02:38:07 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:38:14 visual_prompt]: Inference (test):avg data time: 6.42e-03, avg batch time: 0.1909, average loss: 1.9788
[09/16 02:38:14 visual_prompt]: Classification results with test_vtab-dtd: top1: 60.00	top5: 84.89	
[09/16 02:38:14 visual_prompt]: Training 41 / 100 epoch, with learning rate 3.75
[09/16 02:38:22 visual_prompt]: Epoch 41 / 100: avg data time: 6.10e-02, avg batch time: 0.4622, average train loss: 0.0068
[09/16 02:38:23 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1435, average loss: 0.0045
[09/16 02:38:23 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:38:30 visual_prompt]: Inference (test):avg data time: 4.94e-03, avg batch time: 0.1890, average loss: 1.8481
[09/16 02:38:30 visual_prompt]: Classification results with test_vtab-dtd: top1: 61.33	top5: 86.49	
[09/16 02:38:30 visual_prompt]: Training 42 / 100 epoch, with learning rate 3.673678906964727
[09/16 02:38:38 visual_prompt]: Epoch 42 / 100: avg data time: 6.50e-02, avg batch time: 0.4677, average train loss: 0.0036
[09/16 02:38:40 visual_prompt]: Inference (val):avg data time: 3.41e-05, avg batch time: 0.1431, average loss: 0.0037
[09/16 02:38:40 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:38:47 visual_prompt]: Inference (test):avg data time: 3.59e-03, avg batch time: 0.1877, average loss: 1.7810
[09/16 02:38:47 visual_prompt]: Classification results with test_vtab-dtd: top1: 61.38	top5: 85.96	
[09/16 02:38:47 visual_prompt]: Training 43 / 100 epoch, with learning rate 3.5959278669726933
[09/16 02:38:55 visual_prompt]: Epoch 43 / 100: avg data time: 6.63e-02, avg batch time: 0.4683, average train loss: 0.0029
[09/16 02:38:56 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1433, average loss: 0.0033
[09/16 02:38:56 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:39:03 visual_prompt]: Inference (test):avg data time: 4.86e-03, avg batch time: 0.1888, average loss: 1.6785
[09/16 02:39:03 visual_prompt]: Classification results with test_vtab-dtd: top1: 61.91	top5: 86.76	
[09/16 02:39:03 visual_prompt]: Training 44 / 100 epoch, with learning rate 3.516841607689501
[09/16 02:39:11 visual_prompt]: Epoch 44 / 100: avg data time: 6.26e-02, avg batch time: 0.4644, average train loss: 0.0030
[09/16 02:39:13 visual_prompt]: Inference (val):avg data time: 5.05e-05, avg batch time: 0.1446, average loss: 0.0033
[09/16 02:39:13 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:39:20 visual_prompt]: Inference (test):avg data time: 4.98e-03, avg batch time: 0.1891, average loss: 1.6191
[09/16 02:39:20 visual_prompt]: Classification results with test_vtab-dtd: top1: 62.66	top5: 86.91	
[09/16 02:39:20 visual_prompt]: Training 45 / 100 epoch, with learning rate 3.4365164835397803
[09/16 02:39:28 visual_prompt]: Epoch 45 / 100: avg data time: 6.29e-02, avg batch time: 0.4658, average train loss: 0.0032
[09/16 02:39:30 visual_prompt]: Inference (val):avg data time: 3.55e-05, avg batch time: 0.1434, average loss: 0.0035
[09/16 02:39:30 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:39:37 visual_prompt]: Inference (test):avg data time: 3.62e-03, avg batch time: 0.1858, average loss: 1.5711
[09/16 02:39:37 visual_prompt]: Classification results with test_vtab-dtd: top1: 62.87	top5: 87.02	
[09/16 02:39:37 visual_prompt]: Training 46 / 100 epoch, with learning rate 3.3550503583141724
[09/16 02:39:44 visual_prompt]: Epoch 46 / 100: avg data time: 6.16e-02, avg batch time: 0.4656, average train loss: 0.0037
[09/16 02:39:47 visual_prompt]: Inference (val):avg data time: 5.74e-04, avg batch time: 0.2472, average loss: 0.0038
[09/16 02:39:47 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:39:53 visual_prompt]: Inference (test):avg data time: 2.96e-03, avg batch time: 0.1858, average loss: 1.5281
[09/16 02:39:53 visual_prompt]: Classification results with test_vtab-dtd: top1: 63.35	top5: 87.50	
[09/16 02:39:53 visual_prompt]: Training 47 / 100 epoch, with learning rate 3.2725424859373686
[09/16 02:40:01 visual_prompt]: Epoch 47 / 100: avg data time: 5.74e-02, avg batch time: 0.4597, average train loss: 0.0040
[09/16 02:40:03 visual_prompt]: Inference (val):avg data time: 4.45e-05, avg batch time: 0.1447, average loss: 0.0043
[09/16 02:40:03 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:40:10 visual_prompt]: Inference (test):avg data time: 6.60e-03, avg batch time: 0.1892, average loss: 1.4943
[09/16 02:40:10 visual_prompt]: Classification results with test_vtab-dtd: top1: 63.51	top5: 87.82	
[09/16 02:40:10 visual_prompt]: Training 48 / 100 epoch, with learning rate 3.1890933895424975
[09/16 02:40:18 visual_prompt]: Epoch 48 / 100: avg data time: 6.19e-02, avg batch time: 0.4640, average train loss: 0.0044
[09/16 02:40:19 visual_prompt]: Inference (val):avg data time: 3.63e-05, avg batch time: 0.1432, average loss: 0.0045
[09/16 02:40:19 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:40:27 visual_prompt]: Inference (test):avg data time: 4.13e-03, avg batch time: 0.2035, average loss: 1.4679
[09/16 02:40:27 visual_prompt]: Classification results with test_vtab-dtd: top1: 63.40	top5: 88.03	
[09/16 02:40:27 visual_prompt]: Training 49 / 100 epoch, with learning rate 3.104804738999169
[09/16 02:40:35 visual_prompt]: Epoch 49 / 100: avg data time: 6.13e-02, avg batch time: 0.4624, average train loss: 0.0048
[09/16 02:40:36 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1434, average loss: 0.0045
[09/16 02:40:36 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:40:44 visual_prompt]: Inference (test):avg data time: 4.89e-03, avg batch time: 0.1892, average loss: 1.4450
[09/16 02:40:44 visual_prompt]: Classification results with test_vtab-dtd: top1: 63.88	top5: 88.03	
[09/16 02:40:44 visual_prompt]: Training 50 / 100 epoch, with learning rate 3.019779227044398
[09/16 02:40:51 visual_prompt]: Epoch 50 / 100: avg data time: 6.36e-02, avg batch time: 0.4668, average train loss: 0.0050
[09/16 02:40:53 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1437, average loss: 0.0044
[09/16 02:40:53 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:41:00 visual_prompt]: Inference (test):avg data time: 5.62e-03, avg batch time: 0.1884, average loss: 1.4197
[09/16 02:41:00 visual_prompt]: Classification results with test_vtab-dtd: top1: 64.52	top5: 88.09	
[09/16 02:41:00 visual_prompt]: Training 51 / 100 epoch, with learning rate 2.934120444167326
[09/16 02:41:08 visual_prompt]: Epoch 51 / 100: avg data time: 4.70e-02, avg batch time: 0.4513, average train loss: 0.0052
[09/16 02:41:09 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1433, average loss: 0.0044
[09/16 02:41:09 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:41:16 visual_prompt]: Inference (test):avg data time: 4.53e-03, avg batch time: 0.1866, average loss: 1.4049
[09/16 02:41:16 visual_prompt]: Classification results with test_vtab-dtd: top1: 64.52	top5: 88.51	
[09/16 02:41:16 visual_prompt]: Training 52 / 100 epoch, with learning rate 2.8479327524001636
[09/16 02:41:24 visual_prompt]: Epoch 52 / 100: avg data time: 6.18e-02, avg batch time: 0.4639, average train loss: 0.0051
[09/16 02:41:26 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.1435, average loss: 0.0045
[09/16 02:41:26 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:41:33 visual_prompt]: Inference (test):avg data time: 4.74e-03, avg batch time: 0.1885, average loss: 1.3945
[09/16 02:41:33 visual_prompt]: Classification results with test_vtab-dtd: top1: 65.27	top5: 88.46	
[09/16 02:41:33 visual_prompt]: Training 53 / 100 epoch, with learning rate 2.761321158169134
[09/16 02:41:41 visual_prompt]: Epoch 53 / 100: avg data time: 6.14e-02, avg batch time: 0.4641, average train loss: 0.0050
[09/16 02:41:42 visual_prompt]: Inference (val):avg data time: 3.50e-05, avg batch time: 0.1436, average loss: 0.0042
[09/16 02:41:42 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:41:49 visual_prompt]: Inference (test):avg data time: 3.48e-03, avg batch time: 0.1867, average loss: 1.3784
[09/16 02:41:49 visual_prompt]: Classification results with test_vtab-dtd: top1: 65.16	top5: 88.88	
[09/16 02:41:49 visual_prompt]: Training 54 / 100 epoch, with learning rate 2.6743911843603128
[09/16 02:41:58 visual_prompt]: Epoch 54 / 100: avg data time: 6.59e-02, avg batch time: 0.4900, average train loss: 0.0050
[09/16 02:41:59 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1435, average loss: 0.0040
[09/16 02:41:59 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:42:06 visual_prompt]: Inference (test):avg data time: 3.19e-03, avg batch time: 0.1859, average loss: 1.3670
[09/16 02:42:06 visual_prompt]: Classification results with test_vtab-dtd: top1: 65.59	top5: 88.67	
[09/16 02:42:06 visual_prompt]: Training 55 / 100 epoch, with learning rate 2.5872487417562526
[09/16 02:42:14 visual_prompt]: Epoch 55 / 100: avg data time: 5.57e-02, avg batch time: 0.4591, average train loss: 0.0051
[09/16 02:42:16 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1433, average loss: 0.0039
[09/16 02:42:16 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:42:23 visual_prompt]: Inference (test):avg data time: 4.63e-03, avg batch time: 0.1862, average loss: 1.3629
[09/16 02:42:23 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.06	top5: 88.83	
[09/16 02:42:23 visual_prompt]: Training 56 / 100 epoch, with learning rate 2.5
[09/16 02:42:31 visual_prompt]: Epoch 56 / 100: avg data time: 6.80e-02, avg batch time: 0.4694, average train loss: 0.0050
[09/16 02:42:32 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.1434, average loss: 0.0038
[09/16 02:42:32 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:42:39 visual_prompt]: Inference (test):avg data time: 4.79e-03, avg batch time: 0.1866, average loss: 1.3518
[09/16 02:42:39 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.17	top5: 88.88	
[09/16 02:42:39 visual_prompt]: Training 57 / 100 epoch, with learning rate 2.4127512582437483
[09/16 02:42:47 visual_prompt]: Epoch 57 / 100: avg data time: 5.40e-02, avg batch time: 0.4568, average train loss: 0.0049
[09/16 02:42:49 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.1433, average loss: 0.0035
[09/16 02:42:49 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:42:56 visual_prompt]: Inference (test):avg data time: 3.29e-03, avg batch time: 0.1877, average loss: 1.3361
[09/16 02:42:56 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.44	top5: 88.62	
[09/16 02:42:56 visual_prompt]: Training 58 / 100 epoch, with learning rate 2.325608815639687
[09/16 02:43:03 visual_prompt]: Epoch 58 / 100: avg data time: 6.30e-02, avg batch time: 0.4636, average train loss: 0.0047
[09/16 02:43:05 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1433, average loss: 0.0034
[09/16 02:43:05 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:43:12 visual_prompt]: Inference (test):avg data time: 5.73e-03, avg batch time: 0.1904, average loss: 1.3489
[09/16 02:43:12 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.81	top5: 88.99	
[09/16 02:43:12 visual_prompt]: Training 59 / 100 epoch, with learning rate 2.2386788418308665
[09/16 02:43:20 visual_prompt]: Epoch 59 / 100: avg data time: 6.24e-02, avg batch time: 0.4660, average train loss: 0.0047
[09/16 02:43:22 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1433, average loss: 0.0036
[09/16 02:43:22 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:43:29 visual_prompt]: Inference (test):avg data time: 5.15e-03, avg batch time: 0.1876, average loss: 1.3353
[09/16 02:43:29 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.54	top5: 88.88	
[09/16 02:43:29 visual_prompt]: Training 60 / 100 epoch, with learning rate 2.1520672475998373
[09/16 02:43:36 visual_prompt]: Epoch 60 / 100: avg data time: 5.53e-02, avg batch time: 0.4559, average train loss: 0.0049
[09/16 02:43:38 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.1434, average loss: 0.0035
[09/16 02:43:38 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:43:45 visual_prompt]: Inference (test):avg data time: 5.01e-03, avg batch time: 0.1863, average loss: 1.3432
[09/16 02:43:45 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.76	top5: 88.83	
[09/16 02:43:45 visual_prompt]: Training 61 / 100 epoch, with learning rate 2.0658795558326744
[09/16 02:43:53 visual_prompt]: Epoch 61 / 100: avg data time: 6.55e-02, avg batch time: 0.4675, average train loss: 0.0047
[09/16 02:43:55 visual_prompt]: Inference (val):avg data time: 4.14e-05, avg batch time: 0.1434, average loss: 0.0032
[09/16 02:43:55 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:44:02 visual_prompt]: Inference (test):avg data time: 1.93e-03, avg batch time: 0.1875, average loss: 1.3327
[09/16 02:44:02 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.81	top5: 88.88	
[09/16 02:44:02 visual_prompt]: Training 62 / 100 epoch, with learning rate 1.980220772955602
[09/16 02:44:09 visual_prompt]: Epoch 62 / 100: avg data time: 5.44e-02, avg batch time: 0.4571, average train loss: 0.0045
[09/16 02:44:11 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1434, average loss: 0.0028
[09/16 02:44:11 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:44:18 visual_prompt]: Inference (test):avg data time: 7.44e-03, avg batch time: 0.1903, average loss: 1.3421
[09/16 02:44:18 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.70	top5: 89.47	
[09/16 02:44:18 visual_prompt]: Training 63 / 100 epoch, with learning rate 1.895195261000831
[09/16 02:44:26 visual_prompt]: Epoch 63 / 100: avg data time: 5.66e-02, avg batch time: 0.4609, average train loss: 0.0041
[09/16 02:44:27 visual_prompt]: Inference (val):avg data time: 3.80e-05, avg batch time: 0.1434, average loss: 0.0028
[09/16 02:44:27 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:44:34 visual_prompt]: Inference (test):avg data time: 4.75e-03, avg batch time: 0.1872, average loss: 1.3425
[09/16 02:44:34 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.70	top5: 89.04	
[09/16 02:44:34 visual_prompt]: Training 64 / 100 epoch, with learning rate 1.8109066104575022
[09/16 02:44:42 visual_prompt]: Epoch 64 / 100: avg data time: 6.66e-02, avg batch time: 0.4682, average train loss: 0.0042
[09/16 02:44:44 visual_prompt]: Inference (val):avg data time: 3.70e-05, avg batch time: 0.1431, average loss: 0.0034
[09/16 02:44:44 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:44:51 visual_prompt]: Inference (test):avg data time: 4.83e-03, avg batch time: 0.1889, average loss: 1.3490
[09/16 02:44:51 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.76	top5: 89.68	
[09/16 02:44:51 visual_prompt]: Training 65 / 100 epoch, with learning rate 1.7274575140626316
[09/16 02:44:59 visual_prompt]: Epoch 65 / 100: avg data time: 4.44e-02, avg batch time: 0.4484, average train loss: 0.0042
[09/16 02:45:00 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.1435, average loss: 0.0025
[09/16 02:45:00 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:45:07 visual_prompt]: Inference (test):avg data time: 2.70e-03, avg batch time: 0.1882, average loss: 1.3429
[09/16 02:45:07 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.76	top5: 89.20	
[09/16 02:45:07 visual_prompt]: Training 66 / 100 epoch, with learning rate 1.6449496416858285
[09/16 02:45:15 visual_prompt]: Epoch 66 / 100: avg data time: 5.74e-02, avg batch time: 0.4607, average train loss: 0.0037
[09/16 02:45:17 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.1431, average loss: 0.0025
[09/16 02:45:17 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:45:24 visual_prompt]: Inference (test):avg data time: 2.97e-03, avg batch time: 0.2111, average loss: 1.3508
[09/16 02:45:24 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.23	top5: 89.57	
[09/16 02:45:24 visual_prompt]: Training 67 / 100 epoch, with learning rate 1.5634835164602199
[09/16 02:45:32 visual_prompt]: Epoch 67 / 100: avg data time: 6.47e-02, avg batch time: 0.4661, average train loss: 0.0033
[09/16 02:45:34 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.1436, average loss: 0.0022
[09/16 02:45:34 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:45:41 visual_prompt]: Inference (test):avg data time: 2.39e-03, avg batch time: 0.1883, average loss: 1.3404
[09/16 02:45:41 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.13	top5: 89.15	
[09/16 02:45:41 visual_prompt]: Training 68 / 100 epoch, with learning rate 1.4831583923104998
[09/16 02:45:49 visual_prompt]: Epoch 68 / 100: avg data time: 6.47e-02, avg batch time: 0.4666, average train loss: 0.0030
[09/16 02:45:50 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.1435, average loss: 0.0021
[09/16 02:45:50 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:45:57 visual_prompt]: Inference (test):avg data time: 3.67e-03, avg batch time: 0.1867, average loss: 1.3672
[09/16 02:45:57 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.17	top5: 89.10	
[09/16 02:45:57 visual_prompt]: Training 69 / 100 epoch, with learning rate 1.4040721330273063
[09/16 02:46:05 visual_prompt]: Epoch 69 / 100: avg data time: 6.21e-02, avg batch time: 0.4650, average train loss: 0.0029
[09/16 02:46:07 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1433, average loss: 0.0020
[09/16 02:46:07 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:46:14 visual_prompt]: Inference (test):avg data time: 3.77e-03, avg batch time: 0.1879, average loss: 1.3594
[09/16 02:46:14 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.60	top5: 89.20	
[09/16 02:46:14 visual_prompt]: Training 70 / 100 epoch, with learning rate 1.3263210930352738
[09/16 02:46:22 visual_prompt]: Epoch 70 / 100: avg data time: 5.91e-02, avg batch time: 0.4607, average train loss: 0.0028
[09/16 02:46:23 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1432, average loss: 0.0019
[09/16 02:46:23 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:46:30 visual_prompt]: Inference (test):avg data time: 4.17e-03, avg batch time: 0.1869, average loss: 1.3809
[09/16 02:46:30 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.02	top5: 89.31	
[09/16 02:46:30 visual_prompt]: Training 71 / 100 epoch, with learning rate 1.2500000000000004
[09/16 02:46:38 visual_prompt]: Epoch 71 / 100: avg data time: 6.72e-02, avg batch time: 0.4681, average train loss: 0.0028
[09/16 02:46:40 visual_prompt]: Inference (val):avg data time: 3.47e-05, avg batch time: 0.1433, average loss: 0.0020
[09/16 02:46:40 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:46:47 visual_prompt]: Inference (test):avg data time: 2.69e-03, avg batch time: 0.1872, average loss: 1.3700
[09/16 02:46:47 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.07	top5: 89.47	
[09/16 02:46:47 visual_prompt]: Training 72 / 100 epoch, with learning rate 1.175201839416988
[09/16 02:46:54 visual_prompt]: Epoch 72 / 100: avg data time: 6.03e-02, avg batch time: 0.4615, average train loss: 0.0027
[09/16 02:46:56 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.1434, average loss: 0.0018
[09/16 02:46:56 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:47:03 visual_prompt]: Inference (test):avg data time: 5.20e-03, avg batch time: 0.1905, average loss: 1.3813
[09/16 02:47:03 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.76	top5: 89.20	
[09/16 02:47:03 visual_prompt]: Training 73 / 100 epoch, with learning rate 1.1020177413231333
[09/16 02:47:11 visual_prompt]: Epoch 73 / 100: avg data time: 4.65e-02, avg batch time: 0.4522, average train loss: 0.0026
[09/16 02:47:12 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.1434, average loss: 0.0016
[09/16 02:47:12 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:47:20 visual_prompt]: Inference (test):avg data time: 1.90e-03, avg batch time: 0.1883, average loss: 1.3905
[09/16 02:47:20 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.60	top5: 89.20	
[09/16 02:47:20 visual_prompt]: Training 74 / 100 epoch, with learning rate 1.0305368692688175
[09/16 02:47:27 visual_prompt]: Epoch 74 / 100: avg data time: 5.34e-02, avg batch time: 0.4564, average train loss: 0.0025
[09/16 02:47:29 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1434, average loss: 0.0017
[09/16 02:47:29 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:47:36 visual_prompt]: Inference (test):avg data time: 2.85e-03, avg batch time: 0.1867, average loss: 1.3920
[09/16 02:47:36 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.06	top5: 89.15	
[09/16 02:47:36 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.9608463116858543
[09/16 02:47:44 visual_prompt]: Epoch 75 / 100: avg data time: 6.00e-02, avg batch time: 0.4644, average train loss: 0.0024
[09/16 02:47:45 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1433, average loss: 0.0017
[09/16 02:47:45 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:47:52 visual_prompt]: Inference (test):avg data time: 4.27e-03, avg batch time: 0.1878, average loss: 1.4091
[09/16 02:47:52 visual_prompt]: Classification results with test_vtab-dtd: top1: 65.59	top5: 89.15	
[09/16 02:47:52 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.8930309757836516
[09/16 02:48:00 visual_prompt]: Epoch 76 / 100: avg data time: 5.97e-02, avg batch time: 0.4623, average train loss: 0.0024
[09/16 02:48:02 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1432, average loss: 0.0015
[09/16 02:48:02 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:48:09 visual_prompt]: Inference (test):avg data time: 6.27e-03, avg batch time: 0.1894, average loss: 1.4015
[09/16 02:48:09 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.06	top5: 89.10	
[09/16 02:48:09 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.8271734841028553
[09/16 02:48:17 visual_prompt]: Epoch 77 / 100: avg data time: 5.63e-02, avg batch time: 0.4607, average train loss: 0.0023
[09/16 02:48:18 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1433, average loss: 0.0015
[09/16 02:48:18 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:48:25 visual_prompt]: Inference (test):avg data time: 3.78e-03, avg batch time: 0.1880, average loss: 1.4208
[09/16 02:48:25 visual_prompt]: Classification results with test_vtab-dtd: top1: 65.90	top5: 89.10	
[09/16 02:48:25 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.7633540738525066
[09/16 02:48:33 visual_prompt]: Epoch 78 / 100: avg data time: 5.67e-02, avg batch time: 0.4615, average train loss: 0.0022
[09/16 02:48:35 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1432, average loss: 0.0014
[09/16 02:48:35 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:48:42 visual_prompt]: Inference (test):avg data time: 1.84e-03, avg batch time: 0.1891, average loss: 1.4314
[09/16 02:48:42 visual_prompt]: Classification results with test_vtab-dtd: top1: 65.37	top5: 89.31	
[09/16 02:48:42 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.7016504991533725
[09/16 02:48:50 visual_prompt]: Epoch 79 / 100: avg data time: 4.86e-02, avg batch time: 0.4509, average train loss: 0.0021
[09/16 02:48:51 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1436, average loss: 0.0015
[09/16 02:48:51 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:48:58 visual_prompt]: Inference (test):avg data time: 6.01e-03, avg batch time: 0.1878, average loss: 1.4391
[09/16 02:48:58 visual_prompt]: Classification results with test_vtab-dtd: top1: 65.48	top5: 88.78	
[09/16 02:48:58 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.6421379363065141
[09/16 02:49:06 visual_prompt]: Epoch 80 / 100: avg data time: 6.32e-02, avg batch time: 0.4662, average train loss: 0.0021
[09/16 02:49:08 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1432, average loss: 0.0014
[09/16 02:49:08 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:49:15 visual_prompt]: Inference (test):avg data time: 2.92e-03, avg batch time: 0.1866, average loss: 1.4436
[09/16 02:49:15 visual_prompt]: Classification results with test_vtab-dtd: top1: 65.74	top5: 89.41	
[09/16 02:49:15 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.5848888922025552
[09/16 02:49:23 visual_prompt]: Epoch 81 / 100: avg data time: 6.26e-02, avg batch time: 0.4656, average train loss: 0.0021
[09/16 02:49:24 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1433, average loss: 0.0014
[09/16 02:49:24 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:49:31 visual_prompt]: Inference (test):avg data time: 4.59e-03, avg batch time: 0.1909, average loss: 1.4501
[09/16 02:49:31 visual_prompt]: Classification results with test_vtab-dtd: top1: 65.59	top5: 89.10	
[09/16 02:49:31 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.5299731159831953
[09/16 02:49:39 visual_prompt]: Epoch 82 / 100: avg data time: 6.41e-02, avg batch time: 0.4665, average train loss: 0.0020
[09/16 02:49:41 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1432, average loss: 0.0013
[09/16 02:49:41 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:49:48 visual_prompt]: Inference (test):avg data time: 4.31e-03, avg batch time: 0.1884, average loss: 1.4518
[09/16 02:49:48 visual_prompt]: Classification results with test_vtab-dtd: top1: 65.64	top5: 89.15	
[09/16 02:49:48 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.47745751406263165
[09/16 02:49:56 visual_prompt]: Epoch 83 / 100: avg data time: 5.66e-02, avg batch time: 0.4594, average train loss: 0.0020
[09/16 02:49:57 visual_prompt]: Inference (val):avg data time: 4.23e-05, avg batch time: 0.1436, average loss: 0.0013
[09/16 02:49:57 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:50:04 visual_prompt]: Inference (test):avg data time: 4.43e-03, avg batch time: 0.1898, average loss: 1.4524
[09/16 02:50:05 visual_prompt]: Classification results with test_vtab-dtd: top1: 65.53	top5: 89.41	
[09/16 02:50:05 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.42740606861239594
[09/16 02:50:12 visual_prompt]: Epoch 84 / 100: avg data time: 6.12e-02, avg batch time: 0.4633, average train loss: 0.0020
[09/16 02:50:14 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1434, average loss: 0.0013
[09/16 02:50:14 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:50:21 visual_prompt]: Inference (test):avg data time: 5.33e-03, avg batch time: 0.1882, average loss: 1.4643
[09/16 02:50:21 visual_prompt]: Classification results with test_vtab-dtd: top1: 65.21	top5: 88.99	
[09/16 02:50:21 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.3798797596089351
[09/16 02:50:29 visual_prompt]: Epoch 85 / 100: avg data time: 6.40e-02, avg batch time: 0.4663, average train loss: 0.0020
[09/16 02:50:31 visual_prompt]: Inference (val):avg data time: 3.81e-05, avg batch time: 0.1433, average loss: 0.0013
[09/16 02:50:31 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:50:38 visual_prompt]: Inference (test):avg data time: 2.62e-03, avg batch time: 0.1864, average loss: 1.4589
[09/16 02:50:38 visual_prompt]: Classification results with test_vtab-dtd: top1: 65.74	top5: 89.26	
[09/16 02:50:38 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.33493649053890323
[09/16 02:50:45 visual_prompt]: Epoch 86 / 100: avg data time: 5.37e-02, avg batch time: 0.4575, average train loss: 0.0019
[09/16 02:50:47 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1432, average loss: 0.0013
[09/16 02:50:47 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:50:54 visual_prompt]: Inference (test):avg data time: 4.01e-03, avg batch time: 0.1886, average loss: 1.4654
[09/16 02:50:54 visual_prompt]: Classification results with test_vtab-dtd: top1: 65.32	top5: 89.26	
[09/16 02:50:54 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.29263101785268253
[09/16 02:51:02 visual_prompt]: Epoch 87 / 100: avg data time: 6.29e-02, avg batch time: 0.4647, average train loss: 0.0019
[09/16 02:51:04 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1435, average loss: 0.0013
[09/16 02:51:04 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:51:11 visual_prompt]: Inference (test):avg data time: 5.16e-03, avg batch time: 0.1884, average loss: 1.4664
[09/16 02:51:11 visual_prompt]: Classification results with test_vtab-dtd: top1: 65.21	top5: 89.26	
[09/16 02:51:11 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.25301488425208296
[09/16 02:51:19 visual_prompt]: Epoch 88 / 100: avg data time: 6.82e-02, avg batch time: 0.4725, average train loss: 0.0019
[09/16 02:51:20 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1434, average loss: 0.0013
[09/16 02:51:20 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:51:27 visual_prompt]: Inference (test):avg data time: 2.21e-03, avg batch time: 0.1846, average loss: 1.4741
[09/16 02:51:27 visual_prompt]: Classification results with test_vtab-dtd: top1: 65.05	top5: 89.26	
[09/16 02:51:27 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.21613635589349756
[09/16 02:51:35 visual_prompt]: Epoch 89 / 100: avg data time: 5.70e-02, avg batch time: 0.4643, average train loss: 0.0018
[09/16 02:51:37 visual_prompt]: Inference (val):avg data time: 4.06e-05, avg batch time: 0.1435, average loss: 0.0013
[09/16 02:51:37 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:51:44 visual_prompt]: Inference (test):avg data time: 5.24e-03, avg batch time: 0.1878, average loss: 1.4758
[09/16 02:51:44 visual_prompt]: Classification results with test_vtab-dtd: top1: 65.00	top5: 89.26	
[09/16 02:51:44 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.18204036358303172
[09/16 02:51:52 visual_prompt]: Epoch 90 / 100: avg data time: 6.68e-02, avg batch time: 0.4692, average train loss: 0.0018
[09/16 02:51:53 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.1435, average loss: 0.0013
[09/16 02:51:53 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:52:01 visual_prompt]: Inference (test):avg data time: 6.52e-03, avg batch time: 0.1912, average loss: 1.4736
[09/16 02:52:01 visual_prompt]: Classification results with test_vtab-dtd: top1: 65.16	top5: 89.26	
[09/16 02:52:01 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.1507684480352292
[09/16 02:52:09 visual_prompt]: Epoch 91 / 100: avg data time: 6.49e-02, avg batch time: 0.4666, average train loss: 0.0018
[09/16 02:52:10 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1432, average loss: 0.0013
[09/16 02:52:10 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:52:17 visual_prompt]: Inference (test):avg data time: 3.72e-03, avg batch time: 0.1870, average loss: 1.4719
[09/16 02:52:17 visual_prompt]: Classification results with test_vtab-dtd: top1: 65.37	top5: 89.26	
[09/16 02:52:17 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.12235870926211617
[09/16 02:52:25 visual_prompt]: Epoch 92 / 100: avg data time: 6.32e-02, avg batch time: 0.4654, average train loss: 0.0018
[09/16 02:52:27 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1432, average loss: 0.0013
[09/16 02:52:27 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:52:34 visual_prompt]: Inference (test):avg data time: 3.33e-03, avg batch time: 0.1866, average loss: 1.4744
[09/16 02:52:34 visual_prompt]: Classification results with test_vtab-dtd: top1: 65.11	top5: 89.26	
[09/16 02:52:34 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.09684576015420276
[09/16 02:52:42 visual_prompt]: Epoch 93 / 100: avg data time: 6.48e-02, avg batch time: 0.4657, average train loss: 0.0018
[09/16 02:52:44 visual_prompt]: Inference (val):avg data time: 3.96e-05, avg batch time: 0.1444, average loss: 0.0013
[09/16 02:52:44 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:52:51 visual_prompt]: Inference (test):avg data time: 3.77e-03, avg batch time: 0.1873, average loss: 1.4740
[09/16 02:52:51 visual_prompt]: Classification results with test_vtab-dtd: top1: 65.37	top5: 89.26	
[09/16 02:52:51 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.07426068431000882
[09/16 02:52:58 visual_prompt]: Epoch 94 / 100: avg data time: 5.84e-02, avg batch time: 0.4618, average train loss: 0.0018
[09/16 02:53:00 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.1433, average loss: 0.0013
[09/16 02:53:00 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:53:07 visual_prompt]: Inference (test):avg data time: 3.37e-03, avg batch time: 0.1885, average loss: 1.4761
[09/16 02:53:07 visual_prompt]: Classification results with test_vtab-dtd: top1: 65.21	top5: 89.20	
[09/16 02:53:07 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.05463099816548578
[09/16 02:53:15 visual_prompt]: Epoch 95 / 100: avg data time: 4.56e-02, avg batch time: 0.4490, average train loss: 0.0018
[09/16 02:53:16 visual_prompt]: Inference (val):avg data time: 3.58e-05, avg batch time: 0.1435, average loss: 0.0013
[09/16 02:53:16 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:53:24 visual_prompt]: Inference (test):avg data time: 7.34e-03, avg batch time: 0.1890, average loss: 1.4789
[09/16 02:53:24 visual_prompt]: Classification results with test_vtab-dtd: top1: 65.16	top5: 89.31	
[09/16 02:53:24 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.03798061746947995
[09/16 02:53:31 visual_prompt]: Epoch 96 / 100: avg data time: 6.47e-02, avg batch time: 0.4670, average train loss: 0.0018
[09/16 02:53:33 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1434, average loss: 0.0012
[09/16 02:53:33 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:53:40 visual_prompt]: Inference (test):avg data time: 4.14e-03, avg batch time: 0.1895, average loss: 1.4790
[09/16 02:53:40 visual_prompt]: Classification results with test_vtab-dtd: top1: 65.21	top5: 89.10	
[09/16 02:53:40 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.024329828146074095
[09/16 02:53:48 visual_prompt]: Epoch 97 / 100: avg data time: 6.21e-02, avg batch time: 0.4632, average train loss: 0.0018
[09/16 02:53:50 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1435, average loss: 0.0012
[09/16 02:53:50 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:53:57 visual_prompt]: Inference (test):avg data time: 5.24e-03, avg batch time: 0.1864, average loss: 1.4787
[09/16 02:53:57 visual_prompt]: Classification results with test_vtab-dtd: top1: 65.11	top5: 89.10	
[09/16 02:53:57 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.013695261579316775
[09/16 02:54:05 visual_prompt]: Epoch 98 / 100: avg data time: 6.61e-02, avg batch time: 0.4699, average train loss: 0.0018
[09/16 02:54:06 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1433, average loss: 0.0012
[09/16 02:54:06 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:54:13 visual_prompt]: Inference (test):avg data time: 5.30e-03, avg batch time: 0.1868, average loss: 1.4788
[09/16 02:54:13 visual_prompt]: Classification results with test_vtab-dtd: top1: 65.21	top5: 89.10	
[09/16 02:54:13 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.006089874350439506
[09/16 02:54:21 visual_prompt]: Epoch 99 / 100: avg data time: 6.23e-02, avg batch time: 0.4655, average train loss: 0.0018
[09/16 02:54:23 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1430, average loss: 0.0012
[09/16 02:54:23 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:54:30 visual_prompt]: Inference (test):avg data time: 2.88e-03, avg batch time: 0.1864, average loss: 1.4789
[09/16 02:54:30 visual_prompt]: Classification results with test_vtab-dtd: top1: 65.21	top5: 89.15	
[09/16 02:54:30 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0015229324522605947
[09/16 02:54:38 visual_prompt]: Epoch 100 / 100: avg data time: 6.20e-02, avg batch time: 0.4637, average train loss: 0.0018
[09/16 02:54:39 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1435, average loss: 0.0012
[09/16 02:54:39 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 02:54:46 visual_prompt]: Inference (test):avg data time: 5.84e-03, avg batch time: 0.1887, average loss: 1.4788
[09/16 02:54:46 visual_prompt]: Classification results with test_vtab-dtd: top1: 65.21	top5: 89.15	
[09/16 02:55:09 visual_prompt]: Rank of current process: 0. World size: 1
[09/16 02:55:09 visual_prompt]: Environment info:
-------------------  ----------------------------------------------------
Python               3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              1.7.1
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  ----------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[09/16 02:55:09 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '100', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-dtd', 'DATA.NUMBER_CLASSES', '47', 'SOLVER.BASE_LR', '5.0', 'SOLVER.WEIGHT_DECAY', '0.0001', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir/seed82'], train_type='')
[09/16 02:55:09 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/16 02:55:09 visual_prompt]: Training with config:
[09/16 02:55:09 visual_prompt]: {'CUDNN_BENCHMARK': False,
 'DATA': {'BATCH_SIZE': 64,
          'CLASS_WEIGHTS_TYPE': 'none',
          'CROPSIZE': 224,
          'DATAPATH': 'visual_prompt_tuning/data_path',
          'FEATURE': 'sup_vitb16_imagenet21k',
          'MULTILABEL': False,
          'NAME': 'vtab-dtd',
          'NO_TEST': False,
          'NUMBER_CLASSES': 47,
          'NUM_WORKERS': 4,
          'PERCENTAGE': 1.0,
          'PIN_MEMORY': True},
 'DBG': False,
 'MODEL': {'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'}),
           'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}),
           'MLP_NUM': 0,
           'MODEL_ROOT': 'visual_prompt_tuning/model_root',
           'PROMPT': {'CLSEMB_FOLDER': '',
                      'CLSEMB_PATH': '',
                      'DEEP': True,
                      'DEEP_SHARED': False,
                      'DROPOUT': 0.1,
                      'FORWARD_DEEP_NOEXPAND': False,
                      'INITIATION': 'random',
                      'LOCATION': 'prepend',
                      'NUM_DEEP_LAYERS': None,
                      'NUM_TOKENS': 100,
                      'PROJECT': -1,
                      'REVERSE_DEEP': False,
                      'SAVE_FOR_EACH_EPOCH': False,
                      'VIT_POOL_TYPE': 'original'},
           'SAVE_CKPT': False,
           'TRANSFER_TYPE': 'prompt',
           'TYPE': 'vit',
           'WEIGHT_PATH': ''},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/seed82/vtab-dtd/sup_vitb16_imagenet21k/lr5.0_wd0.0001/run1',
 'RUN_N_TIMES': 1,
 'SEED': None,
 'SOLVER': {'BASE_LR': 5.0,
            'BIAS_MULTIPLIER': 1.0,
            'DBG_TRAINABLE': False,
            'LOG_EVERY_N': 100,
            'LOSS': 'softmax',
            'LOSS_ALPHA': 0.01,
            'MOMENTUM': 0.9,
            'OPTIMIZER': 'sgd',
            'PATIENCE': 300,
            'SCHEDULER': 'cosine',
            'TOTAL_EPOCH': 100,
            'WARMUP_EPOCH': 10,
            'WEIGHT_DECAY': 0.0001,
            'WEIGHT_DECAY_BIAS': 0}}
[09/16 02:55:09 visual_prompt]: Loading training data (final training data for vtab)...
2023-09-16 02:55:09.129741: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-09-16 02:55:09.300184: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-09-16 02:55:10.225306: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-16 02:55:10.225394: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-16 02:55:10.225405: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-09-16 02:55:12.301892: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-16 02:55:12.302009: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-16 02:55:12.302026: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
[09/16 02:55:12 visual_prompt]: Constructing vtab-dtd dataset trainval...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/dtd/3.0.1
[INFO: dataset_builder.py:  510]: Reusing dataset dtd (visual_prompt_tuning/data_path/dtd/3.0.1)
2023-09-16 02:55:12.330446: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset dtd for split train[:800]+validation[:200], from visual_prompt_tuning/data_path/dtd/3.0.1
[09/16 02:55:15 visual_prompt]: Number of images: 1000
[09/16 02:55:15 visual_prompt]: Number of classes: 47 / 47
[09/16 02:55:15 visual_prompt]: Loading validation data...
[09/16 02:55:15 visual_prompt]: Constructing vtab-dtd dataset val...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/dtd/3.0.1
[INFO: dataset_builder.py:  510]: Reusing dataset dtd (visual_prompt_tuning/data_path/dtd/3.0.1)
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset dtd for split validation[:200], from visual_prompt_tuning/data_path/dtd/3.0.1
[09/16 02:55:16 visual_prompt]: Number of images: 200
[09/16 02:55:16 visual_prompt]: Number of classes: 47 / 47
[09/16 02:55:16 visual_prompt]: Loading test data...
[09/16 02:55:16 visual_prompt]: Constructing vtab-dtd dataset test...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/dtd/3.0.1
[INFO: dataset_builder.py:  510]: Reusing dataset dtd (visual_prompt_tuning/data_path/dtd/3.0.1)
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset dtd for split test, from visual_prompt_tuning/data_path/dtd/3.0.1
[09/16 02:55:21 visual_prompt]: Number of images: 1880
[09/16 02:55:21 visual_prompt]: Number of classes: 47 / 47
[09/16 02:55:21 visual_prompt]: Constructing models...
[09/16 02:55:24 visual_prompt]: Total Parameters: 86756399	 Gradient Parameters: 957743
[09/16 02:55:24 visual_prompt]: tuned percent:1.104
[09/16 02:55:26 visual_prompt]: Device used for model: 0
[09/16 02:55:26 visual_prompt]: Setting up Evalutator...
[09/16 02:55:26 visual_prompt]: Setting up Trainer...
[09/16 02:55:26 visual_prompt]: 	Setting up the optimizer...
[09/16 02:55:26 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/16 02:55:35 visual_prompt]: Epoch 1 / 100: avg data time: 7.30e-02, avg batch time: 0.5493, average train loss: 3.9478
[09/16 02:55:37 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1426, average loss: 3.9264
[09/16 02:55:37 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.50	top5: 10.00	
[09/16 02:55:44 visual_prompt]: Inference (test):avg data time: 6.82e-03, avg batch time: 0.1865, average loss: 3.9213
[09/16 02:55:44 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.02	top5: 10.43	
[09/16 02:55:44 visual_prompt]: Best epoch 1: best metric: 0.025
[09/16 02:55:44 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.5
[09/16 02:55:52 visual_prompt]: Epoch 2 / 100: avg data time: 5.27e-02, avg batch time: 0.4530, average train loss: 3.9243
[09/16 02:55:53 visual_prompt]: Inference (val):avg data time: 3.63e-05, avg batch time: 0.1426, average loss: 3.8558
[09/16 02:55:53 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.50	top5: 15.50	
[09/16 02:56:01 visual_prompt]: Inference (test):avg data time: 6.53e-03, avg batch time: 0.1887, average loss: 3.8689
[09/16 02:56:01 visual_prompt]: Classification results with test_vtab-dtd: top1: 3.40	top5: 13.62	
[09/16 02:56:01 visual_prompt]: Training 3 / 100 epoch, with learning rate 1.0
[09/16 02:56:08 visual_prompt]: Epoch 3 / 100: avg data time: 6.37e-02, avg batch time: 0.4653, average train loss: 3.9037
[09/16 02:56:10 visual_prompt]: Inference (val):avg data time: 3.53e-05, avg batch time: 0.1426, average loss: 3.8344
[09/16 02:56:10 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.50	top5: 17.50	
[09/16 02:56:17 visual_prompt]: Inference (test):avg data time: 3.45e-03, avg batch time: 0.1855, average loss: 3.8673
[09/16 02:56:17 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.18	top5: 14.10	
[09/16 02:56:17 visual_prompt]: Training 4 / 100 epoch, with learning rate 1.5
[09/16 02:56:25 visual_prompt]: Epoch 4 / 100: avg data time: 6.45e-02, avg batch time: 0.4662, average train loss: 3.9420
[09/16 02:56:27 visual_prompt]: Inference (val):avg data time: 3.65e-05, avg batch time: 0.1428, average loss: 3.7589
[09/16 02:56:27 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.00	top5: 22.00	
[09/16 02:56:34 visual_prompt]: Inference (test):avg data time: 4.10e-03, avg batch time: 0.1872, average loss: 3.7968
[09/16 02:56:34 visual_prompt]: Classification results with test_vtab-dtd: top1: 5.11	top5: 20.69	
[09/16 02:56:34 visual_prompt]: Training 5 / 100 epoch, with learning rate 2.0
[09/16 02:56:41 visual_prompt]: Epoch 5 / 100: avg data time: 6.11e-02, avg batch time: 0.4632, average train loss: 3.7716
[09/16 02:56:43 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1429, average loss: 3.6977
[09/16 02:56:43 visual_prompt]: Classification results with val_vtab-dtd: top1: 7.50	top5: 25.00	
[09/16 02:56:50 visual_prompt]: Inference (test):avg data time: 2.81e-03, avg batch time: 0.1856, average loss: 3.7773
[09/16 02:56:50 visual_prompt]: Classification results with test_vtab-dtd: top1: 5.48	top5: 24.57	
[09/16 02:56:50 visual_prompt]: Best epoch 5: best metric: 0.075
[09/16 02:56:50 visual_prompt]: Training 6 / 100 epoch, with learning rate 2.5
[09/16 02:56:58 visual_prompt]: Epoch 6 / 100: avg data time: 6.18e-02, avg batch time: 0.4637, average train loss: 3.5474
[09/16 02:56:59 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1431, average loss: 3.4590
[09/16 02:56:59 visual_prompt]: Classification results with val_vtab-dtd: top1: 10.50	top5: 32.00	
[09/16 02:57:07 visual_prompt]: Inference (test):avg data time: 5.73e-03, avg batch time: 0.1894, average loss: 3.4807
[09/16 02:57:07 visual_prompt]: Classification results with test_vtab-dtd: top1: 11.49	top5: 32.13	
[09/16 02:57:07 visual_prompt]: Best epoch 6: best metric: 0.105
[09/16 02:57:07 visual_prompt]: Training 7 / 100 epoch, with learning rate 3.0
[09/16 02:57:14 visual_prompt]: Epoch 7 / 100: avg data time: 6.41e-02, avg batch time: 0.4662, average train loss: 3.3067
[09/16 02:57:16 visual_prompt]: Inference (val):avg data time: 3.95e-05, avg batch time: 0.1432, average loss: 3.7030
[09/16 02:57:16 visual_prompt]: Classification results with val_vtab-dtd: top1: 9.00	top5: 33.00	
[09/16 02:57:23 visual_prompt]: Inference (test):avg data time: 4.31e-03, avg batch time: 0.1883, average loss: 3.7942
[09/16 02:57:23 visual_prompt]: Classification results with test_vtab-dtd: top1: 6.44	top5: 28.67	
[09/16 02:57:23 visual_prompt]: Training 8 / 100 epoch, with learning rate 3.5
[09/16 02:57:31 visual_prompt]: Epoch 8 / 100: avg data time: 6.35e-02, avg batch time: 0.4860, average train loss: 3.1294
[09/16 02:57:33 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1431, average loss: 2.4800
[09/16 02:57:33 visual_prompt]: Classification results with val_vtab-dtd: top1: 31.00	top5: 65.00	
[09/16 02:57:40 visual_prompt]: Inference (test):avg data time: 5.03e-03, avg batch time: 0.1859, average loss: 2.9947
[09/16 02:57:40 visual_prompt]: Classification results with test_vtab-dtd: top1: 23.30	top5: 53.46	
[09/16 02:57:40 visual_prompt]: Best epoch 8: best metric: 0.310
[09/16 02:57:40 visual_prompt]: Training 9 / 100 epoch, with learning rate 4.0
[09/16 02:57:48 visual_prompt]: Epoch 9 / 100: avg data time: 6.18e-02, avg batch time: 0.4643, average train loss: 2.3788
[09/16 02:57:50 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1432, average loss: 2.0192
[09/16 02:57:50 visual_prompt]: Classification results with val_vtab-dtd: top1: 43.50	top5: 78.00	
[09/16 02:57:57 visual_prompt]: Inference (test):avg data time: 3.91e-03, avg batch time: 0.2129, average loss: 2.5824
[09/16 02:57:57 visual_prompt]: Classification results with test_vtab-dtd: top1: 32.13	top5: 65.85	
[09/16 02:57:57 visual_prompt]: Best epoch 9: best metric: 0.435
[09/16 02:57:57 visual_prompt]: Training 10 / 100 epoch, with learning rate 4.5
[09/16 02:58:05 visual_prompt]: Epoch 10 / 100: avg data time: 6.23e-02, avg batch time: 0.4647, average train loss: 1.8807
[09/16 02:58:07 visual_prompt]: Inference (val):avg data time: 5.25e-05, avg batch time: 0.1432, average loss: 1.8492
[09/16 02:58:07 visual_prompt]: Classification results with val_vtab-dtd: top1: 48.00	top5: 80.00	
[09/16 02:58:14 visual_prompt]: Inference (test):avg data time: 5.16e-03, avg batch time: 0.1881, average loss: 2.5444
[09/16 02:58:14 visual_prompt]: Classification results with test_vtab-dtd: top1: 37.34	top5: 67.29	
[09/16 02:58:14 visual_prompt]: Best epoch 10: best metric: 0.480
[09/16 02:58:14 visual_prompt]: Training 11 / 100 epoch, with learning rate 5.0
[09/16 02:58:22 visual_prompt]: Epoch 11 / 100: avg data time: 4.73e-02, avg batch time: 0.4538, average train loss: 1.7257
[09/16 02:58:23 visual_prompt]: Inference (val):avg data time: 3.83e-05, avg batch time: 0.1434, average loss: 1.5606
[09/16 02:58:23 visual_prompt]: Classification results with val_vtab-dtd: top1: 59.50	top5: 86.00	
[09/16 02:58:30 visual_prompt]: Inference (test):avg data time: 4.75e-03, avg batch time: 0.1911, average loss: 2.4611
[09/16 02:58:30 visual_prompt]: Classification results with test_vtab-dtd: top1: 37.98	top5: 72.18	
[09/16 02:58:30 visual_prompt]: Best epoch 11: best metric: 0.595
[09/16 02:58:30 visual_prompt]: Training 12 / 100 epoch, with learning rate 4.998477067547739
[09/16 02:58:38 visual_prompt]: Epoch 12 / 100: avg data time: 5.67e-02, avg batch time: 0.4596, average train loss: 1.3049
[09/16 02:58:40 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1433, average loss: 1.7794
[09/16 02:58:40 visual_prompt]: Classification results with val_vtab-dtd: top1: 51.00	top5: 84.50	
[09/16 02:58:47 visual_prompt]: Inference (test):avg data time: 1.68e-03, avg batch time: 0.1844, average loss: 2.6415
[09/16 02:58:47 visual_prompt]: Classification results with test_vtab-dtd: top1: 36.91	top5: 70.11	
[09/16 02:58:47 visual_prompt]: Training 13 / 100 epoch, with learning rate 4.993910125649561
[09/16 02:58:55 visual_prompt]: Epoch 13 / 100: avg data time: 5.56e-02, avg batch time: 0.4595, average train loss: 1.0509
[09/16 02:58:56 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1435, average loss: 0.9717
[09/16 02:58:56 visual_prompt]: Classification results with val_vtab-dtd: top1: 72.00	top5: 97.50	
[09/16 02:59:03 visual_prompt]: Inference (test):avg data time: 4.98e-03, avg batch time: 0.1871, average loss: 2.4559
[09/16 02:59:03 visual_prompt]: Classification results with test_vtab-dtd: top1: 44.15	top5: 79.63	
[09/16 02:59:03 visual_prompt]: Best epoch 13: best metric: 0.720
[09/16 02:59:03 visual_prompt]: Training 14 / 100 epoch, with learning rate 4.986304738420683
[09/16 02:59:11 visual_prompt]: Epoch 14 / 100: avg data time: 6.31e-02, avg batch time: 0.4656, average train loss: 0.7239
[09/16 02:59:13 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1435, average loss: 0.4866
[09/16 02:59:13 visual_prompt]: Classification results with val_vtab-dtd: top1: 83.00	top5: 99.50	
[09/16 02:59:20 visual_prompt]: Inference (test):avg data time: 4.32e-03, avg batch time: 0.2022, average loss: 2.2411
[09/16 02:59:20 visual_prompt]: Classification results with test_vtab-dtd: top1: 53.51	top5: 82.98	
[09/16 02:59:20 visual_prompt]: Best epoch 14: best metric: 0.830
[09/16 02:59:20 visual_prompt]: Training 15 / 100 epoch, with learning rate 4.975670171853926
[09/16 02:59:28 visual_prompt]: Epoch 15 / 100: avg data time: 6.58e-02, avg batch time: 0.4686, average train loss: 0.7904
[09/16 02:59:30 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1433, average loss: 0.6268
[09/16 02:59:30 visual_prompt]: Classification results with val_vtab-dtd: top1: 81.50	top5: 99.00	
[09/16 02:59:37 visual_prompt]: Inference (test):avg data time: 2.58e-03, avg batch time: 0.1862, average loss: 2.2567
[09/16 02:59:37 visual_prompt]: Classification results with test_vtab-dtd: top1: 51.65	top5: 81.44	
[09/16 02:59:37 visual_prompt]: Training 16 / 100 epoch, with learning rate 4.962019382530521
[09/16 02:59:44 visual_prompt]: Epoch 16 / 100: avg data time: 4.47e-02, avg batch time: 0.4487, average train loss: 0.6847
[09/16 02:59:46 visual_prompt]: Inference (val):avg data time: 3.57e-05, avg batch time: 0.1433, average loss: 0.4868
[09/16 02:59:46 visual_prompt]: Classification results with val_vtab-dtd: top1: 85.00	top5: 98.50	
[09/16 02:59:53 visual_prompt]: Inference (test):avg data time: 3.15e-03, avg batch time: 0.1855, average loss: 2.7696
[09/16 02:59:53 visual_prompt]: Classification results with test_vtab-dtd: top1: 52.98	top5: 80.43	
[09/16 02:59:53 visual_prompt]: Best epoch 16: best metric: 0.850
[09/16 02:59:53 visual_prompt]: Training 17 / 100 epoch, with learning rate 4.945369001834514
[09/16 03:00:01 visual_prompt]: Epoch 17 / 100: avg data time: 6.58e-02, avg batch time: 0.4677, average train loss: 0.4646
[09/16 03:00:03 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1432, average loss: 0.5889
[09/16 03:00:03 visual_prompt]: Classification results with val_vtab-dtd: top1: 83.50	top5: 98.00	
[09/16 03:00:10 visual_prompt]: Inference (test):avg data time: 5.13e-03, avg batch time: 0.1889, average loss: 2.7579
[09/16 03:00:10 visual_prompt]: Classification results with test_vtab-dtd: top1: 51.28	top5: 80.27	
[09/16 03:00:10 visual_prompt]: Training 18 / 100 epoch, with learning rate 4.925739315689991
[09/16 03:00:18 visual_prompt]: Epoch 18 / 100: avg data time: 5.68e-02, avg batch time: 0.4605, average train loss: 0.5632
[09/16 03:00:20 visual_prompt]: Inference (val):avg data time: 3.56e-05, avg batch time: 0.1434, average loss: 0.6252
[09/16 03:00:20 visual_prompt]: Classification results with val_vtab-dtd: top1: 84.00	top5: 99.00	
[09/16 03:00:26 visual_prompt]: Inference (test):avg data time: 4.32e-03, avg batch time: 0.1900, average loss: 3.0206
[09/16 03:00:26 visual_prompt]: Classification results with test_vtab-dtd: top1: 51.06	top5: 80.59	
[09/16 03:00:26 visual_prompt]: Training 19 / 100 epoch, with learning rate 4.903154239845797
[09/16 03:00:34 visual_prompt]: Epoch 19 / 100: avg data time: 6.71e-02, avg batch time: 0.4691, average train loss: 0.4003
[09/16 03:00:36 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.1435, average loss: 0.2494
[09/16 03:00:36 visual_prompt]: Classification results with val_vtab-dtd: top1: 92.00	top5: 100.00	
[09/16 03:00:43 visual_prompt]: Inference (test):avg data time: 3.77e-03, avg batch time: 0.1876, average loss: 2.5342
[09/16 03:00:43 visual_prompt]: Classification results with test_vtab-dtd: top1: 54.36	top5: 82.02	
[09/16 03:00:43 visual_prompt]: Best epoch 19: best metric: 0.920
[09/16 03:00:43 visual_prompt]: Training 20 / 100 epoch, with learning rate 4.877641290737884
[09/16 03:00:51 visual_prompt]: Epoch 20 / 100: avg data time: 6.36e-02, avg batch time: 0.4640, average train loss: 0.2849
[09/16 03:00:53 visual_prompt]: Inference (val):avg data time: 5.17e-05, avg batch time: 0.1434, average loss: 0.3857
[09/16 03:00:53 visual_prompt]: Classification results with val_vtab-dtd: top1: 86.00	top5: 98.50	
[09/16 03:01:00 visual_prompt]: Inference (test):avg data time: 4.75e-03, avg batch time: 0.1876, average loss: 2.8381
[09/16 03:01:00 visual_prompt]: Classification results with test_vtab-dtd: top1: 48.83	top5: 79.95	
[09/16 03:01:00 visual_prompt]: Training 21 / 100 epoch, with learning rate 4.849231551964771
[09/16 03:01:07 visual_prompt]: Epoch 21 / 100: avg data time: 5.73e-02, avg batch time: 0.4606, average train loss: 0.3057
[09/16 03:01:09 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1434, average loss: 0.5739
[09/16 03:01:09 visual_prompt]: Classification results with val_vtab-dtd: top1: 88.00	top5: 98.50	
[09/16 03:01:16 visual_prompt]: Inference (test):avg data time: 4.58e-03, avg batch time: 0.1866, average loss: 3.0659
[09/16 03:01:16 visual_prompt]: Classification results with test_vtab-dtd: top1: 50.59	top5: 79.73	
[09/16 03:01:16 visual_prompt]: Training 22 / 100 epoch, with learning rate 4.817959636416969
[09/16 03:01:24 visual_prompt]: Epoch 22 / 100: avg data time: 5.83e-02, avg batch time: 0.4613, average train loss: 0.3301
[09/16 03:01:26 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1434, average loss: 0.3388
[09/16 03:01:26 visual_prompt]: Classification results with val_vtab-dtd: top1: 90.00	top5: 100.00	
[09/16 03:01:33 visual_prompt]: Inference (test):avg data time: 3.72e-03, avg batch time: 0.1860, average loss: 2.8247
[09/16 03:01:33 visual_prompt]: Classification results with test_vtab-dtd: top1: 51.86	top5: 80.11	
[09/16 03:01:33 visual_prompt]: Training 23 / 100 epoch, with learning rate 4.783863644106502
[09/16 03:01:41 visual_prompt]: Epoch 23 / 100: avg data time: 6.53e-02, avg batch time: 0.4666, average train loss: 0.3243
[09/16 03:01:43 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1433, average loss: 0.2919
[09/16 03:01:43 visual_prompt]: Classification results with val_vtab-dtd: top1: 91.00	top5: 99.00	
[09/16 03:01:50 visual_prompt]: Inference (test):avg data time: 7.09e-03, avg batch time: 0.1893, average loss: 2.6509
[09/16 03:01:50 visual_prompt]: Classification results with test_vtab-dtd: top1: 51.76	top5: 79.20	
[09/16 03:01:50 visual_prompt]: Training 24 / 100 epoch, with learning rate 4.7469851157479175
[09/16 03:01:58 visual_prompt]: Epoch 24 / 100: avg data time: 6.67e-02, avg batch time: 0.4675, average train loss: 0.3067
[09/16 03:01:59 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1440, average loss: 0.2204
[09/16 03:01:59 visual_prompt]: Classification results with val_vtab-dtd: top1: 93.00	top5: 99.50	
[09/16 03:02:06 visual_prompt]: Inference (test):avg data time: 3.08e-03, avg batch time: 0.1886, average loss: 2.7409
[09/16 03:02:06 visual_prompt]: Classification results with test_vtab-dtd: top1: 52.82	top5: 81.44	
[09/16 03:02:06 visual_prompt]: Best epoch 24: best metric: 0.930
[09/16 03:02:06 visual_prompt]: Training 25 / 100 epoch, with learning rate 4.707368982147317
[09/16 03:02:14 visual_prompt]: Epoch 25 / 100: avg data time: 6.26e-02, avg batch time: 0.4629, average train loss: 0.1819
[09/16 03:02:16 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.1433, average loss: 0.1543
[09/16 03:02:16 visual_prompt]: Classification results with val_vtab-dtd: top1: 95.50	top5: 100.00	
[09/16 03:02:23 visual_prompt]: Inference (test):avg data time: 2.36e-03, avg batch time: 0.1845, average loss: 2.5738
[09/16 03:02:23 visual_prompt]: Classification results with test_vtab-dtd: top1: 55.59	top5: 84.47	
[09/16 03:02:23 visual_prompt]: Best epoch 25: best metric: 0.955
[09/16 03:02:23 visual_prompt]: Training 26 / 100 epoch, with learning rate 4.665063509461097
[09/16 03:02:30 visual_prompt]: Epoch 26 / 100: avg data time: 5.55e-02, avg batch time: 0.4580, average train loss: 0.1907
[09/16 03:02:32 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1432, average loss: 0.0789
[09/16 03:02:32 visual_prompt]: Classification results with val_vtab-dtd: top1: 98.00	top5: 100.00	
[09/16 03:02:39 visual_prompt]: Inference (test):avg data time: 4.76e-03, avg batch time: 0.1901, average loss: 2.5261
[09/16 03:02:39 visual_prompt]: Classification results with test_vtab-dtd: top1: 56.81	top5: 82.45	
[09/16 03:02:39 visual_prompt]: Best epoch 26: best metric: 0.980
[09/16 03:02:39 visual_prompt]: Training 27 / 100 epoch, with learning rate 4.620120240391064
[09/16 03:02:47 visual_prompt]: Epoch 27 / 100: avg data time: 6.92e-02, avg batch time: 0.4718, average train loss: 0.1371
[09/16 03:02:49 visual_prompt]: Inference (val):avg data time: 3.46e-05, avg batch time: 0.1433, average loss: 0.1417
[09/16 03:02:49 visual_prompt]: Classification results with val_vtab-dtd: top1: 96.50	top5: 99.50	
[09/16 03:02:56 visual_prompt]: Inference (test):avg data time: 4.27e-03, avg batch time: 0.1863, average loss: 2.6289
[09/16 03:02:56 visual_prompt]: Classification results with test_vtab-dtd: top1: 54.20	top5: 82.55	
[09/16 03:02:56 visual_prompt]: Training 28 / 100 epoch, with learning rate 4.572593931387604
[09/16 03:03:04 visual_prompt]: Epoch 28 / 100: avg data time: 6.41e-02, avg batch time: 0.4677, average train loss: 0.1529
[09/16 03:03:05 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1433, average loss: 0.3408
[09/16 03:03:05 visual_prompt]: Classification results with val_vtab-dtd: top1: 92.50	top5: 99.00	
[09/16 03:03:13 visual_prompt]: Inference (test):avg data time: 3.47e-03, avg batch time: 0.1906, average loss: 2.6901
[09/16 03:03:13 visual_prompt]: Classification results with test_vtab-dtd: top1: 51.17	top5: 79.20	
[09/16 03:03:13 visual_prompt]: Training 29 / 100 epoch, with learning rate 4.522542485937368
[09/16 03:03:20 visual_prompt]: Epoch 29 / 100: avg data time: 6.73e-02, avg batch time: 0.4682, average train loss: 0.1674
[09/16 03:03:22 visual_prompt]: Inference (val):avg data time: 3.57e-05, avg batch time: 0.1433, average loss: 0.2135
[09/16 03:03:22 visual_prompt]: Classification results with val_vtab-dtd: top1: 92.00	top5: 100.00	
[09/16 03:03:29 visual_prompt]: Inference (test):avg data time: 3.84e-03, avg batch time: 0.1892, average loss: 2.7292
[09/16 03:03:29 visual_prompt]: Classification results with test_vtab-dtd: top1: 53.19	top5: 80.21	
[09/16 03:03:29 visual_prompt]: Training 30 / 100 epoch, with learning rate 4.4700268840168045
[09/16 03:03:37 visual_prompt]: Epoch 30 / 100: avg data time: 4.58e-02, avg batch time: 0.4513, average train loss: 0.1536
[09/16 03:03:39 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.1434, average loss: 0.0818
[09/16 03:03:39 visual_prompt]: Classification results with val_vtab-dtd: top1: 97.50	top5: 100.00	
[09/16 03:03:46 visual_prompt]: Inference (test):avg data time: 6.08e-03, avg batch time: 0.1902, average loss: 2.6032
[09/16 03:03:46 visual_prompt]: Classification results with test_vtab-dtd: top1: 55.48	top5: 83.19	
[09/16 03:03:46 visual_prompt]: Training 31 / 100 epoch, with learning rate 4.415111107797445
[09/16 03:03:54 visual_prompt]: Epoch 31 / 100: avg data time: 6.53e-02, avg batch time: 0.4665, average train loss: 0.0911
[09/16 03:03:55 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1434, average loss: 0.3049
[09/16 03:03:55 visual_prompt]: Classification results with val_vtab-dtd: top1: 92.50	top5: 99.50	
[09/16 03:04:02 visual_prompt]: Inference (test):avg data time: 5.81e-03, avg batch time: 0.1897, average loss: 2.7791
[09/16 03:04:02 visual_prompt]: Classification results with test_vtab-dtd: top1: 52.18	top5: 82.34	
[09/16 03:04:02 visual_prompt]: Training 32 / 100 epoch, with learning rate 4.357862063693486
[09/16 03:04:10 visual_prompt]: Epoch 32 / 100: avg data time: 5.90e-02, avg batch time: 0.4603, average train loss: 0.1127
[09/16 03:04:12 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.1434, average loss: 0.0564
[09/16 03:04:12 visual_prompt]: Classification results with val_vtab-dtd: top1: 98.50	top5: 100.00	
[09/16 03:04:19 visual_prompt]: Inference (test):avg data time: 3.07e-03, avg batch time: 0.1918, average loss: 2.4257
[09/16 03:04:19 visual_prompt]: Classification results with test_vtab-dtd: top1: 55.48	top5: 83.09	
[09/16 03:04:19 visual_prompt]: Best epoch 32: best metric: 0.985
[09/16 03:04:19 visual_prompt]: Training 33 / 100 epoch, with learning rate 4.298349500846628
[09/16 03:04:27 visual_prompt]: Epoch 33 / 100: avg data time: 5.33e-02, avg batch time: 0.4772, average train loss: 0.0768
[09/16 03:04:28 visual_prompt]: Inference (val):avg data time: 3.69e-05, avg batch time: 0.1434, average loss: 0.0474
[09/16 03:04:28 visual_prompt]: Classification results with val_vtab-dtd: top1: 98.50	top5: 100.00	
[09/16 03:04:35 visual_prompt]: Inference (test):avg data time: 2.90e-03, avg batch time: 0.1871, average loss: 2.2656
[09/16 03:04:35 visual_prompt]: Classification results with test_vtab-dtd: top1: 58.56	top5: 83.99	
[09/16 03:04:35 visual_prompt]: Training 34 / 100 epoch, with learning rate 4.236645926147493
[09/16 03:04:43 visual_prompt]: Epoch 34 / 100: avg data time: 6.35e-02, avg batch time: 0.4701, average train loss: 0.0352
[09/16 03:04:45 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1433, average loss: 0.0112
[09/16 03:04:45 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:04:52 visual_prompt]: Inference (test):avg data time: 1.59e-03, avg batch time: 0.1898, average loss: 2.1931
[09/16 03:04:52 visual_prompt]: Classification results with test_vtab-dtd: top1: 58.78	top5: 84.15	
[09/16 03:04:52 visual_prompt]: Best epoch 34: best metric: 1.000
[09/16 03:04:52 visual_prompt]: Training 35 / 100 epoch, with learning rate 4.172826515897146
[09/16 03:05:00 visual_prompt]: Epoch 35 / 100: avg data time: 6.81e-02, avg batch time: 0.4687, average train loss: 0.0277
[09/16 03:05:02 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1435, average loss: 0.0473
[09/16 03:05:02 visual_prompt]: Classification results with val_vtab-dtd: top1: 99.50	top5: 100.00	
[09/16 03:05:09 visual_prompt]: Inference (test):avg data time: 5.45e-03, avg batch time: 0.1876, average loss: 2.2730
[09/16 03:05:09 visual_prompt]: Classification results with test_vtab-dtd: top1: 57.02	top5: 84.63	
[09/16 03:05:09 visual_prompt]: Training 36 / 100 epoch, with learning rate 4.106969024216348
[09/16 03:05:17 visual_prompt]: Epoch 36 / 100: avg data time: 7.37e-02, avg batch time: 0.4754, average train loss: 0.0560
[09/16 03:05:19 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1432, average loss: 0.0735
[09/16 03:05:19 visual_prompt]: Classification results with val_vtab-dtd: top1: 98.00	top5: 100.00	
[09/16 03:05:26 visual_prompt]: Inference (test):avg data time: 5.94e-03, avg batch time: 0.1877, average loss: 2.2918
[09/16 03:05:26 visual_prompt]: Classification results with test_vtab-dtd: top1: 57.34	top5: 83.51	
[09/16 03:05:26 visual_prompt]: Training 37 / 100 epoch, with learning rate 4.039153688314146
[09/16 03:05:33 visual_prompt]: Epoch 37 / 100: avg data time: 6.10e-02, avg batch time: 0.4644, average train loss: 0.0740
[09/16 03:05:35 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1432, average loss: 0.1127
[09/16 03:05:35 visual_prompt]: Classification results with val_vtab-dtd: top1: 97.00	top5: 100.00	
[09/16 03:05:42 visual_prompt]: Inference (test):avg data time: 2.85e-03, avg batch time: 0.1854, average loss: 2.2803
[09/16 03:05:42 visual_prompt]: Classification results with test_vtab-dtd: top1: 55.96	top5: 83.88	
[09/16 03:05:42 visual_prompt]: Training 38 / 100 epoch, with learning rate 3.969463130731183
[09/16 03:05:50 visual_prompt]: Epoch 38 / 100: avg data time: 5.45e-02, avg batch time: 0.4582, average train loss: 0.0784
[09/16 03:05:51 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1434, average loss: 0.0357
[09/16 03:05:51 visual_prompt]: Classification results with val_vtab-dtd: top1: 99.50	top5: 100.00	
[09/16 03:05:58 visual_prompt]: Inference (test):avg data time: 2.83e-03, avg batch time: 0.1866, average loss: 2.1377
[09/16 03:05:58 visual_prompt]: Classification results with test_vtab-dtd: top1: 58.14	top5: 83.94	
[09/16 03:05:58 visual_prompt]: Training 39 / 100 epoch, with learning rate 3.897982258676867
[09/16 03:06:06 visual_prompt]: Epoch 39 / 100: avg data time: 7.09e-02, avg batch time: 0.4717, average train loss: 0.0517
[09/16 03:06:08 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.1436, average loss: 0.0405
[09/16 03:06:08 visual_prompt]: Classification results with val_vtab-dtd: top1: 99.00	top5: 100.00	
[09/16 03:06:16 visual_prompt]: Inference (test):avg data time: 3.98e-03, avg batch time: 0.2041, average loss: 1.8500
[09/16 03:06:16 visual_prompt]: Classification results with test_vtab-dtd: top1: 61.17	top5: 87.18	
[09/16 03:06:16 visual_prompt]: Training 40 / 100 epoch, with learning rate 3.824798160583012
[09/16 03:06:23 visual_prompt]: Epoch 40 / 100: avg data time: 6.38e-02, avg batch time: 0.4652, average train loss: 0.0425
[09/16 03:06:25 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1431, average loss: 0.0686
[09/16 03:06:25 visual_prompt]: Classification results with val_vtab-dtd: top1: 98.50	top5: 100.00	
[09/16 03:06:32 visual_prompt]: Inference (test):avg data time: 2.55e-03, avg batch time: 0.1851, average loss: 2.0898
[09/16 03:06:32 visual_prompt]: Classification results with test_vtab-dtd: top1: 58.67	top5: 84.84	
[09/16 03:06:32 visual_prompt]: Training 41 / 100 epoch, with learning rate 3.75
[09/16 03:06:40 visual_prompt]: Epoch 41 / 100: avg data time: 6.03e-02, avg batch time: 0.4625, average train loss: 0.0417
[09/16 03:06:42 visual_prompt]: Inference (val):avg data time: 1.39e-04, avg batch time: 0.2485, average loss: 0.0165
[09/16 03:06:42 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:06:49 visual_prompt]: Inference (test):avg data time: 2.56e-03, avg batch time: 0.1864, average loss: 1.8833
[09/16 03:06:49 visual_prompt]: Classification results with test_vtab-dtd: top1: 60.11	top5: 84.95	
[09/16 03:06:49 visual_prompt]: Training 42 / 100 epoch, with learning rate 3.673678906964727
[09/16 03:06:57 visual_prompt]: Epoch 42 / 100: avg data time: 6.41e-02, avg batch time: 0.4675, average train loss: 0.0884
[09/16 03:06:59 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1436, average loss: 0.0753
[09/16 03:06:59 visual_prompt]: Classification results with val_vtab-dtd: top1: 99.00	top5: 100.00	
[09/16 03:07:06 visual_prompt]: Inference (test):avg data time: 3.33e-03, avg batch time: 0.1879, average loss: 1.9039
[09/16 03:07:06 visual_prompt]: Classification results with test_vtab-dtd: top1: 59.52	top5: 84.84	
[09/16 03:07:06 visual_prompt]: Training 43 / 100 epoch, with learning rate 3.5959278669726933
[09/16 03:07:14 visual_prompt]: Epoch 43 / 100: avg data time: 5.96e-02, avg batch time: 0.4618, average train loss: 0.0511
[09/16 03:07:15 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1435, average loss: 0.0570
[09/16 03:07:15 visual_prompt]: Classification results with val_vtab-dtd: top1: 99.50	top5: 100.00	
[09/16 03:07:22 visual_prompt]: Inference (test):avg data time: 3.18e-03, avg batch time: 0.1855, average loss: 1.9155
[09/16 03:07:22 visual_prompt]: Classification results with test_vtab-dtd: top1: 59.41	top5: 84.79	
[09/16 03:07:22 visual_prompt]: Training 44 / 100 epoch, with learning rate 3.516841607689501
[09/16 03:07:30 visual_prompt]: Epoch 44 / 100: avg data time: 6.46e-02, avg batch time: 0.4673, average train loss: 0.0233
[09/16 03:07:32 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.1435, average loss: 0.0068
[09/16 03:07:32 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:07:39 visual_prompt]: Inference (test):avg data time: 3.90e-03, avg batch time: 0.1901, average loss: 1.6663
[09/16 03:07:39 visual_prompt]: Classification results with test_vtab-dtd: top1: 62.39	top5: 87.02	
[09/16 03:07:39 visual_prompt]: Training 45 / 100 epoch, with learning rate 3.4365164835397803
[09/16 03:07:47 visual_prompt]: Epoch 45 / 100: avg data time: 5.21e-02, avg batch time: 0.4900, average train loss: 0.0132
[09/16 03:07:49 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1432, average loss: 0.0061
[09/16 03:07:49 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:07:56 visual_prompt]: Inference (test):avg data time: 3.45e-03, avg batch time: 0.1908, average loss: 1.7357
[09/16 03:07:56 visual_prompt]: Classification results with test_vtab-dtd: top1: 62.29	top5: 86.86	
[09/16 03:07:56 visual_prompt]: Training 46 / 100 epoch, with learning rate 3.3550503583141724
[09/16 03:08:04 visual_prompt]: Epoch 46 / 100: avg data time: 6.36e-02, avg batch time: 0.4659, average train loss: 0.0086
[09/16 03:08:06 visual_prompt]: Inference (val):avg data time: 3.81e-05, avg batch time: 0.1439, average loss: 0.0052
[09/16 03:08:06 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:08:13 visual_prompt]: Inference (test):avg data time: 5.85e-03, avg batch time: 0.1899, average loss: 1.6743
[09/16 03:08:13 visual_prompt]: Classification results with test_vtab-dtd: top1: 63.51	top5: 86.86	
[09/16 03:08:13 visual_prompt]: Training 47 / 100 epoch, with learning rate 3.2725424859373686
[09/16 03:08:21 visual_prompt]: Epoch 47 / 100: avg data time: 5.28e-02, avg batch time: 0.4568, average train loss: 0.0067
[09/16 03:08:22 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1433, average loss: 0.0043
[09/16 03:08:22 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:08:29 visual_prompt]: Inference (test):avg data time: 4.65e-03, avg batch time: 0.1871, average loss: 1.6145
[09/16 03:08:29 visual_prompt]: Classification results with test_vtab-dtd: top1: 63.56	top5: 86.91	
[09/16 03:08:29 visual_prompt]: Training 48 / 100 epoch, with learning rate 3.1890933895424975
[09/16 03:08:37 visual_prompt]: Epoch 48 / 100: avg data time: 6.67e-02, avg batch time: 0.4688, average train loss: 0.0052
[09/16 03:08:39 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1433, average loss: 0.0042
[09/16 03:08:39 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:08:46 visual_prompt]: Inference (test):avg data time: 6.67e-03, avg batch time: 0.1885, average loss: 1.5447
[09/16 03:08:46 visual_prompt]: Classification results with test_vtab-dtd: top1: 64.68	top5: 87.39	
[09/16 03:08:46 visual_prompt]: Training 49 / 100 epoch, with learning rate 3.104804738999169
[09/16 03:08:54 visual_prompt]: Epoch 49 / 100: avg data time: 6.13e-02, avg batch time: 0.4659, average train loss: 0.0044
[09/16 03:08:56 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1432, average loss: 0.0039
[09/16 03:08:56 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:09:03 visual_prompt]: Inference (test):avg data time: 2.98e-03, avg batch time: 0.1868, average loss: 1.5013
[09/16 03:09:03 visual_prompt]: Classification results with test_vtab-dtd: top1: 65.00	top5: 88.03	
[09/16 03:09:03 visual_prompt]: Training 50 / 100 epoch, with learning rate 3.019779227044398
[09/16 03:09:10 visual_prompt]: Epoch 50 / 100: avg data time: 5.81e-02, avg batch time: 0.4612, average train loss: 0.0042
[09/16 03:09:12 visual_prompt]: Inference (val):avg data time: 3.50e-05, avg batch time: 0.1434, average loss: 0.0040
[09/16 03:09:12 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:09:19 visual_prompt]: Inference (test):avg data time: 2.36e-03, avg batch time: 0.1875, average loss: 1.4672
[09/16 03:09:19 visual_prompt]: Classification results with test_vtab-dtd: top1: 65.43	top5: 88.14	
[09/16 03:09:19 visual_prompt]: Training 51 / 100 epoch, with learning rate 2.934120444167326
[09/16 03:09:27 visual_prompt]: Epoch 51 / 100: avg data time: 6.51e-02, avg batch time: 0.4662, average train loss: 0.0045
[09/16 03:09:29 visual_prompt]: Inference (val):avg data time: 4.61e-05, avg batch time: 0.1433, average loss: 0.0042
[09/16 03:09:29 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:09:36 visual_prompt]: Inference (test):avg data time: 6.80e-03, avg batch time: 0.1903, average loss: 1.4389
[09/16 03:09:36 visual_prompt]: Classification results with test_vtab-dtd: top1: 65.53	top5: 88.62	
[09/16 03:09:36 visual_prompt]: Training 52 / 100 epoch, with learning rate 2.8479327524001636
[09/16 03:09:44 visual_prompt]: Epoch 52 / 100: avg data time: 6.76e-02, avg batch time: 0.4686, average train loss: 0.0047
[09/16 03:09:46 visual_prompt]: Inference (val):avg data time: 6.60e-05, avg batch time: 0.1520, average loss: 0.0043
[09/16 03:09:46 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:09:52 visual_prompt]: Inference (test):avg data time: 4.08e-03, avg batch time: 0.1896, average loss: 1.4162
[09/16 03:09:53 visual_prompt]: Classification results with test_vtab-dtd: top1: 65.53	top5: 88.78	
[09/16 03:09:53 visual_prompt]: Training 53 / 100 epoch, with learning rate 2.761321158169134
[09/16 03:10:01 visual_prompt]: Epoch 53 / 100: avg data time: 6.64e-02, avg batch time: 0.5030, average train loss: 0.0050
[09/16 03:10:03 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1433, average loss: 0.0044
[09/16 03:10:03 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:10:10 visual_prompt]: Inference (test):avg data time: 5.35e-03, avg batch time: 0.1859, average loss: 1.3958
[09/16 03:10:10 visual_prompt]: Classification results with test_vtab-dtd: top1: 65.90	top5: 88.56	
[09/16 03:10:10 visual_prompt]: Training 54 / 100 epoch, with learning rate 2.6743911843603128
[09/16 03:10:18 visual_prompt]: Epoch 54 / 100: avg data time: 5.51e-02, avg batch time: 0.4579, average train loss: 0.0051
[09/16 03:10:19 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1432, average loss: 0.0044
[09/16 03:10:19 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:10:26 visual_prompt]: Inference (test):avg data time: 3.30e-03, avg batch time: 0.1863, average loss: 1.3758
[09/16 03:10:26 visual_prompt]: Classification results with test_vtab-dtd: top1: 65.85	top5: 89.04	
[09/16 03:10:26 visual_prompt]: Training 55 / 100 epoch, with learning rate 2.5872487417562526
[09/16 03:10:34 visual_prompt]: Epoch 55 / 100: avg data time: 6.16e-02, avg batch time: 0.4632, average train loss: 0.0051
[09/16 03:10:36 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.1434, average loss: 0.0043
[09/16 03:10:36 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:10:43 visual_prompt]: Inference (test):avg data time: 4.62e-03, avg batch time: 0.1892, average loss: 1.3625
[09/16 03:10:43 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.33	top5: 89.15	
[09/16 03:10:43 visual_prompt]: Training 56 / 100 epoch, with learning rate 2.5
[09/16 03:10:51 visual_prompt]: Epoch 56 / 100: avg data time: 5.44e-02, avg batch time: 0.4562, average train loss: 0.0052
[09/16 03:10:52 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1434, average loss: 0.0042
[09/16 03:10:52 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:10:59 visual_prompt]: Inference (test):avg data time: 3.01e-03, avg batch time: 0.1876, average loss: 1.3527
[09/16 03:10:59 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.38	top5: 89.04	
[09/16 03:10:59 visual_prompt]: Training 57 / 100 epoch, with learning rate 2.4127512582437483
[09/16 03:11:07 visual_prompt]: Epoch 57 / 100: avg data time: 6.05e-02, avg batch time: 0.4632, average train loss: 0.0050
[09/16 03:11:09 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1434, average loss: 0.0042
[09/16 03:11:09 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:11:16 visual_prompt]: Inference (test):avg data time: 4.57e-03, avg batch time: 0.1880, average loss: 1.3433
[09/16 03:11:16 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.38	top5: 89.26	
[09/16 03:11:16 visual_prompt]: Training 58 / 100 epoch, with learning rate 2.325608815639687
[09/16 03:11:24 visual_prompt]: Epoch 58 / 100: avg data time: 6.62e-02, avg batch time: 0.4678, average train loss: 0.0051
[09/16 03:11:25 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1433, average loss: 0.0042
[09/16 03:11:25 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:11:32 visual_prompt]: Inference (test):avg data time: 5.06e-03, avg batch time: 0.1893, average loss: 1.3372
[09/16 03:11:32 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.65	top5: 89.15	
[09/16 03:11:32 visual_prompt]: Training 59 / 100 epoch, with learning rate 2.2386788418308665
[09/16 03:11:40 visual_prompt]: Epoch 59 / 100: avg data time: 6.42e-02, avg batch time: 0.4659, average train loss: 0.0050
[09/16 03:11:42 visual_prompt]: Inference (val):avg data time: 3.43e-05, avg batch time: 0.1435, average loss: 0.0040
[09/16 03:11:42 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:11:49 visual_prompt]: Inference (test):avg data time: 4.16e-03, avg batch time: 0.1899, average loss: 1.3295
[09/16 03:11:49 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.76	top5: 89.20	
[09/16 03:11:49 visual_prompt]: Training 60 / 100 epoch, with learning rate 2.1520672475998373
[09/16 03:11:57 visual_prompt]: Epoch 60 / 100: avg data time: 6.03e-02, avg batch time: 0.4616, average train loss: 0.0047
[09/16 03:11:59 visual_prompt]: Inference (val):avg data time: 4.84e-05, avg batch time: 0.1444, average loss: 0.0039
[09/16 03:11:59 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:12:06 visual_prompt]: Inference (test):avg data time: 2.64e-03, avg batch time: 0.1841, average loss: 1.3300
[09/16 03:12:06 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.86	top5: 88.88	
[09/16 03:12:06 visual_prompt]: Training 61 / 100 epoch, with learning rate 2.0658795558326744
[09/16 03:12:13 visual_prompt]: Epoch 61 / 100: avg data time: 6.22e-02, avg batch time: 0.4643, average train loss: 0.0047
[09/16 03:12:15 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1433, average loss: 0.0037
[09/16 03:12:15 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:12:22 visual_prompt]: Inference (test):avg data time: 4.66e-03, avg batch time: 0.1868, average loss: 1.3217
[09/16 03:12:22 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.91	top5: 89.10	
[09/16 03:12:22 visual_prompt]: Training 62 / 100 epoch, with learning rate 1.980220772955602
[09/16 03:12:30 visual_prompt]: Epoch 62 / 100: avg data time: 6.21e-02, avg batch time: 0.4648, average train loss: 0.0046
[09/16 03:12:32 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1434, average loss: 0.0036
[09/16 03:12:32 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:12:39 visual_prompt]: Inference (test):avg data time: 2.48e-03, avg batch time: 0.1886, average loss: 1.3262
[09/16 03:12:39 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.97	top5: 88.94	
[09/16 03:12:39 visual_prompt]: Training 63 / 100 epoch, with learning rate 1.895195261000831
[09/16 03:12:47 visual_prompt]: Epoch 63 / 100: avg data time: 6.56e-02, avg batch time: 0.4696, average train loss: 0.0044
[09/16 03:12:48 visual_prompt]: Inference (val):avg data time: 4.45e-05, avg batch time: 0.1443, average loss: 0.0035
[09/16 03:12:48 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:12:55 visual_prompt]: Inference (test):avg data time: 4.45e-03, avg batch time: 0.1879, average loss: 1.3163
[09/16 03:12:56 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.97	top5: 88.99	
[09/16 03:12:56 visual_prompt]: Training 64 / 100 epoch, with learning rate 1.8109066104575022
[09/16 03:13:03 visual_prompt]: Epoch 64 / 100: avg data time: 6.27e-02, avg batch time: 0.4648, average train loss: 0.0044
[09/16 03:13:05 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1433, average loss: 0.0033
[09/16 03:13:05 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:13:12 visual_prompt]: Inference (test):avg data time: 5.77e-03, avg batch time: 0.1904, average loss: 1.3170
[09/16 03:13:12 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.39	top5: 88.83	
[09/16 03:13:12 visual_prompt]: Training 65 / 100 epoch, with learning rate 1.7274575140626316
[09/16 03:13:20 visual_prompt]: Epoch 65 / 100: avg data time: 5.28e-02, avg batch time: 0.4582, average train loss: 0.0043
[09/16 03:13:21 visual_prompt]: Inference (val):avg data time: 3.90e-05, avg batch time: 0.1469, average loss: 0.0032
[09/16 03:13:21 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:13:28 visual_prompt]: Inference (test):avg data time: 5.21e-03, avg batch time: 0.1886, average loss: 1.3152
[09/16 03:13:28 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.86	top5: 88.94	
[09/16 03:13:28 visual_prompt]: Training 66 / 100 epoch, with learning rate 1.6449496416858285
[09/16 03:13:36 visual_prompt]: Epoch 66 / 100: avg data time: 6.72e-02, avg batch time: 0.4691, average train loss: 0.0041
[09/16 03:13:38 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1435, average loss: 0.0029
[09/16 03:13:38 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:13:45 visual_prompt]: Inference (test):avg data time: 6.01e-03, avg batch time: 0.1903, average loss: 1.3182
[09/16 03:13:45 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.34	top5: 89.10	
[09/16 03:13:45 visual_prompt]: Training 67 / 100 epoch, with learning rate 1.5634835164602199
[09/16 03:13:53 visual_prompt]: Epoch 67 / 100: avg data time: 6.18e-02, avg batch time: 0.4625, average train loss: 0.0039
[09/16 03:13:55 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.1433, average loss: 0.0028
[09/16 03:13:55 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:14:02 visual_prompt]: Inference (test):avg data time: 4.76e-03, avg batch time: 0.1884, average loss: 1.3213
[09/16 03:14:02 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.34	top5: 89.04	
[09/16 03:14:02 visual_prompt]: Training 68 / 100 epoch, with learning rate 1.4831583923104998
[09/16 03:14:09 visual_prompt]: Epoch 68 / 100: avg data time: 6.03e-02, avg batch time: 0.4634, average train loss: 0.0039
[09/16 03:14:11 visual_prompt]: Inference (val):avg data time: 3.55e-05, avg batch time: 0.1435, average loss: 0.0027
[09/16 03:14:11 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:14:18 visual_prompt]: Inference (test):avg data time: 6.12e-03, avg batch time: 0.1894, average loss: 1.3252
[09/16 03:14:18 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.54	top5: 88.56	
[09/16 03:14:18 visual_prompt]: Training 69 / 100 epoch, with learning rate 1.4040721330273063
[09/16 03:14:26 visual_prompt]: Epoch 69 / 100: avg data time: 6.56e-02, avg batch time: 0.4679, average train loss: 0.0037
[09/16 03:14:28 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1436, average loss: 0.0027
[09/16 03:14:28 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:14:35 visual_prompt]: Inference (test):avg data time: 1.82e-03, avg batch time: 0.1837, average loss: 1.3330
[09/16 03:14:35 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.81	top5: 88.88	
[09/16 03:14:35 visual_prompt]: Training 70 / 100 epoch, with learning rate 1.3263210930352738
[09/16 03:14:42 visual_prompt]: Epoch 70 / 100: avg data time: 6.87e-02, avg batch time: 0.4713, average train loss: 0.0035
[09/16 03:14:44 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1432, average loss: 0.0025
[09/16 03:14:44 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:14:51 visual_prompt]: Inference (test):avg data time: 5.30e-03, avg batch time: 0.1876, average loss: 1.3294
[09/16 03:14:51 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.76	top5: 89.10	
[09/16 03:14:51 visual_prompt]: Training 71 / 100 epoch, with learning rate 1.2500000000000004
[09/16 03:14:59 visual_prompt]: Epoch 71 / 100: avg data time: 6.36e-02, avg batch time: 0.4648, average train loss: 0.0034
[09/16 03:15:01 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1433, average loss: 0.0026
[09/16 03:15:01 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:15:08 visual_prompt]: Inference (test):avg data time: 3.55e-03, avg batch time: 0.1883, average loss: 1.3274
[09/16 03:15:08 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.13	top5: 89.15	
[09/16 03:15:08 visual_prompt]: Training 72 / 100 epoch, with learning rate 1.175201839416988
[09/16 03:15:16 visual_prompt]: Epoch 72 / 100: avg data time: 6.14e-02, avg batch time: 0.4638, average train loss: 0.0033
[09/16 03:15:17 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1431, average loss: 0.0024
[09/16 03:15:17 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:15:24 visual_prompt]: Inference (test):avg data time: 4.09e-03, avg batch time: 0.1870, average loss: 1.3400
[09/16 03:15:24 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.23	top5: 89.41	
[09/16 03:15:24 visual_prompt]: Training 73 / 100 epoch, with learning rate 1.1020177413231333
[09/16 03:15:32 visual_prompt]: Epoch 73 / 100: avg data time: 5.50e-02, avg batch time: 0.4593, average train loss: 0.0032
[09/16 03:15:34 visual_prompt]: Inference (val):avg data time: 3.32e-05, avg batch time: 0.1432, average loss: 0.0024
[09/16 03:15:34 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:15:41 visual_prompt]: Inference (test):avg data time: 6.81e-03, avg batch time: 0.1896, average loss: 1.3330
[09/16 03:15:41 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.13	top5: 89.10	
[09/16 03:15:41 visual_prompt]: Training 74 / 100 epoch, with learning rate 1.0305368692688175
[09/16 03:15:48 visual_prompt]: Epoch 74 / 100: avg data time: 5.71e-02, avg batch time: 0.4597, average train loss: 0.0032
[09/16 03:15:50 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1434, average loss: 0.0023
[09/16 03:15:50 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:15:57 visual_prompt]: Inference (test):avg data time: 5.83e-03, avg batch time: 0.1899, average loss: 1.3452
[09/16 03:15:57 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.91	top5: 89.26	
[09/16 03:15:57 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.9608463116858543
[09/16 03:16:05 visual_prompt]: Epoch 75 / 100: avg data time: 6.41e-02, avg batch time: 0.4657, average train loss: 0.0030
[09/16 03:16:07 visual_prompt]: Inference (val):avg data time: 3.48e-05, avg batch time: 0.1431, average loss: 0.0022
[09/16 03:16:07 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:16:14 visual_prompt]: Inference (test):avg data time: 3.17e-03, avg batch time: 0.1878, average loss: 1.3500
[09/16 03:16:14 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.29	top5: 88.83	
[09/16 03:16:14 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.8930309757836516
[09/16 03:16:22 visual_prompt]: Epoch 76 / 100: avg data time: 6.38e-02, avg batch time: 0.4652, average train loss: 0.0030
[09/16 03:16:23 visual_prompt]: Inference (val):avg data time: 4.24e-05, avg batch time: 0.1432, average loss: 0.0021
[09/16 03:16:23 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:16:30 visual_prompt]: Inference (test):avg data time: 5.20e-03, avg batch time: 0.1908, average loss: 1.3534
[09/16 03:16:30 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.45	top5: 88.94	
[09/16 03:16:30 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.8271734841028553
[09/16 03:16:38 visual_prompt]: Epoch 77 / 100: avg data time: 4.89e-02, avg batch time: 0.4530, average train loss: 0.0028
[09/16 03:16:40 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1435, average loss: 0.0020
[09/16 03:16:40 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:16:47 visual_prompt]: Inference (test):avg data time: 6.04e-03, avg batch time: 0.1895, average loss: 1.3617
[09/16 03:16:47 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.13	top5: 88.78	
[09/16 03:16:47 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.7633540738525066
[09/16 03:16:54 visual_prompt]: Epoch 78 / 100: avg data time: 6.17e-02, avg batch time: 0.4639, average train loss: 0.0028
[09/16 03:16:56 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1433, average loss: 0.0020
[09/16 03:16:56 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:17:03 visual_prompt]: Inference (test):avg data time: 6.43e-03, avg batch time: 0.1909, average loss: 1.3612
[09/16 03:17:03 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.91	top5: 89.04	
[09/16 03:17:03 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.7016504991533725
[09/16 03:17:11 visual_prompt]: Epoch 79 / 100: avg data time: 4.63e-02, avg batch time: 0.4538, average train loss: 0.0027
[09/16 03:17:13 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1432, average loss: 0.0019
[09/16 03:17:13 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:17:20 visual_prompt]: Inference (test):avg data time: 1.93e-03, avg batch time: 0.1843, average loss: 1.3674
[09/16 03:17:20 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.34	top5: 88.83	
[09/16 03:17:20 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.6421379363065141
[09/16 03:17:27 visual_prompt]: Epoch 80 / 100: avg data time: 5.62e-02, avg batch time: 0.4588, average train loss: 0.0026
[09/16 03:17:29 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.1434, average loss: 0.0019
[09/16 03:17:29 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:17:36 visual_prompt]: Inference (test):avg data time: 2.44e-03, avg batch time: 0.1861, average loss: 1.3657
[09/16 03:17:36 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.39	top5: 88.78	
[09/16 03:17:36 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.5848888922025552
[09/16 03:17:44 visual_prompt]: Epoch 81 / 100: avg data time: 6.23e-02, avg batch time: 0.4642, average train loss: 0.0026
[09/16 03:17:46 visual_prompt]: Inference (val):avg data time: 3.59e-05, avg batch time: 0.1434, average loss: 0.0018
[09/16 03:17:46 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:17:53 visual_prompt]: Inference (test):avg data time: 3.83e-03, avg batch time: 0.1871, average loss: 1.3755
[09/16 03:17:53 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.91	top5: 88.99	
[09/16 03:17:53 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.5299731159831953
[09/16 03:18:00 visual_prompt]: Epoch 82 / 100: avg data time: 5.84e-02, avg batch time: 0.4610, average train loss: 0.0026
[09/16 03:18:02 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1435, average loss: 0.0018
[09/16 03:18:02 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:18:09 visual_prompt]: Inference (test):avg data time: 3.84e-03, avg batch time: 0.1883, average loss: 1.3766
[09/16 03:18:09 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.34	top5: 88.99	
[09/16 03:18:09 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.47745751406263165
[09/16 03:18:17 visual_prompt]: Epoch 83 / 100: avg data time: 7.28e-02, avg batch time: 0.4750, average train loss: 0.0025
[09/16 03:18:19 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1432, average loss: 0.0017
[09/16 03:18:19 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:18:26 visual_prompt]: Inference (test):avg data time: 5.45e-03, avg batch time: 0.1888, average loss: 1.3813
[09/16 03:18:26 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.86	top5: 88.94	
[09/16 03:18:26 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.42740606861239594
[09/16 03:18:34 visual_prompt]: Epoch 84 / 100: avg data time: 6.57e-02, avg batch time: 0.4732, average train loss: 0.0024
[09/16 03:18:36 visual_prompt]: Inference (val):avg data time: 3.38e-05, avg batch time: 0.1436, average loss: 0.0018
[09/16 03:18:36 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:18:43 visual_prompt]: Inference (test):avg data time: 5.08e-03, avg batch time: 0.1874, average loss: 1.3853
[09/16 03:18:43 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.54	top5: 88.67	
[09/16 03:18:43 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.3798797596089351
[09/16 03:18:50 visual_prompt]: Epoch 85 / 100: avg data time: 5.72e-02, avg batch time: 0.4619, average train loss: 0.0024
[09/16 03:18:52 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1432, average loss: 0.0017
[09/16 03:18:52 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:18:59 visual_prompt]: Inference (test):avg data time: 4.13e-03, avg batch time: 0.1864, average loss: 1.3812
[09/16 03:18:59 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.81	top5: 88.99	
[09/16 03:18:59 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.33493649053890323
[09/16 03:19:07 visual_prompt]: Epoch 86 / 100: avg data time: 6.39e-02, avg batch time: 0.4683, average train loss: 0.0024
[09/16 03:19:09 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1434, average loss: 0.0017
[09/16 03:19:09 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:19:16 visual_prompt]: Inference (test):avg data time: 3.66e-03, avg batch time: 0.1866, average loss: 1.3865
[09/16 03:19:16 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.54	top5: 88.78	
[09/16 03:19:16 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.29263101785268253
[09/16 03:19:24 visual_prompt]: Epoch 87 / 100: avg data time: 6.94e-02, avg batch time: 0.4856, average train loss: 0.0023
[09/16 03:19:26 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1433, average loss: 0.0017
[09/16 03:19:26 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:19:32 visual_prompt]: Inference (test):avg data time: 5.70e-03, avg batch time: 0.1905, average loss: 1.3883
[09/16 03:19:32 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.54	top5: 88.78	
[09/16 03:19:32 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.25301488425208296
[09/16 03:19:40 visual_prompt]: Epoch 88 / 100: avg data time: 6.28e-02, avg batch time: 0.4663, average train loss: 0.0023
[09/16 03:19:42 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1433, average loss: 0.0017
[09/16 03:19:42 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:19:49 visual_prompt]: Inference (test):avg data time: 6.01e-03, avg batch time: 0.1903, average loss: 1.3895
[09/16 03:19:49 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.65	top5: 88.78	
[09/16 03:19:49 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.21613635589349756
[09/16 03:19:57 visual_prompt]: Epoch 89 / 100: avg data time: 5.64e-02, avg batch time: 0.4603, average train loss: 0.0023
[09/16 03:19:59 visual_prompt]: Inference (val):avg data time: 3.41e-05, avg batch time: 0.1437, average loss: 0.0017
[09/16 03:19:59 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:20:06 visual_prompt]: Inference (test):avg data time: 5.03e-03, avg batch time: 0.1883, average loss: 1.3923
[09/16 03:20:06 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.76	top5: 88.62	
[09/16 03:20:06 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.18204036358303172
[09/16 03:20:14 visual_prompt]: Epoch 90 / 100: avg data time: 6.38e-02, avg batch time: 0.4651, average train loss: 0.0023
[09/16 03:20:15 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1437, average loss: 0.0016
[09/16 03:20:15 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:20:22 visual_prompt]: Inference (test):avg data time: 4.22e-03, avg batch time: 0.1889, average loss: 1.3917
[09/16 03:20:22 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.22	top5: 88.88	
[09/16 03:20:22 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.1507684480352292
[09/16 03:20:30 visual_prompt]: Epoch 91 / 100: avg data time: 5.74e-02, avg batch time: 0.4591, average train loss: 0.0022
[09/16 03:20:32 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.1435, average loss: 0.0016
[09/16 03:20:32 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:20:39 visual_prompt]: Inference (test):avg data time: 4.13e-03, avg batch time: 0.1877, average loss: 1.3930
[09/16 03:20:39 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.44	top5: 88.83	
[09/16 03:20:39 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.12235870926211617
[09/16 03:20:47 visual_prompt]: Epoch 92 / 100: avg data time: 6.95e-02, avg batch time: 0.4715, average train loss: 0.0022
[09/16 03:20:48 visual_prompt]: Inference (val):avg data time: 3.49e-05, avg batch time: 0.1433, average loss: 0.0016
[09/16 03:20:48 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:20:56 visual_prompt]: Inference (test):avg data time: 5.34e-03, avg batch time: 0.2031, average loss: 1.3952
[09/16 03:20:56 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.54	top5: 88.83	
[09/16 03:20:56 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.09684576015420276
[09/16 03:21:04 visual_prompt]: Epoch 93 / 100: avg data time: 6.39e-02, avg batch time: 0.4642, average train loss: 0.0022
[09/16 03:21:06 visual_prompt]: Inference (val):avg data time: 1.37e-04, avg batch time: 0.2043, average loss: 0.0016
[09/16 03:21:06 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:21:13 visual_prompt]: Inference (test):avg data time: 5.47e-03, avg batch time: 0.1890, average loss: 1.3953
[09/16 03:21:13 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.44	top5: 88.78	
[09/16 03:21:13 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.07426068431000882
[09/16 03:21:21 visual_prompt]: Epoch 94 / 100: avg data time: 6.33e-02, avg batch time: 0.4761, average train loss: 0.0022
[09/16 03:21:22 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1433, average loss: 0.0016
[09/16 03:21:22 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:21:29 visual_prompt]: Inference (test):avg data time: 3.04e-03, avg batch time: 0.1850, average loss: 1.3963
[09/16 03:21:29 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.44	top5: 88.78	
[09/16 03:21:29 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.05463099816548578
[09/16 03:21:37 visual_prompt]: Epoch 95 / 100: avg data time: 6.75e-02, avg batch time: 0.4690, average train loss: 0.0022
[09/16 03:21:39 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1460, average loss: 0.0016
[09/16 03:21:39 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:21:46 visual_prompt]: Inference (test):avg data time: 3.28e-03, avg batch time: 0.1858, average loss: 1.3970
[09/16 03:21:46 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.33	top5: 88.67	
[09/16 03:21:46 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.03798061746947995
[09/16 03:21:54 visual_prompt]: Epoch 96 / 100: avg data time: 6.54e-02, avg batch time: 0.4672, average train loss: 0.0022
[09/16 03:21:56 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1434, average loss: 0.0016
[09/16 03:21:56 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:22:03 visual_prompt]: Inference (test):avg data time: 5.18e-03, avg batch time: 0.1891, average loss: 1.3972
[09/16 03:22:03 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.28	top5: 88.67	
[09/16 03:22:03 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.024329828146074095
[09/16 03:22:10 visual_prompt]: Epoch 97 / 100: avg data time: 6.28e-02, avg batch time: 0.4642, average train loss: 0.0022
[09/16 03:22:12 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1434, average loss: 0.0016
[09/16 03:22:12 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:22:19 visual_prompt]: Inference (test):avg data time: 3.99e-03, avg batch time: 0.1876, average loss: 1.3974
[09/16 03:22:19 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.49	top5: 88.67	
[09/16 03:22:19 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.013695261579316775
[09/16 03:22:27 visual_prompt]: Epoch 98 / 100: avg data time: 5.26e-02, avg batch time: 0.4967, average train loss: 0.0022
[09/16 03:22:29 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.1432, average loss: 0.0016
[09/16 03:22:29 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:22:36 visual_prompt]: Inference (test):avg data time: 4.65e-03, avg batch time: 0.1880, average loss: 1.3973
[09/16 03:22:36 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.38	top5: 88.72	
[09/16 03:22:36 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.006089874350439506
[09/16 03:22:45 visual_prompt]: Epoch 99 / 100: avg data time: 6.39e-02, avg batch time: 0.5171, average train loss: 0.0022
[09/16 03:22:46 visual_prompt]: Inference (val):avg data time: 4.44e-05, avg batch time: 0.1432, average loss: 0.0016
[09/16 03:22:46 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:22:53 visual_prompt]: Inference (test):avg data time: 4.88e-03, avg batch time: 0.1884, average loss: 1.3975
[09/16 03:22:53 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.38	top5: 88.72	
[09/16 03:22:53 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0015229324522605947
[09/16 03:23:01 visual_prompt]: Epoch 100 / 100: avg data time: 5.50e-02, avg batch time: 0.4590, average train loss: 0.0022
[09/16 03:23:03 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.1430, average loss: 0.0016
[09/16 03:23:03 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:23:10 visual_prompt]: Inference (test):avg data time: 6.73e-03, avg batch time: 0.1922, average loss: 1.3975
[09/16 03:23:10 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.38	top5: 88.72	
[09/16 03:23:40 visual_prompt]: Rank of current process: 0. World size: 1
[09/16 03:23:40 visual_prompt]: Environment info:
-------------------  ----------------------------------------------------
Python               3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              1.7.1
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  ----------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[09/16 03:23:40 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '100', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-dtd', 'DATA.NUMBER_CLASSES', '47', 'SOLVER.BASE_LR', '5.0', 'SOLVER.WEIGHT_DECAY', '0.0001', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir/seed100'], train_type='')
[09/16 03:23:40 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/16 03:23:40 visual_prompt]: Training with config:
[09/16 03:23:40 visual_prompt]: {'CUDNN_BENCHMARK': False,
 'DATA': {'BATCH_SIZE': 64,
          'CLASS_WEIGHTS_TYPE': 'none',
          'CROPSIZE': 224,
          'DATAPATH': 'visual_prompt_tuning/data_path',
          'FEATURE': 'sup_vitb16_imagenet21k',
          'MULTILABEL': False,
          'NAME': 'vtab-dtd',
          'NO_TEST': False,
          'NUMBER_CLASSES': 47,
          'NUM_WORKERS': 4,
          'PERCENTAGE': 1.0,
          'PIN_MEMORY': True},
 'DBG': False,
 'MODEL': {'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'}),
           'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}),
           'MLP_NUM': 0,
           'MODEL_ROOT': 'visual_prompt_tuning/model_root',
           'PROMPT': {'CLSEMB_FOLDER': '',
                      'CLSEMB_PATH': '',
                      'DEEP': True,
                      'DEEP_SHARED': False,
                      'DROPOUT': 0.1,
                      'FORWARD_DEEP_NOEXPAND': False,
                      'INITIATION': 'random',
                      'LOCATION': 'prepend',
                      'NUM_DEEP_LAYERS': None,
                      'NUM_TOKENS': 100,
                      'PROJECT': -1,
                      'REVERSE_DEEP': False,
                      'SAVE_FOR_EACH_EPOCH': False,
                      'VIT_POOL_TYPE': 'original'},
           'SAVE_CKPT': False,
           'TRANSFER_TYPE': 'prompt',
           'TYPE': 'vit',
           'WEIGHT_PATH': ''},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/seed100/vtab-dtd/sup_vitb16_imagenet21k/lr5.0_wd0.0001/run1',
 'RUN_N_TIMES': 1,
 'SEED': None,
 'SOLVER': {'BASE_LR': 5.0,
            'BIAS_MULTIPLIER': 1.0,
            'DBG_TRAINABLE': False,
            'LOG_EVERY_N': 100,
            'LOSS': 'softmax',
            'LOSS_ALPHA': 0.01,
            'MOMENTUM': 0.9,
            'OPTIMIZER': 'sgd',
            'PATIENCE': 300,
            'SCHEDULER': 'cosine',
            'TOTAL_EPOCH': 100,
            'WARMUP_EPOCH': 10,
            'WEIGHT_DECAY': 0.0001,
            'WEIGHT_DECAY_BIAS': 0}}
[09/16 03:23:40 visual_prompt]: Loading training data (final training data for vtab)...
2023-09-16 03:23:40.790232: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-09-16 03:23:40.957484: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-09-16 03:23:41.880343: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-16 03:23:41.880426: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-16 03:23:41.880435: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-09-16 03:23:43.934329: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-16 03:23:43.934448: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-16 03:23:43.934466: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
[09/16 03:23:43 visual_prompt]: Constructing vtab-dtd dataset trainval...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/dtd/3.0.1
[INFO: dataset_builder.py:  510]: Reusing dataset dtd (visual_prompt_tuning/data_path/dtd/3.0.1)
2023-09-16 03:23:43.960944: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset dtd for split train[:800]+validation[:200], from visual_prompt_tuning/data_path/dtd/3.0.1
[09/16 03:23:47 visual_prompt]: Number of images: 1000
[09/16 03:23:47 visual_prompt]: Number of classes: 47 / 47
[09/16 03:23:47 visual_prompt]: Loading validation data...
[09/16 03:23:47 visual_prompt]: Constructing vtab-dtd dataset val...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/dtd/3.0.1
[INFO: dataset_builder.py:  510]: Reusing dataset dtd (visual_prompt_tuning/data_path/dtd/3.0.1)
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset dtd for split validation[:200], from visual_prompt_tuning/data_path/dtd/3.0.1
[09/16 03:23:48 visual_prompt]: Number of images: 200
[09/16 03:23:48 visual_prompt]: Number of classes: 47 / 47
[09/16 03:23:48 visual_prompt]: Loading test data...
[09/16 03:23:48 visual_prompt]: Constructing vtab-dtd dataset test...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/dtd/3.0.1
[INFO: dataset_builder.py:  510]: Reusing dataset dtd (visual_prompt_tuning/data_path/dtd/3.0.1)
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset dtd for split test, from visual_prompt_tuning/data_path/dtd/3.0.1
[09/16 03:23:52 visual_prompt]: Number of images: 1880
[09/16 03:23:52 visual_prompt]: Number of classes: 47 / 47
[09/16 03:23:52 visual_prompt]: Constructing models...
[09/16 03:23:55 visual_prompt]: Total Parameters: 86756399	 Gradient Parameters: 957743
[09/16 03:23:55 visual_prompt]: tuned percent:1.104
[09/16 03:23:58 visual_prompt]: Device used for model: 0
[09/16 03:23:58 visual_prompt]: Setting up Evalutator...
[09/16 03:23:58 visual_prompt]: Setting up Trainer...
[09/16 03:23:58 visual_prompt]: 	Setting up the optimizer...
[09/16 03:23:58 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/16 03:24:07 visual_prompt]: Epoch 1 / 100: avg data time: 6.91e-02, avg batch time: 0.5449, average train loss: 3.9405
[09/16 03:24:09 visual_prompt]: Inference (val):avg data time: 5.35e-05, avg batch time: 0.1457, average loss: 3.9649
[09/16 03:24:09 visual_prompt]: Classification results with val_vtab-dtd: top1: 3.00	top5: 12.00	
[09/16 03:24:16 visual_prompt]: Inference (test):avg data time: 6.17e-03, avg batch time: 0.1866, average loss: 3.9402
[09/16 03:24:16 visual_prompt]: Classification results with test_vtab-dtd: top1: 1.91	top5: 10.11	
[09/16 03:24:16 visual_prompt]: Best epoch 1: best metric: 0.030
[09/16 03:24:16 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.5
[09/16 03:24:24 visual_prompt]: Epoch 2 / 100: avg data time: 7.15e-02, avg batch time: 0.4696, average train loss: 3.9544
[09/16 03:24:25 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.1425, average loss: 3.8486
[09/16 03:24:25 visual_prompt]: Classification results with val_vtab-dtd: top1: 3.00	top5: 15.50	
[09/16 03:24:32 visual_prompt]: Inference (test):avg data time: 5.12e-03, avg batch time: 0.1887, average loss: 3.8901
[09/16 03:24:32 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.07	top5: 11.22	
[09/16 03:24:32 visual_prompt]: Training 3 / 100 epoch, with learning rate 1.0
[09/16 03:24:40 visual_prompt]: Epoch 3 / 100: avg data time: 6.19e-02, avg batch time: 0.4625, average train loss: 3.9529
[09/16 03:24:42 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1430, average loss: 4.0657
[09/16 03:24:42 visual_prompt]: Classification results with val_vtab-dtd: top1: 1.00	top5: 11.00	
[09/16 03:24:48 visual_prompt]: Inference (test):avg data time: 2.59e-03, avg batch time: 0.1882, average loss: 4.0384
[09/16 03:24:48 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.64	
[09/16 03:24:48 visual_prompt]: Training 4 / 100 epoch, with learning rate 1.5
[09/16 03:24:56 visual_prompt]: Epoch 4 / 100: avg data time: 6.27e-02, avg batch time: 0.4653, average train loss: 4.0102
[09/16 03:24:58 visual_prompt]: Inference (val):avg data time: 2.11e-05, avg batch time: 0.1425, average loss: 4.0042
[09/16 03:24:58 visual_prompt]: Classification results with val_vtab-dtd: top1: 3.50	top5: 13.00	
[09/16 03:25:05 visual_prompt]: Inference (test):avg data time: 2.64e-03, avg batch time: 0.1866, average loss: 4.0180
[09/16 03:25:05 visual_prompt]: Classification results with test_vtab-dtd: top1: 5.11	top5: 11.86	
[09/16 03:25:05 visual_prompt]: Best epoch 4: best metric: 0.035
[09/16 03:25:05 visual_prompt]: Training 5 / 100 epoch, with learning rate 2.0
[09/16 03:25:13 visual_prompt]: Epoch 5 / 100: avg data time: 6.66e-02, avg batch time: 0.4696, average train loss: 3.9214
[09/16 03:25:14 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1428, average loss: 3.8702
[09/16 03:25:14 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.00	top5: 18.00	
[09/16 03:25:21 visual_prompt]: Inference (test):avg data time: 3.22e-03, avg batch time: 0.1863, average loss: 3.9562
[09/16 03:25:21 visual_prompt]: Classification results with test_vtab-dtd: top1: 3.56	top5: 18.19	
[09/16 03:25:21 visual_prompt]: Training 6 / 100 epoch, with learning rate 2.5
[09/16 03:25:29 visual_prompt]: Epoch 6 / 100: avg data time: 5.73e-02, avg batch time: 0.4574, average train loss: 3.9407
[09/16 03:25:31 visual_prompt]: Inference (val):avg data time: 3.68e-05, avg batch time: 0.1456, average loss: 4.0847
[09/16 03:25:31 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.50	top5: 14.50	
[09/16 03:25:38 visual_prompt]: Inference (test):avg data time: 4.77e-03, avg batch time: 0.1866, average loss: 4.0541
[09/16 03:25:38 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.93	top5: 12.93	
[09/16 03:25:38 visual_prompt]: Training 7 / 100 epoch, with learning rate 3.0
[09/16 03:25:45 visual_prompt]: Epoch 7 / 100: avg data time: 5.92e-02, avg batch time: 0.4604, average train loss: 3.9131
[09/16 03:25:47 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1430, average loss: 3.6014
[09/16 03:25:47 visual_prompt]: Classification results with val_vtab-dtd: top1: 4.50	top5: 25.50	
[09/16 03:25:54 visual_prompt]: Inference (test):avg data time: 2.60e-03, avg batch time: 0.1856, average loss: 3.7477
[09/16 03:25:54 visual_prompt]: Classification results with test_vtab-dtd: top1: 3.56	top5: 19.41	
[09/16 03:25:54 visual_prompt]: Best epoch 7: best metric: 0.045
[09/16 03:25:54 visual_prompt]: Training 8 / 100 epoch, with learning rate 3.5
[09/16 03:26:02 visual_prompt]: Epoch 8 / 100: avg data time: 6.35e-02, avg batch time: 0.4664, average train loss: 3.6709
[09/16 03:26:03 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.1432, average loss: 3.5045
[09/16 03:26:03 visual_prompt]: Classification results with val_vtab-dtd: top1: 11.00	top5: 37.00	
[09/16 03:26:10 visual_prompt]: Inference (test):avg data time: 4.01e-03, avg batch time: 0.1855, average loss: 3.6164
[09/16 03:26:10 visual_prompt]: Classification results with test_vtab-dtd: top1: 9.36	top5: 34.04	
[09/16 03:26:10 visual_prompt]: Best epoch 8: best metric: 0.110
[09/16 03:26:10 visual_prompt]: Training 9 / 100 epoch, with learning rate 4.0
[09/16 03:26:18 visual_prompt]: Epoch 9 / 100: avg data time: 5.40e-02, avg batch time: 0.4583, average train loss: 3.3051
[09/16 03:26:20 visual_prompt]: Inference (val):avg data time: 3.71e-05, avg batch time: 0.1433, average loss: 3.0215
[09/16 03:26:20 visual_prompt]: Classification results with val_vtab-dtd: top1: 19.00	top5: 55.00	
[09/16 03:26:27 visual_prompt]: Inference (test):avg data time: 4.19e-03, avg batch time: 0.1904, average loss: 3.3922
[09/16 03:26:27 visual_prompt]: Classification results with test_vtab-dtd: top1: 17.71	top5: 45.53	
[09/16 03:26:27 visual_prompt]: Best epoch 9: best metric: 0.190
[09/16 03:26:27 visual_prompt]: Training 10 / 100 epoch, with learning rate 4.5
[09/16 03:26:34 visual_prompt]: Epoch 10 / 100: avg data time: 4.70e-02, avg batch time: 0.4501, average train loss: 2.9987
[09/16 03:26:36 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1435, average loss: 2.9494
[09/16 03:26:36 visual_prompt]: Classification results with val_vtab-dtd: top1: 24.50	top5: 62.50	
[09/16 03:26:43 visual_prompt]: Inference (test):avg data time: 2.62e-03, avg batch time: 0.1866, average loss: 3.3885
[09/16 03:26:43 visual_prompt]: Classification results with test_vtab-dtd: top1: 20.80	top5: 54.20	
[09/16 03:26:43 visual_prompt]: Best epoch 10: best metric: 0.245
[09/16 03:26:43 visual_prompt]: Training 11 / 100 epoch, with learning rate 5.0
[09/16 03:26:51 visual_prompt]: Epoch 11 / 100: avg data time: 5.25e-02, avg batch time: 0.4552, average train loss: 2.3357
[09/16 03:26:52 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1434, average loss: 2.2507
[09/16 03:26:52 visual_prompt]: Classification results with val_vtab-dtd: top1: 38.50	top5: 82.00	
[09/16 03:26:59 visual_prompt]: Inference (test):avg data time: 4.00e-03, avg batch time: 0.1891, average loss: 2.9426
[09/16 03:26:59 visual_prompt]: Classification results with test_vtab-dtd: top1: 27.23	top5: 66.17	
[09/16 03:26:59 visual_prompt]: Best epoch 11: best metric: 0.385
[09/16 03:26:59 visual_prompt]: Training 12 / 100 epoch, with learning rate 4.998477067547739
[09/16 03:27:07 visual_prompt]: Epoch 12 / 100: avg data time: 5.49e-02, avg batch time: 0.4571, average train loss: 2.0274
[09/16 03:27:09 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1433, average loss: 1.6880
[09/16 03:27:09 visual_prompt]: Classification results with val_vtab-dtd: top1: 56.50	top5: 85.00	
[09/16 03:27:16 visual_prompt]: Inference (test):avg data time: 5.34e-03, avg batch time: 0.1887, average loss: 2.7531
[09/16 03:27:16 visual_prompt]: Classification results with test_vtab-dtd: top1: 36.91	top5: 69.84	
[09/16 03:27:16 visual_prompt]: Best epoch 12: best metric: 0.565
[09/16 03:27:16 visual_prompt]: Training 13 / 100 epoch, with learning rate 4.993910125649561
[09/16 03:27:23 visual_prompt]: Epoch 13 / 100: avg data time: 5.45e-02, avg batch time: 0.4580, average train loss: 1.5907
[09/16 03:27:25 visual_prompt]: Inference (val):avg data time: 3.64e-05, avg batch time: 0.1433, average loss: 1.3186
[09/16 03:27:25 visual_prompt]: Classification results with val_vtab-dtd: top1: 61.50	top5: 93.50	
[09/16 03:27:32 visual_prompt]: Inference (test):avg data time: 1.63e-03, avg batch time: 0.1871, average loss: 2.1271
[09/16 03:27:32 visual_prompt]: Classification results with test_vtab-dtd: top1: 43.99	top5: 78.30	
[09/16 03:27:32 visual_prompt]: Best epoch 13: best metric: 0.615
[09/16 03:27:32 visual_prompt]: Training 14 / 100 epoch, with learning rate 4.986304738420683
[09/16 03:27:40 visual_prompt]: Epoch 14 / 100: avg data time: 4.99e-02, avg batch time: 0.4524, average train loss: 1.1587
[09/16 03:27:41 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1434, average loss: 1.2633
[09/16 03:27:41 visual_prompt]: Classification results with val_vtab-dtd: top1: 72.00	top5: 89.00	
[09/16 03:27:48 visual_prompt]: Inference (test):avg data time: 2.51e-03, avg batch time: 0.1870, average loss: 2.3331
[09/16 03:27:48 visual_prompt]: Classification results with test_vtab-dtd: top1: 47.18	top5: 75.96	
[09/16 03:27:48 visual_prompt]: Best epoch 14: best metric: 0.720
[09/16 03:27:48 visual_prompt]: Training 15 / 100 epoch, with learning rate 4.975670171853926
[09/16 03:27:56 visual_prompt]: Epoch 15 / 100: avg data time: 4.92e-02, avg batch time: 0.4542, average train loss: 0.9001
[09/16 03:27:57 visual_prompt]: Inference (val):avg data time: 3.71e-05, avg batch time: 0.1433, average loss: 0.8741
[09/16 03:27:57 visual_prompt]: Classification results with val_vtab-dtd: top1: 77.50	top5: 96.00	
[09/16 03:28:04 visual_prompt]: Inference (test):avg data time: 3.92e-03, avg batch time: 0.1883, average loss: 2.5004
[09/16 03:28:04 visual_prompt]: Classification results with test_vtab-dtd: top1: 52.02	top5: 83.09	
[09/16 03:28:04 visual_prompt]: Best epoch 15: best metric: 0.775
[09/16 03:28:04 visual_prompt]: Training 16 / 100 epoch, with learning rate 4.962019382530521
[09/16 03:28:12 visual_prompt]: Epoch 16 / 100: avg data time: 5.55e-02, avg batch time: 0.4595, average train loss: 0.5757
[09/16 03:28:14 visual_prompt]: Inference (val):avg data time: 4.84e-05, avg batch time: 0.1447, average loss: 0.5168
[09/16 03:28:14 visual_prompt]: Classification results with val_vtab-dtd: top1: 84.00	top5: 99.00	
[09/16 03:28:21 visual_prompt]: Inference (test):avg data time: 3.21e-03, avg batch time: 0.1869, average loss: 2.3410
[09/16 03:28:21 visual_prompt]: Classification results with test_vtab-dtd: top1: 52.98	top5: 84.63	
[09/16 03:28:21 visual_prompt]: Best epoch 16: best metric: 0.840
[09/16 03:28:21 visual_prompt]: Training 17 / 100 epoch, with learning rate 4.945369001834514
[09/16 03:28:29 visual_prompt]: Epoch 17 / 100: avg data time: 6.06e-02, avg batch time: 0.4635, average train loss: 0.4234
[09/16 03:28:30 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1432, average loss: 0.3110
[09/16 03:28:30 visual_prompt]: Classification results with val_vtab-dtd: top1: 90.50	top5: 99.50	
[09/16 03:28:37 visual_prompt]: Inference (test):avg data time: 3.10e-03, avg batch time: 0.1879, average loss: 2.4210
[09/16 03:28:37 visual_prompt]: Classification results with test_vtab-dtd: top1: 54.04	top5: 82.98	
[09/16 03:28:37 visual_prompt]: Best epoch 17: best metric: 0.905
[09/16 03:28:37 visual_prompt]: Training 18 / 100 epoch, with learning rate 4.925739315689991
[09/16 03:28:45 visual_prompt]: Epoch 18 / 100: avg data time: 5.61e-02, avg batch time: 0.4596, average train loss: 0.3818
[09/16 03:28:47 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.1432, average loss: 0.3302
[09/16 03:28:47 visual_prompt]: Classification results with val_vtab-dtd: top1: 90.00	top5: 98.50	
[09/16 03:28:54 visual_prompt]: Inference (test):avg data time: 4.09e-03, avg batch time: 0.1874, average loss: 2.4652
[09/16 03:28:54 visual_prompt]: Classification results with test_vtab-dtd: top1: 52.98	top5: 81.54	
[09/16 03:28:54 visual_prompt]: Training 19 / 100 epoch, with learning rate 4.903154239845797
[09/16 03:29:02 visual_prompt]: Epoch 19 / 100: avg data time: 6.68e-02, avg batch time: 0.5009, average train loss: 0.3490
[09/16 03:29:04 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1432, average loss: 0.4229
[09/16 03:29:04 visual_prompt]: Classification results with val_vtab-dtd: top1: 88.50	top5: 98.50	
[09/16 03:29:11 visual_prompt]: Inference (test):avg data time: 2.79e-03, avg batch time: 0.1849, average loss: 2.7705
[09/16 03:29:11 visual_prompt]: Classification results with test_vtab-dtd: top1: 52.02	top5: 81.54	
[09/16 03:29:11 visual_prompt]: Training 20 / 100 epoch, with learning rate 4.877641290737884
[09/16 03:29:18 visual_prompt]: Epoch 20 / 100: avg data time: 6.02e-02, avg batch time: 0.4616, average train loss: 0.3241
[09/16 03:29:20 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1433, average loss: 0.1666
[09/16 03:29:20 visual_prompt]: Classification results with val_vtab-dtd: top1: 96.00	top5: 100.00	
[09/16 03:29:27 visual_prompt]: Inference (test):avg data time: 1.84e-03, avg batch time: 0.1867, average loss: 2.6451
[09/16 03:29:27 visual_prompt]: Classification results with test_vtab-dtd: top1: 52.93	top5: 83.88	
[09/16 03:29:27 visual_prompt]: Best epoch 20: best metric: 0.960
[09/16 03:29:27 visual_prompt]: Training 21 / 100 epoch, with learning rate 4.849231551964771
[09/16 03:29:34 visual_prompt]: Epoch 21 / 100: avg data time: 5.17e-02, avg batch time: 0.4547, average train loss: 0.1787
[09/16 03:29:36 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1436, average loss: 0.1883
[09/16 03:29:36 visual_prompt]: Classification results with val_vtab-dtd: top1: 95.50	top5: 100.00	
[09/16 03:29:43 visual_prompt]: Inference (test):avg data time: 5.05e-03, avg batch time: 0.1889, average loss: 2.7494
[09/16 03:29:43 visual_prompt]: Classification results with test_vtab-dtd: top1: 55.32	top5: 83.83	
[09/16 03:29:43 visual_prompt]: Training 22 / 100 epoch, with learning rate 4.817959636416969
[09/16 03:29:51 visual_prompt]: Epoch 22 / 100: avg data time: 6.12e-02, avg batch time: 0.4631, average train loss: 0.3108
[09/16 03:29:53 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1433, average loss: 0.2984
[09/16 03:29:53 visual_prompt]: Classification results with val_vtab-dtd: top1: 92.00	top5: 98.00	
[09/16 03:30:00 visual_prompt]: Inference (test):avg data time: 5.69e-03, avg batch time: 0.1887, average loss: 2.6541
[09/16 03:30:00 visual_prompt]: Classification results with test_vtab-dtd: top1: 52.50	top5: 79.63	
[09/16 03:30:00 visual_prompt]: Training 23 / 100 epoch, with learning rate 4.783863644106502
[09/16 03:30:07 visual_prompt]: Epoch 23 / 100: avg data time: 5.81e-02, avg batch time: 0.4604, average train loss: 0.1810
[09/16 03:30:09 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1433, average loss: 0.0472
[09/16 03:30:09 visual_prompt]: Classification results with val_vtab-dtd: top1: 99.00	top5: 100.00	
[09/16 03:30:16 visual_prompt]: Inference (test):avg data time: 5.18e-03, avg batch time: 0.1882, average loss: 2.6482
[09/16 03:30:16 visual_prompt]: Classification results with test_vtab-dtd: top1: 56.65	top5: 83.09	
[09/16 03:30:16 visual_prompt]: Best epoch 23: best metric: 0.990
[09/16 03:30:16 visual_prompt]: Training 24 / 100 epoch, with learning rate 4.7469851157479175
[09/16 03:30:24 visual_prompt]: Epoch 24 / 100: avg data time: 6.15e-02, avg batch time: 0.4667, average train loss: 0.1070
[09/16 03:30:26 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1433, average loss: 0.1460
[09/16 03:30:26 visual_prompt]: Classification results with val_vtab-dtd: top1: 96.00	top5: 99.50	
[09/16 03:30:33 visual_prompt]: Inference (test):avg data time: 6.78e-03, avg batch time: 0.1896, average loss: 2.8011
[09/16 03:30:33 visual_prompt]: Classification results with test_vtab-dtd: top1: 55.37	top5: 82.07	
[09/16 03:30:33 visual_prompt]: Training 25 / 100 epoch, with learning rate 4.707368982147317
[09/16 03:30:40 visual_prompt]: Epoch 25 / 100: avg data time: 6.10e-02, avg batch time: 0.4628, average train loss: 0.1126
[09/16 03:30:42 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1433, average loss: 0.0663
[09/16 03:30:42 visual_prompt]: Classification results with val_vtab-dtd: top1: 98.50	top5: 100.00	
[09/16 03:30:49 visual_prompt]: Inference (test):avg data time: 3.48e-03, avg batch time: 0.1889, average loss: 2.6583
[09/16 03:30:49 visual_prompt]: Classification results with test_vtab-dtd: top1: 55.69	top5: 82.98	
[09/16 03:30:49 visual_prompt]: Training 26 / 100 epoch, with learning rate 4.665063509461097
[09/16 03:30:57 visual_prompt]: Epoch 26 / 100: avg data time: 5.84e-02, avg batch time: 0.4615, average train loss: 0.0860
[09/16 03:30:58 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1436, average loss: 0.0822
[09/16 03:30:58 visual_prompt]: Classification results with val_vtab-dtd: top1: 96.50	top5: 100.00	
[09/16 03:31:05 visual_prompt]: Inference (test):avg data time: 4.01e-03, avg batch time: 0.1913, average loss: 2.5826
[09/16 03:31:05 visual_prompt]: Classification results with test_vtab-dtd: top1: 54.95	top5: 82.87	
[09/16 03:31:05 visual_prompt]: Training 27 / 100 epoch, with learning rate 4.620120240391064
[09/16 03:31:13 visual_prompt]: Epoch 27 / 100: avg data time: 6.01e-02, avg batch time: 0.4630, average train loss: 0.1001
[09/16 03:31:15 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1432, average loss: 0.2219
[09/16 03:31:15 visual_prompt]: Classification results with val_vtab-dtd: top1: 92.00	top5: 99.50	
[09/16 03:31:22 visual_prompt]: Inference (test):avg data time: 6.35e-03, avg batch time: 0.1885, average loss: 2.7033
[09/16 03:31:22 visual_prompt]: Classification results with test_vtab-dtd: top1: 54.36	top5: 80.74	
[09/16 03:31:22 visual_prompt]: Training 28 / 100 epoch, with learning rate 4.572593931387604
[09/16 03:31:29 visual_prompt]: Epoch 28 / 100: avg data time: 4.37e-02, avg batch time: 0.4494, average train loss: 0.1849
[09/16 03:31:31 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1433, average loss: 0.1274
[09/16 03:31:31 visual_prompt]: Classification results with val_vtab-dtd: top1: 95.50	top5: 100.00	
[09/16 03:31:38 visual_prompt]: Inference (test):avg data time: 2.47e-03, avg batch time: 0.1857, average loss: 2.4579
[09/16 03:31:38 visual_prompt]: Classification results with test_vtab-dtd: top1: 56.60	top5: 81.54	
[09/16 03:31:38 visual_prompt]: Training 29 / 100 epoch, with learning rate 4.522542485937368
[09/16 03:31:45 visual_prompt]: Epoch 29 / 100: avg data time: 5.82e-02, avg batch time: 0.4596, average train loss: 0.0986
[09/16 03:31:47 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1433, average loss: 0.0698
[09/16 03:31:47 visual_prompt]: Classification results with val_vtab-dtd: top1: 97.50	top5: 100.00	
[09/16 03:31:54 visual_prompt]: Inference (test):avg data time: 3.55e-03, avg batch time: 0.1883, average loss: 2.4928
[09/16 03:31:54 visual_prompt]: Classification results with test_vtab-dtd: top1: 55.43	top5: 84.10	
[09/16 03:31:54 visual_prompt]: Training 30 / 100 epoch, with learning rate 4.4700268840168045
[09/16 03:32:02 visual_prompt]: Epoch 30 / 100: avg data time: 5.81e-02, avg batch time: 0.4607, average train loss: 0.1515
[09/16 03:32:03 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1434, average loss: 0.1028
[09/16 03:32:03 visual_prompt]: Classification results with val_vtab-dtd: top1: 96.00	top5: 100.00	
[09/16 03:32:10 visual_prompt]: Inference (test):avg data time: 5.18e-03, avg batch time: 0.1880, average loss: 2.2330
[09/16 03:32:10 visual_prompt]: Classification results with test_vtab-dtd: top1: 55.48	top5: 82.13	
[09/16 03:32:10 visual_prompt]: Training 31 / 100 epoch, with learning rate 4.415111107797445
[09/16 03:32:18 visual_prompt]: Epoch 31 / 100: avg data time: 5.63e-02, avg batch time: 0.4609, average train loss: 0.1461
[09/16 03:32:20 visual_prompt]: Inference (val):avg data time: 4.08e-05, avg batch time: 0.1433, average loss: 0.1953
[09/16 03:32:20 visual_prompt]: Classification results with val_vtab-dtd: top1: 94.00	top5: 99.50	
[09/16 03:32:27 visual_prompt]: Inference (test):avg data time: 5.08e-03, avg batch time: 0.1877, average loss: 2.6307
[09/16 03:32:27 visual_prompt]: Classification results with test_vtab-dtd: top1: 53.62	top5: 81.01	
[09/16 03:32:27 visual_prompt]: Training 32 / 100 epoch, with learning rate 4.357862063693486
[09/16 03:32:35 visual_prompt]: Epoch 32 / 100: avg data time: 6.67e-02, avg batch time: 0.4715, average train loss: 0.1642
[09/16 03:32:36 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1434, average loss: 0.1093
[09/16 03:32:36 visual_prompt]: Classification results with val_vtab-dtd: top1: 97.50	top5: 100.00	
[09/16 03:32:43 visual_prompt]: Inference (test):avg data time: 3.73e-03, avg batch time: 0.1887, average loss: 2.4769
[09/16 03:32:43 visual_prompt]: Classification results with test_vtab-dtd: top1: 55.48	top5: 81.38	
[09/16 03:32:43 visual_prompt]: Training 33 / 100 epoch, with learning rate 4.298349500846628
[09/16 03:32:51 visual_prompt]: Epoch 33 / 100: avg data time: 4.51e-02, avg batch time: 0.4489, average train loss: 0.2054
[09/16 03:32:52 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1433, average loss: 0.0696
[09/16 03:32:52 visual_prompt]: Classification results with val_vtab-dtd: top1: 97.50	top5: 100.00	
[09/16 03:32:59 visual_prompt]: Inference (test):avg data time: 2.26e-03, avg batch time: 0.1896, average loss: 2.4900
[09/16 03:32:59 visual_prompt]: Classification results with test_vtab-dtd: top1: 55.74	top5: 81.38	
[09/16 03:32:59 visual_prompt]: Training 34 / 100 epoch, with learning rate 4.236645926147493
[09/16 03:33:07 visual_prompt]: Epoch 34 / 100: avg data time: 6.59e-02, avg batch time: 0.4687, average train loss: 0.1796
[09/16 03:33:09 visual_prompt]: Inference (val):avg data time: 3.71e-05, avg batch time: 0.1434, average loss: 0.2406
[09/16 03:33:09 visual_prompt]: Classification results with val_vtab-dtd: top1: 94.50	top5: 99.00	
[09/16 03:33:16 visual_prompt]: Inference (test):avg data time: 5.61e-03, avg batch time: 0.1892, average loss: 2.3100
[09/16 03:33:16 visual_prompt]: Classification results with test_vtab-dtd: top1: 55.96	top5: 83.09	
[09/16 03:33:16 visual_prompt]: Training 35 / 100 epoch, with learning rate 4.172826515897146
[09/16 03:33:23 visual_prompt]: Epoch 35 / 100: avg data time: 5.23e-02, avg batch time: 0.4557, average train loss: 0.1932
[09/16 03:33:25 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1435, average loss: 0.1553
[09/16 03:33:25 visual_prompt]: Classification results with val_vtab-dtd: top1: 94.50	top5: 100.00	
[09/16 03:33:32 visual_prompt]: Inference (test):avg data time: 4.57e-03, avg batch time: 0.1893, average loss: 2.4591
[09/16 03:33:32 visual_prompt]: Classification results with test_vtab-dtd: top1: 55.59	top5: 81.54	
[09/16 03:33:32 visual_prompt]: Training 36 / 100 epoch, with learning rate 4.106969024216348
[09/16 03:33:40 visual_prompt]: Epoch 36 / 100: avg data time: 5.99e-02, avg batch time: 0.4614, average train loss: 0.1630
[09/16 03:33:42 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1430, average loss: 0.1008
[09/16 03:33:42 visual_prompt]: Classification results with val_vtab-dtd: top1: 95.00	top5: 100.00	
[09/16 03:33:49 visual_prompt]: Inference (test):avg data time: 5.45e-03, avg batch time: 0.1897, average loss: 2.4353
[09/16 03:33:49 visual_prompt]: Classification results with test_vtab-dtd: top1: 57.02	top5: 84.57	
[09/16 03:33:49 visual_prompt]: Training 37 / 100 epoch, with learning rate 4.039153688314146
[09/16 03:33:57 visual_prompt]: Epoch 37 / 100: avg data time: 5.79e-02, avg batch time: 0.4616, average train loss: 0.1235
[09/16 03:33:58 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1433, average loss: 0.0870
[09/16 03:33:58 visual_prompt]: Classification results with val_vtab-dtd: top1: 98.50	top5: 100.00	
[09/16 03:34:05 visual_prompt]: Inference (test):avg data time: 6.29e-03, avg batch time: 0.1876, average loss: 2.2392
[09/16 03:34:05 visual_prompt]: Classification results with test_vtab-dtd: top1: 57.66	top5: 84.89	
[09/16 03:34:05 visual_prompt]: Training 38 / 100 epoch, with learning rate 3.969463130731183
[09/16 03:34:13 visual_prompt]: Epoch 38 / 100: avg data time: 5.90e-02, avg batch time: 0.4637, average train loss: 0.0638
[09/16 03:34:15 visual_prompt]: Inference (val):avg data time: 3.64e-05, avg batch time: 0.1434, average loss: 0.0680
[09/16 03:34:15 visual_prompt]: Classification results with val_vtab-dtd: top1: 97.50	top5: 100.00	
[09/16 03:34:22 visual_prompt]: Inference (test):avg data time: 1.59e-03, avg batch time: 0.1852, average loss: 2.3167
[09/16 03:34:22 visual_prompt]: Classification results with test_vtab-dtd: top1: 58.94	top5: 83.62	
[09/16 03:34:22 visual_prompt]: Training 39 / 100 epoch, with learning rate 3.897982258676867
[09/16 03:34:30 visual_prompt]: Epoch 39 / 100: avg data time: 6.23e-02, avg batch time: 0.4683, average train loss: 0.1041
[09/16 03:34:31 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1431, average loss: 0.0534
[09/16 03:34:31 visual_prompt]: Classification results with val_vtab-dtd: top1: 98.50	top5: 100.00	
[09/16 03:34:38 visual_prompt]: Inference (test):avg data time: 6.20e-03, avg batch time: 0.1913, average loss: 2.2179
[09/16 03:34:38 visual_prompt]: Classification results with test_vtab-dtd: top1: 58.40	top5: 85.48	
[09/16 03:34:38 visual_prompt]: Training 40 / 100 epoch, with learning rate 3.824798160583012
[09/16 03:34:46 visual_prompt]: Epoch 40 / 100: avg data time: 6.34e-02, avg batch time: 0.4662, average train loss: 0.1274
[09/16 03:34:48 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1432, average loss: 0.1009
[09/16 03:34:48 visual_prompt]: Classification results with val_vtab-dtd: top1: 96.50	top5: 100.00	
[09/16 03:34:55 visual_prompt]: Inference (test):avg data time: 2.90e-03, avg batch time: 0.1971, average loss: 2.3069
[09/16 03:34:55 visual_prompt]: Classification results with test_vtab-dtd: top1: 55.53	top5: 81.86	
[09/16 03:34:55 visual_prompt]: Training 41 / 100 epoch, with learning rate 3.75
[09/16 03:35:03 visual_prompt]: Epoch 41 / 100: avg data time: 6.29e-02, avg batch time: 0.4651, average train loss: 0.0519
[09/16 03:35:05 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1436, average loss: 0.0297
[09/16 03:35:05 visual_prompt]: Classification results with val_vtab-dtd: top1: 99.00	top5: 100.00	
[09/16 03:35:11 visual_prompt]: Inference (test):avg data time: 3.72e-03, avg batch time: 0.1879, average loss: 2.0093
[09/16 03:35:12 visual_prompt]: Classification results with test_vtab-dtd: top1: 61.01	top5: 85.53	
[09/16 03:35:12 visual_prompt]: Training 42 / 100 epoch, with learning rate 3.673678906964727
[09/16 03:35:19 visual_prompt]: Epoch 42 / 100: avg data time: 5.79e-02, avg batch time: 0.4606, average train loss: 0.0375
[09/16 03:35:21 visual_prompt]: Inference (val):avg data time: 3.98e-05, avg batch time: 0.1433, average loss: 0.0124
[09/16 03:35:21 visual_prompt]: Classification results with val_vtab-dtd: top1: 99.50	top5: 100.00	
[09/16 03:35:28 visual_prompt]: Inference (test):avg data time: 5.29e-03, avg batch time: 0.1894, average loss: 2.0412
[09/16 03:35:28 visual_prompt]: Classification results with test_vtab-dtd: top1: 60.69	top5: 84.73	
[09/16 03:35:28 visual_prompt]: Best epoch 42: best metric: 0.995
[09/16 03:35:28 visual_prompt]: Training 43 / 100 epoch, with learning rate 3.5959278669726933
[09/16 03:35:36 visual_prompt]: Epoch 43 / 100: avg data time: 6.00e-02, avg batch time: 0.4623, average train loss: 0.0219
[09/16 03:35:37 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.1435, average loss: 0.0134
[09/16 03:35:37 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:35:44 visual_prompt]: Inference (test):avg data time: 4.72e-03, avg batch time: 0.1878, average loss: 1.9258
[09/16 03:35:44 visual_prompt]: Classification results with test_vtab-dtd: top1: 61.49	top5: 85.96	
[09/16 03:35:44 visual_prompt]: Best epoch 43: best metric: 1.000
[09/16 03:35:44 visual_prompt]: Training 44 / 100 epoch, with learning rate 3.516841607689501
[09/16 03:35:52 visual_prompt]: Epoch 44 / 100: avg data time: 6.20e-02, avg batch time: 0.4648, average train loss: 0.0138
[09/16 03:35:54 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1434, average loss: 0.0051
[09/16 03:35:54 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:36:01 visual_prompt]: Inference (test):avg data time: 5.82e-03, avg batch time: 0.1886, average loss: 1.8404
[09/16 03:36:01 visual_prompt]: Classification results with test_vtab-dtd: top1: 61.81	top5: 86.60	
[09/16 03:36:01 visual_prompt]: Training 45 / 100 epoch, with learning rate 3.4365164835397803
[09/16 03:36:08 visual_prompt]: Epoch 45 / 100: avg data time: 4.95e-02, avg batch time: 0.4536, average train loss: 0.0055
[09/16 03:36:10 visual_prompt]: Inference (val):avg data time: 3.46e-05, avg batch time: 0.1434, average loss: 0.0037
[09/16 03:36:10 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:36:18 visual_prompt]: Inference (test):avg data time: 6.29e-03, avg batch time: 0.2093, average loss: 1.7713
[09/16 03:36:18 visual_prompt]: Classification results with test_vtab-dtd: top1: 62.66	top5: 86.33	
[09/16 03:36:18 visual_prompt]: Training 46 / 100 epoch, with learning rate 3.3550503583141724
[09/16 03:36:25 visual_prompt]: Epoch 46 / 100: avg data time: 5.82e-02, avg batch time: 0.4624, average train loss: 0.0036
[09/16 03:36:27 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1433, average loss: 0.0033
[09/16 03:36:27 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:36:34 visual_prompt]: Inference (test):avg data time: 4.14e-03, avg batch time: 0.1877, average loss: 1.6811
[09/16 03:36:34 visual_prompt]: Classification results with test_vtab-dtd: top1: 63.67	top5: 87.18	
[09/16 03:36:34 visual_prompt]: Training 47 / 100 epoch, with learning rate 3.2725424859373686
[09/16 03:36:41 visual_prompt]: Epoch 47 / 100: avg data time: 4.72e-02, avg batch time: 0.4511, average train loss: 0.0029
[09/16 03:36:43 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1437, average loss: 0.0033
[09/16 03:36:43 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:36:50 visual_prompt]: Inference (test):avg data time: 9.11e-04, avg batch time: 0.1875, average loss: 1.6265
[09/16 03:36:50 visual_prompt]: Classification results with test_vtab-dtd: top1: 63.83	top5: 87.39	
[09/16 03:36:50 visual_prompt]: Training 48 / 100 epoch, with learning rate 3.1890933895424975
[09/16 03:36:58 visual_prompt]: Epoch 48 / 100: avg data time: 6.07e-02, avg batch time: 0.4615, average train loss: 0.0032
[09/16 03:36:59 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1432, average loss: 0.0035
[09/16 03:36:59 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:37:06 visual_prompt]: Inference (test):avg data time: 2.92e-03, avg batch time: 0.1872, average loss: 1.5846
[09/16 03:37:06 visual_prompt]: Classification results with test_vtab-dtd: top1: 63.78	top5: 87.66	
[09/16 03:37:06 visual_prompt]: Training 49 / 100 epoch, with learning rate 3.104804738999169
[09/16 03:37:14 visual_prompt]: Epoch 49 / 100: avg data time: 4.59e-02, avg batch time: 0.4528, average train loss: 0.0034
[09/16 03:37:15 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1434, average loss: 0.0038
[09/16 03:37:15 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:37:22 visual_prompt]: Inference (test):avg data time: 4.78e-03, avg batch time: 0.1886, average loss: 1.5486
[09/16 03:37:22 visual_prompt]: Classification results with test_vtab-dtd: top1: 63.88	top5: 87.77	
[09/16 03:37:22 visual_prompt]: Training 50 / 100 epoch, with learning rate 3.019779227044398
[09/16 03:37:30 visual_prompt]: Epoch 50 / 100: avg data time: 6.05e-02, avg batch time: 0.4631, average train loss: 0.0038
[09/16 03:37:32 visual_prompt]: Inference (val):avg data time: 3.23e-05, avg batch time: 0.1433, average loss: 0.0040
[09/16 03:37:32 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:37:39 visual_prompt]: Inference (test):avg data time: 5.42e-03, avg batch time: 0.1892, average loss: 1.5135
[09/16 03:37:39 visual_prompt]: Classification results with test_vtab-dtd: top1: 64.41	top5: 88.03	
[09/16 03:37:39 visual_prompt]: Training 51 / 100 epoch, with learning rate 2.934120444167326
[09/16 03:37:47 visual_prompt]: Epoch 51 / 100: avg data time: 6.68e-02, avg batch time: 0.4683, average train loss: 0.0043
[09/16 03:37:48 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1432, average loss: 0.0044
[09/16 03:37:48 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:37:55 visual_prompt]: Inference (test):avg data time: 5.73e-03, avg batch time: 0.1871, average loss: 1.4802
[09/16 03:37:55 visual_prompt]: Classification results with test_vtab-dtd: top1: 64.63	top5: 88.24	
[09/16 03:37:55 visual_prompt]: Training 52 / 100 epoch, with learning rate 2.8479327524001636
[09/16 03:38:03 visual_prompt]: Epoch 52 / 100: avg data time: 6.64e-02, avg batch time: 0.4690, average train loss: 0.0045
[09/16 03:38:05 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1434, average loss: 0.0044
[09/16 03:38:05 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:38:12 visual_prompt]: Inference (test):avg data time: 4.78e-03, avg batch time: 0.1868, average loss: 1.4526
[09/16 03:38:12 visual_prompt]: Classification results with test_vtab-dtd: top1: 65.21	top5: 88.51	
[09/16 03:38:12 visual_prompt]: Training 53 / 100 epoch, with learning rate 2.761321158169134
[09/16 03:38:19 visual_prompt]: Epoch 53 / 100: avg data time: 6.01e-02, avg batch time: 0.4610, average train loss: 0.0046
[09/16 03:38:21 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1434, average loss: 0.0046
[09/16 03:38:21 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:38:28 visual_prompt]: Inference (test):avg data time: 4.57e-03, avg batch time: 0.1903, average loss: 1.4261
[09/16 03:38:28 visual_prompt]: Classification results with test_vtab-dtd: top1: 65.80	top5: 88.46	
[09/16 03:38:28 visual_prompt]: Training 54 / 100 epoch, with learning rate 2.6743911843603128
[09/16 03:38:36 visual_prompt]: Epoch 54 / 100: avg data time: 6.40e-02, avg batch time: 0.4662, average train loss: 0.0049
[09/16 03:38:38 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1433, average loss: 0.0048
[09/16 03:38:38 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:38:45 visual_prompt]: Inference (test):avg data time: 4.10e-03, avg batch time: 0.1883, average loss: 1.4062
[09/16 03:38:45 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.38	top5: 88.40	
[09/16 03:38:45 visual_prompt]: Training 55 / 100 epoch, with learning rate 2.5872487417562526
[09/16 03:38:52 visual_prompt]: Epoch 55 / 100: avg data time: 6.89e-02, avg batch time: 0.4699, average train loss: 0.0051
[09/16 03:38:54 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1432, average loss: 0.0050
[09/16 03:38:54 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:39:02 visual_prompt]: Inference (test):avg data time: 5.24e-03, avg batch time: 0.2015, average loss: 1.3862
[09/16 03:39:02 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.60	top5: 89.04	
[09/16 03:39:02 visual_prompt]: Training 56 / 100 epoch, with learning rate 2.5
[09/16 03:39:09 visual_prompt]: Epoch 56 / 100: avg data time: 6.33e-02, avg batch time: 0.4663, average train loss: 0.0053
[09/16 03:39:11 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1432, average loss: 0.0048
[09/16 03:39:11 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:39:18 visual_prompt]: Inference (test):avg data time: 4.57e-03, avg batch time: 0.1892, average loss: 1.3679
[09/16 03:39:18 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.76	top5: 89.20	
[09/16 03:39:18 visual_prompt]: Training 57 / 100 epoch, with learning rate 2.4127512582437483
[09/16 03:39:26 visual_prompt]: Epoch 57 / 100: avg data time: 6.47e-02, avg batch time: 0.4978, average train loss: 0.0053
[09/16 03:39:28 visual_prompt]: Inference (val):avg data time: 3.58e-05, avg batch time: 0.1434, average loss: 0.0047
[09/16 03:39:28 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:39:35 visual_prompt]: Inference (test):avg data time: 6.90e-03, avg batch time: 0.1884, average loss: 1.3474
[09/16 03:39:35 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.76	top5: 89.36	
[09/16 03:39:35 visual_prompt]: Training 58 / 100 epoch, with learning rate 2.325608815639687
[09/16 03:39:43 visual_prompt]: Epoch 58 / 100: avg data time: 6.06e-02, avg batch time: 0.4622, average train loss: 0.0054
[09/16 03:39:44 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1434, average loss: 0.0047
[09/16 03:39:44 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:39:51 visual_prompt]: Inference (test):avg data time: 5.87e-03, avg batch time: 0.1898, average loss: 1.3403
[09/16 03:39:51 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.34	top5: 89.47	
[09/16 03:39:51 visual_prompt]: Training 59 / 100 epoch, with learning rate 2.2386788418308665
[09/16 03:39:59 visual_prompt]: Epoch 59 / 100: avg data time: 5.92e-02, avg batch time: 0.4630, average train loss: 0.0054
[09/16 03:40:01 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1432, average loss: 0.0045
[09/16 03:40:01 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:40:08 visual_prompt]: Inference (test):avg data time: 6.16e-03, avg batch time: 0.1883, average loss: 1.3235
[09/16 03:40:08 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.07	top5: 89.57	
[09/16 03:40:08 visual_prompt]: Training 60 / 100 epoch, with learning rate 2.1520672475998373
[09/16 03:40:15 visual_prompt]: Epoch 60 / 100: avg data time: 6.04e-02, avg batch time: 0.4613, average train loss: 0.0052
[09/16 03:40:17 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1482, average loss: 0.0044
[09/16 03:40:17 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:40:24 visual_prompt]: Inference (test):avg data time: 2.91e-03, avg batch time: 0.1873, average loss: 1.3168
[09/16 03:40:24 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.13	top5: 89.73	
[09/16 03:40:24 visual_prompt]: Training 61 / 100 epoch, with learning rate 2.0658795558326744
[09/16 03:40:32 visual_prompt]: Epoch 61 / 100: avg data time: 6.09e-02, avg batch time: 0.4620, average train loss: 0.0053
[09/16 03:40:33 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1433, average loss: 0.0046
[09/16 03:40:33 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:40:40 visual_prompt]: Inference (test):avg data time: 6.26e-03, avg batch time: 0.1875, average loss: 1.3082
[09/16 03:40:40 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.02	top5: 89.57	
[09/16 03:40:40 visual_prompt]: Training 62 / 100 epoch, with learning rate 1.980220772955602
[09/16 03:40:48 visual_prompt]: Epoch 62 / 100: avg data time: 5.26e-02, avg batch time: 0.4550, average train loss: 0.0051
[09/16 03:40:50 visual_prompt]: Inference (val):avg data time: 5.01e-04, avg batch time: 0.2691, average loss: 0.0041
[09/16 03:40:50 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:40:57 visual_prompt]: Inference (test):avg data time: 4.61e-03, avg batch time: 0.1877, average loss: 1.3013
[09/16 03:40:57 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.82	top5: 89.89	
[09/16 03:40:57 visual_prompt]: Training 63 / 100 epoch, with learning rate 1.895195261000831
[09/16 03:41:05 visual_prompt]: Epoch 63 / 100: avg data time: 5.95e-02, avg batch time: 0.4614, average train loss: 0.0050
[09/16 03:41:06 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.1432, average loss: 0.0040
[09/16 03:41:06 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:41:13 visual_prompt]: Inference (test):avg data time: 2.82e-03, avg batch time: 0.1882, average loss: 1.2979
[09/16 03:41:13 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.39	top5: 89.95	
[09/16 03:41:13 visual_prompt]: Training 64 / 100 epoch, with learning rate 1.8109066104575022
[09/16 03:41:21 visual_prompt]: Epoch 64 / 100: avg data time: 6.38e-02, avg batch time: 0.4670, average train loss: 0.0050
[09/16 03:41:23 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1436, average loss: 0.0040
[09/16 03:41:23 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:41:30 visual_prompt]: Inference (test):avg data time: 4.22e-03, avg batch time: 0.1876, average loss: 1.2926
[09/16 03:41:30 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.50	top5: 89.89	
[09/16 03:41:30 visual_prompt]: Training 65 / 100 epoch, with learning rate 1.7274575140626316
[09/16 03:41:37 visual_prompt]: Epoch 65 / 100: avg data time: 5.50e-02, avg batch time: 0.4579, average train loss: 0.0049
[09/16 03:41:39 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1433, average loss: 0.0039
[09/16 03:41:39 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:41:46 visual_prompt]: Inference (test):avg data time: 2.93e-03, avg batch time: 0.1858, average loss: 1.2921
[09/16 03:41:46 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.34	top5: 89.95	
[09/16 03:41:46 visual_prompt]: Training 66 / 100 epoch, with learning rate 1.6449496416858285
[09/16 03:41:54 visual_prompt]: Epoch 66 / 100: avg data time: 5.35e-02, avg batch time: 0.4562, average train loss: 0.0048
[09/16 03:41:55 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1436, average loss: 0.0037
[09/16 03:41:55 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:42:02 visual_prompt]: Inference (test):avg data time: 2.54e-03, avg batch time: 0.1888, average loss: 1.2846
[09/16 03:42:02 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.02	top5: 90.11	
[09/16 03:42:02 visual_prompt]: Training 67 / 100 epoch, with learning rate 1.5634835164602199
[09/16 03:42:10 visual_prompt]: Epoch 67 / 100: avg data time: 6.26e-02, avg batch time: 0.4647, average train loss: 0.0046
[09/16 03:42:12 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1432, average loss: 0.0035
[09/16 03:42:12 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:42:19 visual_prompt]: Inference (test):avg data time: 3.44e-03, avg batch time: 0.1868, average loss: 1.2849
[09/16 03:42:19 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.39	top5: 90.27	
[09/16 03:42:19 visual_prompt]: Training 68 / 100 epoch, with learning rate 1.4831583923104998
[09/16 03:42:26 visual_prompt]: Epoch 68 / 100: avg data time: 5.73e-02, avg batch time: 0.4615, average train loss: 0.0045
[09/16 03:42:28 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1434, average loss: 0.0034
[09/16 03:42:28 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:42:35 visual_prompt]: Inference (test):avg data time: 1.42e-03, avg batch time: 0.1872, average loss: 1.2835
[09/16 03:42:35 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.07	top5: 89.95	
[09/16 03:42:35 visual_prompt]: Training 69 / 100 epoch, with learning rate 1.4040721330273063
[09/16 03:42:42 visual_prompt]: Epoch 69 / 100: avg data time: 5.63e-02, avg batch time: 0.4605, average train loss: 0.0043
[09/16 03:42:44 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1432, average loss: 0.0033
[09/16 03:42:44 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:42:51 visual_prompt]: Inference (test):avg data time: 2.20e-03, avg batch time: 0.1861, average loss: 1.2739
[09/16 03:42:51 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.50	top5: 90.05	
[09/16 03:42:51 visual_prompt]: Training 70 / 100 epoch, with learning rate 1.3263210930352738
[09/16 03:42:59 visual_prompt]: Epoch 70 / 100: avg data time: 6.51e-02, avg batch time: 0.4681, average train loss: 0.0043
[09/16 03:43:01 visual_prompt]: Inference (val):avg data time: 3.74e-05, avg batch time: 0.1434, average loss: 0.0032
[09/16 03:43:01 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:43:07 visual_prompt]: Inference (test):avg data time: 6.16e-03, avg batch time: 0.1884, average loss: 1.2725
[09/16 03:43:07 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.71	top5: 89.95	
[09/16 03:43:07 visual_prompt]: Training 71 / 100 epoch, with learning rate 1.2500000000000004
[09/16 03:43:15 visual_prompt]: Epoch 71 / 100: avg data time: 5.90e-02, avg batch time: 0.4612, average train loss: 0.0041
[09/16 03:43:17 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1431, average loss: 0.0031
[09/16 03:43:17 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:43:24 visual_prompt]: Inference (test):avg data time: 3.38e-03, avg batch time: 0.1875, average loss: 1.2779
[09/16 03:43:24 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.07	top5: 90.16	
[09/16 03:43:24 visual_prompt]: Training 72 / 100 epoch, with learning rate 1.175201839416988
[09/16 03:43:31 visual_prompt]: Epoch 72 / 100: avg data time: 5.07e-02, avg batch time: 0.4542, average train loss: 0.0040
[09/16 03:43:33 visual_prompt]: Inference (val):avg data time: 3.58e-05, avg batch time: 0.1434, average loss: 0.0030
[09/16 03:43:33 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:43:40 visual_prompt]: Inference (test):avg data time: 4.99e-03, avg batch time: 0.1870, average loss: 1.2812
[09/16 03:43:40 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.66	top5: 90.27	
[09/16 03:43:40 visual_prompt]: Training 73 / 100 epoch, with learning rate 1.1020177413231333
[09/16 03:43:48 visual_prompt]: Epoch 73 / 100: avg data time: 4.58e-02, avg batch time: 0.4769, average train loss: 0.0038
[09/16 03:43:50 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1435, average loss: 0.0029
[09/16 03:43:50 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:43:57 visual_prompt]: Inference (test):avg data time: 4.70e-03, avg batch time: 0.1880, average loss: 1.2811
[09/16 03:43:57 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.45	top5: 90.32	
[09/16 03:43:57 visual_prompt]: Training 74 / 100 epoch, with learning rate 1.0305368692688175
[09/16 03:44:05 visual_prompt]: Epoch 74 / 100: avg data time: 6.77e-02, avg batch time: 0.4690, average train loss: 0.0038
[09/16 03:44:06 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.1434, average loss: 0.0028
[09/16 03:44:06 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:44:13 visual_prompt]: Inference (test):avg data time: 3.12e-03, avg batch time: 0.1862, average loss: 1.2839
[09/16 03:44:13 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.34	top5: 90.37	
[09/16 03:44:13 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.9608463116858543
[09/16 03:44:21 visual_prompt]: Epoch 75 / 100: avg data time: 6.49e-02, avg batch time: 0.4662, average train loss: 0.0037
[09/16 03:44:23 visual_prompt]: Inference (val):avg data time: 4.14e-05, avg batch time: 0.1433, average loss: 0.0028
[09/16 03:44:23 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:44:29 visual_prompt]: Inference (test):avg data time: 3.77e-03, avg batch time: 0.1880, average loss: 1.2900
[09/16 03:44:29 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.34	top5: 90.16	
[09/16 03:44:29 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.8930309757836516
[09/16 03:44:37 visual_prompt]: Epoch 76 / 100: avg data time: 5.21e-02, avg batch time: 0.4553, average train loss: 0.0036
[09/16 03:44:39 visual_prompt]: Inference (val):avg data time: 3.90e-05, avg batch time: 0.1432, average loss: 0.0027
[09/16 03:44:39 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:44:46 visual_prompt]: Inference (test):avg data time: 6.09e-03, avg batch time: 0.1988, average loss: 1.2918
[09/16 03:44:46 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.18	top5: 90.27	
[09/16 03:44:46 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.8271734841028553
[09/16 03:44:54 visual_prompt]: Epoch 77 / 100: avg data time: 6.18e-02, avg batch time: 0.4643, average train loss: 0.0036
[09/16 03:44:55 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1435, average loss: 0.0026
[09/16 03:44:55 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:45:02 visual_prompt]: Inference (test):avg data time: 1.99e-03, avg batch time: 0.1855, average loss: 1.2959
[09/16 03:45:02 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.29	top5: 90.32	
[09/16 03:45:02 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.7633540738525066
[09/16 03:45:10 visual_prompt]: Epoch 78 / 100: avg data time: 6.30e-02, avg batch time: 0.4662, average train loss: 0.0035
[09/16 03:45:12 visual_prompt]: Inference (val):avg data time: 4.89e-05, avg batch time: 0.1433, average loss: 0.0026
[09/16 03:45:12 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:45:19 visual_prompt]: Inference (test):avg data time: 6.90e-03, avg batch time: 0.1896, average loss: 1.2948
[09/16 03:45:19 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.39	top5: 90.37	
[09/16 03:45:19 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.7016504991533725
[09/16 03:45:27 visual_prompt]: Epoch 79 / 100: avg data time: 5.90e-02, avg batch time: 0.4616, average train loss: 0.0034
[09/16 03:45:29 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.1469, average loss: 0.0025
[09/16 03:45:29 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:45:36 visual_prompt]: Inference (test):avg data time: 3.61e-03, avg batch time: 0.1868, average loss: 1.2942
[09/16 03:45:36 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.07	top5: 90.43	
[09/16 03:45:36 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.6421379363065141
[09/16 03:45:43 visual_prompt]: Epoch 80 / 100: avg data time: 6.21e-02, avg batch time: 0.4676, average train loss: 0.0033
[09/16 03:45:45 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1433, average loss: 0.0025
[09/16 03:45:45 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:45:52 visual_prompt]: Inference (test):avg data time: 9.83e-04, avg batch time: 0.1847, average loss: 1.2992
[09/16 03:45:52 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.29	top5: 90.21	
[09/16 03:45:52 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.5848888922025552
[09/16 03:46:00 visual_prompt]: Epoch 81 / 100: avg data time: 6.34e-02, avg batch time: 0.4649, average train loss: 0.0032
[09/16 03:46:01 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.1436, average loss: 0.0025
[09/16 03:46:01 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:46:08 visual_prompt]: Inference (test):avg data time: 4.57e-03, avg batch time: 0.1878, average loss: 1.2970
[09/16 03:46:08 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.66	top5: 90.53	
[09/16 03:46:08 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.5299731159831953
[09/16 03:46:16 visual_prompt]: Epoch 82 / 100: avg data time: 6.38e-02, avg batch time: 0.4656, average train loss: 0.0032
[09/16 03:46:18 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.1432, average loss: 0.0023
[09/16 03:46:18 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:46:25 visual_prompt]: Inference (test):avg data time: 1.47e-03, avg batch time: 0.1850, average loss: 1.2992
[09/16 03:46:25 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.07	top5: 90.37	
[09/16 03:46:25 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.47745751406263165
[09/16 03:46:33 visual_prompt]: Epoch 83 / 100: avg data time: 6.69e-02, avg batch time: 0.4728, average train loss: 0.0032
[09/16 03:46:34 visual_prompt]: Inference (val):avg data time: 3.76e-05, avg batch time: 0.1434, average loss: 0.0024
[09/16 03:46:34 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:46:41 visual_prompt]: Inference (test):avg data time: 3.95e-03, avg batch time: 0.1904, average loss: 1.2990
[09/16 03:46:41 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.23	top5: 90.43	
[09/16 03:46:41 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.42740606861239594
[09/16 03:46:49 visual_prompt]: Epoch 84 / 100: avg data time: 4.49e-02, avg batch time: 0.4486, average train loss: 0.0031
[09/16 03:46:50 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1433, average loss: 0.0022
[09/16 03:46:51 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:46:57 visual_prompt]: Inference (test):avg data time: 4.54e-03, avg batch time: 0.1879, average loss: 1.3043
[09/16 03:46:57 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.66	top5: 90.59	
[09/16 03:46:57 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.3798797596089351
[09/16 03:47:05 visual_prompt]: Epoch 85 / 100: avg data time: 5.83e-02, avg batch time: 0.4632, average train loss: 0.0030
[09/16 03:47:07 visual_prompt]: Inference (val):avg data time: 3.49e-05, avg batch time: 0.1432, average loss: 0.0023
[09/16 03:47:07 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:47:14 visual_prompt]: Inference (test):avg data time: 3.99e-03, avg batch time: 0.1872, average loss: 1.3039
[09/16 03:47:14 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.07	top5: 90.48	
[09/16 03:47:14 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.33493649053890323
[09/16 03:47:22 visual_prompt]: Epoch 86 / 100: avg data time: 6.86e-02, avg batch time: 0.4717, average train loss: 0.0030
[09/16 03:47:23 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1430, average loss: 0.0022
[09/16 03:47:23 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:47:31 visual_prompt]: Inference (test):avg data time: 1.95e-03, avg batch time: 0.1905, average loss: 1.3053
[09/16 03:47:31 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.55	top5: 90.37	
[09/16 03:47:31 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.29263101785268253
[09/16 03:47:38 visual_prompt]: Epoch 87 / 100: avg data time: 5.29e-02, avg batch time: 0.4604, average train loss: 0.0030
[09/16 03:47:40 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.1434, average loss: 0.0022
[09/16 03:47:40 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:47:47 visual_prompt]: Inference (test):avg data time: 3.52e-03, avg batch time: 0.1868, average loss: 1.3051
[09/16 03:47:47 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.45	top5: 90.27	
[09/16 03:47:47 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.25301488425208296
[09/16 03:47:55 visual_prompt]: Epoch 88 / 100: avg data time: 6.01e-02, avg batch time: 0.4624, average train loss: 0.0030
[09/16 03:47:56 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1433, average loss: 0.0021
[09/16 03:47:56 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:48:03 visual_prompt]: Inference (test):avg data time: 4.91e-03, avg batch time: 0.1871, average loss: 1.3060
[09/16 03:48:03 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.18	top5: 90.43	
[09/16 03:48:03 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.21613635589349756
[09/16 03:48:11 visual_prompt]: Epoch 89 / 100: avg data time: 6.83e-02, avg batch time: 0.4706, average train loss: 0.0029
[09/16 03:48:13 visual_prompt]: Inference (val):avg data time: 3.46e-05, avg batch time: 0.1433, average loss: 0.0021
[09/16 03:48:13 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:48:20 visual_prompt]: Inference (test):avg data time: 5.33e-03, avg batch time: 0.1906, average loss: 1.3054
[09/16 03:48:20 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.55	top5: 90.32	
[09/16 03:48:20 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.18204036358303172
[09/16 03:48:28 visual_prompt]: Epoch 90 / 100: avg data time: 6.84e-02, avg batch time: 0.4687, average train loss: 0.0029
[09/16 03:48:29 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1432, average loss: 0.0021
[09/16 03:48:29 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:48:36 visual_prompt]: Inference (test):avg data time: 5.43e-03, avg batch time: 0.1874, average loss: 1.3054
[09/16 03:48:36 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.34	top5: 90.37	
[09/16 03:48:36 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.1507684480352292
[09/16 03:48:44 visual_prompt]: Epoch 91 / 100: avg data time: 5.26e-02, avg batch time: 0.4542, average train loss: 0.0029
[09/16 03:48:46 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1434, average loss: 0.0021
[09/16 03:48:46 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:48:53 visual_prompt]: Inference (test):avg data time: 4.21e-03, avg batch time: 0.1883, average loss: 1.3099
[09/16 03:48:53 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.07	top5: 90.32	
[09/16 03:48:53 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.12235870926211617
[09/16 03:49:01 visual_prompt]: Epoch 92 / 100: avg data time: 6.71e-02, avg batch time: 0.4690, average train loss: 0.0029
[09/16 03:49:02 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1432, average loss: 0.0021
[09/16 03:49:02 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:49:09 visual_prompt]: Inference (test):avg data time: 4.06e-03, avg batch time: 0.1902, average loss: 1.3114
[09/16 03:49:09 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.13	top5: 90.27	
[09/16 03:49:09 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.09684576015420276
[09/16 03:49:17 visual_prompt]: Epoch 93 / 100: avg data time: 6.38e-02, avg batch time: 0.4659, average train loss: 0.0029
[09/16 03:49:18 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1431, average loss: 0.0021
[09/16 03:49:18 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:49:25 visual_prompt]: Inference (test):avg data time: 4.75e-03, avg batch time: 0.1915, average loss: 1.3123
[09/16 03:49:25 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.07	top5: 90.48	
[09/16 03:49:25 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.07426068431000882
[09/16 03:49:33 visual_prompt]: Epoch 94 / 100: avg data time: 6.14e-02, avg batch time: 0.4635, average train loss: 0.0028
[09/16 03:49:35 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1432, average loss: 0.0021
[09/16 03:49:35 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:49:42 visual_prompt]: Inference (test):avg data time: 7.92e-03, avg batch time: 0.1901, average loss: 1.3128
[09/16 03:49:42 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.91	top5: 90.43	
[09/16 03:49:42 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.05463099816548578
[09/16 03:49:50 visual_prompt]: Epoch 95 / 100: avg data time: 6.56e-02, avg batch time: 0.4671, average train loss: 0.0029
[09/16 03:49:51 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1433, average loss: 0.0021
[09/16 03:49:51 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:49:58 visual_prompt]: Inference (test):avg data time: 3.97e-03, avg batch time: 0.1888, average loss: 1.3119
[09/16 03:49:58 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.02	top5: 90.37	
[09/16 03:49:58 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.03798061746947995
[09/16 03:50:06 visual_prompt]: Epoch 96 / 100: avg data time: 5.87e-02, avg batch time: 0.4609, average train loss: 0.0028
[09/16 03:50:08 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1432, average loss: 0.0021
[09/16 03:50:08 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:50:15 visual_prompt]: Inference (test):avg data time: 2.96e-03, avg batch time: 0.1870, average loss: 1.3117
[09/16 03:50:15 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.02	top5: 90.32	
[09/16 03:50:15 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.024329828146074095
[09/16 03:50:22 visual_prompt]: Epoch 97 / 100: avg data time: 6.35e-02, avg batch time: 0.4659, average train loss: 0.0028
[09/16 03:50:24 visual_prompt]: Inference (val):avg data time: 3.57e-05, avg batch time: 0.1434, average loss: 0.0021
[09/16 03:50:24 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:50:31 visual_prompt]: Inference (test):avg data time: 3.56e-03, avg batch time: 0.1873, average loss: 1.3124
[09/16 03:50:31 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.23	top5: 90.27	
[09/16 03:50:31 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.013695261579316775
[09/16 03:50:39 visual_prompt]: Epoch 98 / 100: avg data time: 5.06e-02, avg batch time: 0.4568, average train loss: 0.0028
[09/16 03:50:41 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1433, average loss: 0.0021
[09/16 03:50:41 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:50:47 visual_prompt]: Inference (test):avg data time: 2.75e-03, avg batch time: 0.1862, average loss: 1.3126
[09/16 03:50:47 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.07	top5: 90.27	
[09/16 03:50:47 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.006089874350439506
[09/16 03:50:55 visual_prompt]: Epoch 99 / 100: avg data time: 5.22e-02, avg batch time: 0.4561, average train loss: 0.0028
[09/16 03:50:57 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1433, average loss: 0.0021
[09/16 03:50:57 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:51:04 visual_prompt]: Inference (test):avg data time: 2.30e-03, avg batch time: 0.1858, average loss: 1.3127
[09/16 03:51:04 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.02	top5: 90.27	
[09/16 03:51:04 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0015229324522605947
[09/16 03:51:11 visual_prompt]: Epoch 100 / 100: avg data time: 6.49e-02, avg batch time: 0.4669, average train loss: 0.0028
[09/16 03:51:13 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1430, average loss: 0.0021
[09/16 03:51:13 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 03:51:20 visual_prompt]: Inference (test):avg data time: 4.72e-03, avg batch time: 0.1887, average loss: 1.3127
[09/16 03:51:20 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.02	top5: 90.27	
[09/16 03:51:29 visual_prompt]: Rank of current process: 0. World size: 1
[09/16 03:51:29 visual_prompt]: Environment info:
-------------------  ----------------------------------------------------
Python               3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              1.7.1
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  ----------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[09/16 03:51:29 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '100', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-dtd', 'DATA.NUMBER_CLASSES', '47', 'SOLVER.BASE_LR', '5.0', 'SOLVER.WEIGHT_DECAY', '0.0001', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir/seed800'], train_type='')
[09/16 03:51:29 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/16 03:51:29 visual_prompt]: Training with config:
[09/16 03:51:29 visual_prompt]: {'CUDNN_BENCHMARK': False,
 'DATA': {'BATCH_SIZE': 64,
          'CLASS_WEIGHTS_TYPE': 'none',
          'CROPSIZE': 224,
          'DATAPATH': 'visual_prompt_tuning/data_path',
          'FEATURE': 'sup_vitb16_imagenet21k',
          'MULTILABEL': False,
          'NAME': 'vtab-dtd',
          'NO_TEST': False,
          'NUMBER_CLASSES': 47,
          'NUM_WORKERS': 4,
          'PERCENTAGE': 1.0,
          'PIN_MEMORY': True},
 'DBG': False,
 'MODEL': {'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'}),
           'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}),
           'MLP_NUM': 0,
           'MODEL_ROOT': 'visual_prompt_tuning/model_root',
           'PROMPT': {'CLSEMB_FOLDER': '',
                      'CLSEMB_PATH': '',
                      'DEEP': True,
                      'DEEP_SHARED': False,
                      'DROPOUT': 0.1,
                      'FORWARD_DEEP_NOEXPAND': False,
                      'INITIATION': 'random',
                      'LOCATION': 'prepend',
                      'NUM_DEEP_LAYERS': None,
                      'NUM_TOKENS': 100,
                      'PROJECT': -1,
                      'REVERSE_DEEP': False,
                      'SAVE_FOR_EACH_EPOCH': False,
                      'VIT_POOL_TYPE': 'original'},
           'SAVE_CKPT': False,
           'TRANSFER_TYPE': 'prompt',
           'TYPE': 'vit',
           'WEIGHT_PATH': ''},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/seed800/vtab-dtd/sup_vitb16_imagenet21k/lr5.0_wd0.0001/run1',
 'RUN_N_TIMES': 1,
 'SEED': None,
 'SOLVER': {'BASE_LR': 5.0,
            'BIAS_MULTIPLIER': 1.0,
            'DBG_TRAINABLE': False,
            'LOG_EVERY_N': 100,
            'LOSS': 'softmax',
            'LOSS_ALPHA': 0.01,
            'MOMENTUM': 0.9,
            'OPTIMIZER': 'sgd',
            'PATIENCE': 300,
            'SCHEDULER': 'cosine',
            'TOTAL_EPOCH': 100,
            'WARMUP_EPOCH': 10,
            'WEIGHT_DECAY': 0.0001,
            'WEIGHT_DECAY_BIAS': 0}}
[09/16 03:51:29 visual_prompt]: Loading training data (final training data for vtab)...
2023-09-16 03:51:29.890808: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-09-16 03:51:30.077717: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-09-16 03:51:31.016184: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-16 03:51:31.016271: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-16 03:51:31.016281: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-09-16 03:51:33.049776: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-16 03:51:33.049903: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-16 03:51:33.049921: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
[09/16 03:51:33 visual_prompt]: Constructing vtab-dtd dataset trainval...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/dtd/3.0.1
[INFO: dataset_builder.py:  510]: Reusing dataset dtd (visual_prompt_tuning/data_path/dtd/3.0.1)
2023-09-16 03:51:33.076157: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset dtd for split train[:800]+validation[:200], from visual_prompt_tuning/data_path/dtd/3.0.1
[09/16 03:51:36 visual_prompt]: Number of images: 1000
[09/16 03:51:36 visual_prompt]: Number of classes: 47 / 47
[09/16 03:51:36 visual_prompt]: Loading validation data...
[09/16 03:51:36 visual_prompt]: Constructing vtab-dtd dataset val...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/dtd/3.0.1
[INFO: dataset_builder.py:  510]: Reusing dataset dtd (visual_prompt_tuning/data_path/dtd/3.0.1)
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset dtd for split validation[:200], from visual_prompt_tuning/data_path/dtd/3.0.1
[09/16 03:51:37 visual_prompt]: Number of images: 200
[09/16 03:51:37 visual_prompt]: Number of classes: 47 / 47
[09/16 03:51:37 visual_prompt]: Loading test data...
[09/16 03:51:37 visual_prompt]: Constructing vtab-dtd dataset test...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/dtd/3.0.1
[INFO: dataset_builder.py:  510]: Reusing dataset dtd (visual_prompt_tuning/data_path/dtd/3.0.1)
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset dtd for split test, from visual_prompt_tuning/data_path/dtd/3.0.1
[09/16 03:51:42 visual_prompt]: Number of images: 1880
[09/16 03:51:42 visual_prompt]: Number of classes: 47 / 47
[09/16 03:51:42 visual_prompt]: Constructing models...
[09/16 03:51:44 visual_prompt]: Total Parameters: 86756399	 Gradient Parameters: 957743
[09/16 03:51:44 visual_prompt]: tuned percent:1.104
[09/16 03:51:47 visual_prompt]: Device used for model: 0
[09/16 03:51:47 visual_prompt]: Setting up Evalutator...
[09/16 03:51:47 visual_prompt]: Setting up Trainer...
[09/16 03:51:47 visual_prompt]: 	Setting up the optimizer...
[09/16 03:51:47 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/16 03:51:56 visual_prompt]: Epoch 1 / 100: avg data time: 6.97e-02, avg batch time: 0.5477, average train loss: 3.9713
[09/16 03:51:58 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1421, average loss: 3.9217
[09/16 03:51:58 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.00	top5: 12.00	
[09/16 03:52:05 visual_prompt]: Inference (test):avg data time: 3.08e-03, avg batch time: 0.1857, average loss: 3.9774
[09/16 03:52:05 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.69	
[09/16 03:52:05 visual_prompt]: Best epoch 1: best metric: 0.020
[09/16 03:52:05 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.5
[09/16 03:52:13 visual_prompt]: Epoch 2 / 100: avg data time: 6.20e-02, avg batch time: 0.4632, average train loss: 3.9639
[09/16 03:52:14 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1425, average loss: 3.8717
[09/16 03:52:14 visual_prompt]: Classification results with val_vtab-dtd: top1: 5.00	top5: 16.00	
[09/16 03:52:21 visual_prompt]: Inference (test):avg data time: 2.38e-03, avg batch time: 0.1853, average loss: 3.8848
[09/16 03:52:21 visual_prompt]: Classification results with test_vtab-dtd: top1: 4.73	top5: 13.94	
[09/16 03:52:21 visual_prompt]: Best epoch 2: best metric: 0.050
[09/16 03:52:21 visual_prompt]: Training 3 / 100 epoch, with learning rate 1.0
[09/16 03:52:29 visual_prompt]: Epoch 3 / 100: avg data time: 6.33e-02, avg batch time: 0.4644, average train loss: 3.9563
[09/16 03:52:31 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1427, average loss: 3.8519
[09/16 03:52:31 visual_prompt]: Classification results with val_vtab-dtd: top1: 3.50	top5: 17.00	
[09/16 03:52:38 visual_prompt]: Inference (test):avg data time: 5.46e-03, avg batch time: 0.1897, average loss: 3.8695
[09/16 03:52:38 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.23	top5: 14.15	
[09/16 03:52:38 visual_prompt]: Training 4 / 100 epoch, with learning rate 1.5
[09/16 03:52:46 visual_prompt]: Epoch 4 / 100: avg data time: 5.91e-02, avg batch time: 0.4605, average train loss: 3.9687
[09/16 03:52:47 visual_prompt]: Inference (val):avg data time: 3.67e-05, avg batch time: 0.1429, average loss: 3.7010
[09/16 03:52:47 visual_prompt]: Classification results with val_vtab-dtd: top1: 9.00	top5: 28.00	
[09/16 03:52:54 visual_prompt]: Inference (test):avg data time: 6.59e-03, avg batch time: 0.1885, average loss: 3.8480
[09/16 03:52:54 visual_prompt]: Classification results with test_vtab-dtd: top1: 4.89	top5: 20.69	
[09/16 03:52:54 visual_prompt]: Best epoch 4: best metric: 0.090
[09/16 03:52:54 visual_prompt]: Training 5 / 100 epoch, with learning rate 2.0
[09/16 03:53:02 visual_prompt]: Epoch 5 / 100: avg data time: 5.22e-02, avg batch time: 0.4571, average train loss: 3.9895
[09/16 03:53:04 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1428, average loss: 3.7349
[09/16 03:53:04 visual_prompt]: Classification results with val_vtab-dtd: top1: 1.00	top5: 17.50	
[09/16 03:53:11 visual_prompt]: Inference (test):avg data time: 5.00e-03, avg batch time: 0.1884, average loss: 3.7139
[09/16 03:53:11 visual_prompt]: Classification results with test_vtab-dtd: top1: 4.04	top5: 21.28	
[09/16 03:53:11 visual_prompt]: Training 6 / 100 epoch, with learning rate 2.5
[09/16 03:53:19 visual_prompt]: Epoch 6 / 100: avg data time: 6.87e-02, avg batch time: 0.4695, average train loss: 3.6437
[09/16 03:53:20 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1429, average loss: 3.3748
[09/16 03:53:20 visual_prompt]: Classification results with val_vtab-dtd: top1: 13.50	top5: 37.00	
[09/16 03:53:27 visual_prompt]: Inference (test):avg data time: 5.36e-03, avg batch time: 0.1877, average loss: 3.6168
[09/16 03:53:27 visual_prompt]: Classification results with test_vtab-dtd: top1: 8.03	top5: 30.11	
[09/16 03:53:27 visual_prompt]: Best epoch 6: best metric: 0.135
[09/16 03:53:27 visual_prompt]: Training 7 / 100 epoch, with learning rate 3.0
[09/16 03:53:35 visual_prompt]: Epoch 7 / 100: avg data time: 5.60e-02, avg batch time: 0.4589, average train loss: 3.4336
[09/16 03:53:37 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1429, average loss: 3.7370
[09/16 03:53:37 visual_prompt]: Classification results with val_vtab-dtd: top1: 9.00	top5: 31.00	
[09/16 03:53:44 visual_prompt]: Inference (test):avg data time: 6.76e-03, avg batch time: 0.1901, average loss: 3.8176
[09/16 03:53:44 visual_prompt]: Classification results with test_vtab-dtd: top1: 9.04	top5: 27.29	
[09/16 03:53:44 visual_prompt]: Training 8 / 100 epoch, with learning rate 3.5
[09/16 03:53:52 visual_prompt]: Epoch 8 / 100: avg data time: 6.35e-02, avg batch time: 0.4647, average train loss: 3.4768
[09/16 03:53:53 visual_prompt]: Inference (val):avg data time: 4.71e-05, avg batch time: 0.1436, average loss: 3.7750
[09/16 03:53:53 visual_prompt]: Classification results with val_vtab-dtd: top1: 15.00	top5: 32.50	
[09/16 03:54:01 visual_prompt]: Inference (test):avg data time: 6.00e-03, avg batch time: 0.1886, average loss: 3.9367
[09/16 03:54:01 visual_prompt]: Classification results with test_vtab-dtd: top1: 12.18	top5: 28.88	
[09/16 03:54:01 visual_prompt]: Best epoch 8: best metric: 0.150
[09/16 03:54:01 visual_prompt]: Training 9 / 100 epoch, with learning rate 4.0
[09/16 03:54:08 visual_prompt]: Epoch 9 / 100: avg data time: 6.09e-02, avg batch time: 0.4631, average train loss: 2.7184
[09/16 03:54:10 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1437, average loss: 2.5869
[09/16 03:54:10 visual_prompt]: Classification results with val_vtab-dtd: top1: 42.00	top5: 73.00	
[09/16 03:54:17 visual_prompt]: Inference (test):avg data time: 3.69e-03, avg batch time: 0.1871, average loss: 3.1334
[09/16 03:54:17 visual_prompt]: Classification results with test_vtab-dtd: top1: 35.21	top5: 66.17	
[09/16 03:54:17 visual_prompt]: Best epoch 9: best metric: 0.420
[09/16 03:54:17 visual_prompt]: Training 10 / 100 epoch, with learning rate 4.5
[09/16 03:54:25 visual_prompt]: Epoch 10 / 100: avg data time: 6.16e-02, avg batch time: 0.4672, average train loss: 1.5695
[09/16 03:54:27 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1430, average loss: 1.1205
[09/16 03:54:27 visual_prompt]: Classification results with val_vtab-dtd: top1: 71.00	top5: 94.50	
[09/16 03:54:34 visual_prompt]: Inference (test):avg data time: 3.02e-03, avg batch time: 0.1873, average loss: 1.9993
[09/16 03:54:34 visual_prompt]: Classification results with test_vtab-dtd: top1: 52.39	top5: 83.51	
[09/16 03:54:34 visual_prompt]: Best epoch 10: best metric: 0.710
[09/16 03:54:34 visual_prompt]: Training 11 / 100 epoch, with learning rate 5.0
[09/16 03:54:41 visual_prompt]: Epoch 11 / 100: avg data time: 6.26e-02, avg batch time: 0.4649, average train loss: 0.7251
[09/16 03:54:43 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1431, average loss: 0.3808
[09/16 03:54:43 visual_prompt]: Classification results with val_vtab-dtd: top1: 85.50	top5: 99.50	
[09/16 03:54:50 visual_prompt]: Inference (test):avg data time: 3.86e-03, avg batch time: 0.1862, average loss: 2.0207
[09/16 03:54:50 visual_prompt]: Classification results with test_vtab-dtd: top1: 54.47	top5: 84.73	
[09/16 03:54:50 visual_prompt]: Best epoch 11: best metric: 0.855
[09/16 03:54:50 visual_prompt]: Training 12 / 100 epoch, with learning rate 4.998477067547739
[09/16 03:54:58 visual_prompt]: Epoch 12 / 100: avg data time: 5.36e-02, avg batch time: 0.4580, average train loss: 0.9089
[09/16 03:55:00 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1433, average loss: 3.0399
[09/16 03:55:00 visual_prompt]: Classification results with val_vtab-dtd: top1: 40.00	top5: 66.50	
[09/16 03:55:07 visual_prompt]: Inference (test):avg data time: 3.96e-03, avg batch time: 0.1860, average loss: 4.0930
[09/16 03:55:07 visual_prompt]: Classification results with test_vtab-dtd: top1: 28.14	top5: 53.56	
[09/16 03:55:07 visual_prompt]: Training 13 / 100 epoch, with learning rate 4.993910125649561
[09/16 03:55:14 visual_prompt]: Epoch 13 / 100: avg data time: 4.87e-02, avg batch time: 0.4518, average train loss: 0.9221
[09/16 03:55:16 visual_prompt]: Inference (val):avg data time: 3.58e-05, avg batch time: 0.1432, average loss: 0.5058
[09/16 03:55:16 visual_prompt]: Classification results with val_vtab-dtd: top1: 86.50	top5: 98.00	
[09/16 03:55:23 visual_prompt]: Inference (test):avg data time: 1.79e-03, avg batch time: 0.1872, average loss: 1.9678
[09/16 03:55:23 visual_prompt]: Classification results with test_vtab-dtd: top1: 53.40	top5: 83.19	
[09/16 03:55:23 visual_prompt]: Best epoch 13: best metric: 0.865
[09/16 03:55:23 visual_prompt]: Training 14 / 100 epoch, with learning rate 4.986304738420683
[09/16 03:55:30 visual_prompt]: Epoch 14 / 100: avg data time: 6.18e-02, avg batch time: 0.4638, average train loss: 0.3744
[09/16 03:55:32 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1435, average loss: 0.1702
[09/16 03:55:32 visual_prompt]: Classification results with val_vtab-dtd: top1: 95.00	top5: 100.00	
[09/16 03:55:39 visual_prompt]: Inference (test):avg data time: 3.73e-03, avg batch time: 0.1874, average loss: 1.9666
[09/16 03:55:39 visual_prompt]: Classification results with test_vtab-dtd: top1: 54.26	top5: 84.47	
[09/16 03:55:39 visual_prompt]: Best epoch 14: best metric: 0.950
[09/16 03:55:39 visual_prompt]: Training 15 / 100 epoch, with learning rate 4.975670171853926
[09/16 03:55:47 visual_prompt]: Epoch 15 / 100: avg data time: 6.69e-02, avg batch time: 0.4686, average train loss: 0.1591
[09/16 03:55:49 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1432, average loss: 0.1383
[09/16 03:55:49 visual_prompt]: Classification results with val_vtab-dtd: top1: 95.50	top5: 100.00	
[09/16 03:55:56 visual_prompt]: Inference (test):avg data time: 5.18e-03, avg batch time: 0.1893, average loss: 2.2595
[09/16 03:55:56 visual_prompt]: Classification results with test_vtab-dtd: top1: 55.69	top5: 84.04	
[09/16 03:55:56 visual_prompt]: Best epoch 15: best metric: 0.955
[09/16 03:55:56 visual_prompt]: Training 16 / 100 epoch, with learning rate 4.962019382530521
[09/16 03:56:03 visual_prompt]: Epoch 16 / 100: avg data time: 4.66e-02, avg batch time: 0.4521, average train loss: 0.1543
[09/16 03:56:05 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1431, average loss: 0.0634
[09/16 03:56:05 visual_prompt]: Classification results with val_vtab-dtd: top1: 99.00	top5: 100.00	
[09/16 03:56:12 visual_prompt]: Inference (test):avg data time: 4.86e-03, avg batch time: 0.1879, average loss: 2.2107
[09/16 03:56:12 visual_prompt]: Classification results with test_vtab-dtd: top1: 58.19	top5: 84.95	
[09/16 03:56:12 visual_prompt]: Best epoch 16: best metric: 0.990
[09/16 03:56:12 visual_prompt]: Training 17 / 100 epoch, with learning rate 4.945369001834514
[09/16 03:56:20 visual_prompt]: Epoch 17 / 100: avg data time: 6.17e-02, avg batch time: 0.4629, average train loss: 0.2056
[09/16 03:56:22 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1456, average loss: 0.0502
[09/16 03:56:22 visual_prompt]: Classification results with val_vtab-dtd: top1: 99.00	top5: 100.00	
[09/16 03:56:29 visual_prompt]: Inference (test):avg data time: 1.09e-03, avg batch time: 0.1866, average loss: 1.9354
[09/16 03:56:29 visual_prompt]: Classification results with test_vtab-dtd: top1: 60.53	top5: 86.12	
[09/16 03:56:29 visual_prompt]: Training 18 / 100 epoch, with learning rate 4.925739315689991
[09/16 03:56:36 visual_prompt]: Epoch 18 / 100: avg data time: 6.09e-02, avg batch time: 0.4633, average train loss: 0.1698
[09/16 03:56:38 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1432, average loss: 0.0943
[09/16 03:56:38 visual_prompt]: Classification results with val_vtab-dtd: top1: 97.00	top5: 99.50	
[09/16 03:56:45 visual_prompt]: Inference (test):avg data time: 4.49e-03, avg batch time: 0.1865, average loss: 2.1521
[09/16 03:56:45 visual_prompt]: Classification results with test_vtab-dtd: top1: 56.65	top5: 85.00	
[09/16 03:56:45 visual_prompt]: Training 19 / 100 epoch, with learning rate 4.903154239845797
[09/16 03:56:53 visual_prompt]: Epoch 19 / 100: avg data time: 6.96e-02, avg batch time: 0.4721, average train loss: 0.1112
[09/16 03:56:55 visual_prompt]: Inference (val):avg data time: 4.96e-05, avg batch time: 0.1435, average loss: 0.2602
[09/16 03:56:55 visual_prompt]: Classification results with val_vtab-dtd: top1: 94.50	top5: 98.50	
[09/16 03:57:02 visual_prompt]: Inference (test):avg data time: 6.97e-03, avg batch time: 0.1884, average loss: 2.3791
[09/16 03:57:02 visual_prompt]: Classification results with test_vtab-dtd: top1: 56.49	top5: 84.15	
[09/16 03:57:02 visual_prompt]: Training 20 / 100 epoch, with learning rate 4.877641290737884
[09/16 03:57:10 visual_prompt]: Epoch 20 / 100: avg data time: 6.61e-02, avg batch time: 0.4682, average train loss: 0.1433
[09/16 03:57:12 visual_prompt]: Inference (val):avg data time: 3.43e-05, avg batch time: 0.1433, average loss: 0.1023
[09/16 03:57:12 visual_prompt]: Classification results with val_vtab-dtd: top1: 97.00	top5: 100.00	
[09/16 03:57:19 visual_prompt]: Inference (test):avg data time: 4.69e-03, avg batch time: 0.1888, average loss: 2.3836
[09/16 03:57:19 visual_prompt]: Classification results with test_vtab-dtd: top1: 56.65	top5: 84.63	
[09/16 03:57:19 visual_prompt]: Training 21 / 100 epoch, with learning rate 4.849231551964771
[09/16 03:57:27 visual_prompt]: Epoch 21 / 100: avg data time: 6.88e-02, avg batch time: 0.4723, average train loss: 0.0767
[09/16 03:57:29 visual_prompt]: Inference (val):avg data time: 3.52e-05, avg batch time: 0.1434, average loss: 0.4012
[09/16 03:57:29 visual_prompt]: Classification results with val_vtab-dtd: top1: 95.00	top5: 97.00	
[09/16 03:57:36 visual_prompt]: Inference (test):avg data time: 4.18e-03, avg batch time: 0.1894, average loss: 2.3120
[09/16 03:57:36 visual_prompt]: Classification results with test_vtab-dtd: top1: 56.28	top5: 82.34	
[09/16 03:57:36 visual_prompt]: Training 22 / 100 epoch, with learning rate 4.817959636416969
[09/16 03:57:43 visual_prompt]: Epoch 22 / 100: avg data time: 5.27e-02, avg batch time: 0.4603, average train loss: 0.1374
[09/16 03:57:45 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1431, average loss: 0.0772
[09/16 03:57:45 visual_prompt]: Classification results with val_vtab-dtd: top1: 98.00	top5: 100.00	
[09/16 03:57:52 visual_prompt]: Inference (test):avg data time: 2.60e-03, avg batch time: 0.1895, average loss: 2.0958
[09/16 03:57:52 visual_prompt]: Classification results with test_vtab-dtd: top1: 60.21	top5: 85.43	
[09/16 03:57:52 visual_prompt]: Training 23 / 100 epoch, with learning rate 4.783863644106502
[09/16 03:58:00 visual_prompt]: Epoch 23 / 100: avg data time: 6.66e-02, avg batch time: 0.4687, average train loss: 0.1116
[09/16 03:58:02 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.1433, average loss: 0.0966
[09/16 03:58:02 visual_prompt]: Classification results with val_vtab-dtd: top1: 97.50	top5: 100.00	
[09/16 03:58:09 visual_prompt]: Inference (test):avg data time: 2.20e-03, avg batch time: 0.1856, average loss: 2.2632
[09/16 03:58:09 visual_prompt]: Classification results with test_vtab-dtd: top1: 59.31	top5: 83.62	
[09/16 03:58:09 visual_prompt]: Training 24 / 100 epoch, with learning rate 4.7469851157479175
[09/16 03:58:16 visual_prompt]: Epoch 24 / 100: avg data time: 5.12e-02, avg batch time: 0.4574, average train loss: 0.0947
[09/16 03:58:18 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1432, average loss: 0.1377
[09/16 03:58:18 visual_prompt]: Classification results with val_vtab-dtd: top1: 96.00	top5: 100.00	
[09/16 03:58:25 visual_prompt]: Inference (test):avg data time: 1.99e-03, avg batch time: 0.1869, average loss: 2.2063
[09/16 03:58:25 visual_prompt]: Classification results with test_vtab-dtd: top1: 57.07	top5: 85.16	
[09/16 03:58:25 visual_prompt]: Training 25 / 100 epoch, with learning rate 4.707368982147317
[09/16 03:58:33 visual_prompt]: Epoch 25 / 100: avg data time: 5.59e-02, avg batch time: 0.4621, average train loss: 0.1559
[09/16 03:58:34 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1434, average loss: 0.0577
[09/16 03:58:34 visual_prompt]: Classification results with val_vtab-dtd: top1: 98.50	top5: 100.00	
[09/16 03:58:41 visual_prompt]: Inference (test):avg data time: 1.85e-03, avg batch time: 0.1869, average loss: 1.8823
[09/16 03:58:41 visual_prompt]: Classification results with test_vtab-dtd: top1: 60.90	top5: 85.69	
[09/16 03:58:41 visual_prompt]: Training 26 / 100 epoch, with learning rate 4.665063509461097
[09/16 03:58:49 visual_prompt]: Epoch 26 / 100: avg data time: 4.39e-02, avg batch time: 0.4497, average train loss: 0.1041
[09/16 03:58:51 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1438, average loss: 0.0763
[09/16 03:58:51 visual_prompt]: Classification results with val_vtab-dtd: top1: 98.00	top5: 100.00	
[09/16 03:58:58 visual_prompt]: Inference (test):avg data time: 3.03e-03, avg batch time: 0.1870, average loss: 2.0883
[09/16 03:58:58 visual_prompt]: Classification results with test_vtab-dtd: top1: 60.16	top5: 85.90	
[09/16 03:58:58 visual_prompt]: Training 27 / 100 epoch, with learning rate 4.620120240391064
[09/16 03:59:06 visual_prompt]: Epoch 27 / 100: avg data time: 6.07e-02, avg batch time: 0.4638, average train loss: 0.0893
[09/16 03:59:07 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1435, average loss: 0.0777
[09/16 03:59:07 visual_prompt]: Classification results with val_vtab-dtd: top1: 98.50	top5: 100.00	
[09/16 03:59:14 visual_prompt]: Inference (test):avg data time: 7.00e-03, avg batch time: 0.1882, average loss: 2.0955
[09/16 03:59:14 visual_prompt]: Classification results with test_vtab-dtd: top1: 58.72	top5: 84.79	
[09/16 03:59:14 visual_prompt]: Training 28 / 100 epoch, with learning rate 4.572593931387604
[09/16 03:59:22 visual_prompt]: Epoch 28 / 100: avg data time: 6.73e-02, avg batch time: 0.4699, average train loss: 0.0975
[09/16 03:59:24 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1434, average loss: 0.1729
[09/16 03:59:24 visual_prompt]: Classification results with val_vtab-dtd: top1: 95.00	top5: 100.00	
[09/16 03:59:31 visual_prompt]: Inference (test):avg data time: 4.48e-03, avg batch time: 0.1873, average loss: 1.9084
[09/16 03:59:31 visual_prompt]: Classification results with test_vtab-dtd: top1: 56.54	top5: 85.27	
[09/16 03:59:31 visual_prompt]: Training 29 / 100 epoch, with learning rate 4.522542485937368
[09/16 03:59:39 visual_prompt]: Epoch 29 / 100: avg data time: 5.25e-02, avg batch time: 0.4582, average train loss: 0.1080
[09/16 03:59:41 visual_prompt]: Inference (val):avg data time: 3.70e-05, avg batch time: 0.1439, average loss: 0.0291
[09/16 03:59:41 visual_prompt]: Classification results with val_vtab-dtd: top1: 99.00	top5: 100.00	
[09/16 03:59:48 visual_prompt]: Inference (test):avg data time: 6.48e-03, avg batch time: 0.1912, average loss: 2.1067
[09/16 03:59:48 visual_prompt]: Classification results with test_vtab-dtd: top1: 60.11	top5: 85.05	
[09/16 03:59:48 visual_prompt]: Training 30 / 100 epoch, with learning rate 4.4700268840168045
[09/16 03:59:56 visual_prompt]: Epoch 30 / 100: avg data time: 6.86e-02, avg batch time: 0.4722, average train loss: 0.1794
[09/16 03:59:58 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1433, average loss: 0.1090
[09/16 03:59:58 visual_prompt]: Classification results with val_vtab-dtd: top1: 96.50	top5: 100.00	
[09/16 04:00:05 visual_prompt]: Inference (test):avg data time: 2.93e-03, avg batch time: 0.1868, average loss: 2.0493
[09/16 04:00:05 visual_prompt]: Classification results with test_vtab-dtd: top1: 56.44	top5: 85.00	
[09/16 04:00:05 visual_prompt]: Training 31 / 100 epoch, with learning rate 4.415111107797445
[09/16 04:00:12 visual_prompt]: Epoch 31 / 100: avg data time: 5.95e-02, avg batch time: 0.4610, average train loss: 0.1415
[09/16 04:00:14 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1433, average loss: 0.0500
[09/16 04:00:14 visual_prompt]: Classification results with val_vtab-dtd: top1: 99.00	top5: 100.00	
[09/16 04:00:21 visual_prompt]: Inference (test):avg data time: 3.82e-03, avg batch time: 0.1878, average loss: 2.0403
[09/16 04:00:21 visual_prompt]: Classification results with test_vtab-dtd: top1: 59.79	top5: 85.96	
[09/16 04:00:21 visual_prompt]: Training 32 / 100 epoch, with learning rate 4.357862063693486
[09/16 04:00:29 visual_prompt]: Epoch 32 / 100: avg data time: 6.23e-02, avg batch time: 0.4647, average train loss: 0.1286
[09/16 04:00:31 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1432, average loss: 0.0956
[09/16 04:00:31 visual_prompt]: Classification results with val_vtab-dtd: top1: 97.50	top5: 100.00	
[09/16 04:00:38 visual_prompt]: Inference (test):avg data time: 5.33e-03, avg batch time: 0.1871, average loss: 2.1318
[09/16 04:00:38 visual_prompt]: Classification results with test_vtab-dtd: top1: 56.12	top5: 82.82	
[09/16 04:00:38 visual_prompt]: Training 33 / 100 epoch, with learning rate 4.298349500846628
[09/16 04:00:45 visual_prompt]: Epoch 33 / 100: avg data time: 6.35e-02, avg batch time: 0.4647, average train loss: 0.0708
[09/16 04:00:47 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1433, average loss: 0.0384
[09/16 04:00:47 visual_prompt]: Classification results with val_vtab-dtd: top1: 99.00	top5: 100.00	
[09/16 04:00:54 visual_prompt]: Inference (test):avg data time: 4.43e-03, avg batch time: 0.1905, average loss: 2.0725
[09/16 04:00:54 visual_prompt]: Classification results with test_vtab-dtd: top1: 59.20	top5: 84.89	
[09/16 04:00:54 visual_prompt]: Training 34 / 100 epoch, with learning rate 4.236645926147493
[09/16 04:01:02 visual_prompt]: Epoch 34 / 100: avg data time: 6.00e-02, avg batch time: 0.4623, average train loss: 0.0615
[09/16 04:01:04 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.1434, average loss: 0.0760
[09/16 04:01:04 visual_prompt]: Classification results with val_vtab-dtd: top1: 99.00	top5: 100.00	
[09/16 04:01:11 visual_prompt]: Inference (test):avg data time: 2.78e-03, avg batch time: 0.1862, average loss: 2.0077
[09/16 04:01:11 visual_prompt]: Classification results with test_vtab-dtd: top1: 58.67	top5: 84.95	
[09/16 04:01:11 visual_prompt]: Training 35 / 100 epoch, with learning rate 4.172826515897146
[09/16 04:01:18 visual_prompt]: Epoch 35 / 100: avg data time: 4.34e-02, avg batch time: 0.4478, average train loss: 0.0552
[09/16 04:01:20 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.1433, average loss: 0.0971
[09/16 04:01:20 visual_prompt]: Classification results with val_vtab-dtd: top1: 96.50	top5: 100.00	
[09/16 04:01:27 visual_prompt]: Inference (test):avg data time: 2.94e-03, avg batch time: 0.1871, average loss: 2.0531
[09/16 04:01:27 visual_prompt]: Classification results with test_vtab-dtd: top1: 58.35	top5: 85.37	
[09/16 04:01:27 visual_prompt]: Training 36 / 100 epoch, with learning rate 4.106969024216348
[09/16 04:01:35 visual_prompt]: Epoch 36 / 100: avg data time: 6.43e-02, avg batch time: 0.4662, average train loss: 0.0877
[09/16 04:01:37 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1437, average loss: 0.0117
[09/16 04:01:37 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 04:01:43 visual_prompt]: Inference (test):avg data time: 2.94e-03, avg batch time: 0.1868, average loss: 1.9387
[09/16 04:01:43 visual_prompt]: Classification results with test_vtab-dtd: top1: 61.28	top5: 85.80	
[09/16 04:01:43 visual_prompt]: Best epoch 36: best metric: 1.000
[09/16 04:01:43 visual_prompt]: Training 37 / 100 epoch, with learning rate 4.039153688314146
[09/16 04:01:51 visual_prompt]: Epoch 37 / 100: avg data time: 6.57e-02, avg batch time: 0.4764, average train loss: 0.0487
[09/16 04:01:53 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1433, average loss: 0.0887
[09/16 04:01:53 visual_prompt]: Classification results with val_vtab-dtd: top1: 97.50	top5: 100.00	
[09/16 04:02:00 visual_prompt]: Inference (test):avg data time: 4.43e-03, avg batch time: 0.1861, average loss: 2.1674
[09/16 04:02:00 visual_prompt]: Classification results with test_vtab-dtd: top1: 59.47	top5: 82.23	
[09/16 04:02:00 visual_prompt]: Training 38 / 100 epoch, with learning rate 3.969463130731183
[09/16 04:02:08 visual_prompt]: Epoch 38 / 100: avg data time: 6.76e-02, avg batch time: 0.4691, average train loss: 0.0580
[09/16 04:02:10 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1435, average loss: 0.0829
[09/16 04:02:10 visual_prompt]: Classification results with val_vtab-dtd: top1: 98.50	top5: 100.00	
[09/16 04:02:17 visual_prompt]: Inference (test):avg data time: 3.70e-03, avg batch time: 0.1865, average loss: 1.9958
[09/16 04:02:17 visual_prompt]: Classification results with test_vtab-dtd: top1: 59.79	top5: 84.36	
[09/16 04:02:17 visual_prompt]: Training 39 / 100 epoch, with learning rate 3.897982258676867
[09/16 04:02:24 visual_prompt]: Epoch 39 / 100: avg data time: 6.76e-02, avg batch time: 0.4707, average train loss: 0.0337
[09/16 04:02:26 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1433, average loss: 0.0225
[09/16 04:02:26 visual_prompt]: Classification results with val_vtab-dtd: top1: 99.50	top5: 100.00	
[09/16 04:02:33 visual_prompt]: Inference (test):avg data time: 5.25e-03, avg batch time: 0.1882, average loss: 1.8536
[09/16 04:02:33 visual_prompt]: Classification results with test_vtab-dtd: top1: 61.60	top5: 86.01	
[09/16 04:02:33 visual_prompt]: Training 40 / 100 epoch, with learning rate 3.824798160583012
[09/16 04:02:41 visual_prompt]: Epoch 40 / 100: avg data time: 5.96e-02, avg batch time: 0.4633, average train loss: 0.0222
[09/16 04:02:43 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1435, average loss: 0.0180
[09/16 04:02:43 visual_prompt]: Classification results with val_vtab-dtd: top1: 99.50	top5: 100.00	
[09/16 04:02:50 visual_prompt]: Inference (test):avg data time: 1.79e-03, avg batch time: 0.1872, average loss: 1.7524
[09/16 04:02:50 visual_prompt]: Classification results with test_vtab-dtd: top1: 62.93	top5: 86.60	
[09/16 04:02:50 visual_prompt]: Training 41 / 100 epoch, with learning rate 3.75
[09/16 04:02:57 visual_prompt]: Epoch 41 / 100: avg data time: 4.90e-02, avg batch time: 0.4594, average train loss: 0.0122
[09/16 04:02:59 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1433, average loss: 0.0065
[09/16 04:02:59 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 04:03:06 visual_prompt]: Inference (test):avg data time: 5.55e-03, avg batch time: 0.1891, average loss: 1.6758
[09/16 04:03:06 visual_prompt]: Classification results with test_vtab-dtd: top1: 63.67	top5: 86.49	
[09/16 04:03:06 visual_prompt]: Training 42 / 100 epoch, with learning rate 3.673678906964727
[09/16 04:03:14 visual_prompt]: Epoch 42 / 100: avg data time: 5.95e-02, avg batch time: 0.4631, average train loss: 0.0071
[09/16 04:03:16 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1434, average loss: 0.0044
[09/16 04:03:16 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 04:03:23 visual_prompt]: Inference (test):avg data time: 5.93e-03, avg batch time: 0.1905, average loss: 1.6076
[09/16 04:03:23 visual_prompt]: Classification results with test_vtab-dtd: top1: 63.83	top5: 87.71	
[09/16 04:03:23 visual_prompt]: Training 43 / 100 epoch, with learning rate 3.5959278669726933
[09/16 04:03:31 visual_prompt]: Epoch 43 / 100: avg data time: 6.00e-02, avg batch time: 0.4653, average train loss: 0.0041
[09/16 04:03:33 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1435, average loss: 0.0040
[09/16 04:03:33 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 04:03:39 visual_prompt]: Inference (test):avg data time: 3.17e-03, avg batch time: 0.1866, average loss: 1.5666
[09/16 04:03:40 visual_prompt]: Classification results with test_vtab-dtd: top1: 65.05	top5: 87.39	
[09/16 04:03:40 visual_prompt]: Training 44 / 100 epoch, with learning rate 3.516841607689501
[09/16 04:03:47 visual_prompt]: Epoch 44 / 100: avg data time: 6.54e-02, avg batch time: 0.4694, average train loss: 0.0037
[09/16 04:03:49 visual_prompt]: Inference (val):avg data time: 3.45e-05, avg batch time: 0.1436, average loss: 0.0037
[09/16 04:03:49 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 04:03:56 visual_prompt]: Inference (test):avg data time: 4.12e-03, avg batch time: 0.1876, average loss: 1.5088
[09/16 04:03:56 visual_prompt]: Classification results with test_vtab-dtd: top1: 65.37	top5: 88.03	
[09/16 04:03:56 visual_prompt]: Training 45 / 100 epoch, with learning rate 3.4365164835397803
[09/16 04:04:04 visual_prompt]: Epoch 45 / 100: avg data time: 6.29e-02, avg batch time: 0.4643, average train loss: 0.0039
[09/16 04:04:06 visual_prompt]: Inference (val):avg data time: 3.53e-05, avg batch time: 0.1462, average loss: 0.0040
[09/16 04:04:06 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 04:04:13 visual_prompt]: Inference (test):avg data time: 2.81e-03, avg batch time: 0.1872, average loss: 1.4707
[09/16 04:04:13 visual_prompt]: Classification results with test_vtab-dtd: top1: 65.64	top5: 88.09	
[09/16 04:04:13 visual_prompt]: Training 46 / 100 epoch, with learning rate 3.3550503583141724
[09/16 04:04:20 visual_prompt]: Epoch 46 / 100: avg data time: 5.56e-02, avg batch time: 0.4588, average train loss: 0.0043
[09/16 04:04:22 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1432, average loss: 0.0044
[09/16 04:04:22 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 04:04:29 visual_prompt]: Inference (test):avg data time: 3.78e-03, avg batch time: 0.1873, average loss: 1.4374
[09/16 04:04:29 visual_prompt]: Classification results with test_vtab-dtd: top1: 65.59	top5: 88.56	
[09/16 04:04:29 visual_prompt]: Training 47 / 100 epoch, with learning rate 3.2725424859373686
[09/16 04:04:37 visual_prompt]: Epoch 47 / 100: avg data time: 6.49e-02, avg batch time: 0.4670, average train loss: 0.0047
[09/16 04:04:38 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1432, average loss: 0.0045
[09/16 04:04:38 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 04:04:45 visual_prompt]: Inference (test):avg data time: 3.58e-03, avg batch time: 0.1876, average loss: 1.3997
[09/16 04:04:45 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.17	top5: 88.78	
[09/16 04:04:45 visual_prompt]: Training 48 / 100 epoch, with learning rate 3.1890933895424975
[09/16 04:04:53 visual_prompt]: Epoch 48 / 100: avg data time: 6.50e-02, avg batch time: 0.4672, average train loss: 0.0050
[09/16 04:04:55 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1434, average loss: 0.0046
[09/16 04:04:55 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 04:05:02 visual_prompt]: Inference (test):avg data time: 5.93e-03, avg batch time: 0.1875, average loss: 1.3853
[09/16 04:05:02 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.01	top5: 88.99	
[09/16 04:05:02 visual_prompt]: Training 49 / 100 epoch, with learning rate 3.104804738999169
[09/16 04:05:10 visual_prompt]: Epoch 49 / 100: avg data time: 6.22e-02, avg batch time: 0.4644, average train loss: 0.0052
[09/16 04:05:11 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1436, average loss: 0.0048
[09/16 04:05:11 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 04:05:18 visual_prompt]: Inference (test):avg data time: 5.84e-03, avg batch time: 0.1887, average loss: 1.3647
[09/16 04:05:18 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.38	top5: 89.20	
[09/16 04:05:18 visual_prompt]: Training 50 / 100 epoch, with learning rate 3.019779227044398
[09/16 04:05:26 visual_prompt]: Epoch 50 / 100: avg data time: 6.30e-02, avg batch time: 0.4669, average train loss: 0.0054
[09/16 04:05:28 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1434, average loss: 0.0050
[09/16 04:05:28 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 04:05:35 visual_prompt]: Inference (test):avg data time: 2.75e-03, avg batch time: 0.1860, average loss: 1.3480
[09/16 04:05:35 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.60	top5: 89.47	
[09/16 04:05:35 visual_prompt]: Training 51 / 100 epoch, with learning rate 2.934120444167326
[09/16 04:05:43 visual_prompt]: Epoch 51 / 100: avg data time: 6.67e-02, avg batch time: 0.4701, average train loss: 0.0054
[09/16 04:05:45 visual_prompt]: Inference (val):avg data time: 3.71e-05, avg batch time: 0.1433, average loss: 0.0049
[09/16 04:05:45 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 04:05:52 visual_prompt]: Inference (test):avg data time: 3.29e-03, avg batch time: 0.1880, average loss: 1.3299
[09/16 04:05:52 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.54	top5: 89.68	
[09/16 04:05:52 visual_prompt]: Training 52 / 100 epoch, with learning rate 2.8479327524001636
[09/16 04:05:59 visual_prompt]: Epoch 52 / 100: avg data time: 5.50e-02, avg batch time: 0.4614, average train loss: 0.0057
[09/16 04:06:01 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.1432, average loss: 0.0051
[09/16 04:06:01 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 04:06:08 visual_prompt]: Inference (test):avg data time: 5.99e-03, avg batch time: 0.1886, average loss: 1.3195
[09/16 04:06:08 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.28	top5: 89.63	
[09/16 04:06:08 visual_prompt]: Training 53 / 100 epoch, with learning rate 2.761321158169134
[09/16 04:06:16 visual_prompt]: Epoch 53 / 100: avg data time: 5.72e-02, avg batch time: 0.4592, average train loss: 0.0061
[09/16 04:06:18 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1435, average loss: 0.0053
[09/16 04:06:18 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 04:06:25 visual_prompt]: Inference (test):avg data time: 5.20e-03, avg batch time: 0.1878, average loss: 1.3051
[09/16 04:06:25 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.65	top5: 89.36	
[09/16 04:06:25 visual_prompt]: Training 54 / 100 epoch, with learning rate 2.6743911843603128
[09/16 04:06:32 visual_prompt]: Epoch 54 / 100: avg data time: 6.12e-02, avg batch time: 0.4638, average train loss: 0.0059
[09/16 04:06:34 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1433, average loss: 0.0049
[09/16 04:06:34 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 04:06:41 visual_prompt]: Inference (test):avg data time: 8.31e-03, avg batch time: 0.1898, average loss: 1.2895
[09/16 04:06:41 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.13	top5: 90.05	
[09/16 04:06:41 visual_prompt]: Training 55 / 100 epoch, with learning rate 2.5872487417562526
[09/16 04:06:49 visual_prompt]: Epoch 55 / 100: avg data time: 6.18e-02, avg batch time: 0.4647, average train loss: 0.0055
[09/16 04:06:51 visual_prompt]: Inference (val):avg data time: 3.88e-05, avg batch time: 0.1433, average loss: 0.0046
[09/16 04:06:51 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 04:06:58 visual_prompt]: Inference (test):avg data time: 3.45e-03, avg batch time: 0.1866, average loss: 1.2741
[09/16 04:06:58 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.39	top5: 90.05	
[09/16 04:06:58 visual_prompt]: Training 56 / 100 epoch, with learning rate 2.5
[09/16 04:07:06 visual_prompt]: Epoch 56 / 100: avg data time: 7.01e-02, avg batch time: 0.4714, average train loss: 0.0053
[09/16 04:07:08 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1433, average loss: 0.0043
[09/16 04:07:08 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 04:07:15 visual_prompt]: Inference (test):avg data time: 3.91e-03, avg batch time: 0.1897, average loss: 1.2683
[09/16 04:07:15 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.71	top5: 90.27	
[09/16 04:07:15 visual_prompt]: Training 57 / 100 epoch, with learning rate 2.4127512582437483
[09/16 04:07:23 visual_prompt]: Epoch 57 / 100: avg data time: 6.29e-02, avg batch time: 0.4677, average train loss: 0.0050
[09/16 04:07:24 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.1433, average loss: 0.0040
[09/16 04:07:24 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 04:07:32 visual_prompt]: Inference (test):avg data time: 6.60e-03, avg batch time: 0.1882, average loss: 1.2642
[09/16 04:07:32 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.61	top5: 90.27	
[09/16 04:07:32 visual_prompt]: Training 58 / 100 epoch, with learning rate 2.325608815639687
[09/16 04:07:39 visual_prompt]: Epoch 58 / 100: avg data time: 6.84e-02, avg batch time: 0.4692, average train loss: 0.0049
[09/16 04:07:41 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1431, average loss: 0.0037
[09/16 04:07:41 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 04:07:48 visual_prompt]: Inference (test):avg data time: 4.96e-03, avg batch time: 0.1881, average loss: 1.2613
[09/16 04:07:48 visual_prompt]: Classification results with test_vtab-dtd: top1: 68.35	top5: 90.21	
[09/16 04:07:48 visual_prompt]: Training 59 / 100 epoch, with learning rate 2.2386788418308665
[09/16 04:07:56 visual_prompt]: Epoch 59 / 100: avg data time: 7.16e-02, avg batch time: 0.4748, average train loss: 0.0047
[09/16 04:07:58 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1434, average loss: 0.0036
[09/16 04:07:58 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 04:08:05 visual_prompt]: Inference (test):avg data time: 3.54e-03, avg batch time: 0.1878, average loss: 1.2539
[09/16 04:08:05 visual_prompt]: Classification results with test_vtab-dtd: top1: 68.30	top5: 90.53	
[09/16 04:08:05 visual_prompt]: Training 60 / 100 epoch, with learning rate 2.1520672475998373
[09/16 04:08:13 visual_prompt]: Epoch 60 / 100: avg data time: 5.47e-02, avg batch time: 0.4578, average train loss: 0.0047
[09/16 04:08:14 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1434, average loss: 0.0038
[09/16 04:08:14 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 04:08:21 visual_prompt]: Inference (test):avg data time: 1.50e-03, avg batch time: 0.1867, average loss: 1.2600
[09/16 04:08:21 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.93	top5: 90.80	
[09/16 04:08:21 visual_prompt]: Training 61 / 100 epoch, with learning rate 2.0658795558326744
[09/16 04:08:29 visual_prompt]: Epoch 61 / 100: avg data time: 6.56e-02, avg batch time: 0.4728, average train loss: 0.0045
[09/16 04:08:31 visual_prompt]: Inference (val):avg data time: 6.68e-05, avg batch time: 0.1495, average loss: 0.0033
[09/16 04:08:31 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 04:08:38 visual_prompt]: Inference (test):avg data time: 4.09e-03, avg batch time: 0.1884, average loss: 1.2613
[09/16 04:08:38 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.87	top5: 90.74	
[09/16 04:08:38 visual_prompt]: Training 62 / 100 epoch, with learning rate 1.980220772955602
[09/16 04:08:46 visual_prompt]: Epoch 62 / 100: avg data time: 6.70e-02, avg batch time: 0.4689, average train loss: 0.0042
[09/16 04:08:48 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1432, average loss: 0.0031
[09/16 04:08:48 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 04:08:55 visual_prompt]: Inference (test):avg data time: 2.31e-03, avg batch time: 0.2088, average loss: 1.2627
[09/16 04:08:55 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.93	top5: 90.53	
[09/16 04:08:55 visual_prompt]: Training 63 / 100 epoch, with learning rate 1.895195261000831
[09/16 04:09:03 visual_prompt]: Epoch 63 / 100: avg data time: 6.19e-02, avg batch time: 0.4648, average train loss: 0.0040
[09/16 04:09:05 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1442, average loss: 0.0031
[09/16 04:09:05 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 04:09:12 visual_prompt]: Inference (test):avg data time: 3.72e-03, avg batch time: 0.1865, average loss: 1.2615
[09/16 04:09:12 visual_prompt]: Classification results with test_vtab-dtd: top1: 68.19	top5: 91.17	
[09/16 04:09:12 visual_prompt]: Training 64 / 100 epoch, with learning rate 1.8109066104575022
[09/16 04:09:20 visual_prompt]: Epoch 64 / 100: avg data time: 6.43e-02, avg batch time: 0.4677, average train loss: 0.0038
[09/16 04:09:21 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.1432, average loss: 0.0029
[09/16 04:09:21 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 04:09:28 visual_prompt]: Inference (test):avg data time: 3.04e-03, avg batch time: 0.1861, average loss: 1.2619
[09/16 04:09:28 visual_prompt]: Classification results with test_vtab-dtd: top1: 68.35	top5: 91.06	
[09/16 04:09:28 visual_prompt]: Training 65 / 100 epoch, with learning rate 1.7274575140626316
[09/16 04:09:36 visual_prompt]: Epoch 65 / 100: avg data time: 5.91e-02, avg batch time: 0.4612, average train loss: 0.0037
[09/16 04:09:38 visual_prompt]: Inference (val):avg data time: 4.35e-05, avg batch time: 0.1436, average loss: 0.0027
[09/16 04:09:38 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 04:09:45 visual_prompt]: Inference (test):avg data time: 3.91e-03, avg batch time: 0.1865, average loss: 1.2682
[09/16 04:09:45 visual_prompt]: Classification results with test_vtab-dtd: top1: 68.72	top5: 90.85	
[09/16 04:09:45 visual_prompt]: Training 66 / 100 epoch, with learning rate 1.6449496416858285
[09/16 04:09:53 visual_prompt]: Epoch 66 / 100: avg data time: 5.32e-02, avg batch time: 0.5005, average train loss: 0.0035
[09/16 04:09:55 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1433, average loss: 0.0024
[09/16 04:09:55 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 04:10:02 visual_prompt]: Inference (test):avg data time: 2.72e-03, avg batch time: 0.1864, average loss: 1.2545
[09/16 04:10:02 visual_prompt]: Classification results with test_vtab-dtd: top1: 68.56	top5: 91.22	
[09/16 04:10:02 visual_prompt]: Training 67 / 100 epoch, with learning rate 1.5634835164602199
[09/16 04:10:10 visual_prompt]: Epoch 67 / 100: avg data time: 5.79e-02, avg batch time: 0.4619, average train loss: 0.0033
[09/16 04:10:11 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1435, average loss: 0.0023
[09/16 04:10:11 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 04:10:18 visual_prompt]: Inference (test):avg data time: 3.09e-03, avg batch time: 0.1871, average loss: 1.2660
[09/16 04:10:18 visual_prompt]: Classification results with test_vtab-dtd: top1: 68.78	top5: 91.17	
[09/16 04:10:18 visual_prompt]: Training 68 / 100 epoch, with learning rate 1.4831583923104998
[09/16 04:10:26 visual_prompt]: Epoch 68 / 100: avg data time: 4.30e-02, avg batch time: 0.4472, average train loss: 0.0031
[09/16 04:10:27 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1435, average loss: 0.0022
[09/16 04:10:28 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 04:10:34 visual_prompt]: Inference (test):avg data time: 5.32e-03, avg batch time: 0.1869, average loss: 1.2732
[09/16 04:10:34 visual_prompt]: Classification results with test_vtab-dtd: top1: 68.30	top5: 91.12	
[09/16 04:10:34 visual_prompt]: Training 69 / 100 epoch, with learning rate 1.4040721330273063
[09/16 04:10:42 visual_prompt]: Epoch 69 / 100: avg data time: 5.31e-02, avg batch time: 0.4617, average train loss: 0.0029
[09/16 04:10:44 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1433, average loss: 0.0021
[09/16 04:10:44 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 04:10:51 visual_prompt]: Inference (test):avg data time: 3.35e-03, avg batch time: 0.1870, average loss: 1.2716
[09/16 04:10:51 visual_prompt]: Classification results with test_vtab-dtd: top1: 68.62	top5: 90.96	
[09/16 04:10:51 visual_prompt]: Training 70 / 100 epoch, with learning rate 1.3263210930352738
[09/16 04:10:59 visual_prompt]: Epoch 70 / 100: avg data time: 5.62e-02, avg batch time: 0.4596, average train loss: 0.0028
[09/16 04:11:00 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.1445, average loss: 0.0020
[09/16 04:11:00 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 04:11:07 visual_prompt]: Inference (test):avg data time: 5.81e-03, avg batch time: 0.1898, average loss: 1.2795
[09/16 04:11:07 visual_prompt]: Classification results with test_vtab-dtd: top1: 68.56	top5: 91.22	
[09/16 04:11:07 visual_prompt]: Training 71 / 100 epoch, with learning rate 1.2500000000000004
[09/16 04:11:15 visual_prompt]: Epoch 71 / 100: avg data time: 6.09e-02, avg batch time: 0.4629, average train loss: 0.0028
[09/16 04:11:17 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1434, average loss: 0.0019
[09/16 04:11:17 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 04:11:24 visual_prompt]: Inference (test):avg data time: 5.67e-03, avg batch time: 0.1910, average loss: 1.2868
[09/16 04:11:24 visual_prompt]: Classification results with test_vtab-dtd: top1: 68.40	top5: 90.96	
[09/16 04:11:24 visual_prompt]: Training 72 / 100 epoch, with learning rate 1.175201839416988
[09/16 04:11:32 visual_prompt]: Epoch 72 / 100: avg data time: 5.23e-02, avg batch time: 0.4554, average train loss: 0.0027
[09/16 04:11:33 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1433, average loss: 0.0019
[09/16 04:11:33 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 04:11:40 visual_prompt]: Inference (test):avg data time: 5.26e-03, avg batch time: 0.1876, average loss: 1.2913
[09/16 04:11:40 visual_prompt]: Classification results with test_vtab-dtd: top1: 68.46	top5: 91.06	
[09/16 04:11:40 visual_prompt]: Training 73 / 100 epoch, with learning rate 1.1020177413231333
[09/16 04:11:48 visual_prompt]: Epoch 73 / 100: avg data time: 6.20e-02, avg batch time: 0.4638, average train loss: 0.0027
[09/16 04:11:50 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1434, average loss: 0.0019
[09/16 04:11:50 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 04:11:57 visual_prompt]: Inference (test):avg data time: 3.62e-03, avg batch time: 0.1892, average loss: 1.3034
[09/16 04:11:57 visual_prompt]: Classification results with test_vtab-dtd: top1: 68.67	top5: 90.69	
[09/16 04:11:57 visual_prompt]: Training 74 / 100 epoch, with learning rate 1.0305368692688175
[09/16 04:12:05 visual_prompt]: Epoch 74 / 100: avg data time: 6.15e-02, avg batch time: 0.4643, average train loss: 0.0027
[09/16 04:12:06 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.1435, average loss: 0.0018
[09/16 04:12:06 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 04:12:14 visual_prompt]: Inference (test):avg data time: 3.87e-03, avg batch time: 0.1899, average loss: 1.2916
[09/16 04:12:14 visual_prompt]: Classification results with test_vtab-dtd: top1: 68.19	top5: 91.33	
[09/16 04:12:14 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.9608463116858543
[09/16 04:12:22 visual_prompt]: Epoch 75 / 100: avg data time: 6.41e-02, avg batch time: 0.4652, average train loss: 0.0026
[09/16 04:12:23 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1432, average loss: 0.0018
[09/16 04:12:23 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 04:12:30 visual_prompt]: Inference (test):avg data time: 3.61e-03, avg batch time: 0.1867, average loss: 1.3016
[09/16 04:12:30 visual_prompt]: Classification results with test_vtab-dtd: top1: 68.46	top5: 91.49	
[09/16 04:12:30 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.8930309757836516
[09/16 04:12:39 visual_prompt]: Epoch 76 / 100: avg data time: 6.05e-02, avg batch time: 0.4870, average train loss: 0.0024
[09/16 04:12:40 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1434, average loss: 0.0017
[09/16 04:12:40 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 04:12:47 visual_prompt]: Inference (test):avg data time: 1.81e-03, avg batch time: 0.1836, average loss: 1.3090
[09/16 04:12:47 visual_prompt]: Classification results with test_vtab-dtd: top1: 68.30	top5: 91.17	
[09/16 04:12:47 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.8271734841028553
[09/16 04:12:55 visual_prompt]: Epoch 77 / 100: avg data time: 5.88e-02, avg batch time: 0.4602, average train loss: 0.0024
[09/16 04:12:57 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.1432, average loss: 0.0017
[09/16 04:12:57 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 04:13:04 visual_prompt]: Inference (test):avg data time: 3.90e-03, avg batch time: 0.1871, average loss: 1.3129
[09/16 04:13:04 visual_prompt]: Classification results with test_vtab-dtd: top1: 68.67	top5: 91.17	
[09/16 04:13:04 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.7633540738525066
[09/16 04:13:12 visual_prompt]: Epoch 78 / 100: avg data time: 5.91e-02, avg batch time: 0.4623, average train loss: 0.0023
[09/16 04:13:13 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1433, average loss: 0.0016
[09/16 04:13:13 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 04:13:20 visual_prompt]: Inference (test):avg data time: 2.98e-03, avg batch time: 0.1879, average loss: 1.3097
[09/16 04:13:20 visual_prompt]: Classification results with test_vtab-dtd: top1: 68.51	top5: 91.33	
[09/16 04:13:20 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.7016504991533725
[09/16 04:13:28 visual_prompt]: Epoch 79 / 100: avg data time: 5.99e-02, avg batch time: 0.4618, average train loss: 0.0022
[09/16 04:13:30 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1434, average loss: 0.0016
[09/16 04:13:30 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 04:13:37 visual_prompt]: Inference (test):avg data time: 6.21e-03, avg batch time: 0.1885, average loss: 1.3224
[09/16 04:13:37 visual_prompt]: Classification results with test_vtab-dtd: top1: 68.94	top5: 91.17	
[09/16 04:13:37 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.6421379363065141
[09/16 04:13:45 visual_prompt]: Epoch 80 / 100: avg data time: 6.60e-02, avg batch time: 0.4673, average train loss: 0.0022
[09/16 04:13:46 visual_prompt]: Inference (val):avg data time: 3.73e-05, avg batch time: 0.1432, average loss: 0.0016
[09/16 04:13:46 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 04:13:54 visual_prompt]: Inference (test):avg data time: 4.97e-03, avg batch time: 0.1883, average loss: 1.3215
[09/16 04:13:54 visual_prompt]: Classification results with test_vtab-dtd: top1: 68.40	top5: 91.12	
[09/16 04:13:54 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.5848888922025552
[09/16 04:14:01 visual_prompt]: Epoch 81 / 100: avg data time: 6.28e-02, avg batch time: 0.4645, average train loss: 0.0021
[09/16 04:14:03 visual_prompt]: Inference (val):avg data time: 4.63e-05, avg batch time: 0.1433, average loss: 0.0015
[09/16 04:14:03 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 04:14:10 visual_prompt]: Inference (test):avg data time: 3.72e-03, avg batch time: 0.1898, average loss: 1.3298
[09/16 04:14:10 visual_prompt]: Classification results with test_vtab-dtd: top1: 68.19	top5: 90.85	
[09/16 04:14:10 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.5299731159831953
[09/16 04:14:18 visual_prompt]: Epoch 82 / 100: avg data time: 5.66e-02, avg batch time: 0.4586, average train loss: 0.0021
[09/16 04:14:20 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1433, average loss: 0.0015
[09/16 04:14:20 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 04:14:27 visual_prompt]: Inference (test):avg data time: 3.49e-03, avg batch time: 0.1859, average loss: 1.3314
[09/16 04:14:27 visual_prompt]: Classification results with test_vtab-dtd: top1: 68.35	top5: 91.01	
[09/16 04:14:27 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.47745751406263165
[09/16 04:14:34 visual_prompt]: Epoch 83 / 100: avg data time: 6.87e-02, avg batch time: 0.4705, average train loss: 0.0021
[09/16 04:14:36 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.1434, average loss: 0.0015
[09/16 04:14:36 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 04:14:43 visual_prompt]: Inference (test):avg data time: 4.79e-03, avg batch time: 0.1883, average loss: 1.3374
[09/16 04:14:43 visual_prompt]: Classification results with test_vtab-dtd: top1: 68.09	top5: 91.12	
[09/16 04:14:43 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.42740606861239594
[09/16 04:14:51 visual_prompt]: Epoch 84 / 100: avg data time: 4.51e-02, avg batch time: 0.4487, average train loss: 0.0021
[09/16 04:14:52 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1434, average loss: 0.0015
[09/16 04:14:52 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 04:14:59 visual_prompt]: Inference (test):avg data time: 5.54e-03, avg batch time: 0.1881, average loss: 1.3390
[09/16 04:14:59 visual_prompt]: Classification results with test_vtab-dtd: top1: 68.14	top5: 91.12	
[09/16 04:14:59 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.3798797596089351
[09/16 04:15:07 visual_prompt]: Epoch 85 / 100: avg data time: 6.27e-02, avg batch time: 0.4664, average train loss: 0.0021
[09/16 04:15:09 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1434, average loss: 0.0015
[09/16 04:15:09 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 04:15:16 visual_prompt]: Inference (test):avg data time: 3.86e-03, avg batch time: 0.1863, average loss: 1.3461
[09/16 04:15:16 visual_prompt]: Classification results with test_vtab-dtd: top1: 68.56	top5: 90.90	
[09/16 04:15:16 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.33493649053890323
[09/16 04:15:24 visual_prompt]: Epoch 86 / 100: avg data time: 6.54e-02, avg batch time: 0.4672, average train loss: 0.0020
[09/16 04:15:26 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1433, average loss: 0.0015
[09/16 04:15:26 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 04:15:33 visual_prompt]: Inference (test):avg data time: 3.24e-03, avg batch time: 0.1878, average loss: 1.3395
[09/16 04:15:33 visual_prompt]: Classification results with test_vtab-dtd: top1: 68.19	top5: 90.74	
[09/16 04:15:33 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.29263101785268253
[09/16 04:15:40 visual_prompt]: Epoch 87 / 100: avg data time: 6.04e-02, avg batch time: 0.4633, average train loss: 0.0020
[09/16 04:15:42 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.1432, average loss: 0.0014
[09/16 04:15:42 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 04:15:49 visual_prompt]: Inference (test):avg data time: 5.48e-03, avg batch time: 0.1872, average loss: 1.3505
[09/16 04:15:49 visual_prompt]: Classification results with test_vtab-dtd: top1: 68.24	top5: 90.80	
[09/16 04:15:49 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.25301488425208296
[09/16 04:15:57 visual_prompt]: Epoch 88 / 100: avg data time: 6.42e-02, avg batch time: 0.4664, average train loss: 0.0020
[09/16 04:15:59 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1433, average loss: 0.0014
[09/16 04:15:59 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 04:16:06 visual_prompt]: Inference (test):avg data time: 6.16e-03, avg batch time: 0.1916, average loss: 1.3563
[09/16 04:16:06 visual_prompt]: Classification results with test_vtab-dtd: top1: 68.14	top5: 90.85	
[09/16 04:16:06 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.21613635589349756
[09/16 04:16:13 visual_prompt]: Epoch 89 / 100: avg data time: 5.34e-02, avg batch time: 0.4572, average train loss: 0.0020
[09/16 04:16:15 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1434, average loss: 0.0014
[09/16 04:16:15 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 04:16:23 visual_prompt]: Inference (test):avg data time: 2.95e-03, avg batch time: 0.2016, average loss: 1.3514
[09/16 04:16:23 visual_prompt]: Classification results with test_vtab-dtd: top1: 68.19	top5: 91.01	
[09/16 04:16:23 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.18204036358303172
[09/16 04:16:31 visual_prompt]: Epoch 90 / 100: avg data time: 6.08e-02, avg batch time: 0.4616, average train loss: 0.0020
[09/16 04:16:32 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1434, average loss: 0.0014
[09/16 04:16:32 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 04:16:39 visual_prompt]: Inference (test):avg data time: 4.78e-03, avg batch time: 0.1886, average loss: 1.3598
[09/16 04:16:39 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.98	top5: 90.90	
[09/16 04:16:39 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.1507684480352292
[09/16 04:16:47 visual_prompt]: Epoch 91 / 100: avg data time: 6.57e-02, avg batch time: 0.4679, average train loss: 0.0019
[09/16 04:16:49 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1431, average loss: 0.0014
[09/16 04:16:49 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 04:16:56 visual_prompt]: Inference (test):avg data time: 5.12e-03, avg batch time: 0.1884, average loss: 1.3552
[09/16 04:16:56 visual_prompt]: Classification results with test_vtab-dtd: top1: 68.30	top5: 90.80	
[09/16 04:16:56 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.12235870926211617
[09/16 04:17:04 visual_prompt]: Epoch 92 / 100: avg data time: 5.59e-02, avg batch time: 0.4607, average train loss: 0.0019
[09/16 04:17:05 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1434, average loss: 0.0014
[09/16 04:17:05 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 04:17:12 visual_prompt]: Inference (test):avg data time: 3.42e-03, avg batch time: 0.1935, average loss: 1.3528
[09/16 04:17:12 visual_prompt]: Classification results with test_vtab-dtd: top1: 68.46	top5: 90.74	
[09/16 04:17:12 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.09684576015420276
[09/16 04:17:20 visual_prompt]: Epoch 93 / 100: avg data time: 6.53e-02, avg batch time: 0.4708, average train loss: 0.0019
[09/16 04:17:22 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1431, average loss: 0.0014
[09/16 04:17:22 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 04:17:29 visual_prompt]: Inference (test):avg data time: 3.94e-03, avg batch time: 0.1875, average loss: 1.3553
[09/16 04:17:29 visual_prompt]: Classification results with test_vtab-dtd: top1: 68.09	top5: 90.74	
[09/16 04:17:29 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.07426068431000882
[09/16 04:17:37 visual_prompt]: Epoch 94 / 100: avg data time: 6.24e-02, avg batch time: 0.4863, average train loss: 0.0019
[09/16 04:17:39 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1433, average loss: 0.0014
[09/16 04:17:39 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 04:17:46 visual_prompt]: Inference (test):avg data time: 2.43e-03, avg batch time: 0.1870, average loss: 1.3556
[09/16 04:17:46 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.98	top5: 90.90	
[09/16 04:17:46 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.05463099816548578
[09/16 04:17:54 visual_prompt]: Epoch 95 / 100: avg data time: 6.59e-02, avg batch time: 0.4678, average train loss: 0.0019
[09/16 04:17:56 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1432, average loss: 0.0014
[09/16 04:17:56 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 04:18:03 visual_prompt]: Inference (test):avg data time: 1.79e-03, avg batch time: 0.1853, average loss: 1.3553
[09/16 04:18:03 visual_prompt]: Classification results with test_vtab-dtd: top1: 68.03	top5: 90.96	
[09/16 04:18:03 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.03798061746947995
[09/16 04:18:10 visual_prompt]: Epoch 96 / 100: avg data time: 6.94e-02, avg batch time: 0.4720, average train loss: 0.0019
[09/16 04:18:12 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1432, average loss: 0.0014
[09/16 04:18:12 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 04:18:19 visual_prompt]: Inference (test):avg data time: 5.37e-03, avg batch time: 0.1890, average loss: 1.3571
[09/16 04:18:19 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.98	top5: 90.96	
[09/16 04:18:19 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.024329828146074095
[09/16 04:18:27 visual_prompt]: Epoch 97 / 100: avg data time: 5.99e-02, avg batch time: 0.4612, average train loss: 0.0019
[09/16 04:18:29 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1434, average loss: 0.0014
[09/16 04:18:29 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 04:18:36 visual_prompt]: Inference (test):avg data time: 5.36e-03, avg batch time: 0.1877, average loss: 1.3566
[09/16 04:18:36 visual_prompt]: Classification results with test_vtab-dtd: top1: 68.03	top5: 90.85	
[09/16 04:18:36 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.013695261579316775
[09/16 04:18:43 visual_prompt]: Epoch 98 / 100: avg data time: 5.07e-02, avg batch time: 0.4540, average train loss: 0.0019
[09/16 04:18:45 visual_prompt]: Inference (val):avg data time: 4.35e-05, avg batch time: 0.1432, average loss: 0.0014
[09/16 04:18:45 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 04:18:52 visual_prompt]: Inference (test):avg data time: 5.46e-03, avg batch time: 0.1867, average loss: 1.3568
[09/16 04:18:52 visual_prompt]: Classification results with test_vtab-dtd: top1: 68.14	top5: 90.85	
[09/16 04:18:52 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.006089874350439506
[09/16 04:19:00 visual_prompt]: Epoch 99 / 100: avg data time: 6.30e-02, avg batch time: 0.4652, average train loss: 0.0019
[09/16 04:19:02 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1434, average loss: 0.0014
[09/16 04:19:02 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 04:19:09 visual_prompt]: Inference (test):avg data time: 3.07e-03, avg batch time: 0.1877, average loss: 1.3569
[09/16 04:19:09 visual_prompt]: Classification results with test_vtab-dtd: top1: 68.14	top5: 90.85	
[09/16 04:19:09 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0015229324522605947
[09/16 04:19:16 visual_prompt]: Epoch 100 / 100: avg data time: 6.01e-02, avg batch time: 0.4623, average train loss: 0.0019
[09/16 04:19:18 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1436, average loss: 0.0014
[09/16 04:19:18 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/16 04:19:25 visual_prompt]: Inference (test):avg data time: 6.93e-03, avg batch time: 0.1897, average loss: 1.3568
[09/16 04:19:25 visual_prompt]: Classification results with test_vtab-dtd: top1: 68.14	top5: 90.85	
