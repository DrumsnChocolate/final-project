/bin/bash: /home/s1952889/miniconda3/envs/prompt/lib/libtinfo.so.6: no version information available (required by /bin/bash)
An exception occurred in telemetry logging.Disabling telemetry to prevent further exceptions.
Traceback (most recent call last):
  File "/home/s1952889/miniconda3/envs/prompt/lib/python3.11/site-packages/iopath/common/file_io.py", line 946, in __log_tmetry_keys
    handler.log_event()
  File "/home/s1952889/miniconda3/envs/prompt/lib/python3.11/site-packages/iopath/common/event_logger.py", line 97, in log_event
    del self._evt
        ^^^^^^^^^
AttributeError: 'NativePathHandler' object has no attribute '_evt'
Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-cifar(num_classes=100)', 'DATA.NUMBER_CLASSES', '100', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/25 21:37:01 visual_prompt]: Rank of current process: 0. World size: 1
[09/25 21:37:05 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/25 21:37:05 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-cifar(num_classes=100)', 'DATA.NUMBER_CLASSES', '100', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/25 21:37:05 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/25 21:37:05 visual_prompt]: Training with config:
[09/25 21:37:05 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-cifar(num_classes=100)/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr50.0_wd0.01/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 50.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-cifar(num_classes=100)', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 100, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/25 21:37:05 visual_prompt]: Loading training data...
2023-09-25 21:37:08.161539: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-09-25 21:37:11.821739: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-09-25 21:37:23.155021: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[09/25 21:37:54 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[:800], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/25 21:37:56 visual_prompt]: Number of images: 800
[09/25 21:37:56 visual_prompt]: Number of classes: 100 / 100
[09/25 21:37:56 visual_prompt]: Loading validation data...
[09/25 21:37:56 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[45000:45200], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/25 21:37:57 visual_prompt]: Number of images: 200
[09/25 21:37:57 visual_prompt]: Number of classes: 90 / 100
[09/25 21:37:57 visual_prompt]: Constructing models...
[09/25 21:38:03 visual_prompt]: Total Parameters: 86336356	 Gradient Parameters: 537700
[09/25 21:38:03 visual_prompt]: tuned percent:0.623
[09/25 21:38:29 visual_prompt]: Device used for model: 0
[09/25 21:38:29 visual_prompt]: Setting up Evaluator...
[09/25 21:38:29 visual_prompt]: Setting up Trainer...
[09/25 21:38:29 visual_prompt]: 	Setting up the optimizer...
[09/25 21:38:29 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/25 21:39:05 visual_prompt]: Epoch 1 / 100: avg data time: 2.18e-01, avg batch time: 2.6940, average train loss: 4.6589
[09/25 21:39:06 visual_prompt]: Inference (val):avg data time: 1.98e-05, avg batch time: 0.1748, average loss: 4.6218
[09/25 21:39:06 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 7.00	
[09/25 21:39:06 visual_prompt]: Best epoch 1: best metric: 0.010
[09/25 21:39:06 visual_prompt]: Training 2 / 100 epoch, with learning rate 5.0
[09/25 21:39:13 visual_prompt]: Epoch 2 / 100: avg data time: 5.64e-02, avg batch time: 0.4920, average train loss: 5.0188
[09/25 21:39:14 visual_prompt]: Inference (val):avg data time: 1.79e-05, avg batch time: 0.1644, average loss: 5.1582
[09/25 21:39:14 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 3.00	
[09/25 21:39:14 visual_prompt]: Best epoch 2: best metric: 0.015
[09/25 21:39:14 visual_prompt]: Training 3 / 100 epoch, with learning rate 10.0
[09/25 21:39:21 visual_prompt]: Epoch 3 / 100: avg data time: 5.90e-02, avg batch time: 0.4959, average train loss: 5.5064
[09/25 21:39:22 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1647, average loss: 6.3273
[09/25 21:39:22 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.00	
[09/25 21:39:22 visual_prompt]: Training 4 / 100 epoch, with learning rate 15.0
[09/25 21:39:29 visual_prompt]: Epoch 4 / 100: avg data time: 5.43e-02, avg batch time: 0.4924, average train loss: 8.7941
[09/25 21:39:30 visual_prompt]: Inference (val):avg data time: 1.77e-05, avg batch time: 0.1652, average loss: 8.7674
[09/25 21:39:30 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 6.00	
[09/25 21:39:30 visual_prompt]: Best epoch 4: best metric: 0.020
[09/25 21:39:30 visual_prompt]: Training 5 / 100 epoch, with learning rate 20.0
[09/25 21:39:37 visual_prompt]: Epoch 5 / 100: avg data time: 5.54e-02, avg batch time: 0.4970, average train loss: 14.0253
[09/25 21:39:38 visual_prompt]: Inference (val):avg data time: 1.52e-05, avg batch time: 0.1657, average loss: 16.4699
[09/25 21:39:38 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 5.50	
[09/25 21:39:38 visual_prompt]: Training 6 / 100 epoch, with learning rate 25.0
[09/25 21:39:45 visual_prompt]: Epoch 6 / 100: avg data time: 4.50e-02, avg batch time: 0.4860, average train loss: 25.6720
[09/25 21:39:46 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1663, average loss: 30.9956
[09/25 21:39:46 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 5.00	
[09/25 21:39:46 visual_prompt]: Training 7 / 100 epoch, with learning rate 30.0
[09/25 21:39:53 visual_prompt]: Epoch 7 / 100: avg data time: 5.82e-02, avg batch time: 0.5017, average train loss: 46.9957
[09/25 21:39:54 visual_prompt]: Inference (val):avg data time: 1.87e-05, avg batch time: 0.1670, average loss: 55.5380
[09/25 21:39:54 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 6.00	
[09/25 21:39:54 visual_prompt]: Training 8 / 100 epoch, with learning rate 35.0
[09/25 21:40:01 visual_prompt]: Epoch 8 / 100: avg data time: 5.77e-02, avg batch time: 0.5023, average train loss: 72.0352
[09/25 21:40:03 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1677, average loss: 78.9407
[09/25 21:40:03 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 7.00	
[09/25 21:40:03 visual_prompt]: Training 9 / 100 epoch, with learning rate 40.0
[09/25 21:40:09 visual_prompt]: Epoch 9 / 100: avg data time: 5.10e-02, avg batch time: 0.4967, average train loss: 98.9376
[09/25 21:40:11 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1684, average loss: 103.1513
[09/25 21:40:11 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 1.50	
[09/25 21:40:11 visual_prompt]: Training 10 / 100 epoch, with learning rate 45.0
[09/25 21:40:17 visual_prompt]: Epoch 10 / 100: avg data time: 5.26e-02, avg batch time: 0.5009, average train loss: 123.7639
[09/25 21:40:19 visual_prompt]: Inference (val):avg data time: 1.87e-05, avg batch time: 0.1689, average loss: 124.9058
[09/25 21:40:19 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 7.00	
[09/25 21:40:19 visual_prompt]: Training 11 / 100 epoch, with learning rate 50.0
[09/25 21:40:26 visual_prompt]: Epoch 11 / 100: avg data time: 5.51e-02, avg batch time: 0.5045, average train loss: 151.2211
[09/25 21:40:27 visual_prompt]: Inference (val):avg data time: 1.93e-05, avg batch time: 0.1699, average loss: 147.1017
[09/25 21:40:27 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.00	
[09/25 21:40:27 visual_prompt]: Training 12 / 100 epoch, with learning rate 49.9847706754774
[09/25 21:40:34 visual_prompt]: Epoch 12 / 100: avg data time: 5.07e-02, avg batch time: 0.5017, average train loss: 182.4975
[09/25 21:40:35 visual_prompt]: Inference (val):avg data time: 1.58e-05, avg batch time: 0.1706, average loss: 167.0507
[09/25 21:40:35 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 4.00	
[09/25 21:40:35 visual_prompt]: Training 13 / 100 epoch, with learning rate 49.939101256495604
[09/25 21:40:42 visual_prompt]: Epoch 13 / 100: avg data time: 4.81e-02, avg batch time: 0.5022, average train loss: 186.0578
[09/25 21:40:44 visual_prompt]: Inference (val):avg data time: 1.72e-05, avg batch time: 0.1711, average loss: 177.5197
[09/25 21:40:44 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.00	
[09/25 21:40:44 visual_prompt]: Training 14 / 100 epoch, with learning rate 49.86304738420683
[09/25 21:40:50 visual_prompt]: Epoch 14 / 100: avg data time: 5.52e-02, avg batch time: 0.5092, average train loss: 199.3054
[09/25 21:40:52 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1717, average loss: 203.5547
[09/25 21:40:52 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.00	
[09/25 21:40:52 visual_prompt]: Training 15 / 100 epoch, with learning rate 49.75670171853926
[09/25 21:40:59 visual_prompt]: Epoch 15 / 100: avg data time: 5.05e-02, avg batch time: 0.5057, average train loss: 211.3830
[09/25 21:41:00 visual_prompt]: Inference (val):avg data time: 1.98e-05, avg batch time: 0.1718, average loss: 207.1308
[09/25 21:41:00 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 4.00	
[09/25 21:41:00 visual_prompt]: Training 16 / 100 epoch, with learning rate 49.6201938253052
[09/25 21:41:07 visual_prompt]: Epoch 16 / 100: avg data time: 5.26e-02, avg batch time: 0.5074, average train loss: 216.5107
[09/25 21:41:08 visual_prompt]: Inference (val):avg data time: 1.81e-05, avg batch time: 0.1721, average loss: 214.4259
[09/25 21:41:08 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 4.00	
[09/25 21:41:08 visual_prompt]: Training 17 / 100 epoch, with learning rate 49.45369001834514
[09/25 21:41:15 visual_prompt]: Epoch 17 / 100: avg data time: 5.35e-02, avg batch time: 0.5089, average train loss: 230.3483
[09/25 21:41:17 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1720, average loss: 226.6146
[09/25 21:41:17 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 4.00	
[09/25 21:41:17 visual_prompt]: Training 18 / 100 epoch, with learning rate 49.25739315689991
[09/25 21:41:23 visual_prompt]: Epoch 18 / 100: avg data time: 5.07e-02, avg batch time: 0.5053, average train loss: 239.4993
[09/25 21:41:25 visual_prompt]: Inference (val):avg data time: 1.77e-05, avg batch time: 0.1715, average loss: 232.3206
[09/25 21:41:25 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.50	
[09/25 21:41:25 visual_prompt]: Training 19 / 100 epoch, with learning rate 49.03154239845797
[09/25 21:41:31 visual_prompt]: Epoch 19 / 100: avg data time: 3.93e-02, avg batch time: 0.4957, average train loss: 236.0934
[09/25 21:41:33 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1721, average loss: 244.8703
[09/25 21:41:33 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.00	
[09/25 21:41:33 visual_prompt]: Training 20 / 100 epoch, with learning rate 48.77641290737884
[09/25 21:41:40 visual_prompt]: Epoch 20 / 100: avg data time: 5.05e-02, avg batch time: 0.5060, average train loss: 228.6704
[09/25 21:41:41 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1717, average loss: 235.1021
[09/25 21:41:41 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 4.50	
[09/25 21:41:41 visual_prompt]: Training 21 / 100 epoch, with learning rate 48.49231551964771
[09/25 21:41:48 visual_prompt]: Epoch 21 / 100: avg data time: 4.84e-02, avg batch time: 0.5026, average train loss: 228.0151
[09/25 21:41:49 visual_prompt]: Inference (val):avg data time: 1.60e-05, avg batch time: 0.1715, average loss: 231.0421
[09/25 21:41:49 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.00	top5: 4.00	
[09/25 21:41:49 visual_prompt]: Training 22 / 100 epoch, with learning rate 48.17959636416968
[09/25 21:41:56 visual_prompt]: Epoch 22 / 100: avg data time: 5.34e-02, avg batch time: 0.5069, average train loss: 236.4072
[09/25 21:41:58 visual_prompt]: Inference (val):avg data time: 1.73e-05, avg batch time: 0.1710, average loss: 242.2441
[09/25 21:41:58 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 6.00	
[09/25 21:41:58 visual_prompt]: Training 23 / 100 epoch, with learning rate 47.83863644106502
[09/25 21:42:04 visual_prompt]: Epoch 23 / 100: avg data time: 5.57e-02, avg batch time: 0.5085, average train loss: 232.4504
[09/25 21:42:06 visual_prompt]: Inference (val):avg data time: 1.81e-05, avg batch time: 0.1710, average loss: 233.8584
[09/25 21:42:06 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.50	
[09/25 21:42:06 visual_prompt]: Training 24 / 100 epoch, with learning rate 47.46985115747918
[09/25 21:42:13 visual_prompt]: Epoch 24 / 100: avg data time: 4.93e-02, avg batch time: 0.5022, average train loss: 241.5269
[09/25 21:42:14 visual_prompt]: Inference (val):avg data time: 1.66e-05, avg batch time: 0.1711, average loss: 246.5184
[09/25 21:42:14 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 3.50	
[09/25 21:42:14 visual_prompt]: Training 25 / 100 epoch, with learning rate 47.073689821473174
[09/25 21:42:21 visual_prompt]: Epoch 25 / 100: avg data time: 5.52e-02, avg batch time: 0.5075, average train loss: 233.7058
[09/25 21:42:22 visual_prompt]: Inference (val):avg data time: 1.75e-05, avg batch time: 0.1706, average loss: 211.6953
[09/25 21:42:22 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 4.00	
[09/25 21:42:22 visual_prompt]: Training 26 / 100 epoch, with learning rate 46.65063509461097
[09/25 21:42:29 visual_prompt]: Epoch 26 / 100: avg data time: 5.38e-02, avg batch time: 0.5056, average train loss: 226.4865
[09/25 21:42:31 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1703, average loss: 201.2443
[09/25 21:42:31 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 7.00	
[09/25 21:42:31 visual_prompt]: Training 27 / 100 epoch, with learning rate 46.20120240391065
[09/25 21:42:37 visual_prompt]: Epoch 27 / 100: avg data time: 5.46e-02, avg batch time: 0.5063, average train loss: 215.8560
[09/25 21:42:39 visual_prompt]: Inference (val):avg data time: 2.08e-05, avg batch time: 0.1703, average loss: 207.1371
[09/25 21:42:39 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 4.50	
[09/25 21:42:39 visual_prompt]: Training 28 / 100 epoch, with learning rate 45.72593931387604
[09/25 21:42:46 visual_prompt]: Epoch 28 / 100: avg data time: 5.67e-02, avg batch time: 0.5070, average train loss: 217.6584
[09/25 21:42:47 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1700, average loss: 218.1724
[09/25 21:42:47 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 7.00	
[09/25 21:42:47 visual_prompt]: Training 29 / 100 epoch, with learning rate 45.22542485937369
[09/25 21:42:54 visual_prompt]: Epoch 29 / 100: avg data time: 5.79e-02, avg batch time: 0.5073, average train loss: 223.4960
[09/25 21:42:55 visual_prompt]: Inference (val):avg data time: 1.97e-05, avg batch time: 0.1700, average loss: 202.2189
[09/25 21:42:55 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 4.50	
[09/25 21:42:55 visual_prompt]: Training 30 / 100 epoch, with learning rate 44.70026884016804
[09/25 21:43:02 visual_prompt]: Epoch 30 / 100: avg data time: 3.94e-02, avg batch time: 0.4895, average train loss: 196.2670
[09/25 21:43:03 visual_prompt]: Inference (val):avg data time: 1.97e-05, avg batch time: 0.1695, average loss: 182.5303
[09/25 21:43:03 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.50	
[09/25 21:43:03 visual_prompt]: Training 31 / 100 epoch, with learning rate 44.15111107797445
[09/25 21:43:10 visual_prompt]: Epoch 31 / 100: avg data time: 4.77e-02, avg batch time: 0.4985, average train loss: 188.4181
[09/25 21:43:11 visual_prompt]: Inference (val):avg data time: 1.74e-05, avg batch time: 0.1693, average loss: 179.5924
[09/25 21:43:11 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 3.50	
[09/25 21:43:11 visual_prompt]: Training 32 / 100 epoch, with learning rate 43.57862063693486
[09/25 21:43:18 visual_prompt]: Epoch 32 / 100: avg data time: 5.23e-02, avg batch time: 0.5014, average train loss: 182.9257
[09/25 21:43:20 visual_prompt]: Inference (val):avg data time: 1.72e-05, avg batch time: 0.1687, average loss: 186.9637
[09/25 21:43:20 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 3.50	
[09/25 21:43:20 visual_prompt]: Training 33 / 100 epoch, with learning rate 42.98349500846628
[09/25 21:43:26 visual_prompt]: Epoch 33 / 100: avg data time: 5.40e-02, avg batch time: 0.5021, average train loss: 183.1717
[09/25 21:43:28 visual_prompt]: Inference (val):avg data time: 1.78e-05, avg batch time: 0.1688, average loss: 194.5661
[09/25 21:43:28 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 7.50	
[09/25 21:43:28 visual_prompt]: Training 34 / 100 epoch, with learning rate 42.36645926147493
[09/25 21:43:35 visual_prompt]: Epoch 34 / 100: avg data time: 5.43e-02, avg batch time: 0.5018, average train loss: 195.0189
[09/25 21:43:36 visual_prompt]: Inference (val):avg data time: 1.60e-05, avg batch time: 0.1683, average loss: 185.8724
[09/25 21:43:36 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.00	
[09/25 21:43:36 visual_prompt]: Training 35 / 100 epoch, with learning rate 41.72826515897145
[09/25 21:43:43 visual_prompt]: Epoch 35 / 100: avg data time: 5.68e-02, avg batch time: 0.5053, average train loss: 179.1332
[09/25 21:43:44 visual_prompt]: Inference (val):avg data time: 1.89e-05, avg batch time: 0.1684, average loss: 194.4747
[09/25 21:43:44 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 6.50	
[09/25 21:43:44 visual_prompt]: Training 36 / 100 epoch, with learning rate 41.06969024216348
[09/25 21:43:51 visual_prompt]: Epoch 36 / 100: avg data time: 4.76e-02, avg batch time: 0.4948, average train loss: 177.7253
[09/25 21:43:52 visual_prompt]: Inference (val):avg data time: 1.79e-05, avg batch time: 0.1682, average loss: 182.5168
[09/25 21:43:52 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.00	top5: 4.50	
[09/25 21:43:52 visual_prompt]: Training 37 / 100 epoch, with learning rate 40.391536883141455
[09/25 21:43:59 visual_prompt]: Epoch 37 / 100: avg data time: 5.36e-02, avg batch time: 0.4999, average train loss: 198.9976
[09/25 21:44:00 visual_prompt]: Inference (val):avg data time: 1.78e-05, avg batch time: 0.1682, average loss: 203.6805
[09/25 21:44:00 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 4.00	
[09/25 21:44:00 visual_prompt]: Training 38 / 100 epoch, with learning rate 39.69463130731183
[09/25 21:44:07 visual_prompt]: Epoch 38 / 100: avg data time: 5.07e-02, avg batch time: 0.4968, average train loss: 193.6496
[09/25 21:44:09 visual_prompt]: Inference (val):avg data time: 1.70e-05, avg batch time: 0.1678, average loss: 184.5784
[09/25 21:44:09 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 4.00	
[09/25 21:44:09 visual_prompt]: Training 39 / 100 epoch, with learning rate 38.97982258676867
[09/25 21:44:15 visual_prompt]: Epoch 39 / 100: avg data time: 5.69e-02, avg batch time: 0.5018, average train loss: 201.4827
[09/25 21:44:17 visual_prompt]: Inference (val):avg data time: 1.79e-05, avg batch time: 0.1681, average loss: 178.8327
[09/25 21:44:17 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 6.00	
[09/25 21:44:17 visual_prompt]: Training 40 / 100 epoch, with learning rate 38.24798160583012
[09/25 21:44:23 visual_prompt]: Epoch 40 / 100: avg data time: 5.23e-02, avg batch time: 0.4971, average train loss: 171.3875
[09/25 21:44:25 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1675, average loss: 174.2939
[09/25 21:44:25 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 4.00	
[09/25 21:44:25 visual_prompt]: Training 41 / 100 epoch, with learning rate 37.5
[09/25 21:44:31 visual_prompt]: Epoch 41 / 100: avg data time: 5.08e-02, avg batch time: 0.4960, average train loss: 163.9614
[09/25 21:44:33 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.1676, average loss: 176.9280
[09/25 21:44:33 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 4.00	
[09/25 21:44:33 visual_prompt]: Training 42 / 100 epoch, with learning rate 36.736789069647266
[09/25 21:44:39 visual_prompt]: Epoch 42 / 100: avg data time: 4.40e-02, avg batch time: 0.4901, average train loss: 169.2974
[09/25 21:44:41 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1676, average loss: 168.5464
[09/25 21:44:41 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 5.00	
[09/25 21:44:41 visual_prompt]: Training 43 / 100 epoch, with learning rate 35.959278669726935
[09/25 21:44:48 visual_prompt]: Epoch 43 / 100: avg data time: 5.93e-02, avg batch time: 0.5034, average train loss: 175.5669
[09/25 21:44:49 visual_prompt]: Inference (val):avg data time: 1.80e-05, avg batch time: 0.1673, average loss: 158.8502
[09/25 21:44:49 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 6.50	
[09/25 21:44:49 visual_prompt]: Training 44 / 100 epoch, with learning rate 35.16841607689501
[09/25 21:44:56 visual_prompt]: Epoch 44 / 100: avg data time: 5.33e-02, avg batch time: 0.4983, average train loss: 182.0492
[09/25 21:44:57 visual_prompt]: Inference (val):avg data time: 1.78e-05, avg batch time: 0.1674, average loss: 161.0866
[09/25 21:44:57 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 8.50	
[09/25 21:44:57 visual_prompt]: Training 45 / 100 epoch, with learning rate 34.365164835397806
[09/25 21:45:04 visual_prompt]: Epoch 45 / 100: avg data time: 4.15e-02, avg batch time: 0.4885, average train loss: 164.7299
[09/25 21:45:05 visual_prompt]: Inference (val):avg data time: 1.94e-05, avg batch time: 0.1673, average loss: 140.7424
[09/25 21:45:05 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 4.00	
[09/25 21:45:05 visual_prompt]: Training 46 / 100 epoch, with learning rate 33.55050358314172
[09/25 21:45:12 visual_prompt]: Epoch 46 / 100: avg data time: 4.51e-02, avg batch time: 0.4882, average train loss: 143.1012
[09/25 21:45:13 visual_prompt]: Inference (val):avg data time: 1.81e-05, avg batch time: 0.1671, average loss: 129.4061
[09/25 21:45:13 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.00	top5: 5.50	
[09/25 21:45:13 visual_prompt]: Training 47 / 100 epoch, with learning rate 32.72542485937369
[09/25 21:45:20 visual_prompt]: Epoch 47 / 100: avg data time: 5.53e-02, avg batch time: 0.4988, average train loss: 131.0529
[09/25 21:45:21 visual_prompt]: Inference (val):avg data time: 1.70e-05, avg batch time: 0.1669, average loss: 138.8407
[09/25 21:45:21 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.50	
[09/25 21:45:21 visual_prompt]: Training 48 / 100 epoch, with learning rate 31.89093389542498
[09/25 21:45:28 visual_prompt]: Epoch 48 / 100: avg data time: 5.60e-02, avg batch time: 0.4983, average train loss: 159.3096
[09/25 21:45:29 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.1669, average loss: 132.2513
[09/25 21:45:29 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.00	
[09/25 21:45:29 visual_prompt]: Training 49 / 100 epoch, with learning rate 31.04804738999169
[09/25 21:45:36 visual_prompt]: Epoch 49 / 100: avg data time: 5.38e-02, avg batch time: 0.4970, average train loss: 139.6071
[09/25 21:45:37 visual_prompt]: Inference (val):avg data time: 1.75e-05, avg batch time: 0.1667, average loss: 138.6932
[09/25 21:45:37 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 6.50	
[09/25 21:45:37 visual_prompt]: Training 50 / 100 epoch, with learning rate 30.19779227044398
[09/25 21:45:44 visual_prompt]: Epoch 50 / 100: avg data time: 5.86e-02, avg batch time: 0.5007, average train loss: 143.9634
[09/25 21:45:46 visual_prompt]: Inference (val):avg data time: 1.64e-05, avg batch time: 0.1664, average loss: 142.5181
[09/25 21:45:46 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 9.00	
[09/25 21:45:46 visual_prompt]: Training 51 / 100 epoch, with learning rate 29.341204441673263
[09/25 21:45:52 visual_prompt]: Epoch 51 / 100: avg data time: 5.65e-02, avg batch time: 0.4990, average train loss: 141.3429
[09/25 21:45:54 visual_prompt]: Inference (val):avg data time: 1.69e-05, avg batch time: 0.1665, average loss: 137.8725
[09/25 21:45:54 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.00	
[09/25 21:45:54 visual_prompt]: Training 52 / 100 epoch, with learning rate 28.479327524001636
[09/25 21:46:00 visual_prompt]: Epoch 52 / 100: avg data time: 5.04e-02, avg batch time: 0.4937, average train loss: 139.7156
[09/25 21:46:02 visual_prompt]: Inference (val):avg data time: 1.70e-05, avg batch time: 0.1668, average loss: 143.2728
[09/25 21:46:02 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 4.00	
[09/25 21:46:02 visual_prompt]: Training 53 / 100 epoch, with learning rate 27.61321158169134
[09/25 21:46:08 visual_prompt]: Epoch 53 / 100: avg data time: 5.15e-02, avg batch time: 0.4937, average train loss: 139.5181
[09/25 21:46:10 visual_prompt]: Inference (val):avg data time: 1.79e-05, avg batch time: 0.1664, average loss: 137.1027
[09/25 21:46:10 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.50	
[09/25 21:46:10 visual_prompt]: Training 54 / 100 epoch, with learning rate 26.74391184360313
[09/25 21:46:16 visual_prompt]: Epoch 54 / 100: avg data time: 5.21e-02, avg batch time: 0.4937, average train loss: 129.8101
[09/25 21:46:18 visual_prompt]: Inference (val):avg data time: 1.85e-05, avg batch time: 0.1664, average loss: 124.6785
[09/25 21:46:18 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 6.00	
[09/25 21:46:18 visual_prompt]: Training 55 / 100 epoch, with learning rate 25.872487417562528
[09/25 21:46:24 visual_prompt]: Epoch 55 / 100: avg data time: 5.06e-02, avg batch time: 0.4922, average train loss: 121.7500
[09/25 21:46:26 visual_prompt]: Inference (val):avg data time: 1.97e-05, avg batch time: 0.1663, average loss: 138.8731
[09/25 21:46:26 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 3.00	
[09/25 21:46:26 visual_prompt]: Training 56 / 100 epoch, with learning rate 25.0
[09/25 21:46:32 visual_prompt]: Epoch 56 / 100: avg data time: 3.77e-02, avg batch time: 0.4820, average train loss: 122.2028
[09/25 21:46:34 visual_prompt]: Inference (val):avg data time: 1.81e-05, avg batch time: 0.1663, average loss: 115.3045
[09/25 21:46:34 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.00	top5: 3.00	
[09/25 21:46:34 visual_prompt]: Training 57 / 100 epoch, with learning rate 24.127512582437483
[09/25 21:46:40 visual_prompt]: Epoch 57 / 100: avg data time: 4.55e-02, avg batch time: 0.4880, average train loss: 109.3811
[09/25 21:46:42 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1664, average loss: 102.4545
[09/25 21:46:42 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 8.00	
[09/25 21:46:42 visual_prompt]: Training 58 / 100 epoch, with learning rate 23.256088156396867
[09/25 21:46:48 visual_prompt]: Epoch 58 / 100: avg data time: 5.75e-02, avg batch time: 0.5001, average train loss: 97.3230
[09/25 21:46:50 visual_prompt]: Inference (val):avg data time: 1.70e-05, avg batch time: 0.1661, average loss: 99.8816
[09/25 21:46:50 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 6.00	
[09/25 21:46:50 visual_prompt]: Training 59 / 100 epoch, with learning rate 22.38678841830867
[09/25 21:46:56 visual_prompt]: Epoch 59 / 100: avg data time: 3.83e-02, avg batch time: 0.4808, average train loss: 93.2189
[09/25 21:46:58 visual_prompt]: Inference (val):avg data time: 1.70e-05, avg batch time: 0.1664, average loss: 96.9897
[09/25 21:46:58 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 4.50	
[09/25 21:46:58 visual_prompt]: Training 60 / 100 epoch, with learning rate 21.52067247599837
[09/25 21:47:04 visual_prompt]: Epoch 60 / 100: avg data time: 5.17e-02, avg batch time: 0.4946, average train loss: 83.2268
[09/25 21:47:06 visual_prompt]: Inference (val):avg data time: 1.84e-05, avg batch time: 0.1665, average loss: 80.1399
[09/25 21:47:06 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.00	top5: 2.50	
[09/25 21:47:06 visual_prompt]: Training 61 / 100 epoch, with learning rate 20.65879555832674
[09/25 21:47:13 visual_prompt]: Epoch 61 / 100: avg data time: 5.58e-02, avg batch time: 0.4975, average train loss: 73.1277
[09/25 21:47:14 visual_prompt]: Inference (val):avg data time: 1.73e-05, avg batch time: 0.1662, average loss: 67.1211
[09/25 21:47:14 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.00	
[09/25 21:47:14 visual_prompt]: Training 62 / 100 epoch, with learning rate 19.80220772955602
[09/25 21:47:21 visual_prompt]: Epoch 62 / 100: avg data time: 5.19e-02, avg batch time: 0.4948, average train loss: 65.0197
[09/25 21:47:22 visual_prompt]: Inference (val):avg data time: 1.65e-05, avg batch time: 0.1661, average loss: 70.0376
[09/25 21:47:22 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 5.00	
[09/25 21:47:22 visual_prompt]: Training 63 / 100 epoch, with learning rate 18.95195261000831
[09/25 21:47:29 visual_prompt]: Epoch 63 / 100: avg data time: 5.05e-02, avg batch time: 0.4920, average train loss: 60.7401
[09/25 21:47:30 visual_prompt]: Inference (val):avg data time: 1.75e-05, avg batch time: 0.1661, average loss: 62.5836
[09/25 21:47:30 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 4.00	
[09/25 21:47:30 visual_prompt]: Training 64 / 100 epoch, with learning rate 18.10906610457502
[09/25 21:47:37 visual_prompt]: Epoch 64 / 100: avg data time: 5.41e-02, avg batch time: 0.4955, average train loss: 68.5369
[09/25 21:47:38 visual_prompt]: Inference (val):avg data time: 1.78e-05, avg batch time: 0.1664, average loss: 55.4281
[09/25 21:47:38 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.50	
[09/25 21:47:38 visual_prompt]: Training 65 / 100 epoch, with learning rate 17.274575140626318
[09/25 21:47:45 visual_prompt]: Epoch 65 / 100: avg data time: 3.98e-02, avg batch time: 0.4823, average train loss: 57.5761
[09/25 21:47:46 visual_prompt]: Inference (val):avg data time: 1.97e-05, avg batch time: 0.1662, average loss: 57.5546
[09/25 21:47:46 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 6.00	
[09/25 21:47:46 visual_prompt]: Training 66 / 100 epoch, with learning rate 16.449496416858285
[09/25 21:47:53 visual_prompt]: Epoch 66 / 100: avg data time: 5.87e-02, avg batch time: 0.5014, average train loss: 56.8351
[09/25 21:47:54 visual_prompt]: Inference (val):avg data time: 1.85e-05, avg batch time: 0.1660, average loss: 54.9486
[09/25 21:47:54 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 6.50	
[09/25 21:47:54 visual_prompt]: Training 67 / 100 epoch, with learning rate 15.634835164602197
[09/25 21:48:01 visual_prompt]: Epoch 67 / 100: avg data time: 5.26e-02, avg batch time: 0.4944, average train loss: 55.1034
[09/25 21:48:02 visual_prompt]: Inference (val):avg data time: 1.69e-05, avg batch time: 0.1658, average loss: 50.6478
[09/25 21:48:02 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 3.00	
[09/25 21:48:02 visual_prompt]: Training 68 / 100 epoch, with learning rate 14.831583923104999
[09/25 21:48:09 visual_prompt]: Epoch 68 / 100: avg data time: 4.87e-02, avg batch time: 0.4905, average train loss: 53.0136
[09/25 21:48:10 visual_prompt]: Inference (val):avg data time: 1.63e-05, avg batch time: 0.1661, average loss: 49.5742
[09/25 21:48:10 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 4.00	
[09/25 21:48:10 visual_prompt]: Training 69 / 100 epoch, with learning rate 14.040721330273062
[09/25 21:48:17 visual_prompt]: Epoch 69 / 100: avg data time: 5.00e-02, avg batch time: 0.4918, average train loss: 50.4079
[09/25 21:48:18 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1661, average loss: 48.9214
[09/25 21:48:18 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.00	
[09/25 21:48:18 visual_prompt]: Training 70 / 100 epoch, with learning rate 13.263210930352736
[09/25 21:48:25 visual_prompt]: Epoch 70 / 100: avg data time: 5.12e-02, avg batch time: 0.4925, average train loss: 47.2136
[09/25 21:48:26 visual_prompt]: Inference (val):avg data time: 1.58e-05, avg batch time: 0.1661, average loss: 42.7956
[09/25 21:48:26 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 4.00	
[09/25 21:48:26 visual_prompt]: Training 71 / 100 epoch, with learning rate 12.500000000000005
[09/25 21:48:33 visual_prompt]: Epoch 71 / 100: avg data time: 5.37e-02, avg batch time: 0.4948, average train loss: 42.8284
[09/25 21:48:34 visual_prompt]: Inference (val):avg data time: 1.90e-05, avg batch time: 0.1662, average loss: 36.5584
[09/25 21:48:34 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 4.50	
[09/25 21:48:34 visual_prompt]: Training 72 / 100 epoch, with learning rate 11.75201839416988
[09/25 21:48:41 visual_prompt]: Epoch 72 / 100: avg data time: 5.81e-02, avg batch time: 0.4994, average train loss: 37.9752
[09/25 21:48:42 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1663, average loss: 33.8375
[09/25 21:48:42 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.50	
[09/25 21:48:42 visual_prompt]: Training 73 / 100 epoch, with learning rate 11.020177413231332
[09/25 21:48:49 visual_prompt]: Epoch 73 / 100: avg data time: 4.41e-02, avg batch time: 0.4881, average train loss: 35.2395
[09/25 21:48:50 visual_prompt]: Inference (val):avg data time: 1.69e-05, avg batch time: 0.1661, average loss: 31.4118
[09/25 21:48:50 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 2.50	
[09/25 21:48:50 visual_prompt]: Training 74 / 100 epoch, with learning rate 10.305368692688175
[09/25 21:48:57 visual_prompt]: Epoch 74 / 100: avg data time: 5.70e-02, avg batch time: 0.4978, average train loss: 32.7002
[09/25 21:48:59 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1660, average loss: 25.6715
[09/25 21:48:59 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 3.50	
[09/25 21:48:59 visual_prompt]: Training 75 / 100 epoch, with learning rate 9.608463116858543
[09/25 21:49:05 visual_prompt]: Epoch 75 / 100: avg data time: 4.75e-02, avg batch time: 0.4906, average train loss: 30.2710
[09/25 21:49:07 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1662, average loss: 24.8343
[09/25 21:49:07 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 6.00	
[09/25 21:49:07 visual_prompt]: Training 76 / 100 epoch, with learning rate 8.930309757836516
[09/25 21:49:13 visual_prompt]: Epoch 76 / 100: avg data time: 5.17e-02, avg batch time: 0.4925, average train loss: 26.2189
[09/25 21:49:15 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.1659, average loss: 23.3784
[09/25 21:49:15 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 8.00	
[09/25 21:49:15 visual_prompt]: Training 77 / 100 epoch, with learning rate 8.271734841028552
[09/25 21:49:21 visual_prompt]: Epoch 77 / 100: avg data time: 4.71e-02, avg batch time: 0.4886, average train loss: 22.6183
[09/25 21:49:23 visual_prompt]: Inference (val):avg data time: 1.81e-05, avg batch time: 0.1661, average loss: 19.6138
[09/25 21:49:23 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.50	
[09/25 21:49:23 visual_prompt]: Training 78 / 100 epoch, with learning rate 7.633540738525066
[09/25 21:49:29 visual_prompt]: Epoch 78 / 100: avg data time: 5.92e-02, avg batch time: 0.5004, average train loss: 19.0304
[09/25 21:49:31 visual_prompt]: Inference (val):avg data time: 1.98e-05, avg batch time: 0.1663, average loss: 18.4877
[09/25 21:49:31 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.00	
[09/25 21:49:31 visual_prompt]: Training 79 / 100 epoch, with learning rate 7.016504991533726
[09/25 21:49:37 visual_prompt]: Epoch 79 / 100: avg data time: 5.13e-02, avg batch time: 0.4937, average train loss: 17.6741
[09/25 21:49:39 visual_prompt]: Inference (val):avg data time: 1.86e-05, avg batch time: 0.1661, average loss: 16.5520
[09/25 21:49:39 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 5.50	
[09/25 21:49:39 visual_prompt]: Training 80 / 100 epoch, with learning rate 6.4213793630651415
[09/25 21:49:46 visual_prompt]: Epoch 80 / 100: avg data time: 5.69e-02, avg batch time: 0.4985, average train loss: 15.9521
[09/25 21:49:47 visual_prompt]: Inference (val):avg data time: 1.82e-05, avg batch time: 0.1659, average loss: 13.6668
[09/25 21:49:47 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 7.50	
[09/25 21:49:47 visual_prompt]: Training 81 / 100 epoch, with learning rate 5.848888922025552
[09/25 21:49:54 visual_prompt]: Epoch 81 / 100: avg data time: 4.93e-02, avg batch time: 0.4912, average train loss: 13.2496
[09/25 21:49:55 visual_prompt]: Inference (val):avg data time: 1.82e-05, avg batch time: 0.1661, average loss: 10.6092
[09/25 21:49:55 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 3.50	
[09/25 21:49:55 visual_prompt]: Training 82 / 100 epoch, with learning rate 5.2997311598319525
[09/25 21:50:02 visual_prompt]: Epoch 82 / 100: avg data time: 5.11e-02, avg batch time: 0.4926, average train loss: 11.4503
[09/25 21:50:03 visual_prompt]: Inference (val):avg data time: 1.90e-05, avg batch time: 0.1662, average loss: 9.3131
[09/25 21:50:03 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 5.00	
[09/25 21:50:03 visual_prompt]: Training 83 / 100 epoch, with learning rate 4.774575140626316
[09/25 21:50:10 visual_prompt]: Epoch 83 / 100: avg data time: 5.31e-02, avg batch time: 0.4941, average train loss: 9.8251
[09/25 21:50:11 visual_prompt]: Inference (val):avg data time: 1.98e-05, avg batch time: 0.1658, average loss: 8.7787
[09/25 21:50:11 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.50	
[09/25 21:50:11 visual_prompt]: Training 84 / 100 epoch, with learning rate 4.27406068612396
[09/25 21:50:18 visual_prompt]: Epoch 84 / 100: avg data time: 5.21e-02, avg batch time: 0.4942, average train loss: 9.0442
[09/25 21:50:19 visual_prompt]: Inference (val):avg data time: 1.84e-05, avg batch time: 0.1663, average loss: 8.0839
[09/25 21:50:19 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.00	
[09/25 21:50:19 visual_prompt]: Training 85 / 100 epoch, with learning rate 3.798797596089351
[09/25 21:50:26 visual_prompt]: Epoch 85 / 100: avg data time: 5.38e-02, avg batch time: 0.4956, average train loss: 8.2226
[09/25 21:50:27 visual_prompt]: Inference (val):avg data time: 1.89e-05, avg batch time: 0.1663, average loss: 7.5877
[09/25 21:50:27 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 6.00	
[09/25 21:50:27 visual_prompt]: Training 86 / 100 epoch, with learning rate 3.349364905389032
[09/25 21:50:34 visual_prompt]: Epoch 86 / 100: avg data time: 5.23e-02, avg batch time: 0.4935, average train loss: 7.6275
[09/25 21:50:35 visual_prompt]: Inference (val):avg data time: 1.99e-05, avg batch time: 0.1663, average loss: 7.2803
[09/25 21:50:35 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 3.00	
[09/25 21:50:35 visual_prompt]: Training 87 / 100 epoch, with learning rate 2.9263101785268253
[09/25 21:50:42 visual_prompt]: Epoch 87 / 100: avg data time: 5.63e-02, avg batch time: 0.4984, average train loss: 7.1089
[09/25 21:50:44 visual_prompt]: Inference (val):avg data time: 1.82e-05, avg batch time: 0.1663, average loss: 6.7765
[09/25 21:50:44 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 2.50	
[09/25 21:50:44 visual_prompt]: Training 88 / 100 epoch, with learning rate 2.5301488425208296
[09/25 21:50:50 visual_prompt]: Epoch 88 / 100: avg data time: 5.68e-02, avg batch time: 0.4979, average train loss: 6.8614
[09/25 21:50:52 visual_prompt]: Inference (val):avg data time: 1.63e-05, avg batch time: 0.1661, average loss: 6.6826
[09/25 21:50:52 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 5.50	
[09/25 21:50:52 visual_prompt]: Training 89 / 100 epoch, with learning rate 2.1613635589349753
[09/25 21:50:58 visual_prompt]: Epoch 89 / 100: avg data time: 4.98e-02, avg batch time: 0.4924, average train loss: 6.7130
[09/25 21:51:00 visual_prompt]: Inference (val):avg data time: 1.80e-05, avg batch time: 0.1660, average loss: 6.6606
[09/25 21:51:00 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.50	
[09/25 21:51:00 visual_prompt]: Training 90 / 100 epoch, with learning rate 1.820403635830317
[09/25 21:51:06 visual_prompt]: Epoch 90 / 100: avg data time: 4.98e-02, avg batch time: 0.4917, average train loss: 6.5981
[09/25 21:51:08 visual_prompt]: Inference (val):avg data time: 1.69e-05, avg batch time: 0.1656, average loss: 6.4460
[09/25 21:51:08 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.00	
[09/25 21:51:08 visual_prompt]: Training 91 / 100 epoch, with learning rate 1.507684480352292
[09/25 21:51:14 visual_prompt]: Epoch 91 / 100: avg data time: 5.13e-02, avg batch time: 0.4921, average train loss: 6.3673
[09/25 21:51:16 visual_prompt]: Inference (val):avg data time: 1.86e-05, avg batch time: 0.1661, average loss: 6.3227
[09/25 21:51:16 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/25 21:51:16 visual_prompt]: Training 92 / 100 epoch, with learning rate 1.2235870926211616
[09/25 21:51:22 visual_prompt]: Epoch 92 / 100: avg data time: 4.66e-02, avg batch time: 0.4880, average train loss: 6.2349
[09/25 21:51:24 visual_prompt]: Inference (val):avg data time: 1.81e-05, avg batch time: 0.1663, average loss: 6.2379
[09/25 21:51:24 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 5.50	
[09/25 21:51:24 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.9684576015420276
[09/25 21:51:30 visual_prompt]: Epoch 93 / 100: avg data time: 5.43e-02, avg batch time: 0.4956, average train loss: 6.2077
[09/25 21:51:32 visual_prompt]: Inference (val):avg data time: 1.62e-05, avg batch time: 0.1661, average loss: 6.2914
[09/25 21:51:32 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.00	
[09/25 21:51:32 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.7426068431000882
[09/25 21:51:39 visual_prompt]: Epoch 94 / 100: avg data time: 5.86e-02, avg batch time: 0.4995, average train loss: 6.1310
[09/25 21:51:40 visual_prompt]: Inference (val):avg data time: 1.67e-05, avg batch time: 0.1660, average loss: 6.1844
[09/25 21:51:40 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.00	
[09/25 21:51:40 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.5463099816548578
[09/25 21:51:47 visual_prompt]: Epoch 95 / 100: avg data time: 5.26e-02, avg batch time: 0.4930, average train loss: 6.0795
[09/25 21:51:48 visual_prompt]: Inference (val):avg data time: 1.58e-05, avg batch time: 0.1657, average loss: 6.1926
[09/25 21:51:48 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.00	
[09/25 21:51:48 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.3798061746947995
[09/25 21:51:55 visual_prompt]: Epoch 96 / 100: avg data time: 5.68e-02, avg batch time: 0.4972, average train loss: 6.0423
[09/25 21:51:56 visual_prompt]: Inference (val):avg data time: 1.73e-05, avg batch time: 0.1658, average loss: 6.1503
[09/25 21:51:56 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.00	
[09/25 21:51:56 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.24329828146074095
[09/25 21:52:03 visual_prompt]: Epoch 97 / 100: avg data time: 5.68e-02, avg batch time: 0.4973, average train loss: 5.9953
[09/25 21:52:04 visual_prompt]: Inference (val):avg data time: 1.96e-05, avg batch time: 0.1659, average loss: 6.1316
[09/25 21:52:04 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.00	
[09/25 21:52:04 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.13695261579316775
[09/25 21:52:11 visual_prompt]: Epoch 98 / 100: avg data time: 5.01e-02, avg batch time: 0.4908, average train loss: 5.9482
[09/25 21:52:12 visual_prompt]: Inference (val):avg data time: 1.70e-05, avg batch time: 0.1657, average loss: 6.1080
[09/25 21:52:12 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 5.00	
[09/25 21:52:12 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.06089874350439506
[09/25 21:52:19 visual_prompt]: Epoch 99 / 100: avg data time: 4.87e-02, avg batch time: 0.4892, average train loss: 5.8967
[09/25 21:52:20 visual_prompt]: Inference (val):avg data time: 1.72e-05, avg batch time: 0.1659, average loss: 6.0889
[09/25 21:52:20 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/25 21:52:20 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.015229324522605947
[09/25 21:52:27 visual_prompt]: Epoch 100 / 100: avg data time: 5.27e-02, avg batch time: 0.4937, average train loss: 5.8546
[09/25 21:52:28 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1658, average loss: 6.0769
[09/25 21:52:28 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.00	
[09/25 21:52:28 visual_prompt]: Rank of current process: 0. World size: 1
[09/25 21:52:28 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/25 21:52:28 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-cifar(num_classes=100)', 'DATA.NUMBER_CLASSES', '100', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/25 21:52:28 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/25 21:52:28 visual_prompt]: Training with config:
[09/25 21:52:28 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-cifar(num_classes=100)/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr50.0_wd0.001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 50.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-cifar(num_classes=100)', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 100, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/25 21:52:28 visual_prompt]: Loading training data...
[09/25 21:52:28 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[:800], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/25 21:52:29 visual_prompt]: Number of images: 800
[09/25 21:52:29 visual_prompt]: Number of classes: 100 / 100
[09/25 21:52:29 visual_prompt]: Loading validation data...
[09/25 21:52:29 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[45000:45200], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/25 21:52:30 visual_prompt]: Number of images: 200
[09/25 21:52:30 visual_prompt]: Number of classes: 90 / 100
[09/25 21:52:30 visual_prompt]: Constructing models...
[09/25 21:52:32 visual_prompt]: Total Parameters: 86336356	 Gradient Parameters: 537700
[09/25 21:52:32 visual_prompt]: tuned percent:0.623
[09/25 21:52:32 visual_prompt]: Device used for model: 0
[09/25 21:52:32 visual_prompt]: Setting up Evaluator...
[09/25 21:52:32 visual_prompt]: Setting up Trainer...
[09/25 21:52:32 visual_prompt]: 	Setting up the optimizer...
[09/25 21:52:32 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/25 21:52:39 visual_prompt]: Epoch 1 / 100: avg data time: 5.30e-02, avg batch time: 0.4940, average train loss: 4.6565
[09/25 21:52:40 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1660, average loss: 4.6218
[09/25 21:52:40 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 7.00	
[09/25 21:52:40 visual_prompt]: Best epoch 1: best metric: 0.010
[09/25 21:52:40 visual_prompt]: Training 2 / 100 epoch, with learning rate 5.0
[09/25 21:52:47 visual_prompt]: Epoch 2 / 100: avg data time: 5.67e-02, avg batch time: 0.4983, average train loss: 4.9926
[09/25 21:52:49 visual_prompt]: Inference (val):avg data time: 1.97e-05, avg batch time: 0.1658, average loss: 5.4420
[09/25 21:52:49 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 6.50	
[09/25 21:52:49 visual_prompt]: Training 3 / 100 epoch, with learning rate 10.0
[09/25 21:52:55 visual_prompt]: Epoch 3 / 100: avg data time: 5.20e-02, avg batch time: 0.4921, average train loss: 5.9020
[09/25 21:52:57 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.1656, average loss: 6.2318
[09/25 21:52:57 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 5.50	
[09/25 21:52:57 visual_prompt]: Best epoch 3: best metric: 0.015
[09/25 21:52:57 visual_prompt]: Training 4 / 100 epoch, with learning rate 15.0
[09/25 21:53:03 visual_prompt]: Epoch 4 / 100: avg data time: 5.27e-02, avg batch time: 0.4936, average train loss: 8.7197
[09/25 21:53:05 visual_prompt]: Inference (val):avg data time: 1.96e-05, avg batch time: 0.1659, average loss: 8.2456
[09/25 21:53:05 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 4.00	
[09/25 21:53:05 visual_prompt]: Training 5 / 100 epoch, with learning rate 20.0
[09/25 21:53:12 visual_prompt]: Epoch 5 / 100: avg data time: 5.66e-02, avg batch time: 0.4979, average train loss: 21.5675
[09/25 21:53:13 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1656, average loss: 31.5863
[09/25 21:53:13 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.50	
[09/25 21:53:13 visual_prompt]: Training 6 / 100 epoch, with learning rate 25.0
[09/25 21:53:20 visual_prompt]: Epoch 6 / 100: avg data time: 4.61e-02, avg batch time: 0.4883, average train loss: 42.4354
[09/25 21:53:21 visual_prompt]: Inference (val):avg data time: 3.62e-05, avg batch time: 0.1659, average loss: 39.1774
[09/25 21:53:21 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 6.00	
[09/25 21:53:21 visual_prompt]: Training 7 / 100 epoch, with learning rate 30.0
[09/25 21:53:28 visual_prompt]: Epoch 7 / 100: avg data time: 4.38e-02, avg batch time: 0.4850, average train loss: 80.0717
[09/25 21:53:29 visual_prompt]: Inference (val):avg data time: 2.11e-05, avg batch time: 0.1662, average loss: 49.5151
[09/25 21:53:29 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.00	top5: 4.00	
[09/25 21:53:29 visual_prompt]: Training 8 / 100 epoch, with learning rate 35.0
[09/25 21:53:36 visual_prompt]: Epoch 8 / 100: avg data time: 5.90e-02, avg batch time: 0.4993, average train loss: 98.5078
[09/25 21:53:37 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.1662, average loss: 118.0460
[09/25 21:53:37 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.00	
[09/25 21:53:37 visual_prompt]: Training 9 / 100 epoch, with learning rate 40.0
[09/25 21:53:44 visual_prompt]: Epoch 9 / 100: avg data time: 5.22e-02, avg batch time: 0.4939, average train loss: 136.1840
[09/25 21:53:45 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1659, average loss: 174.8145
[09/25 21:53:45 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 7.00	
[09/25 21:53:45 visual_prompt]: Training 10 / 100 epoch, with learning rate 45.0
[09/25 21:53:52 visual_prompt]: Epoch 10 / 100: avg data time: 5.08e-02, avg batch time: 0.4927, average train loss: 149.5254
[09/25 21:53:54 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1660, average loss: 155.9444
[09/25 21:53:54 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 6.00	
[09/25 21:53:54 visual_prompt]: Training 11 / 100 epoch, with learning rate 50.0
[09/25 21:54:00 visual_prompt]: Epoch 11 / 100: avg data time: 5.28e-02, avg batch time: 0.4940, average train loss: 179.0079
[09/25 21:54:02 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1660, average loss: 183.5500
[09/25 21:54:02 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 3.50	
[09/25 21:54:02 visual_prompt]: Training 12 / 100 epoch, with learning rate 49.9847706754774
[09/25 21:54:08 visual_prompt]: Epoch 12 / 100: avg data time: 5.56e-02, avg batch time: 0.4980, average train loss: 180.3289
[09/25 21:54:10 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1659, average loss: 149.3932
[09/25 21:54:10 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 6.00	
[09/25 21:54:10 visual_prompt]: Training 13 / 100 epoch, with learning rate 49.939101256495604
[09/25 21:54:17 visual_prompt]: Epoch 13 / 100: avg data time: 5.33e-02, avg batch time: 0.4941, average train loss: 191.9172
[09/25 21:54:18 visual_prompt]: Inference (val):avg data time: 3.73e-05, avg batch time: 0.1658, average loss: 169.2719
[09/25 21:54:18 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/25 21:54:18 visual_prompt]: Training 14 / 100 epoch, with learning rate 49.86304738420683
[09/25 21:54:25 visual_prompt]: Epoch 14 / 100: avg data time: 5.99e-02, avg batch time: 0.5004, average train loss: 195.7584
[09/25 21:54:26 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1663, average loss: 182.2947
[09/25 21:54:26 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 9.00	
[09/25 21:54:26 visual_prompt]: Best epoch 14: best metric: 0.020
[09/25 21:54:26 visual_prompt]: Training 15 / 100 epoch, with learning rate 49.75670171853926
[09/25 21:54:33 visual_prompt]: Epoch 15 / 100: avg data time: 4.67e-02, avg batch time: 0.4894, average train loss: 223.3908
[09/25 21:54:34 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1662, average loss: 198.9942
[09/25 21:54:34 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 6.50	
[09/25 21:54:34 visual_prompt]: Training 16 / 100 epoch, with learning rate 49.6201938253052
[09/25 21:54:41 visual_prompt]: Epoch 16 / 100: avg data time: 5.94e-02, avg batch time: 0.5006, average train loss: 228.0623
[09/25 21:54:43 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1663, average loss: 223.8180
[09/25 21:54:43 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 5.50	
[09/25 21:54:43 visual_prompt]: Training 17 / 100 epoch, with learning rate 49.45369001834514
[09/25 21:54:49 visual_prompt]: Epoch 17 / 100: avg data time: 3.75e-02, avg batch time: 0.4812, average train loss: 263.7238
[09/25 21:54:51 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1661, average loss: 237.2317
[09/25 21:54:51 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.50	
[09/25 21:54:51 visual_prompt]: Training 18 / 100 epoch, with learning rate 49.25739315689991
[09/25 21:54:57 visual_prompt]: Epoch 18 / 100: avg data time: 5.14e-02, avg batch time: 0.4937, average train loss: 301.1401
[09/25 21:54:59 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1662, average loss: 278.2145
[09/25 21:54:59 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 7.00	
[09/25 21:54:59 visual_prompt]: Training 19 / 100 epoch, with learning rate 49.03154239845797
[09/25 21:55:06 visual_prompt]: Epoch 19 / 100: avg data time: 6.10e-02, avg batch time: 0.5018, average train loss: 240.4143
[09/25 21:55:07 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1659, average loss: 259.0198
[09/25 21:55:07 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.50	
[09/25 21:55:07 visual_prompt]: Training 20 / 100 epoch, with learning rate 48.77641290737884
[09/25 21:55:14 visual_prompt]: Epoch 20 / 100: avg data time: 5.24e-02, avg batch time: 0.4930, average train loss: 252.1419
[09/25 21:55:15 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1662, average loss: 265.3051
[09/25 21:55:15 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.00	top5: 3.50	
[09/25 21:55:15 visual_prompt]: Training 21 / 100 epoch, with learning rate 48.49231551964771
[09/25 21:55:22 visual_prompt]: Epoch 21 / 100: avg data time: 4.42e-02, avg batch time: 0.4866, average train loss: 237.9111
[09/25 21:55:23 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1661, average loss: 246.9788
[09/25 21:55:23 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 4.50	
[09/25 21:55:23 visual_prompt]: Training 22 / 100 epoch, with learning rate 48.17959636416968
[09/25 21:55:30 visual_prompt]: Epoch 22 / 100: avg data time: 5.65e-02, avg batch time: 0.4980, average train loss: 252.1076
[09/25 21:55:31 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1659, average loss: 212.0096
[09/25 21:55:31 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 4.50	
[09/25 21:55:31 visual_prompt]: Training 23 / 100 epoch, with learning rate 47.83863644106502
[09/25 21:55:38 visual_prompt]: Epoch 23 / 100: avg data time: 5.75e-02, avg batch time: 0.4975, average train loss: 208.6417
[09/25 21:55:40 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1658, average loss: 210.8975
[09/25 21:55:40 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 8.50	
[09/25 21:55:40 visual_prompt]: Training 24 / 100 epoch, with learning rate 47.46985115747918
[09/25 21:55:46 visual_prompt]: Epoch 24 / 100: avg data time: 4.62e-02, avg batch time: 0.4871, average train loss: 192.9635
[09/25 21:55:48 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1659, average loss: 212.7679
[09/25 21:55:48 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.00	
[09/25 21:55:48 visual_prompt]: Training 25 / 100 epoch, with learning rate 47.073689821473174
[09/25 21:55:54 visual_prompt]: Epoch 25 / 100: avg data time: 5.32e-02, avg batch time: 0.4940, average train loss: 206.8174
[09/25 21:55:56 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1660, average loss: 224.4795
[09/25 21:55:56 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 3.50	
[09/25 21:55:56 visual_prompt]: Training 26 / 100 epoch, with learning rate 46.65063509461097
[09/25 21:56:02 visual_prompt]: Epoch 26 / 100: avg data time: 4.68e-02, avg batch time: 0.4868, average train loss: 223.2671
[09/25 21:56:04 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1658, average loss: 231.9873
[09/25 21:56:04 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 5.00	
[09/25 21:56:04 visual_prompt]: Training 27 / 100 epoch, with learning rate 46.20120240391065
[09/25 21:56:10 visual_prompt]: Epoch 27 / 100: avg data time: 5.08e-02, avg batch time: 0.4913, average train loss: 245.0996
[09/25 21:56:12 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.1659, average loss: 221.9429
[09/25 21:56:12 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.00	
[09/25 21:56:12 visual_prompt]: Training 28 / 100 epoch, with learning rate 45.72593931387604
[09/25 21:56:18 visual_prompt]: Epoch 28 / 100: avg data time: 4.47e-02, avg batch time: 0.4871, average train loss: 232.8108
[09/25 21:56:20 visual_prompt]: Inference (val):avg data time: 1.99e-05, avg batch time: 0.1659, average loss: 226.5595
[09/25 21:56:20 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.00	
[09/25 21:56:20 visual_prompt]: Training 29 / 100 epoch, with learning rate 45.22542485937369
[09/25 21:56:26 visual_prompt]: Epoch 29 / 100: avg data time: 4.85e-02, avg batch time: 0.4888, average train loss: 223.3546
[09/25 21:56:28 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1657, average loss: 218.5943
[09/25 21:56:28 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.00	
[09/25 21:56:28 visual_prompt]: Training 30 / 100 epoch, with learning rate 44.70026884016804
[09/25 21:56:34 visual_prompt]: Epoch 30 / 100: avg data time: 4.91e-02, avg batch time: 0.4906, average train loss: 228.1772
[09/25 21:56:36 visual_prompt]: Inference (val):avg data time: 1.83e-05, avg batch time: 0.1660, average loss: 221.7402
[09/25 21:56:36 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 4.50	
[09/25 21:56:36 visual_prompt]: Training 31 / 100 epoch, with learning rate 44.15111107797445
[09/25 21:56:42 visual_prompt]: Epoch 31 / 100: avg data time: 4.07e-02, avg batch time: 0.4844, average train loss: 284.3345
[09/25 21:56:44 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1657, average loss: 223.3846
[09/25 21:56:44 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.00	
[09/25 21:56:44 visual_prompt]: Training 32 / 100 epoch, with learning rate 43.57862063693486
[09/25 21:56:51 visual_prompt]: Epoch 32 / 100: avg data time: 4.47e-02, avg batch time: 0.4860, average train loss: 241.5747
[09/25 21:56:52 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1659, average loss: 577.0507
[09/25 21:56:52 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 5.50	
[09/25 21:56:52 visual_prompt]: Training 33 / 100 epoch, with learning rate 42.98349500846628
[09/25 21:56:59 visual_prompt]: Epoch 33 / 100: avg data time: 5.77e-02, avg batch time: 0.4993, average train loss: 216.6511
[09/25 21:57:00 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1658, average loss: 193.5536
[09/25 21:57:00 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 7.00	
[09/25 21:57:00 visual_prompt]: Training 34 / 100 epoch, with learning rate 42.36645926147493
[09/25 21:57:07 visual_prompt]: Epoch 34 / 100: avg data time: 5.35e-02, avg batch time: 0.4943, average train loss: 221.5563
[09/25 21:57:08 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1659, average loss: 223.5531
[09/25 21:57:08 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.50	
[09/25 21:57:08 visual_prompt]: Training 35 / 100 epoch, with learning rate 41.72826515897145
[09/25 21:57:15 visual_prompt]: Epoch 35 / 100: avg data time: 5.55e-02, avg batch time: 0.4955, average train loss: 185.4675
[09/25 21:57:16 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1659, average loss: 180.7400
[09/25 21:57:16 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 4.50	
[09/25 21:57:16 visual_prompt]: Training 36 / 100 epoch, with learning rate 41.06969024216348
[09/25 21:57:23 visual_prompt]: Epoch 36 / 100: avg data time: 5.64e-02, avg batch time: 0.4977, average train loss: 192.9080
[09/25 21:57:25 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1658, average loss: 181.1334
[09/25 21:57:25 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.00	top5: 3.00	
[09/25 21:57:25 visual_prompt]: Training 37 / 100 epoch, with learning rate 40.391536883141455
[09/25 21:57:31 visual_prompt]: Epoch 37 / 100: avg data time: 5.85e-02, avg batch time: 0.4988, average train loss: 183.4407
[09/25 21:57:33 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1660, average loss: 189.0893
[09/25 21:57:33 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.00	
[09/25 21:57:33 visual_prompt]: Training 38 / 100 epoch, with learning rate 39.69463130731183
[09/25 21:57:39 visual_prompt]: Epoch 38 / 100: avg data time: 5.51e-02, avg batch time: 0.4951, average train loss: 186.7373
[09/25 21:57:41 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1656, average loss: 151.3952
[09/25 21:57:41 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.00	top5: 4.50	
[09/25 21:57:41 visual_prompt]: Training 39 / 100 epoch, with learning rate 38.97982258676867
[09/25 21:57:48 visual_prompt]: Epoch 39 / 100: avg data time: 5.22e-02, avg batch time: 0.4943, average train loss: 162.2761
[09/25 21:57:49 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.1657, average loss: 147.6681
[09/25 21:57:49 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 6.50	
[09/25 21:57:49 visual_prompt]: Training 40 / 100 epoch, with learning rate 38.24798160583012
[09/25 21:57:56 visual_prompt]: Epoch 40 / 100: avg data time: 5.56e-02, avg batch time: 0.4965, average train loss: 183.0203
[09/25 21:57:57 visual_prompt]: Inference (val):avg data time: 1.88e-05, avg batch time: 0.1660, average loss: 168.4577
[09/25 21:57:57 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 5.00	
[09/25 21:57:57 visual_prompt]: Training 41 / 100 epoch, with learning rate 37.5
[09/25 21:58:04 visual_prompt]: Epoch 41 / 100: avg data time: 5.45e-02, avg batch time: 0.4966, average train loss: 170.6602
[09/25 21:58:06 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1658, average loss: 143.8477
[09/25 21:58:06 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 4.50	
[09/25 21:58:06 visual_prompt]: Training 42 / 100 epoch, with learning rate 36.736789069647266
[09/25 21:58:12 visual_prompt]: Epoch 42 / 100: avg data time: 5.15e-02, avg batch time: 0.4914, average train loss: 154.1582
[09/25 21:58:14 visual_prompt]: Inference (val):avg data time: 1.98e-05, avg batch time: 0.1660, average loss: 371.2476
[09/25 21:58:14 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.50	
[09/25 21:58:14 visual_prompt]: Training 43 / 100 epoch, with learning rate 35.959278669726935
[09/25 21:58:20 visual_prompt]: Epoch 43 / 100: avg data time: 5.51e-02, avg batch time: 0.4962, average train loss: 187.5297
[09/25 21:58:22 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1661, average loss: 172.9751
[09/25 21:58:22 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 5.50	
[09/25 21:58:22 visual_prompt]: Training 44 / 100 epoch, with learning rate 35.16841607689501
[09/25 21:58:28 visual_prompt]: Epoch 44 / 100: avg data time: 4.94e-02, avg batch time: 0.4925, average train loss: 142.0804
[09/25 21:58:30 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1657, average loss: 133.3840
[09/25 21:58:30 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.00	
[09/25 21:58:30 visual_prompt]: Training 45 / 100 epoch, with learning rate 34.365164835397806
[09/25 21:58:37 visual_prompt]: Epoch 45 / 100: avg data time: 4.90e-02, avg batch time: 0.4910, average train loss: 154.5404
[09/25 21:58:38 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1661, average loss: 164.5724
[09/25 21:58:38 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.00	
[09/25 21:58:38 visual_prompt]: Training 46 / 100 epoch, with learning rate 33.55050358314172
[09/25 21:58:45 visual_prompt]: Epoch 46 / 100: avg data time: 5.68e-02, avg batch time: 0.4983, average train loss: 157.7999
[09/25 21:58:46 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1660, average loss: 195.0168
[09/25 21:58:46 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 2.00	
[09/25 21:58:46 visual_prompt]: Training 47 / 100 epoch, with learning rate 32.72542485937369
[09/25 21:58:53 visual_prompt]: Epoch 47 / 100: avg data time: 4.04e-02, avg batch time: 0.4810, average train loss: 150.2466
[09/25 21:58:54 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1659, average loss: 132.5314
[09/25 21:58:54 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.50	
[09/25 21:58:54 visual_prompt]: Training 48 / 100 epoch, with learning rate 31.89093389542498
[09/25 21:59:01 visual_prompt]: Epoch 48 / 100: avg data time: 5.94e-02, avg batch time: 0.5009, average train loss: 170.1250
[09/25 21:59:02 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1661, average loss: 143.2357
[09/25 21:59:02 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 4.50	
[09/25 21:59:02 visual_prompt]: Training 49 / 100 epoch, with learning rate 31.04804738999169
[09/25 21:59:09 visual_prompt]: Epoch 49 / 100: avg data time: 4.64e-02, avg batch time: 0.4886, average train loss: 146.3440
[09/25 21:59:11 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1663, average loss: 136.2573
[09/25 21:59:11 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.00	top5: 4.50	
[09/25 21:59:11 visual_prompt]: Training 50 / 100 epoch, with learning rate 30.19779227044398
[09/25 21:59:17 visual_prompt]: Epoch 50 / 100: avg data time: 5.72e-02, avg batch time: 0.4992, average train loss: 137.0763
[09/25 21:59:19 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1659, average loss: 306.9740
[09/25 21:59:19 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 7.00	
[09/25 21:59:19 visual_prompt]: Training 51 / 100 epoch, with learning rate 29.341204441673263
[09/25 21:59:25 visual_prompt]: Epoch 51 / 100: avg data time: 4.78e-02, avg batch time: 0.4901, average train loss: 162.0812
[09/25 21:59:27 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1663, average loss: 148.8875
[09/25 21:59:27 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.00	top5: 5.00	
[09/25 21:59:27 visual_prompt]: Training 52 / 100 epoch, with learning rate 28.479327524001636
[09/25 21:59:34 visual_prompt]: Epoch 52 / 100: avg data time: 5.95e-02, avg batch time: 0.5011, average train loss: 154.3106
[09/25 21:59:35 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1663, average loss: 144.6793
[09/25 21:59:35 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 6.00	
[09/25 21:59:35 visual_prompt]: Training 53 / 100 epoch, with learning rate 27.61321158169134
[09/25 21:59:42 visual_prompt]: Epoch 53 / 100: avg data time: 4.60e-02, avg batch time: 0.4880, average train loss: 160.4299
[09/25 21:59:43 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1665, average loss: 142.4933
[09/25 21:59:43 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 2.50	
[09/25 21:59:43 visual_prompt]: Training 54 / 100 epoch, with learning rate 26.74391184360313
[09/25 21:59:50 visual_prompt]: Epoch 54 / 100: avg data time: 5.12e-02, avg batch time: 0.4932, average train loss: 154.5952
[09/25 21:59:51 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1661, average loss: 146.9444
[09/25 21:59:51 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.00	
[09/25 21:59:51 visual_prompt]: Training 55 / 100 epoch, with learning rate 25.872487417562528
[09/25 21:59:58 visual_prompt]: Epoch 55 / 100: avg data time: 5.43e-02, avg batch time: 0.4957, average train loss: 166.0857
[09/25 21:59:59 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1661, average loss: 157.5017
[09/25 21:59:59 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.00	top5: 4.50	
[09/25 21:59:59 visual_prompt]: Training 56 / 100 epoch, with learning rate 25.0
[09/25 22:00:06 visual_prompt]: Epoch 56 / 100: avg data time: 4.82e-02, avg batch time: 0.4901, average train loss: 143.9232
[09/25 22:00:07 visual_prompt]: Inference (val):avg data time: 1.80e-05, avg batch time: 0.1663, average loss: 105.4627
[09/25 22:00:07 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.00	top5: 5.50	
[09/25 22:00:07 visual_prompt]: Training 57 / 100 epoch, with learning rate 24.127512582437483
[09/25 22:00:14 visual_prompt]: Epoch 57 / 100: avg data time: 5.62e-02, avg batch time: 0.4974, average train loss: 117.0971
[09/25 22:00:16 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1664, average loss: 110.5215
[09/25 22:00:16 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.00	top5: 2.50	
[09/25 22:00:16 visual_prompt]: Training 58 / 100 epoch, with learning rate 23.256088156396867
[09/25 22:00:22 visual_prompt]: Epoch 58 / 100: avg data time: 3.92e-02, avg batch time: 0.4814, average train loss: 130.8119
[09/25 22:00:23 visual_prompt]: Inference (val):avg data time: 1.94e-05, avg batch time: 0.1666, average loss: 126.8988
[09/25 22:00:23 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 7.50	
[09/25 22:00:23 visual_prompt]: Training 59 / 100 epoch, with learning rate 22.38678841830867
[09/25 22:00:30 visual_prompt]: Epoch 59 / 100: avg data time: 4.39e-02, avg batch time: 0.4864, average train loss: 119.2642
[09/25 22:00:32 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1665, average loss: 101.3298
[09/25 22:00:32 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.00	
[09/25 22:00:32 visual_prompt]: Training 60 / 100 epoch, with learning rate 21.52067247599837
[09/25 22:00:38 visual_prompt]: Epoch 60 / 100: avg data time: 5.08e-02, avg batch time: 0.4933, average train loss: 90.9714
[09/25 22:00:40 visual_prompt]: Inference (val):avg data time: 1.87e-05, avg batch time: 0.1662, average loss: 89.7864
[09/25 22:00:40 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.00	
[09/25 22:00:40 visual_prompt]: Training 61 / 100 epoch, with learning rate 20.65879555832674
[09/25 22:00:46 visual_prompt]: Epoch 61 / 100: avg data time: 5.26e-02, avg batch time: 0.4951, average train loss: 86.5402
[09/25 22:00:48 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1660, average loss: 71.6555
[09/25 22:00:48 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 6.00	
[09/25 22:00:48 visual_prompt]: Training 62 / 100 epoch, with learning rate 19.80220772955602
[09/25 22:00:55 visual_prompt]: Epoch 62 / 100: avg data time: 5.14e-02, avg batch time: 0.4926, average train loss: 68.4528
[09/25 22:00:56 visual_prompt]: Inference (val):avg data time: 2.01e-05, avg batch time: 0.1661, average loss: 69.8691
[09/25 22:00:56 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 4.50	
[09/25 22:00:56 visual_prompt]: Training 63 / 100 epoch, with learning rate 18.95195261000831
[09/25 22:01:03 visual_prompt]: Epoch 63 / 100: avg data time: 5.37e-02, avg batch time: 0.4960, average train loss: 67.2249
[09/25 22:01:04 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1665, average loss: 71.0732
[09/25 22:01:04 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.00	
[09/25 22:01:04 visual_prompt]: Training 64 / 100 epoch, with learning rate 18.10906610457502
[09/25 22:01:11 visual_prompt]: Epoch 64 / 100: avg data time: 4.34e-02, avg batch time: 0.4865, average train loss: 72.4062
[09/25 22:01:12 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1662, average loss: 109.2069
[09/25 22:01:12 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 6.00	
[09/25 22:01:12 visual_prompt]: Training 65 / 100 epoch, with learning rate 17.274575140626318
[09/25 22:01:19 visual_prompt]: Epoch 65 / 100: avg data time: 5.61e-02, avg batch time: 0.4980, average train loss: 76.4543
[09/25 22:01:20 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1662, average loss: 66.3991
[09/25 22:01:20 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.00	
[09/25 22:01:20 visual_prompt]: Training 66 / 100 epoch, with learning rate 16.449496416858285
[09/25 22:01:27 visual_prompt]: Epoch 66 / 100: avg data time: 4.01e-02, avg batch time: 0.4849, average train loss: 64.7805
[09/25 22:01:28 visual_prompt]: Inference (val):avg data time: 1.91e-05, avg batch time: 0.1662, average loss: 53.1999
[09/25 22:01:28 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 6.00	
[09/25 22:01:28 visual_prompt]: Training 67 / 100 epoch, with learning rate 15.634835164602197
[09/25 22:01:35 visual_prompt]: Epoch 67 / 100: avg data time: 5.06e-02, avg batch time: 0.4925, average train loss: 57.5614
[09/25 22:01:37 visual_prompt]: Inference (val):avg data time: 2.00e-05, avg batch time: 0.1660, average loss: 50.7045
[09/25 22:01:37 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 4.00	
[09/25 22:01:37 visual_prompt]: Training 68 / 100 epoch, with learning rate 14.831583923104999
[09/25 22:01:43 visual_prompt]: Epoch 68 / 100: avg data time: 5.91e-02, avg batch time: 0.4999, average train loss: 52.1521
[09/25 22:01:45 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1660, average loss: 44.5843
[09/25 22:01:45 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.00	top5: 4.50	
[09/25 22:01:45 visual_prompt]: Training 69 / 100 epoch, with learning rate 14.040721330273062
[09/25 22:01:51 visual_prompt]: Epoch 69 / 100: avg data time: 4.50e-02, avg batch time: 0.4880, average train loss: 44.7526
[09/25 22:01:53 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1664, average loss: 36.0996
[09/25 22:01:53 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 1.50	
[09/25 22:01:53 visual_prompt]: Training 70 / 100 epoch, with learning rate 13.263210930352736
[09/25 22:02:00 visual_prompt]: Epoch 70 / 100: avg data time: 5.06e-02, avg batch time: 0.4920, average train loss: 36.7214
[09/25 22:02:01 visual_prompt]: Inference (val):avg data time: 2.11e-05, avg batch time: 0.1661, average loss: 32.4821
[09/25 22:02:01 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.50	
[09/25 22:02:01 visual_prompt]: Training 71 / 100 epoch, with learning rate 12.500000000000005
[09/25 22:02:08 visual_prompt]: Epoch 71 / 100: avg data time: 5.23e-02, avg batch time: 0.4940, average train loss: 31.3130
[09/25 22:02:09 visual_prompt]: Inference (val):avg data time: 1.98e-05, avg batch time: 0.1661, average loss: 25.3976
[09/25 22:02:09 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 4.50	
[09/25 22:02:09 visual_prompt]: Training 72 / 100 epoch, with learning rate 11.75201839416988
[09/25 22:02:16 visual_prompt]: Epoch 72 / 100: avg data time: 5.31e-02, avg batch time: 0.4946, average train loss: 24.1053
[09/25 22:02:17 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.1661, average loss: 21.9622
[09/25 22:02:17 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/25 22:02:17 visual_prompt]: Training 73 / 100 epoch, with learning rate 11.020177413231332
[09/25 22:02:24 visual_prompt]: Epoch 73 / 100: avg data time: 5.65e-02, avg batch time: 0.4978, average train loss: 23.1457
[09/25 22:02:25 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.1661, average loss: 20.1115
[09/25 22:02:25 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.00	
[09/25 22:02:25 visual_prompt]: Training 74 / 100 epoch, with learning rate 10.305368692688175
[09/25 22:02:32 visual_prompt]: Epoch 74 / 100: avg data time: 5.50e-02, avg batch time: 0.4963, average train loss: 20.5091
[09/25 22:02:34 visual_prompt]: Inference (val):avg data time: 2.11e-05, avg batch time: 0.1663, average loss: 21.8112
[09/25 22:02:34 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/25 22:02:34 visual_prompt]: Training 75 / 100 epoch, with learning rate 9.608463116858543
[09/25 22:02:40 visual_prompt]: Epoch 75 / 100: avg data time: 5.60e-02, avg batch time: 0.4979, average train loss: 26.0038
[09/25 22:02:42 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1661, average loss: 19.2598
[09/25 22:02:42 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.00	
[09/25 22:02:42 visual_prompt]: Training 76 / 100 epoch, with learning rate 8.930309757836516
[09/25 22:02:48 visual_prompt]: Epoch 76 / 100: avg data time: 5.60e-02, avg batch time: 0.4984, average train loss: 20.4591
[09/25 22:02:50 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.1663, average loss: 20.5676
[09/25 22:02:50 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 4.00	
[09/25 22:02:50 visual_prompt]: Training 77 / 100 epoch, with learning rate 8.271734841028552
[09/25 22:02:57 visual_prompt]: Epoch 77 / 100: avg data time: 5.94e-02, avg batch time: 0.5007, average train loss: 19.8066
[09/25 22:02:58 visual_prompt]: Inference (val):avg data time: 1.96e-05, avg batch time: 0.1661, average loss: 14.5721
[09/25 22:02:58 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 9.00	
[09/25 22:02:58 visual_prompt]: Training 78 / 100 epoch, with learning rate 7.633540738525066
[09/25 22:03:05 visual_prompt]: Epoch 78 / 100: avg data time: 3.90e-02, avg batch time: 0.4815, average train loss: 19.0986
[09/25 22:03:06 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1661, average loss: 14.4642
[09/25 22:03:06 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 6.00	
[09/25 22:03:06 visual_prompt]: Training 79 / 100 epoch, with learning rate 7.016504991533726
[09/25 22:03:13 visual_prompt]: Epoch 79 / 100: avg data time: 4.07e-02, avg batch time: 0.4826, average train loss: 17.5788
[09/25 22:03:14 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1660, average loss: 11.9191
[09/25 22:03:14 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.00	
[09/25 22:03:14 visual_prompt]: Training 80 / 100 epoch, with learning rate 6.4213793630651415
[09/25 22:03:21 visual_prompt]: Epoch 80 / 100: avg data time: 4.12e-02, avg batch time: 0.4838, average train loss: 14.0994
[09/25 22:03:22 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1662, average loss: 14.5885
[09/25 22:03:22 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.00	
[09/25 22:03:22 visual_prompt]: Training 81 / 100 epoch, with learning rate 5.848888922025552
[09/25 22:03:29 visual_prompt]: Epoch 81 / 100: avg data time: 5.02e-02, avg batch time: 0.4925, average train loss: 17.7926
[09/25 22:03:30 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1660, average loss: 10.2102
[09/25 22:03:30 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 5.00	
[09/25 22:03:30 visual_prompt]: Training 82 / 100 epoch, with learning rate 5.2997311598319525
[09/25 22:03:37 visual_prompt]: Epoch 82 / 100: avg data time: 4.97e-02, avg batch time: 0.4926, average train loss: 13.0530
[09/25 22:03:38 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1662, average loss: 9.1603
[09/25 22:03:38 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.00	top5: 5.00	
[09/25 22:03:38 visual_prompt]: Training 83 / 100 epoch, with learning rate 4.774575140626316
[09/25 22:03:45 visual_prompt]: Epoch 83 / 100: avg data time: 5.41e-02, avg batch time: 0.4949, average train loss: 11.6659
[09/25 22:03:47 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1662, average loss: 8.1568
[09/25 22:03:47 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.00	
[09/25 22:03:47 visual_prompt]: Training 84 / 100 epoch, with learning rate 4.27406068612396
[09/25 22:03:53 visual_prompt]: Epoch 84 / 100: avg data time: 5.49e-02, avg batch time: 0.4964, average train loss: 10.8732
[09/25 22:03:55 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1664, average loss: 7.2522
[09/25 22:03:55 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.50	
[09/25 22:03:55 visual_prompt]: Training 85 / 100 epoch, with learning rate 3.798797596089351
[09/25 22:04:01 visual_prompt]: Epoch 85 / 100: avg data time: 5.35e-02, avg batch time: 0.4957, average train loss: 9.1356
[09/25 22:04:03 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1663, average loss: 6.7458
[09/25 22:04:03 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 5.00	
[09/25 22:04:03 visual_prompt]: Training 86 / 100 epoch, with learning rate 3.349364905389032
[09/25 22:04:10 visual_prompt]: Epoch 86 / 100: avg data time: 5.76e-02, avg batch time: 0.4986, average train loss: 7.6539
[09/25 22:04:11 visual_prompt]: Inference (val):avg data time: 1.94e-05, avg batch time: 0.1660, average loss: 8.6602
[09/25 22:04:11 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 2.00	
[09/25 22:04:11 visual_prompt]: Training 87 / 100 epoch, with learning rate 2.9263101785268253
[09/25 22:04:18 visual_prompt]: Epoch 87 / 100: avg data time: 5.93e-02, avg batch time: 0.4999, average train loss: 8.3364
[09/25 22:04:19 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1661, average loss: 6.6123
[09/25 22:04:19 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 6.00	
[09/25 22:04:19 visual_prompt]: Training 88 / 100 epoch, with learning rate 2.5301488425208296
[09/25 22:04:26 visual_prompt]: Epoch 88 / 100: avg data time: 5.16e-02, avg batch time: 0.4928, average train loss: 8.1186
[09/25 22:04:27 visual_prompt]: Inference (val):avg data time: 2.05e-05, avg batch time: 0.1657, average loss: 6.0650
[09/25 22:04:27 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 4.00	
[09/25 22:04:27 visual_prompt]: Training 89 / 100 epoch, with learning rate 2.1613635589349753
[09/25 22:04:34 visual_prompt]: Epoch 89 / 100: avg data time: 5.43e-02, avg batch time: 0.4942, average train loss: 7.1102
[09/25 22:04:36 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1658, average loss: 5.7096
[09/25 22:04:36 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 6.50	
[09/25 22:04:36 visual_prompt]: Training 90 / 100 epoch, with learning rate 1.820403635830317
[09/25 22:04:42 visual_prompt]: Epoch 90 / 100: avg data time: 5.39e-02, avg batch time: 0.4937, average train loss: 6.1007
[09/25 22:04:44 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1656, average loss: 5.9507
[09/25 22:04:44 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.00	
[09/25 22:04:44 visual_prompt]: Training 91 / 100 epoch, with learning rate 1.507684480352292
[09/25 22:04:50 visual_prompt]: Epoch 91 / 100: avg data time: 5.52e-02, avg batch time: 0.4951, average train loss: 5.7925
[09/25 22:04:52 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1657, average loss: 5.3537
[09/25 22:04:52 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 4.00	
[09/25 22:04:52 visual_prompt]: Training 92 / 100 epoch, with learning rate 1.2235870926211616
[09/25 22:04:59 visual_prompt]: Epoch 92 / 100: avg data time: 5.47e-02, avg batch time: 0.4941, average train loss: 5.4708
[09/25 22:05:00 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1656, average loss: 5.1458
[09/25 22:05:00 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.00	
[09/25 22:05:00 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.9684576015420276
[09/25 22:05:07 visual_prompt]: Epoch 93 / 100: avg data time: 3.99e-02, avg batch time: 0.4812, average train loss: 5.2294
[09/25 22:05:08 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1655, average loss: 4.9656
[09/25 22:05:08 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 5.00	
[09/25 22:05:08 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.7426068431000882
[09/25 22:05:15 visual_prompt]: Epoch 94 / 100: avg data time: 6.23e-02, avg batch time: 0.5028, average train loss: 5.1347
[09/25 22:05:16 visual_prompt]: Inference (val):avg data time: 1.98e-05, avg batch time: 0.1656, average loss: 5.0530
[09/25 22:05:16 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.00	
[09/25 22:05:16 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.5463099816548578
[09/25 22:05:23 visual_prompt]: Epoch 95 / 100: avg data time: 5.74e-02, avg batch time: 0.4972, average train loss: 5.0194
[09/25 22:05:24 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1656, average loss: 4.8289
[09/25 22:05:24 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/25 22:05:24 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.3798061746947995
[09/25 22:05:31 visual_prompt]: Epoch 96 / 100: avg data time: 5.73e-02, avg batch time: 0.4977, average train loss: 4.8956
[09/25 22:05:33 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1658, average loss: 4.6783
[09/25 22:05:33 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.00	
[09/25 22:05:33 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.24329828146074095
[09/25 22:05:39 visual_prompt]: Epoch 97 / 100: avg data time: 5.15e-02, avg batch time: 0.4928, average train loss: 4.7272
[09/25 22:05:41 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1656, average loss: 4.6433
[09/25 22:05:41 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.50	
[09/25 22:05:41 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.13695261579316775
[09/25 22:05:47 visual_prompt]: Epoch 98 / 100: avg data time: 5.34e-02, avg batch time: 0.4930, average train loss: 4.6451
[09/25 22:05:49 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1656, average loss: 4.6781
[09/25 22:05:49 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.00	
[09/25 22:05:49 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.06089874350439506
[09/25 22:05:56 visual_prompt]: Epoch 99 / 100: avg data time: 5.87e-02, avg batch time: 0.4982, average train loss: 4.5707
[09/25 22:05:57 visual_prompt]: Inference (val):avg data time: 2.01e-05, avg batch time: 0.1657, average loss: 4.6051
[09/25 22:05:57 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 9.00	
[09/25 22:05:57 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.015229324522605947
[09/25 22:06:04 visual_prompt]: Epoch 100 / 100: avg data time: 5.34e-02, avg batch time: 0.4933, average train loss: 4.5230
[09/25 22:06:05 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1656, average loss: 4.6403
[09/25 22:06:05 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 5.00	
[09/25 22:06:05 visual_prompt]: Rank of current process: 0. World size: 1
[09/25 22:06:05 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/25 22:06:05 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-cifar(num_classes=100)', 'DATA.NUMBER_CLASSES', '100', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/25 22:06:05 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/25 22:06:05 visual_prompt]: Training with config:
[09/25 22:06:05 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-cifar(num_classes=100)/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr50.0_wd0.0001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 50.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-cifar(num_classes=100)', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 100, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/25 22:06:05 visual_prompt]: Loading training data...
[09/25 22:06:05 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[:800], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/25 22:06:06 visual_prompt]: Number of images: 800
[09/25 22:06:06 visual_prompt]: Number of classes: 100 / 100
[09/25 22:06:06 visual_prompt]: Loading validation data...
[09/25 22:06:06 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[45000:45200], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/25 22:06:06 visual_prompt]: Number of images: 200
[09/25 22:06:06 visual_prompt]: Number of classes: 90 / 100
[09/25 22:06:06 visual_prompt]: Constructing models...
[09/25 22:06:09 visual_prompt]: Total Parameters: 86336356	 Gradient Parameters: 537700
[09/25 22:06:09 visual_prompt]: tuned percent:0.623
[09/25 22:06:09 visual_prompt]: Device used for model: 0
[09/25 22:06:09 visual_prompt]: Setting up Evaluator...
[09/25 22:06:09 visual_prompt]: Setting up Trainer...
[09/25 22:06:09 visual_prompt]: 	Setting up the optimizer...
[09/25 22:06:09 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/25 22:06:16 visual_prompt]: Epoch 1 / 100: avg data time: 5.54e-02, avg batch time: 0.4969, average train loss: 4.6568
[09/25 22:06:17 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1657, average loss: 4.6218
[09/25 22:06:17 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 7.00	
[09/25 22:06:17 visual_prompt]: Best epoch 1: best metric: 0.010
[09/25 22:06:17 visual_prompt]: Training 2 / 100 epoch, with learning rate 5.0
[09/25 22:06:24 visual_prompt]: Epoch 2 / 100: avg data time: 4.68e-02, avg batch time: 0.4867, average train loss: 6.4172
[09/25 22:06:25 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1657, average loss: 6.6040
[09/25 22:06:25 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 5.00	
[09/25 22:06:25 visual_prompt]: Best epoch 2: best metric: 0.015
[09/25 22:06:25 visual_prompt]: Training 3 / 100 epoch, with learning rate 10.0
[09/25 22:06:32 visual_prompt]: Epoch 3 / 100: avg data time: 5.19e-02, avg batch time: 0.4930, average train loss: 7.3759
[09/25 22:06:33 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1655, average loss: 8.7905
[09/25 22:06:33 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.50	
[09/25 22:06:33 visual_prompt]: Training 4 / 100 epoch, with learning rate 15.0
[09/25 22:06:40 visual_prompt]: Epoch 4 / 100: avg data time: 5.79e-02, avg batch time: 0.4980, average train loss: 10.2447
[09/25 22:06:41 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1657, average loss: 15.4315
[09/25 22:06:41 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 7.50	
[09/25 22:06:41 visual_prompt]: Training 5 / 100 epoch, with learning rate 20.0
[09/25 22:06:48 visual_prompt]: Epoch 5 / 100: avg data time: 5.78e-02, avg batch time: 0.4972, average train loss: 17.7843
[09/25 22:06:50 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1658, average loss: 23.2185
[09/25 22:06:50 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 6.00	
[09/25 22:06:50 visual_prompt]: Training 6 / 100 epoch, with learning rate 25.0
[09/25 22:06:56 visual_prompt]: Epoch 6 / 100: avg data time: 5.38e-02, avg batch time: 0.4957, average train loss: 34.9778
[09/25 22:06:58 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1657, average loss: 45.1257
[09/25 22:06:58 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.50	
[09/25 22:06:58 visual_prompt]: Training 7 / 100 epoch, with learning rate 30.0
[09/25 22:07:04 visual_prompt]: Epoch 7 / 100: avg data time: 5.16e-02, avg batch time: 0.4915, average train loss: 58.0301
[09/25 22:07:06 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1656, average loss: 53.8955
[09/25 22:07:06 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 7.00	
[09/25 22:07:06 visual_prompt]: Training 8 / 100 epoch, with learning rate 35.0
[09/25 22:07:13 visual_prompt]: Epoch 8 / 100: avg data time: 5.64e-02, avg batch time: 0.4972, average train loss: 112.0916
[09/25 22:07:14 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1659, average loss: 89.5517
[09/25 22:07:14 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 7.50	
[09/25 22:07:14 visual_prompt]: Best epoch 8: best metric: 0.020
[09/25 22:07:14 visual_prompt]: Training 9 / 100 epoch, with learning rate 40.0
[09/25 22:07:21 visual_prompt]: Epoch 9 / 100: avg data time: 5.35e-02, avg batch time: 0.4946, average train loss: 129.9930
[09/25 22:07:22 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1660, average loss: 81.7744
[09/25 22:07:22 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 4.50	
[09/25 22:07:22 visual_prompt]: Training 10 / 100 epoch, with learning rate 45.0
[09/25 22:07:29 visual_prompt]: Epoch 10 / 100: avg data time: 4.44e-02, avg batch time: 0.4869, average train loss: 131.3907
[09/25 22:07:30 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1661, average loss: 220.1655
[09/25 22:07:30 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 3.50	
[09/25 22:07:30 visual_prompt]: Training 11 / 100 epoch, with learning rate 50.0
[09/25 22:07:37 visual_prompt]: Epoch 11 / 100: avg data time: 5.74e-02, avg batch time: 0.4979, average train loss: 221.0512
[09/25 22:07:38 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1660, average loss: 172.8222
[09/25 22:07:38 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 4.50	
[09/25 22:07:38 visual_prompt]: Training 12 / 100 epoch, with learning rate 49.9847706754774
[09/25 22:07:45 visual_prompt]: Epoch 12 / 100: avg data time: 5.12e-02, avg batch time: 0.4940, average train loss: 196.5803
[09/25 22:07:46 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1661, average loss: 202.1505
[09/25 22:07:46 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 4.50	
[09/25 22:07:46 visual_prompt]: Training 13 / 100 epoch, with learning rate 49.939101256495604
[09/25 22:07:53 visual_prompt]: Epoch 13 / 100: avg data time: 5.28e-02, avg batch time: 0.4936, average train loss: 247.3476
[09/25 22:07:54 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1660, average loss: 241.8087
[09/25 22:07:54 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 4.50	
[09/25 22:07:54 visual_prompt]: Training 14 / 100 epoch, with learning rate 49.86304738420683
[09/25 22:08:01 visual_prompt]: Epoch 14 / 100: avg data time: 5.37e-02, avg batch time: 0.4943, average train loss: 266.6248
[09/25 22:08:03 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1657, average loss: 283.7840
[09/25 22:08:03 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.00	
[09/25 22:08:03 visual_prompt]: Training 15 / 100 epoch, with learning rate 49.75670171853926
[09/25 22:08:09 visual_prompt]: Epoch 15 / 100: avg data time: 5.31e-02, avg batch time: 0.4939, average train loss: 297.9159
[09/25 22:08:11 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1660, average loss: 252.6810
[09/25 22:08:11 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.00	
[09/25 22:08:11 visual_prompt]: Training 16 / 100 epoch, with learning rate 49.6201938253052
[09/25 22:08:18 visual_prompt]: Epoch 16 / 100: avg data time: 5.40e-02, avg batch time: 0.4966, average train loss: 286.3494
[09/25 22:08:19 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1660, average loss: 301.0385
[09/25 22:08:19 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 4.00	
[09/25 22:08:19 visual_prompt]: Training 17 / 100 epoch, with learning rate 49.45369001834514
[09/25 22:08:26 visual_prompt]: Epoch 17 / 100: avg data time: 4.38e-02, avg batch time: 0.4869, average train loss: 335.8678
[09/25 22:08:27 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1661, average loss: 289.1435
[09/25 22:08:27 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/25 22:08:27 visual_prompt]: Training 18 / 100 epoch, with learning rate 49.25739315689991
[09/25 22:08:34 visual_prompt]: Epoch 18 / 100: avg data time: 5.69e-02, avg batch time: 0.4975, average train loss: 315.9236
[09/25 22:08:35 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1659, average loss: 285.4547
[09/25 22:08:35 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.00	top5: 3.00	
[09/25 22:08:35 visual_prompt]: Training 19 / 100 epoch, with learning rate 49.03154239845797
[09/25 22:08:42 visual_prompt]: Epoch 19 / 100: avg data time: 6.01e-02, avg batch time: 0.5003, average train loss: 277.7680
[09/25 22:08:44 visual_prompt]: Inference (val):avg data time: 4.18e-05, avg batch time: 0.1657, average loss: 244.8417
[09/25 22:08:44 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 4.50	
[09/25 22:08:44 visual_prompt]: Training 20 / 100 epoch, with learning rate 48.77641290737884
[09/25 22:08:50 visual_prompt]: Epoch 20 / 100: avg data time: 6.07e-02, avg batch time: 0.5007, average train loss: 300.4998
[09/25 22:08:52 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1660, average loss: 232.6409
[09/25 22:08:52 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 6.00	
[09/25 22:08:52 visual_prompt]: Training 21 / 100 epoch, with learning rate 48.49231551964771
[09/25 22:08:58 visual_prompt]: Epoch 21 / 100: avg data time: 3.84e-02, avg batch time: 0.4801, average train loss: 258.4432
[09/25 22:09:00 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1659, average loss: 284.0577
[09/25 22:09:00 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 7.00	
[09/25 22:09:00 visual_prompt]: Training 22 / 100 epoch, with learning rate 48.17959636416968
[09/25 22:09:07 visual_prompt]: Epoch 22 / 100: avg data time: 6.16e-02, avg batch time: 0.5019, average train loss: 259.2953
[09/25 22:09:08 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1661, average loss: 216.2103
[09/25 22:09:08 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 7.50	
[09/25 22:09:08 visual_prompt]: Training 23 / 100 epoch, with learning rate 47.83863644106502
[09/25 22:09:15 visual_prompt]: Epoch 23 / 100: avg data time: 4.83e-02, avg batch time: 0.4900, average train loss: 233.5795
[09/25 22:09:16 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1660, average loss: 252.0638
[09/25 22:09:16 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.50	
[09/25 22:09:16 visual_prompt]: Training 24 / 100 epoch, with learning rate 47.46985115747918
[09/25 22:09:23 visual_prompt]: Epoch 24 / 100: avg data time: 5.23e-02, avg batch time: 0.4933, average train loss: 237.0746
[09/25 22:09:24 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1660, average loss: 249.3647
[09/25 22:09:24 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/25 22:09:24 visual_prompt]: Training 25 / 100 epoch, with learning rate 47.073689821473174
[09/25 22:09:31 visual_prompt]: Epoch 25 / 100: avg data time: 5.56e-02, avg batch time: 0.4976, average train loss: 237.2270
[09/25 22:09:32 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1661, average loss: 205.1898
[09/25 22:09:32 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.00	top5: 3.50	
[09/25 22:09:32 visual_prompt]: Training 26 / 100 epoch, with learning rate 46.65063509461097
[09/25 22:09:39 visual_prompt]: Epoch 26 / 100: avg data time: 5.24e-02, avg batch time: 0.4936, average train loss: 258.7391
[09/25 22:09:41 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1659, average loss: 242.0289
[09/25 22:09:41 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 4.50	
[09/25 22:09:41 visual_prompt]: Training 27 / 100 epoch, with learning rate 46.20120240391065
[09/25 22:09:47 visual_prompt]: Epoch 27 / 100: avg data time: 5.67e-02, avg batch time: 0.4970, average train loss: 247.8933
[09/25 22:09:49 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1657, average loss: 247.6428
[09/25 22:09:49 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 6.50	
[09/25 22:09:49 visual_prompt]: Training 28 / 100 epoch, with learning rate 45.72593931387604
[09/25 22:09:55 visual_prompt]: Epoch 28 / 100: avg data time: 4.38e-02, avg batch time: 0.4866, average train loss: 268.5950
[09/25 22:09:57 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1656, average loss: 222.9749
[09/25 22:09:57 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 7.50	
[09/25 22:09:57 visual_prompt]: Training 29 / 100 epoch, with learning rate 45.22542485937369
[09/25 22:10:03 visual_prompt]: Epoch 29 / 100: avg data time: 5.13e-02, avg batch time: 0.4914, average train loss: 269.6227
[09/25 22:10:05 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1657, average loss: 267.9271
[09/25 22:10:05 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 4.50	
[09/25 22:10:05 visual_prompt]: Training 30 / 100 epoch, with learning rate 44.70026884016804
[09/25 22:10:12 visual_prompt]: Epoch 30 / 100: avg data time: 5.46e-02, avg batch time: 0.4946, average train loss: 290.1512
[09/25 22:10:13 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1657, average loss: 258.5428
[09/25 22:10:13 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.00	
[09/25 22:10:13 visual_prompt]: Training 31 / 100 epoch, with learning rate 44.15111107797445
[09/25 22:10:20 visual_prompt]: Epoch 31 / 100: avg data time: 6.00e-02, avg batch time: 0.5003, average train loss: 236.2741
[09/25 22:10:21 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1660, average loss: 190.5656
[09/25 22:10:21 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.50	
[09/25 22:10:21 visual_prompt]: Training 32 / 100 epoch, with learning rate 43.57862063693486
[09/25 22:10:28 visual_prompt]: Epoch 32 / 100: avg data time: 5.58e-02, avg batch time: 0.4961, average train loss: 241.1547
[09/25 22:10:30 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1660, average loss: 272.6843
[09/25 22:10:30 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 6.00	
[09/25 22:10:30 visual_prompt]: Training 33 / 100 epoch, with learning rate 42.98349500846628
[09/25 22:10:36 visual_prompt]: Epoch 33 / 100: avg data time: 5.31e-02, avg batch time: 0.4935, average train loss: 278.5193
[09/25 22:10:38 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1657, average loss: 224.4291
[09/25 22:10:38 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 5.50	
[09/25 22:10:38 visual_prompt]: Training 34 / 100 epoch, with learning rate 42.36645926147493
[09/25 22:10:44 visual_prompt]: Epoch 34 / 100: avg data time: 5.31e-02, avg batch time: 0.4939, average train loss: 220.0649
[09/25 22:10:46 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1657, average loss: 234.8231
[09/25 22:10:46 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.00	
[09/25 22:10:46 visual_prompt]: Training 35 / 100 epoch, with learning rate 41.72826515897145
[09/25 22:10:53 visual_prompt]: Epoch 35 / 100: avg data time: 5.79e-02, avg batch time: 0.4988, average train loss: 252.2282
[09/25 22:10:54 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1658, average loss: 206.2396
[09/25 22:10:54 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 7.00	
[09/25 22:10:54 visual_prompt]: Training 36 / 100 epoch, with learning rate 41.06969024216348
[09/25 22:11:01 visual_prompt]: Epoch 36 / 100: avg data time: 5.68e-02, avg batch time: 0.4981, average train loss: 235.4694
[09/25 22:11:02 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1656, average loss: 245.6074
[09/25 22:11:02 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.00	top5: 5.00	
[09/25 22:11:02 visual_prompt]: Training 37 / 100 epoch, with learning rate 40.391536883141455
[09/25 22:11:09 visual_prompt]: Epoch 37 / 100: avg data time: 4.57e-02, avg batch time: 0.4880, average train loss: 231.0007
[09/25 22:11:10 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1659, average loss: 243.8422
[09/25 22:11:10 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 4.00	
[09/25 22:11:10 visual_prompt]: Training 38 / 100 epoch, with learning rate 39.69463130731183
[09/25 22:11:17 visual_prompt]: Epoch 38 / 100: avg data time: 4.90e-02, avg batch time: 0.4904, average train loss: 208.0630
[09/25 22:11:19 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1660, average loss: 202.9271
[09/25 22:11:19 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 4.00	
[09/25 22:11:19 visual_prompt]: Training 39 / 100 epoch, with learning rate 38.97982258676867
[09/25 22:11:25 visual_prompt]: Epoch 39 / 100: avg data time: 5.84e-02, avg batch time: 0.5011, average train loss: 175.4366
[09/25 22:11:27 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1661, average loss: 168.3601
[09/25 22:11:27 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 6.00	
[09/25 22:11:27 visual_prompt]: Training 40 / 100 epoch, with learning rate 38.24798160583012
[09/25 22:11:33 visual_prompt]: Epoch 40 / 100: avg data time: 5.39e-02, avg batch time: 0.4949, average train loss: 176.1454
[09/25 22:11:35 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1659, average loss: 168.2028
[09/25 22:11:35 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 4.50	
[09/25 22:11:35 visual_prompt]: Training 41 / 100 epoch, with learning rate 37.5
[09/25 22:11:42 visual_prompt]: Epoch 41 / 100: avg data time: 4.90e-02, avg batch time: 0.4910, average train loss: 185.4031
[09/25 22:11:43 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1662, average loss: 230.0332
[09/25 22:11:43 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 2.50	
[09/25 22:11:43 visual_prompt]: Training 42 / 100 epoch, with learning rate 36.736789069647266
[09/25 22:11:50 visual_prompt]: Epoch 42 / 100: avg data time: 5.79e-02, avg batch time: 0.4988, average train loss: 212.1473
[09/25 22:11:51 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1662, average loss: 233.5870
[09/25 22:11:51 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 5.50	
[09/25 22:11:51 visual_prompt]: Training 43 / 100 epoch, with learning rate 35.959278669726935
[09/25 22:11:58 visual_prompt]: Epoch 43 / 100: avg data time: 6.04e-02, avg batch time: 0.5023, average train loss: 240.3088
[09/25 22:11:59 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1659, average loss: 198.9324
[09/25 22:11:59 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 7.00	
[09/25 22:11:59 visual_prompt]: Training 44 / 100 epoch, with learning rate 35.16841607689501
[09/25 22:12:06 visual_prompt]: Epoch 44 / 100: avg data time: 4.25e-02, avg batch time: 0.4844, average train loss: 251.3334
[09/25 22:12:08 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1661, average loss: 231.8901
[09/25 22:12:08 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.00	top5: 4.50	
[09/25 22:12:08 visual_prompt]: Training 45 / 100 epoch, with learning rate 34.365164835397806
[09/25 22:12:14 visual_prompt]: Epoch 45 / 100: avg data time: 4.69e-02, avg batch time: 0.4889, average train loss: 224.4813
[09/25 22:12:16 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1659, average loss: 219.6608
[09/25 22:12:16 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 4.50	
[09/25 22:12:16 visual_prompt]: Training 46 / 100 epoch, with learning rate 33.55050358314172
[09/25 22:12:22 visual_prompt]: Epoch 46 / 100: avg data time: 4.81e-02, avg batch time: 0.4903, average train loss: 199.5664
[09/25 22:12:24 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1658, average loss: 196.7249
[09/25 22:12:24 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/25 22:12:24 visual_prompt]: Training 47 / 100 epoch, with learning rate 32.72542485937369
[09/25 22:12:30 visual_prompt]: Epoch 47 / 100: avg data time: 5.53e-02, avg batch time: 0.4957, average train loss: 145.3342
[09/25 22:12:32 visual_prompt]: Inference (val):avg data time: 4.54e-05, avg batch time: 0.1660, average loss: 130.9019
[09/25 22:12:32 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.50	
[09/25 22:12:32 visual_prompt]: Training 48 / 100 epoch, with learning rate 31.89093389542498
[09/25 22:12:39 visual_prompt]: Epoch 48 / 100: avg data time: 4.92e-02, avg batch time: 0.4902, average train loss: 143.9543
[09/25 22:12:40 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1658, average loss: 152.4550
[09/25 22:12:40 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 4.00	
[09/25 22:12:40 visual_prompt]: Training 49 / 100 epoch, with learning rate 31.04804738999169
[09/25 22:12:47 visual_prompt]: Epoch 49 / 100: avg data time: 5.28e-02, avg batch time: 0.4941, average train loss: 154.3997
[09/25 22:12:48 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1661, average loss: 145.0129
[09/25 22:12:48 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 6.50	
[09/25 22:12:48 visual_prompt]: Training 50 / 100 epoch, with learning rate 30.19779227044398
[09/25 22:12:55 visual_prompt]: Epoch 50 / 100: avg data time: 5.62e-02, avg batch time: 0.4986, average train loss: 148.8417
[09/25 22:12:56 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1661, average loss: 126.1790
[09/25 22:12:56 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 7.00	
[09/25 22:12:56 visual_prompt]: Training 51 / 100 epoch, with learning rate 29.341204441673263
[09/25 22:13:03 visual_prompt]: Epoch 51 / 100: avg data time: 5.81e-02, avg batch time: 0.4990, average train loss: 165.1484
[09/25 22:13:05 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1661, average loss: 189.6139
[09/25 22:13:05 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 4.00	
[09/25 22:13:05 visual_prompt]: Training 52 / 100 epoch, with learning rate 28.479327524001636
[09/25 22:13:11 visual_prompt]: Epoch 52 / 100: avg data time: 5.96e-02, avg batch time: 0.5014, average train loss: 177.7916
[09/25 22:13:13 visual_prompt]: Inference (val):avg data time: 3.35e-05, avg batch time: 0.1660, average loss: 154.9974
[09/25 22:13:13 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 4.00	
[09/25 22:13:13 visual_prompt]: Training 53 / 100 epoch, with learning rate 27.61321158169134
[09/25 22:13:20 visual_prompt]: Epoch 53 / 100: avg data time: 5.50e-02, avg batch time: 0.4967, average train loss: 132.0660
[09/25 22:13:21 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1663, average loss: 139.4642
[09/25 22:13:21 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 4.50	
[09/25 22:13:21 visual_prompt]: Training 54 / 100 epoch, with learning rate 26.74391184360313
[09/25 22:13:28 visual_prompt]: Epoch 54 / 100: avg data time: 4.47e-02, avg batch time: 0.4882, average train loss: 132.0078
[09/25 22:13:29 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1663, average loss: 114.7753
[09/25 22:13:29 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 6.00	
[09/25 22:13:29 visual_prompt]: Training 55 / 100 epoch, with learning rate 25.872487417562528
[09/25 22:13:36 visual_prompt]: Epoch 55 / 100: avg data time: 5.37e-02, avg batch time: 0.4953, average train loss: 116.0013
[09/25 22:13:37 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1663, average loss: 104.4949
[09/25 22:13:37 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 5.50	
[09/25 22:13:37 visual_prompt]: Training 56 / 100 epoch, with learning rate 25.0
[09/25 22:13:44 visual_prompt]: Epoch 56 / 100: avg data time: 5.07e-02, avg batch time: 0.4929, average train loss: 91.3013
[09/25 22:13:45 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1661, average loss: 76.7303
[09/25 22:13:45 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 7.50	
[09/25 22:13:45 visual_prompt]: Training 57 / 100 epoch, with learning rate 24.127512582437483
[09/25 22:13:52 visual_prompt]: Epoch 57 / 100: avg data time: 4.10e-02, avg batch time: 0.4824, average train loss: 85.9397
[09/25 22:13:53 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1660, average loss: 76.5568
[09/25 22:13:53 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.00	
[09/25 22:13:53 visual_prompt]: Training 58 / 100 epoch, with learning rate 23.256088156396867
[09/25 22:14:00 visual_prompt]: Epoch 58 / 100: avg data time: 5.79e-02, avg batch time: 0.4996, average train loss: 80.2962
[09/25 22:14:02 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1660, average loss: 81.4591
[09/25 22:14:02 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.00	top5: 6.50	
[09/25 22:14:02 visual_prompt]: Training 59 / 100 epoch, with learning rate 22.38678841830867
[09/25 22:14:08 visual_prompt]: Epoch 59 / 100: avg data time: 5.56e-02, avg batch time: 0.4971, average train loss: 89.2311
[09/25 22:14:10 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1658, average loss: 85.8415
[09/25 22:14:10 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 4.00	
[09/25 22:14:10 visual_prompt]: Training 60 / 100 epoch, with learning rate 21.52067247599837
[09/25 22:14:17 visual_prompt]: Epoch 60 / 100: avg data time: 5.53e-02, avg batch time: 0.4954, average train loss: 92.0770
[09/25 22:14:18 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1659, average loss: 90.7141
[09/25 22:14:18 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 3.00	
[09/25 22:14:18 visual_prompt]: Training 61 / 100 epoch, with learning rate 20.65879555832674
[09/25 22:14:25 visual_prompt]: Epoch 61 / 100: avg data time: 5.47e-02, avg batch time: 0.4957, average train loss: 82.9207
[09/25 22:14:26 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1658, average loss: 81.9382
[09/25 22:14:26 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 6.50	
[09/25 22:14:26 visual_prompt]: Training 62 / 100 epoch, with learning rate 19.80220772955602
[09/25 22:14:33 visual_prompt]: Epoch 62 / 100: avg data time: 5.01e-02, avg batch time: 0.4915, average train loss: 82.9376
[09/25 22:14:34 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1657, average loss: 68.4145
[09/25 22:14:34 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 6.50	
[09/25 22:14:34 visual_prompt]: Training 63 / 100 epoch, with learning rate 18.95195261000831
[09/25 22:14:41 visual_prompt]: Epoch 63 / 100: avg data time: 4.60e-02, avg batch time: 0.4873, average train loss: 72.8417
[09/25 22:14:42 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1659, average loss: 69.9851
[09/25 22:14:42 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.00	
[09/25 22:14:42 visual_prompt]: Training 64 / 100 epoch, with learning rate 18.10906610457502
[09/25 22:14:49 visual_prompt]: Epoch 64 / 100: avg data time: 5.55e-02, avg batch time: 0.4965, average train loss: 62.3671
[09/25 22:14:51 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1658, average loss: 57.5407
[09/25 22:14:51 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.00	
[09/25 22:14:51 visual_prompt]: Training 65 / 100 epoch, with learning rate 17.274575140626318
[09/25 22:14:57 visual_prompt]: Epoch 65 / 100: avg data time: 4.52e-02, avg batch time: 0.4884, average train loss: 58.1585
[09/25 22:14:59 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1660, average loss: 56.0599
[09/25 22:14:59 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 2.50	
[09/25 22:14:59 visual_prompt]: Training 66 / 100 epoch, with learning rate 16.449496416858285
[09/25 22:15:05 visual_prompt]: Epoch 66 / 100: avg data time: 4.15e-02, avg batch time: 0.4831, average train loss: 50.0557
[09/25 22:15:07 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1658, average loss: 49.6542
[09/25 22:15:07 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/25 22:15:07 visual_prompt]: Training 67 / 100 epoch, with learning rate 15.634835164602197
[09/25 22:15:13 visual_prompt]: Epoch 67 / 100: avg data time: 5.64e-02, avg batch time: 0.4981, average train loss: 49.6318
[09/25 22:15:15 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1658, average loss: 44.9684
[09/25 22:15:15 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 7.50	
[09/25 22:15:15 visual_prompt]: Training 68 / 100 epoch, with learning rate 14.831583923104999
[09/25 22:15:21 visual_prompt]: Epoch 68 / 100: avg data time: 5.31e-02, avg batch time: 0.4933, average train loss: 47.2711
[09/25 22:15:23 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1658, average loss: 44.2570
[09/25 22:15:23 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 4.00	
[09/25 22:15:23 visual_prompt]: Training 69 / 100 epoch, with learning rate 14.040721330273062
[09/25 22:15:30 visual_prompt]: Epoch 69 / 100: avg data time: 5.37e-02, avg batch time: 0.4942, average train loss: 43.9120
[09/25 22:15:31 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1657, average loss: 38.3235
[09/25 22:15:31 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 7.50	
[09/25 22:15:31 visual_prompt]: Training 70 / 100 epoch, with learning rate 13.263210930352736
[09/25 22:15:38 visual_prompt]: Epoch 70 / 100: avg data time: 5.17e-02, avg batch time: 0.4925, average train loss: 41.0686
[09/25 22:15:39 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1659, average loss: 37.4750
[09/25 22:15:39 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 5.50	
[09/25 22:15:39 visual_prompt]: Training 71 / 100 epoch, with learning rate 12.500000000000005
[09/25 22:15:46 visual_prompt]: Epoch 71 / 100: avg data time: 6.23e-02, avg batch time: 0.5029, average train loss: 39.4072
[09/25 22:15:48 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1660, average loss: 35.7824
[09/25 22:15:48 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 4.50	
[09/25 22:15:48 visual_prompt]: Training 72 / 100 epoch, with learning rate 11.75201839416988
[09/25 22:15:54 visual_prompt]: Epoch 72 / 100: avg data time: 6.21e-02, avg batch time: 0.5034, average train loss: 29.9799
[09/25 22:15:56 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1658, average loss: 20.2827
[09/25 22:15:56 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 6.50	
[09/25 22:15:56 visual_prompt]: Training 73 / 100 epoch, with learning rate 11.020177413231332
[09/25 22:16:03 visual_prompt]: Epoch 73 / 100: avg data time: 5.09e-02, avg batch time: 0.4925, average train loss: 20.5462
[09/25 22:16:04 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1658, average loss: 18.2323
[09/25 22:16:04 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.50	
[09/25 22:16:04 visual_prompt]: Training 74 / 100 epoch, with learning rate 10.305368692688175
[09/25 22:16:11 visual_prompt]: Epoch 74 / 100: avg data time: 5.35e-02, avg batch time: 0.4963, average train loss: 19.1206
[09/25 22:16:12 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1656, average loss: 12.0833
[09/25 22:16:12 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 4.00	
[09/25 22:16:12 visual_prompt]: Training 75 / 100 epoch, with learning rate 9.608463116858543
[09/25 22:16:19 visual_prompt]: Epoch 75 / 100: avg data time: 4.47e-02, avg batch time: 0.4858, average train loss: 12.4159
[09/25 22:16:20 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1657, average loss: 10.2307
[09/25 22:16:20 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 4.00	
[09/25 22:16:20 visual_prompt]: Training 76 / 100 epoch, with learning rate 8.930309757836516
[09/25 22:16:27 visual_prompt]: Epoch 76 / 100: avg data time: 4.36e-02, avg batch time: 0.4877, average train loss: 8.7874
[09/25 22:16:28 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.1660, average loss: 7.8947
[09/25 22:16:28 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/25 22:16:28 visual_prompt]: Training 77 / 100 epoch, with learning rate 8.271734841028552
[09/25 22:16:35 visual_prompt]: Epoch 77 / 100: avg data time: 5.91e-02, avg batch time: 0.4999, average train loss: 6.8149
[09/25 22:16:37 visual_prompt]: Inference (val):avg data time: 4.26e-05, avg batch time: 0.1660, average loss: 6.7611
[09/25 22:16:37 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 3.00	
[09/25 22:16:37 visual_prompt]: Training 78 / 100 epoch, with learning rate 7.633540738525066
[09/25 22:16:43 visual_prompt]: Epoch 78 / 100: avg data time: 4.06e-02, avg batch time: 0.4845, average train loss: 6.2268
[09/25 22:16:45 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1663, average loss: 5.8801
[09/25 22:16:45 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 8.50	
[09/25 22:16:45 visual_prompt]: Training 79 / 100 epoch, with learning rate 7.016504991533726
[09/25 22:16:51 visual_prompt]: Epoch 79 / 100: avg data time: 5.26e-02, avg batch time: 0.4939, average train loss: 5.7867
[09/25 22:16:53 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1664, average loss: 5.5838
[09/25 22:16:53 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 3.50	
[09/25 22:16:53 visual_prompt]: Training 80 / 100 epoch, with learning rate 6.4213793630651415
[09/25 22:17:00 visual_prompt]: Epoch 80 / 100: avg data time: 5.44e-02, avg batch time: 0.4958, average train loss: 5.3651
[09/25 22:17:01 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1664, average loss: 4.8487
[09/25 22:17:01 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 7.00	
[09/25 22:17:01 visual_prompt]: Training 81 / 100 epoch, with learning rate 5.848888922025552
[09/25 22:17:08 visual_prompt]: Epoch 81 / 100: avg data time: 4.21e-02, avg batch time: 0.4865, average train loss: 5.0757
[09/25 22:17:09 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1662, average loss: 4.9882
[09/25 22:17:09 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 3.50	
[09/25 22:17:09 visual_prompt]: Training 82 / 100 epoch, with learning rate 5.2997311598319525
[09/25 22:17:16 visual_prompt]: Epoch 82 / 100: avg data time: 5.48e-02, avg batch time: 0.4985, average train loss: 4.9690
[09/25 22:17:17 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1663, average loss: 4.9733
[09/25 22:17:17 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.00	
[09/25 22:17:17 visual_prompt]: Training 83 / 100 epoch, with learning rate 4.774575140626316
[09/25 22:17:24 visual_prompt]: Epoch 83 / 100: avg data time: 5.23e-02, avg batch time: 0.4934, average train loss: 4.9815
[09/25 22:17:25 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1664, average loss: 4.7599
[09/25 22:17:25 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 5.00	
[09/25 22:17:25 visual_prompt]: Training 84 / 100 epoch, with learning rate 4.27406068612396
[09/25 22:17:32 visual_prompt]: Epoch 84 / 100: avg data time: 5.48e-02, avg batch time: 0.4974, average train loss: 4.8742
[09/25 22:17:33 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1663, average loss: 4.7847
[09/25 22:17:33 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 4.00	
[09/25 22:17:33 visual_prompt]: Training 85 / 100 epoch, with learning rate 3.798797596089351
[09/25 22:17:40 visual_prompt]: Epoch 85 / 100: avg data time: 5.54e-02, avg batch time: 0.4983, average train loss: 4.8390
[09/25 22:17:42 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1664, average loss: 4.7680
[09/25 22:17:42 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.50	top5: 5.00	
[09/25 22:17:42 visual_prompt]: Best epoch 85: best metric: 0.025
[09/25 22:17:42 visual_prompt]: Training 86 / 100 epoch, with learning rate 3.349364905389032
[09/25 22:17:48 visual_prompt]: Epoch 86 / 100: avg data time: 5.60e-02, avg batch time: 0.4974, average train loss: 4.7419
[09/25 22:17:50 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1665, average loss: 4.6894
[09/25 22:17:50 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.00	
[09/25 22:17:50 visual_prompt]: Training 87 / 100 epoch, with learning rate 2.9263101785268253
[09/25 22:17:56 visual_prompt]: Epoch 87 / 100: avg data time: 5.72e-02, avg batch time: 0.4988, average train loss: 4.7288
[09/25 22:17:58 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1663, average loss: 4.6912
[09/25 22:17:58 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 6.50	
[09/25 22:17:58 visual_prompt]: Training 88 / 100 epoch, with learning rate 2.5301488425208296
[09/25 22:18:05 visual_prompt]: Epoch 88 / 100: avg data time: 5.16e-02, avg batch time: 0.4951, average train loss: 4.7144
[09/25 22:18:06 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1662, average loss: 4.6462
[09/25 22:18:06 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 8.00	
[09/25 22:18:06 visual_prompt]: Training 89 / 100 epoch, with learning rate 2.1613635589349753
[09/25 22:18:13 visual_prompt]: Epoch 89 / 100: avg data time: 5.77e-02, avg batch time: 0.4995, average train loss: 4.5868
[09/25 22:18:14 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1663, average loss: 4.6073
[09/25 22:18:14 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 9.00	
[09/25 22:18:14 visual_prompt]: Training 90 / 100 epoch, with learning rate 1.820403635830317
[09/25 22:18:21 visual_prompt]: Epoch 90 / 100: avg data time: 5.72e-02, avg batch time: 0.4999, average train loss: 4.4920
[09/25 22:18:23 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1665, average loss: 4.5792
[09/25 22:18:23 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 11.00	
[09/25 22:18:23 visual_prompt]: Training 91 / 100 epoch, with learning rate 1.507684480352292
[09/25 22:18:29 visual_prompt]: Epoch 91 / 100: avg data time: 6.01e-02, avg batch time: 0.5020, average train loss: 4.4477
[09/25 22:18:31 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1662, average loss: 4.5698
[09/25 22:18:31 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 6.50	
[09/25 22:18:31 visual_prompt]: Training 92 / 100 epoch, with learning rate 1.2235870926211616
[09/25 22:18:38 visual_prompt]: Epoch 92 / 100: avg data time: 4.61e-02, avg batch time: 0.4896, average train loss: 4.3852
[09/25 22:18:39 visual_prompt]: Inference (val):avg data time: 3.91e-05, avg batch time: 0.1661, average loss: 4.5548
[09/25 22:18:39 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.50	top5: 10.00	
[09/25 22:18:39 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.9684576015420276
[09/25 22:18:46 visual_prompt]: Epoch 93 / 100: avg data time: 4.99e-02, avg batch time: 0.4924, average train loss: 4.3345
[09/25 22:18:47 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1662, average loss: 4.5072
[09/25 22:18:47 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 12.00	
[09/25 22:18:47 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.7426068431000882
[09/25 22:18:54 visual_prompt]: Epoch 94 / 100: avg data time: 4.23e-02, avg batch time: 0.4844, average train loss: 4.2813
[09/25 22:18:55 visual_prompt]: Inference (val):avg data time: 3.95e-05, avg batch time: 0.1663, average loss: 4.4844
[09/25 22:18:55 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 11.50	
[09/25 22:18:55 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.5463099816548578
[09/25 22:19:02 visual_prompt]: Epoch 95 / 100: avg data time: 4.01e-02, avg batch time: 0.4834, average train loss: 4.2531
[09/25 22:19:03 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1662, average loss: 4.4884
[09/25 22:19:03 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 13.50	
[09/25 22:19:03 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.3798061746947995
[09/25 22:19:10 visual_prompt]: Epoch 96 / 100: avg data time: 5.90e-02, avg batch time: 0.5004, average train loss: 4.2284
[09/25 22:19:12 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1664, average loss: 4.4624
[09/25 22:19:12 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 10.50	
[09/25 22:19:12 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.24329828146074095
[09/25 22:19:18 visual_prompt]: Epoch 97 / 100: avg data time: 5.87e-02, avg batch time: 0.5005, average train loss: 4.1940
[09/25 22:19:20 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1663, average loss: 4.4776
[09/25 22:19:20 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 11.50	
[09/25 22:19:20 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.13695261579316775
[09/25 22:19:26 visual_prompt]: Epoch 98 / 100: avg data time: 4.77e-02, avg batch time: 0.4892, average train loss: 4.1783
[09/25 22:19:28 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1662, average loss: 4.4641
[09/25 22:19:28 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 12.00	
[09/25 22:19:28 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.06089874350439506
[09/25 22:19:34 visual_prompt]: Epoch 99 / 100: avg data time: 4.48e-02, avg batch time: 0.4874, average train loss: 4.1650
[09/25 22:19:36 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1663, average loss: 4.4616
[09/25 22:19:36 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.50	top5: 11.50	
[09/25 22:19:36 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.015229324522605947
[09/25 22:19:43 visual_prompt]: Epoch 100 / 100: avg data time: 5.69e-02, avg batch time: 0.4992, average train loss: 4.1573
[09/25 22:19:44 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1664, average loss: 4.4630
[09/25 22:19:44 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.50	top5: 12.50	
[09/25 22:19:44 visual_prompt]: Rank of current process: 0. World size: 1
[09/25 22:19:44 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/25 22:19:44 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-cifar(num_classes=100)', 'DATA.NUMBER_CLASSES', '100', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/25 22:19:44 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/25 22:19:44 visual_prompt]: Training with config:
[09/25 22:19:44 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-cifar(num_classes=100)/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr50.0_wd0.0/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 50.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-cifar(num_classes=100)', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 100, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/25 22:19:44 visual_prompt]: Loading training data...
[09/25 22:19:44 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[:800], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/25 22:19:45 visual_prompt]: Number of images: 800
[09/25 22:19:45 visual_prompt]: Number of classes: 100 / 100
[09/25 22:19:45 visual_prompt]: Loading validation data...
[09/25 22:19:45 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[45000:45200], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/25 22:19:45 visual_prompt]: Number of images: 200
[09/25 22:19:45 visual_prompt]: Number of classes: 90 / 100
[09/25 22:19:45 visual_prompt]: Constructing models...
[09/25 22:19:48 visual_prompt]: Total Parameters: 86336356	 Gradient Parameters: 537700
[09/25 22:19:48 visual_prompt]: tuned percent:0.623
[09/25 22:19:48 visual_prompt]: Device used for model: 0
[09/25 22:19:48 visual_prompt]: Setting up Evaluator...
[09/25 22:19:48 visual_prompt]: Setting up Trainer...
[09/25 22:19:48 visual_prompt]: 	Setting up the optimizer...
[09/25 22:19:48 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/25 22:19:55 visual_prompt]: Epoch 1 / 100: avg data time: 4.79e-02, avg batch time: 0.4904, average train loss: 4.6559
[09/25 22:19:56 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1659, average loss: 4.6218
[09/25 22:19:56 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 7.00	
[09/25 22:19:56 visual_prompt]: Best epoch 1: best metric: 0.010
[09/25 22:19:56 visual_prompt]: Training 2 / 100 epoch, with learning rate 5.0
[09/25 22:20:03 visual_prompt]: Epoch 2 / 100: avg data time: 5.43e-02, avg batch time: 0.4943, average train loss: 5.0180
[09/25 22:20:04 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1660, average loss: 5.2208
[09/25 22:20:04 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.00	top5: 2.00	
[09/25 22:20:04 visual_prompt]: Training 3 / 100 epoch, with learning rate 10.0
[09/25 22:20:11 visual_prompt]: Epoch 3 / 100: avg data time: 5.73e-02, avg batch time: 0.4973, average train loss: 6.6024
[09/25 22:20:12 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1657, average loss: 10.2819
[09/25 22:20:12 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 7.00	
[09/25 22:20:12 visual_prompt]: Best epoch 3: best metric: 0.015
[09/25 22:20:12 visual_prompt]: Training 4 / 100 epoch, with learning rate 15.0
[09/25 22:20:19 visual_prompt]: Epoch 4 / 100: avg data time: 6.46e-02, avg batch time: 0.5046, average train loss: 13.2329
[09/25 22:20:21 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1660, average loss: 14.6461
[09/25 22:20:21 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.00	
[09/25 22:20:21 visual_prompt]: Training 5 / 100 epoch, with learning rate 20.0
[09/25 22:20:27 visual_prompt]: Epoch 5 / 100: avg data time: 4.44e-02, avg batch time: 0.4862, average train loss: 22.7561
[09/25 22:20:29 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1661, average loss: 19.9352
[09/25 22:20:29 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.00	
[09/25 22:20:29 visual_prompt]: Training 6 / 100 epoch, with learning rate 25.0
[09/25 22:20:35 visual_prompt]: Epoch 6 / 100: avg data time: 4.84e-02, avg batch time: 0.4898, average train loss: 34.8691
[09/25 22:20:37 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1659, average loss: 47.6935
[09/25 22:20:37 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 7.00	
[09/25 22:20:37 visual_prompt]: Training 7 / 100 epoch, with learning rate 30.0
[09/25 22:20:44 visual_prompt]: Epoch 7 / 100: avg data time: 5.79e-02, avg batch time: 0.4988, average train loss: 59.8571
[09/25 22:20:45 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1659, average loss: 63.4093
[09/25 22:20:45 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 6.50	
[09/25 22:20:45 visual_prompt]: Training 8 / 100 epoch, with learning rate 35.0
[09/25 22:20:52 visual_prompt]: Epoch 8 / 100: avg data time: 4.16e-02, avg batch time: 0.4834, average train loss: 84.3098
[09/25 22:20:53 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1661, average loss: 89.4938
[09/25 22:20:53 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 4.50	
[09/25 22:20:53 visual_prompt]: Training 9 / 100 epoch, with learning rate 40.0
[09/25 22:21:00 visual_prompt]: Epoch 9 / 100: avg data time: 4.11e-02, avg batch time: 0.4823, average train loss: 107.5997
[09/25 22:21:01 visual_prompt]: Inference (val):avg data time: 4.06e-05, avg batch time: 0.1660, average loss: 103.0946
[09/25 22:21:01 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 6.00	
[09/25 22:21:01 visual_prompt]: Training 10 / 100 epoch, with learning rate 45.0
[09/25 22:21:08 visual_prompt]: Epoch 10 / 100: avg data time: 5.28e-02, avg batch time: 0.4945, average train loss: 135.5048
[09/25 22:21:09 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1661, average loss: 118.0872
[09/25 22:21:09 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.00	
[09/25 22:21:09 visual_prompt]: Training 11 / 100 epoch, with learning rate 50.0
[09/25 22:21:16 visual_prompt]: Epoch 11 / 100: avg data time: 5.39e-02, avg batch time: 0.4957, average train loss: 160.3155
[09/25 22:21:17 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1661, average loss: 170.9865
[09/25 22:21:17 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.00	
[09/25 22:21:17 visual_prompt]: Training 12 / 100 epoch, with learning rate 49.9847706754774
[09/25 22:21:24 visual_prompt]: Epoch 12 / 100: avg data time: 5.79e-02, avg batch time: 0.4982, average train loss: 211.4236
[09/25 22:21:25 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1664, average loss: 226.5425
[09/25 22:21:25 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.00	
[09/25 22:21:25 visual_prompt]: Training 13 / 100 epoch, with learning rate 49.939101256495604
[09/25 22:21:32 visual_prompt]: Epoch 13 / 100: avg data time: 5.46e-02, avg batch time: 0.4955, average train loss: 253.8251
[09/25 22:21:33 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1661, average loss: 215.1138
[09/25 22:21:33 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 3.50	
[09/25 22:21:33 visual_prompt]: Training 14 / 100 epoch, with learning rate 49.86304738420683
[09/25 22:21:40 visual_prompt]: Epoch 14 / 100: avg data time: 4.48e-02, avg batch time: 0.4871, average train loss: 232.8190
[09/25 22:21:41 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1661, average loss: 226.6590
[09/25 22:21:41 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 3.50	
[09/25 22:21:41 visual_prompt]: Training 15 / 100 epoch, with learning rate 49.75670171853926
[09/25 22:21:48 visual_prompt]: Epoch 15 / 100: avg data time: 4.02e-02, avg batch time: 0.4817, average train loss: 207.2060
[09/25 22:21:49 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1659, average loss: 199.1074
[09/25 22:21:49 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 5.50	
[09/25 22:21:49 visual_prompt]: Training 16 / 100 epoch, with learning rate 49.6201938253052
[09/25 22:21:56 visual_prompt]: Epoch 16 / 100: avg data time: 4.34e-02, avg batch time: 0.4855, average train loss: 209.7956
[09/25 22:21:57 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1659, average loss: 248.3934
[09/25 22:21:57 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 1.50	
[09/25 22:21:57 visual_prompt]: Training 17 / 100 epoch, with learning rate 49.45369001834514
[09/25 22:22:04 visual_prompt]: Epoch 17 / 100: avg data time: 4.38e-02, avg batch time: 0.4844, average train loss: 216.3598
[09/25 22:22:05 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1661, average loss: 187.3606
[09/25 22:22:05 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.50	
[09/25 22:22:05 visual_prompt]: Training 18 / 100 epoch, with learning rate 49.25739315689991
[09/25 22:22:12 visual_prompt]: Epoch 18 / 100: avg data time: 5.55e-02, avg batch time: 0.4958, average train loss: 187.7600
[09/25 22:22:14 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1661, average loss: 167.4076
[09/25 22:22:14 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 5.50	
[09/25 22:22:14 visual_prompt]: Training 19 / 100 epoch, with learning rate 49.03154239845797
[09/25 22:22:20 visual_prompt]: Epoch 19 / 100: avg data time: 4.53e-02, avg batch time: 0.4878, average train loss: 189.5061
[09/25 22:22:22 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1661, average loss: 192.3847
[09/25 22:22:22 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 6.50	
[09/25 22:22:22 visual_prompt]: Best epoch 19: best metric: 0.020
[09/25 22:22:22 visual_prompt]: Training 20 / 100 epoch, with learning rate 48.77641290737884
[09/25 22:22:28 visual_prompt]: Epoch 20 / 100: avg data time: 5.99e-02, avg batch time: 0.5005, average train loss: 195.5250
[09/25 22:22:30 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1661, average loss: 193.5074
[09/25 22:22:30 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 4.50	
[09/25 22:22:30 visual_prompt]: Training 21 / 100 epoch, with learning rate 48.49231551964771
[09/25 22:22:36 visual_prompt]: Epoch 21 / 100: avg data time: 4.39e-02, avg batch time: 0.4884, average train loss: 192.2392
[09/25 22:22:38 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1662, average loss: 195.2146
[09/25 22:22:38 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 5.50	
[09/25 22:22:38 visual_prompt]: Training 22 / 100 epoch, with learning rate 48.17959636416968
[09/25 22:22:44 visual_prompt]: Epoch 22 / 100: avg data time: 5.25e-02, avg batch time: 0.4931, average train loss: 188.7894
[09/25 22:22:46 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1660, average loss: 175.2194
[09/25 22:22:46 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 2.00	
[09/25 22:22:46 visual_prompt]: Training 23 / 100 epoch, with learning rate 47.83863644106502
[09/25 22:22:53 visual_prompt]: Epoch 23 / 100: avg data time: 4.78e-02, avg batch time: 0.4885, average train loss: 156.5312
[09/25 22:22:54 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1661, average loss: 158.3014
[09/25 22:22:54 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.50	
[09/25 22:22:54 visual_prompt]: Training 24 / 100 epoch, with learning rate 47.46985115747918
[09/25 22:23:01 visual_prompt]: Epoch 24 / 100: avg data time: 5.56e-02, avg batch time: 0.4965, average train loss: 139.6466
[09/25 22:23:02 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1661, average loss: 135.9346
[09/25 22:23:02 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/25 22:23:02 visual_prompt]: Training 25 / 100 epoch, with learning rate 47.073689821473174
[09/25 22:23:09 visual_prompt]: Epoch 25 / 100: avg data time: 4.36e-02, avg batch time: 0.4868, average train loss: 124.8262
[09/25 22:23:10 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1669, average loss: 126.2760
[09/25 22:23:10 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.50	
[09/25 22:23:10 visual_prompt]: Training 26 / 100 epoch, with learning rate 46.65063509461097
[09/25 22:23:17 visual_prompt]: Epoch 26 / 100: avg data time: 5.60e-02, avg batch time: 0.4969, average train loss: 127.1084
[09/25 22:23:18 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1662, average loss: 131.0481
[09/25 22:23:18 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 5.50	
[09/25 22:23:18 visual_prompt]: Training 27 / 100 epoch, with learning rate 46.20120240391065
[09/25 22:23:25 visual_prompt]: Epoch 27 / 100: avg data time: 5.07e-02, avg batch time: 0.4912, average train loss: 123.6815
[09/25 22:23:26 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1661, average loss: 133.5571
[09/25 22:23:26 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.00	
[09/25 22:23:26 visual_prompt]: Training 28 / 100 epoch, with learning rate 45.72593931387604
[09/25 22:23:33 visual_prompt]: Epoch 28 / 100: avg data time: 5.37e-02, avg batch time: 0.4945, average train loss: 117.8412
[09/25 22:23:34 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1660, average loss: 102.4685
[09/25 22:23:34 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 7.50	
[09/25 22:23:34 visual_prompt]: Training 29 / 100 epoch, with learning rate 45.22542485937369
[09/25 22:23:41 visual_prompt]: Epoch 29 / 100: avg data time: 5.47e-02, avg batch time: 0.4960, average train loss: 102.9882
[09/25 22:23:43 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1661, average loss: 99.0871
[09/25 22:23:43 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 4.00	
[09/25 22:23:43 visual_prompt]: Training 30 / 100 epoch, with learning rate 44.70026884016804
[09/25 22:23:49 visual_prompt]: Epoch 30 / 100: avg data time: 4.65e-02, avg batch time: 0.4892, average train loss: 88.0519
[09/25 22:23:51 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1661, average loss: 86.9184
[09/25 22:23:51 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.50	
[09/25 22:23:51 visual_prompt]: Training 31 / 100 epoch, with learning rate 44.15111107797445
[09/25 22:23:57 visual_prompt]: Epoch 31 / 100: avg data time: 5.40e-02, avg batch time: 0.4959, average train loss: 70.1937
[09/25 22:23:59 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1662, average loss: 72.9323
[09/25 22:23:59 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 6.00	
[09/25 22:23:59 visual_prompt]: Training 32 / 100 epoch, with learning rate 43.57862063693486
[09/25 22:24:05 visual_prompt]: Epoch 32 / 100: avg data time: 4.98e-02, avg batch time: 0.4913, average train loss: 62.3928
[09/25 22:24:07 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1660, average loss: 69.9226
[09/25 22:24:07 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/25 22:24:07 visual_prompt]: Training 33 / 100 epoch, with learning rate 42.98349500846628
[09/25 22:24:13 visual_prompt]: Epoch 33 / 100: avg data time: 6.07e-02, avg batch time: 0.5010, average train loss: 59.8708
[09/25 22:24:15 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1659, average loss: 60.6637
[09/25 22:24:15 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 3.00	
[09/25 22:24:15 visual_prompt]: Training 34 / 100 epoch, with learning rate 42.36645926147493
[09/25 22:24:22 visual_prompt]: Epoch 34 / 100: avg data time: 5.38e-02, avg batch time: 0.4943, average train loss: 55.4960
[09/25 22:24:23 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1660, average loss: 47.7964
[09/25 22:24:23 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 5.50	
[09/25 22:24:23 visual_prompt]: Training 35 / 100 epoch, with learning rate 41.72826515897145
[09/25 22:24:30 visual_prompt]: Epoch 35 / 100: avg data time: 4.96e-02, avg batch time: 0.4907, average train loss: 48.0945
[09/25 22:24:31 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1662, average loss: 42.2035
[09/25 22:24:31 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 5.00	
[09/25 22:24:31 visual_prompt]: Training 36 / 100 epoch, with learning rate 41.06969024216348
[09/25 22:24:38 visual_prompt]: Epoch 36 / 100: avg data time: 4.72e-02, avg batch time: 0.4892, average train loss: 43.0525
[09/25 22:24:39 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1660, average loss: 39.6192
[09/25 22:24:39 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 7.50	
[09/25 22:24:39 visual_prompt]: Training 37 / 100 epoch, with learning rate 40.391536883141455
[09/25 22:24:46 visual_prompt]: Epoch 37 / 100: avg data time: 5.34e-02, avg batch time: 0.4954, average train loss: 36.8653
[09/25 22:24:47 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1661, average loss: 32.4410
[09/25 22:24:47 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 6.00	
[09/25 22:24:47 visual_prompt]: Training 38 / 100 epoch, with learning rate 39.69463130731183
[09/25 22:24:54 visual_prompt]: Epoch 38 / 100: avg data time: 6.05e-02, avg batch time: 0.5018, average train loss: 28.5110
[09/25 22:24:56 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1662, average loss: 26.9403
[09/25 22:24:56 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 6.00	
[09/25 22:24:56 visual_prompt]: Training 39 / 100 epoch, with learning rate 38.97982258676867
[09/25 22:25:02 visual_prompt]: Epoch 39 / 100: avg data time: 4.28e-02, avg batch time: 0.4867, average train loss: 27.6011
[09/25 22:25:04 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1660, average loss: 24.9231
[09/25 22:25:04 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/25 22:25:04 visual_prompt]: Training 40 / 100 epoch, with learning rate 38.24798160583012
[09/25 22:25:10 visual_prompt]: Epoch 40 / 100: avg data time: 5.36e-02, avg batch time: 0.4951, average train loss: 25.0326
[09/25 22:25:12 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1662, average loss: 26.1800
[09/25 22:25:12 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.50	
[09/25 22:25:12 visual_prompt]: Training 41 / 100 epoch, with learning rate 37.5
[09/25 22:25:18 visual_prompt]: Epoch 41 / 100: avg data time: 5.62e-02, avg batch time: 0.4975, average train loss: 22.9195
[09/25 22:25:20 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1663, average loss: 30.1327
[09/25 22:25:20 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.00	top5: 5.00	
[09/25 22:25:20 visual_prompt]: Training 42 / 100 epoch, with learning rate 36.736789069647266
[09/25 22:25:27 visual_prompt]: Epoch 42 / 100: avg data time: 5.15e-02, avg batch time: 0.4933, average train loss: 21.3514
[09/25 22:25:28 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1662, average loss: 18.9966
[09/25 22:25:28 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 7.00	
[09/25 22:25:28 visual_prompt]: Training 43 / 100 epoch, with learning rate 35.959278669726935
[09/25 22:25:35 visual_prompt]: Epoch 43 / 100: avg data time: 5.45e-02, avg batch time: 0.4968, average train loss: 19.5056
[09/25 22:25:36 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1661, average loss: 19.9109
[09/25 22:25:36 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 6.00	
[09/25 22:25:36 visual_prompt]: Training 44 / 100 epoch, with learning rate 35.16841607689501
[09/25 22:25:43 visual_prompt]: Epoch 44 / 100: avg data time: 5.59e-02, avg batch time: 0.4965, average train loss: 16.2848
[09/25 22:25:44 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1662, average loss: 24.0493
[09/25 22:25:44 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 7.00	
[09/25 22:25:44 visual_prompt]: Training 45 / 100 epoch, with learning rate 34.365164835397806
[09/25 22:25:51 visual_prompt]: Epoch 45 / 100: avg data time: 4.56e-02, avg batch time: 0.4862, average train loss: 15.6982
[09/25 22:25:52 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1659, average loss: 19.0099
[09/25 22:25:52 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.50	top5: 4.00	
[09/25 22:25:52 visual_prompt]: Best epoch 45: best metric: 0.025
[09/25 22:25:52 visual_prompt]: Training 46 / 100 epoch, with learning rate 33.55050358314172
[09/25 22:25:59 visual_prompt]: Epoch 46 / 100: avg data time: 4.63e-02, avg batch time: 0.4894, average train loss: 14.7889
[09/25 22:26:00 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1660, average loss: 19.6781
[09/25 22:26:00 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.50	top5: 7.50	
[09/25 22:26:00 visual_prompt]: Training 47 / 100 epoch, with learning rate 32.72542485937369
[09/25 22:26:07 visual_prompt]: Epoch 47 / 100: avg data time: 5.12e-02, avg batch time: 0.4934, average train loss: 16.4153
[09/25 22:26:09 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1660, average loss: 20.4833
[09/25 22:26:09 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 4.50	
[09/25 22:26:09 visual_prompt]: Training 48 / 100 epoch, with learning rate 31.89093389542498
[09/25 22:26:15 visual_prompt]: Epoch 48 / 100: avg data time: 5.01e-02, avg batch time: 0.4919, average train loss: 15.7743
[09/25 22:26:17 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1661, average loss: 27.8680
[09/25 22:26:17 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/25 22:26:17 visual_prompt]: Training 49 / 100 epoch, with learning rate 31.04804738999169
[09/25 22:26:23 visual_prompt]: Epoch 49 / 100: avg data time: 5.26e-02, avg batch time: 0.4939, average train loss: 15.9859
[09/25 22:26:25 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1662, average loss: 20.3215
[09/25 22:26:25 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 10.00	
[09/25 22:26:25 visual_prompt]: Training 50 / 100 epoch, with learning rate 30.19779227044398
[09/25 22:26:32 visual_prompt]: Epoch 50 / 100: avg data time: 5.68e-02, avg batch time: 0.4975, average train loss: 14.3894
[09/25 22:26:33 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1663, average loss: 15.6502
[09/25 22:26:33 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 7.50	
[09/25 22:26:33 visual_prompt]: Training 51 / 100 epoch, with learning rate 29.341204441673263
[09/25 22:26:40 visual_prompt]: Epoch 51 / 100: avg data time: 5.77e-02, avg batch time: 0.4985, average train loss: 12.5355
[09/25 22:26:41 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1663, average loss: 14.8236
[09/25 22:26:41 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 6.00	
[09/25 22:26:41 visual_prompt]: Training 52 / 100 epoch, with learning rate 28.479327524001636
[09/25 22:26:48 visual_prompt]: Epoch 52 / 100: avg data time: 5.73e-02, avg batch time: 0.4980, average train loss: 11.0123
[09/25 22:26:49 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1662, average loss: 17.0693
[09/25 22:26:49 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 6.00	
[09/25 22:26:49 visual_prompt]: Training 53 / 100 epoch, with learning rate 27.61321158169134
[09/25 22:26:56 visual_prompt]: Epoch 53 / 100: avg data time: 5.23e-02, avg batch time: 0.4943, average train loss: 11.1336
[09/25 22:26:58 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1660, average loss: 14.7363
[09/25 22:26:58 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 8.00	
[09/25 22:26:58 visual_prompt]: Training 54 / 100 epoch, with learning rate 26.74391184360313
[09/25 22:27:04 visual_prompt]: Epoch 54 / 100: avg data time: 5.53e-02, avg batch time: 0.4966, average train loss: 10.8758
[09/25 22:27:06 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1661, average loss: 15.3331
[09/25 22:27:06 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.50	top5: 4.50	
[09/25 22:27:06 visual_prompt]: Training 55 / 100 epoch, with learning rate 25.872487417562528
[09/25 22:27:12 visual_prompt]: Epoch 55 / 100: avg data time: 5.78e-02, avg batch time: 0.4992, average train loss: 11.3151
[09/25 22:27:14 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1661, average loss: 14.9814
[09/25 22:27:14 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 5.00	
[09/25 22:27:14 visual_prompt]: Training 56 / 100 epoch, with learning rate 25.0
[09/25 22:27:21 visual_prompt]: Epoch 56 / 100: avg data time: 5.63e-02, avg batch time: 0.4980, average train loss: 11.7318
[09/25 22:27:22 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1661, average loss: 13.1383
[09/25 22:27:22 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 3.00	top5: 6.50	
[09/25 22:27:22 visual_prompt]: Best epoch 56: best metric: 0.030
[09/25 22:27:22 visual_prompt]: Training 57 / 100 epoch, with learning rate 24.127512582437483
[09/25 22:27:29 visual_prompt]: Epoch 57 / 100: avg data time: 4.68e-02, avg batch time: 0.4884, average train loss: 10.5902
[09/25 22:27:30 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1663, average loss: 15.5626
[09/25 22:27:30 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 5.50	
[09/25 22:27:30 visual_prompt]: Training 58 / 100 epoch, with learning rate 23.256088156396867
[09/25 22:27:37 visual_prompt]: Epoch 58 / 100: avg data time: 5.71e-02, avg batch time: 0.4979, average train loss: 9.8846
[09/25 22:27:38 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1660, average loss: 14.2452
[09/25 22:27:38 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 7.00	
[09/25 22:27:38 visual_prompt]: Training 59 / 100 epoch, with learning rate 22.38678841830867
[09/25 22:27:45 visual_prompt]: Epoch 59 / 100: avg data time: 5.02e-02, avg batch time: 0.4917, average train loss: 9.6083
[09/25 22:27:46 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1663, average loss: 15.3944
[09/25 22:27:46 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.50	top5: 7.50	
[09/25 22:27:46 visual_prompt]: Training 60 / 100 epoch, with learning rate 21.52067247599837
[09/25 22:27:53 visual_prompt]: Epoch 60 / 100: avg data time: 5.81e-02, avg batch time: 0.5002, average train loss: 9.6484
[09/25 22:27:55 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1661, average loss: 19.3508
[09/25 22:27:55 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 7.00	
[09/25 22:27:55 visual_prompt]: Training 61 / 100 epoch, with learning rate 20.65879555832674
[09/25 22:28:01 visual_prompt]: Epoch 61 / 100: avg data time: 5.74e-02, avg batch time: 0.4987, average train loss: 9.0733
[09/25 22:28:03 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1662, average loss: 12.3841
[09/25 22:28:03 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 6.50	
[09/25 22:28:03 visual_prompt]: Training 62 / 100 epoch, with learning rate 19.80220772955602
[09/25 22:28:10 visual_prompt]: Epoch 62 / 100: avg data time: 5.59e-02, avg batch time: 0.4967, average train loss: 9.0472
[09/25 22:28:11 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1661, average loss: 10.8357
[09/25 22:28:11 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.50	top5: 9.50	
[09/25 22:28:11 visual_prompt]: Training 63 / 100 epoch, with learning rate 18.95195261000831
[09/25 22:28:18 visual_prompt]: Epoch 63 / 100: avg data time: 5.62e-02, avg batch time: 0.4976, average train loss: 9.1255
[09/25 22:28:19 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1660, average loss: 13.8516
[09/25 22:28:19 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.50	
[09/25 22:28:19 visual_prompt]: Training 64 / 100 epoch, with learning rate 18.10906610457502
[09/25 22:28:26 visual_prompt]: Epoch 64 / 100: avg data time: 5.26e-02, avg batch time: 0.4942, average train loss: 9.0520
[09/25 22:28:27 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1661, average loss: 13.9435
[09/25 22:28:27 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 6.00	
[09/25 22:28:27 visual_prompt]: Training 65 / 100 epoch, with learning rate 17.274575140626318
[09/25 22:28:34 visual_prompt]: Epoch 65 / 100: avg data time: 5.93e-02, avg batch time: 0.4999, average train loss: 8.4120
[09/25 22:28:36 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1661, average loss: 11.6276
[09/25 22:28:36 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 7.00	
[09/25 22:28:36 visual_prompt]: Training 66 / 100 epoch, with learning rate 16.449496416858285
[09/25 22:28:42 visual_prompt]: Epoch 66 / 100: avg data time: 5.20e-02, avg batch time: 0.4943, average train loss: 8.2633
[09/25 22:28:44 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1661, average loss: 11.9877
[09/25 22:28:44 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 5.50	
[09/25 22:28:44 visual_prompt]: Training 67 / 100 epoch, with learning rate 15.634835164602197
[09/25 22:28:51 visual_prompt]: Epoch 67 / 100: avg data time: 5.82e-02, avg batch time: 0.5016, average train loss: 8.6655
[09/25 22:28:52 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1664, average loss: 11.3377
[09/25 22:28:52 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 6.00	
[09/25 22:28:52 visual_prompt]: Training 68 / 100 epoch, with learning rate 14.831583923104999
[09/25 22:28:59 visual_prompt]: Epoch 68 / 100: avg data time: 5.40e-02, avg batch time: 0.4950, average train loss: 8.1368
[09/25 22:29:00 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1660, average loss: 12.0332
[09/25 22:29:00 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 4.00	
[09/25 22:29:00 visual_prompt]: Training 69 / 100 epoch, with learning rate 14.040721330273062
[09/25 22:29:07 visual_prompt]: Epoch 69 / 100: avg data time: 5.45e-02, avg batch time: 0.4959, average train loss: 8.2828
[09/25 22:29:08 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1660, average loss: 12.1459
[09/25 22:29:08 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 6.50	
[09/25 22:29:08 visual_prompt]: Training 70 / 100 epoch, with learning rate 13.263210930352736
[09/25 22:29:15 visual_prompt]: Epoch 70 / 100: avg data time: 5.34e-02, avg batch time: 0.4966, average train loss: 7.6040
[09/25 22:29:16 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1661, average loss: 10.9960
[09/25 22:29:16 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 5.50	
[09/25 22:29:16 visual_prompt]: Training 71 / 100 epoch, with learning rate 12.500000000000005
[09/25 22:29:23 visual_prompt]: Epoch 71 / 100: avg data time: 5.20e-02, avg batch time: 0.4939, average train loss: 7.9266
[09/25 22:29:25 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1662, average loss: 13.2275
[09/25 22:29:25 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 7.50	
[09/25 22:29:25 visual_prompt]: Training 72 / 100 epoch, with learning rate 11.75201839416988
[09/25 22:29:31 visual_prompt]: Epoch 72 / 100: avg data time: 5.41e-02, avg batch time: 0.4957, average train loss: 7.7015
[09/25 22:29:33 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1660, average loss: 11.2896
[09/25 22:29:33 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 7.50	
[09/25 22:29:33 visual_prompt]: Training 73 / 100 epoch, with learning rate 11.020177413231332
[09/25 22:29:39 visual_prompt]: Epoch 73 / 100: avg data time: 5.08e-02, avg batch time: 0.4939, average train loss: 7.4086
[09/25 22:29:41 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1663, average loss: 10.9829
[09/25 22:29:41 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 4.50	
[09/25 22:29:41 visual_prompt]: Training 74 / 100 epoch, with learning rate 10.305368692688175
[09/25 22:29:48 visual_prompt]: Epoch 74 / 100: avg data time: 5.63e-02, avg batch time: 0.4993, average train loss: 7.5373
[09/25 22:29:49 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1661, average loss: 11.5712
[09/25 22:29:49 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 6.00	
[09/25 22:29:49 visual_prompt]: Training 75 / 100 epoch, with learning rate 9.608463116858543
[09/25 22:29:56 visual_prompt]: Epoch 75 / 100: avg data time: 4.42e-02, avg batch time: 0.4850, average train loss: 7.3254
[09/25 22:29:57 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1662, average loss: 12.9543
[09/25 22:29:57 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 8.50	
[09/25 22:29:57 visual_prompt]: Training 76 / 100 epoch, with learning rate 8.930309757836516
[09/25 22:30:04 visual_prompt]: Epoch 76 / 100: avg data time: 5.40e-02, avg batch time: 0.4949, average train loss: 7.1365
[09/25 22:30:05 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1662, average loss: 13.0417
[09/25 22:30:05 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 5.50	
[09/25 22:30:05 visual_prompt]: Training 77 / 100 epoch, with learning rate 8.271734841028552
[09/25 22:30:12 visual_prompt]: Epoch 77 / 100: avg data time: 5.00e-02, avg batch time: 0.4924, average train loss: 7.0055
[09/25 22:30:13 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1662, average loss: 11.0686
[09/25 22:30:13 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.50	top5: 7.50	
[09/25 22:30:13 visual_prompt]: Training 78 / 100 epoch, with learning rate 7.633540738525066
[09/25 22:30:20 visual_prompt]: Epoch 78 / 100: avg data time: 5.01e-02, avg batch time: 0.4929, average train loss: 6.9614
[09/25 22:30:21 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1664, average loss: 11.7753
[09/25 22:30:21 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.50	top5: 8.00	
[09/25 22:30:21 visual_prompt]: Training 79 / 100 epoch, with learning rate 7.016504991533726
[09/25 22:30:28 visual_prompt]: Epoch 79 / 100: avg data time: 5.56e-02, avg batch time: 0.4966, average train loss: 6.7989
[09/25 22:30:30 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1666, average loss: 13.1637
[09/25 22:30:30 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 8.50	
[09/25 22:30:30 visual_prompt]: Training 80 / 100 epoch, with learning rate 6.4213793630651415
[09/25 22:30:36 visual_prompt]: Epoch 80 / 100: avg data time: 4.59e-02, avg batch time: 0.4877, average train loss: 7.0745
[09/25 22:30:38 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1661, average loss: 11.9965
[09/25 22:30:38 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.50	top5: 6.50	
[09/25 22:30:38 visual_prompt]: Training 81 / 100 epoch, with learning rate 5.848888922025552
[09/25 22:30:44 visual_prompt]: Epoch 81 / 100: avg data time: 5.34e-02, avg batch time: 0.4959, average train loss: 6.6786
[09/25 22:30:46 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1662, average loss: 11.7731
[09/25 22:30:46 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 7.00	
[09/25 22:30:46 visual_prompt]: Training 82 / 100 epoch, with learning rate 5.2997311598319525
[09/25 22:30:53 visual_prompt]: Epoch 82 / 100: avg data time: 5.84e-02, avg batch time: 0.4995, average train loss: 6.7222
[09/25 22:30:54 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1663, average loss: 11.5402
[09/25 22:30:54 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.50	top5: 6.50	
[09/25 22:30:54 visual_prompt]: Training 83 / 100 epoch, with learning rate 4.774575140626316
[09/25 22:31:01 visual_prompt]: Epoch 83 / 100: avg data time: 5.86e-02, avg batch time: 0.4997, average train loss: 6.6147
[09/25 22:31:02 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1663, average loss: 13.0986
[09/25 22:31:02 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 7.00	
[09/25 22:31:02 visual_prompt]: Training 84 / 100 epoch, with learning rate 4.27406068612396
[09/25 22:31:09 visual_prompt]: Epoch 84 / 100: avg data time: 5.31e-02, avg batch time: 0.4950, average train loss: 6.6188
[09/25 22:31:10 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1664, average loss: 11.7820
[09/25 22:31:10 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.50	top5: 7.50	
[09/25 22:31:10 visual_prompt]: Training 85 / 100 epoch, with learning rate 3.798797596089351
[09/25 22:31:17 visual_prompt]: Epoch 85 / 100: avg data time: 5.79e-02, avg batch time: 0.5001, average train loss: 6.5738
[09/25 22:31:18 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1665, average loss: 12.2862
[09/25 22:31:18 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.50	top5: 5.00	
[09/25 22:31:18 visual_prompt]: Training 86 / 100 epoch, with learning rate 3.349364905389032
[09/25 22:31:25 visual_prompt]: Epoch 86 / 100: avg data time: 5.55e-02, avg batch time: 0.4968, average train loss: 6.2374
[09/25 22:31:27 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1664, average loss: 12.8621
[09/25 22:31:27 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 7.00	
[09/25 22:31:27 visual_prompt]: Training 87 / 100 epoch, with learning rate 2.9263101785268253
[09/25 22:31:33 visual_prompt]: Epoch 87 / 100: avg data time: 5.34e-02, avg batch time: 0.4947, average train loss: 6.2996
[09/25 22:31:35 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1664, average loss: 11.0338
[09/25 22:31:35 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.50	top5: 6.00	
[09/25 22:31:35 visual_prompt]: Training 88 / 100 epoch, with learning rate 2.5301488425208296
[09/25 22:31:41 visual_prompt]: Epoch 88 / 100: avg data time: 5.05e-02, avg batch time: 0.4923, average train loss: 6.4450
[09/25 22:31:43 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1666, average loss: 12.1059
[09/25 22:31:43 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.50	top5: 6.50	
[09/25 22:31:43 visual_prompt]: Training 89 / 100 epoch, with learning rate 2.1613635589349753
[09/25 22:31:50 visual_prompt]: Epoch 89 / 100: avg data time: 5.51e-02, avg batch time: 0.4964, average train loss: 6.4043
[09/25 22:31:51 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1663, average loss: 11.8027
[09/25 22:31:51 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 7.50	
[09/25 22:31:51 visual_prompt]: Training 90 / 100 epoch, with learning rate 1.820403635830317
[09/25 22:31:58 visual_prompt]: Epoch 90 / 100: avg data time: 3.99e-02, avg batch time: 0.4840, average train loss: 6.2369
[09/25 22:31:59 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1663, average loss: 11.7318
[09/25 22:31:59 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.50	top5: 6.00	
[09/25 22:31:59 visual_prompt]: Training 91 / 100 epoch, with learning rate 1.507684480352292
[09/25 22:32:06 visual_prompt]: Epoch 91 / 100: avg data time: 4.92e-02, avg batch time: 0.4904, average train loss: 6.4073
[09/25 22:32:07 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1662, average loss: 12.1471
[09/25 22:32:07 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 6.00	
[09/25 22:32:07 visual_prompt]: Training 92 / 100 epoch, with learning rate 1.2235870926211616
[09/25 22:32:14 visual_prompt]: Epoch 92 / 100: avg data time: 5.25e-02, avg batch time: 0.4947, average train loss: 6.3285
[09/25 22:32:15 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1663, average loss: 11.7580
[09/25 22:32:15 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 6.00	
[09/25 22:32:15 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.9684576015420276
[09/25 22:32:22 visual_prompt]: Epoch 93 / 100: avg data time: 4.99e-02, avg batch time: 0.4919, average train loss: 6.3431
[09/25 22:32:23 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1661, average loss: 11.9880
[09/25 22:32:23 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 7.00	
[09/25 22:32:23 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.7426068431000882
[09/25 22:32:30 visual_prompt]: Epoch 94 / 100: avg data time: 5.66e-02, avg batch time: 0.4973, average train loss: 6.4282
[09/25 22:32:32 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1662, average loss: 11.9814
[09/25 22:32:32 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 6.50	
[09/25 22:32:32 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.5463099816548578
[09/25 22:32:38 visual_prompt]: Epoch 95 / 100: avg data time: 5.71e-02, avg batch time: 0.4991, average train loss: 6.1062
[09/25 22:32:40 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1661, average loss: 11.8137
[09/25 22:32:40 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.50	top5: 6.50	
[09/25 22:32:40 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.3798061746947995
[09/25 22:32:46 visual_prompt]: Epoch 96 / 100: avg data time: 4.88e-02, avg batch time: 0.4911, average train loss: 6.2456
[09/25 22:32:48 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1662, average loss: 12.0352
[09/25 22:32:48 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 6.50	
[09/25 22:32:48 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.24329828146074095
[09/25 22:32:55 visual_prompt]: Epoch 97 / 100: avg data time: 5.57e-02, avg batch time: 0.4967, average train loss: 6.3987
[09/25 22:32:56 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1660, average loss: 12.1109
[09/25 22:32:56 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 6.50	
[09/25 22:32:56 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.13695261579316775
[09/25 22:33:03 visual_prompt]: Epoch 98 / 100: avg data time: 4.89e-02, avg batch time: 0.4910, average train loss: 6.2140
[09/25 22:33:04 visual_prompt]: Inference (val):avg data time: 4.39e-05, avg batch time: 0.1659, average loss: 12.0136
[09/25 22:33:04 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 6.50	
[09/25 22:33:04 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.06089874350439506
[09/25 22:33:11 visual_prompt]: Epoch 99 / 100: avg data time: 4.47e-02, avg batch time: 0.4861, average train loss: 6.3034
[09/25 22:33:12 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1661, average loss: 12.0170
[09/25 22:33:12 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 6.50	
[09/25 22:33:12 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.015229324522605947
[09/25 22:33:19 visual_prompt]: Epoch 100 / 100: avg data time: 5.81e-02, avg batch time: 0.4990, average train loss: 6.2599
[09/25 22:33:20 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1661, average loss: 12.0099
[09/25 22:33:20 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 6.50	
[09/25 22:33:20 visual_prompt]: Rank of current process: 0. World size: 1
[09/25 22:33:20 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/25 22:33:20 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-cifar(num_classes=100)', 'DATA.NUMBER_CLASSES', '100', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/25 22:33:20 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/25 22:33:20 visual_prompt]: Training with config:
[09/25 22:33:20 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-cifar(num_classes=100)/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr25.0_wd0.01/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 25.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-cifar(num_classes=100)', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 100, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/25 22:33:20 visual_prompt]: Loading training data...
[09/25 22:33:20 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[:800], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/25 22:33:21 visual_prompt]: Number of images: 800
[09/25 22:33:21 visual_prompt]: Number of classes: 100 / 100
[09/25 22:33:21 visual_prompt]: Loading validation data...
[09/25 22:33:21 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[45000:45200], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/25 22:33:22 visual_prompt]: Number of images: 200
[09/25 22:33:22 visual_prompt]: Number of classes: 90 / 100
[09/25 22:33:22 visual_prompt]: Constructing models...
[09/25 22:33:24 visual_prompt]: Total Parameters: 86336356	 Gradient Parameters: 537700
[09/25 22:33:24 visual_prompt]: tuned percent:0.623
[09/25 22:33:24 visual_prompt]: Device used for model: 0
[09/25 22:33:24 visual_prompt]: Setting up Evaluator...
[09/25 22:33:24 visual_prompt]: Setting up Trainer...
[09/25 22:33:24 visual_prompt]: 	Setting up the optimizer...
[09/25 22:33:24 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/25 22:33:31 visual_prompt]: Epoch 1 / 100: avg data time: 5.85e-02, avg batch time: 0.5006, average train loss: 4.6583
[09/25 22:33:32 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1659, average loss: 4.6218
[09/25 22:33:32 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 7.00	
[09/25 22:33:32 visual_prompt]: Best epoch 1: best metric: 0.010
[09/25 22:33:32 visual_prompt]: Training 2 / 100 epoch, with learning rate 2.5
[09/25 22:33:39 visual_prompt]: Epoch 2 / 100: avg data time: 5.15e-02, avg batch time: 0.4927, average train loss: 4.7269
[09/25 22:33:40 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1657, average loss: 4.8322
[09/25 22:33:40 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.00	
[09/25 22:33:40 visual_prompt]: Training 3 / 100 epoch, with learning rate 5.0
[09/25 22:33:47 visual_prompt]: Epoch 3 / 100: avg data time: 5.21e-02, avg batch time: 0.4927, average train loss: 4.9049
[09/25 22:33:49 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1658, average loss: 4.9036
[09/25 22:33:49 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 7.00	
[09/25 22:33:49 visual_prompt]: Best epoch 3: best metric: 0.015
[09/25 22:33:49 visual_prompt]: Training 4 / 100 epoch, with learning rate 7.5
[09/25 22:33:55 visual_prompt]: Epoch 4 / 100: avg data time: 5.46e-02, avg batch time: 0.4947, average train loss: 4.9778
[09/25 22:33:57 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1658, average loss: 5.1060
[09/25 22:33:57 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.00	
[09/25 22:33:57 visual_prompt]: Training 5 / 100 epoch, with learning rate 10.0
[09/25 22:34:03 visual_prompt]: Epoch 5 / 100: avg data time: 5.31e-02, avg batch time: 0.4938, average train loss: 5.3593
[09/25 22:34:05 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1659, average loss: 5.4977
[09/25 22:34:05 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.00	
[09/25 22:34:05 visual_prompt]: Training 6 / 100 epoch, with learning rate 12.5
[09/25 22:34:11 visual_prompt]: Epoch 6 / 100: avg data time: 4.54e-02, avg batch time: 0.4869, average train loss: 5.9552
[09/25 22:34:13 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1658, average loss: 7.2432
[09/25 22:34:13 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.00	top5: 4.00	
[09/25 22:34:13 visual_prompt]: Training 7 / 100 epoch, with learning rate 15.0
[09/25 22:34:20 visual_prompt]: Epoch 7 / 100: avg data time: 5.35e-02, avg batch time: 0.4951, average train loss: 7.8456
[09/25 22:34:21 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1659, average loss: 8.6574
[09/25 22:34:21 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 4.50	
[09/25 22:34:21 visual_prompt]: Training 8 / 100 epoch, with learning rate 17.5
[09/25 22:34:28 visual_prompt]: Epoch 8 / 100: avg data time: 5.04e-02, avg batch time: 0.4910, average train loss: 13.4668
[09/25 22:34:29 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1661, average loss: 14.6129
[09/25 22:34:29 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 3.50	
[09/25 22:34:29 visual_prompt]: Training 9 / 100 epoch, with learning rate 20.0
[09/25 22:34:36 visual_prompt]: Epoch 9 / 100: avg data time: 5.21e-02, avg batch time: 0.4927, average train loss: 22.3560
[09/25 22:34:37 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1658, average loss: 20.8714
[09/25 22:34:37 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.50	
[09/25 22:34:37 visual_prompt]: Training 10 / 100 epoch, with learning rate 22.5
[09/25 22:34:44 visual_prompt]: Epoch 10 / 100: avg data time: 5.63e-02, avg batch time: 0.4989, average train loss: 30.3500
[09/25 22:34:45 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1660, average loss: 29.4719
[09/25 22:34:45 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.50	
[09/25 22:34:45 visual_prompt]: Training 11 / 100 epoch, with learning rate 25.0
[09/25 22:34:52 visual_prompt]: Epoch 11 / 100: avg data time: 4.16e-02, avg batch time: 0.4823, average train loss: 42.1379
[09/25 22:34:53 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1662, average loss: 38.0084
[09/25 22:34:53 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.50	
[09/25 22:34:53 visual_prompt]: Training 12 / 100 epoch, with learning rate 24.9923853377387
[09/25 22:35:00 visual_prompt]: Epoch 12 / 100: avg data time: 4.44e-02, avg batch time: 0.4883, average train loss: 58.8270
[09/25 22:35:02 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1663, average loss: 54.2043
[09/25 22:35:02 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 3.50	
[09/25 22:35:02 visual_prompt]: Training 13 / 100 epoch, with learning rate 24.969550628247802
[09/25 22:35:08 visual_prompt]: Epoch 13 / 100: avg data time: 5.02e-02, avg batch time: 0.4914, average train loss: 61.9338
[09/25 22:35:10 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1660, average loss: 54.3877
[09/25 22:35:10 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.00	top5: 4.00	
[09/25 22:35:10 visual_prompt]: Training 14 / 100 epoch, with learning rate 24.931523692103415
[09/25 22:35:16 visual_prompt]: Epoch 14 / 100: avg data time: 5.45e-02, avg batch time: 0.4955, average train loss: 78.7809
[09/25 22:35:18 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.1661, average loss: 64.4364
[09/25 22:35:18 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 3.00	top5: 7.50	
[09/25 22:35:18 visual_prompt]: Best epoch 14: best metric: 0.030
[09/25 22:35:18 visual_prompt]: Training 15 / 100 epoch, with learning rate 24.87835085926963
[09/25 22:35:25 visual_prompt]: Epoch 15 / 100: avg data time: 5.75e-02, avg batch time: 0.4992, average train loss: 70.7079
[09/25 22:35:26 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1661, average loss: 65.4200
[09/25 22:35:26 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 6.00	
[09/25 22:35:26 visual_prompt]: Training 16 / 100 epoch, with learning rate 24.8100969126526
[09/25 22:35:33 visual_prompt]: Epoch 16 / 100: avg data time: 6.03e-02, avg batch time: 0.5010, average train loss: 79.9284
[09/25 22:35:34 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1660, average loss: 72.2212
[09/25 22:35:34 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 3.50	
[09/25 22:35:34 visual_prompt]: Training 17 / 100 epoch, with learning rate 24.72684500917257
[09/25 22:35:41 visual_prompt]: Epoch 17 / 100: avg data time: 5.12e-02, avg batch time: 0.4934, average train loss: 83.2152
[09/25 22:35:42 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1661, average loss: 74.5195
[09/25 22:35:42 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.00	top5: 6.00	
[09/25 22:35:42 visual_prompt]: Training 18 / 100 epoch, with learning rate 24.628696578449954
[09/25 22:35:49 visual_prompt]: Epoch 18 / 100: avg data time: 5.28e-02, avg batch time: 0.4937, average train loss: 82.5673
[09/25 22:35:50 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1661, average loss: 75.9386
[09/25 22:35:50 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/25 22:35:50 visual_prompt]: Training 19 / 100 epoch, with learning rate 24.515771199228986
[09/25 22:35:57 visual_prompt]: Epoch 19 / 100: avg data time: 5.12e-02, avg batch time: 0.4933, average train loss: 94.0643
[09/25 22:35:58 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1659, average loss: 85.7049
[09/25 22:35:58 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.00	
[09/25 22:35:58 visual_prompt]: Training 20 / 100 epoch, with learning rate 24.38820645368942
[09/25 22:36:05 visual_prompt]: Epoch 20 / 100: avg data time: 5.36e-02, avg batch time: 0.4950, average train loss: 97.1354
[09/25 22:36:07 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1663, average loss: 79.0721
[09/25 22:36:07 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 3.50	
[09/25 22:36:07 visual_prompt]: Training 21 / 100 epoch, with learning rate 24.246157759823856
[09/25 22:36:13 visual_prompt]: Epoch 21 / 100: avg data time: 5.50e-02, avg batch time: 0.4958, average train loss: 82.4954
[09/25 22:36:15 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1660, average loss: 92.4456
[09/25 22:36:15 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 6.50	
[09/25 22:36:15 visual_prompt]: Training 22 / 100 epoch, with learning rate 24.08979818208484
[09/25 22:36:22 visual_prompt]: Epoch 22 / 100: avg data time: 5.41e-02, avg batch time: 0.4958, average train loss: 85.4948
[09/25 22:36:23 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1661, average loss: 78.3209
[09/25 22:36:23 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 3.50	
[09/25 22:36:23 visual_prompt]: Training 23 / 100 epoch, with learning rate 23.91931822053251
[09/25 22:36:30 visual_prompt]: Epoch 23 / 100: avg data time: 4.75e-02, avg batch time: 0.4887, average train loss: 91.7520
[09/25 22:36:31 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1663, average loss: 88.7374
[09/25 22:36:31 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 3.50	
[09/25 22:36:31 visual_prompt]: Training 24 / 100 epoch, with learning rate 23.73492557873959
[09/25 22:36:38 visual_prompt]: Epoch 24 / 100: avg data time: 6.13e-02, avg batch time: 0.5045, average train loss: 89.5610
[09/25 22:36:39 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1662, average loss: 92.4088
[09/25 22:36:39 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 7.50	
[09/25 22:36:39 visual_prompt]: Training 25 / 100 epoch, with learning rate 23.536844910736587
[09/25 22:36:46 visual_prompt]: Epoch 25 / 100: avg data time: 4.47e-02, avg batch time: 0.4877, average train loss: 89.9447
[09/25 22:36:47 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1662, average loss: 82.6796
[09/25 22:36:47 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 6.50	
[09/25 22:36:47 visual_prompt]: Training 26 / 100 epoch, with learning rate 23.325317547305485
[09/25 22:36:54 visual_prompt]: Epoch 26 / 100: avg data time: 5.51e-02, avg batch time: 0.4965, average train loss: 83.4262
[09/25 22:36:56 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1664, average loss: 89.2603
[09/25 22:36:56 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.00	
[09/25 22:36:56 visual_prompt]: Training 27 / 100 epoch, with learning rate 23.100601201955325
[09/25 22:37:02 visual_prompt]: Epoch 27 / 100: avg data time: 5.38e-02, avg batch time: 0.4960, average train loss: 83.8357
[09/25 22:37:04 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1663, average loss: 78.4655
[09/25 22:37:04 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 4.00	
[09/25 22:37:04 visual_prompt]: Training 28 / 100 epoch, with learning rate 22.86296965693802
[09/25 22:37:10 visual_prompt]: Epoch 28 / 100: avg data time: 5.11e-02, avg batch time: 0.4926, average train loss: 82.2572
[09/25 22:37:12 visual_prompt]: Inference (val):avg data time: 3.80e-05, avg batch time: 0.1661, average loss: 82.6544
[09/25 22:37:12 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 4.50	
[09/25 22:37:12 visual_prompt]: Training 29 / 100 epoch, with learning rate 22.612712429686844
[09/25 22:37:19 visual_prompt]: Epoch 29 / 100: avg data time: 6.17e-02, avg batch time: 0.5024, average train loss: 88.1296
[09/25 22:37:20 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1663, average loss: 91.4725
[09/25 22:37:20 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 4.00	
[09/25 22:37:20 visual_prompt]: Training 30 / 100 epoch, with learning rate 22.35013442008402
[09/25 22:37:27 visual_prompt]: Epoch 30 / 100: avg data time: 4.61e-02, avg batch time: 0.4877, average train loss: 91.9802
[09/25 22:37:28 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1660, average loss: 85.9179
[09/25 22:37:28 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/25 22:37:28 visual_prompt]: Training 31 / 100 epoch, with learning rate 22.075555538987224
[09/25 22:37:35 visual_prompt]: Epoch 31 / 100: avg data time: 5.53e-02, avg batch time: 0.4960, average train loss: 95.5744
[09/25 22:37:36 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1662, average loss: 83.9942
[09/25 22:37:36 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.00	
[09/25 22:37:36 visual_prompt]: Training 32 / 100 epoch, with learning rate 21.78931031846743
[09/25 22:37:43 visual_prompt]: Epoch 32 / 100: avg data time: 4.22e-02, avg batch time: 0.4842, average train loss: 84.6478
[09/25 22:37:44 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1661, average loss: 66.9944
[09/25 22:37:44 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 6.50	
[09/25 22:37:44 visual_prompt]: Training 33 / 100 epoch, with learning rate 21.49174750423314
[09/25 22:37:51 visual_prompt]: Epoch 33 / 100: avg data time: 5.83e-02, avg batch time: 0.4995, average train loss: 75.9263
[09/25 22:37:52 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1658, average loss: 68.3841
[09/25 22:37:52 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.00	
[09/25 22:37:52 visual_prompt]: Training 34 / 100 epoch, with learning rate 21.183229630737465
[09/25 22:37:59 visual_prompt]: Epoch 34 / 100: avg data time: 5.64e-02, avg batch time: 0.4976, average train loss: 69.9623
[09/25 22:38:01 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1660, average loss: 71.2857
[09/25 22:38:01 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/25 22:38:01 visual_prompt]: Training 35 / 100 epoch, with learning rate 20.864132579485727
[09/25 22:38:07 visual_prompt]: Epoch 35 / 100: avg data time: 5.23e-02, avg batch time: 0.4942, average train loss: 70.0291
[09/25 22:38:09 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1660, average loss: 66.0009
[09/25 22:38:09 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.50	
[09/25 22:38:09 visual_prompt]: Training 36 / 100 epoch, with learning rate 20.53484512108174
[09/25 22:38:15 visual_prompt]: Epoch 36 / 100: avg data time: 5.79e-02, avg batch time: 0.4989, average train loss: 69.3272
[09/25 22:38:17 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1662, average loss: 67.4864
[09/25 22:38:17 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.00	
[09/25 22:38:17 visual_prompt]: Training 37 / 100 epoch, with learning rate 20.195768441570728
[09/25 22:38:23 visual_prompt]: Epoch 37 / 100: avg data time: 4.37e-02, avg batch time: 0.4856, average train loss: 68.4264
[09/25 22:38:25 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1661, average loss: 73.0024
[09/25 22:38:25 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.00	top5: 5.50	
[09/25 22:38:25 visual_prompt]: Training 38 / 100 epoch, with learning rate 19.847315653655915
[09/25 22:38:32 visual_prompt]: Epoch 38 / 100: avg data time: 5.03e-02, avg batch time: 0.4911, average train loss: 67.0083
[09/25 22:38:33 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1661, average loss: 73.9431
[09/25 22:38:33 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 6.00	
[09/25 22:38:33 visual_prompt]: Training 39 / 100 epoch, with learning rate 19.489911293384335
[09/25 22:38:40 visual_prompt]: Epoch 39 / 100: avg data time: 5.02e-02, avg batch time: 0.4910, average train loss: 64.6091
[09/25 22:38:41 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1662, average loss: 63.7468
[09/25 22:38:41 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 7.00	
[09/25 22:38:41 visual_prompt]: Training 40 / 100 epoch, with learning rate 19.12399080291506
[09/25 22:38:48 visual_prompt]: Epoch 40 / 100: avg data time: 4.67e-02, avg batch time: 0.4884, average train loss: 61.9809
[09/25 22:38:49 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1663, average loss: 54.6161
[09/25 22:38:49 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 6.00	
[09/25 22:38:49 visual_prompt]: Training 41 / 100 epoch, with learning rate 18.75
[09/25 22:38:56 visual_prompt]: Epoch 41 / 100: avg data time: 5.68e-02, avg batch time: 0.4977, average train loss: 57.8169
[09/25 22:38:57 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1662, average loss: 49.2599
[09/25 22:38:57 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 4.00	
[09/25 22:38:57 visual_prompt]: Training 42 / 100 epoch, with learning rate 18.368394534823633
[09/25 22:39:04 visual_prompt]: Epoch 42 / 100: avg data time: 4.37e-02, avg batch time: 0.4849, average train loss: 53.9779
[09/25 22:39:06 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1658, average loss: 51.8064
[09/25 22:39:06 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 5.50	
[09/25 22:39:06 visual_prompt]: Training 43 / 100 epoch, with learning rate 17.979639334863467
[09/25 22:39:12 visual_prompt]: Epoch 43 / 100: avg data time: 5.19e-02, avg batch time: 0.4926, average train loss: 52.9320
[09/25 22:39:14 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1659, average loss: 53.1601
[09/25 22:39:14 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 3.50	
[09/25 22:39:14 visual_prompt]: Training 44 / 100 epoch, with learning rate 17.584208038447503
[09/25 22:39:20 visual_prompt]: Epoch 44 / 100: avg data time: 5.10e-02, avg batch time: 0.4929, average train loss: 51.4615
[09/25 22:39:22 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1660, average loss: 49.3058
[09/25 22:39:22 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 6.00	
[09/25 22:39:22 visual_prompt]: Training 45 / 100 epoch, with learning rate 17.182582417698903
[09/25 22:39:28 visual_prompt]: Epoch 45 / 100: avg data time: 4.41e-02, avg batch time: 0.4867, average train loss: 48.4640
[09/25 22:39:30 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1662, average loss: 41.9055
[09/25 22:39:30 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.50	
[09/25 22:39:30 visual_prompt]: Training 46 / 100 epoch, with learning rate 16.77525179157086
[09/25 22:39:36 visual_prompt]: Epoch 46 / 100: avg data time: 5.27e-02, avg batch time: 0.4958, average train loss: 45.5909
[09/25 22:39:38 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1659, average loss: 38.3364
[09/25 22:39:38 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.50	
[09/25 22:39:38 visual_prompt]: Training 47 / 100 epoch, with learning rate 16.362712429686844
[09/25 22:39:45 visual_prompt]: Epoch 47 / 100: avg data time: 4.50e-02, avg batch time: 0.4877, average train loss: 40.3015
[09/25 22:39:46 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1661, average loss: 49.7727
[09/25 22:39:46 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 4.00	
[09/25 22:39:46 visual_prompt]: Training 48 / 100 epoch, with learning rate 15.94546694771249
[09/25 22:39:53 visual_prompt]: Epoch 48 / 100: avg data time: 4.36e-02, avg batch time: 0.4845, average train loss: 38.3923
[09/25 22:39:54 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1661, average loss: 30.4124
[09/25 22:39:54 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.50	
[09/25 22:39:54 visual_prompt]: Training 49 / 100 epoch, with learning rate 15.524023694995845
[09/25 22:40:01 visual_prompt]: Epoch 49 / 100: avg data time: 5.42e-02, avg batch time: 0.4947, average train loss: 35.9469
[09/25 22:40:02 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1661, average loss: 30.5031
[09/25 22:40:02 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 6.00	
[09/25 22:40:02 visual_prompt]: Training 50 / 100 epoch, with learning rate 15.09889613522199
[09/25 22:40:09 visual_prompt]: Epoch 50 / 100: avg data time: 5.42e-02, avg batch time: 0.4961, average train loss: 38.1682
[09/25 22:40:10 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1663, average loss: 33.7313
[09/25 22:40:10 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.50	
[09/25 22:40:10 visual_prompt]: Training 51 / 100 epoch, with learning rate 14.670602220836631
[09/25 22:40:17 visual_prompt]: Epoch 51 / 100: avg data time: 5.56e-02, avg batch time: 0.4977, average train loss: 36.6914
[09/25 22:40:19 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1661, average loss: 27.8252
[09/25 22:40:19 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.50	
[09/25 22:40:19 visual_prompt]: Training 52 / 100 epoch, with learning rate 14.239663762000818
[09/25 22:40:25 visual_prompt]: Epoch 52 / 100: avg data time: 3.88e-02, avg batch time: 0.4827, average train loss: 31.0260
[09/25 22:40:26 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1664, average loss: 30.0364
[09/25 22:40:26 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 5.00	
[09/25 22:40:26 visual_prompt]: Training 53 / 100 epoch, with learning rate 13.80660579084567
[09/25 22:40:33 visual_prompt]: Epoch 53 / 100: avg data time: 4.63e-02, avg batch time: 0.4878, average train loss: 31.1789
[09/25 22:40:35 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1662, average loss: 26.1170
[09/25 22:40:35 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.50	top5: 4.50	
[09/25 22:40:35 visual_prompt]: Training 54 / 100 epoch, with learning rate 13.371955921801565
[09/25 22:40:41 visual_prompt]: Epoch 54 / 100: avg data time: 4.44e-02, avg batch time: 0.4872, average train loss: 28.4488
[09/25 22:40:43 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1659, average loss: 24.1564
[09/25 22:40:43 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.50	
[09/25 22:40:43 visual_prompt]: Training 55 / 100 epoch, with learning rate 12.936243708781264
[09/25 22:40:49 visual_prompt]: Epoch 55 / 100: avg data time: 5.07e-02, avg batch time: 0.4915, average train loss: 26.9263
[09/25 22:40:51 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1659, average loss: 23.3965
[09/25 22:40:51 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.50	
[09/25 22:40:51 visual_prompt]: Training 56 / 100 epoch, with learning rate 12.5
[09/25 22:40:57 visual_prompt]: Epoch 56 / 100: avg data time: 5.05e-02, avg batch time: 0.4934, average train loss: 25.9711
[09/25 22:40:59 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1661, average loss: 22.6564
[09/25 22:40:59 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 9.00	
[09/25 22:40:59 visual_prompt]: Training 57 / 100 epoch, with learning rate 12.063756291218741
[09/25 22:41:05 visual_prompt]: Epoch 57 / 100: avg data time: 4.50e-02, avg batch time: 0.4869, average train loss: 22.6407
[09/25 22:41:07 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1662, average loss: 23.0384
[09/25 22:41:07 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 3.50	
[09/25 22:41:07 visual_prompt]: Training 58 / 100 epoch, with learning rate 11.628044078198434
[09/25 22:41:13 visual_prompt]: Epoch 58 / 100: avg data time: 5.71e-02, avg batch time: 0.4983, average train loss: 20.9889
[09/25 22:41:15 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1662, average loss: 17.3354
[09/25 22:41:15 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 7.00	
[09/25 22:41:15 visual_prompt]: Training 59 / 100 epoch, with learning rate 11.193394209154334
[09/25 22:41:22 visual_prompt]: Epoch 59 / 100: avg data time: 5.54e-02, avg batch time: 0.4973, average train loss: 21.3071
[09/25 22:41:23 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1662, average loss: 15.7102
[09/25 22:41:23 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.00	
[09/25 22:41:23 visual_prompt]: Training 60 / 100 epoch, with learning rate 10.760336237999185
[09/25 22:41:30 visual_prompt]: Epoch 60 / 100: avg data time: 5.71e-02, avg batch time: 0.4993, average train loss: 31.4227
[09/25 22:41:31 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1662, average loss: 17.9291
[09/25 22:41:31 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 4.50	
[09/25 22:41:31 visual_prompt]: Training 61 / 100 epoch, with learning rate 10.32939777916337
[09/25 22:41:38 visual_prompt]: Epoch 61 / 100: avg data time: 5.54e-02, avg batch time: 0.4970, average train loss: 18.3119
[09/25 22:41:39 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1660, average loss: 12.2097
[09/25 22:41:39 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 4.50	
[09/25 22:41:39 visual_prompt]: Training 62 / 100 epoch, with learning rate 9.90110386477801
[09/25 22:41:46 visual_prompt]: Epoch 62 / 100: avg data time: 5.51e-02, avg batch time: 0.4957, average train loss: 20.8045
[09/25 22:41:47 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1663, average loss: 10.7265
[09/25 22:41:47 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 4.00	
[09/25 22:41:47 visual_prompt]: Training 63 / 100 epoch, with learning rate 9.475976305004155
[09/25 22:41:54 visual_prompt]: Epoch 63 / 100: avg data time: 5.70e-02, avg batch time: 0.4985, average train loss: 19.6017
[09/25 22:41:56 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1662, average loss: 11.5188
[09/25 22:41:56 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.00	
[09/25 22:41:56 visual_prompt]: Training 64 / 100 epoch, with learning rate 9.05453305228751
[09/25 22:42:02 visual_prompt]: Epoch 64 / 100: avg data time: 5.43e-02, avg batch time: 0.4954, average train loss: 19.7775
[09/25 22:42:04 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1661, average loss: 11.2725
[09/25 22:42:04 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.50	
[09/25 22:42:04 visual_prompt]: Training 65 / 100 epoch, with learning rate 8.637287570313159
[09/25 22:42:10 visual_prompt]: Epoch 65 / 100: avg data time: 5.31e-02, avg batch time: 0.4937, average train loss: 17.9596
[09/25 22:42:12 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1662, average loss: 11.1943
[09/25 22:42:12 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 6.00	
[09/25 22:42:12 visual_prompt]: Training 66 / 100 epoch, with learning rate 8.224748208429142
[09/25 22:42:19 visual_prompt]: Epoch 66 / 100: avg data time: 5.57e-02, avg batch time: 0.4977, average train loss: 16.7434
[09/25 22:42:20 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1660, average loss: 10.2304
[09/25 22:42:20 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 4.50	
[09/25 22:42:20 visual_prompt]: Training 67 / 100 epoch, with learning rate 7.817417582301099
[09/25 22:42:27 visual_prompt]: Epoch 67 / 100: avg data time: 4.96e-02, avg batch time: 0.4903, average train loss: 14.4019
[09/25 22:42:28 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1659, average loss: 10.1554
[09/25 22:42:28 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.00	
[09/25 22:42:28 visual_prompt]: Training 68 / 100 epoch, with learning rate 7.415791961552499
[09/25 22:42:35 visual_prompt]: Epoch 68 / 100: avg data time: 5.51e-02, avg batch time: 0.4960, average train loss: 12.3760
[09/25 22:42:36 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1662, average loss: 7.4866
[09/25 22:42:36 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 5.50	
[09/25 22:42:36 visual_prompt]: Training 69 / 100 epoch, with learning rate 7.020360665136531
[09/25 22:42:43 visual_prompt]: Epoch 69 / 100: avg data time: 5.71e-02, avg batch time: 0.4988, average train loss: 10.8605
[09/25 22:42:44 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1659, average loss: 7.2731
[09/25 22:42:44 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 5.00	
[09/25 22:42:44 visual_prompt]: Training 70 / 100 epoch, with learning rate 6.631605465176368
[09/25 22:42:51 visual_prompt]: Epoch 70 / 100: avg data time: 5.75e-02, avg batch time: 0.4993, average train loss: 10.5865
[09/25 22:42:53 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1661, average loss: 6.9397
[09/25 22:42:53 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.00	top5: 2.50	
[09/25 22:42:53 visual_prompt]: Training 71 / 100 epoch, with learning rate 6.250000000000003
[09/25 22:42:59 visual_prompt]: Epoch 71 / 100: avg data time: 5.23e-02, avg batch time: 0.4940, average train loss: 9.4569
[09/25 22:43:01 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1662, average loss: 18.9439
[09/25 22:43:01 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/25 22:43:01 visual_prompt]: Training 72 / 100 epoch, with learning rate 5.87600919708494
[09/25 22:43:08 visual_prompt]: Epoch 72 / 100: avg data time: 5.56e-02, avg batch time: 0.4970, average train loss: 10.1989
[09/25 22:43:09 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1660, average loss: 7.8742
[09/25 22:43:09 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.00	
[09/25 22:43:09 visual_prompt]: Training 73 / 100 epoch, with learning rate 5.510088706615666
[09/25 22:43:16 visual_prompt]: Epoch 73 / 100: avg data time: 4.44e-02, avg batch time: 0.4864, average train loss: 10.5336
[09/25 22:43:17 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1660, average loss: 7.1488
[09/25 22:43:17 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.00	
[09/25 22:43:17 visual_prompt]: Training 74 / 100 epoch, with learning rate 5.1526843463440875
[09/25 22:43:24 visual_prompt]: Epoch 74 / 100: avg data time: 4.93e-02, avg batch time: 0.4911, average train loss: 10.0428
[09/25 22:43:25 visual_prompt]: Inference (val):avg data time: 4.39e-05, avg batch time: 0.1660, average loss: 6.1939
[09/25 22:43:25 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.00	top5: 5.50	
[09/25 22:43:25 visual_prompt]: Training 75 / 100 epoch, with learning rate 4.804231558429271
[09/25 22:43:32 visual_prompt]: Epoch 75 / 100: avg data time: 5.34e-02, avg batch time: 0.4962, average train loss: 9.1857
[09/25 22:43:33 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1665, average loss: 6.1949
[09/25 22:43:33 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 4.00	
[09/25 22:43:33 visual_prompt]: Training 76 / 100 epoch, with learning rate 4.465154878918258
[09/25 22:43:40 visual_prompt]: Epoch 76 / 100: avg data time: 4.70e-02, avg batch time: 0.4884, average train loss: 8.7009
[09/25 22:43:41 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1661, average loss: 6.1501
[09/25 22:43:41 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 4.00	
[09/25 22:43:41 visual_prompt]: Training 77 / 100 epoch, with learning rate 4.135867420514276
[09/25 22:43:48 visual_prompt]: Epoch 77 / 100: avg data time: 3.93e-02, avg batch time: 0.4822, average train loss: 8.2049
[09/25 22:43:49 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1664, average loss: 5.7782
[09/25 22:43:49 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.00	
[09/25 22:43:49 visual_prompt]: Training 78 / 100 epoch, with learning rate 3.816770369262533
[09/25 22:43:56 visual_prompt]: Epoch 78 / 100: avg data time: 5.71e-02, avg batch time: 0.5000, average train loss: 8.4896
[09/25 22:43:57 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1662, average loss: 5.8152
[09/25 22:43:57 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 5.50	
[09/25 22:43:57 visual_prompt]: Training 79 / 100 epoch, with learning rate 3.508252495766863
[09/25 22:44:04 visual_prompt]: Epoch 79 / 100: avg data time: 4.69e-02, avg batch time: 0.4894, average train loss: 7.6009
[09/25 22:44:05 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1664, average loss: 5.5833
[09/25 22:44:05 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.50	
[09/25 22:44:05 visual_prompt]: Training 80 / 100 epoch, with learning rate 3.2106896815325707
[09/25 22:44:12 visual_prompt]: Epoch 80 / 100: avg data time: 5.46e-02, avg batch time: 0.4960, average train loss: 7.4217
[09/25 22:44:14 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1664, average loss: 5.3796
[09/25 22:44:14 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 7.00	
[09/25 22:44:14 visual_prompt]: Training 81 / 100 epoch, with learning rate 2.924444461012776
[09/25 22:44:20 visual_prompt]: Epoch 81 / 100: avg data time: 5.41e-02, avg batch time: 0.4973, average train loss: 6.8953
[09/25 22:44:22 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1662, average loss: 5.3127
[09/25 22:44:22 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 5.50	
[09/25 22:44:22 visual_prompt]: Training 82 / 100 epoch, with learning rate 2.6498655799159763
[09/25 22:44:28 visual_prompt]: Epoch 82 / 100: avg data time: 5.68e-02, avg batch time: 0.4990, average train loss: 6.4676
[09/25 22:44:30 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1664, average loss: 5.2000
[09/25 22:44:30 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.00	
[09/25 22:44:30 visual_prompt]: Training 83 / 100 epoch, with learning rate 2.387287570313158
[09/25 22:44:37 visual_prompt]: Epoch 83 / 100: avg data time: 5.27e-02, avg batch time: 0.4939, average train loss: 6.3868
[09/25 22:44:38 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1666, average loss: 5.0938
[09/25 22:44:38 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 4.50	
[09/25 22:44:38 visual_prompt]: Training 84 / 100 epoch, with learning rate 2.13703034306198
[09/25 22:44:45 visual_prompt]: Epoch 84 / 100: avg data time: 5.82e-02, avg batch time: 0.5002, average train loss: 5.9860
[09/25 22:44:46 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1664, average loss: 4.9638
[09/25 22:44:46 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/25 22:44:46 visual_prompt]: Training 85 / 100 epoch, with learning rate 1.8993987980446756
[09/25 22:44:53 visual_prompt]: Epoch 85 / 100: avg data time: 5.71e-02, avg batch time: 0.4997, average train loss: 5.7586
[09/25 22:44:54 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1664, average loss: 4.9085
[09/25 22:44:54 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 4.50	
[09/25 22:44:54 visual_prompt]: Training 86 / 100 epoch, with learning rate 1.674682452694516
[09/25 22:45:01 visual_prompt]: Epoch 86 / 100: avg data time: 5.21e-02, avg batch time: 0.4936, average train loss: 5.6307
[09/25 22:45:02 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1661, average loss: 4.9774
[09/25 22:45:02 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 6.00	
[09/25 22:45:02 visual_prompt]: Training 87 / 100 epoch, with learning rate 1.4631550892634126
[09/25 22:45:09 visual_prompt]: Epoch 87 / 100: avg data time: 5.44e-02, avg batch time: 0.4963, average train loss: 5.4625
[09/25 22:45:11 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1664, average loss: 4.8326
[09/25 22:45:11 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.00	
[09/25 22:45:11 visual_prompt]: Training 88 / 100 epoch, with learning rate 1.2650744212604148
[09/25 22:45:17 visual_prompt]: Epoch 88 / 100: avg data time: 6.09e-02, avg batch time: 0.5030, average train loss: 5.2568
[09/25 22:45:19 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1662, average loss: 4.7933
[09/25 22:45:19 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 4.00	
[09/25 22:45:19 visual_prompt]: Training 89 / 100 epoch, with learning rate 1.0806817794674877
[09/25 22:45:25 visual_prompt]: Epoch 89 / 100: avg data time: 4.54e-02, avg batch time: 0.4886, average train loss: 5.2128
[09/25 22:45:27 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1665, average loss: 4.8242
[09/25 22:45:27 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.00	
[09/25 22:45:27 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.9102018179151585
[09/25 22:45:34 visual_prompt]: Epoch 90 / 100: avg data time: 5.24e-02, avg batch time: 0.4952, average train loss: 5.1520
[09/25 22:45:35 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1663, average loss: 4.7465
[09/25 22:45:35 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.00	
[09/25 22:45:35 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.753842240176146
[09/25 22:45:42 visual_prompt]: Epoch 91 / 100: avg data time: 5.26e-02, avg batch time: 0.4944, average train loss: 5.1262
[09/25 22:45:43 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1664, average loss: 4.7568
[09/25 22:45:43 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 7.50	
[09/25 22:45:43 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.6117935463105808
[09/25 22:45:50 visual_prompt]: Epoch 92 / 100: avg data time: 5.96e-02, avg batch time: 0.5011, average train loss: 5.0789
[09/25 22:45:51 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1663, average loss: 4.7565
[09/25 22:45:51 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.00	
[09/25 22:45:51 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.4842288007710138
[09/25 22:45:58 visual_prompt]: Epoch 93 / 100: avg data time: 5.01e-02, avg batch time: 0.4940, average train loss: 4.9631
[09/25 22:46:00 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1662, average loss: 4.7139
[09/25 22:46:00 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.00	
[09/25 22:46:00 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.3713034215500441
[09/25 22:46:06 visual_prompt]: Epoch 94 / 100: avg data time: 5.71e-02, avg batch time: 0.4981, average train loss: 4.9220
[09/25 22:46:08 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1661, average loss: 4.7057
[09/25 22:46:08 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.00	
[09/25 22:46:08 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.2731549908274289
[09/25 22:46:15 visual_prompt]: Epoch 95 / 100: avg data time: 5.34e-02, avg batch time: 0.4953, average train loss: 4.8362
[09/25 22:46:16 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1660, average loss: 4.6677
[09/25 22:46:16 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 7.50	
[09/25 22:46:16 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.18990308734739975
[09/25 22:46:23 visual_prompt]: Epoch 96 / 100: avg data time: 5.43e-02, avg batch time: 0.4961, average train loss: 4.7448
[09/25 22:46:24 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1662, average loss: 4.6952
[09/25 22:46:24 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.50	
[09/25 22:46:24 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.12164914073037048
[09/25 22:46:31 visual_prompt]: Epoch 97 / 100: avg data time: 5.34e-02, avg batch time: 0.4954, average train loss: 4.8179
[09/25 22:46:32 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1662, average loss: 4.6616
[09/25 22:46:32 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.50	
[09/25 22:46:32 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.06847630789658388
[09/25 22:46:39 visual_prompt]: Epoch 98 / 100: avg data time: 4.45e-02, avg batch time: 0.4883, average train loss: 4.6946
[09/25 22:46:40 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1662, average loss: 4.6399
[09/25 22:46:40 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 6.00	
[09/25 22:46:40 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.03044937175219753
[09/25 22:46:47 visual_prompt]: Epoch 99 / 100: avg data time: 5.19e-02, avg batch time: 0.4940, average train loss: 4.5881
[09/25 22:46:48 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1662, average loss: 4.6608
[09/25 22:46:48 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/25 22:46:48 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0076146622613029735
[09/25 22:46:55 visual_prompt]: Epoch 100 / 100: avg data time: 5.60e-02, avg batch time: 0.4991, average train loss: 4.5628
[09/25 22:46:57 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1661, average loss: 4.6482
[09/25 22:46:57 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/25 22:46:57 visual_prompt]: Rank of current process: 0. World size: 1
[09/25 22:46:57 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/25 22:46:57 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-cifar(num_classes=100)', 'DATA.NUMBER_CLASSES', '100', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/25 22:46:57 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/25 22:46:57 visual_prompt]: Training with config:
[09/25 22:46:57 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-cifar(num_classes=100)/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr25.0_wd0.001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 25.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-cifar(num_classes=100)', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 100, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/25 22:46:57 visual_prompt]: Loading training data...
[09/25 22:46:57 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[:800], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/25 22:46:58 visual_prompt]: Number of images: 800
[09/25 22:46:58 visual_prompt]: Number of classes: 100 / 100
[09/25 22:46:58 visual_prompt]: Loading validation data...
[09/25 22:46:58 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[45000:45200], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/25 22:46:58 visual_prompt]: Number of images: 200
[09/25 22:46:58 visual_prompt]: Number of classes: 90 / 100
[09/25 22:46:58 visual_prompt]: Constructing models...
[09/25 22:47:00 visual_prompt]: Total Parameters: 86336356	 Gradient Parameters: 537700
[09/25 22:47:00 visual_prompt]: tuned percent:0.623
[09/25 22:47:01 visual_prompt]: Device used for model: 0
[09/25 22:47:01 visual_prompt]: Setting up Evaluator...
[09/25 22:47:01 visual_prompt]: Setting up Trainer...
[09/25 22:47:01 visual_prompt]: 	Setting up the optimizer...
[09/25 22:47:01 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/25 22:47:07 visual_prompt]: Epoch 1 / 100: avg data time: 4.98e-02, avg batch time: 0.4916, average train loss: 4.6622
[09/25 22:47:09 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1662, average loss: 4.6218
[09/25 22:47:09 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 7.00	
[09/25 22:47:09 visual_prompt]: Best epoch 1: best metric: 0.010
[09/25 22:47:09 visual_prompt]: Training 2 / 100 epoch, with learning rate 2.5
[09/25 22:47:15 visual_prompt]: Epoch 2 / 100: avg data time: 5.68e-02, avg batch time: 0.4994, average train loss: 4.7861
[09/25 22:47:17 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1663, average loss: 4.9241
[09/25 22:47:17 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 3.00	
[09/25 22:47:17 visual_prompt]: Best epoch 2: best metric: 0.015
[09/25 22:47:17 visual_prompt]: Training 3 / 100 epoch, with learning rate 5.0
[09/25 22:47:23 visual_prompt]: Epoch 3 / 100: avg data time: 4.80e-02, avg batch time: 0.4901, average train loss: 5.0764
[09/25 22:47:25 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1661, average loss: 5.0637
[09/25 22:47:25 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.00	
[09/25 22:47:25 visual_prompt]: Training 4 / 100 epoch, with learning rate 7.5
[09/25 22:47:32 visual_prompt]: Epoch 4 / 100: avg data time: 5.60e-02, avg batch time: 0.4975, average train loss: 5.4215
[09/25 22:47:33 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1661, average loss: 5.4293
[09/25 22:47:33 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.50	
[09/25 22:47:33 visual_prompt]: Training 5 / 100 epoch, with learning rate 10.0
[09/25 22:47:40 visual_prompt]: Epoch 5 / 100: avg data time: 5.36e-02, avg batch time: 0.4946, average train loss: 6.2286
[09/25 22:47:41 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1660, average loss: 7.2647
[09/25 22:47:41 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.50	
[09/25 22:47:41 visual_prompt]: Training 6 / 100 epoch, with learning rate 12.5
[09/25 22:47:48 visual_prompt]: Epoch 6 / 100: avg data time: 5.28e-02, avg batch time: 0.4948, average train loss: 6.4355
[09/25 22:47:49 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1662, average loss: 6.9120
[09/25 22:47:49 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 6.50	
[09/25 22:47:49 visual_prompt]: Training 7 / 100 epoch, with learning rate 15.0
[09/25 22:47:56 visual_prompt]: Epoch 7 / 100: avg data time: 5.90e-02, avg batch time: 0.4999, average train loss: 8.3923
[09/25 22:47:58 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1663, average loss: 10.0346
[09/25 22:47:58 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 3.00	
[09/25 22:47:58 visual_prompt]: Training 8 / 100 epoch, with learning rate 17.5
[09/25 22:48:04 visual_prompt]: Epoch 8 / 100: avg data time: 5.45e-02, avg batch time: 0.4959, average train loss: 11.6345
[09/25 22:48:06 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1660, average loss: 23.8037
[09/25 22:48:06 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 6.00	
[09/25 22:48:06 visual_prompt]: Training 9 / 100 epoch, with learning rate 20.0
[09/25 22:48:12 visual_prompt]: Epoch 9 / 100: avg data time: 5.17e-02, avg batch time: 0.4929, average train loss: 22.5652
[09/25 22:48:14 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1664, average loss: 24.4977
[09/25 22:48:14 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.00	
[09/25 22:48:14 visual_prompt]: Training 10 / 100 epoch, with learning rate 22.5
[09/25 22:48:21 visual_prompt]: Epoch 10 / 100: avg data time: 5.83e-02, avg batch time: 0.5005, average train loss: 36.2339
[09/25 22:48:22 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1663, average loss: 50.2325
[09/25 22:48:22 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 3.50	
[09/25 22:48:22 visual_prompt]: Training 11 / 100 epoch, with learning rate 25.0
[09/25 22:48:29 visual_prompt]: Epoch 11 / 100: avg data time: 4.60e-02, avg batch time: 0.4882, average train loss: 45.5473
[09/25 22:48:30 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1662, average loss: 62.3359
[09/25 22:48:30 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.50	
[09/25 22:48:30 visual_prompt]: Training 12 / 100 epoch, with learning rate 24.9923853377387
[09/25 22:48:37 visual_prompt]: Epoch 12 / 100: avg data time: 5.62e-02, avg batch time: 0.4992, average train loss: 63.3998
[09/25 22:48:38 visual_prompt]: Inference (val):avg data time: 2.11e-05, avg batch time: 0.1662, average loss: 60.8828
[09/25 22:48:38 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 4.50	
[09/25 22:48:38 visual_prompt]: Training 13 / 100 epoch, with learning rate 24.969550628247802
[09/25 22:48:45 visual_prompt]: Epoch 13 / 100: avg data time: 5.27e-02, avg batch time: 0.4946, average train loss: 73.7222
[09/25 22:48:47 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1662, average loss: 82.9502
[09/25 22:48:47 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 3.50	
[09/25 22:48:47 visual_prompt]: Training 14 / 100 epoch, with learning rate 24.931523692103415
[09/25 22:48:53 visual_prompt]: Epoch 14 / 100: avg data time: 5.70e-02, avg batch time: 0.4997, average train loss: 95.8721
[09/25 22:48:55 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1663, average loss: 80.7263
[09/25 22:48:55 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.00	top5: 4.00	
[09/25 22:48:55 visual_prompt]: Training 15 / 100 epoch, with learning rate 24.87835085926963
[09/25 22:49:02 visual_prompt]: Epoch 15 / 100: avg data time: 5.94e-02, avg batch time: 0.5021, average train loss: 95.6967
[09/25 22:49:03 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1661, average loss: 82.8105
[09/25 22:49:03 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 4.50	
[09/25 22:49:03 visual_prompt]: Training 16 / 100 epoch, with learning rate 24.8100969126526
[09/25 22:49:10 visual_prompt]: Epoch 16 / 100: avg data time: 5.37e-02, avg batch time: 0.4962, average train loss: 105.4999
[09/25 22:49:11 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1659, average loss: 94.5618
[09/25 22:49:11 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 2.50	
[09/25 22:49:11 visual_prompt]: Training 17 / 100 epoch, with learning rate 24.72684500917257
[09/25 22:49:18 visual_prompt]: Epoch 17 / 100: avg data time: 4.97e-02, avg batch time: 0.4922, average train loss: 96.8733
[09/25 22:49:19 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1666, average loss: 83.7469
[09/25 22:49:19 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.00	
[09/25 22:49:19 visual_prompt]: Training 18 / 100 epoch, with learning rate 24.628696578449954
[09/25 22:49:26 visual_prompt]: Epoch 18 / 100: avg data time: 5.60e-02, avg batch time: 0.4974, average train loss: 100.4222
[09/25 22:49:27 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1663, average loss: 104.3273
[09/25 22:49:27 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/25 22:49:27 visual_prompt]: Training 19 / 100 epoch, with learning rate 24.515771199228986
[09/25 22:49:34 visual_prompt]: Epoch 19 / 100: avg data time: 5.95e-02, avg batch time: 0.5022, average train loss: 109.8701
[09/25 22:49:36 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1663, average loss: 79.2627
[09/25 22:49:36 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 5.50	
[09/25 22:49:36 visual_prompt]: Training 20 / 100 epoch, with learning rate 24.38820645368942
[09/25 22:49:42 visual_prompt]: Epoch 20 / 100: avg data time: 4.90e-02, avg batch time: 0.4930, average train loss: 107.9760
[09/25 22:49:44 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1663, average loss: 99.6997
[09/25 22:49:44 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 7.00	
[09/25 22:49:44 visual_prompt]: Training 21 / 100 epoch, with learning rate 24.246157759823856
[09/25 22:49:51 visual_prompt]: Epoch 21 / 100: avg data time: 4.69e-02, avg batch time: 0.4886, average train loss: 101.6039
[09/25 22:49:52 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1660, average loss: 76.9863
[09/25 22:49:52 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 4.50	
[09/25 22:49:52 visual_prompt]: Training 22 / 100 epoch, with learning rate 24.08979818208484
[09/25 22:49:59 visual_prompt]: Epoch 22 / 100: avg data time: 4.92e-02, avg batch time: 0.4918, average train loss: 94.0888
[09/25 22:50:00 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1663, average loss: 72.9005
[09/25 22:50:00 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.00	top5: 4.00	
[09/25 22:50:00 visual_prompt]: Training 23 / 100 epoch, with learning rate 23.91931822053251
[09/25 22:50:07 visual_prompt]: Epoch 23 / 100: avg data time: 5.47e-02, avg batch time: 0.4971, average train loss: 87.0848
[09/25 22:50:08 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1662, average loss: 78.7378
[09/25 22:50:08 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 6.50	
[09/25 22:50:08 visual_prompt]: Training 24 / 100 epoch, with learning rate 23.73492557873959
[09/25 22:50:15 visual_prompt]: Epoch 24 / 100: avg data time: 5.76e-02, avg batch time: 0.5007, average train loss: 86.5989
[09/25 22:50:17 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1664, average loss: 76.7624
[09/25 22:50:17 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.50	
[09/25 22:50:17 visual_prompt]: Training 25 / 100 epoch, with learning rate 23.536844910736587
[09/25 22:50:23 visual_prompt]: Epoch 25 / 100: avg data time: 5.89e-02, avg batch time: 0.5015, average train loss: 89.4406
[09/25 22:50:25 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1661, average loss: 84.8652
[09/25 22:50:25 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 1.50	
[09/25 22:50:25 visual_prompt]: Training 26 / 100 epoch, with learning rate 23.325317547305485
[09/25 22:50:31 visual_prompt]: Epoch 26 / 100: avg data time: 5.26e-02, avg batch time: 0.4938, average train loss: 104.3624
[09/25 22:50:33 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1663, average loss: 85.6973
[09/25 22:50:33 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 4.50	
[09/25 22:50:33 visual_prompt]: Training 27 / 100 epoch, with learning rate 23.100601201955325
[09/25 22:50:40 visual_prompt]: Epoch 27 / 100: avg data time: 5.68e-02, avg batch time: 0.4989, average train loss: 89.0987
[09/25 22:50:41 visual_prompt]: Inference (val):avg data time: 4.03e-05, avg batch time: 0.1663, average loss: 102.9387
[09/25 22:50:41 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 7.00	
[09/25 22:50:41 visual_prompt]: Training 28 / 100 epoch, with learning rate 22.86296965693802
[09/25 22:50:48 visual_prompt]: Epoch 28 / 100: avg data time: 5.65e-02, avg batch time: 0.4983, average train loss: 90.0618
[09/25 22:50:49 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1661, average loss: 94.5138
[09/25 22:50:49 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 5.50	
[09/25 22:50:49 visual_prompt]: Training 29 / 100 epoch, with learning rate 22.612712429686844
[09/25 22:50:56 visual_prompt]: Epoch 29 / 100: avg data time: 4.34e-02, avg batch time: 0.4847, average train loss: 107.6698
[09/25 22:50:57 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1662, average loss: 90.4278
[09/25 22:50:57 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/25 22:50:57 visual_prompt]: Training 30 / 100 epoch, with learning rate 22.35013442008402
[09/25 22:51:04 visual_prompt]: Epoch 30 / 100: avg data time: 4.99e-02, avg batch time: 0.4916, average train loss: 93.3889
[09/25 22:51:05 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1666, average loss: 127.1358
[09/25 22:51:05 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.00	
[09/25 22:51:05 visual_prompt]: Training 31 / 100 epoch, with learning rate 22.075555538987224
[09/25 22:51:12 visual_prompt]: Epoch 31 / 100: avg data time: 4.61e-02, avg batch time: 0.4882, average train loss: 118.5696
[09/25 22:51:14 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1662, average loss: 97.8762
[09/25 22:51:14 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 3.50	
[09/25 22:51:14 visual_prompt]: Training 32 / 100 epoch, with learning rate 21.78931031846743
[09/25 22:51:20 visual_prompt]: Epoch 32 / 100: avg data time: 5.60e-02, avg batch time: 0.4994, average train loss: 89.0365
[09/25 22:51:22 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1663, average loss: 78.9530
[09/25 22:51:22 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 7.00	
[09/25 22:51:22 visual_prompt]: Training 33 / 100 epoch, with learning rate 21.49174750423314
[09/25 22:51:28 visual_prompt]: Epoch 33 / 100: avg data time: 4.00e-02, avg batch time: 0.4824, average train loss: 79.3616
[09/25 22:51:30 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1661, average loss: 69.9267
[09/25 22:51:30 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.00	top5: 4.50	
[09/25 22:51:30 visual_prompt]: Training 34 / 100 epoch, with learning rate 21.183229630737465
[09/25 22:51:36 visual_prompt]: Epoch 34 / 100: avg data time: 4.88e-02, avg batch time: 0.4915, average train loss: 76.4597
[09/25 22:51:38 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1663, average loss: 75.2178
[09/25 22:51:38 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 6.50	
[09/25 22:51:38 visual_prompt]: Training 35 / 100 epoch, with learning rate 20.864132579485727
[09/25 22:51:45 visual_prompt]: Epoch 35 / 100: avg data time: 5.72e-02, avg batch time: 0.4994, average train loss: 81.8268
[09/25 22:51:46 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1663, average loss: 71.2936
[09/25 22:51:46 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 7.00	
[09/25 22:51:46 visual_prompt]: Training 36 / 100 epoch, with learning rate 20.53484512108174
[09/25 22:51:53 visual_prompt]: Epoch 36 / 100: avg data time: 5.44e-02, avg batch time: 0.4959, average train loss: 74.7103
[09/25 22:51:54 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1660, average loss: 61.6521
[09/25 22:51:54 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 5.50	
[09/25 22:51:54 visual_prompt]: Best epoch 36: best metric: 0.020
[09/25 22:51:54 visual_prompt]: Training 37 / 100 epoch, with learning rate 20.195768441570728
[09/25 22:52:01 visual_prompt]: Epoch 37 / 100: avg data time: 5.51e-02, avg batch time: 0.4979, average train loss: 75.5409
[09/25 22:52:02 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1665, average loss: 78.9245
[09/25 22:52:02 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 4.00	
[09/25 22:52:02 visual_prompt]: Training 38 / 100 epoch, with learning rate 19.847315653655915
[09/25 22:52:09 visual_prompt]: Epoch 38 / 100: avg data time: 5.23e-02, avg batch time: 0.4938, average train loss: 69.7408
[09/25 22:52:11 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1663, average loss: 67.1583
[09/25 22:52:11 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.00	
[09/25 22:52:11 visual_prompt]: Training 39 / 100 epoch, with learning rate 19.489911293384335
[09/25 22:52:17 visual_prompt]: Epoch 39 / 100: avg data time: 5.07e-02, avg batch time: 0.4930, average train loss: 63.1119
[09/25 22:52:19 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1664, average loss: 61.5548
[09/25 22:52:19 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 4.50	
[09/25 22:52:19 visual_prompt]: Training 40 / 100 epoch, with learning rate 19.12399080291506
[09/25 22:52:25 visual_prompt]: Epoch 40 / 100: avg data time: 4.81e-02, avg batch time: 0.4921, average train loss: 59.9691
[09/25 22:52:27 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1662, average loss: 56.8797
[09/25 22:52:27 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.50	
[09/25 22:52:27 visual_prompt]: Training 41 / 100 epoch, with learning rate 18.75
[09/25 22:52:33 visual_prompt]: Epoch 41 / 100: avg data time: 4.61e-02, avg batch time: 0.4888, average train loss: 58.8715
[09/25 22:52:35 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1661, average loss: 57.7924
[09/25 22:52:35 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 4.00	
[09/25 22:52:35 visual_prompt]: Training 42 / 100 epoch, with learning rate 18.368394534823633
[09/25 22:52:42 visual_prompt]: Epoch 42 / 100: avg data time: 5.90e-02, avg batch time: 0.5006, average train loss: 59.1933
[09/25 22:52:43 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1660, average loss: 178.8875
[09/25 22:52:43 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.00	
[09/25 22:52:43 visual_prompt]: Training 43 / 100 epoch, with learning rate 17.979639334863467
[09/25 22:52:50 visual_prompt]: Epoch 43 / 100: avg data time: 5.68e-02, avg batch time: 0.4989, average train loss: 71.6825
[09/25 22:52:51 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1663, average loss: 57.4405
[09/25 22:52:51 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.00	
[09/25 22:52:51 visual_prompt]: Training 44 / 100 epoch, with learning rate 17.584208038447503
[09/25 22:52:58 visual_prompt]: Epoch 44 / 100: avg data time: 5.02e-02, avg batch time: 0.4917, average train loss: 54.8009
[09/25 22:52:59 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1663, average loss: 46.6086
[09/25 22:52:59 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 7.00	
[09/25 22:52:59 visual_prompt]: Training 45 / 100 epoch, with learning rate 17.182582417698903
[09/25 22:53:06 visual_prompt]: Epoch 45 / 100: avg data time: 4.51e-02, avg batch time: 0.4866, average train loss: 49.5224
[09/25 22:53:07 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1663, average loss: 45.5465
[09/25 22:53:07 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 4.00	
[09/25 22:53:07 visual_prompt]: Training 46 / 100 epoch, with learning rate 16.77525179157086
[09/25 22:53:14 visual_prompt]: Epoch 46 / 100: avg data time: 4.42e-02, avg batch time: 0.4883, average train loss: 51.2072
[09/25 22:53:15 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1663, average loss: 66.2345
[09/25 22:53:15 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 6.00	
[09/25 22:53:15 visual_prompt]: Training 47 / 100 epoch, with learning rate 16.362712429686844
[09/25 22:53:22 visual_prompt]: Epoch 47 / 100: avg data time: 4.49e-02, avg batch time: 0.4871, average train loss: 62.8639
[09/25 22:53:23 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1663, average loss: 64.7507
[09/25 22:53:23 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 6.00	
[09/25 22:53:23 visual_prompt]: Training 48 / 100 epoch, with learning rate 15.94546694771249
[09/25 22:53:30 visual_prompt]: Epoch 48 / 100: avg data time: 4.43e-02, avg batch time: 0.4878, average train loss: 86.6554
[09/25 22:53:32 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1663, average loss: 96.0880
[09/25 22:53:32 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 5.50	
[09/25 22:53:32 visual_prompt]: Training 49 / 100 epoch, with learning rate 15.524023694995845
[09/25 22:53:38 visual_prompt]: Epoch 49 / 100: avg data time: 5.48e-02, avg batch time: 0.4959, average train loss: 63.5331
[09/25 22:53:40 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1664, average loss: 48.6249
[09/25 22:53:40 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 8.00	
[09/25 22:53:40 visual_prompt]: Training 50 / 100 epoch, with learning rate 15.09889613522199
[09/25 22:53:46 visual_prompt]: Epoch 50 / 100: avg data time: 4.96e-02, avg batch time: 0.4933, average train loss: 54.8996
[09/25 22:53:48 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1662, average loss: 54.1185
[09/25 22:53:48 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 7.50	
[09/25 22:53:48 visual_prompt]: Training 51 / 100 epoch, with learning rate 14.670602220836631
[09/25 22:53:54 visual_prompt]: Epoch 51 / 100: avg data time: 5.13e-02, avg batch time: 0.4925, average train loss: 50.9065
[09/25 22:53:56 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1665, average loss: 48.2009
[09/25 22:53:56 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 4.00	
[09/25 22:53:56 visual_prompt]: Training 52 / 100 epoch, with learning rate 14.239663762000818
[09/25 22:54:03 visual_prompt]: Epoch 52 / 100: avg data time: 5.74e-02, avg batch time: 0.4994, average train loss: 47.2022
[09/25 22:54:04 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1662, average loss: 44.7290
[09/25 22:54:04 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.00	top5: 4.00	
[09/25 22:54:04 visual_prompt]: Training 53 / 100 epoch, with learning rate 13.80660579084567
[09/25 22:54:11 visual_prompt]: Epoch 53 / 100: avg data time: 4.93e-02, avg batch time: 0.4919, average train loss: 44.7014
[09/25 22:54:12 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1661, average loss: 43.1454
[09/25 22:54:12 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.00	top5: 4.50	
[09/25 22:54:12 visual_prompt]: Training 54 / 100 epoch, with learning rate 13.371955921801565
[09/25 22:54:19 visual_prompt]: Epoch 54 / 100: avg data time: 5.36e-02, avg batch time: 0.4955, average train loss: 50.7038
[09/25 22:54:20 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1663, average loss: 44.2922
[09/25 22:54:20 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.00	
[09/25 22:54:20 visual_prompt]: Training 55 / 100 epoch, with learning rate 12.936243708781264
[09/25 22:54:27 visual_prompt]: Epoch 55 / 100: avg data time: 5.69e-02, avg batch time: 0.4986, average train loss: 44.8654
[09/25 22:54:29 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1661, average loss: 37.7415
[09/25 22:54:29 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 3.50	
[09/25 22:54:29 visual_prompt]: Training 56 / 100 epoch, with learning rate 12.5
[09/25 22:54:35 visual_prompt]: Epoch 56 / 100: avg data time: 4.81e-02, avg batch time: 0.4910, average train loss: 44.3065
[09/25 22:54:37 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1660, average loss: 40.5293
[09/25 22:54:37 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 7.50	
[09/25 22:54:37 visual_prompt]: Training 57 / 100 epoch, with learning rate 12.063756291218741
[09/25 22:54:43 visual_prompt]: Epoch 57 / 100: avg data time: 5.71e-02, avg batch time: 0.4984, average train loss: 39.0921
[09/25 22:54:45 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1660, average loss: 31.4566
[09/25 22:54:45 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 6.00	
[09/25 22:54:45 visual_prompt]: Training 58 / 100 epoch, with learning rate 11.628044078198434
[09/25 22:54:52 visual_prompt]: Epoch 58 / 100: avg data time: 5.25e-02, avg batch time: 0.4929, average train loss: 32.7101
[09/25 22:54:53 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1662, average loss: 29.4625
[09/25 22:54:53 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 7.50	
[09/25 22:54:53 visual_prompt]: Training 59 / 100 epoch, with learning rate 11.193394209154334
[09/25 22:55:00 visual_prompt]: Epoch 59 / 100: avg data time: 5.22e-02, avg batch time: 0.4948, average train loss: 25.8564
[09/25 22:55:01 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1661, average loss: 21.2825
[09/25 22:55:01 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 5.00	
[09/25 22:55:01 visual_prompt]: Training 60 / 100 epoch, with learning rate 10.760336237999185
[09/25 22:55:08 visual_prompt]: Epoch 60 / 100: avg data time: 5.49e-02, avg batch time: 0.4967, average train loss: 20.2473
[09/25 22:55:09 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1662, average loss: 21.3544
[09/25 22:55:09 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.50	
[09/25 22:55:09 visual_prompt]: Training 61 / 100 epoch, with learning rate 10.32939777916337
[09/25 22:55:16 visual_prompt]: Epoch 61 / 100: avg data time: 5.51e-02, avg batch time: 0.4958, average train loss: 20.7690
[09/25 22:55:18 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1662, average loss: 17.3713
[09/25 22:55:18 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 3.50	
[09/25 22:55:18 visual_prompt]: Training 62 / 100 epoch, with learning rate 9.90110386477801
[09/25 22:55:24 visual_prompt]: Epoch 62 / 100: avg data time: 5.71e-02, avg batch time: 0.4977, average train loss: 17.9582
[09/25 22:55:26 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1662, average loss: 15.5706
[09/25 22:55:26 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 7.50	
[09/25 22:55:26 visual_prompt]: Training 63 / 100 epoch, with learning rate 9.475976305004155
[09/25 22:55:32 visual_prompt]: Epoch 63 / 100: avg data time: 5.10e-02, avg batch time: 0.4932, average train loss: 18.9696
[09/25 22:55:34 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1658, average loss: 20.3311
[09/25 22:55:34 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 4.50	
[09/25 22:55:34 visual_prompt]: Training 64 / 100 epoch, with learning rate 9.05453305228751
[09/25 22:55:41 visual_prompt]: Epoch 64 / 100: avg data time: 5.64e-02, avg batch time: 0.4965, average train loss: 17.7033
[09/25 22:55:42 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1659, average loss: 11.2194
[09/25 22:55:42 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 7.50	
[09/25 22:55:42 visual_prompt]: Training 65 / 100 epoch, with learning rate 8.637287570313159
[09/25 22:55:49 visual_prompt]: Epoch 65 / 100: avg data time: 5.45e-02, avg batch time: 0.4963, average train loss: 12.7122
[09/25 22:55:50 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1661, average loss: 11.4150
[09/25 22:55:50 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 7.00	
[09/25 22:55:50 visual_prompt]: Training 66 / 100 epoch, with learning rate 8.224748208429142
[09/25 22:55:57 visual_prompt]: Epoch 66 / 100: avg data time: 6.17e-02, avg batch time: 0.5031, average train loss: 11.0760
[09/25 22:55:58 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1664, average loss: 10.6887
[09/25 22:55:58 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 4.50	
[09/25 22:55:58 visual_prompt]: Training 67 / 100 epoch, with learning rate 7.817417582301099
[09/25 22:56:05 visual_prompt]: Epoch 67 / 100: avg data time: 5.85e-02, avg batch time: 0.4994, average train loss: 10.6492
[09/25 22:56:07 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1663, average loss: 9.7851
[09/25 22:56:07 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 4.00	
[09/25 22:56:07 visual_prompt]: Training 68 / 100 epoch, with learning rate 7.415791961552499
[09/25 22:56:13 visual_prompt]: Epoch 68 / 100: avg data time: 5.74e-02, avg batch time: 0.4994, average train loss: 10.5713
[09/25 22:56:15 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1660, average loss: 8.8245
[09/25 22:56:15 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.50	
[09/25 22:56:15 visual_prompt]: Training 69 / 100 epoch, with learning rate 7.020360665136531
[09/25 22:56:22 visual_prompt]: Epoch 69 / 100: avg data time: 5.60e-02, avg batch time: 0.4969, average train loss: 9.4860
[09/25 22:56:23 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1662, average loss: 14.8314
[09/25 22:56:23 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.50	
[09/25 22:56:23 visual_prompt]: Training 70 / 100 epoch, with learning rate 6.631605465176368
[09/25 22:56:30 visual_prompt]: Epoch 70 / 100: avg data time: 5.10e-02, avg batch time: 0.4928, average train loss: 13.4933
[09/25 22:56:31 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1658, average loss: 13.6567
[09/25 22:56:31 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.50	
[09/25 22:56:31 visual_prompt]: Training 71 / 100 epoch, with learning rate 6.250000000000003
[09/25 22:56:38 visual_prompt]: Epoch 71 / 100: avg data time: 5.65e-02, avg batch time: 0.4968, average train loss: 12.2908
[09/25 22:56:39 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1661, average loss: 9.6326
[09/25 22:56:39 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 3.50	
[09/25 22:56:39 visual_prompt]: Training 72 / 100 epoch, with learning rate 5.87600919708494
[09/25 22:56:46 visual_prompt]: Epoch 72 / 100: avg data time: 5.35e-02, avg batch time: 0.4946, average train loss: 9.1766
[09/25 22:56:47 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1660, average loss: 7.3159
[09/25 22:56:47 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.50	
[09/25 22:56:47 visual_prompt]: Training 73 / 100 epoch, with learning rate 5.510088706615666
[09/25 22:56:54 visual_prompt]: Epoch 73 / 100: avg data time: 4.28e-02, avg batch time: 0.4855, average train loss: 7.4131
[09/25 22:56:55 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1657, average loss: 7.6642
[09/25 22:56:55 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 3.50	
[09/25 22:56:55 visual_prompt]: Training 74 / 100 epoch, with learning rate 5.1526843463440875
[09/25 22:57:02 visual_prompt]: Epoch 74 / 100: avg data time: 4.88e-02, avg batch time: 0.4914, average train loss: 7.2947
[09/25 22:57:04 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1661, average loss: 6.2497
[09/25 22:57:04 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/25 22:57:04 visual_prompt]: Training 75 / 100 epoch, with learning rate 4.804231558429271
[09/25 22:57:10 visual_prompt]: Epoch 75 / 100: avg data time: 5.12e-02, avg batch time: 0.4920, average train loss: 6.4263
[09/25 22:57:12 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1661, average loss: 6.6810
[09/25 22:57:12 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.00	
[09/25 22:57:12 visual_prompt]: Training 76 / 100 epoch, with learning rate 4.465154878918258
[09/25 22:57:18 visual_prompt]: Epoch 76 / 100: avg data time: 5.94e-02, avg batch time: 0.5007, average train loss: 6.9140
[09/25 22:57:20 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1663, average loss: 6.7829
[09/25 22:57:20 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 7.00	
[09/25 22:57:20 visual_prompt]: Training 77 / 100 epoch, with learning rate 4.135867420514276
[09/25 22:57:27 visual_prompt]: Epoch 77 / 100: avg data time: 4.96e-02, avg batch time: 0.4910, average train loss: 6.3129
[09/25 22:57:28 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1665, average loss: 5.7511
[09/25 22:57:28 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 6.50	
[09/25 22:57:28 visual_prompt]: Training 78 / 100 epoch, with learning rate 3.816770369262533
[09/25 22:57:35 visual_prompt]: Epoch 78 / 100: avg data time: 5.80e-02, avg batch time: 0.5000, average train loss: 5.5158
[09/25 22:57:36 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1661, average loss: 5.3533
[09/25 22:57:36 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.00	
[09/25 22:57:36 visual_prompt]: Training 79 / 100 epoch, with learning rate 3.508252495766863
[09/25 22:57:43 visual_prompt]: Epoch 79 / 100: avg data time: 5.36e-02, avg batch time: 0.4951, average train loss: 5.3789
[09/25 22:57:44 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1663, average loss: 5.2717
[09/25 22:57:44 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/25 22:57:44 visual_prompt]: Training 80 / 100 epoch, with learning rate 3.2106896815325707
[09/25 22:57:51 visual_prompt]: Epoch 80 / 100: avg data time: 5.06e-02, avg batch time: 0.4929, average train loss: 5.2224
[09/25 22:57:53 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1665, average loss: 5.0904
[09/25 22:57:53 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 6.00	
[09/25 22:57:53 visual_prompt]: Training 81 / 100 epoch, with learning rate 2.924444461012776
[09/25 22:57:59 visual_prompt]: Epoch 81 / 100: avg data time: 5.31e-02, avg batch time: 0.4942, average train loss: 5.4050
[09/25 22:58:01 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1664, average loss: 5.1079
[09/25 22:58:01 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 4.50	
[09/25 22:58:01 visual_prompt]: Training 82 / 100 epoch, with learning rate 2.6498655799159763
[09/25 22:58:07 visual_prompt]: Epoch 82 / 100: avg data time: 5.97e-02, avg batch time: 0.5009, average train loss: 5.1540
[09/25 22:58:09 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1662, average loss: 5.0253
[09/25 22:58:09 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 6.50	
[09/25 22:58:09 visual_prompt]: Training 83 / 100 epoch, with learning rate 2.387287570313158
[09/25 22:58:16 visual_prompt]: Epoch 83 / 100: avg data time: 5.58e-02, avg batch time: 0.4969, average train loss: 5.0218
[09/25 22:58:17 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1663, average loss: 4.9708
[09/25 22:58:17 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.00	top5: 4.00	
[09/25 22:58:17 visual_prompt]: Training 84 / 100 epoch, with learning rate 2.13703034306198
[09/25 22:58:24 visual_prompt]: Epoch 84 / 100: avg data time: 5.96e-02, avg batch time: 0.5013, average train loss: 4.9262
[09/25 22:58:25 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1664, average loss: 4.9401
[09/25 22:58:25 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 6.00	
[09/25 22:58:25 visual_prompt]: Training 85 / 100 epoch, with learning rate 1.8993987980446756
[09/25 22:58:32 visual_prompt]: Epoch 85 / 100: avg data time: 5.80e-02, avg batch time: 0.5000, average train loss: 4.9062
[09/25 22:58:34 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1664, average loss: 4.8059
[09/25 22:58:34 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 5.00	
[09/25 22:58:34 visual_prompt]: Training 86 / 100 epoch, with learning rate 1.674682452694516
[09/25 22:58:40 visual_prompt]: Epoch 86 / 100: avg data time: 5.64e-02, avg batch time: 0.4980, average train loss: 4.8298
[09/25 22:58:42 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1661, average loss: 4.8305
[09/25 22:58:42 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.00	
[09/25 22:58:42 visual_prompt]: Training 87 / 100 epoch, with learning rate 1.4631550892634126
[09/25 22:58:48 visual_prompt]: Epoch 87 / 100: avg data time: 4.70e-02, avg batch time: 0.4901, average train loss: 4.7984
[09/25 22:58:50 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1663, average loss: 4.7663
[09/25 22:58:50 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 6.50	
[09/25 22:58:50 visual_prompt]: Training 88 / 100 epoch, with learning rate 1.2650744212604148
[09/25 22:58:57 visual_prompt]: Epoch 88 / 100: avg data time: 5.58e-02, avg batch time: 0.4984, average train loss: 4.7907
[09/25 22:58:58 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1661, average loss: 4.7947
[09/25 22:58:58 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.00	
[09/25 22:58:58 visual_prompt]: Training 89 / 100 epoch, with learning rate 1.0806817794674877
[09/25 22:59:05 visual_prompt]: Epoch 89 / 100: avg data time: 4.54e-02, avg batch time: 0.4873, average train loss: 4.8485
[09/25 22:59:06 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1661, average loss: 4.7460
[09/25 22:59:06 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.00	
[09/25 22:59:06 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.9102018179151585
[09/25 22:59:13 visual_prompt]: Epoch 90 / 100: avg data time: 4.57e-02, avg batch time: 0.4890, average train loss: 4.7626
[09/25 22:59:14 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1661, average loss: 4.6770
[09/25 22:59:14 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 5.00	
[09/25 22:59:14 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.753842240176146
[09/25 22:59:21 visual_prompt]: Epoch 91 / 100: avg data time: 4.50e-02, avg batch time: 0.4884, average train loss: 4.6908
[09/25 22:59:22 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1660, average loss: 4.6624
[09/25 22:59:22 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.00	
[09/25 22:59:22 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.6117935463105808
[09/25 22:59:29 visual_prompt]: Epoch 92 / 100: avg data time: 4.04e-02, avg batch time: 0.4839, average train loss: 4.6685
[09/25 22:59:30 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1660, average loss: 4.6600
[09/25 22:59:30 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/25 22:59:30 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.4842288007710138
[09/25 22:59:37 visual_prompt]: Epoch 93 / 100: avg data time: 5.05e-02, avg batch time: 0.4943, average train loss: 4.6294
[09/25 22:59:38 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1662, average loss: 4.6089
[09/25 22:59:38 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 8.00	
[09/25 22:59:38 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.3713034215500441
[09/25 22:59:45 visual_prompt]: Epoch 94 / 100: avg data time: 5.82e-02, avg batch time: 0.5006, average train loss: 4.5805
[09/25 22:59:47 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1664, average loss: 4.6044
[09/25 22:59:47 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 3.50	top5: 8.00	
[09/25 22:59:47 visual_prompt]: Best epoch 94: best metric: 0.035
[09/25 22:59:47 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.2731549908274289
[09/25 22:59:53 visual_prompt]: Epoch 95 / 100: avg data time: 5.15e-02, avg batch time: 0.4931, average train loss: 4.5025
[09/25 22:59:55 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1662, average loss: 4.6200
[09/25 22:59:55 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 7.50	
[09/25 22:59:55 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.18990308734739975
[09/25 23:00:01 visual_prompt]: Epoch 96 / 100: avg data time: 5.29e-02, avg batch time: 0.4940, average train loss: 4.4455
[09/25 23:00:03 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1663, average loss: 4.6212
[09/25 23:00:03 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 12.50	
[09/25 23:00:03 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.12164914073037048
[09/25 23:00:10 visual_prompt]: Epoch 97 / 100: avg data time: 5.79e-02, avg batch time: 0.4998, average train loss: 4.3694
[09/25 23:00:11 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1662, average loss: 4.5062
[09/25 23:00:11 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 4.00	top5: 15.50	
[09/25 23:00:11 visual_prompt]: Best epoch 97: best metric: 0.040
[09/25 23:00:11 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.06847630789658388
[09/25 23:00:18 visual_prompt]: Epoch 98 / 100: avg data time: 5.99e-02, avg batch time: 0.5012, average train loss: 4.3277
[09/25 23:00:19 visual_prompt]: Inference (val):avg data time: 4.16e-05, avg batch time: 0.1662, average loss: 4.4951
[09/25 23:00:19 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 13.50	
[09/25 23:00:19 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.03044937175219753
[09/25 23:00:26 visual_prompt]: Epoch 99 / 100: avg data time: 5.67e-02, avg batch time: 0.4993, average train loss: 4.2828
[09/25 23:00:27 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1663, average loss: 4.4892
[09/25 23:00:27 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 3.00	top5: 13.50	
[09/25 23:00:27 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0076146622613029735
[09/25 23:00:34 visual_prompt]: Epoch 100 / 100: avg data time: 4.67e-02, avg batch time: 0.4892, average train loss: 4.2545
[09/25 23:00:36 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1664, average loss: 4.4819
[09/25 23:00:36 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 3.50	top5: 13.50	
[09/25 23:00:36 visual_prompt]: Rank of current process: 0. World size: 1
[09/25 23:00:36 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/25 23:00:36 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-cifar(num_classes=100)', 'DATA.NUMBER_CLASSES', '100', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/25 23:00:36 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/25 23:00:36 visual_prompt]: Training with config:
[09/25 23:00:36 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-cifar(num_classes=100)/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr25.0_wd0.0001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 25.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-cifar(num_classes=100)', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 100, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/25 23:00:36 visual_prompt]: Loading training data...
[09/25 23:00:36 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[:800], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/25 23:00:36 visual_prompt]: Number of images: 800
[09/25 23:00:36 visual_prompt]: Number of classes: 100 / 100
[09/25 23:00:36 visual_prompt]: Loading validation data...
[09/25 23:00:36 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[45000:45200], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/25 23:00:37 visual_prompt]: Number of images: 200
[09/25 23:00:37 visual_prompt]: Number of classes: 90 / 100
[09/25 23:00:37 visual_prompt]: Constructing models...
[09/25 23:00:39 visual_prompt]: Total Parameters: 86336356	 Gradient Parameters: 537700
[09/25 23:00:39 visual_prompt]: tuned percent:0.623
[09/25 23:00:39 visual_prompt]: Device used for model: 0
[09/25 23:00:39 visual_prompt]: Setting up Evaluator...
[09/25 23:00:39 visual_prompt]: Setting up Trainer...
[09/25 23:00:39 visual_prompt]: 	Setting up the optimizer...
[09/25 23:00:39 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/25 23:00:46 visual_prompt]: Epoch 1 / 100: avg data time: 5.78e-02, avg batch time: 0.5003, average train loss: 4.6551
[09/25 23:00:48 visual_prompt]: Inference (val):avg data time: 3.77e-05, avg batch time: 0.1663, average loss: 4.6218
[09/25 23:00:48 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 7.00	
[09/25 23:00:48 visual_prompt]: Best epoch 1: best metric: 0.010
[09/25 23:00:48 visual_prompt]: Training 2 / 100 epoch, with learning rate 2.5
[09/25 23:00:54 visual_prompt]: Epoch 2 / 100: avg data time: 5.58e-02, avg batch time: 0.4969, average train loss: 4.8926
[09/25 23:00:56 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1663, average loss: 4.9929
[09/25 23:00:56 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/25 23:00:56 visual_prompt]: Training 3 / 100 epoch, with learning rate 5.0
[09/25 23:01:03 visual_prompt]: Epoch 3 / 100: avg data time: 5.83e-02, avg batch time: 0.4993, average train loss: 5.2302
[09/25 23:01:04 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1662, average loss: 5.4667
[09/25 23:01:04 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.00	
[09/25 23:01:04 visual_prompt]: Training 4 / 100 epoch, with learning rate 7.5
[09/25 23:01:11 visual_prompt]: Epoch 4 / 100: avg data time: 5.21e-02, avg batch time: 0.4942, average train loss: 5.7013
[09/25 23:01:12 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1664, average loss: 5.6911
[09/25 23:01:12 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 4.00	
[09/25 23:01:12 visual_prompt]: Training 5 / 100 epoch, with learning rate 10.0
[09/25 23:01:19 visual_prompt]: Epoch 5 / 100: avg data time: 4.65e-02, avg batch time: 0.4890, average train loss: 5.9638
[09/25 23:01:20 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1664, average loss: 6.6287
[09/25 23:01:20 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.00	
[09/25 23:01:20 visual_prompt]: Training 6 / 100 epoch, with learning rate 12.5
[09/25 23:01:27 visual_prompt]: Epoch 6 / 100: avg data time: 4.99e-02, avg batch time: 0.4931, average train loss: 7.1903
[09/25 23:01:28 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1663, average loss: 6.1651
[09/25 23:01:28 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 3.00	top5: 8.00	
[09/25 23:01:28 visual_prompt]: Best epoch 6: best metric: 0.030
[09/25 23:01:28 visual_prompt]: Training 7 / 100 epoch, with learning rate 15.0
[09/25 23:01:35 visual_prompt]: Epoch 7 / 100: avg data time: 5.27e-02, avg batch time: 0.4947, average train loss: 6.5090
[09/25 23:01:36 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1664, average loss: 8.7850
[09/25 23:01:36 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.50	top5: 6.50	
[09/25 23:01:36 visual_prompt]: Training 8 / 100 epoch, with learning rate 17.5
[09/25 23:01:43 visual_prompt]: Epoch 8 / 100: avg data time: 5.64e-02, avg batch time: 0.4983, average train loss: 16.9314
[09/25 23:01:45 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1664, average loss: 16.7955
[09/25 23:01:45 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 6.00	
[09/25 23:01:45 visual_prompt]: Training 9 / 100 epoch, with learning rate 20.0
[09/25 23:01:51 visual_prompt]: Epoch 9 / 100: avg data time: 4.45e-02, avg batch time: 0.4872, average train loss: 35.9033
[09/25 23:01:53 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1659, average loss: 45.5190
[09/25 23:01:53 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.00	top5: 5.50	
[09/25 23:01:53 visual_prompt]: Training 10 / 100 epoch, with learning rate 22.5
[09/25 23:01:59 visual_prompt]: Epoch 10 / 100: avg data time: 5.52e-02, avg batch time: 0.4966, average train loss: 63.5944
[09/25 23:02:01 visual_prompt]: Inference (val):avg data time: 3.84e-05, avg batch time: 0.1661, average loss: 71.1840
[09/25 23:02:01 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 8.00	
[09/25 23:02:01 visual_prompt]: Training 11 / 100 epoch, with learning rate 25.0
[09/25 23:02:08 visual_prompt]: Epoch 11 / 100: avg data time: 4.91e-02, avg batch time: 0.4919, average train loss: 79.6248
[09/25 23:02:09 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1659, average loss: 66.8528
[09/25 23:02:09 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 4.00	
[09/25 23:02:09 visual_prompt]: Training 12 / 100 epoch, with learning rate 24.9923853377387
[09/25 23:02:16 visual_prompt]: Epoch 12 / 100: avg data time: 5.20e-02, avg batch time: 0.4940, average train loss: 73.3316
[09/25 23:02:17 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1661, average loss: 78.2455
[09/25 23:02:17 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/25 23:02:17 visual_prompt]: Training 13 / 100 epoch, with learning rate 24.969550628247802
[09/25 23:02:24 visual_prompt]: Epoch 13 / 100: avg data time: 5.62e-02, avg batch time: 0.4971, average train loss: 80.7703
[09/25 23:02:25 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1659, average loss: 64.4560
[09/25 23:02:25 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 5.50	
[09/25 23:02:25 visual_prompt]: Training 14 / 100 epoch, with learning rate 24.931523692103415
[09/25 23:02:32 visual_prompt]: Epoch 14 / 100: avg data time: 5.70e-02, avg batch time: 0.4975, average train loss: 85.8323
[09/25 23:02:34 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1659, average loss: 76.0311
[09/25 23:02:34 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 7.00	
[09/25 23:02:34 visual_prompt]: Training 15 / 100 epoch, with learning rate 24.87835085926963
[09/25 23:02:40 visual_prompt]: Epoch 15 / 100: avg data time: 5.66e-02, avg batch time: 0.4988, average train loss: 92.3275
[09/25 23:02:42 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1657, average loss: 84.1644
[09/25 23:02:42 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.50	
[09/25 23:02:42 visual_prompt]: Training 16 / 100 epoch, with learning rate 24.8100969126526
[09/25 23:02:48 visual_prompt]: Epoch 16 / 100: avg data time: 5.31e-02, avg batch time: 0.4933, average train loss: 94.4418
[09/25 23:02:50 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1658, average loss: 79.8533
[09/25 23:02:50 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 6.50	
[09/25 23:02:50 visual_prompt]: Training 17 / 100 epoch, with learning rate 24.72684500917257
[09/25 23:02:57 visual_prompt]: Epoch 17 / 100: avg data time: 5.80e-02, avg batch time: 0.4995, average train loss: 87.5006
[09/25 23:02:58 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1658, average loss: 98.6925
[09/25 23:02:58 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.50	
[09/25 23:02:58 visual_prompt]: Training 18 / 100 epoch, with learning rate 24.628696578449954
[09/25 23:03:05 visual_prompt]: Epoch 18 / 100: avg data time: 5.44e-02, avg batch time: 0.4969, average train loss: 103.1097
[09/25 23:03:06 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1658, average loss: 95.3528
[09/25 23:03:06 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 6.50	
[09/25 23:03:06 visual_prompt]: Training 19 / 100 epoch, with learning rate 24.515771199228986
[09/25 23:03:13 visual_prompt]: Epoch 19 / 100: avg data time: 4.91e-02, avg batch time: 0.4917, average train loss: 105.8705
[09/25 23:03:14 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1659, average loss: 90.7092
[09/25 23:03:14 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.00	
[09/25 23:03:14 visual_prompt]: Training 20 / 100 epoch, with learning rate 24.38820645368942
[09/25 23:03:21 visual_prompt]: Epoch 20 / 100: avg data time: 5.48e-02, avg batch time: 0.4962, average train loss: 105.9134
[09/25 23:03:23 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1660, average loss: 86.5562
[09/25 23:03:23 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.00	
[09/25 23:03:23 visual_prompt]: Training 21 / 100 epoch, with learning rate 24.246157759823856
[09/25 23:03:29 visual_prompt]: Epoch 21 / 100: avg data time: 5.36e-02, avg batch time: 0.4946, average train loss: 94.7546
[09/25 23:03:31 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1658, average loss: 84.3005
[09/25 23:03:31 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.50	
[09/25 23:03:31 visual_prompt]: Training 22 / 100 epoch, with learning rate 24.08979818208484
[09/25 23:03:37 visual_prompt]: Epoch 22 / 100: avg data time: 4.20e-02, avg batch time: 0.4847, average train loss: 92.5936
[09/25 23:03:39 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1660, average loss: 80.6465
[09/25 23:03:39 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.00	top5: 5.50	
[09/25 23:03:39 visual_prompt]: Training 23 / 100 epoch, with learning rate 23.91931822053251
[09/25 23:03:45 visual_prompt]: Epoch 23 / 100: avg data time: 4.50e-02, avg batch time: 0.4872, average train loss: 104.0992
[09/25 23:03:47 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1663, average loss: 105.2346
[09/25 23:03:47 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.00	top5: 2.00	
[09/25 23:03:47 visual_prompt]: Training 24 / 100 epoch, with learning rate 23.73492557873959
[09/25 23:03:53 visual_prompt]: Epoch 24 / 100: avg data time: 4.88e-02, avg batch time: 0.4912, average train loss: 116.1525
[09/25 23:03:55 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1662, average loss: 94.2161
[09/25 23:03:55 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/25 23:03:55 visual_prompt]: Training 25 / 100 epoch, with learning rate 23.536844910736587
[09/25 23:04:01 visual_prompt]: Epoch 25 / 100: avg data time: 5.24e-02, avg batch time: 0.4934, average train loss: 101.8647
[09/25 23:04:03 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1661, average loss: 115.1898
[09/25 23:04:03 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.00	
[09/25 23:04:03 visual_prompt]: Training 26 / 100 epoch, with learning rate 23.325317547305485
[09/25 23:04:10 visual_prompt]: Epoch 26 / 100: avg data time: 4.22e-02, avg batch time: 0.4856, average train loss: 107.0960
[09/25 23:04:11 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1660, average loss: 100.3915
[09/25 23:04:11 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.00	top5: 3.50	
[09/25 23:04:11 visual_prompt]: Training 27 / 100 epoch, with learning rate 23.100601201955325
[09/25 23:04:18 visual_prompt]: Epoch 27 / 100: avg data time: 5.46e-02, avg batch time: 0.4962, average train loss: 96.8909
[09/25 23:04:19 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1661, average loss: 89.6453
[09/25 23:04:19 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.50	
[09/25 23:04:19 visual_prompt]: Training 28 / 100 epoch, with learning rate 22.86296965693802
[09/25 23:04:26 visual_prompt]: Epoch 28 / 100: avg data time: 5.53e-02, avg batch time: 0.4970, average train loss: 100.5283
[09/25 23:04:27 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1660, average loss: 96.3874
[09/25 23:04:27 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 6.50	
[09/25 23:04:27 visual_prompt]: Training 29 / 100 epoch, with learning rate 22.612712429686844
[09/25 23:04:34 visual_prompt]: Epoch 29 / 100: avg data time: 6.27e-02, avg batch time: 0.5042, average train loss: 97.3813
[09/25 23:04:36 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1659, average loss: 92.1291
[09/25 23:04:36 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 6.50	
[09/25 23:04:36 visual_prompt]: Training 30 / 100 epoch, with learning rate 22.35013442008402
[09/25 23:04:42 visual_prompt]: Epoch 30 / 100: avg data time: 4.34e-02, avg batch time: 0.4854, average train loss: 117.7692
[09/25 23:04:44 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1662, average loss: 102.9589
[09/25 23:04:44 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 4.50	
[09/25 23:04:44 visual_prompt]: Training 31 / 100 epoch, with learning rate 22.075555538987224
[09/25 23:04:50 visual_prompt]: Epoch 31 / 100: avg data time: 5.69e-02, avg batch time: 0.4984, average train loss: 109.9072
[09/25 23:04:52 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1662, average loss: 102.8973
[09/25 23:04:52 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.00	top5: 4.50	
[09/25 23:04:52 visual_prompt]: Training 32 / 100 epoch, with learning rate 21.78931031846743
[09/25 23:04:59 visual_prompt]: Epoch 32 / 100: avg data time: 5.78e-02, avg batch time: 0.4996, average train loss: 122.2658
[09/25 23:05:00 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1663, average loss: 121.2740
[09/25 23:05:00 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 4.50	
[09/25 23:05:00 visual_prompt]: Training 33 / 100 epoch, with learning rate 21.49174750423314
[09/25 23:05:07 visual_prompt]: Epoch 33 / 100: avg data time: 5.68e-02, avg batch time: 0.4997, average train loss: 123.2782
[09/25 23:05:08 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1664, average loss: 103.1487
[09/25 23:05:08 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 3.00	top5: 6.50	
[09/25 23:05:08 visual_prompt]: Training 34 / 100 epoch, with learning rate 21.183229630737465
[09/25 23:05:15 visual_prompt]: Epoch 34 / 100: avg data time: 6.22e-02, avg batch time: 0.5046, average train loss: 122.8838
[09/25 23:05:17 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1665, average loss: 85.8395
[09/25 23:05:17 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 4.50	
[09/25 23:05:17 visual_prompt]: Training 35 / 100 epoch, with learning rate 20.864132579485727
[09/25 23:05:23 visual_prompt]: Epoch 35 / 100: avg data time: 5.69e-02, avg batch time: 0.5007, average train loss: 101.7998
[09/25 23:05:25 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1663, average loss: 87.3048
[09/25 23:05:25 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 7.50	
[09/25 23:05:25 visual_prompt]: Training 36 / 100 epoch, with learning rate 20.53484512108174
[09/25 23:05:32 visual_prompt]: Epoch 36 / 100: avg data time: 5.02e-02, avg batch time: 0.4921, average train loss: 93.5880
[09/25 23:05:33 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1665, average loss: 78.5323
[09/25 23:05:33 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 6.00	
[09/25 23:05:33 visual_prompt]: Training 37 / 100 epoch, with learning rate 20.195768441570728
[09/25 23:05:40 visual_prompt]: Epoch 37 / 100: avg data time: 5.75e-02, avg batch time: 0.4998, average train loss: 78.5607
[09/25 23:05:41 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1659, average loss: 92.0452
[09/25 23:05:41 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 4.50	
[09/25 23:05:41 visual_prompt]: Training 38 / 100 epoch, with learning rate 19.847315653655915
[09/25 23:05:48 visual_prompt]: Epoch 38 / 100: avg data time: 5.67e-02, avg batch time: 0.4973, average train loss: 77.3134
[09/25 23:05:49 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1663, average loss: 84.6050
[09/25 23:05:49 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 4.00	
[09/25 23:05:49 visual_prompt]: Training 39 / 100 epoch, with learning rate 19.489911293384335
[09/25 23:05:56 visual_prompt]: Epoch 39 / 100: avg data time: 4.22e-02, avg batch time: 0.4852, average train loss: 110.7559
[09/25 23:05:57 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1659, average loss: 101.3684
[09/25 23:05:57 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.00	
[09/25 23:05:57 visual_prompt]: Training 40 / 100 epoch, with learning rate 19.12399080291506
[09/25 23:06:04 visual_prompt]: Epoch 40 / 100: avg data time: 4.80e-02, avg batch time: 0.4893, average train loss: 115.6549
[09/25 23:06:05 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1659, average loss: 74.5482
[09/25 23:06:05 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.00	top5: 5.00	
[09/25 23:06:05 visual_prompt]: Training 41 / 100 epoch, with learning rate 18.75
[09/25 23:06:12 visual_prompt]: Epoch 41 / 100: avg data time: 3.94e-02, avg batch time: 0.4822, average train loss: 84.3545
[09/25 23:06:13 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1660, average loss: 74.8005
[09/25 23:06:13 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.00	
[09/25 23:06:13 visual_prompt]: Training 42 / 100 epoch, with learning rate 18.368394534823633
[09/25 23:06:20 visual_prompt]: Epoch 42 / 100: avg data time: 4.75e-02, avg batch time: 0.4899, average train loss: 79.5842
[09/25 23:06:21 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1662, average loss: 61.5458
[09/25 23:06:21 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 6.00	
[09/25 23:06:21 visual_prompt]: Training 43 / 100 epoch, with learning rate 17.979639334863467
[09/25 23:06:28 visual_prompt]: Epoch 43 / 100: avg data time: 4.67e-02, avg batch time: 0.4884, average train loss: 70.0212
[09/25 23:06:30 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1661, average loss: 53.0117
[09/25 23:06:30 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/25 23:06:30 visual_prompt]: Training 44 / 100 epoch, with learning rate 17.584208038447503
[09/25 23:06:36 visual_prompt]: Epoch 44 / 100: avg data time: 5.68e-02, avg batch time: 0.4973, average train loss: 57.3394
[09/25 23:06:38 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1661, average loss: 54.4249
[09/25 23:06:38 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 5.50	
[09/25 23:06:38 visual_prompt]: Training 45 / 100 epoch, with learning rate 17.182582417698903
[09/25 23:06:44 visual_prompt]: Epoch 45 / 100: avg data time: 5.72e-02, avg batch time: 0.4986, average train loss: 59.7944
[09/25 23:06:46 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1659, average loss: 46.6642
[09/25 23:06:46 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 6.00	
[09/25 23:06:46 visual_prompt]: Training 46 / 100 epoch, with learning rate 16.77525179157086
[09/25 23:06:53 visual_prompt]: Epoch 46 / 100: avg data time: 4.07e-02, avg batch time: 0.4833, average train loss: 46.7241
[09/25 23:06:54 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1660, average loss: 39.7955
[09/25 23:06:54 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 5.00	
[09/25 23:06:54 visual_prompt]: Training 47 / 100 epoch, with learning rate 16.362712429686844
[09/25 23:07:01 visual_prompt]: Epoch 47 / 100: avg data time: 5.54e-02, avg batch time: 0.4971, average train loss: 42.3082
[09/25 23:07:02 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1661, average loss: 35.8762
[09/25 23:07:02 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 8.50	
[09/25 23:07:02 visual_prompt]: Training 48 / 100 epoch, with learning rate 15.94546694771249
[09/25 23:07:09 visual_prompt]: Epoch 48 / 100: avg data time: 5.38e-02, avg batch time: 0.4958, average train loss: 37.5942
[09/25 23:07:10 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1660, average loss: 33.3131
[09/25 23:07:10 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 2.50	
[09/25 23:07:10 visual_prompt]: Training 49 / 100 epoch, with learning rate 15.524023694995845
[09/25 23:07:17 visual_prompt]: Epoch 49 / 100: avg data time: 5.29e-02, avg batch time: 0.4932, average train loss: 33.4069
[09/25 23:07:18 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1660, average loss: 27.0683
[09/25 23:07:18 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 8.00	
[09/25 23:07:18 visual_prompt]: Training 50 / 100 epoch, with learning rate 15.09889613522199
[09/25 23:07:25 visual_prompt]: Epoch 50 / 100: avg data time: 5.74e-02, avg batch time: 0.4984, average train loss: 27.8195
[09/25 23:07:27 visual_prompt]: Inference (val):avg data time: 3.58e-05, avg batch time: 0.1661, average loss: 19.1078
[09/25 23:07:27 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 6.00	
[09/25 23:07:27 visual_prompt]: Training 51 / 100 epoch, with learning rate 14.670602220836631
[09/25 23:07:33 visual_prompt]: Epoch 51 / 100: avg data time: 5.22e-02, avg batch time: 0.4937, average train loss: 21.6184
[09/25 23:07:35 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1664, average loss: 17.8149
[09/25 23:07:35 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 3.50	
[09/25 23:07:35 visual_prompt]: Training 52 / 100 epoch, with learning rate 14.239663762000818
[09/25 23:07:41 visual_prompt]: Epoch 52 / 100: avg data time: 4.73e-02, avg batch time: 0.4878, average train loss: 19.6344
[09/25 23:07:43 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1661, average loss: 15.4981
[09/25 23:07:43 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 3.50	
[09/25 23:07:43 visual_prompt]: Training 53 / 100 epoch, with learning rate 13.80660579084567
[09/25 23:07:50 visual_prompt]: Epoch 53 / 100: avg data time: 5.63e-02, avg batch time: 0.4975, average train loss: 17.8794
[09/25 23:07:51 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1661, average loss: 16.2123
[09/25 23:07:51 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.00	
[09/25 23:07:51 visual_prompt]: Training 54 / 100 epoch, with learning rate 13.371955921801565
[09/25 23:07:58 visual_prompt]: Epoch 54 / 100: avg data time: 5.31e-02, avg batch time: 0.4944, average train loss: 15.7899
[09/25 23:07:59 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1659, average loss: 12.7722
[09/25 23:07:59 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/25 23:07:59 visual_prompt]: Training 55 / 100 epoch, with learning rate 12.936243708781264
[09/25 23:08:06 visual_prompt]: Epoch 55 / 100: avg data time: 5.23e-02, avg batch time: 0.4937, average train loss: 11.4611
[09/25 23:08:07 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1662, average loss: 10.6619
[09/25 23:08:07 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 3.00	
[09/25 23:08:07 visual_prompt]: Training 56 / 100 epoch, with learning rate 12.5
[09/25 23:08:14 visual_prompt]: Epoch 56 / 100: avg data time: 5.39e-02, avg batch time: 0.4951, average train loss: 12.4974
[09/25 23:08:15 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1664, average loss: 16.3624
[09/25 23:08:15 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 4.50	
[09/25 23:08:15 visual_prompt]: Training 57 / 100 epoch, with learning rate 12.063756291218741
[09/25 23:08:22 visual_prompt]: Epoch 57 / 100: avg data time: 5.46e-02, avg batch time: 0.4959, average train loss: 13.5136
[09/25 23:08:24 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1663, average loss: 13.2445
[09/25 23:08:24 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.00	
[09/25 23:08:24 visual_prompt]: Training 58 / 100 epoch, with learning rate 11.628044078198434
[09/25 23:08:30 visual_prompt]: Epoch 58 / 100: avg data time: 4.91e-02, avg batch time: 0.4907, average train loss: 11.1690
[09/25 23:08:32 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1663, average loss: 11.3730
[09/25 23:08:32 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.50	
[09/25 23:08:32 visual_prompt]: Training 59 / 100 epoch, with learning rate 11.193394209154334
[09/25 23:08:38 visual_prompt]: Epoch 59 / 100: avg data time: 5.20e-02, avg batch time: 0.4927, average train loss: 9.6891
[09/25 23:08:40 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1660, average loss: 11.5295
[09/25 23:08:40 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.00	top5: 4.00	
[09/25 23:08:40 visual_prompt]: Training 60 / 100 epoch, with learning rate 10.760336237999185
[09/25 23:08:47 visual_prompt]: Epoch 60 / 100: avg data time: 5.15e-02, avg batch time: 0.4933, average train loss: 10.7032
[09/25 23:08:48 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1662, average loss: 9.8612
[09/25 23:08:48 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 3.50	
[09/25 23:08:48 visual_prompt]: Training 61 / 100 epoch, with learning rate 10.32939777916337
[09/25 23:08:55 visual_prompt]: Epoch 61 / 100: avg data time: 4.00e-02, avg batch time: 0.4841, average train loss: 9.3100
[09/25 23:08:56 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.1659, average loss: 8.7714
[09/25 23:08:56 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 3.50	
[09/25 23:08:56 visual_prompt]: Training 62 / 100 epoch, with learning rate 9.90110386477801
[09/25 23:09:03 visual_prompt]: Epoch 62 / 100: avg data time: 5.66e-02, avg batch time: 0.4994, average train loss: 7.4240
[09/25 23:09:04 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1661, average loss: 7.0272
[09/25 23:09:04 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.00	
[09/25 23:09:04 visual_prompt]: Training 63 / 100 epoch, with learning rate 9.475976305004155
[09/25 23:09:11 visual_prompt]: Epoch 63 / 100: avg data time: 4.04e-02, avg batch time: 0.4828, average train loss: 6.3794
[09/25 23:09:12 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1662, average loss: 6.5425
[09/25 23:09:12 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 6.00	
[09/25 23:09:12 visual_prompt]: Training 64 / 100 epoch, with learning rate 9.05453305228751
[09/25 23:09:19 visual_prompt]: Epoch 64 / 100: avg data time: 5.30e-02, avg batch time: 0.4948, average train loss: 5.9699
[09/25 23:09:20 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1661, average loss: 5.7688
[09/25 23:09:20 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 4.00	
[09/25 23:09:20 visual_prompt]: Training 65 / 100 epoch, with learning rate 8.637287570313159
[09/25 23:09:27 visual_prompt]: Epoch 65 / 100: avg data time: 5.65e-02, avg batch time: 0.4972, average train loss: 5.4264
[09/25 23:09:29 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1662, average loss: 5.6865
[09/25 23:09:29 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.50	
[09/25 23:09:29 visual_prompt]: Training 66 / 100 epoch, with learning rate 8.224748208429142
[09/25 23:09:35 visual_prompt]: Epoch 66 / 100: avg data time: 4.68e-02, avg batch time: 0.4892, average train loss: 5.3751
[09/25 23:09:37 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1662, average loss: 5.3407
[09/25 23:09:37 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 6.00	
[09/25 23:09:37 visual_prompt]: Training 67 / 100 epoch, with learning rate 7.817417582301099
[09/25 23:09:43 visual_prompt]: Epoch 67 / 100: avg data time: 5.99e-02, avg batch time: 0.5007, average train loss: 5.3032
[09/25 23:09:45 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1661, average loss: 5.1431
[09/25 23:09:45 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 7.00	
[09/25 23:09:45 visual_prompt]: Training 68 / 100 epoch, with learning rate 7.415791961552499
[09/25 23:09:52 visual_prompt]: Epoch 68 / 100: avg data time: 5.32e-02, avg batch time: 0.4955, average train loss: 5.2251
[09/25 23:09:53 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1663, average loss: 5.0256
[09/25 23:09:53 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 9.00	
[09/25 23:09:53 visual_prompt]: Training 69 / 100 epoch, with learning rate 7.020360665136531
[09/25 23:10:00 visual_prompt]: Epoch 69 / 100: avg data time: 5.65e-02, avg batch time: 0.4974, average train loss: 4.9709
[09/25 23:10:01 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1663, average loss: 4.9927
[09/25 23:10:01 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.50	top5: 6.00	
[09/25 23:10:01 visual_prompt]: Training 70 / 100 epoch, with learning rate 6.631605465176368
[09/25 23:10:08 visual_prompt]: Epoch 70 / 100: avg data time: 5.72e-02, avg batch time: 0.4982, average train loss: 4.8558
[09/25 23:10:09 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1662, average loss: 4.8576
[09/25 23:10:09 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 10.00	
[09/25 23:10:09 visual_prompt]: Training 71 / 100 epoch, with learning rate 6.250000000000003
[09/25 23:10:16 visual_prompt]: Epoch 71 / 100: avg data time: 5.68e-02, avg batch time: 0.4976, average train loss: 4.8116
[09/25 23:10:18 visual_prompt]: Inference (val):avg data time: 4.17e-05, avg batch time: 0.1662, average loss: 4.7217
[09/25 23:10:18 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 3.00	top5: 12.00	
[09/25 23:10:18 visual_prompt]: Training 72 / 100 epoch, with learning rate 5.87600919708494
[09/25 23:10:24 visual_prompt]: Epoch 72 / 100: avg data time: 4.55e-02, avg batch time: 0.4873, average train loss: 4.6051
[09/25 23:10:26 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1660, average loss: 4.8653
[09/25 23:10:26 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 3.50	top5: 10.50	
[09/25 23:10:26 visual_prompt]: Best epoch 72: best metric: 0.035
[09/25 23:10:26 visual_prompt]: Training 73 / 100 epoch, with learning rate 5.510088706615666
[09/25 23:10:32 visual_prompt]: Epoch 73 / 100: avg data time: 4.51e-02, avg batch time: 0.4878, average train loss: 4.5720
[09/25 23:10:34 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1661, average loss: 4.4920
[09/25 23:10:34 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 3.00	top5: 15.50	
[09/25 23:10:34 visual_prompt]: Training 74 / 100 epoch, with learning rate 5.1526843463440875
[09/25 23:10:40 visual_prompt]: Epoch 74 / 100: avg data time: 4.28e-02, avg batch time: 0.4858, average train loss: 4.4284
[09/25 23:10:42 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1661, average loss: 4.4440
[09/25 23:10:42 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 4.00	top5: 12.50	
[09/25 23:10:42 visual_prompt]: Best epoch 74: best metric: 0.040
[09/25 23:10:42 visual_prompt]: Training 75 / 100 epoch, with learning rate 4.804231558429271
[09/25 23:10:48 visual_prompt]: Epoch 75 / 100: avg data time: 4.63e-02, avg batch time: 0.4890, average train loss: 4.2759
[09/25 23:10:50 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1664, average loss: 4.4236
[09/25 23:10:50 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 6.00	top5: 17.50	
[09/25 23:10:50 visual_prompt]: Best epoch 75: best metric: 0.060
[09/25 23:10:50 visual_prompt]: Training 76 / 100 epoch, with learning rate 4.465154878918258
[09/25 23:10:56 visual_prompt]: Epoch 76 / 100: avg data time: 5.32e-02, avg batch time: 0.4954, average train loss: 4.2249
[09/25 23:10:58 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1663, average loss: 4.4730
[09/25 23:10:58 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 5.00	top5: 18.50	
[09/25 23:10:58 visual_prompt]: Training 77 / 100 epoch, with learning rate 4.135867420514276
[09/25 23:11:05 visual_prompt]: Epoch 77 / 100: avg data time: 5.20e-02, avg batch time: 0.4937, average train loss: 4.0309
[09/25 23:11:06 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1663, average loss: 4.4821
[09/25 23:11:06 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 6.00	top5: 23.00	
[09/25 23:11:06 visual_prompt]: Training 78 / 100 epoch, with learning rate 3.816770369262533
[09/25 23:11:13 visual_prompt]: Epoch 78 / 100: avg data time: 5.74e-02, avg batch time: 0.4986, average train loss: 3.9318
[09/25 23:11:14 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1662, average loss: 4.3622
[09/25 23:11:14 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 5.00	top5: 19.00	
[09/25 23:11:14 visual_prompt]: Training 79 / 100 epoch, with learning rate 3.508252495766863
[09/25 23:11:21 visual_prompt]: Epoch 79 / 100: avg data time: 5.76e-02, avg batch time: 0.5007, average train loss: 3.8270
[09/25 23:11:23 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1660, average loss: 4.2268
[09/25 23:11:23 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 8.50	top5: 23.00	
[09/25 23:11:23 visual_prompt]: Best epoch 79: best metric: 0.085
[09/25 23:11:23 visual_prompt]: Training 80 / 100 epoch, with learning rate 3.2106896815325707
[09/25 23:11:29 visual_prompt]: Epoch 80 / 100: avg data time: 5.53e-02, avg batch time: 0.4974, average train loss: 3.5871
[09/25 23:11:31 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1663, average loss: 4.3379
[09/25 23:11:31 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 7.00	top5: 25.00	
[09/25 23:11:31 visual_prompt]: Training 81 / 100 epoch, with learning rate 2.924444461012776
[09/25 23:11:37 visual_prompt]: Epoch 81 / 100: avg data time: 4.07e-02, avg batch time: 0.4835, average train loss: 3.4716
[09/25 23:11:39 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1661, average loss: 4.2507
[09/25 23:11:39 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 8.00	top5: 21.00	
[09/25 23:11:39 visual_prompt]: Training 82 / 100 epoch, with learning rate 2.6498655799159763
[09/25 23:11:46 visual_prompt]: Epoch 82 / 100: avg data time: 6.03e-02, avg batch time: 0.5025, average train loss: 3.1432
[09/25 23:11:47 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1662, average loss: 4.2815
[09/25 23:11:47 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 12.00	top5: 29.50	
[09/25 23:11:47 visual_prompt]: Best epoch 82: best metric: 0.120
[09/25 23:11:47 visual_prompt]: Training 83 / 100 epoch, with learning rate 2.387287570313158
[09/25 23:11:54 visual_prompt]: Epoch 83 / 100: avg data time: 5.23e-02, avg batch time: 0.4941, average train loss: 2.8241
[09/25 23:11:55 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1662, average loss: 4.4302
[09/25 23:11:55 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 14.00	top5: 33.50	
[09/25 23:11:55 visual_prompt]: Best epoch 83: best metric: 0.140
[09/25 23:11:55 visual_prompt]: Training 84 / 100 epoch, with learning rate 2.13703034306198
[09/25 23:12:02 visual_prompt]: Epoch 84 / 100: avg data time: 4.91e-02, avg batch time: 0.4905, average train loss: 2.2128
[09/25 23:12:03 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1661, average loss: 4.1520
[09/25 23:12:03 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 18.50	top5: 44.50	
[09/25 23:12:03 visual_prompt]: Best epoch 84: best metric: 0.185
[09/25 23:12:03 visual_prompt]: Training 85 / 100 epoch, with learning rate 1.8993987980446756
[09/25 23:12:10 visual_prompt]: Epoch 85 / 100: avg data time: 6.12e-02, avg batch time: 0.5029, average train loss: 1.5227
[09/25 23:12:12 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1662, average loss: 4.6151
[09/25 23:12:12 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 16.00	top5: 40.00	
[09/25 23:12:12 visual_prompt]: Training 86 / 100 epoch, with learning rate 1.674682452694516
[09/25 23:12:18 visual_prompt]: Epoch 86 / 100: avg data time: 5.18e-02, avg batch time: 0.4938, average train loss: 0.9734
[09/25 23:12:20 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1660, average loss: 4.2671
[09/25 23:12:20 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 17.00	top5: 50.50	
[09/25 23:12:20 visual_prompt]: Training 87 / 100 epoch, with learning rate 1.4631550892634126
[09/25 23:12:26 visual_prompt]: Epoch 87 / 100: avg data time: 5.47e-02, avg batch time: 0.4960, average train loss: 0.4494
[09/25 23:12:28 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1663, average loss: 4.5098
[09/25 23:12:28 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 18.00	top5: 49.00	
[09/25 23:12:28 visual_prompt]: Training 88 / 100 epoch, with learning rate 1.2650744212604148
[09/25 23:12:34 visual_prompt]: Epoch 88 / 100: avg data time: 4.37e-02, avg batch time: 0.4856, average train loss: 0.1748
[09/25 23:12:36 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1663, average loss: 4.4780
[09/25 23:12:36 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 20.00	top5: 54.00	
[09/25 23:12:36 visual_prompt]: Best epoch 88: best metric: 0.200
[09/25 23:12:36 visual_prompt]: Training 89 / 100 epoch, with learning rate 1.0806817794674877
[09/25 23:12:43 visual_prompt]: Epoch 89 / 100: avg data time: 5.07e-02, avg batch time: 0.4928, average train loss: 0.0882
[09/25 23:12:44 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1662, average loss: 4.3402
[09/25 23:12:44 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 25.50	top5: 53.50	
[09/25 23:12:44 visual_prompt]: Best epoch 89: best metric: 0.255
[09/25 23:12:44 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.9102018179151585
[09/25 23:12:51 visual_prompt]: Epoch 90 / 100: avg data time: 5.43e-02, avg batch time: 0.4969, average train loss: 0.0428
[09/25 23:12:52 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1664, average loss: 4.3052
[09/25 23:12:52 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 26.00	top5: 55.50	
[09/25 23:12:52 visual_prompt]: Best epoch 90: best metric: 0.260
[09/25 23:12:52 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.753842240176146
[09/25 23:12:59 visual_prompt]: Epoch 91 / 100: avg data time: 5.58e-02, avg batch time: 0.4982, average train loss: 0.0320
[09/25 23:13:00 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1661, average loss: 4.3015
[09/25 23:13:00 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 25.00	top5: 56.50	
[09/25 23:13:00 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.6117935463105808
[09/25 23:13:07 visual_prompt]: Epoch 92 / 100: avg data time: 4.64e-02, avg batch time: 0.4892, average train loss: 0.0207
[09/25 23:13:09 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1665, average loss: 4.3271
[09/25 23:13:09 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 25.00	top5: 55.00	
[09/25 23:13:09 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.4842288007710138
[09/25 23:13:15 visual_prompt]: Epoch 93 / 100: avg data time: 5.54e-02, avg batch time: 0.4968, average train loss: 0.0178
[09/25 23:13:17 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1664, average loss: 4.2918
[09/25 23:13:17 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 26.00	top5: 57.50	
[09/25 23:13:17 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.3713034215500441
[09/25 23:13:23 visual_prompt]: Epoch 94 / 100: avg data time: 5.58e-02, avg batch time: 0.4970, average train loss: 0.0161
[09/25 23:13:25 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1662, average loss: 4.2811
[09/25 23:13:25 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 25.00	top5: 57.00	
[09/25 23:13:25 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.2731549908274289
[09/25 23:13:32 visual_prompt]: Epoch 95 / 100: avg data time: 5.04e-02, avg batch time: 0.4938, average train loss: 0.0155
[09/25 23:13:33 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1663, average loss: 4.2745
[09/25 23:13:33 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 25.00	top5: 57.50	
[09/25 23:13:33 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.18990308734739975
[09/25 23:13:40 visual_prompt]: Epoch 96 / 100: avg data time: 5.84e-02, avg batch time: 0.5000, average train loss: 0.0152
[09/25 23:13:41 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1663, average loss: 4.2712
[09/25 23:13:41 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 25.00	top5: 58.00	
[09/25 23:13:41 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.12164914073037048
[09/25 23:13:48 visual_prompt]: Epoch 97 / 100: avg data time: 6.30e-02, avg batch time: 0.5053, average train loss: 0.0149
[09/25 23:13:50 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1665, average loss: 4.2673
[09/25 23:13:50 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 24.00	top5: 57.50	
[09/25 23:13:50 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.06847630789658388
[09/25 23:13:56 visual_prompt]: Epoch 98 / 100: avg data time: 4.51e-02, avg batch time: 0.4864, average train loss: 0.0147
[09/25 23:13:58 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1663, average loss: 4.2656
[09/25 23:13:58 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 24.00	top5: 57.50	
[09/25 23:13:58 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.03044937175219753
[09/25 23:14:04 visual_prompt]: Epoch 99 / 100: avg data time: 5.11e-02, avg batch time: 0.4924, average train loss: 0.0146
[09/25 23:14:06 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1665, average loss: 4.2653
[09/25 23:14:06 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 24.00	top5: 57.50	
[09/25 23:14:06 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0076146622613029735
[09/25 23:14:12 visual_prompt]: Epoch 100 / 100: avg data time: 5.01e-02, avg batch time: 0.4941, average train loss: 0.0146
[09/25 23:14:14 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1662, average loss: 4.2652
[09/25 23:14:14 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 23.50	top5: 58.00	
[09/25 23:14:14 visual_prompt]: Rank of current process: 0. World size: 1
[09/25 23:14:14 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/25 23:14:14 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-cifar(num_classes=100)', 'DATA.NUMBER_CLASSES', '100', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/25 23:14:14 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/25 23:14:14 visual_prompt]: Training with config:
[09/25 23:14:14 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-cifar(num_classes=100)/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr25.0_wd0.0/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 25.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-cifar(num_classes=100)', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 100, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/25 23:14:14 visual_prompt]: Loading training data...
[09/25 23:14:14 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[:800], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/25 23:14:15 visual_prompt]: Number of images: 800
[09/25 23:14:15 visual_prompt]: Number of classes: 100 / 100
[09/25 23:14:15 visual_prompt]: Loading validation data...
[09/25 23:14:15 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[45000:45200], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/25 23:14:15 visual_prompt]: Number of images: 200
[09/25 23:14:15 visual_prompt]: Number of classes: 90 / 100
[09/25 23:14:15 visual_prompt]: Constructing models...
[09/25 23:14:18 visual_prompt]: Total Parameters: 86336356	 Gradient Parameters: 537700
[09/25 23:14:18 visual_prompt]: tuned percent:0.623
[09/25 23:14:18 visual_prompt]: Device used for model: 0
[09/25 23:14:18 visual_prompt]: Setting up Evaluator...
[09/25 23:14:18 visual_prompt]: Setting up Trainer...
[09/25 23:14:18 visual_prompt]: 	Setting up the optimizer...
[09/25 23:14:18 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/25 23:14:25 visual_prompt]: Epoch 1 / 100: avg data time: 5.33e-02, avg batch time: 0.4948, average train loss: 4.6574
[09/25 23:14:26 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1659, average loss: 4.6218
[09/25 23:14:26 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 7.00	
[09/25 23:14:26 visual_prompt]: Best epoch 1: best metric: 0.010
[09/25 23:14:26 visual_prompt]: Training 2 / 100 epoch, with learning rate 2.5
[09/25 23:14:33 visual_prompt]: Epoch 2 / 100: avg data time: 4.59e-02, avg batch time: 0.4873, average train loss: 4.7701
[09/25 23:14:34 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1657, average loss: 4.8504
[09/25 23:14:34 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.00	top5: 3.50	
[09/25 23:14:34 visual_prompt]: Training 3 / 100 epoch, with learning rate 5.0
[09/25 23:14:41 visual_prompt]: Epoch 3 / 100: avg data time: 5.61e-02, avg batch time: 0.4965, average train loss: 5.1040
[09/25 23:14:42 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1660, average loss: 5.1355
[09/25 23:14:42 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 5.00	
[09/25 23:14:42 visual_prompt]: Best epoch 3: best metric: 0.015
[09/25 23:14:42 visual_prompt]: Training 4 / 100 epoch, with learning rate 7.5
[09/25 23:14:49 visual_prompt]: Epoch 4 / 100: avg data time: 5.49e-02, avg batch time: 0.4959, average train loss: 5.4740
[09/25 23:14:50 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1661, average loss: 5.6760
[09/25 23:14:50 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 7.00	
[09/25 23:14:50 visual_prompt]: Training 5 / 100 epoch, with learning rate 10.0
[09/25 23:14:57 visual_prompt]: Epoch 5 / 100: avg data time: 5.73e-02, avg batch time: 0.4987, average train loss: 6.2140
[09/25 23:14:59 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1661, average loss: 6.9231
[09/25 23:14:59 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 4.50	
[09/25 23:14:59 visual_prompt]: Training 6 / 100 epoch, with learning rate 12.5
[09/25 23:15:05 visual_prompt]: Epoch 6 / 100: avg data time: 4.70e-02, avg batch time: 0.4883, average train loss: 9.6100
[09/25 23:15:07 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1658, average loss: 15.1442
[09/25 23:15:07 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.50	
[09/25 23:15:07 visual_prompt]: Training 7 / 100 epoch, with learning rate 15.0
[09/25 23:15:13 visual_prompt]: Epoch 7 / 100: avg data time: 5.31e-02, avg batch time: 0.4932, average train loss: 22.2477
[09/25 23:15:15 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1656, average loss: 27.1147
[09/25 23:15:15 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.00	
[09/25 23:15:15 visual_prompt]: Training 8 / 100 epoch, with learning rate 17.5
[09/25 23:15:21 visual_prompt]: Epoch 8 / 100: avg data time: 4.90e-02, avg batch time: 0.4907, average train loss: 44.8550
[09/25 23:15:23 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1657, average loss: 52.4337
[09/25 23:15:23 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 4.50	
[09/25 23:15:23 visual_prompt]: Training 9 / 100 epoch, with learning rate 20.0
[09/25 23:15:30 visual_prompt]: Epoch 9 / 100: avg data time: 5.45e-02, avg batch time: 0.4958, average train loss: 75.1789
[09/25 23:15:31 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1658, average loss: 107.4506
[09/25 23:15:31 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/25 23:15:31 visual_prompt]: Training 10 / 100 epoch, with learning rate 22.5
[09/25 23:15:38 visual_prompt]: Epoch 10 / 100: avg data time: 5.93e-02, avg batch time: 0.4996, average train loss: 131.8502
[09/25 23:15:39 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1659, average loss: 101.4448
[09/25 23:15:39 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.50	
[09/25 23:15:39 visual_prompt]: Training 11 / 100 epoch, with learning rate 25.0
[09/25 23:15:46 visual_prompt]: Epoch 11 / 100: avg data time: 5.10e-02, avg batch time: 0.4921, average train loss: 135.2802
[09/25 23:15:47 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1663, average loss: 74.9587
[09/25 23:15:47 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.50	
[09/25 23:15:47 visual_prompt]: Training 12 / 100 epoch, with learning rate 24.9923853377387
[09/25 23:15:54 visual_prompt]: Epoch 12 / 100: avg data time: 4.10e-02, avg batch time: 0.4836, average train loss: 135.3153
[09/25 23:15:55 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1659, average loss: 122.9680
[09/25 23:15:56 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 7.00	
[09/25 23:15:56 visual_prompt]: Best epoch 12: best metric: 0.020
[09/25 23:15:56 visual_prompt]: Training 13 / 100 epoch, with learning rate 24.969550628247802
[09/25 23:16:02 visual_prompt]: Epoch 13 / 100: avg data time: 5.59e-02, avg batch time: 0.4971, average train loss: 186.8865
[09/25 23:16:04 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1661, average loss: 169.1021
[09/25 23:16:04 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.00	
[09/25 23:16:04 visual_prompt]: Training 14 / 100 epoch, with learning rate 24.931523692103415
[09/25 23:16:10 visual_prompt]: Epoch 14 / 100: avg data time: 4.58e-02, avg batch time: 0.4883, average train loss: 191.6591
[09/25 23:16:12 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1662, average loss: 170.1120
[09/25 23:16:12 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 4.50	
[09/25 23:16:12 visual_prompt]: Training 15 / 100 epoch, with learning rate 24.87835085926963
[09/25 23:16:18 visual_prompt]: Epoch 15 / 100: avg data time: 4.80e-02, avg batch time: 0.4890, average train loss: 160.1001
[09/25 23:16:20 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1662, average loss: 135.0995
[09/25 23:16:20 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.00	
[09/25 23:16:20 visual_prompt]: Training 16 / 100 epoch, with learning rate 24.8100969126526
[09/25 23:16:26 visual_prompt]: Epoch 16 / 100: avg data time: 4.84e-02, avg batch time: 0.4907, average train loss: 123.9935
[09/25 23:16:28 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1661, average loss: 103.9349
[09/25 23:16:28 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 6.50	
[09/25 23:16:28 visual_prompt]: Training 17 / 100 epoch, with learning rate 24.72684500917257
[09/25 23:16:35 visual_prompt]: Epoch 17 / 100: avg data time: 5.79e-02, avg batch time: 0.5004, average train loss: 102.1338
[09/25 23:16:36 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1666, average loss: 92.3048
[09/25 23:16:36 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.00	top5: 3.50	
[09/25 23:16:36 visual_prompt]: Training 18 / 100 epoch, with learning rate 24.628696578449954
[09/25 23:16:43 visual_prompt]: Epoch 18 / 100: avg data time: 4.22e-02, avg batch time: 0.4849, average train loss: 77.5875
[09/25 23:16:44 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1662, average loss: 65.1201
[09/25 23:16:44 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 4.50	
[09/25 23:16:44 visual_prompt]: Training 19 / 100 epoch, with learning rate 24.515771199228986
[09/25 23:16:51 visual_prompt]: Epoch 19 / 100: avg data time: 5.38e-02, avg batch time: 0.4961, average train loss: 64.7529
[09/25 23:16:52 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1662, average loss: 66.6172
[09/25 23:16:52 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.00	
[09/25 23:16:52 visual_prompt]: Training 20 / 100 epoch, with learning rate 24.38820645368942
[09/25 23:16:59 visual_prompt]: Epoch 20 / 100: avg data time: 4.75e-02, avg batch time: 0.4898, average train loss: 57.4534
[09/25 23:17:00 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1664, average loss: 50.5910
[09/25 23:17:01 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 5.00	
[09/25 23:17:01 visual_prompt]: Training 21 / 100 epoch, with learning rate 24.246157759823856
[09/25 23:17:07 visual_prompt]: Epoch 21 / 100: avg data time: 5.51e-02, avg batch time: 0.4968, average train loss: 44.9936
[09/25 23:17:09 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1662, average loss: 42.0577
[09/25 23:17:09 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 5.00	
[09/25 23:17:09 visual_prompt]: Training 22 / 100 epoch, with learning rate 24.08979818208484
[09/25 23:17:15 visual_prompt]: Epoch 22 / 100: avg data time: 5.45e-02, avg batch time: 0.4959, average train loss: 40.9072
[09/25 23:17:17 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1662, average loss: 39.8447
[09/25 23:17:17 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 7.00	
[09/25 23:17:17 visual_prompt]: Training 23 / 100 epoch, with learning rate 23.91931822053251
[09/25 23:17:24 visual_prompt]: Epoch 23 / 100: avg data time: 5.90e-02, avg batch time: 0.5007, average train loss: 36.8405
[09/25 23:17:25 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1663, average loss: 27.6198
[09/25 23:17:25 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 6.50	
[09/25 23:17:25 visual_prompt]: Training 24 / 100 epoch, with learning rate 23.73492557873959
[09/25 23:17:32 visual_prompt]: Epoch 24 / 100: avg data time: 5.78e-02, avg batch time: 0.4999, average train loss: 32.4159
[09/25 23:17:33 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1663, average loss: 27.7243
[09/25 23:17:33 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.50	
[09/25 23:17:33 visual_prompt]: Training 25 / 100 epoch, with learning rate 23.536844910736587
[09/25 23:17:40 visual_prompt]: Epoch 25 / 100: avg data time: 4.54e-02, avg batch time: 0.4889, average train loss: 29.0261
[09/25 23:17:41 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1664, average loss: 27.9582
[09/25 23:17:41 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.50	top5: 10.00	
[09/25 23:17:41 visual_prompt]: Best epoch 25: best metric: 0.025
[09/25 23:17:41 visual_prompt]: Training 26 / 100 epoch, with learning rate 23.325317547305485
[09/25 23:17:48 visual_prompt]: Epoch 26 / 100: avg data time: 5.26e-02, avg batch time: 0.4955, average train loss: 26.0887
[09/25 23:17:50 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1662, average loss: 27.2064
[09/25 23:17:50 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 10.00	
[09/25 23:17:50 visual_prompt]: Training 27 / 100 epoch, with learning rate 23.100601201955325
[09/25 23:17:56 visual_prompt]: Epoch 27 / 100: avg data time: 5.31e-02, avg batch time: 0.4959, average train loss: 24.0529
[09/25 23:17:58 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1662, average loss: 23.6389
[09/25 23:17:58 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 3.00	top5: 8.50	
[09/25 23:17:58 visual_prompt]: Best epoch 27: best metric: 0.030
[09/25 23:17:58 visual_prompt]: Training 28 / 100 epoch, with learning rate 22.86296965693802
[09/25 23:18:04 visual_prompt]: Epoch 28 / 100: avg data time: 5.51e-02, avg batch time: 0.4971, average train loss: 23.0836
[09/25 23:18:06 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1660, average loss: 18.4748
[09/25 23:18:06 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.50	top5: 12.00	
[09/25 23:18:06 visual_prompt]: Training 29 / 100 epoch, with learning rate 22.612712429686844
[09/25 23:18:13 visual_prompt]: Epoch 29 / 100: avg data time: 5.91e-02, avg batch time: 0.5008, average train loss: 20.9851
[09/25 23:18:14 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1661, average loss: 16.3905
[09/25 23:18:14 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 8.00	
[09/25 23:18:14 visual_prompt]: Training 30 / 100 epoch, with learning rate 22.35013442008402
[09/25 23:18:21 visual_prompt]: Epoch 30 / 100: avg data time: 5.21e-02, avg batch time: 0.4934, average train loss: 18.8904
[09/25 23:18:22 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1662, average loss: 19.8089
[09/25 23:18:22 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 3.50	
[09/25 23:18:22 visual_prompt]: Training 31 / 100 epoch, with learning rate 22.075555538987224
[09/25 23:18:29 visual_prompt]: Epoch 31 / 100: avg data time: 3.96e-02, avg batch time: 0.4832, average train loss: 19.5970
[09/25 23:18:30 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1664, average loss: 15.0456
[09/25 23:18:30 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.50	top5: 12.50	
[09/25 23:18:30 visual_prompt]: Training 32 / 100 epoch, with learning rate 21.78931031846743
[09/25 23:18:37 visual_prompt]: Epoch 32 / 100: avg data time: 5.63e-02, avg batch time: 0.4974, average train loss: 16.0042
[09/25 23:18:39 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1661, average loss: 14.4698
[09/25 23:18:39 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 10.50	
[09/25 23:18:39 visual_prompt]: Training 33 / 100 epoch, with learning rate 21.49174750423314
[09/25 23:18:45 visual_prompt]: Epoch 33 / 100: avg data time: 5.06e-02, avg batch time: 0.4938, average train loss: 15.7901
[09/25 23:18:47 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1664, average loss: 11.4519
[09/25 23:18:47 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 8.50	
[09/25 23:18:47 visual_prompt]: Training 34 / 100 epoch, with learning rate 21.183229630737465
[09/25 23:18:54 visual_prompt]: Epoch 34 / 100: avg data time: 5.74e-02, avg batch time: 0.5001, average train loss: 12.4805
[09/25 23:18:55 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1662, average loss: 11.1519
[09/25 23:18:55 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 10.00	
[09/25 23:18:55 visual_prompt]: Training 35 / 100 epoch, with learning rate 20.864132579485727
[09/25 23:19:02 visual_prompt]: Epoch 35 / 100: avg data time: 5.72e-02, avg batch time: 0.4988, average train loss: 12.2081
[09/25 23:19:03 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1664, average loss: 10.5078
[09/25 23:19:03 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 11.00	
[09/25 23:19:03 visual_prompt]: Training 36 / 100 epoch, with learning rate 20.53484512108174
[09/25 23:19:10 visual_prompt]: Epoch 36 / 100: avg data time: 5.35e-02, avg batch time: 0.4954, average train loss: 10.4092
[09/25 23:19:11 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1664, average loss: 8.8779
[09/25 23:19:11 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.50	top5: 9.00	
[09/25 23:19:11 visual_prompt]: Training 37 / 100 epoch, with learning rate 20.195768441570728
[09/25 23:19:18 visual_prompt]: Epoch 37 / 100: avg data time: 5.36e-02, avg batch time: 0.4968, average train loss: 10.8613
[09/25 23:19:19 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1663, average loss: 13.9215
[09/25 23:19:19 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.50	top5: 7.00	
[09/25 23:19:19 visual_prompt]: Training 38 / 100 epoch, with learning rate 19.847315653655915
[09/25 23:19:26 visual_prompt]: Epoch 38 / 100: avg data time: 5.59e-02, avg batch time: 0.4970, average train loss: 10.8872
[09/25 23:19:28 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1661, average loss: 10.1030
[09/25 23:19:28 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.50	top5: 9.50	
[09/25 23:19:28 visual_prompt]: Training 39 / 100 epoch, with learning rate 19.489911293384335
[09/25 23:19:34 visual_prompt]: Epoch 39 / 100: avg data time: 4.50e-02, avg batch time: 0.4871, average train loss: 10.6660
[09/25 23:19:36 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1663, average loss: 11.1417
[09/25 23:19:36 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 7.50	
[09/25 23:19:36 visual_prompt]: Training 40 / 100 epoch, with learning rate 19.12399080291506
[09/25 23:19:42 visual_prompt]: Epoch 40 / 100: avg data time: 4.54e-02, avg batch time: 0.4880, average train loss: 11.0780
[09/25 23:19:44 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1664, average loss: 11.8660
[09/25 23:19:44 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 8.50	
[09/25 23:19:44 visual_prompt]: Training 41 / 100 epoch, with learning rate 18.75
[09/25 23:19:50 visual_prompt]: Epoch 41 / 100: avg data time: 4.90e-02, avg batch time: 0.4914, average train loss: 11.9325
[09/25 23:19:52 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1661, average loss: 8.1257
[09/25 23:19:52 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 3.00	top5: 13.00	
[09/25 23:19:52 visual_prompt]: Training 42 / 100 epoch, with learning rate 18.368394534823633
[09/25 23:19:59 visual_prompt]: Epoch 42 / 100: avg data time: 5.85e-02, avg batch time: 0.5034, average train loss: 10.7450
[09/25 23:20:00 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1661, average loss: 9.7863
[09/25 23:20:00 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 3.00	top5: 10.50	
[09/25 23:20:00 visual_prompt]: Training 43 / 100 epoch, with learning rate 17.979639334863467
[09/25 23:20:07 visual_prompt]: Epoch 43 / 100: avg data time: 5.39e-02, avg batch time: 0.4967, average train loss: 9.5196
[09/25 23:20:08 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1662, average loss: 8.0556
[09/25 23:20:08 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 4.00	top5: 9.00	
[09/25 23:20:08 visual_prompt]: Best epoch 43: best metric: 0.040
[09/25 23:20:08 visual_prompt]: Training 44 / 100 epoch, with learning rate 17.584208038447503
[09/25 23:20:15 visual_prompt]: Epoch 44 / 100: avg data time: 5.52e-02, avg batch time: 0.4962, average train loss: 8.1181
[09/25 23:20:16 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1662, average loss: 8.0932
[09/25 23:20:16 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.50	top5: 14.00	
[09/25 23:20:16 visual_prompt]: Training 45 / 100 epoch, with learning rate 17.182582417698903
[09/25 23:20:23 visual_prompt]: Epoch 45 / 100: avg data time: 4.53e-02, avg batch time: 0.4863, average train loss: 8.3262
[09/25 23:20:24 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1662, average loss: 7.5152
[09/25 23:20:24 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 5.00	top5: 14.00	
[09/25 23:20:24 visual_prompt]: Best epoch 45: best metric: 0.050
[09/25 23:20:24 visual_prompt]: Training 46 / 100 epoch, with learning rate 16.77525179157086
[09/25 23:20:31 visual_prompt]: Epoch 46 / 100: avg data time: 5.79e-02, avg batch time: 0.4995, average train loss: 7.9636
[09/25 23:20:33 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1661, average loss: 6.5696
[09/25 23:20:33 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 3.00	top5: 11.00	
[09/25 23:20:33 visual_prompt]: Training 47 / 100 epoch, with learning rate 16.362712429686844
[09/25 23:20:39 visual_prompt]: Epoch 47 / 100: avg data time: 5.87e-02, avg batch time: 0.4996, average train loss: 7.6746
[09/25 23:20:41 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1664, average loss: 7.8840
[09/25 23:20:41 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 3.00	top5: 12.00	
[09/25 23:20:41 visual_prompt]: Training 48 / 100 epoch, with learning rate 15.94546694771249
[09/25 23:20:48 visual_prompt]: Epoch 48 / 100: avg data time: 4.68e-02, avg batch time: 0.4895, average train loss: 7.5024
[09/25 23:20:49 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1660, average loss: 8.7129
[09/25 23:20:49 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 11.50	
[09/25 23:20:49 visual_prompt]: Training 49 / 100 epoch, with learning rate 15.524023694995845
[09/25 23:20:56 visual_prompt]: Epoch 49 / 100: avg data time: 4.86e-02, avg batch time: 0.4902, average train loss: 7.1887
[09/25 23:20:57 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1661, average loss: 7.8254
[09/25 23:20:57 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.50	top5: 12.00	
[09/25 23:20:57 visual_prompt]: Training 50 / 100 epoch, with learning rate 15.09889613522199
[09/25 23:21:04 visual_prompt]: Epoch 50 / 100: avg data time: 4.11e-02, avg batch time: 0.4842, average train loss: 7.1554
[09/25 23:21:05 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1663, average loss: 8.5389
[09/25 23:21:05 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 13.50	
[09/25 23:21:05 visual_prompt]: Training 51 / 100 epoch, with learning rate 14.670602220836631
[09/25 23:21:12 visual_prompt]: Epoch 51 / 100: avg data time: 5.89e-02, avg batch time: 0.5002, average train loss: 7.2024
[09/25 23:21:13 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1662, average loss: 7.3039
[09/25 23:21:13 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 5.00	top5: 12.00	
[09/25 23:21:13 visual_prompt]: Training 52 / 100 epoch, with learning rate 14.239663762000818
[09/25 23:21:20 visual_prompt]: Epoch 52 / 100: avg data time: 5.63e-02, avg batch time: 0.4986, average train loss: 7.4349
[09/25 23:21:22 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1661, average loss: 6.0157
[09/25 23:21:22 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 6.00	top5: 22.00	
[09/25 23:21:22 visual_prompt]: Best epoch 52: best metric: 0.060
[09/25 23:21:22 visual_prompt]: Training 53 / 100 epoch, with learning rate 13.80660579084567
[09/25 23:21:28 visual_prompt]: Epoch 53 / 100: avg data time: 4.62e-02, avg batch time: 0.4881, average train loss: 7.0327
[09/25 23:21:30 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1661, average loss: 6.3680
[09/25 23:21:30 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 3.50	top5: 15.00	
[09/25 23:21:30 visual_prompt]: Training 54 / 100 epoch, with learning rate 13.371955921801565
[09/25 23:21:36 visual_prompt]: Epoch 54 / 100: avg data time: 5.65e-02, avg batch time: 0.4990, average train loss: 7.1010
[09/25 23:21:38 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1662, average loss: 6.7774
[09/25 23:21:38 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 15.50	
[09/25 23:21:38 visual_prompt]: Training 55 / 100 epoch, with learning rate 12.936243708781264
[09/25 23:21:45 visual_prompt]: Epoch 55 / 100: avg data time: 5.96e-02, avg batch time: 0.5003, average train loss: 6.6695
[09/25 23:21:46 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1662, average loss: 6.5855
[09/25 23:21:46 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 4.00	top5: 13.00	
[09/25 23:21:46 visual_prompt]: Training 56 / 100 epoch, with learning rate 12.5
[09/25 23:21:53 visual_prompt]: Epoch 56 / 100: avg data time: 5.50e-02, avg batch time: 0.4967, average train loss: 6.6972
[09/25 23:21:54 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1661, average loss: 7.6282
[09/25 23:21:54 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 4.50	top5: 14.00	
[09/25 23:21:54 visual_prompt]: Training 57 / 100 epoch, with learning rate 12.063756291218741
[09/25 23:22:01 visual_prompt]: Epoch 57 / 100: avg data time: 5.86e-02, avg batch time: 0.4999, average train loss: 6.3536
[09/25 23:22:03 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1661, average loss: 6.3411
[09/25 23:22:03 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 4.00	top5: 18.50	
[09/25 23:22:03 visual_prompt]: Training 58 / 100 epoch, with learning rate 11.628044078198434
[09/25 23:22:09 visual_prompt]: Epoch 58 / 100: avg data time: 5.78e-02, avg batch time: 0.4994, average train loss: 6.3470
[09/25 23:22:11 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1662, average loss: 6.6924
[09/25 23:22:11 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 3.50	top5: 15.50	
[09/25 23:22:11 visual_prompt]: Training 59 / 100 epoch, with learning rate 11.193394209154334
[09/25 23:22:17 visual_prompt]: Epoch 59 / 100: avg data time: 5.54e-02, avg batch time: 0.4966, average train loss: 6.1188
[09/25 23:22:19 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1662, average loss: 6.5776
[09/25 23:22:19 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 3.50	top5: 12.00	
[09/25 23:22:19 visual_prompt]: Training 60 / 100 epoch, with learning rate 10.760336237999185
[09/25 23:22:26 visual_prompt]: Epoch 60 / 100: avg data time: 4.30e-02, avg batch time: 0.4850, average train loss: 5.9600
[09/25 23:22:27 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1662, average loss: 6.8039
[09/25 23:22:27 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 5.00	top5: 10.50	
[09/25 23:22:27 visual_prompt]: Training 61 / 100 epoch, with learning rate 10.32939777916337
[09/25 23:22:34 visual_prompt]: Epoch 61 / 100: avg data time: 5.42e-02, avg batch time: 0.4958, average train loss: 5.8345
[09/25 23:22:35 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1661, average loss: 7.1344
[09/25 23:22:35 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 11.50	
[09/25 23:22:35 visual_prompt]: Training 62 / 100 epoch, with learning rate 9.90110386477801
[09/25 23:22:42 visual_prompt]: Epoch 62 / 100: avg data time: 4.25e-02, avg batch time: 0.4851, average train loss: 5.9988
[09/25 23:22:43 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1662, average loss: 7.1421
[09/25 23:22:43 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 3.00	top5: 12.50	
[09/25 23:22:43 visual_prompt]: Training 63 / 100 epoch, with learning rate 9.475976305004155
[09/25 23:22:50 visual_prompt]: Epoch 63 / 100: avg data time: 5.61e-02, avg batch time: 0.4986, average train loss: 6.0324
[09/25 23:22:51 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1662, average loss: 6.4878
[09/25 23:22:51 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 6.00	top5: 17.00	
[09/25 23:22:51 visual_prompt]: Training 64 / 100 epoch, with learning rate 9.05453305228751
[09/25 23:22:58 visual_prompt]: Epoch 64 / 100: avg data time: 5.46e-02, avg batch time: 0.4957, average train loss: 5.6047
[09/25 23:23:00 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1661, average loss: 6.0014
[09/25 23:23:00 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 5.50	top5: 17.50	
[09/25 23:23:00 visual_prompt]: Training 65 / 100 epoch, with learning rate 8.637287570313159
[09/25 23:23:06 visual_prompt]: Epoch 65 / 100: avg data time: 4.38e-02, avg batch time: 0.4857, average train loss: 5.8139
[09/25 23:23:08 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1666, average loss: 6.5812
[09/25 23:23:08 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.50	top5: 14.00	
[09/25 23:23:08 visual_prompt]: Training 66 / 100 epoch, with learning rate 8.224748208429142
[09/25 23:23:14 visual_prompt]: Epoch 66 / 100: avg data time: 5.45e-02, avg batch time: 0.4972, average train loss: 5.6790
[09/25 23:23:16 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1660, average loss: 6.0010
[09/25 23:23:16 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 5.00	top5: 18.00	
[09/25 23:23:16 visual_prompt]: Training 67 / 100 epoch, with learning rate 7.817417582301099
[09/25 23:23:22 visual_prompt]: Epoch 67 / 100: avg data time: 5.45e-02, avg batch time: 0.4955, average train loss: 5.4113
[09/25 23:23:24 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1663, average loss: 6.4943
[09/25 23:23:24 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 3.50	top5: 12.50	
[09/25 23:23:24 visual_prompt]: Training 68 / 100 epoch, with learning rate 7.415791961552499
[09/25 23:23:30 visual_prompt]: Epoch 68 / 100: avg data time: 4.54e-02, avg batch time: 0.4865, average train loss: 5.6719
[09/25 23:23:32 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1663, average loss: 6.1195
[09/25 23:23:32 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 5.00	top5: 18.00	
[09/25 23:23:32 visual_prompt]: Training 69 / 100 epoch, with learning rate 7.020360665136531
[09/25 23:23:39 visual_prompt]: Epoch 69 / 100: avg data time: 4.32e-02, avg batch time: 0.4867, average train loss: 5.5927
[09/25 23:23:40 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1663, average loss: 5.6612
[09/25 23:23:40 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 7.00	top5: 21.50	
[09/25 23:23:40 visual_prompt]: Best epoch 69: best metric: 0.070
[09/25 23:23:40 visual_prompt]: Training 70 / 100 epoch, with learning rate 6.631605465176368
[09/25 23:23:47 visual_prompt]: Epoch 70 / 100: avg data time: 5.55e-02, avg batch time: 0.4971, average train loss: 5.2265
[09/25 23:23:48 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1662, average loss: 5.4119
[09/25 23:23:48 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 6.00	top5: 19.50	
[09/25 23:23:48 visual_prompt]: Training 71 / 100 epoch, with learning rate 6.250000000000003
[09/25 23:23:55 visual_prompt]: Epoch 71 / 100: avg data time: 5.03e-02, avg batch time: 0.4928, average train loss: 5.2701
[09/25 23:23:56 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1663, average loss: 5.5667
[09/25 23:23:56 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 4.50	top5: 18.50	
[09/25 23:23:56 visual_prompt]: Training 72 / 100 epoch, with learning rate 5.87600919708494
[09/25 23:24:03 visual_prompt]: Epoch 72 / 100: avg data time: 5.46e-02, avg batch time: 0.4955, average train loss: 5.2731
[09/25 23:24:04 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1661, average loss: 5.7773
[09/25 23:24:04 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 4.00	top5: 20.00	
[09/25 23:24:04 visual_prompt]: Training 73 / 100 epoch, with learning rate 5.510088706615666
[09/25 23:24:11 visual_prompt]: Epoch 73 / 100: avg data time: 4.10e-02, avg batch time: 0.4831, average train loss: 5.0603
[09/25 23:24:12 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1661, average loss: 5.9751
[09/25 23:24:12 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 5.00	top5: 15.50	
[09/25 23:24:12 visual_prompt]: Training 74 / 100 epoch, with learning rate 5.1526843463440875
[09/25 23:24:19 visual_prompt]: Epoch 74 / 100: avg data time: 5.83e-02, avg batch time: 0.5020, average train loss: 5.0081
[09/25 23:24:21 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1663, average loss: 5.3728
[09/25 23:24:21 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 4.00	top5: 21.50	
[09/25 23:24:21 visual_prompt]: Training 75 / 100 epoch, with learning rate 4.804231558429271
[09/25 23:24:27 visual_prompt]: Epoch 75 / 100: avg data time: 5.63e-02, avg batch time: 0.4986, average train loss: 4.7988
[09/25 23:24:29 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1672, average loss: 4.9399
[09/25 23:24:29 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 8.50	top5: 24.50	
[09/25 23:24:29 visual_prompt]: Best epoch 75: best metric: 0.085
[09/25 23:24:29 visual_prompt]: Training 76 / 100 epoch, with learning rate 4.465154878918258
[09/25 23:24:35 visual_prompt]: Epoch 76 / 100: avg data time: 3.99e-02, avg batch time: 0.4828, average train loss: 4.7980
[09/25 23:24:37 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1663, average loss: 5.4947
[09/25 23:24:37 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 4.50	top5: 14.50	
[09/25 23:24:37 visual_prompt]: Training 77 / 100 epoch, with learning rate 4.135867420514276
[09/25 23:24:43 visual_prompt]: Epoch 77 / 100: avg data time: 5.14e-02, avg batch time: 0.4936, average train loss: 4.8157
[09/25 23:24:45 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1661, average loss: 5.2608
[09/25 23:24:45 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 4.50	top5: 22.50	
[09/25 23:24:45 visual_prompt]: Training 78 / 100 epoch, with learning rate 3.816770369262533
[09/25 23:24:51 visual_prompt]: Epoch 78 / 100: avg data time: 4.14e-02, avg batch time: 0.4847, average train loss: 4.9262
[09/25 23:24:53 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1662, average loss: 5.4372
[09/25 23:24:53 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.50	top5: 21.00	
[09/25 23:24:53 visual_prompt]: Training 79 / 100 epoch, with learning rate 3.508252495766863
[09/25 23:24:59 visual_prompt]: Epoch 79 / 100: avg data time: 4.64e-02, avg batch time: 0.4888, average train loss: 4.8763
[09/25 23:25:01 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1664, average loss: 5.1620
[09/25 23:25:01 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 6.00	top5: 21.50	
[09/25 23:25:01 visual_prompt]: Training 80 / 100 epoch, with learning rate 3.2106896815325707
[09/25 23:25:08 visual_prompt]: Epoch 80 / 100: avg data time: 5.57e-02, avg batch time: 0.4972, average train loss: 4.7779
[09/25 23:25:09 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1662, average loss: 5.3598
[09/25 23:25:09 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 3.50	top5: 20.50	
[09/25 23:25:09 visual_prompt]: Training 81 / 100 epoch, with learning rate 2.924444461012776
[09/25 23:25:16 visual_prompt]: Epoch 81 / 100: avg data time: 5.34e-02, avg batch time: 0.4961, average train loss: 4.7015
[09/25 23:25:17 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1663, average loss: 5.4531
[09/25 23:25:17 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 3.50	top5: 18.00	
[09/25 23:25:17 visual_prompt]: Training 82 / 100 epoch, with learning rate 2.6498655799159763
[09/25 23:25:24 visual_prompt]: Epoch 82 / 100: avg data time: 5.82e-02, avg batch time: 0.4997, average train loss: 4.5700
[09/25 23:25:25 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1661, average loss: 5.2495
[09/25 23:25:25 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 6.00	top5: 20.00	
[09/25 23:25:25 visual_prompt]: Training 83 / 100 epoch, with learning rate 2.387287570313158
[09/25 23:25:32 visual_prompt]: Epoch 83 / 100: avg data time: 4.08e-02, avg batch time: 0.4842, average train loss: 4.6428
[09/25 23:25:33 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1662, average loss: 4.9138
[09/25 23:25:33 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 7.50	top5: 21.00	
[09/25 23:25:33 visual_prompt]: Training 84 / 100 epoch, with learning rate 2.13703034306198
[09/25 23:25:40 visual_prompt]: Epoch 84 / 100: avg data time: 5.24e-02, avg batch time: 0.4944, average train loss: 4.6452
[09/25 23:25:42 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1660, average loss: 5.3296
[09/25 23:25:42 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 4.50	top5: 19.50	
[09/25 23:25:42 visual_prompt]: Training 85 / 100 epoch, with learning rate 1.8993987980446756
[09/25 23:25:48 visual_prompt]: Epoch 85 / 100: avg data time: 5.02e-02, avg batch time: 0.4915, average train loss: 4.6004
[09/25 23:25:50 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1662, average loss: 5.1128
[09/25 23:25:50 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 7.50	top5: 20.50	
[09/25 23:25:50 visual_prompt]: Training 86 / 100 epoch, with learning rate 1.674682452694516
[09/25 23:25:56 visual_prompt]: Epoch 86 / 100: avg data time: 5.63e-02, avg batch time: 0.4975, average train loss: 4.6065
[09/25 23:25:58 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1661, average loss: 5.2362
[09/25 23:25:58 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 4.00	top5: 20.00	
[09/25 23:25:58 visual_prompt]: Training 87 / 100 epoch, with learning rate 1.4631550892634126
[09/25 23:26:05 visual_prompt]: Epoch 87 / 100: avg data time: 5.22e-02, avg batch time: 0.4951, average train loss: 4.4225
[09/25 23:26:06 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1659, average loss: 5.2361
[09/25 23:26:06 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 6.50	top5: 20.50	
[09/25 23:26:06 visual_prompt]: Training 88 / 100 epoch, with learning rate 1.2650744212604148
[09/25 23:26:13 visual_prompt]: Epoch 88 / 100: avg data time: 5.14e-02, avg batch time: 0.4936, average train loss: 4.4655
[09/25 23:26:14 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1662, average loss: 5.0441
[09/25 23:26:14 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 6.00	top5: 20.50	
[09/25 23:26:14 visual_prompt]: Training 89 / 100 epoch, with learning rate 1.0806817794674877
[09/25 23:26:21 visual_prompt]: Epoch 89 / 100: avg data time: 5.49e-02, avg batch time: 0.4969, average train loss: 4.5663
[09/25 23:26:22 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1659, average loss: 5.3301
[09/25 23:26:22 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 5.50	top5: 18.50	
[09/25 23:26:22 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.9102018179151585
[09/25 23:26:29 visual_prompt]: Epoch 90 / 100: avg data time: 5.24e-02, avg batch time: 0.4933, average train loss: 4.6159
[09/25 23:26:31 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1661, average loss: 5.0464
[09/25 23:26:31 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 7.00	top5: 21.50	
[09/25 23:26:31 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.753842240176146
[09/25 23:26:37 visual_prompt]: Epoch 91 / 100: avg data time: 5.52e-02, avg batch time: 0.4966, average train loss: 4.2964
[09/25 23:26:39 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1660, average loss: 5.1037
[09/25 23:26:39 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 6.00	top5: 21.00	
[09/25 23:26:39 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.6117935463105808
[09/25 23:26:45 visual_prompt]: Epoch 92 / 100: avg data time: 5.71e-02, avg batch time: 0.4978, average train loss: 4.2627
[09/25 23:26:47 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1662, average loss: 5.1829
[09/25 23:26:47 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 5.00	top5: 20.00	
[09/25 23:26:47 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.4842288007710138
[09/25 23:26:53 visual_prompt]: Epoch 93 / 100: avg data time: 4.42e-02, avg batch time: 0.4863, average train loss: 4.4342
[09/25 23:26:55 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1661, average loss: 5.1480
[09/25 23:26:55 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 6.50	top5: 22.00	
[09/25 23:26:55 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.3713034215500441
[09/25 23:27:02 visual_prompt]: Epoch 94 / 100: avg data time: 5.28e-02, avg batch time: 0.4948, average train loss: 4.4858
[09/25 23:27:03 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1662, average loss: 5.0525
[09/25 23:27:03 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 7.00	top5: 22.00	
[09/25 23:27:03 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.2731549908274289
[09/25 23:27:10 visual_prompt]: Epoch 95 / 100: avg data time: 5.38e-02, avg batch time: 0.4947, average train loss: 4.4210
[09/25 23:27:11 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1660, average loss: 5.0442
[09/25 23:27:11 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 7.00	top5: 22.00	
[09/25 23:27:11 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.18990308734739975
[09/25 23:27:18 visual_prompt]: Epoch 96 / 100: avg data time: 5.53e-02, avg batch time: 0.4976, average train loss: 4.3106
[09/25 23:27:19 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1659, average loss: 5.0799
[09/25 23:27:19 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 6.00	top5: 21.00	
[09/25 23:27:19 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.12164914073037048
[09/25 23:27:26 visual_prompt]: Epoch 97 / 100: avg data time: 5.18e-02, avg batch time: 0.4928, average train loss: 4.3973
[09/25 23:27:27 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1660, average loss: 5.0731
[09/25 23:27:27 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 6.50	top5: 21.50	
[09/25 23:27:27 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.06847630789658388
[09/25 23:27:34 visual_prompt]: Epoch 98 / 100: avg data time: 5.57e-02, avg batch time: 0.4969, average train loss: 4.4237
[09/25 23:27:36 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1661, average loss: 5.0682
[09/25 23:27:36 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 7.00	top5: 21.50	
[09/25 23:27:36 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.03044937175219753
[09/25 23:27:42 visual_prompt]: Epoch 99 / 100: avg data time: 5.71e-02, avg batch time: 0.4997, average train loss: 4.4230
[09/25 23:27:44 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1658, average loss: 5.0700
[09/25 23:27:44 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 7.00	top5: 21.50	
[09/25 23:27:44 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0076146622613029735
[09/25 23:27:50 visual_prompt]: Epoch 100 / 100: avg data time: 4.19e-02, avg batch time: 0.4840, average train loss: 4.2843
[09/25 23:27:52 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1662, average loss: 5.0707
[09/25 23:27:52 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 7.00	top5: 21.50	
[09/25 23:27:52 visual_prompt]: Rank of current process: 0. World size: 1
[09/25 23:27:52 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/25 23:27:52 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-cifar(num_classes=100)', 'DATA.NUMBER_CLASSES', '100', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/25 23:27:52 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/25 23:27:52 visual_prompt]: Training with config:
[09/25 23:27:52 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-cifar(num_classes=100)/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr10.0_wd0.01/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 10.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-cifar(num_classes=100)', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 100, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/25 23:27:52 visual_prompt]: Loading training data...
[09/25 23:27:52 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[:800], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/25 23:27:53 visual_prompt]: Number of images: 800
[09/25 23:27:53 visual_prompt]: Number of classes: 100 / 100
[09/25 23:27:53 visual_prompt]: Loading validation data...
[09/25 23:27:53 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[45000:45200], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/25 23:27:53 visual_prompt]: Number of images: 200
[09/25 23:27:53 visual_prompt]: Number of classes: 90 / 100
[09/25 23:27:53 visual_prompt]: Constructing models...
[09/25 23:27:56 visual_prompt]: Total Parameters: 86336356	 Gradient Parameters: 537700
[09/25 23:27:56 visual_prompt]: tuned percent:0.623
[09/25 23:27:56 visual_prompt]: Device used for model: 0
[09/25 23:27:56 visual_prompt]: Setting up Evaluator...
[09/25 23:27:56 visual_prompt]: Setting up Trainer...
[09/25 23:27:56 visual_prompt]: 	Setting up the optimizer...
[09/25 23:27:56 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/25 23:28:03 visual_prompt]: Epoch 1 / 100: avg data time: 6.13e-02, avg batch time: 0.5007, average train loss: 4.6537
[09/25 23:28:04 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1657, average loss: 4.6218
[09/25 23:28:04 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 7.00	
[09/25 23:28:04 visual_prompt]: Best epoch 1: best metric: 0.010
[09/25 23:28:04 visual_prompt]: Training 2 / 100 epoch, with learning rate 1.0
[09/25 23:28:11 visual_prompt]: Epoch 2 / 100: avg data time: 5.13e-02, avg batch time: 0.4913, average train loss: 4.6965
[09/25 23:28:12 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1658, average loss: 4.6630
[09/25 23:28:12 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.50	
[09/25 23:28:12 visual_prompt]: Best epoch 2: best metric: 0.015
[09/25 23:28:12 visual_prompt]: Training 3 / 100 epoch, with learning rate 2.0
[09/25 23:28:19 visual_prompt]: Epoch 3 / 100: avg data time: 5.63e-02, avg batch time: 0.4988, average train loss: 4.7038
[09/25 23:28:21 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1662, average loss: 4.6959
[09/25 23:28:21 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/25 23:28:21 visual_prompt]: Training 4 / 100 epoch, with learning rate 3.0
[09/25 23:28:27 visual_prompt]: Epoch 4 / 100: avg data time: 5.24e-02, avg batch time: 0.4919, average train loss: 4.7234
[09/25 23:28:29 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1654, average loss: 4.7380
[09/25 23:28:29 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 4.00	
[09/25 23:28:29 visual_prompt]: Training 5 / 100 epoch, with learning rate 4.0
[09/25 23:28:35 visual_prompt]: Epoch 5 / 100: avg data time: 5.34e-02, avg batch time: 0.4930, average train loss: 4.8105
[09/25 23:28:37 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1662, average loss: 4.8178
[09/25 23:28:37 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 7.00	
[09/25 23:28:37 visual_prompt]: Training 6 / 100 epoch, with learning rate 5.0
[09/25 23:28:44 visual_prompt]: Epoch 6 / 100: avg data time: 4.89e-02, avg batch time: 0.4918, average train loss: 4.8304
[09/25 23:28:45 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1659, average loss: 5.3070
[09/25 23:28:45 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 3.50	
[09/25 23:28:45 visual_prompt]: Training 7 / 100 epoch, with learning rate 6.0
[09/25 23:28:52 visual_prompt]: Epoch 7 / 100: avg data time: 5.29e-02, avg batch time: 0.4932, average train loss: 6.4275
[09/25 23:28:53 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1661, average loss: 8.7575
[09/25 23:28:53 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 3.00	
[09/25 23:28:53 visual_prompt]: Training 8 / 100 epoch, with learning rate 7.0
[09/25 23:29:00 visual_prompt]: Epoch 8 / 100: avg data time: 6.01e-02, avg batch time: 0.5003, average train loss: 6.4725
[09/25 23:29:01 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1661, average loss: 6.4169
[09/25 23:29:01 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 5.50	
[09/25 23:29:01 visual_prompt]: Training 9 / 100 epoch, with learning rate 8.0
[09/25 23:29:08 visual_prompt]: Epoch 9 / 100: avg data time: 4.75e-02, avg batch time: 0.4886, average train loss: 6.7768
[09/25 23:29:10 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1661, average loss: 7.4293
[09/25 23:29:10 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/25 23:29:10 visual_prompt]: Training 10 / 100 epoch, with learning rate 9.0
[09/25 23:29:16 visual_prompt]: Epoch 10 / 100: avg data time: 5.31e-02, avg batch time: 0.4943, average train loss: 7.9541
[09/25 23:29:18 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1663, average loss: 7.6316
[09/25 23:29:18 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 5.00	
[09/25 23:29:18 visual_prompt]: Training 11 / 100 epoch, with learning rate 10.0
[09/25 23:29:24 visual_prompt]: Epoch 11 / 100: avg data time: 4.22e-02, avg batch time: 0.4851, average train loss: 8.4960
[09/25 23:29:26 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1662, average loss: 7.2793
[09/25 23:29:26 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.50	
[09/25 23:29:26 visual_prompt]: Training 12 / 100 epoch, with learning rate 9.996954135095478
[09/25 23:29:33 visual_prompt]: Epoch 12 / 100: avg data time: 6.04e-02, avg batch time: 0.5020, average train loss: 11.5448
[09/25 23:29:34 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1663, average loss: 11.5868
[09/25 23:29:34 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 6.00	
[09/25 23:29:34 visual_prompt]: Training 13 / 100 epoch, with learning rate 9.987820251299121
[09/25 23:29:41 visual_prompt]: Epoch 13 / 100: avg data time: 5.52e-02, avg batch time: 0.4966, average train loss: 12.6981
[09/25 23:29:42 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1662, average loss: 9.9863
[09/25 23:29:42 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 4.50	
[09/25 23:29:42 visual_prompt]: Training 14 / 100 epoch, with learning rate 9.972609476841367
[09/25 23:29:49 visual_prompt]: Epoch 14 / 100: avg data time: 5.18e-02, avg batch time: 0.4939, average train loss: 15.5172
[09/25 23:29:50 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1661, average loss: 10.3821
[09/25 23:29:50 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 3.50	
[09/25 23:29:50 visual_prompt]: Training 15 / 100 epoch, with learning rate 9.951340343707852
[09/25 23:29:57 visual_prompt]: Epoch 15 / 100: avg data time: 5.37e-02, avg batch time: 0.4957, average train loss: 14.3732
[09/25 23:29:59 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1663, average loss: 10.2278
[09/25 23:29:59 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.00	
[09/25 23:29:59 visual_prompt]: Training 16 / 100 epoch, with learning rate 9.924038765061042
[09/25 23:30:06 visual_prompt]: Epoch 16 / 100: avg data time: 6.19e-02, avg batch time: 0.5027, average train loss: 13.9156
[09/25 23:30:07 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1663, average loss: 9.6179
[09/25 23:30:07 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 8.00	
[09/25 23:30:07 visual_prompt]: Training 17 / 100 epoch, with learning rate 9.890738003669028
[09/25 23:30:14 visual_prompt]: Epoch 17 / 100: avg data time: 5.15e-02, avg batch time: 0.4930, average train loss: 13.6301
[09/25 23:30:15 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1664, average loss: 10.1517
[09/25 23:30:15 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.50	
[09/25 23:30:15 visual_prompt]: Training 18 / 100 epoch, with learning rate 9.851478631379981
[09/25 23:30:22 visual_prompt]: Epoch 18 / 100: avg data time: 5.91e-02, avg batch time: 0.5013, average train loss: 13.5096
[09/25 23:30:23 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1663, average loss: 8.5702
[09/25 23:30:23 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 4.50	
[09/25 23:30:23 visual_prompt]: Training 19 / 100 epoch, with learning rate 9.806308479691594
[09/25 23:30:30 visual_prompt]: Epoch 19 / 100: avg data time: 5.68e-02, avg batch time: 0.4986, average train loss: 12.5608
[09/25 23:30:32 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1659, average loss: 8.8015
[09/25 23:30:32 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 6.50	
[09/25 23:30:32 visual_prompt]: Best epoch 19: best metric: 0.020
[09/25 23:30:32 visual_prompt]: Training 20 / 100 epoch, with learning rate 9.755282581475768
[09/25 23:30:38 visual_prompt]: Epoch 20 / 100: avg data time: 5.81e-02, avg batch time: 0.4989, average train loss: 10.9831
[09/25 23:30:40 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1664, average loss: 7.2702
[09/25 23:30:40 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 4.50	
[09/25 23:30:40 visual_prompt]: Training 21 / 100 epoch, with learning rate 9.698463103929543
[09/25 23:30:46 visual_prompt]: Epoch 21 / 100: avg data time: 4.66e-02, avg batch time: 0.4875, average train loss: 12.9364
[09/25 23:30:48 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1661, average loss: 7.7441
[09/25 23:30:48 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.00	
[09/25 23:30:48 visual_prompt]: Training 22 / 100 epoch, with learning rate 9.635919272833938
[09/25 23:30:54 visual_prompt]: Epoch 22 / 100: avg data time: 4.68e-02, avg batch time: 0.4887, average train loss: 9.5325
[09/25 23:30:56 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1666, average loss: 8.5201
[09/25 23:30:56 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 2.50	
[09/25 23:30:56 visual_prompt]: Training 23 / 100 epoch, with learning rate 9.567727288213003
[09/25 23:31:03 visual_prompt]: Epoch 23 / 100: avg data time: 5.18e-02, avg batch time: 0.4951, average train loss: 11.2426
[09/25 23:31:04 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1666, average loss: 7.7106
[09/25 23:31:04 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.00	
[09/25 23:31:04 visual_prompt]: Training 24 / 100 epoch, with learning rate 9.493970231495835
[09/25 23:31:11 visual_prompt]: Epoch 24 / 100: avg data time: 5.51e-02, avg batch time: 0.4975, average train loss: 10.1372
[09/25 23:31:12 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1664, average loss: 10.0643
[09/25 23:31:12 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 5.00	
[09/25 23:31:12 visual_prompt]: Training 25 / 100 epoch, with learning rate 9.414737964294634
[09/25 23:31:19 visual_prompt]: Epoch 25 / 100: avg data time: 4.11e-02, avg batch time: 0.4849, average train loss: 11.8930
[09/25 23:31:20 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1664, average loss: 9.6536
[09/25 23:31:20 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.50	
[09/25 23:31:20 visual_prompt]: Training 26 / 100 epoch, with learning rate 9.330127018922195
[09/25 23:31:27 visual_prompt]: Epoch 26 / 100: avg data time: 5.67e-02, avg batch time: 0.4992, average train loss: 10.1622
[09/25 23:31:29 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1662, average loss: 7.9900
[09/25 23:31:29 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 4.50	
[09/25 23:31:29 visual_prompt]: Training 27 / 100 epoch, with learning rate 9.240240480782129
[09/25 23:31:35 visual_prompt]: Epoch 27 / 100: avg data time: 4.58e-02, avg batch time: 0.4878, average train loss: 14.8337
[09/25 23:31:37 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1666, average loss: 13.2243
[09/25 23:31:37 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 5.00	
[09/25 23:31:37 visual_prompt]: Training 28 / 100 epoch, with learning rate 9.145187862775208
[09/25 23:31:43 visual_prompt]: Epoch 28 / 100: avg data time: 5.40e-02, avg batch time: 0.4958, average train loss: 13.0238
[09/25 23:31:45 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1664, average loss: 13.4320
[09/25 23:31:45 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.00	
[09/25 23:31:45 visual_prompt]: Training 29 / 100 epoch, with learning rate 9.045084971874736
[09/25 23:31:52 visual_prompt]: Epoch 29 / 100: avg data time: 4.91e-02, avg batch time: 0.4922, average train loss: 13.5058
[09/25 23:31:53 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1664, average loss: 11.0729
[09/25 23:31:53 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 6.00	
[09/25 23:31:53 visual_prompt]: Training 30 / 100 epoch, with learning rate 8.940053768033609
[09/25 23:32:00 visual_prompt]: Epoch 30 / 100: avg data time: 5.20e-02, avg batch time: 0.4933, average train loss: 15.0497
[09/25 23:32:01 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1667, average loss: 11.8389
[09/25 23:32:01 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.50	
[09/25 23:32:01 visual_prompt]: Training 31 / 100 epoch, with learning rate 8.83022221559489
[09/25 23:32:08 visual_prompt]: Epoch 31 / 100: avg data time: 5.49e-02, avg batch time: 0.4981, average train loss: 12.0070
[09/25 23:32:09 visual_prompt]: Inference (val):avg data time: 2.11e-05, avg batch time: 0.1662, average loss: 10.6093
[09/25 23:32:09 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 7.00	
[09/25 23:32:09 visual_prompt]: Training 32 / 100 epoch, with learning rate 8.715724127386972
[09/25 23:32:16 visual_prompt]: Epoch 32 / 100: avg data time: 5.15e-02, avg batch time: 0.4928, average train loss: 11.7916
[09/25 23:32:18 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1663, average loss: 10.0685
[09/25 23:32:18 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 6.00	
[09/25 23:32:18 visual_prompt]: Training 33 / 100 epoch, with learning rate 8.596699001693256
[09/25 23:32:24 visual_prompt]: Epoch 33 / 100: avg data time: 5.43e-02, avg batch time: 0.4975, average train loss: 12.4040
[09/25 23:32:26 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1665, average loss: 10.1395
[09/25 23:32:26 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 3.50	
[09/25 23:32:26 visual_prompt]: Training 34 / 100 epoch, with learning rate 8.473291852294986
[09/25 23:32:33 visual_prompt]: Epoch 34 / 100: avg data time: 5.60e-02, avg batch time: 0.4982, average train loss: 14.6212
[09/25 23:32:34 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1664, average loss: 10.5906
[09/25 23:32:34 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 5.50	
[09/25 23:32:34 visual_prompt]: Training 35 / 100 epoch, with learning rate 8.345653031794292
[09/25 23:32:41 visual_prompt]: Epoch 35 / 100: avg data time: 5.84e-02, avg batch time: 0.4993, average train loss: 14.5981
[09/25 23:32:42 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1664, average loss: 11.8615
[09/25 23:32:42 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 4.50	
[09/25 23:32:42 visual_prompt]: Training 36 / 100 epoch, with learning rate 8.213938048432697
[09/25 23:32:49 visual_prompt]: Epoch 36 / 100: avg data time: 4.94e-02, avg batch time: 0.4923, average train loss: 13.2263
[09/25 23:32:50 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1665, average loss: 10.6785
[09/25 23:32:50 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.00	
[09/25 23:32:50 visual_prompt]: Training 37 / 100 epoch, with learning rate 8.078307376628292
[09/25 23:32:57 visual_prompt]: Epoch 37 / 100: avg data time: 5.66e-02, avg batch time: 0.4994, average train loss: 14.1496
[09/25 23:32:59 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1665, average loss: 10.9795
[09/25 23:32:59 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 4.50	
[09/25 23:32:59 visual_prompt]: Training 38 / 100 epoch, with learning rate 7.938926261462366
[09/25 23:33:05 visual_prompt]: Epoch 38 / 100: avg data time: 5.28e-02, avg batch time: 0.4941, average train loss: 11.9700
[09/25 23:33:07 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1663, average loss: 10.6078
[09/25 23:33:07 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.00	
[09/25 23:33:07 visual_prompt]: Training 39 / 100 epoch, with learning rate 7.795964517353734
[09/25 23:33:14 visual_prompt]: Epoch 39 / 100: avg data time: 5.83e-02, avg batch time: 0.4999, average train loss: 12.6301
[09/25 23:33:15 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1663, average loss: 11.7168
[09/25 23:33:15 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.00	
[09/25 23:33:15 visual_prompt]: Training 40 / 100 epoch, with learning rate 7.649596321166024
[09/25 23:33:22 visual_prompt]: Epoch 40 / 100: avg data time: 5.56e-02, avg batch time: 0.4965, average train loss: 10.8838
[09/25 23:33:23 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1661, average loss: 7.7316
[09/25 23:33:23 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.50	
[09/25 23:33:23 visual_prompt]: Training 41 / 100 epoch, with learning rate 7.5
[09/25 23:33:30 visual_prompt]: Epoch 41 / 100: avg data time: 5.62e-02, avg batch time: 0.4978, average train loss: 8.9553
[09/25 23:33:31 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1664, average loss: 7.5968
[09/25 23:33:31 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.00	
[09/25 23:33:31 visual_prompt]: Training 42 / 100 epoch, with learning rate 7.347357813929454
[09/25 23:33:38 visual_prompt]: Epoch 42 / 100: avg data time: 5.70e-02, avg batch time: 0.4990, average train loss: 8.0348
[09/25 23:33:40 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1662, average loss: 6.3333
[09/25 23:33:40 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.00	
[09/25 23:33:40 visual_prompt]: Training 43 / 100 epoch, with learning rate 7.191855733945387
[09/25 23:33:46 visual_prompt]: Epoch 43 / 100: avg data time: 4.63e-02, avg batch time: 0.4882, average train loss: 7.0796
[09/25 23:33:48 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1664, average loss: 6.4174
[09/25 23:33:48 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 3.50	
[09/25 23:33:48 visual_prompt]: Training 44 / 100 epoch, with learning rate 7.033683215379002
[09/25 23:33:54 visual_prompt]: Epoch 44 / 100: avg data time: 5.38e-02, avg batch time: 0.4965, average train loss: 7.0211
[09/25 23:33:56 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1663, average loss: 6.3431
[09/25 23:33:56 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 6.00	
[09/25 23:33:56 visual_prompt]: Training 45 / 100 epoch, with learning rate 6.873032967079561
[09/25 23:34:03 visual_prompt]: Epoch 45 / 100: avg data time: 4.80e-02, avg batch time: 0.4909, average train loss: 7.6939
[09/25 23:34:04 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1666, average loss: 5.8947
[09/25 23:34:04 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.00	
[09/25 23:34:04 visual_prompt]: Training 46 / 100 epoch, with learning rate 6.710100716628345
[09/25 23:34:11 visual_prompt]: Epoch 46 / 100: avg data time: 5.68e-02, avg batch time: 0.4994, average train loss: 7.7714
[09/25 23:34:12 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1663, average loss: 7.5006
[09/25 23:34:12 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.00	
[09/25 23:34:12 visual_prompt]: Training 47 / 100 epoch, with learning rate 6.545084971874737
[09/25 23:34:19 visual_prompt]: Epoch 47 / 100: avg data time: 4.47e-02, avg batch time: 0.4883, average train loss: 7.2284
[09/25 23:34:20 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1662, average loss: 7.0422
[09/25 23:34:20 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/25 23:34:20 visual_prompt]: Training 48 / 100 epoch, with learning rate 6.378186779084995
[09/25 23:34:27 visual_prompt]: Epoch 48 / 100: avg data time: 4.58e-02, avg batch time: 0.4883, average train loss: 7.7264
[09/25 23:34:28 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1665, average loss: 9.2405
[09/25 23:34:28 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 6.00	
[09/25 23:34:28 visual_prompt]: Training 49 / 100 epoch, with learning rate 6.209609477998338
[09/25 23:34:35 visual_prompt]: Epoch 49 / 100: avg data time: 5.26e-02, avg batch time: 0.4947, average train loss: 8.8607
[09/25 23:34:37 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1659, average loss: 6.5871
[09/25 23:34:37 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 7.50	
[09/25 23:34:37 visual_prompt]: Training 50 / 100 epoch, with learning rate 6.039558454088796
[09/25 23:34:43 visual_prompt]: Epoch 50 / 100: avg data time: 4.53e-02, avg batch time: 0.4882, average train loss: 7.5303
[09/25 23:34:45 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1665, average loss: 6.6337
[09/25 23:34:45 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.00	
[09/25 23:34:45 visual_prompt]: Training 51 / 100 epoch, with learning rate 5.868240888334652
[09/25 23:34:51 visual_prompt]: Epoch 51 / 100: avg data time: 5.30e-02, avg batch time: 0.4947, average train loss: 8.6635
[09/25 23:34:53 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1666, average loss: 6.5155
[09/25 23:34:53 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 3.00	
[09/25 23:34:53 visual_prompt]: Training 52 / 100 epoch, with learning rate 5.695865504800327
[09/25 23:35:00 visual_prompt]: Epoch 52 / 100: avg data time: 5.62e-02, avg batch time: 0.4976, average train loss: 7.1447
[09/25 23:35:01 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1665, average loss: 6.1567
[09/25 23:35:01 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.00	
[09/25 23:35:01 visual_prompt]: Training 53 / 100 epoch, with learning rate 5.522642316338268
[09/25 23:35:08 visual_prompt]: Epoch 53 / 100: avg data time: 5.26e-02, avg batch time: 0.4938, average train loss: 6.4408
[09/25 23:35:09 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1662, average loss: 5.5552
[09/25 23:35:09 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.00	
[09/25 23:35:09 visual_prompt]: Training 54 / 100 epoch, with learning rate 5.3487823687206255
[09/25 23:35:16 visual_prompt]: Epoch 54 / 100: avg data time: 5.89e-02, avg batch time: 0.5002, average train loss: 6.1282
[09/25 23:35:18 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.1665, average loss: 5.3746
[09/25 23:35:18 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 3.50	
[09/25 23:35:18 visual_prompt]: Training 55 / 100 epoch, with learning rate 5.174497483512505
[09/25 23:35:24 visual_prompt]: Epoch 55 / 100: avg data time: 5.24e-02, avg batch time: 0.4943, average train loss: 5.9706
[09/25 23:35:26 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1663, average loss: 5.7954
[09/25 23:35:26 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.00	
[09/25 23:35:26 visual_prompt]: Training 56 / 100 epoch, with learning rate 5.0
[09/25 23:35:32 visual_prompt]: Epoch 56 / 100: avg data time: 4.55e-02, avg batch time: 0.4888, average train loss: 5.5969
[09/25 23:35:34 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1660, average loss: 5.4362
[09/25 23:35:34 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.50	
[09/25 23:35:34 visual_prompt]: Training 57 / 100 epoch, with learning rate 4.8255025164874965
[09/25 23:35:41 visual_prompt]: Epoch 57 / 100: avg data time: 5.38e-02, avg batch time: 0.4944, average train loss: 5.4989
[09/25 23:35:42 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1666, average loss: 5.2056
[09/25 23:35:42 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 6.00	
[09/25 23:35:42 visual_prompt]: Training 58 / 100 epoch, with learning rate 4.651217631279374
[09/25 23:35:49 visual_prompt]: Epoch 58 / 100: avg data time: 5.88e-02, avg batch time: 0.5006, average train loss: 5.3864
[09/25 23:35:50 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1664, average loss: 5.1941
[09/25 23:35:50 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 4.50	
[09/25 23:35:50 visual_prompt]: Training 59 / 100 epoch, with learning rate 4.477357683661733
[09/25 23:35:57 visual_prompt]: Epoch 59 / 100: avg data time: 4.86e-02, avg batch time: 0.4917, average train loss: 5.1625
[09/25 23:35:59 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1661, average loss: 4.9931
[09/25 23:35:59 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 4.00	
[09/25 23:35:59 visual_prompt]: Training 60 / 100 epoch, with learning rate 4.3041344951996745
[09/25 23:36:05 visual_prompt]: Epoch 60 / 100: avg data time: 5.77e-02, avg batch time: 0.4999, average train loss: 4.9500
[09/25 23:36:07 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1662, average loss: 5.0022
[09/25 23:36:07 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.50	
[09/25 23:36:07 visual_prompt]: Training 61 / 100 epoch, with learning rate 4.131759111665349
[09/25 23:36:14 visual_prompt]: Epoch 61 / 100: avg data time: 5.58e-02, avg batch time: 0.4986, average train loss: 5.0317
[09/25 23:36:15 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.1664, average loss: 6.5796
[09/25 23:36:15 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 7.00	
[09/25 23:36:15 visual_prompt]: Training 62 / 100 epoch, with learning rate 3.960441545911204
[09/25 23:36:22 visual_prompt]: Epoch 62 / 100: avg data time: 4.80e-02, avg batch time: 0.4900, average train loss: 6.5168
[09/25 23:36:23 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1664, average loss: 5.8236
[09/25 23:36:23 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 4.00	
[09/25 23:36:23 visual_prompt]: Training 63 / 100 epoch, with learning rate 3.790390522001662
[09/25 23:36:30 visual_prompt]: Epoch 63 / 100: avg data time: 6.02e-02, avg batch time: 0.5025, average train loss: 6.8907
[09/25 23:36:32 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1664, average loss: 6.0790
[09/25 23:36:32 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.00	
[09/25 23:36:32 visual_prompt]: Training 64 / 100 epoch, with learning rate 3.6218132209150045
[09/25 23:36:38 visual_prompt]: Epoch 64 / 100: avg data time: 6.03e-02, avg batch time: 0.5015, average train loss: 6.4322
[09/25 23:36:40 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1662, average loss: 6.4617
[09/25 23:36:40 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.00	
[09/25 23:36:40 visual_prompt]: Training 65 / 100 epoch, with learning rate 3.454915028125263
[09/25 23:36:46 visual_prompt]: Epoch 65 / 100: avg data time: 4.65e-02, avg batch time: 0.4877, average train loss: 6.1953
[09/25 23:36:48 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1663, average loss: 6.3419
[09/25 23:36:48 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.00	top5: 6.00	
[09/25 23:36:48 visual_prompt]: Training 66 / 100 epoch, with learning rate 3.289899283371657
[09/25 23:36:55 visual_prompt]: Epoch 66 / 100: avg data time: 5.65e-02, avg batch time: 0.4980, average train loss: 6.0558
[09/25 23:36:56 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1660, average loss: 6.3017
[09/25 23:36:56 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 6.50	
[09/25 23:36:56 visual_prompt]: Training 67 / 100 epoch, with learning rate 3.1269670329204398
[09/25 23:37:03 visual_prompt]: Epoch 67 / 100: avg data time: 5.98e-02, avg batch time: 0.5002, average train loss: 6.0092
[09/25 23:37:04 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1663, average loss: 5.9716
[09/25 23:37:04 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.00	top5: 3.50	
[09/25 23:37:04 visual_prompt]: Training 68 / 100 epoch, with learning rate 2.9663167846209997
[09/25 23:37:11 visual_prompt]: Epoch 68 / 100: avg data time: 6.09e-02, avg batch time: 0.5023, average train loss: 5.8797
[09/25 23:37:12 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1662, average loss: 5.8126
[09/25 23:37:12 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 4.50	
[09/25 23:37:12 visual_prompt]: Training 69 / 100 epoch, with learning rate 2.8081442660546125
[09/25 23:37:19 visual_prompt]: Epoch 69 / 100: avg data time: 4.66e-02, avg batch time: 0.4906, average train loss: 5.6920
[09/25 23:37:21 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1664, average loss: 5.8910
[09/25 23:37:21 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.00	
[09/25 23:37:21 visual_prompt]: Training 70 / 100 epoch, with learning rate 2.6526421860705476
[09/25 23:37:27 visual_prompt]: Epoch 70 / 100: avg data time: 5.54e-02, avg batch time: 0.4962, average train loss: 5.6942
[09/25 23:37:29 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1661, average loss: 5.7295
[09/25 23:37:29 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 4.00	
[09/25 23:37:29 visual_prompt]: Training 71 / 100 epoch, with learning rate 2.500000000000001
[09/25 23:37:36 visual_prompt]: Epoch 71 / 100: avg data time: 5.62e-02, avg batch time: 0.4973, average train loss: 5.5924
[09/25 23:37:37 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1662, average loss: 5.5751
[09/25 23:37:37 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.00	
[09/25 23:37:37 visual_prompt]: Training 72 / 100 epoch, with learning rate 2.350403678833976
[09/25 23:37:44 visual_prompt]: Epoch 72 / 100: avg data time: 4.59e-02, avg batch time: 0.4883, average train loss: 5.4704
[09/25 23:37:45 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1666, average loss: 5.5366
[09/25 23:37:45 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.50	
[09/25 23:37:45 visual_prompt]: Training 73 / 100 epoch, with learning rate 2.2040354826462667
[09/25 23:37:52 visual_prompt]: Epoch 73 / 100: avg data time: 5.55e-02, avg batch time: 0.4995, average train loss: 5.4819
[09/25 23:37:53 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1666, average loss: 5.4240
[09/25 23:37:53 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.00	top5: 5.00	
[09/25 23:37:53 visual_prompt]: Training 74 / 100 epoch, with learning rate 2.061073738537635
[09/25 23:38:00 visual_prompt]: Epoch 74 / 100: avg data time: 5.04e-02, avg batch time: 0.4923, average train loss: 5.3858
[09/25 23:38:02 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1666, average loss: 5.4177
[09/25 23:38:02 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 5.50	
[09/25 23:38:02 visual_prompt]: Training 75 / 100 epoch, with learning rate 1.9216926233717087
[09/25 23:38:08 visual_prompt]: Epoch 75 / 100: avg data time: 4.26e-02, avg batch time: 0.4858, average train loss: 5.3187
[09/25 23:38:10 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1665, average loss: 5.3247
[09/25 23:38:10 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.50	
[09/25 23:38:10 visual_prompt]: Training 76 / 100 epoch, with learning rate 1.7860619515673033
[09/25 23:38:16 visual_prompt]: Epoch 76 / 100: avg data time: 5.86e-02, avg batch time: 0.5003, average train loss: 5.2390
[09/25 23:38:18 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1666, average loss: 5.4335
[09/25 23:38:18 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 7.00	
[09/25 23:38:18 visual_prompt]: Training 77 / 100 epoch, with learning rate 1.6543469682057106
[09/25 23:38:25 visual_prompt]: Epoch 77 / 100: avg data time: 6.50e-02, avg batch time: 0.5057, average train loss: 5.2871
[09/25 23:38:26 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1663, average loss: 5.2532
[09/25 23:38:26 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 4.50	
[09/25 23:38:26 visual_prompt]: Training 78 / 100 epoch, with learning rate 1.5267081477050133
[09/25 23:38:33 visual_prompt]: Epoch 78 / 100: avg data time: 5.59e-02, avg batch time: 0.4983, average train loss: 5.1861
[09/25 23:38:34 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.1663, average loss: 5.1708
[09/25 23:38:34 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 4.50	
[09/25 23:38:34 visual_prompt]: Training 79 / 100 epoch, with learning rate 1.403300998306745
[09/25 23:38:41 visual_prompt]: Epoch 79 / 100: avg data time: 4.68e-02, avg batch time: 0.4901, average train loss: 5.1363
[09/25 23:38:43 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1665, average loss: 5.1190
[09/25 23:38:43 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 6.50	
[09/25 23:38:43 visual_prompt]: Training 80 / 100 epoch, with learning rate 1.2842758726130281
[09/25 23:38:49 visual_prompt]: Epoch 80 / 100: avg data time: 5.31e-02, avg batch time: 0.4950, average train loss: 5.0998
[09/25 23:38:51 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1664, average loss: 5.1203
[09/25 23:38:51 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.50	
[09/25 23:38:51 visual_prompt]: Training 81 / 100 epoch, with learning rate 1.1697777844051105
[09/25 23:38:57 visual_prompt]: Epoch 81 / 100: avg data time: 5.35e-02, avg batch time: 0.4950, average train loss: 5.0410
[09/25 23:38:59 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1665, average loss: 5.0922
[09/25 23:38:59 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.50	
[09/25 23:38:59 visual_prompt]: Training 82 / 100 epoch, with learning rate 1.0599462319663906
[09/25 23:39:06 visual_prompt]: Epoch 82 / 100: avg data time: 4.65e-02, avg batch time: 0.4886, average train loss: 5.0232
[09/25 23:39:07 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1665, average loss: 5.0594
[09/25 23:39:07 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.00	
[09/25 23:39:07 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.9549150281252633
[09/25 23:39:14 visual_prompt]: Epoch 83 / 100: avg data time: 4.54e-02, avg batch time: 0.4891, average train loss: 4.9494
[09/25 23:39:15 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1665, average loss: 4.9766
[09/25 23:39:15 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.50	
[09/25 23:39:15 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.8548121372247919
[09/25 23:39:22 visual_prompt]: Epoch 84 / 100: avg data time: 5.53e-02, avg batch time: 0.4977, average train loss: 4.9274
[09/25 23:39:23 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1667, average loss: 4.9416
[09/25 23:39:23 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.50	
[09/25 23:39:23 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.7597595192178702
[09/25 23:39:30 visual_prompt]: Epoch 85 / 100: avg data time: 5.26e-02, avg batch time: 0.4947, average train loss: 4.8795
[09/25 23:39:31 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1662, average loss: 5.0424
[09/25 23:39:31 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 3.00	
[09/25 23:39:31 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.6698729810778065
[09/25 23:39:38 visual_prompt]: Epoch 86 / 100: avg data time: 4.15e-02, avg batch time: 0.4843, average train loss: 4.8987
[09/25 23:39:40 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1668, average loss: 4.9422
[09/25 23:39:40 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 5.50	
[09/25 23:39:40 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.5852620357053651
[09/25 23:39:46 visual_prompt]: Epoch 87 / 100: avg data time: 5.45e-02, avg batch time: 0.4977, average train loss: 4.8786
[09/25 23:39:48 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1666, average loss: 4.9385
[09/25 23:39:48 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 6.00	
[09/25 23:39:48 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.5060297685041659
[09/25 23:39:54 visual_prompt]: Epoch 88 / 100: avg data time: 5.50e-02, avg batch time: 0.4981, average train loss: 4.8438
[09/25 23:39:56 visual_prompt]: Inference (val):avg data time: 3.60e-05, avg batch time: 0.1663, average loss: 4.8941
[09/25 23:39:56 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.00	
[09/25 23:39:56 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.4322727117869951
[09/25 23:40:03 visual_prompt]: Epoch 89 / 100: avg data time: 5.13e-02, avg batch time: 0.4941, average train loss: 4.8217
[09/25 23:40:04 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1664, average loss: 4.8866
[09/25 23:40:04 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.00	
[09/25 23:40:04 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.36408072716606343
[09/25 23:40:11 visual_prompt]: Epoch 90 / 100: avg data time: 4.33e-02, avg batch time: 0.4870, average train loss: 4.7954
[09/25 23:40:12 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1664, average loss: 4.8662
[09/25 23:40:12 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 6.00	
[09/25 23:40:12 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.3015368960704584
[09/25 23:40:19 visual_prompt]: Epoch 91 / 100: avg data time: 5.51e-02, avg batch time: 0.4979, average train loss: 4.7782
[09/25 23:40:21 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1663, average loss: 4.8318
[09/25 23:40:21 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.00	
[09/25 23:40:21 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.24471741852423234
[09/25 23:40:27 visual_prompt]: Epoch 92 / 100: avg data time: 5.97e-02, avg batch time: 0.5027, average train loss: 4.7599
[09/25 23:40:29 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1662, average loss: 4.8153
[09/25 23:40:29 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/25 23:40:29 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.19369152030840553
[09/25 23:40:36 visual_prompt]: Epoch 93 / 100: avg data time: 5.73e-02, avg batch time: 0.4999, average train loss: 4.7354
[09/25 23:40:37 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1665, average loss: 4.7741
[09/25 23:40:37 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 6.00	
[09/25 23:40:37 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.14852136862001764
[09/25 23:40:44 visual_prompt]: Epoch 94 / 100: avg data time: 5.57e-02, avg batch time: 0.4974, average train loss: 4.7312
[09/25 23:40:45 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1664, average loss: 4.8707
[09/25 23:40:45 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/25 23:40:45 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.10926199633097156
[09/25 23:40:52 visual_prompt]: Epoch 95 / 100: avg data time: 6.41e-02, avg batch time: 0.5055, average train loss: 4.7404
[09/25 23:40:54 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1665, average loss: 4.7820
[09/25 23:40:54 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.00	
[09/25 23:40:54 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.0759612349389599
[09/25 23:41:00 visual_prompt]: Epoch 96 / 100: avg data time: 4.33e-02, avg batch time: 0.4856, average train loss: 4.6892
[09/25 23:41:02 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1664, average loss: 4.7522
[09/25 23:41:02 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/25 23:41:02 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.04865965629214819
[09/25 23:41:09 visual_prompt]: Epoch 97 / 100: avg data time: 5.04e-02, avg batch time: 0.4931, average train loss: 4.6382
[09/25 23:41:10 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1664, average loss: 4.6637
[09/25 23:41:10 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 3.50	
[09/25 23:41:10 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.02739052315863355
[09/25 23:41:17 visual_prompt]: Epoch 98 / 100: avg data time: 5.68e-02, avg batch time: 0.4983, average train loss: 4.6177
[09/25 23:41:18 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1664, average loss: 4.6594
[09/25 23:41:18 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 4.00	
[09/25 23:41:18 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.012179748700879012
[09/25 23:41:25 visual_prompt]: Epoch 99 / 100: avg data time: 6.45e-02, avg batch time: 0.5061, average train loss: 4.5774
[09/25 23:41:27 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1663, average loss: 4.6494
[09/25 23:41:27 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/25 23:41:27 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0030458649045211894
[09/25 23:41:33 visual_prompt]: Epoch 100 / 100: avg data time: 5.51e-02, avg batch time: 0.4965, average train loss: 4.5615
[09/25 23:41:35 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1664, average loss: 4.6459
[09/25 23:41:35 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.00	
[09/25 23:41:35 visual_prompt]: Rank of current process: 0. World size: 1
[09/25 23:41:35 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/25 23:41:35 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-cifar(num_classes=100)', 'DATA.NUMBER_CLASSES', '100', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/25 23:41:35 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/25 23:41:35 visual_prompt]: Training with config:
[09/25 23:41:35 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-cifar(num_classes=100)/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr10.0_wd0.001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 10.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-cifar(num_classes=100)', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 100, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/25 23:41:35 visual_prompt]: Loading training data...
[09/25 23:41:35 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[:800], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/25 23:41:36 visual_prompt]: Number of images: 800
[09/25 23:41:36 visual_prompt]: Number of classes: 100 / 100
[09/25 23:41:36 visual_prompt]: Loading validation data...
[09/25 23:41:36 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[45000:45200], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/25 23:41:36 visual_prompt]: Number of images: 200
[09/25 23:41:36 visual_prompt]: Number of classes: 90 / 100
[09/25 23:41:36 visual_prompt]: Constructing models...
[09/25 23:41:39 visual_prompt]: Total Parameters: 86336356	 Gradient Parameters: 537700
[09/25 23:41:39 visual_prompt]: tuned percent:0.623
[09/25 23:41:39 visual_prompt]: Device used for model: 0
[09/25 23:41:39 visual_prompt]: Setting up Evaluator...
[09/25 23:41:39 visual_prompt]: Setting up Trainer...
[09/25 23:41:39 visual_prompt]: 	Setting up the optimizer...
[09/25 23:41:39 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/25 23:41:46 visual_prompt]: Epoch 1 / 100: avg data time: 5.51e-02, avg batch time: 0.4974, average train loss: 4.6586
[09/25 23:41:47 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1662, average loss: 4.6218
[09/25 23:41:47 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 7.00	
[09/25 23:41:47 visual_prompt]: Best epoch 1: best metric: 0.010
[09/25 23:41:47 visual_prompt]: Training 2 / 100 epoch, with learning rate 1.0
[09/25 23:41:54 visual_prompt]: Epoch 2 / 100: avg data time: 5.62e-02, avg batch time: 0.4972, average train loss: 4.7161
[09/25 23:41:55 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1660, average loss: 4.6937
[09/25 23:41:55 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 5.00	
[09/25 23:41:55 visual_prompt]: Best epoch 2: best metric: 0.015
[09/25 23:41:55 visual_prompt]: Training 3 / 100 epoch, with learning rate 2.0
[09/25 23:42:02 visual_prompt]: Epoch 3 / 100: avg data time: 6.19e-02, avg batch time: 0.5030, average train loss: 4.7482
[09/25 23:42:04 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1661, average loss: 4.7413
[09/25 23:42:04 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.00	
[09/25 23:42:04 visual_prompt]: Training 4 / 100 epoch, with learning rate 3.0
[09/25 23:42:10 visual_prompt]: Epoch 4 / 100: avg data time: 4.32e-02, avg batch time: 0.4846, average train loss: 4.8183
[09/25 23:42:12 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1662, average loss: 4.7957
[09/25 23:42:12 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.50	
[09/25 23:42:12 visual_prompt]: Training 5 / 100 epoch, with learning rate 4.0
[09/25 23:42:18 visual_prompt]: Epoch 5 / 100: avg data time: 5.10e-02, avg batch time: 0.4933, average train loss: 4.7509
[09/25 23:42:20 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1663, average loss: 4.7574
[09/25 23:42:20 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.00	
[09/25 23:42:20 visual_prompt]: Training 6 / 100 epoch, with learning rate 5.0
[09/25 23:42:27 visual_prompt]: Epoch 6 / 100: avg data time: 5.89e-02, avg batch time: 0.4994, average train loss: 4.8327
[09/25 23:42:28 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1661, average loss: 4.9317
[09/25 23:42:28 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.50	
[09/25 23:42:28 visual_prompt]: Training 7 / 100 epoch, with learning rate 6.0
[09/25 23:42:35 visual_prompt]: Epoch 7 / 100: avg data time: 5.90e-02, avg batch time: 0.5008, average train loss: 4.9570
[09/25 23:42:36 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1660, average loss: 4.6565
[09/25 23:42:36 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 8.00	
[09/25 23:42:36 visual_prompt]: Training 8 / 100 epoch, with learning rate 7.0
[09/25 23:42:43 visual_prompt]: Epoch 8 / 100: avg data time: 5.62e-02, avg batch time: 0.4998, average train loss: 4.9982
[09/25 23:42:45 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1659, average loss: 5.1981
[09/25 23:42:45 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 6.00	
[09/25 23:42:45 visual_prompt]: Training 9 / 100 epoch, with learning rate 8.0
[09/25 23:42:51 visual_prompt]: Epoch 9 / 100: avg data time: 4.82e-02, avg batch time: 0.4899, average train loss: 5.3916
[09/25 23:42:53 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1660, average loss: 5.7319
[09/25 23:42:53 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.00	
[09/25 23:42:53 visual_prompt]: Training 10 / 100 epoch, with learning rate 9.0
[09/25 23:42:59 visual_prompt]: Epoch 10 / 100: avg data time: 5.23e-02, avg batch time: 0.4928, average train loss: 5.1993
[09/25 23:43:01 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1663, average loss: 5.8171
[09/25 23:43:01 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.50	
[09/25 23:43:01 visual_prompt]: Training 11 / 100 epoch, with learning rate 10.0
[09/25 23:43:08 visual_prompt]: Epoch 11 / 100: avg data time: 5.77e-02, avg batch time: 0.4980, average train loss: 6.1716
[09/25 23:43:09 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1660, average loss: 6.4385
[09/25 23:43:09 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.00	
[09/25 23:43:09 visual_prompt]: Training 12 / 100 epoch, with learning rate 9.996954135095478
[09/25 23:43:16 visual_prompt]: Epoch 12 / 100: avg data time: 5.67e-02, avg batch time: 0.4979, average train loss: 6.3156
[09/25 23:43:17 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1655, average loss: 6.2651
[09/25 23:43:17 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.00	
[09/25 23:43:17 visual_prompt]: Training 13 / 100 epoch, with learning rate 9.987820251299121
[09/25 23:43:24 visual_prompt]: Epoch 13 / 100: avg data time: 5.62e-02, avg batch time: 0.4959, average train loss: 8.8760
[09/25 23:43:26 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1661, average loss: 10.3612
[09/25 23:43:26 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 6.50	
[09/25 23:43:26 visual_prompt]: Best epoch 13: best metric: 0.020
[09/25 23:43:26 visual_prompt]: Training 14 / 100 epoch, with learning rate 9.972609476841367
[09/25 23:43:32 visual_prompt]: Epoch 14 / 100: avg data time: 6.15e-02, avg batch time: 0.5018, average train loss: 17.2282
[09/25 23:43:34 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1661, average loss: 16.4712
[09/25 23:43:34 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 5.50	
[09/25 23:43:34 visual_prompt]: Training 15 / 100 epoch, with learning rate 9.951340343707852
[09/25 23:43:41 visual_prompt]: Epoch 15 / 100: avg data time: 5.81e-02, avg batch time: 0.5004, average train loss: 18.1575
[09/25 23:43:42 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1663, average loss: 23.9646
[09/25 23:43:42 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 8.00	
[09/25 23:43:42 visual_prompt]: Training 16 / 100 epoch, with learning rate 9.924038765061042
[09/25 23:43:49 visual_prompt]: Epoch 16 / 100: avg data time: 6.23e-02, avg batch time: 0.5031, average train loss: 23.2483
[09/25 23:43:50 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1661, average loss: 22.7453
[09/25 23:43:50 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 2.50	
[09/25 23:43:50 visual_prompt]: Training 17 / 100 epoch, with learning rate 9.890738003669028
[09/25 23:43:57 visual_prompt]: Epoch 17 / 100: avg data time: 5.51e-02, avg batch time: 0.4959, average train loss: 23.0761
[09/25 23:43:58 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1662, average loss: 19.6464
[09/25 23:43:58 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 4.50	
[09/25 23:43:58 visual_prompt]: Training 18 / 100 epoch, with learning rate 9.851478631379981
[09/25 23:44:05 visual_prompt]: Epoch 18 / 100: avg data time: 5.20e-02, avg batch time: 0.4922, average train loss: 16.6665
[09/25 23:44:07 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1659, average loss: 13.8511
[09/25 23:44:07 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.00	
[09/25 23:44:07 visual_prompt]: Training 19 / 100 epoch, with learning rate 9.806308479691594
[09/25 23:44:13 visual_prompt]: Epoch 19 / 100: avg data time: 5.26e-02, avg batch time: 0.4942, average train loss: 14.5800
[09/25 23:44:15 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1660, average loss: 14.9213
[09/25 23:44:15 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 5.50	
[09/25 23:44:15 visual_prompt]: Training 20 / 100 epoch, with learning rate 9.755282581475768
[09/25 23:44:22 visual_prompt]: Epoch 20 / 100: avg data time: 5.99e-02, avg batch time: 0.5012, average train loss: 18.3599
[09/25 23:44:23 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1657, average loss: 16.3524
[09/25 23:44:23 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.50	
[09/25 23:44:23 visual_prompt]: Training 21 / 100 epoch, with learning rate 9.698463103929543
[09/25 23:44:30 visual_prompt]: Epoch 21 / 100: avg data time: 5.57e-02, avg batch time: 0.4968, average train loss: 20.8283
[09/25 23:44:31 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1659, average loss: 18.7536
[09/25 23:44:31 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.00	top5: 4.50	
[09/25 23:44:31 visual_prompt]: Training 22 / 100 epoch, with learning rate 9.635919272833938
[09/25 23:44:38 visual_prompt]: Epoch 22 / 100: avg data time: 5.89e-02, avg batch time: 0.4992, average train loss: 22.6058
[09/25 23:44:39 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1662, average loss: 20.6679
[09/25 23:44:39 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.00	top5: 3.50	
[09/25 23:44:39 visual_prompt]: Training 23 / 100 epoch, with learning rate 9.567727288213003
[09/25 23:44:46 visual_prompt]: Epoch 23 / 100: avg data time: 5.66e-02, avg batch time: 0.4973, average train loss: 22.8047
[09/25 23:44:48 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1660, average loss: 22.6310
[09/25 23:44:48 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.00	top5: 4.50	
[09/25 23:44:48 visual_prompt]: Training 24 / 100 epoch, with learning rate 9.493970231495835
[09/25 23:44:54 visual_prompt]: Epoch 24 / 100: avg data time: 5.59e-02, avg batch time: 0.4972, average train loss: 39.6475
[09/25 23:44:56 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1659, average loss: 23.2752
[09/25 23:44:56 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.00	top5: 4.50	
[09/25 23:44:56 visual_prompt]: Training 25 / 100 epoch, with learning rate 9.414737964294634
[09/25 23:45:02 visual_prompt]: Epoch 25 / 100: avg data time: 5.25e-02, avg batch time: 0.4937, average train loss: 31.9070
[09/25 23:45:04 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1659, average loss: 23.2922
[09/25 23:45:04 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 4.50	
[09/25 23:45:04 visual_prompt]: Training 26 / 100 epoch, with learning rate 9.330127018922195
[09/25 23:45:11 visual_prompt]: Epoch 26 / 100: avg data time: 5.69e-02, avg batch time: 0.4984, average train loss: 24.2233
[09/25 23:45:12 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1658, average loss: 16.0844
[09/25 23:45:12 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.50	
[09/25 23:45:12 visual_prompt]: Training 27 / 100 epoch, with learning rate 9.240240480782129
[09/25 23:45:19 visual_prompt]: Epoch 27 / 100: avg data time: 4.80e-02, avg batch time: 0.4880, average train loss: 18.1199
[09/25 23:45:20 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1659, average loss: 14.4439
[09/25 23:45:20 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.00	
[09/25 23:45:20 visual_prompt]: Training 28 / 100 epoch, with learning rate 9.145187862775208
[09/25 23:45:27 visual_prompt]: Epoch 28 / 100: avg data time: 5.88e-02, avg batch time: 0.4997, average train loss: 16.3600
[09/25 23:45:28 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1661, average loss: 12.7964
[09/25 23:45:28 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.00	
[09/25 23:45:28 visual_prompt]: Training 29 / 100 epoch, with learning rate 9.045084971874736
[09/25 23:45:35 visual_prompt]: Epoch 29 / 100: avg data time: 5.75e-02, avg batch time: 0.4999, average train loss: 16.1828
[09/25 23:45:37 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1660, average loss: 11.9321
[09/25 23:45:37 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 3.00	
[09/25 23:45:37 visual_prompt]: Training 30 / 100 epoch, with learning rate 8.940053768033609
[09/25 23:45:43 visual_prompt]: Epoch 30 / 100: avg data time: 5.64e-02, avg batch time: 0.4975, average train loss: 14.6856
[09/25 23:45:45 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1669, average loss: 12.4045
[09/25 23:45:45 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 7.50	
[09/25 23:45:45 visual_prompt]: Training 31 / 100 epoch, with learning rate 8.83022221559489
[09/25 23:45:52 visual_prompt]: Epoch 31 / 100: avg data time: 5.45e-02, avg batch time: 0.4958, average train loss: 16.3695
[09/25 23:45:53 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1665, average loss: 10.9698
[09/25 23:45:53 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.00	
[09/25 23:45:53 visual_prompt]: Training 32 / 100 epoch, with learning rate 8.715724127386972
[09/25 23:46:00 visual_prompt]: Epoch 32 / 100: avg data time: 5.29e-02, avg batch time: 0.4942, average train loss: 17.8207
[09/25 23:46:01 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1659, average loss: 9.7529
[09/25 23:46:01 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 4.50	
[09/25 23:46:01 visual_prompt]: Training 33 / 100 epoch, with learning rate 8.596699001693256
[09/25 23:46:08 visual_prompt]: Epoch 33 / 100: avg data time: 4.58e-02, avg batch time: 0.4869, average train loss: 12.5182
[09/25 23:46:09 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1660, average loss: 11.1887
[09/25 23:46:09 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 7.50	
[09/25 23:46:09 visual_prompt]: Training 34 / 100 epoch, with learning rate 8.473291852294986
[09/25 23:46:16 visual_prompt]: Epoch 34 / 100: avg data time: 5.30e-02, avg batch time: 0.4927, average train loss: 14.1109
[09/25 23:46:18 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1659, average loss: 10.3862
[09/25 23:46:18 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 4.50	
[09/25 23:46:18 visual_prompt]: Training 35 / 100 epoch, with learning rate 8.345653031794292
[09/25 23:46:24 visual_prompt]: Epoch 35 / 100: avg data time: 4.88e-02, avg batch time: 0.4905, average train loss: 11.9502
[09/25 23:46:26 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1660, average loss: 8.8369
[09/25 23:46:26 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.00	top5: 3.00	
[09/25 23:46:26 visual_prompt]: Training 36 / 100 epoch, with learning rate 8.213938048432697
[09/25 23:46:32 visual_prompt]: Epoch 36 / 100: avg data time: 5.98e-02, avg batch time: 0.5002, average train loss: 9.4644
[09/25 23:46:34 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1660, average loss: 7.2190
[09/25 23:46:34 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 3.50	
[09/25 23:46:34 visual_prompt]: Training 37 / 100 epoch, with learning rate 8.078307376628292
[09/25 23:46:41 visual_prompt]: Epoch 37 / 100: avg data time: 5.40e-02, avg batch time: 0.4949, average train loss: 7.7880
[09/25 23:46:42 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1662, average loss: 6.3206
[09/25 23:46:42 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.00	
[09/25 23:46:42 visual_prompt]: Training 38 / 100 epoch, with learning rate 7.938926261462366
[09/25 23:46:49 visual_prompt]: Epoch 38 / 100: avg data time: 5.75e-02, avg batch time: 0.4986, average train loss: 7.6493
[09/25 23:46:50 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1663, average loss: 6.7448
[09/25 23:46:50 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.00	
[09/25 23:46:50 visual_prompt]: Training 39 / 100 epoch, with learning rate 7.795964517353734
[09/25 23:46:57 visual_prompt]: Epoch 39 / 100: avg data time: 5.46e-02, avg batch time: 0.4969, average train loss: 7.2997
[09/25 23:46:59 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1660, average loss: 6.0064
[09/25 23:46:59 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 6.00	
[09/25 23:46:59 visual_prompt]: Training 40 / 100 epoch, with learning rate 7.649596321166024
[09/25 23:47:05 visual_prompt]: Epoch 40 / 100: avg data time: 4.17e-02, avg batch time: 0.4846, average train loss: 6.4471
[09/25 23:47:07 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1661, average loss: 5.8232
[09/25 23:47:07 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.00	
[09/25 23:47:07 visual_prompt]: Training 41 / 100 epoch, with learning rate 7.5
[09/25 23:47:13 visual_prompt]: Epoch 41 / 100: avg data time: 6.16e-02, avg batch time: 0.5025, average train loss: 6.1339
[09/25 23:47:15 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1662, average loss: 5.6854
[09/25 23:47:15 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.00	
[09/25 23:47:15 visual_prompt]: Training 42 / 100 epoch, with learning rate 7.347357813929454
[09/25 23:47:22 visual_prompt]: Epoch 42 / 100: avg data time: 4.59e-02, avg batch time: 0.4885, average train loss: 5.6905
[09/25 23:47:23 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1664, average loss: 5.7291
[09/25 23:47:23 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 4.50	
[09/25 23:47:23 visual_prompt]: Training 43 / 100 epoch, with learning rate 7.191855733945387
[09/25 23:47:30 visual_prompt]: Epoch 43 / 100: avg data time: 5.32e-02, avg batch time: 0.4943, average train loss: 5.6803
[09/25 23:47:31 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1662, average loss: 5.8307
[09/25 23:47:31 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.00	
[09/25 23:47:31 visual_prompt]: Training 44 / 100 epoch, with learning rate 7.033683215379002
[09/25 23:47:38 visual_prompt]: Epoch 44 / 100: avg data time: 5.96e-02, avg batch time: 0.5001, average train loss: 5.7277
[09/25 23:47:39 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1661, average loss: 5.8851
[09/25 23:47:39 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.50	
[09/25 23:47:39 visual_prompt]: Training 45 / 100 epoch, with learning rate 6.873032967079561
[09/25 23:47:46 visual_prompt]: Epoch 45 / 100: avg data time: 5.39e-02, avg batch time: 0.4956, average train loss: 5.6600
[09/25 23:47:48 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1661, average loss: 5.3390
[09/25 23:47:48 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 3.50	
[09/25 23:47:48 visual_prompt]: Training 46 / 100 epoch, with learning rate 6.710100716628345
[09/25 23:47:54 visual_prompt]: Epoch 46 / 100: avg data time: 5.45e-02, avg batch time: 0.4953, average train loss: 5.2939
[09/25 23:47:56 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1664, average loss: 5.1158
[09/25 23:47:56 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.00	
[09/25 23:47:56 visual_prompt]: Training 47 / 100 epoch, with learning rate 6.545084971874737
[09/25 23:48:03 visual_prompt]: Epoch 47 / 100: avg data time: 5.90e-02, avg batch time: 0.5009, average train loss: 5.2203
[09/25 23:48:04 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1662, average loss: 5.0395
[09/25 23:48:04 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 6.00	
[09/25 23:48:04 visual_prompt]: Training 48 / 100 epoch, with learning rate 6.378186779084995
[09/25 23:48:11 visual_prompt]: Epoch 48 / 100: avg data time: 5.55e-02, avg batch time: 0.4969, average train loss: 4.9980
[09/25 23:48:12 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1662, average loss: 4.9239
[09/25 23:48:12 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/25 23:48:12 visual_prompt]: Training 49 / 100 epoch, with learning rate 6.209609477998338
[09/25 23:48:19 visual_prompt]: Epoch 49 / 100: avg data time: 5.85e-02, avg batch time: 0.5004, average train loss: 4.9785
[09/25 23:48:21 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1662, average loss: 5.0353
[09/25 23:48:21 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.00	
[09/25 23:48:21 visual_prompt]: Training 50 / 100 epoch, with learning rate 6.039558454088796
[09/25 23:48:27 visual_prompt]: Epoch 50 / 100: avg data time: 4.26e-02, avg batch time: 0.4848, average train loss: 4.8774
[09/25 23:48:29 visual_prompt]: Inference (val):avg data time: 4.45e-05, avg batch time: 0.1665, average loss: 4.9550
[09/25 23:48:29 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 4.50	
[09/25 23:48:29 visual_prompt]: Training 51 / 100 epoch, with learning rate 5.868240888334652
[09/25 23:48:35 visual_prompt]: Epoch 51 / 100: avg data time: 4.80e-02, avg batch time: 0.4910, average train loss: 4.9079
[09/25 23:48:37 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1663, average loss: 4.9111
[09/25 23:48:37 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.00	
[09/25 23:48:37 visual_prompt]: Training 52 / 100 epoch, with learning rate 5.695865504800327
[09/25 23:48:44 visual_prompt]: Epoch 52 / 100: avg data time: 5.54e-02, avg batch time: 0.4966, average train loss: 4.8837
[09/25 23:48:45 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1664, average loss: 5.0068
[09/25 23:48:45 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 7.00	
[09/25 23:48:45 visual_prompt]: Training 53 / 100 epoch, with learning rate 5.522642316338268
[09/25 23:48:52 visual_prompt]: Epoch 53 / 100: avg data time: 5.44e-02, avg batch time: 0.4959, average train loss: 4.9663
[09/25 23:48:53 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1665, average loss: 4.9809
[09/25 23:48:53 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.00	
[09/25 23:48:53 visual_prompt]: Training 54 / 100 epoch, with learning rate 5.3487823687206255
[09/25 23:49:00 visual_prompt]: Epoch 54 / 100: avg data time: 5.50e-02, avg batch time: 0.4974, average train loss: 4.9105
[09/25 23:49:01 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1661, average loss: 4.8639
[09/25 23:49:01 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.00	
[09/25 23:49:01 visual_prompt]: Training 55 / 100 epoch, with learning rate 5.174497483512505
[09/25 23:49:08 visual_prompt]: Epoch 55 / 100: avg data time: 5.30e-02, avg batch time: 0.4952, average train loss: 5.0064
[09/25 23:49:09 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1660, average loss: 5.0304
[09/25 23:49:09 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.00	
[09/25 23:49:09 visual_prompt]: Training 56 / 100 epoch, with learning rate 5.0
[09/25 23:49:16 visual_prompt]: Epoch 56 / 100: avg data time: 4.78e-02, avg batch time: 0.4888, average train loss: 5.1012
[09/25 23:49:18 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1662, average loss: 5.0986
[09/25 23:49:18 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.00	
[09/25 23:49:18 visual_prompt]: Training 57 / 100 epoch, with learning rate 4.8255025164874965
[09/25 23:49:24 visual_prompt]: Epoch 57 / 100: avg data time: 5.01e-02, avg batch time: 0.4928, average train loss: 5.0163
[09/25 23:49:26 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1659, average loss: 5.1396
[09/25 23:49:26 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.50	
[09/25 23:49:26 visual_prompt]: Training 58 / 100 epoch, with learning rate 4.651217631279374
[09/25 23:49:32 visual_prompt]: Epoch 58 / 100: avg data time: 5.65e-02, avg batch time: 0.4968, average train loss: 5.0453
[09/25 23:49:34 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1664, average loss: 4.8603
[09/25 23:49:34 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 4.50	
[09/25 23:49:34 visual_prompt]: Training 59 / 100 epoch, with learning rate 4.477357683661733
[09/25 23:49:41 visual_prompt]: Epoch 59 / 100: avg data time: 5.40e-02, avg batch time: 0.4950, average train loss: 4.9206
[09/25 23:49:42 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1660, average loss: 4.8076
[09/25 23:49:42 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 5.50	
[09/25 23:49:42 visual_prompt]: Training 60 / 100 epoch, with learning rate 4.3041344951996745
[09/25 23:49:49 visual_prompt]: Epoch 60 / 100: avg data time: 5.91e-02, avg batch time: 0.5025, average train loss: 4.8786
[09/25 23:49:50 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1663, average loss: 4.8471
[09/25 23:49:50 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 5.00	
[09/25 23:49:50 visual_prompt]: Training 61 / 100 epoch, with learning rate 4.131759111665349
[09/25 23:49:57 visual_prompt]: Epoch 61 / 100: avg data time: 5.21e-02, avg batch time: 0.4925, average train loss: 4.8865
[09/25 23:49:59 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1662, average loss: 4.9879
[09/25 23:49:59 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 5.50	
[09/25 23:49:59 visual_prompt]: Training 62 / 100 epoch, with learning rate 3.960441545911204
[09/25 23:50:05 visual_prompt]: Epoch 62 / 100: avg data time: 5.75e-02, avg batch time: 0.4980, average train loss: 4.9478
[09/25 23:50:07 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1661, average loss: 4.7635
[09/25 23:50:07 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 7.50	
[09/25 23:50:07 visual_prompt]: Training 63 / 100 epoch, with learning rate 3.790390522001662
[09/25 23:50:14 visual_prompt]: Epoch 63 / 100: avg data time: 5.04e-02, avg batch time: 0.4917, average train loss: 4.8482
[09/25 23:50:15 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1661, average loss: 4.8207
[09/25 23:50:15 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.50	
[09/25 23:50:15 visual_prompt]: Training 64 / 100 epoch, with learning rate 3.6218132209150045
[09/25 23:50:22 visual_prompt]: Epoch 64 / 100: avg data time: 5.71e-02, avg batch time: 0.4988, average train loss: 4.8614
[09/25 23:50:23 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1660, average loss: 5.4070
[09/25 23:50:23 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 5.00	
[09/25 23:50:23 visual_prompt]: Training 65 / 100 epoch, with learning rate 3.454915028125263
[09/25 23:50:30 visual_prompt]: Epoch 65 / 100: avg data time: 4.41e-02, avg batch time: 0.4853, average train loss: 4.9576
[09/25 23:50:31 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1660, average loss: 4.8707
[09/25 23:50:31 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.00	top5: 3.50	
[09/25 23:50:31 visual_prompt]: Training 66 / 100 epoch, with learning rate 3.289899283371657
[09/25 23:50:38 visual_prompt]: Epoch 66 / 100: avg data time: 5.98e-02, avg batch time: 0.5002, average train loss: 4.9214
[09/25 23:50:40 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1658, average loss: 4.7837
[09/25 23:50:40 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/25 23:50:40 visual_prompt]: Training 67 / 100 epoch, with learning rate 3.1269670329204398
[09/25 23:50:46 visual_prompt]: Epoch 67 / 100: avg data time: 5.50e-02, avg batch time: 0.4956, average train loss: 4.8874
[09/25 23:50:48 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1658, average loss: 4.7870
[09/25 23:50:48 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.50	
[09/25 23:50:48 visual_prompt]: Training 68 / 100 epoch, with learning rate 2.9663167846209997
[09/25 23:50:55 visual_prompt]: Epoch 68 / 100: avg data time: 5.66e-02, avg batch time: 0.4963, average train loss: 4.7659
[09/25 23:50:56 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1661, average loss: 4.6747
[09/25 23:50:56 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 6.00	
[09/25 23:50:56 visual_prompt]: Training 69 / 100 epoch, with learning rate 2.8081442660546125
[09/25 23:51:03 visual_prompt]: Epoch 69 / 100: avg data time: 5.76e-02, avg batch time: 0.4975, average train loss: 4.7331
[09/25 23:51:04 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1662, average loss: 4.7747
[09/25 23:51:04 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 7.50	
[09/25 23:51:04 visual_prompt]: Training 70 / 100 epoch, with learning rate 2.6526421860705476
[09/25 23:51:11 visual_prompt]: Epoch 70 / 100: avg data time: 4.80e-02, avg batch time: 0.4891, average train loss: 4.7136
[09/25 23:51:12 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1661, average loss: 4.7175
[09/25 23:51:12 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.00	
[09/25 23:51:12 visual_prompt]: Training 71 / 100 epoch, with learning rate 2.500000000000001
[09/25 23:51:19 visual_prompt]: Epoch 71 / 100: avg data time: 5.42e-02, avg batch time: 0.4949, average train loss: 4.7094
[09/25 23:51:20 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1664, average loss: 4.6752
[09/25 23:51:20 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.00	
[09/25 23:51:20 visual_prompt]: Training 72 / 100 epoch, with learning rate 2.350403678833976
[09/25 23:51:27 visual_prompt]: Epoch 72 / 100: avg data time: 4.46e-02, avg batch time: 0.4849, average train loss: 4.6930
[09/25 23:51:28 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1659, average loss: 4.7046
[09/25 23:51:28 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 4.00	
[09/25 23:51:28 visual_prompt]: Training 73 / 100 epoch, with learning rate 2.2040354826462667
[09/25 23:51:35 visual_prompt]: Epoch 73 / 100: avg data time: 5.52e-02, avg batch time: 0.4953, average train loss: 4.6881
[09/25 23:51:37 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1659, average loss: 4.6887
[09/25 23:51:37 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.00	
[09/25 23:51:37 visual_prompt]: Training 74 / 100 epoch, with learning rate 2.061073738537635
[09/25 23:51:43 visual_prompt]: Epoch 74 / 100: avg data time: 5.77e-02, avg batch time: 0.4982, average train loss: 4.6635
[09/25 23:51:45 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1659, average loss: 4.7042
[09/25 23:51:45 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/25 23:51:45 visual_prompt]: Training 75 / 100 epoch, with learning rate 1.9216926233717087
[09/25 23:51:52 visual_prompt]: Epoch 75 / 100: avg data time: 5.35e-02, avg batch time: 0.4934, average train loss: 4.6617
[09/25 23:51:53 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1661, average loss: 4.6176
[09/25 23:51:53 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.50	
[09/25 23:51:53 visual_prompt]: Training 76 / 100 epoch, with learning rate 1.7860619515673033
[09/25 23:52:00 visual_prompt]: Epoch 76 / 100: avg data time: 5.54e-02, avg batch time: 0.4974, average train loss: 4.6623
[09/25 23:52:01 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1662, average loss: 4.6808
[09/25 23:52:01 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 6.00	
[09/25 23:52:01 visual_prompt]: Training 77 / 100 epoch, with learning rate 1.6543469682057106
[09/25 23:52:08 visual_prompt]: Epoch 77 / 100: avg data time: 5.44e-02, avg batch time: 0.4956, average train loss: 4.6723
[09/25 23:52:10 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1663, average loss: 4.6490
[09/25 23:52:10 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.00	
[09/25 23:52:10 visual_prompt]: Training 78 / 100 epoch, with learning rate 1.5267081477050133
[09/25 23:52:16 visual_prompt]: Epoch 78 / 100: avg data time: 5.19e-02, avg batch time: 0.4935, average train loss: 4.6558
[09/25 23:52:18 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1664, average loss: 4.6904
[09/25 23:52:18 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.00	
[09/25 23:52:18 visual_prompt]: Training 79 / 100 epoch, with learning rate 1.403300998306745
[09/25 23:52:24 visual_prompt]: Epoch 79 / 100: avg data time: 5.47e-02, avg batch time: 0.4971, average train loss: 4.6675
[09/25 23:52:26 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1667, average loss: 4.6324
[09/25 23:52:26 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.00	
[09/25 23:52:26 visual_prompt]: Training 80 / 100 epoch, with learning rate 1.2842758726130281
[09/25 23:52:33 visual_prompt]: Epoch 80 / 100: avg data time: 5.10e-02, avg batch time: 0.4931, average train loss: 4.6160
[09/25 23:52:34 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1666, average loss: 4.7979
[09/25 23:52:34 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.50	top5: 6.00	
[09/25 23:52:34 visual_prompt]: Best epoch 80: best metric: 0.025
[09/25 23:52:34 visual_prompt]: Training 81 / 100 epoch, with learning rate 1.1697777844051105
[09/25 23:52:41 visual_prompt]: Epoch 81 / 100: avg data time: 4.39e-02, avg batch time: 0.4865, average train loss: 4.6832
[09/25 23:52:42 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1662, average loss: 4.6647
[09/25 23:52:42 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.50	
[09/25 23:52:42 visual_prompt]: Training 82 / 100 epoch, with learning rate 1.0599462319663906
[09/25 23:52:49 visual_prompt]: Epoch 82 / 100: avg data time: 4.45e-02, avg batch time: 0.4893, average train loss: 4.6818
[09/25 23:52:50 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1664, average loss: 4.6503
[09/25 23:52:50 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.50	
[09/25 23:52:50 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.9549150281252633
[09/25 23:52:57 visual_prompt]: Epoch 83 / 100: avg data time: 5.22e-02, avg batch time: 0.4950, average train loss: 4.5916
[09/25 23:52:58 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1666, average loss: 4.5612
[09/25 23:52:58 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 8.50	
[09/25 23:52:58 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.8548121372247919
[09/25 23:53:05 visual_prompt]: Epoch 84 / 100: avg data time: 5.44e-02, avg batch time: 0.4970, average train loss: 4.5477
[09/25 23:53:07 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1664, average loss: 4.6036
[09/25 23:53:07 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 6.00	
[09/25 23:53:07 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.7597595192178702
[09/25 23:53:13 visual_prompt]: Epoch 85 / 100: avg data time: 5.18e-02, avg batch time: 0.4941, average train loss: 4.5477
[09/25 23:53:15 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1664, average loss: 4.5609
[09/25 23:53:15 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 9.50	
[09/25 23:53:15 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.6698729810778065
[09/25 23:53:22 visual_prompt]: Epoch 86 / 100: avg data time: 5.17e-02, avg batch time: 0.4938, average train loss: 4.4910
[09/25 23:53:23 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1662, average loss: 4.5399
[09/25 23:53:23 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 9.00	
[09/25 23:53:23 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.5852620357053651
[09/25 23:53:30 visual_prompt]: Epoch 87 / 100: avg data time: 4.89e-02, avg batch time: 0.4918, average train loss: 4.4379
[09/25 23:53:31 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1662, average loss: 4.5617
[09/25 23:53:31 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 12.00	
[09/25 23:53:31 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.5060297685041659
[09/25 23:53:38 visual_prompt]: Epoch 88 / 100: avg data time: 5.69e-02, avg batch time: 0.4981, average train loss: 4.3813
[09/25 23:53:39 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1665, average loss: 4.5573
[09/25 23:53:39 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 7.50	
[09/25 23:53:39 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.4322727117869951
[09/25 23:53:46 visual_prompt]: Epoch 89 / 100: avg data time: 4.19e-02, avg batch time: 0.4849, average train loss: 4.3224
[09/25 23:53:48 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1663, average loss: 4.5199
[09/25 23:53:48 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.50	top5: 13.00	
[09/25 23:53:48 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.36408072716606343
[09/25 23:53:54 visual_prompt]: Epoch 90 / 100: avg data time: 5.48e-02, avg batch time: 0.4962, average train loss: 4.3023
[09/25 23:53:56 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1663, average loss: 4.5158
[09/25 23:53:56 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.50	top5: 12.50	
[09/25 23:53:56 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.3015368960704584
[09/25 23:54:03 visual_prompt]: Epoch 91 / 100: avg data time: 5.69e-02, avg batch time: 0.4990, average train loss: 4.2811
[09/25 23:54:04 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1661, average loss: 4.6291
[09/25 23:54:04 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 9.50	
[09/25 23:54:04 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.24471741852423234
[09/25 23:54:11 visual_prompt]: Epoch 92 / 100: avg data time: 6.11e-02, avg batch time: 0.5032, average train loss: 4.3015
[09/25 23:54:12 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1663, average loss: 4.5466
[09/25 23:54:12 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 11.00	
[09/25 23:54:12 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.19369152030840553
[09/25 23:54:19 visual_prompt]: Epoch 93 / 100: avg data time: 5.48e-02, avg batch time: 0.4957, average train loss: 4.2397
[09/25 23:54:20 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1665, average loss: 4.5529
[09/25 23:54:21 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 13.00	
[09/25 23:54:21 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.14852136862001764
[09/25 23:54:27 visual_prompt]: Epoch 94 / 100: avg data time: 5.65e-02, avg batch time: 0.4987, average train loss: 4.1943
[09/25 23:54:29 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1662, average loss: 4.5281
[09/25 23:54:29 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 3.00	top5: 13.50	
[09/25 23:54:29 visual_prompt]: Best epoch 94: best metric: 0.030
[09/25 23:54:29 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.10926199633097156
[09/25 23:54:36 visual_prompt]: Epoch 95 / 100: avg data time: 5.86e-02, avg batch time: 0.4999, average train loss: 4.1386
[09/25 23:54:37 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1661, average loss: 4.5675
[09/25 23:54:37 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.50	top5: 13.00	
[09/25 23:54:37 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.0759612349389599
[09/25 23:54:44 visual_prompt]: Epoch 96 / 100: avg data time: 5.12e-02, avg batch time: 0.4933, average train loss: 4.0848
[09/25 23:54:45 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1663, average loss: 4.5394
[09/25 23:54:45 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.50	top5: 13.50	
[09/25 23:54:45 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.04865965629214819
[09/25 23:54:52 visual_prompt]: Epoch 97 / 100: avg data time: 5.26e-02, avg batch time: 0.4948, average train loss: 4.0567
[09/25 23:54:53 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1663, average loss: 4.5451
[09/25 23:54:53 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 13.00	
[09/25 23:54:53 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.02739052315863355
[09/25 23:55:00 visual_prompt]: Epoch 98 / 100: avg data time: 5.53e-02, avg batch time: 0.4979, average train loss: 4.0144
[09/25 23:55:02 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1664, average loss: 4.5473
[09/25 23:55:02 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 3.50	top5: 16.00	
[09/25 23:55:02 visual_prompt]: Best epoch 98: best metric: 0.035
[09/25 23:55:02 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.012179748700879012
[09/25 23:55:08 visual_prompt]: Epoch 99 / 100: avg data time: 5.68e-02, avg batch time: 0.4978, average train loss: 3.9741
[09/25 23:55:10 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.1663, average loss: 4.5377
[09/25 23:55:10 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 4.00	top5: 14.00	
[09/25 23:55:10 visual_prompt]: Best epoch 99: best metric: 0.040
[09/25 23:55:10 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0030458649045211894
[09/25 23:55:16 visual_prompt]: Epoch 100 / 100: avg data time: 4.65e-02, avg batch time: 0.4888, average train loss: 3.9379
[09/25 23:55:18 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1663, average loss: 4.5377
[09/25 23:55:18 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 4.00	top5: 14.50	
[09/25 23:55:18 visual_prompt]: Rank of current process: 0. World size: 1
[09/25 23:55:18 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/25 23:55:18 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-cifar(num_classes=100)', 'DATA.NUMBER_CLASSES', '100', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/25 23:55:18 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/25 23:55:18 visual_prompt]: Training with config:
[09/25 23:55:18 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-cifar(num_classes=100)/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr10.0_wd0.0001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 10.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-cifar(num_classes=100)', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 100, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/25 23:55:18 visual_prompt]: Loading training data...
[09/25 23:55:18 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[:800], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/25 23:55:19 visual_prompt]: Number of images: 800
[09/25 23:55:19 visual_prompt]: Number of classes: 100 / 100
[09/25 23:55:19 visual_prompt]: Loading validation data...
[09/25 23:55:19 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[45000:45200], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/25 23:55:19 visual_prompt]: Number of images: 200
[09/25 23:55:19 visual_prompt]: Number of classes: 90 / 100
[09/25 23:55:19 visual_prompt]: Constructing models...
[09/25 23:55:22 visual_prompt]: Total Parameters: 86336356	 Gradient Parameters: 537700
[09/25 23:55:22 visual_prompt]: tuned percent:0.623
[09/25 23:55:22 visual_prompt]: Device used for model: 0
[09/25 23:55:22 visual_prompt]: Setting up Evaluator...
[09/25 23:55:22 visual_prompt]: Setting up Trainer...
[09/25 23:55:22 visual_prompt]: 	Setting up the optimizer...
[09/25 23:55:22 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/25 23:55:29 visual_prompt]: Epoch 1 / 100: avg data time: 6.23e-02, avg batch time: 0.5022, average train loss: 4.6600
[09/25 23:55:30 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1659, average loss: 4.6218
[09/25 23:55:30 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 7.00	
[09/25 23:55:30 visual_prompt]: Best epoch 1: best metric: 0.010
[09/25 23:55:30 visual_prompt]: Training 2 / 100 epoch, with learning rate 1.0
[09/25 23:55:37 visual_prompt]: Epoch 2 / 100: avg data time: 5.12e-02, avg batch time: 0.4926, average train loss: 4.6949
[09/25 23:55:38 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1659, average loss: 4.6991
[09/25 23:55:38 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 7.50	
[09/25 23:55:38 visual_prompt]: Best epoch 2: best metric: 0.015
[09/25 23:55:38 visual_prompt]: Training 3 / 100 epoch, with learning rate 2.0
[09/25 23:55:45 visual_prompt]: Epoch 3 / 100: avg data time: 4.64e-02, avg batch time: 0.4902, average train loss: 4.7637
[09/25 23:55:46 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1660, average loss: 4.7005
[09/25 23:55:46 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 7.50	
[09/25 23:55:46 visual_prompt]: Training 4 / 100 epoch, with learning rate 3.0
[09/25 23:55:53 visual_prompt]: Epoch 4 / 100: avg data time: 5.21e-02, avg batch time: 0.4937, average train loss: 4.8340
[09/25 23:55:55 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1659, average loss: 4.9967
[09/25 23:55:55 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 6.50	
[09/25 23:55:55 visual_prompt]: Training 5 / 100 epoch, with learning rate 4.0
[09/25 23:56:01 visual_prompt]: Epoch 5 / 100: avg data time: 5.09e-02, avg batch time: 0.4926, average train loss: 5.0906
[09/25 23:56:03 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1661, average loss: 5.1261
[09/25 23:56:03 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.50	
[09/25 23:56:03 visual_prompt]: Training 6 / 100 epoch, with learning rate 5.0
[09/25 23:56:09 visual_prompt]: Epoch 6 / 100: avg data time: 5.68e-02, avg batch time: 0.4978, average train loss: 4.9806
[09/25 23:56:11 visual_prompt]: Inference (val):avg data time: 4.04e-05, avg batch time: 0.1661, average loss: 5.6032
[09/25 23:56:11 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 8.00	
[09/25 23:56:11 visual_prompt]: Training 7 / 100 epoch, with learning rate 6.0
[09/25 23:56:18 visual_prompt]: Epoch 7 / 100: avg data time: 4.77e-02, avg batch time: 0.4903, average train loss: 6.5006
[09/25 23:56:19 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1660, average loss: 6.7574
[09/25 23:56:19 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 8.00	
[09/25 23:56:19 visual_prompt]: Training 8 / 100 epoch, with learning rate 7.0
[09/25 23:56:26 visual_prompt]: Epoch 8 / 100: avg data time: 5.44e-02, avg batch time: 0.4947, average train loss: 7.6108
[09/25 23:56:27 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1659, average loss: 7.6876
[09/25 23:56:27 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.50	
[09/25 23:56:27 visual_prompt]: Training 9 / 100 epoch, with learning rate 8.0
[09/25 23:56:34 visual_prompt]: Epoch 9 / 100: avg data time: 5.24e-02, avg batch time: 0.4936, average train loss: 13.0144
[09/25 23:56:35 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1657, average loss: 12.4451
[09/25 23:56:35 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 4.50	
[09/25 23:56:35 visual_prompt]: Training 10 / 100 epoch, with learning rate 9.0
[09/25 23:56:42 visual_prompt]: Epoch 10 / 100: avg data time: 6.04e-02, avg batch time: 0.5007, average train loss: 16.2967
[09/25 23:56:44 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1659, average loss: 13.3361
[09/25 23:56:44 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 3.00	top5: 5.50	
[09/25 23:56:44 visual_prompt]: Best epoch 10: best metric: 0.030
[09/25 23:56:44 visual_prompt]: Training 11 / 100 epoch, with learning rate 10.0
[09/25 23:56:50 visual_prompt]: Epoch 11 / 100: avg data time: 5.71e-02, avg batch time: 0.4971, average train loss: 17.4262
[09/25 23:56:52 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1657, average loss: 17.9843
[09/25 23:56:52 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 5.00	
[09/25 23:56:52 visual_prompt]: Training 12 / 100 epoch, with learning rate 9.996954135095478
[09/25 23:56:59 visual_prompt]: Epoch 12 / 100: avg data time: 5.40e-02, avg batch time: 0.4940, average train loss: 21.7863
[09/25 23:57:00 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1660, average loss: 17.7074
[09/25 23:57:00 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.00	
[09/25 23:57:00 visual_prompt]: Training 13 / 100 epoch, with learning rate 9.987820251299121
[09/25 23:57:07 visual_prompt]: Epoch 13 / 100: avg data time: 5.56e-02, avg batch time: 0.4970, average train loss: 21.4100
[09/25 23:57:08 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1659, average loss: 18.2092
[09/25 23:57:08 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 3.50	
[09/25 23:57:08 visual_prompt]: Training 14 / 100 epoch, with learning rate 9.972609476841367
[09/25 23:57:15 visual_prompt]: Epoch 14 / 100: avg data time: 5.56e-02, avg batch time: 0.4964, average train loss: 20.4464
[09/25 23:57:16 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1657, average loss: 15.7108
[09/25 23:57:16 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 6.50	
[09/25 23:57:16 visual_prompt]: Training 15 / 100 epoch, with learning rate 9.951340343707852
[09/25 23:57:23 visual_prompt]: Epoch 15 / 100: avg data time: 5.78e-02, avg batch time: 0.4984, average train loss: 18.6336
[09/25 23:57:25 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1657, average loss: 14.7280
[09/25 23:57:25 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 5.00	
[09/25 23:57:25 visual_prompt]: Training 16 / 100 epoch, with learning rate 9.924038765061042
[09/25 23:57:31 visual_prompt]: Epoch 16 / 100: avg data time: 4.94e-02, avg batch time: 0.4906, average train loss: 16.5677
[09/25 23:57:33 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1657, average loss: 12.5562
[09/25 23:57:33 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 7.00	
[09/25 23:57:33 visual_prompt]: Training 17 / 100 epoch, with learning rate 9.890738003669028
[09/25 23:57:40 visual_prompt]: Epoch 17 / 100: avg data time: 5.54e-02, avg batch time: 0.4953, average train loss: 13.1088
[09/25 23:57:41 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1660, average loss: 12.0557
[09/25 23:57:41 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 6.00	
[09/25 23:57:41 visual_prompt]: Training 18 / 100 epoch, with learning rate 9.851478631379981
[09/25 23:57:48 visual_prompt]: Epoch 18 / 100: avg data time: 4.93e-02, avg batch time: 0.4895, average train loss: 12.6109
[09/25 23:57:49 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1657, average loss: 11.2939
[09/25 23:57:49 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.00	
[09/25 23:57:49 visual_prompt]: Training 19 / 100 epoch, with learning rate 9.806308479691594
[09/25 23:57:56 visual_prompt]: Epoch 19 / 100: avg data time: 5.82e-02, avg batch time: 0.4983, average train loss: 16.0553
[09/25 23:57:57 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1658, average loss: 13.6847
[09/25 23:57:57 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.50	top5: 5.00	
[09/25 23:57:57 visual_prompt]: Training 20 / 100 epoch, with learning rate 9.755282581475768
[09/25 23:58:04 visual_prompt]: Epoch 20 / 100: avg data time: 5.76e-02, avg batch time: 0.4984, average train loss: 15.2553
[09/25 23:58:06 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1659, average loss: 15.1359
[09/25 23:58:06 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.50	
[09/25 23:58:06 visual_prompt]: Training 21 / 100 epoch, with learning rate 9.698463103929543
[09/25 23:58:12 visual_prompt]: Epoch 21 / 100: avg data time: 5.65e-02, avg batch time: 0.4964, average train loss: 16.4287
[09/25 23:58:14 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1658, average loss: 13.1914
[09/25 23:58:14 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 4.00	
[09/25 23:58:14 visual_prompt]: Training 22 / 100 epoch, with learning rate 9.635919272833938
[09/25 23:58:21 visual_prompt]: Epoch 22 / 100: avg data time: 6.07e-02, avg batch time: 0.5016, average train loss: 14.8581
[09/25 23:58:22 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1657, average loss: 13.1511
[09/25 23:58:22 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 8.50	
[09/25 23:58:22 visual_prompt]: Training 23 / 100 epoch, with learning rate 9.567727288213003
[09/25 23:58:29 visual_prompt]: Epoch 23 / 100: avg data time: 5.24e-02, avg batch time: 0.4940, average train loss: 16.0738
[09/25 23:58:30 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1657, average loss: 13.0622
[09/25 23:58:30 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 9.00	
[09/25 23:58:30 visual_prompt]: Training 24 / 100 epoch, with learning rate 9.493970231495835
[09/25 23:58:37 visual_prompt]: Epoch 24 / 100: avg data time: 5.55e-02, avg batch time: 0.4970, average train loss: 16.0248
[09/25 23:58:39 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1657, average loss: 12.5210
[09/25 23:58:39 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 3.50	
[09/25 23:58:39 visual_prompt]: Training 25 / 100 epoch, with learning rate 9.414737964294634
[09/25 23:58:45 visual_prompt]: Epoch 25 / 100: avg data time: 5.53e-02, avg batch time: 0.4952, average train loss: 13.7351
[09/25 23:58:47 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1657, average loss: 10.7656
[09/25 23:58:47 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 5.50	
[09/25 23:58:47 visual_prompt]: Training 26 / 100 epoch, with learning rate 9.330127018922195
[09/25 23:58:54 visual_prompt]: Epoch 26 / 100: avg data time: 5.75e-02, avg batch time: 0.4979, average train loss: 13.4584
[09/25 23:58:55 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1658, average loss: 15.9165
[09/25 23:58:55 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 5.00	
[09/25 23:58:55 visual_prompt]: Training 27 / 100 epoch, with learning rate 9.240240480782129
[09/25 23:59:02 visual_prompt]: Epoch 27 / 100: avg data time: 5.53e-02, avg batch time: 0.4955, average train loss: 14.9766
[09/25 23:59:03 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1659, average loss: 13.0657
[09/25 23:59:03 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.50	
[09/25 23:59:03 visual_prompt]: Training 28 / 100 epoch, with learning rate 9.145187862775208
[09/25 23:59:10 visual_prompt]: Epoch 28 / 100: avg data time: 5.34e-02, avg batch time: 0.4956, average train loss: 18.7311
[09/25 23:59:11 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1659, average loss: 14.8618
[09/25 23:59:11 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 7.00	
[09/25 23:59:11 visual_prompt]: Training 29 / 100 epoch, with learning rate 9.045084971874736
[09/25 23:59:18 visual_prompt]: Epoch 29 / 100: avg data time: 6.06e-02, avg batch time: 0.5010, average train loss: 18.3293
[09/25 23:59:20 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1655, average loss: 18.6020
[09/25 23:59:20 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.00	
[09/25 23:59:20 visual_prompt]: Training 30 / 100 epoch, with learning rate 8.940053768033609
[09/25 23:59:26 visual_prompt]: Epoch 30 / 100: avg data time: 5.24e-02, avg batch time: 0.4944, average train loss: 24.9819
[09/25 23:59:28 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1659, average loss: 16.2828
[09/25 23:59:28 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 6.00	
[09/25 23:59:28 visual_prompt]: Training 31 / 100 epoch, with learning rate 8.83022221559489
[09/25 23:59:35 visual_prompt]: Epoch 31 / 100: avg data time: 6.00e-02, avg batch time: 0.5005, average train loss: 20.7285
[09/25 23:59:36 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1659, average loss: 16.3614
[09/25 23:59:36 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 7.00	
[09/25 23:59:36 visual_prompt]: Training 32 / 100 epoch, with learning rate 8.715724127386972
[09/25 23:59:43 visual_prompt]: Epoch 32 / 100: avg data time: 4.83e-02, avg batch time: 0.4911, average train loss: 18.6473
[09/25 23:59:44 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1659, average loss: 14.0339
[09/25 23:59:44 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.00	
[09/25 23:59:44 visual_prompt]: Training 33 / 100 epoch, with learning rate 8.596699001693256
[09/25 23:59:51 visual_prompt]: Epoch 33 / 100: avg data time: 4.75e-02, avg batch time: 0.4877, average train loss: 16.3974
[09/25 23:59:52 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1661, average loss: 13.8874
[09/25 23:59:52 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 6.00	
[09/25 23:59:52 visual_prompt]: Training 34 / 100 epoch, with learning rate 8.473291852294986
[09/25 23:59:59 visual_prompt]: Epoch 34 / 100: avg data time: 4.75e-02, avg batch time: 0.4899, average train loss: 13.9221
[09/26 00:00:00 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1660, average loss: 12.4169
[09/26 00:00:00 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.00	
[09/26 00:00:00 visual_prompt]: Training 35 / 100 epoch, with learning rate 8.345653031794292
[09/26 00:00:07 visual_prompt]: Epoch 35 / 100: avg data time: 5.37e-02, avg batch time: 0.4959, average train loss: 11.6779
[09/26 00:00:09 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1660, average loss: 8.9414
[09/26 00:00:09 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 6.50	
[09/26 00:00:09 visual_prompt]: Training 36 / 100 epoch, with learning rate 8.213938048432697
[09/26 00:00:15 visual_prompt]: Epoch 36 / 100: avg data time: 5.46e-02, avg batch time: 0.4959, average train loss: 8.8133
[09/26 00:00:17 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1659, average loss: 7.0875
[09/26 00:00:17 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 6.00	
[09/26 00:00:17 visual_prompt]: Training 37 / 100 epoch, with learning rate 8.078307376628292
[09/26 00:00:24 visual_prompt]: Epoch 37 / 100: avg data time: 6.12e-02, avg batch time: 0.5014, average train loss: 7.6947
[09/26 00:00:25 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1658, average loss: 6.3507
[09/26 00:00:25 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 3.00	top5: 10.50	
[09/26 00:00:25 visual_prompt]: Training 38 / 100 epoch, with learning rate 7.938926261462366
[09/26 00:00:32 visual_prompt]: Epoch 38 / 100: avg data time: 5.35e-02, avg batch time: 0.4942, average train loss: 6.3454
[09/26 00:00:33 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1659, average loss: 5.7404
[09/26 00:00:33 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 8.00	
[09/26 00:00:33 visual_prompt]: Training 39 / 100 epoch, with learning rate 7.795964517353734
[09/26 00:00:40 visual_prompt]: Epoch 39 / 100: avg data time: 6.25e-02, avg batch time: 0.5026, average train loss: 5.7986
[09/26 00:00:42 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1659, average loss: 5.5888
[09/26 00:00:42 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.00	top5: 7.00	
[09/26 00:00:42 visual_prompt]: Training 40 / 100 epoch, with learning rate 7.649596321166024
[09/26 00:00:48 visual_prompt]: Epoch 40 / 100: avg data time: 5.55e-02, avg batch time: 0.4961, average train loss: 5.7907
[09/26 00:00:50 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1658, average loss: 5.5983
[09/26 00:00:50 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 9.50	
[09/26 00:00:50 visual_prompt]: Training 41 / 100 epoch, with learning rate 7.5
[09/26 00:00:57 visual_prompt]: Epoch 41 / 100: avg data time: 5.20e-02, avg batch time: 0.4932, average train loss: 5.9228
[09/26 00:00:58 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1657, average loss: 5.5916
[09/26 00:00:58 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 4.00	top5: 8.50	
[09/26 00:00:58 visual_prompt]: Best epoch 41: best metric: 0.040
[09/26 00:00:58 visual_prompt]: Training 42 / 100 epoch, with learning rate 7.347357813929454
[09/26 00:01:05 visual_prompt]: Epoch 42 / 100: avg data time: 4.25e-02, avg batch time: 0.4834, average train loss: 5.4724
[09/26 00:01:06 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1659, average loss: 5.8035
[09/26 00:01:06 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 9.00	
[09/26 00:01:06 visual_prompt]: Training 43 / 100 epoch, with learning rate 7.191855733945387
[09/26 00:01:13 visual_prompt]: Epoch 43 / 100: avg data time: 5.39e-02, avg batch time: 0.4954, average train loss: 5.4259
[09/26 00:01:14 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1659, average loss: 5.5417
[09/26 00:01:14 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 8.00	
[09/26 00:01:14 visual_prompt]: Training 44 / 100 epoch, with learning rate 7.033683215379002
[09/26 00:01:21 visual_prompt]: Epoch 44 / 100: avg data time: 4.79e-02, avg batch time: 0.4901, average train loss: 5.2396
[09/26 00:01:22 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1658, average loss: 5.1152
[09/26 00:01:22 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 3.50	top5: 9.00	
[09/26 00:01:22 visual_prompt]: Training 45 / 100 epoch, with learning rate 6.873032967079561
[09/26 00:01:29 visual_prompt]: Epoch 45 / 100: avg data time: 5.62e-02, avg batch time: 0.4983, average train loss: 5.0125
[09/26 00:01:31 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1659, average loss: 5.2697
[09/26 00:01:31 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 3.00	top5: 11.00	
[09/26 00:01:31 visual_prompt]: Training 46 / 100 epoch, with learning rate 6.710100716628345
[09/26 00:01:37 visual_prompt]: Epoch 46 / 100: avg data time: 5.08e-02, avg batch time: 0.4929, average train loss: 5.5717
[09/26 00:01:39 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1660, average loss: 6.3066
[09/26 00:01:39 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.50	
[09/26 00:01:39 visual_prompt]: Training 47 / 100 epoch, with learning rate 6.545084971874737
[09/26 00:01:45 visual_prompt]: Epoch 47 / 100: avg data time: 5.55e-02, avg batch time: 0.4966, average train loss: 6.2825
[09/26 00:01:47 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1660, average loss: 5.8417
[09/26 00:01:47 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.00	top5: 3.50	
[09/26 00:01:47 visual_prompt]: Training 48 / 100 epoch, with learning rate 6.378186779084995
[09/26 00:01:54 visual_prompt]: Epoch 48 / 100: avg data time: 5.71e-02, avg batch time: 0.4977, average train loss: 5.7280
[09/26 00:01:55 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1660, average loss: 5.4679
[09/26 00:01:55 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 7.50	
[09/26 00:01:55 visual_prompt]: Training 49 / 100 epoch, with learning rate 6.209609477998338
[09/26 00:02:02 visual_prompt]: Epoch 49 / 100: avg data time: 5.50e-02, avg batch time: 0.4956, average train loss: 5.5505
[09/26 00:02:03 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1662, average loss: 5.1429
[09/26 00:02:03 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 7.00	
[09/26 00:02:03 visual_prompt]: Training 50 / 100 epoch, with learning rate 6.039558454088796
[09/26 00:02:10 visual_prompt]: Epoch 50 / 100: avg data time: 4.71e-02, avg batch time: 0.4895, average train loss: 5.3251
[09/26 00:02:11 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1658, average loss: 5.0963
[09/26 00:02:11 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.50	
[09/26 00:02:11 visual_prompt]: Training 51 / 100 epoch, with learning rate 5.868240888334652
[09/26 00:02:18 visual_prompt]: Epoch 51 / 100: avg data time: 6.29e-02, avg batch time: 0.5029, average train loss: 5.1951
[09/26 00:02:20 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1661, average loss: 5.2390
[09/26 00:02:20 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.50	top5: 8.00	
[09/26 00:02:20 visual_prompt]: Training 52 / 100 epoch, with learning rate 5.695865504800327
[09/26 00:02:26 visual_prompt]: Epoch 52 / 100: avg data time: 5.08e-02, avg batch time: 0.4935, average train loss: 5.4378
[09/26 00:02:28 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1658, average loss: 5.3560
[09/26 00:02:28 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 3.00	top5: 8.00	
[09/26 00:02:28 visual_prompt]: Training 53 / 100 epoch, with learning rate 5.522642316338268
[09/26 00:02:35 visual_prompt]: Epoch 53 / 100: avg data time: 4.73e-02, avg batch time: 0.4904, average train loss: 5.2316
[09/26 00:02:36 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1660, average loss: 4.8891
[09/26 00:02:36 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 9.00	
[09/26 00:02:36 visual_prompt]: Training 54 / 100 epoch, with learning rate 5.3487823687206255
[09/26 00:02:43 visual_prompt]: Epoch 54 / 100: avg data time: 6.01e-02, avg batch time: 0.5006, average train loss: 4.9601
[09/26 00:02:44 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1660, average loss: 4.9587
[09/26 00:02:44 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.50	top5: 8.50	
[09/26 00:02:44 visual_prompt]: Training 55 / 100 epoch, with learning rate 5.174497483512505
[09/26 00:02:51 visual_prompt]: Epoch 55 / 100: avg data time: 5.36e-02, avg batch time: 0.4948, average train loss: 4.8402
[09/26 00:02:53 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1659, average loss: 4.7506
[09/26 00:02:53 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.50	top5: 9.00	
[09/26 00:02:53 visual_prompt]: Training 56 / 100 epoch, with learning rate 5.0
[09/26 00:02:59 visual_prompt]: Epoch 56 / 100: avg data time: 5.47e-02, avg batch time: 0.4964, average train loss: 4.8349
[09/26 00:03:01 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1660, average loss: 4.8167
[09/26 00:03:01 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 10.50	
[09/26 00:03:01 visual_prompt]: Training 57 / 100 epoch, with learning rate 4.8255025164874965
[09/26 00:03:08 visual_prompt]: Epoch 57 / 100: avg data time: 5.68e-02, avg batch time: 0.4977, average train loss: 4.7396
[09/26 00:03:09 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1659, average loss: 4.6327
[09/26 00:03:09 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.50	top5: 11.50	
[09/26 00:03:09 visual_prompt]: Training 58 / 100 epoch, with learning rate 4.651217631279374
[09/26 00:03:16 visual_prompt]: Epoch 58 / 100: avg data time: 5.52e-02, avg batch time: 0.4969, average train loss: 4.5851
[09/26 00:03:17 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1661, average loss: 4.7076
[09/26 00:03:17 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 3.50	top5: 12.00	
[09/26 00:03:17 visual_prompt]: Training 59 / 100 epoch, with learning rate 4.477357683661733
[09/26 00:03:24 visual_prompt]: Epoch 59 / 100: avg data time: 5.53e-02, avg batch time: 0.4964, average train loss: 4.6110
[09/26 00:03:25 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1659, average loss: 4.6371
[09/26 00:03:25 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 4.50	top5: 11.00	
[09/26 00:03:25 visual_prompt]: Best epoch 59: best metric: 0.045
[09/26 00:03:25 visual_prompt]: Training 60 / 100 epoch, with learning rate 4.3041344951996745
[09/26 00:03:32 visual_prompt]: Epoch 60 / 100: avg data time: 5.41e-02, avg batch time: 0.4947, average train loss: 4.5381
[09/26 00:03:34 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1661, average loss: 4.6318
[09/26 00:03:34 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 11.50	
[09/26 00:03:34 visual_prompt]: Training 61 / 100 epoch, with learning rate 4.131759111665349
[09/26 00:03:40 visual_prompt]: Epoch 61 / 100: avg data time: 3.96e-02, avg batch time: 0.4827, average train loss: 4.5123
[09/26 00:03:42 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1661, average loss: 4.6490
[09/26 00:03:42 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.50	top5: 12.50	
[09/26 00:03:42 visual_prompt]: Training 62 / 100 epoch, with learning rate 3.960441545911204
[09/26 00:03:48 visual_prompt]: Epoch 62 / 100: avg data time: 5.68e-02, avg batch time: 0.4994, average train loss: 4.5056
[09/26 00:03:50 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1661, average loss: 4.6251
[09/26 00:03:50 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 11.50	
[09/26 00:03:50 visual_prompt]: Training 63 / 100 epoch, with learning rate 3.790390522001662
[09/26 00:03:57 visual_prompt]: Epoch 63 / 100: avg data time: 5.73e-02, avg batch time: 0.4983, average train loss: 4.3108
[09/26 00:03:58 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1661, average loss: 4.6941
[09/26 00:03:58 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 4.00	top5: 14.50	
[09/26 00:03:58 visual_prompt]: Training 64 / 100 epoch, with learning rate 3.6218132209150045
[09/26 00:04:05 visual_prompt]: Epoch 64 / 100: avg data time: 6.10e-02, avg batch time: 0.5040, average train loss: 4.2572
[09/26 00:04:07 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1660, average loss: 4.4205
[09/26 00:04:07 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.50	top5: 13.50	
[09/26 00:04:07 visual_prompt]: Training 65 / 100 epoch, with learning rate 3.454915028125263
[09/26 00:04:13 visual_prompt]: Epoch 65 / 100: avg data time: 6.06e-02, avg batch time: 0.5016, average train loss: 4.2055
[09/26 00:04:15 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1662, average loss: 4.4648
[09/26 00:04:15 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 14.00	
[09/26 00:04:15 visual_prompt]: Training 66 / 100 epoch, with learning rate 3.289899283371657
[09/26 00:04:22 visual_prompt]: Epoch 66 / 100: avg data time: 5.60e-02, avg batch time: 0.4971, average train loss: 4.0604
[09/26 00:04:23 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1663, average loss: 4.7804
[09/26 00:04:23 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 11.00	
[09/26 00:04:23 visual_prompt]: Training 67 / 100 epoch, with learning rate 3.1269670329204398
[09/26 00:04:30 visual_prompt]: Epoch 67 / 100: avg data time: 5.77e-02, avg batch time: 0.4996, average train loss: 4.0972
[09/26 00:04:31 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1661, average loss: 4.3561
[09/26 00:04:31 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 5.50	top5: 23.00	
[09/26 00:04:31 visual_prompt]: Best epoch 67: best metric: 0.055
[09/26 00:04:31 visual_prompt]: Training 68 / 100 epoch, with learning rate 2.9663167846209997
[09/26 00:04:38 visual_prompt]: Epoch 68 / 100: avg data time: 4.61e-02, avg batch time: 0.4890, average train loss: 3.9350
[09/26 00:04:39 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1663, average loss: 4.3981
[09/26 00:04:39 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 3.50	top5: 16.00	
[09/26 00:04:39 visual_prompt]: Training 69 / 100 epoch, with learning rate 2.8081442660546125
[09/26 00:04:46 visual_prompt]: Epoch 69 / 100: avg data time: 5.41e-02, avg batch time: 0.4965, average train loss: 3.9697
[09/26 00:04:48 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1664, average loss: 4.3443
[09/26 00:04:48 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 5.00	top5: 16.00	
[09/26 00:04:48 visual_prompt]: Training 70 / 100 epoch, with learning rate 2.6526421860705476
[09/26 00:04:54 visual_prompt]: Epoch 70 / 100: avg data time: 5.33e-02, avg batch time: 0.4965, average train loss: 3.8836
[09/26 00:04:56 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1664, average loss: 4.3580
[09/26 00:04:56 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 5.50	top5: 20.00	
[09/26 00:04:56 visual_prompt]: Training 71 / 100 epoch, with learning rate 2.500000000000001
[09/26 00:05:03 visual_prompt]: Epoch 71 / 100: avg data time: 5.44e-02, avg batch time: 0.4958, average train loss: 3.7767
[09/26 00:05:04 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1664, average loss: 4.3434
[09/26 00:05:04 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 8.00	top5: 25.00	
[09/26 00:05:04 visual_prompt]: Best epoch 71: best metric: 0.080
[09/26 00:05:04 visual_prompt]: Training 72 / 100 epoch, with learning rate 2.350403678833976
[09/26 00:05:11 visual_prompt]: Epoch 72 / 100: avg data time: 6.34e-02, avg batch time: 0.5047, average train loss: 3.5999
[09/26 00:05:12 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1662, average loss: 4.2568
[09/26 00:05:12 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 9.50	top5: 25.00	
[09/26 00:05:12 visual_prompt]: Best epoch 72: best metric: 0.095
[09/26 00:05:12 visual_prompt]: Training 73 / 100 epoch, with learning rate 2.2040354826462667
[09/26 00:05:19 visual_prompt]: Epoch 73 / 100: avg data time: 4.85e-02, avg batch time: 0.4920, average train loss: 3.3369
[09/26 00:05:20 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1665, average loss: 4.1535
[09/26 00:05:20 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 10.00	top5: 32.00	
[09/26 00:05:20 visual_prompt]: Best epoch 73: best metric: 0.100
[09/26 00:05:20 visual_prompt]: Training 74 / 100 epoch, with learning rate 2.061073738537635
[09/26 00:05:27 visual_prompt]: Epoch 74 / 100: avg data time: 5.20e-02, avg batch time: 0.4949, average train loss: 3.3783
[09/26 00:05:29 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1663, average loss: 4.2723
[09/26 00:05:29 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 7.00	top5: 25.50	
[09/26 00:05:29 visual_prompt]: Training 75 / 100 epoch, with learning rate 1.9216926233717087
[09/26 00:05:35 visual_prompt]: Epoch 75 / 100: avg data time: 5.38e-02, avg batch time: 0.4953, average train loss: 3.1350
[09/26 00:05:37 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1664, average loss: 4.4749
[09/26 00:05:37 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 9.50	top5: 31.50	
[09/26 00:05:37 visual_prompt]: Training 76 / 100 epoch, with learning rate 1.7860619515673033
[09/26 00:05:43 visual_prompt]: Epoch 76 / 100: avg data time: 4.67e-02, avg batch time: 0.4903, average train loss: 2.8463
[09/26 00:05:45 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1664, average loss: 4.2080
[09/26 00:05:45 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 12.00	top5: 29.00	
[09/26 00:05:45 visual_prompt]: Best epoch 76: best metric: 0.120
[09/26 00:05:45 visual_prompt]: Training 77 / 100 epoch, with learning rate 1.6543469682057106
[09/26 00:05:52 visual_prompt]: Epoch 77 / 100: avg data time: 5.74e-02, avg batch time: 0.5015, average train loss: 2.3779
[09/26 00:05:53 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1664, average loss: 4.4275
[09/26 00:05:53 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 10.50	top5: 32.50	
[09/26 00:05:53 visual_prompt]: Training 78 / 100 epoch, with learning rate 1.5267081477050133
[09/26 00:06:00 visual_prompt]: Epoch 78 / 100: avg data time: 5.52e-02, avg batch time: 0.4966, average train loss: 2.1329
[09/26 00:06:01 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1663, average loss: 4.3614
[09/26 00:06:01 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 12.00	top5: 37.00	
[09/26 00:06:01 visual_prompt]: Training 79 / 100 epoch, with learning rate 1.403300998306745
[09/26 00:06:08 visual_prompt]: Epoch 79 / 100: avg data time: 4.74e-02, avg batch time: 0.4903, average train loss: 1.5621
[09/26 00:06:10 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1663, average loss: 4.5066
[09/26 00:06:10 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 13.00	top5: 40.00	
[09/26 00:06:10 visual_prompt]: Best epoch 79: best metric: 0.130
[09/26 00:06:10 visual_prompt]: Training 80 / 100 epoch, with learning rate 1.2842758726130281
[09/26 00:06:16 visual_prompt]: Epoch 80 / 100: avg data time: 5.73e-02, avg batch time: 0.4992, average train loss: 1.1262
[09/26 00:06:18 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1662, average loss: 4.5205
[09/26 00:06:18 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 16.00	top5: 42.00	
[09/26 00:06:18 visual_prompt]: Best epoch 80: best metric: 0.160
[09/26 00:06:18 visual_prompt]: Training 81 / 100 epoch, with learning rate 1.1697777844051105
[09/26 00:06:25 visual_prompt]: Epoch 81 / 100: avg data time: 5.42e-02, avg batch time: 0.4977, average train loss: 0.7167
[09/26 00:06:26 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1662, average loss: 4.5283
[09/26 00:06:26 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 16.00	top5: 42.00	
[09/26 00:06:26 visual_prompt]: Training 82 / 100 epoch, with learning rate 1.0599462319663906
[09/26 00:06:33 visual_prompt]: Epoch 82 / 100: avg data time: 5.64e-02, avg batch time: 0.4994, average train loss: 0.4228
[09/26 00:06:34 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1665, average loss: 4.5944
[09/26 00:06:34 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 20.50	top5: 43.50	
[09/26 00:06:34 visual_prompt]: Best epoch 82: best metric: 0.205
[09/26 00:06:34 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.9549150281252633
[09/26 00:06:41 visual_prompt]: Epoch 83 / 100: avg data time: 4.62e-02, avg batch time: 0.4894, average train loss: 0.2156
[09/26 00:06:42 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1665, average loss: 4.6114
[09/26 00:06:42 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 20.50	top5: 45.00	
[09/26 00:06:42 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.8548121372247919
[09/26 00:06:49 visual_prompt]: Epoch 84 / 100: avg data time: 5.46e-02, avg batch time: 0.4969, average train loss: 0.0992
[09/26 00:06:51 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1665, average loss: 4.6397
[09/26 00:06:51 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 21.00	top5: 45.00	
[09/26 00:06:51 visual_prompt]: Best epoch 84: best metric: 0.210
[09/26 00:06:51 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.7597595192178702
[09/26 00:06:57 visual_prompt]: Epoch 85 / 100: avg data time: 4.15e-02, avg batch time: 0.4847, average train loss: 0.0706
[09/26 00:06:59 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1665, average loss: 4.4497
[09/26 00:06:59 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 20.50	top5: 46.00	
[09/26 00:06:59 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.6698729810778065
[09/26 00:07:05 visual_prompt]: Epoch 86 / 100: avg data time: 5.60e-02, avg batch time: 0.4980, average train loss: 0.0391
[09/26 00:07:07 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1664, average loss: 4.4678
[09/26 00:07:07 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 22.00	top5: 46.00	
[09/26 00:07:07 visual_prompt]: Best epoch 86: best metric: 0.220
[09/26 00:07:07 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.5852620357053651
[09/26 00:07:14 visual_prompt]: Epoch 87 / 100: avg data time: 4.68e-02, avg batch time: 0.4892, average train loss: 0.0282
[09/26 00:07:15 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1665, average loss: 4.4608
[09/26 00:07:15 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 24.00	top5: 46.50	
[09/26 00:07:15 visual_prompt]: Best epoch 87: best metric: 0.240
[09/26 00:07:15 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.5060297685041659
[09/26 00:07:22 visual_prompt]: Epoch 88 / 100: avg data time: 5.59e-02, avg batch time: 0.4991, average train loss: 0.0262
[09/26 00:07:23 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1663, average loss: 4.4795
[09/26 00:07:23 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 24.50	top5: 45.50	
[09/26 00:07:23 visual_prompt]: Best epoch 88: best metric: 0.245
[09/26 00:07:23 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.4322727117869951
[09/26 00:07:30 visual_prompt]: Epoch 89 / 100: avg data time: 5.57e-02, avg batch time: 0.4977, average train loss: 0.0219
[09/26 00:07:31 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1665, average loss: 4.4484
[09/26 00:07:31 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 24.50	top5: 46.00	
[09/26 00:07:31 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.36408072716606343
[09/26 00:07:38 visual_prompt]: Epoch 90 / 100: avg data time: 5.56e-02, avg batch time: 0.4990, average train loss: 0.0215
[09/26 00:07:40 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1666, average loss: 4.4410
[09/26 00:07:40 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 24.00	top5: 45.50	
[09/26 00:07:40 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.3015368960704584
[09/26 00:07:47 visual_prompt]: Epoch 91 / 100: avg data time: 6.05e-02, avg batch time: 0.5029, average train loss: 0.0204
[09/26 00:07:48 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1664, average loss: 4.4504
[09/26 00:07:48 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 24.50	top5: 45.50	
[09/26 00:07:48 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.24471741852423234
[09/26 00:07:55 visual_prompt]: Epoch 92 / 100: avg data time: 5.64e-02, avg batch time: 0.4983, average train loss: 0.0193
[09/26 00:07:56 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1665, average loss: 4.4444
[09/26 00:07:56 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 25.00	top5: 46.00	
[09/26 00:07:56 visual_prompt]: Best epoch 92: best metric: 0.250
[09/26 00:07:56 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.19369152030840553
[09/26 00:08:03 visual_prompt]: Epoch 93 / 100: avg data time: 5.56e-02, avg batch time: 0.4984, average train loss: 0.0191
[09/26 00:08:04 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1666, average loss: 4.4369
[09/26 00:08:04 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 25.00	top5: 46.00	
[09/26 00:08:04 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.14852136862001764
[09/26 00:08:11 visual_prompt]: Epoch 94 / 100: avg data time: 4.05e-02, avg batch time: 0.4851, average train loss: 0.0194
[09/26 00:08:12 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1665, average loss: 4.4315
[09/26 00:08:12 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 25.00	top5: 45.50	
[09/26 00:08:12 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.10926199633097156
[09/26 00:08:19 visual_prompt]: Epoch 95 / 100: avg data time: 5.18e-02, avg batch time: 0.4946, average train loss: 0.0181
[09/26 00:08:21 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1665, average loss: 4.4330
[09/26 00:08:21 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 25.00	top5: 45.50	
[09/26 00:08:21 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.0759612349389599
[09/26 00:08:27 visual_prompt]: Epoch 96 / 100: avg data time: 5.69e-02, avg batch time: 0.4990, average train loss: 0.0194
[09/26 00:08:29 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1666, average loss: 4.4299
[09/26 00:08:29 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 25.00	top5: 45.50	
[09/26 00:08:29 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.04865965629214819
[09/26 00:08:36 visual_prompt]: Epoch 97 / 100: avg data time: 5.30e-02, avg batch time: 0.4975, average train loss: 0.0188
[09/26 00:08:37 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1664, average loss: 4.4295
[09/26 00:08:37 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 25.00	top5: 46.00	
[09/26 00:08:37 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.02739052315863355
[09/26 00:08:44 visual_prompt]: Epoch 98 / 100: avg data time: 5.49e-02, avg batch time: 0.4982, average train loss: 0.0183
[09/26 00:08:45 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1665, average loss: 4.4297
[09/26 00:08:45 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 25.00	top5: 46.00	
[09/26 00:08:45 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.012179748700879012
[09/26 00:08:52 visual_prompt]: Epoch 99 / 100: avg data time: 5.50e-02, avg batch time: 0.4976, average train loss: 0.0174
[09/26 00:08:54 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1664, average loss: 4.4296
[09/26 00:08:54 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 25.00	top5: 46.00	
[09/26 00:08:54 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0030458649045211894
[09/26 00:09:00 visual_prompt]: Epoch 100 / 100: avg data time: 6.23e-02, avg batch time: 0.5048, average train loss: 0.0187
[09/26 00:09:02 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1666, average loss: 4.4296
[09/26 00:09:02 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 25.00	top5: 46.00	
[09/26 00:09:02 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 00:09:02 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 00:09:02 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-cifar(num_classes=100)', 'DATA.NUMBER_CLASSES', '100', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 00:09:02 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 00:09:02 visual_prompt]: Training with config:
[09/26 00:09:02 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-cifar(num_classes=100)/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr10.0_wd0.0/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 10.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-cifar(num_classes=100)', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 100, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 00:09:02 visual_prompt]: Loading training data...
[09/26 00:09:02 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[:800], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/26 00:09:03 visual_prompt]: Number of images: 800
[09/26 00:09:03 visual_prompt]: Number of classes: 100 / 100
[09/26 00:09:03 visual_prompt]: Loading validation data...
[09/26 00:09:03 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[45000:45200], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/26 00:09:03 visual_prompt]: Number of images: 200
[09/26 00:09:03 visual_prompt]: Number of classes: 90 / 100
[09/26 00:09:03 visual_prompt]: Constructing models...
[09/26 00:09:06 visual_prompt]: Total Parameters: 86336356	 Gradient Parameters: 537700
[09/26 00:09:06 visual_prompt]: tuned percent:0.623
[09/26 00:09:06 visual_prompt]: Device used for model: 0
[09/26 00:09:06 visual_prompt]: Setting up Evaluator...
[09/26 00:09:06 visual_prompt]: Setting up Trainer...
[09/26 00:09:06 visual_prompt]: 	Setting up the optimizer...
[09/26 00:09:06 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 00:09:12 visual_prompt]: Epoch 1 / 100: avg data time: 5.78e-02, avg batch time: 0.4986, average train loss: 4.6559
[09/26 00:09:14 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1661, average loss: 4.6218
[09/26 00:09:14 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 7.00	
[09/26 00:09:14 visual_prompt]: Best epoch 1: best metric: 0.010
[09/26 00:09:14 visual_prompt]: Training 2 / 100 epoch, with learning rate 1.0
[09/26 00:09:21 visual_prompt]: Epoch 2 / 100: avg data time: 5.54e-02, avg batch time: 0.4959, average train loss: 4.7165
[09/26 00:09:22 visual_prompt]: Inference (val):avg data time: 5.23e-05, avg batch time: 0.1662, average loss: 4.7068
[09/26 00:09:22 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 4.00	
[09/26 00:09:22 visual_prompt]: Training 3 / 100 epoch, with learning rate 2.0
[09/26 00:09:29 visual_prompt]: Epoch 3 / 100: avg data time: 6.45e-02, avg batch time: 0.5058, average train loss: 4.7396
[09/26 00:09:31 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1661, average loss: 4.7026
[09/26 00:09:31 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 7.00	
[09/26 00:09:31 visual_prompt]: Best epoch 3: best metric: 0.015
[09/26 00:09:31 visual_prompt]: Training 4 / 100 epoch, with learning rate 3.0
[09/26 00:09:37 visual_prompt]: Epoch 4 / 100: avg data time: 5.39e-02, avg batch time: 0.4966, average train loss: 4.6949
[09/26 00:09:39 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1661, average loss: 4.7975
[09/26 00:09:39 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 7.50	
[09/26 00:09:39 visual_prompt]: Best epoch 4: best metric: 0.020
[09/26 00:09:39 visual_prompt]: Training 5 / 100 epoch, with learning rate 4.0
[09/26 00:09:46 visual_prompt]: Epoch 5 / 100: avg data time: 5.68e-02, avg batch time: 0.4982, average train loss: 4.6688
[09/26 00:09:47 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1662, average loss: 4.7695
[09/26 00:09:47 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.50	top5: 13.50	
[09/26 00:09:47 visual_prompt]: Best epoch 5: best metric: 0.025
[09/26 00:09:47 visual_prompt]: Training 6 / 100 epoch, with learning rate 5.0
[09/26 00:09:54 visual_prompt]: Epoch 6 / 100: avg data time: 5.64e-02, avg batch time: 0.4979, average train loss: 4.0786
[09/26 00:09:55 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1659, average loss: 6.6463
[09/26 00:09:55 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 6.00	
[09/26 00:09:55 visual_prompt]: Training 7 / 100 epoch, with learning rate 6.0
[09/26 00:10:02 visual_prompt]: Epoch 7 / 100: avg data time: 4.74e-02, avg batch time: 0.4899, average train loss: 4.9075
[09/26 00:10:03 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1666, average loss: 5.2731
[09/26 00:10:03 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 6.50	top5: 12.00	
[09/26 00:10:03 visual_prompt]: Best epoch 7: best metric: 0.065
[09/26 00:10:03 visual_prompt]: Training 8 / 100 epoch, with learning rate 7.0
[09/26 00:10:10 visual_prompt]: Epoch 8 / 100: avg data time: 5.42e-02, avg batch time: 0.4963, average train loss: 4.7616
[09/26 00:10:12 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1662, average loss: 5.6408
[09/26 00:10:12 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 5.50	top5: 19.00	
[09/26 00:10:12 visual_prompt]: Training 9 / 100 epoch, with learning rate 8.0
[09/26 00:10:18 visual_prompt]: Epoch 9 / 100: avg data time: 5.42e-02, avg batch time: 0.4952, average train loss: 5.5052
[09/26 00:10:20 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.1661, average loss: 5.8009
[09/26 00:10:20 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 5.50	top5: 16.00	
[09/26 00:10:20 visual_prompt]: Training 10 / 100 epoch, with learning rate 9.0
[09/26 00:10:27 visual_prompt]: Epoch 10 / 100: avg data time: 5.54e-02, avg batch time: 0.4967, average train loss: 4.7460
[09/26 00:10:28 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.1661, average loss: 5.0657
[09/26 00:10:28 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 13.50	top5: 36.50	
[09/26 00:10:28 visual_prompt]: Best epoch 10: best metric: 0.135
[09/26 00:10:28 visual_prompt]: Training 11 / 100 epoch, with learning rate 10.0
[09/26 00:10:35 visual_prompt]: Epoch 11 / 100: avg data time: 5.41e-02, avg batch time: 0.4971, average train loss: 3.1533
[09/26 00:10:36 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1662, average loss: 4.2884
[09/26 00:10:36 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 17.50	top5: 54.50	
[09/26 00:10:36 visual_prompt]: Best epoch 11: best metric: 0.175
[09/26 00:10:36 visual_prompt]: Training 12 / 100 epoch, with learning rate 9.996954135095478
[09/26 00:10:43 visual_prompt]: Epoch 12 / 100: avg data time: 5.96e-02, avg batch time: 0.5007, average train loss: 1.8133
[09/26 00:10:45 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1662, average loss: 3.4534
[09/26 00:10:45 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 37.00	top5: 67.50	
[09/26 00:10:45 visual_prompt]: Best epoch 12: best metric: 0.370
[09/26 00:10:45 visual_prompt]: Training 13 / 100 epoch, with learning rate 9.987820251299121
[09/26 00:10:51 visual_prompt]: Epoch 13 / 100: avg data time: 4.79e-02, avg batch time: 0.4908, average train loss: 1.0106
[09/26 00:10:53 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1661, average loss: 3.7209
[09/26 00:10:53 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 38.50	top5: 77.00	
[09/26 00:10:53 visual_prompt]: Best epoch 13: best metric: 0.385
[09/26 00:10:53 visual_prompt]: Training 14 / 100 epoch, with learning rate 9.972609476841367
[09/26 00:10:59 visual_prompt]: Epoch 14 / 100: avg data time: 4.42e-02, avg batch time: 0.4879, average train loss: 0.6225
[09/26 00:11:01 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1665, average loss: 3.1299
[09/26 00:11:01 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 41.50	top5: 74.50	
[09/26 00:11:01 visual_prompt]: Best epoch 14: best metric: 0.415
[09/26 00:11:01 visual_prompt]: Training 15 / 100 epoch, with learning rate 9.951340343707852
[09/26 00:11:08 visual_prompt]: Epoch 15 / 100: avg data time: 5.63e-02, avg batch time: 0.4989, average train loss: 0.4024
[09/26 00:11:09 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1664, average loss: 3.4827
[09/26 00:11:09 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 45.50	top5: 79.50	
[09/26 00:11:09 visual_prompt]: Best epoch 15: best metric: 0.455
[09/26 00:11:09 visual_prompt]: Training 16 / 100 epoch, with learning rate 9.924038765061042
[09/26 00:11:16 visual_prompt]: Epoch 16 / 100: avg data time: 4.10e-02, avg batch time: 0.4859, average train loss: 0.2352
[09/26 00:11:17 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1664, average loss: 3.5740
[09/26 00:11:17 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 46.00	top5: 81.00	
[09/26 00:11:17 visual_prompt]: Best epoch 16: best metric: 0.460
[09/26 00:11:17 visual_prompt]: Training 17 / 100 epoch, with learning rate 9.890738003669028
[09/26 00:11:24 visual_prompt]: Epoch 17 / 100: avg data time: 5.06e-02, avg batch time: 0.4920, average train loss: 0.1828
[09/26 00:11:25 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1664, average loss: 3.6652
[09/26 00:11:25 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 45.00	top5: 80.00	
[09/26 00:11:25 visual_prompt]: Training 18 / 100 epoch, with learning rate 9.851478631379981
[09/26 00:11:32 visual_prompt]: Epoch 18 / 100: avg data time: 5.42e-02, avg batch time: 0.4978, average train loss: 0.1079
[09/26 00:11:34 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1664, average loss: 3.9631
[09/26 00:11:34 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 46.00	top5: 76.00	
[09/26 00:11:34 visual_prompt]: Training 19 / 100 epoch, with learning rate 9.806308479691594
[09/26 00:11:40 visual_prompt]: Epoch 19 / 100: avg data time: 6.16e-02, avg batch time: 0.5033, average train loss: 0.1147
[09/26 00:11:42 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1664, average loss: 3.5153
[09/26 00:11:42 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 51.50	top5: 81.50	
[09/26 00:11:42 visual_prompt]: Best epoch 19: best metric: 0.515
[09/26 00:11:42 visual_prompt]: Training 20 / 100 epoch, with learning rate 9.755282581475768
[09/26 00:11:49 visual_prompt]: Epoch 20 / 100: avg data time: 5.46e-02, avg batch time: 0.4967, average train loss: 0.0838
[09/26 00:11:50 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1664, average loss: 3.4693
[09/26 00:11:50 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 51.50	top5: 82.50	
[09/26 00:11:50 visual_prompt]: Training 21 / 100 epoch, with learning rate 9.698463103929543
[09/26 00:11:57 visual_prompt]: Epoch 21 / 100: avg data time: 5.59e-02, avg batch time: 0.4979, average train loss: 0.1022
[09/26 00:11:58 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1664, average loss: 3.5180
[09/26 00:11:58 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 47.50	top5: 83.00	
[09/26 00:11:58 visual_prompt]: Training 22 / 100 epoch, with learning rate 9.635919272833938
[09/26 00:12:05 visual_prompt]: Epoch 22 / 100: avg data time: 5.08e-02, avg batch time: 0.4933, average train loss: 0.1055
[09/26 00:12:07 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1665, average loss: 4.4782
[09/26 00:12:07 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 49.00	top5: 84.00	
[09/26 00:12:07 visual_prompt]: Training 23 / 100 epoch, with learning rate 9.567727288213003
[09/26 00:12:13 visual_prompt]: Epoch 23 / 100: avg data time: 5.26e-02, avg batch time: 0.4948, average train loss: 0.0886
[09/26 00:12:15 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1665, average loss: 3.2600
[09/26 00:12:15 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 49.50	top5: 81.00	
[09/26 00:12:15 visual_prompt]: Training 24 / 100 epoch, with learning rate 9.493970231495835
[09/26 00:12:22 visual_prompt]: Epoch 24 / 100: avg data time: 5.75e-02, avg batch time: 0.5010, average train loss: 0.0250
[09/26 00:12:23 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1666, average loss: 3.3076
[09/26 00:12:23 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 53.00	top5: 81.50	
[09/26 00:12:23 visual_prompt]: Best epoch 24: best metric: 0.530
[09/26 00:12:23 visual_prompt]: Training 25 / 100 epoch, with learning rate 9.414737964294634
[09/26 00:12:30 visual_prompt]: Epoch 25 / 100: avg data time: 4.95e-02, avg batch time: 0.4943, average train loss: 0.0045
[09/26 00:12:31 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1663, average loss: 3.3545
[09/26 00:12:31 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 53.50	top5: 83.50	
[09/26 00:12:31 visual_prompt]: Best epoch 25: best metric: 0.535
[09/26 00:12:31 visual_prompt]: Training 26 / 100 epoch, with learning rate 9.330127018922195
[09/26 00:12:38 visual_prompt]: Epoch 26 / 100: avg data time: 5.38e-02, avg batch time: 0.4963, average train loss: 0.0062
[09/26 00:12:39 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1666, average loss: 3.3703
[09/26 00:12:39 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.00	top5: 84.00	
[09/26 00:12:39 visual_prompt]: Best epoch 26: best metric: 0.540
[09/26 00:12:39 visual_prompt]: Training 27 / 100 epoch, with learning rate 9.240240480782129
[09/26 00:12:46 visual_prompt]: Epoch 27 / 100: avg data time: 4.65e-02, avg batch time: 0.4902, average train loss: 0.0056
[09/26 00:12:47 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1666, average loss: 3.2874
[09/26 00:12:47 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.50	top5: 85.50	
[09/26 00:12:47 visual_prompt]: Best epoch 27: best metric: 0.545
[09/26 00:12:47 visual_prompt]: Training 28 / 100 epoch, with learning rate 9.145187862775208
[09/26 00:12:54 visual_prompt]: Epoch 28 / 100: avg data time: 4.79e-02, avg batch time: 0.4911, average train loss: 0.0080
[09/26 00:12:56 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1665, average loss: 3.2101
[09/26 00:12:56 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 55.00	top5: 86.50	
[09/26 00:12:56 visual_prompt]: Best epoch 28: best metric: 0.550
[09/26 00:12:56 visual_prompt]: Training 29 / 100 epoch, with learning rate 9.045084971874736
[09/26 00:13:02 visual_prompt]: Epoch 29 / 100: avg data time: 4.43e-02, avg batch time: 0.4880, average train loss: 0.0016
[09/26 00:13:04 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1662, average loss: 3.0682
[09/26 00:13:04 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 57.00	top5: 87.00	
[09/26 00:13:04 visual_prompt]: Best epoch 29: best metric: 0.570
[09/26 00:13:04 visual_prompt]: Training 30 / 100 epoch, with learning rate 8.940053768033609
[09/26 00:13:10 visual_prompt]: Epoch 30 / 100: avg data time: 5.62e-02, avg batch time: 0.4989, average train loss: 0.0004
[09/26 00:13:12 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1664, average loss: 3.0952
[09/26 00:13:12 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 57.00	top5: 88.00	
[09/26 00:13:12 visual_prompt]: Training 31 / 100 epoch, with learning rate 8.83022221559489
[09/26 00:13:19 visual_prompt]: Epoch 31 / 100: avg data time: 5.57e-02, avg batch time: 0.4976, average train loss: 0.0003
[09/26 00:13:20 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1664, average loss: 3.1071
[09/26 00:13:20 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 57.00	top5: 87.50	
[09/26 00:13:20 visual_prompt]: Training 32 / 100 epoch, with learning rate 8.715724127386972
[09/26 00:13:27 visual_prompt]: Epoch 32 / 100: avg data time: 5.52e-02, avg batch time: 0.4980, average train loss: 0.0008
[09/26 00:13:28 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1664, average loss: 3.1154
[09/26 00:13:28 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 57.00	top5: 87.50	
[09/26 00:13:28 visual_prompt]: Training 33 / 100 epoch, with learning rate 8.596699001693256
[09/26 00:13:35 visual_prompt]: Epoch 33 / 100: avg data time: 5.63e-02, avg batch time: 0.4988, average train loss: 0.0002
[09/26 00:13:37 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1664, average loss: 3.1255
[09/26 00:13:37 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.50	top5: 86.50	
[09/26 00:13:37 visual_prompt]: Best epoch 33: best metric: 0.585
[09/26 00:13:37 visual_prompt]: Training 34 / 100 epoch, with learning rate 8.473291852294986
[09/26 00:13:43 visual_prompt]: Epoch 34 / 100: avg data time: 4.78e-02, avg batch time: 0.4897, average train loss: 0.0003
[09/26 00:13:45 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1665, average loss: 3.1294
[09/26 00:13:45 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 86.50	
[09/26 00:13:45 visual_prompt]: Training 35 / 100 epoch, with learning rate 8.345653031794292
[09/26 00:13:51 visual_prompt]: Epoch 35 / 100: avg data time: 5.68e-02, avg batch time: 0.4982, average train loss: 0.0002
[09/26 00:13:53 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1663, average loss: 3.1337
[09/26 00:13:53 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 86.50	
[09/26 00:13:53 visual_prompt]: Training 36 / 100 epoch, with learning rate 8.213938048432697
[09/26 00:14:00 visual_prompt]: Epoch 36 / 100: avg data time: 4.78e-02, avg batch time: 0.4915, average train loss: 0.0002
[09/26 00:14:01 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1667, average loss: 3.1453
[09/26 00:14:01 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 86.50	
[09/26 00:14:01 visual_prompt]: Training 37 / 100 epoch, with learning rate 8.078307376628292
[09/26 00:14:08 visual_prompt]: Epoch 37 / 100: avg data time: 6.27e-02, avg batch time: 0.5041, average train loss: 0.0001
[09/26 00:14:10 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1663, average loss: 3.1477
[09/26 00:14:10 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 86.50	
[09/26 00:14:10 visual_prompt]: Training 38 / 100 epoch, with learning rate 7.938926261462366
[09/26 00:14:16 visual_prompt]: Epoch 38 / 100: avg data time: 5.90e-02, avg batch time: 0.5008, average train loss: 0.0002
[09/26 00:14:18 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1663, average loss: 3.1480
[09/26 00:14:18 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.50	top5: 86.50	
[09/26 00:14:18 visual_prompt]: Training 39 / 100 epoch, with learning rate 7.795964517353734
[09/26 00:14:24 visual_prompt]: Epoch 39 / 100: avg data time: 4.84e-02, avg batch time: 0.4905, average train loss: 0.0001
[09/26 00:14:26 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1665, average loss: 3.1493
[09/26 00:14:26 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.50	top5: 86.50	
[09/26 00:14:26 visual_prompt]: Training 40 / 100 epoch, with learning rate 7.649596321166024
[09/26 00:14:32 visual_prompt]: Epoch 40 / 100: avg data time: 4.38e-02, avg batch time: 0.4864, average train loss: 0.0001
[09/26 00:14:34 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1664, average loss: 3.1511
[09/26 00:14:34 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.50	top5: 86.50	
[09/26 00:14:34 visual_prompt]: Training 41 / 100 epoch, with learning rate 7.5
[09/26 00:14:41 visual_prompt]: Epoch 41 / 100: avg data time: 5.24e-02, avg batch time: 0.4951, average train loss: 0.0001
[09/26 00:14:42 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1665, average loss: 3.1514
[09/26 00:14:42 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.50	top5: 86.50	
[09/26 00:14:42 visual_prompt]: Training 42 / 100 epoch, with learning rate 7.347357813929454
[09/26 00:14:49 visual_prompt]: Epoch 42 / 100: avg data time: 4.26e-02, avg batch time: 0.4856, average train loss: 0.0001
[09/26 00:14:50 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.1665, average loss: 3.1554
[09/26 00:14:50 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.50	top5: 86.50	
[09/26 00:14:50 visual_prompt]: Training 43 / 100 epoch, with learning rate 7.191855733945387
[09/26 00:14:57 visual_prompt]: Epoch 43 / 100: avg data time: 5.25e-02, avg batch time: 0.4943, average train loss: 0.0002
[09/26 00:14:58 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1665, average loss: 3.1521
[09/26 00:14:58 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.50	top5: 86.00	
[09/26 00:14:58 visual_prompt]: Training 44 / 100 epoch, with learning rate 7.033683215379002
[09/26 00:15:05 visual_prompt]: Epoch 44 / 100: avg data time: 4.73e-02, avg batch time: 0.4910, average train loss: 0.0001
[09/26 00:15:06 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1663, average loss: 3.1506
[09/26 00:15:06 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.00	top5: 86.00	
[09/26 00:15:06 visual_prompt]: Best epoch 44: best metric: 0.590
[09/26 00:15:06 visual_prompt]: Training 45 / 100 epoch, with learning rate 6.873032967079561
[09/26 00:15:13 visual_prompt]: Epoch 45 / 100: avg data time: 5.58e-02, avg batch time: 0.4980, average train loss: 0.0001
[09/26 00:15:15 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1666, average loss: 3.1525
[09/26 00:15:15 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.00	top5: 86.00	
[09/26 00:15:15 visual_prompt]: Training 46 / 100 epoch, with learning rate 6.710100716628345
[09/26 00:15:21 visual_prompt]: Epoch 46 / 100: avg data time: 5.18e-02, avg batch time: 0.4956, average train loss: 0.0001
[09/26 00:15:23 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1665, average loss: 3.1538
[09/26 00:15:23 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.00	top5: 86.00	
[09/26 00:15:23 visual_prompt]: Training 47 / 100 epoch, with learning rate 6.545084971874737
[09/26 00:15:30 visual_prompt]: Epoch 47 / 100: avg data time: 5.74e-02, avg batch time: 0.4996, average train loss: 0.0001
[09/26 00:15:31 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1662, average loss: 3.1549
[09/26 00:15:31 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.00	top5: 86.00	
[09/26 00:15:31 visual_prompt]: Training 48 / 100 epoch, with learning rate 6.378186779084995
[09/26 00:15:38 visual_prompt]: Epoch 48 / 100: avg data time: 6.00e-02, avg batch time: 0.5039, average train loss: 0.0001
[09/26 00:15:39 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1664, average loss: 3.1562
[09/26 00:15:39 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.00	top5: 86.00	
[09/26 00:15:39 visual_prompt]: Training 49 / 100 epoch, with learning rate 6.209609477998338
[09/26 00:15:46 visual_prompt]: Epoch 49 / 100: avg data time: 5.74e-02, avg batch time: 0.4997, average train loss: 0.0001
[09/26 00:15:48 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1666, average loss: 3.1556
[09/26 00:15:48 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.00	top5: 86.00	
[09/26 00:15:48 visual_prompt]: Training 50 / 100 epoch, with learning rate 6.039558454088796
[09/26 00:15:54 visual_prompt]: Epoch 50 / 100: avg data time: 5.39e-02, avg batch time: 0.4955, average train loss: 0.0001
[09/26 00:15:56 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1663, average loss: 3.1555
[09/26 00:15:56 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.00	top5: 86.00	
[09/26 00:15:56 visual_prompt]: Training 51 / 100 epoch, with learning rate 5.868240888334652
[09/26 00:16:03 visual_prompt]: Epoch 51 / 100: avg data time: 5.03e-02, avg batch time: 0.4918, average train loss: 0.0001
[09/26 00:16:04 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1666, average loss: 3.1587
[09/26 00:16:04 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.00	top5: 86.00	
[09/26 00:16:04 visual_prompt]: Training 52 / 100 epoch, with learning rate 5.695865504800327
[09/26 00:16:11 visual_prompt]: Epoch 52 / 100: avg data time: 5.12e-02, avg batch time: 0.4940, average train loss: 0.0001
[09/26 00:16:12 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1663, average loss: 3.1593
[09/26 00:16:12 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.50	top5: 86.00	
[09/26 00:16:12 visual_prompt]: Training 53 / 100 epoch, with learning rate 5.522642316338268
[09/26 00:16:19 visual_prompt]: Epoch 53 / 100: avg data time: 6.02e-02, avg batch time: 0.5027, average train loss: 0.0001
[09/26 00:16:21 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1662, average loss: 3.1586
[09/26 00:16:21 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.00	top5: 86.00	
[09/26 00:16:21 visual_prompt]: Training 54 / 100 epoch, with learning rate 5.3487823687206255
[09/26 00:16:27 visual_prompt]: Epoch 54 / 100: avg data time: 4.72e-02, avg batch time: 0.4910, average train loss: 0.0001
[09/26 00:16:29 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1664, average loss: 3.1585
[09/26 00:16:29 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.00	top5: 86.00	
[09/26 00:16:29 visual_prompt]: Training 55 / 100 epoch, with learning rate 5.174497483512505
[09/26 00:16:36 visual_prompt]: Epoch 55 / 100: avg data time: 5.69e-02, avg batch time: 0.4984, average train loss: 0.0001
[09/26 00:16:37 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1666, average loss: 3.1589
[09/26 00:16:37 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.00	top5: 86.00	
[09/26 00:16:37 visual_prompt]: Training 56 / 100 epoch, with learning rate 5.0
[09/26 00:16:44 visual_prompt]: Epoch 56 / 100: avg data time: 5.39e-02, avg batch time: 0.4962, average train loss: 0.0001
[09/26 00:16:45 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1663, average loss: 3.1599
[09/26 00:16:45 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.00	top5: 86.00	
[09/26 00:16:45 visual_prompt]: Training 57 / 100 epoch, with learning rate 4.8255025164874965
[09/26 00:16:52 visual_prompt]: Epoch 57 / 100: avg data time: 4.75e-02, avg batch time: 0.4923, average train loss: 0.0001
[09/26 00:16:54 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1662, average loss: 3.1603
[09/26 00:16:54 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.00	top5: 86.00	
[09/26 00:16:54 visual_prompt]: Training 58 / 100 epoch, with learning rate 4.651217631279374
[09/26 00:17:00 visual_prompt]: Epoch 58 / 100: avg data time: 5.15e-02, avg batch time: 0.4942, average train loss: 0.0001
[09/26 00:17:02 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1663, average loss: 3.1611
[09/26 00:17:02 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.00	top5: 86.00	
[09/26 00:17:02 visual_prompt]: Training 59 / 100 epoch, with learning rate 4.477357683661733
[09/26 00:17:08 visual_prompt]: Epoch 59 / 100: avg data time: 5.37e-02, avg batch time: 0.4959, average train loss: 0.0002
[09/26 00:17:10 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1663, average loss: 3.1558
[09/26 00:17:10 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.00	top5: 86.00	
[09/26 00:17:10 visual_prompt]: Training 60 / 100 epoch, with learning rate 4.3041344951996745
[09/26 00:17:17 visual_prompt]: Epoch 60 / 100: avg data time: 5.12e-02, avg batch time: 0.4934, average train loss: 0.0001
[09/26 00:17:18 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1663, average loss: 3.1541
[09/26 00:17:18 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.50	top5: 86.00	
[09/26 00:17:18 visual_prompt]: Best epoch 60: best metric: 0.595
[09/26 00:17:18 visual_prompt]: Training 61 / 100 epoch, with learning rate 4.131759111665349
[09/26 00:17:25 visual_prompt]: Epoch 61 / 100: avg data time: 5.74e-02, avg batch time: 0.5000, average train loss: 0.0001
[09/26 00:17:26 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1664, average loss: 3.1548
[09/26 00:17:26 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.50	top5: 86.00	
[09/26 00:17:26 visual_prompt]: Training 62 / 100 epoch, with learning rate 3.960441545911204
[09/26 00:17:33 visual_prompt]: Epoch 62 / 100: avg data time: 5.36e-02, avg batch time: 0.4954, average train loss: 0.0001
[09/26 00:17:35 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1663, average loss: 3.1561
[09/26 00:17:35 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.50	top5: 86.00	
[09/26 00:17:35 visual_prompt]: Training 63 / 100 epoch, with learning rate 3.790390522001662
[09/26 00:17:41 visual_prompt]: Epoch 63 / 100: avg data time: 4.30e-02, avg batch time: 0.4856, average train loss: 0.0000
[09/26 00:17:43 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1665, average loss: 3.1567
[09/26 00:17:43 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.50	top5: 86.00	
[09/26 00:17:43 visual_prompt]: Training 64 / 100 epoch, with learning rate 3.6218132209150045
[09/26 00:17:49 visual_prompt]: Epoch 64 / 100: avg data time: 5.93e-02, avg batch time: 0.5025, average train loss: 0.0001
[09/26 00:17:51 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1664, average loss: 3.1572
[09/26 00:17:51 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.50	top5: 86.00	
[09/26 00:17:51 visual_prompt]: Training 65 / 100 epoch, with learning rate 3.454915028125263
[09/26 00:17:58 visual_prompt]: Epoch 65 / 100: avg data time: 5.57e-02, avg batch time: 0.4973, average train loss: 0.0000
[09/26 00:17:59 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1662, average loss: 3.1575
[09/26 00:17:59 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.50	top5: 86.00	
[09/26 00:17:59 visual_prompt]: Training 66 / 100 epoch, with learning rate 3.289899283371657
[09/26 00:18:06 visual_prompt]: Epoch 66 / 100: avg data time: 5.52e-02, avg batch time: 0.4979, average train loss: 0.0001
[09/26 00:18:07 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1664, average loss: 3.1579
[09/26 00:18:07 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.50	top5: 86.00	
[09/26 00:18:07 visual_prompt]: Training 67 / 100 epoch, with learning rate 3.1269670329204398
[09/26 00:18:14 visual_prompt]: Epoch 67 / 100: avg data time: 5.60e-02, avg batch time: 0.4976, average train loss: 0.0001
[09/26 00:18:16 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1664, average loss: 3.1586
[09/26 00:18:16 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.50	top5: 86.00	
[09/26 00:18:16 visual_prompt]: Training 68 / 100 epoch, with learning rate 2.9663167846209997
[09/26 00:18:22 visual_prompt]: Epoch 68 / 100: avg data time: 4.10e-02, avg batch time: 0.4865, average train loss: 0.0001
[09/26 00:18:24 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1664, average loss: 3.1590
[09/26 00:18:24 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.50	top5: 86.00	
[09/26 00:18:24 visual_prompt]: Training 69 / 100 epoch, with learning rate 2.8081442660546125
[09/26 00:18:31 visual_prompt]: Epoch 69 / 100: avg data time: 6.03e-02, avg batch time: 0.5017, average train loss: 0.0001
[09/26 00:18:32 visual_prompt]: Inference (val):avg data time: 5.14e-05, avg batch time: 0.1665, average loss: 3.1596
[09/26 00:18:32 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.50	top5: 86.00	
[09/26 00:18:32 visual_prompt]: Training 70 / 100 epoch, with learning rate 2.6526421860705476
[09/26 00:18:39 visual_prompt]: Epoch 70 / 100: avg data time: 5.51e-02, avg batch time: 0.4973, average train loss: 0.0001
[09/26 00:18:40 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1665, average loss: 3.1601
[09/26 00:18:40 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.50	top5: 86.00	
[09/26 00:18:40 visual_prompt]: Training 71 / 100 epoch, with learning rate 2.500000000000001
[09/26 00:18:47 visual_prompt]: Epoch 71 / 100: avg data time: 5.62e-02, avg batch time: 0.4992, average train loss: 0.0001
[09/26 00:18:49 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1663, average loss: 3.1606
[09/26 00:18:49 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.50	top5: 86.00	
[09/26 00:18:49 visual_prompt]: Training 72 / 100 epoch, with learning rate 2.350403678833976
[09/26 00:18:55 visual_prompt]: Epoch 72 / 100: avg data time: 5.62e-02, avg batch time: 0.4987, average train loss: 0.0001
[09/26 00:18:57 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1663, average loss: 3.1611
[09/26 00:18:57 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.50	top5: 86.00	
[09/26 00:18:57 visual_prompt]: Training 73 / 100 epoch, with learning rate 2.2040354826462667
[09/26 00:19:04 visual_prompt]: Epoch 73 / 100: avg data time: 5.34e-02, avg batch time: 0.4950, average train loss: 0.0001
[09/26 00:19:05 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1664, average loss: 3.1615
[09/26 00:19:05 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.50	top5: 86.00	
[09/26 00:19:05 visual_prompt]: Training 74 / 100 epoch, with learning rate 2.061073738537635
[09/26 00:19:12 visual_prompt]: Epoch 74 / 100: avg data time: 5.32e-02, avg batch time: 0.4954, average train loss: 0.0001
[09/26 00:19:13 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1663, average loss: 3.1620
[09/26 00:19:13 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.50	top5: 86.00	
[09/26 00:19:13 visual_prompt]: Training 75 / 100 epoch, with learning rate 1.9216926233717087
[09/26 00:19:20 visual_prompt]: Epoch 75 / 100: avg data time: 5.57e-02, avg batch time: 0.4975, average train loss: 0.0000
[09/26 00:19:22 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1662, average loss: 3.1625
[09/26 00:19:22 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.50	top5: 86.00	
[09/26 00:19:22 visual_prompt]: Training 76 / 100 epoch, with learning rate 1.7860619515673033
[09/26 00:19:28 visual_prompt]: Epoch 76 / 100: avg data time: 6.08e-02, avg batch time: 0.5025, average train loss: 0.0000
[09/26 00:19:30 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1662, average loss: 3.1628
[09/26 00:19:30 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.50	top5: 86.00	
[09/26 00:19:30 visual_prompt]: Training 77 / 100 epoch, with learning rate 1.6543469682057106
[09/26 00:19:37 visual_prompt]: Epoch 77 / 100: avg data time: 5.95e-02, avg batch time: 0.5011, average train loss: 0.0000
[09/26 00:19:38 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1663, average loss: 3.1631
[09/26 00:19:38 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.50	top5: 86.00	
[09/26 00:19:38 visual_prompt]: Training 78 / 100 epoch, with learning rate 1.5267081477050133
[09/26 00:19:45 visual_prompt]: Epoch 78 / 100: avg data time: 5.95e-02, avg batch time: 0.5026, average train loss: 0.0001
[09/26 00:19:46 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1662, average loss: 3.1633
[09/26 00:19:46 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.50	top5: 86.00	
[09/26 00:19:46 visual_prompt]: Training 79 / 100 epoch, with learning rate 1.403300998306745
[09/26 00:19:53 visual_prompt]: Epoch 79 / 100: avg data time: 6.09e-02, avg batch time: 0.5037, average train loss: 0.0001
[09/26 00:19:55 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1662, average loss: 3.1634
[09/26 00:19:55 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.50	top5: 86.00	
[09/26 00:19:55 visual_prompt]: Training 80 / 100 epoch, with learning rate 1.2842758726130281
[09/26 00:20:01 visual_prompt]: Epoch 80 / 100: avg data time: 4.39e-02, avg batch time: 0.4870, average train loss: 0.0001
[09/26 00:20:03 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1664, average loss: 3.1636
[09/26 00:20:03 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.50	top5: 86.00	
[09/26 00:20:03 visual_prompt]: Training 81 / 100 epoch, with learning rate 1.1697777844051105
[09/26 00:20:10 visual_prompt]: Epoch 81 / 100: avg data time: 4.59e-02, avg batch time: 0.4901, average train loss: 0.0001
[09/26 00:20:11 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1664, average loss: 3.1637
[09/26 00:20:11 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.50	top5: 86.00	
[09/26 00:20:11 visual_prompt]: Training 82 / 100 epoch, with learning rate 1.0599462319663906
[09/26 00:20:18 visual_prompt]: Epoch 82 / 100: avg data time: 4.45e-02, avg batch time: 0.4892, average train loss: 0.0001
[09/26 00:20:19 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1664, average loss: 3.1639
[09/26 00:20:19 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.50	top5: 86.00	
[09/26 00:20:19 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.9549150281252633
[09/26 00:20:26 visual_prompt]: Epoch 83 / 100: avg data time: 6.19e-02, avg batch time: 0.5038, average train loss: 0.0001
[09/26 00:20:27 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1664, average loss: 3.1641
[09/26 00:20:27 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.50	top5: 86.00	
[09/26 00:20:27 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.8548121372247919
[09/26 00:20:34 visual_prompt]: Epoch 84 / 100: avg data time: 5.52e-02, avg batch time: 0.4976, average train loss: 0.0000
[09/26 00:20:36 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1664, average loss: 3.1645
[09/26 00:20:36 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.50	top5: 86.00	
[09/26 00:20:36 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.7597595192178702
[09/26 00:20:42 visual_prompt]: Epoch 85 / 100: avg data time: 5.18e-02, avg batch time: 0.4941, average train loss: 0.0001
[09/26 00:20:44 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1664, average loss: 3.1647
[09/26 00:20:44 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.50	top5: 86.00	
[09/26 00:20:44 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.6698729810778065
[09/26 00:20:51 visual_prompt]: Epoch 86 / 100: avg data time: 5.78e-02, avg batch time: 0.5001, average train loss: 0.0001
[09/26 00:20:52 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1666, average loss: 3.1648
[09/26 00:20:52 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.50	top5: 86.00	
[09/26 00:20:52 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.5852620357053651
[09/26 00:20:59 visual_prompt]: Epoch 87 / 100: avg data time: 5.20e-02, avg batch time: 0.4939, average train loss: 0.0001
[09/26 00:21:00 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1664, average loss: 3.1649
[09/26 00:21:00 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.50	top5: 86.00	
[09/26 00:21:00 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.5060297685041659
[09/26 00:21:07 visual_prompt]: Epoch 88 / 100: avg data time: 5.12e-02, avg batch time: 0.4942, average train loss: 0.0000
[09/26 00:21:09 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1665, average loss: 3.1650
[09/26 00:21:09 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.50	top5: 86.00	
[09/26 00:21:09 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.4322727117869951
[09/26 00:21:15 visual_prompt]: Epoch 89 / 100: avg data time: 4.90e-02, avg batch time: 0.4914, average train loss: 0.0000
[09/26 00:21:17 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1664, average loss: 3.1651
[09/26 00:21:17 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.50	top5: 86.00	
[09/26 00:21:17 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.36408072716606343
[09/26 00:21:23 visual_prompt]: Epoch 90 / 100: avg data time: 4.31e-02, avg batch time: 0.4857, average train loss: 0.0000
[09/26 00:21:25 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1667, average loss: 3.1651
[09/26 00:21:25 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.50	top5: 86.00	
[09/26 00:21:25 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.3015368960704584
[09/26 00:21:32 visual_prompt]: Epoch 91 / 100: avg data time: 5.87e-02, avg batch time: 0.5003, average train loss: 0.0001
[09/26 00:21:33 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1664, average loss: 3.1652
[09/26 00:21:33 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.50	top5: 86.00	
[09/26 00:21:33 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.24471741852423234
[09/26 00:21:40 visual_prompt]: Epoch 92 / 100: avg data time: 5.58e-02, avg batch time: 0.4987, average train loss: 0.0001
[09/26 00:21:41 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1663, average loss: 3.1651
[09/26 00:21:41 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.50	top5: 86.00	
[09/26 00:21:41 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.19369152030840553
[09/26 00:21:48 visual_prompt]: Epoch 93 / 100: avg data time: 5.32e-02, avg batch time: 0.4959, average train loss: 0.0000
[09/26 00:21:49 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1664, average loss: 3.1652
[09/26 00:21:49 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.50	top5: 86.00	
[09/26 00:21:49 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.14852136862001764
[09/26 00:21:56 visual_prompt]: Epoch 94 / 100: avg data time: 4.80e-02, avg batch time: 0.4914, average train loss: 0.0001
[09/26 00:21:58 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1662, average loss: 3.1652
[09/26 00:21:58 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.50	top5: 86.00	
[09/26 00:21:58 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.10926199633097156
[09/26 00:22:04 visual_prompt]: Epoch 95 / 100: avg data time: 4.19e-02, avg batch time: 0.4850, average train loss: 0.0001
[09/26 00:22:06 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1663, average loss: 3.1652
[09/26 00:22:06 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.50	top5: 86.00	
[09/26 00:22:06 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.0759612349389599
[09/26 00:22:13 visual_prompt]: Epoch 96 / 100: avg data time: 5.81e-02, avg batch time: 0.4999, average train loss: 0.0000
[09/26 00:22:14 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1663, average loss: 3.1652
[09/26 00:22:14 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.50	top5: 86.00	
[09/26 00:22:14 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.04865965629214819
[09/26 00:22:21 visual_prompt]: Epoch 97 / 100: avg data time: 4.70e-02, avg batch time: 0.4910, average train loss: 0.0001
[09/26 00:22:22 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1663, average loss: 3.1652
[09/26 00:22:22 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.50	top5: 86.00	
[09/26 00:22:22 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.02739052315863355
[09/26 00:22:29 visual_prompt]: Epoch 98 / 100: avg data time: 6.38e-02, avg batch time: 0.5056, average train loss: 0.0000
[09/26 00:22:31 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1663, average loss: 3.1653
[09/26 00:22:31 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.50	top5: 86.00	
[09/26 00:22:31 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.012179748700879012
[09/26 00:22:37 visual_prompt]: Epoch 99 / 100: avg data time: 4.39e-02, avg batch time: 0.4879, average train loss: 0.0000
[09/26 00:22:39 visual_prompt]: Inference (val):avg data time: 4.40e-05, avg batch time: 0.1665, average loss: 3.1653
[09/26 00:22:39 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.50	top5: 86.00	
[09/26 00:22:39 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0030458649045211894
[09/26 00:22:45 visual_prompt]: Epoch 100 / 100: avg data time: 5.60e-02, avg batch time: 0.4975, average train loss: 0.0001
[09/26 00:22:47 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1664, average loss: 3.1653
[09/26 00:22:47 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.50	top5: 86.00	
[09/26 00:22:47 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 00:22:47 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 00:22:47 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-cifar(num_classes=100)', 'DATA.NUMBER_CLASSES', '100', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 00:22:47 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 00:22:47 visual_prompt]: Training with config:
[09/26 00:22:47 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-cifar(num_classes=100)/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr5.0_wd0.01/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 5.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-cifar(num_classes=100)', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 100, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 00:22:47 visual_prompt]: Loading training data...
[09/26 00:22:47 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[:800], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/26 00:22:48 visual_prompt]: Number of images: 800
[09/26 00:22:48 visual_prompt]: Number of classes: 100 / 100
[09/26 00:22:48 visual_prompt]: Loading validation data...
[09/26 00:22:48 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[45000:45200], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/26 00:22:48 visual_prompt]: Number of images: 200
[09/26 00:22:48 visual_prompt]: Number of classes: 90 / 100
[09/26 00:22:48 visual_prompt]: Constructing models...
[09/26 00:22:51 visual_prompt]: Total Parameters: 86336356	 Gradient Parameters: 537700
[09/26 00:22:51 visual_prompt]: tuned percent:0.623
[09/26 00:22:51 visual_prompt]: Device used for model: 0
[09/26 00:22:51 visual_prompt]: Setting up Evaluator...
[09/26 00:22:51 visual_prompt]: Setting up Trainer...
[09/26 00:22:51 visual_prompt]: 	Setting up the optimizer...
[09/26 00:22:51 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 00:22:58 visual_prompt]: Epoch 1 / 100: avg data time: 6.27e-02, avg batch time: 0.5030, average train loss: 4.6594
[09/26 00:22:59 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1660, average loss: 4.6218
[09/26 00:22:59 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 7.00	
[09/26 00:22:59 visual_prompt]: Best epoch 1: best metric: 0.010
[09/26 00:22:59 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.5
[09/26 00:23:06 visual_prompt]: Epoch 2 / 100: avg data time: 4.29e-02, avg batch time: 0.4851, average train loss: 4.6487
[09/26 00:23:07 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1658, average loss: 4.6580
[09/26 00:23:07 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 8.00	
[09/26 00:23:07 visual_prompt]: Best epoch 2: best metric: 0.020
[09/26 00:23:07 visual_prompt]: Training 3 / 100 epoch, with learning rate 1.0
[09/26 00:23:14 visual_prompt]: Epoch 3 / 100: avg data time: 5.64e-02, avg batch time: 0.4967, average train loss: 4.6609
[09/26 00:23:15 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1657, average loss: 4.6389
[09/26 00:23:15 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.50	
[09/26 00:23:15 visual_prompt]: Training 4 / 100 epoch, with learning rate 1.5
[09/26 00:23:22 visual_prompt]: Epoch 4 / 100: avg data time: 5.51e-02, avg batch time: 0.4959, average train loss: 4.6653
[09/26 00:23:24 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1658, average loss: 4.6377
[09/26 00:23:24 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 7.00	
[09/26 00:23:24 visual_prompt]: Training 5 / 100 epoch, with learning rate 2.0
[09/26 00:23:30 visual_prompt]: Epoch 5 / 100: avg data time: 5.73e-02, avg batch time: 0.4982, average train loss: 4.6988
[09/26 00:23:32 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1659, average loss: 4.6909
[09/26 00:23:32 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 6.00	
[09/26 00:23:32 visual_prompt]: Training 6 / 100 epoch, with learning rate 2.5
[09/26 00:23:39 visual_prompt]: Epoch 6 / 100: avg data time: 4.34e-02, avg batch time: 0.4868, average train loss: 4.6836
[09/26 00:23:40 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1661, average loss: 5.1104
[09/26 00:23:40 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.50	
[09/26 00:23:40 visual_prompt]: Training 7 / 100 epoch, with learning rate 3.0
[09/26 00:23:47 visual_prompt]: Epoch 7 / 100: avg data time: 5.37e-02, avg batch time: 0.4939, average train loss: 4.8198
[09/26 00:23:48 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1660, average loss: 4.9043
[09/26 00:23:48 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 4.50	
[09/26 00:23:48 visual_prompt]: Training 8 / 100 epoch, with learning rate 3.5
[09/26 00:23:55 visual_prompt]: Epoch 8 / 100: avg data time: 5.56e-02, avg batch time: 0.4958, average train loss: 4.8098
[09/26 00:23:56 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1654, average loss: 4.7448
[09/26 00:23:56 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.00	top5: 4.00	
[09/26 00:23:56 visual_prompt]: Training 9 / 100 epoch, with learning rate 4.0
[09/26 00:24:03 visual_prompt]: Epoch 9 / 100: avg data time: 6.45e-02, avg batch time: 0.5043, average train loss: 4.8659
[09/26 00:24:05 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1657, average loss: 4.8374
[09/26 00:24:05 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 4.00	
[09/26 00:24:05 visual_prompt]: Training 10 / 100 epoch, with learning rate 4.5
[09/26 00:24:11 visual_prompt]: Epoch 10 / 100: avg data time: 5.06e-02, avg batch time: 0.4925, average train loss: 4.8546
[09/26 00:24:13 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1659, average loss: 4.8060
[09/26 00:24:13 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.00	
[09/26 00:24:13 visual_prompt]: Training 11 / 100 epoch, with learning rate 5.0
[09/26 00:24:20 visual_prompt]: Epoch 11 / 100: avg data time: 5.80e-02, avg batch time: 0.4996, average train loss: 4.8953
[09/26 00:24:21 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1657, average loss: 5.1156
[09/26 00:24:21 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/26 00:24:21 visual_prompt]: Training 12 / 100 epoch, with learning rate 4.998477067547739
[09/26 00:24:28 visual_prompt]: Epoch 12 / 100: avg data time: 5.42e-02, avg batch time: 0.4948, average train loss: 4.8878
[09/26 00:24:29 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1662, average loss: 5.2198
[09/26 00:24:29 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 7.00	
[09/26 00:24:29 visual_prompt]: Training 13 / 100 epoch, with learning rate 4.993910125649561
[09/26 00:24:36 visual_prompt]: Epoch 13 / 100: avg data time: 5.21e-02, avg batch time: 0.4945, average train loss: 4.9499
[09/26 00:24:38 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1661, average loss: 4.9743
[09/26 00:24:38 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 3.00	
[09/26 00:24:38 visual_prompt]: Training 14 / 100 epoch, with learning rate 4.986304738420683
[09/26 00:24:44 visual_prompt]: Epoch 14 / 100: avg data time: 5.95e-02, avg batch time: 0.5011, average train loss: 5.0504
[09/26 00:24:46 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1663, average loss: 5.0470
[09/26 00:24:46 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 3.50	
[09/26 00:24:46 visual_prompt]: Training 15 / 100 epoch, with learning rate 4.975670171853926
[09/26 00:24:53 visual_prompt]: Epoch 15 / 100: avg data time: 5.06e-02, avg batch time: 0.4928, average train loss: 5.1621
[09/26 00:24:54 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1660, average loss: 5.0133
[09/26 00:24:54 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 4.50	
[09/26 00:24:54 visual_prompt]: Training 16 / 100 epoch, with learning rate 4.962019382530521
[09/26 00:25:01 visual_prompt]: Epoch 16 / 100: avg data time: 4.78e-02, avg batch time: 0.4904, average train loss: 5.2166
[09/26 00:25:02 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1660, average loss: 5.0324
[09/26 00:25:02 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 5.00	
[09/26 00:25:02 visual_prompt]: Training 17 / 100 epoch, with learning rate 4.945369001834514
[09/26 00:25:09 visual_prompt]: Epoch 17 / 100: avg data time: 4.93e-02, avg batch time: 0.4935, average train loss: 5.1274
[09/26 00:25:10 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1659, average loss: 4.9919
[09/26 00:25:10 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.00	
[09/26 00:25:10 visual_prompt]: Training 18 / 100 epoch, with learning rate 4.925739315689991
[09/26 00:25:17 visual_prompt]: Epoch 18 / 100: avg data time: 5.18e-02, avg batch time: 0.4929, average train loss: 5.3182
[09/26 00:25:19 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1661, average loss: 5.0779
[09/26 00:25:19 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.00	top5: 4.00	
[09/26 00:25:19 visual_prompt]: Training 19 / 100 epoch, with learning rate 4.903154239845797
[09/26 00:25:25 visual_prompt]: Epoch 19 / 100: avg data time: 6.31e-02, avg batch time: 0.5040, average train loss: 5.1335
[09/26 00:25:27 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1664, average loss: 5.2019
[09/26 00:25:27 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 4.50	
[09/26 00:25:27 visual_prompt]: Training 20 / 100 epoch, with learning rate 4.877641290737884
[09/26 00:25:34 visual_prompt]: Epoch 20 / 100: avg data time: 5.78e-02, avg batch time: 0.5008, average train loss: 5.2634
[09/26 00:25:35 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1664, average loss: 4.9636
[09/26 00:25:35 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.00	
[09/26 00:25:35 visual_prompt]: Training 21 / 100 epoch, with learning rate 4.849231551964771
[09/26 00:25:42 visual_prompt]: Epoch 21 / 100: avg data time: 5.04e-02, avg batch time: 0.4919, average train loss: 4.9959
[09/26 00:25:43 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1661, average loss: 4.9747
[09/26 00:25:43 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 6.50	
[09/26 00:25:43 visual_prompt]: Training 22 / 100 epoch, with learning rate 4.817959636416969
[09/26 00:25:50 visual_prompt]: Epoch 22 / 100: avg data time: 5.40e-02, avg batch time: 0.4964, average train loss: 5.1255
[09/26 00:25:52 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1660, average loss: 4.9510
[09/26 00:25:52 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.50	
[09/26 00:25:52 visual_prompt]: Training 23 / 100 epoch, with learning rate 4.783863644106502
[09/26 00:25:58 visual_prompt]: Epoch 23 / 100: avg data time: 4.89e-02, avg batch time: 0.4910, average train loss: 4.9975
[09/26 00:26:00 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1660, average loss: 4.9217
[09/26 00:26:00 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.00	
[09/26 00:26:00 visual_prompt]: Training 24 / 100 epoch, with learning rate 4.7469851157479175
[09/26 00:26:06 visual_prompt]: Epoch 24 / 100: avg data time: 4.83e-02, avg batch time: 0.4913, average train loss: 4.9077
[09/26 00:26:08 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1661, average loss: 6.0537
[09/26 00:26:08 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 4.50	
[09/26 00:26:08 visual_prompt]: Training 25 / 100 epoch, with learning rate 4.707368982147317
[09/26 00:26:15 visual_prompt]: Epoch 25 / 100: avg data time: 5.86e-02, avg batch time: 0.5005, average train loss: 5.1560
[09/26 00:26:16 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1661, average loss: 5.4325
[09/26 00:26:16 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 3.50	
[09/26 00:26:16 visual_prompt]: Training 26 / 100 epoch, with learning rate 4.665063509461097
[09/26 00:26:23 visual_prompt]: Epoch 26 / 100: avg data time: 5.25e-02, avg batch time: 0.4938, average train loss: 5.1355
[09/26 00:26:24 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1658, average loss: 5.0463
[09/26 00:26:24 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.00	
[09/26 00:26:24 visual_prompt]: Training 27 / 100 epoch, with learning rate 4.620120240391064
[09/26 00:26:31 visual_prompt]: Epoch 27 / 100: avg data time: 4.16e-02, avg batch time: 0.4848, average train loss: 5.0357
[09/26 00:26:32 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1662, average loss: 5.1555
[09/26 00:26:32 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 7.50	
[09/26 00:26:32 visual_prompt]: Training 28 / 100 epoch, with learning rate 4.572593931387604
[09/26 00:26:39 visual_prompt]: Epoch 28 / 100: avg data time: 5.43e-02, avg batch time: 0.4961, average train loss: 5.1525
[09/26 00:26:41 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1661, average loss: 5.2339
[09/26 00:26:41 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 6.00	
[09/26 00:26:41 visual_prompt]: Training 29 / 100 epoch, with learning rate 4.522542485937368
[09/26 00:26:47 visual_prompt]: Epoch 29 / 100: avg data time: 4.95e-02, avg batch time: 0.4908, average train loss: 5.1282
[09/26 00:26:49 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1664, average loss: 5.0254
[09/26 00:26:49 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 9.00	
[09/26 00:26:49 visual_prompt]: Training 30 / 100 epoch, with learning rate 4.4700268840168045
[09/26 00:26:55 visual_prompt]: Epoch 30 / 100: avg data time: 5.18e-02, avg batch time: 0.4940, average train loss: 4.9515
[09/26 00:26:57 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1662, average loss: 4.9961
[09/26 00:26:57 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/26 00:26:57 visual_prompt]: Training 31 / 100 epoch, with learning rate 4.415111107797445
[09/26 00:27:03 visual_prompt]: Epoch 31 / 100: avg data time: 5.34e-02, avg batch time: 0.4943, average train loss: 4.9267
[09/26 00:27:05 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1662, average loss: 5.0351
[09/26 00:27:05 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 6.00	
[09/26 00:27:05 visual_prompt]: Training 32 / 100 epoch, with learning rate 4.357862063693486
[09/26 00:27:12 visual_prompt]: Epoch 32 / 100: avg data time: 5.71e-02, avg batch time: 0.4981, average train loss: 5.0387
[09/26 00:27:13 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1664, average loss: 4.7520
[09/26 00:27:13 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 5.00	
[09/26 00:27:13 visual_prompt]: Training 33 / 100 epoch, with learning rate 4.298349500846628
[09/26 00:27:20 visual_prompt]: Epoch 33 / 100: avg data time: 5.36e-02, avg batch time: 0.4948, average train loss: 4.8724
[09/26 00:27:21 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1661, average loss: 4.8217
[09/26 00:27:21 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 4.00	
[09/26 00:27:21 visual_prompt]: Training 34 / 100 epoch, with learning rate 4.236645926147493
[09/26 00:27:28 visual_prompt]: Epoch 34 / 100: avg data time: 6.00e-02, avg batch time: 0.5017, average train loss: 4.8396
[09/26 00:27:30 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1659, average loss: 4.8802
[09/26 00:27:30 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/26 00:27:30 visual_prompt]: Training 35 / 100 epoch, with learning rate 4.172826515897146
[09/26 00:27:37 visual_prompt]: Epoch 35 / 100: avg data time: 6.31e-02, avg batch time: 0.5041, average train loss: 4.9019
[09/26 00:27:38 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1661, average loss: 4.8637
[09/26 00:27:38 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 7.00	
[09/26 00:27:38 visual_prompt]: Training 36 / 100 epoch, with learning rate 4.106969024216348
[09/26 00:27:45 visual_prompt]: Epoch 36 / 100: avg data time: 5.97e-02, avg batch time: 0.5024, average train loss: 4.8914
[09/26 00:27:46 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1661, average loss: 4.8125
[09/26 00:27:46 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 6.50	
[09/26 00:27:46 visual_prompt]: Training 37 / 100 epoch, with learning rate 4.039153688314146
[09/26 00:27:53 visual_prompt]: Epoch 37 / 100: avg data time: 4.23e-02, avg batch time: 0.4840, average train loss: 4.7904
[09/26 00:27:54 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1661, average loss: 5.0054
[09/26 00:27:54 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/26 00:27:54 visual_prompt]: Training 38 / 100 epoch, with learning rate 3.969463130731183
[09/26 00:28:01 visual_prompt]: Epoch 38 / 100: avg data time: 5.55e-02, avg batch time: 0.4964, average train loss: 4.8837
[09/26 00:28:03 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1662, average loss: 7.6433
[09/26 00:28:03 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 6.50	
[09/26 00:28:03 visual_prompt]: Training 39 / 100 epoch, with learning rate 3.897982258676867
[09/26 00:28:09 visual_prompt]: Epoch 39 / 100: avg data time: 5.47e-02, avg batch time: 0.4981, average train loss: 5.7689
[09/26 00:28:11 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1663, average loss: 5.3328
[09/26 00:28:11 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.00	
[09/26 00:28:11 visual_prompt]: Training 40 / 100 epoch, with learning rate 3.824798160583012
[09/26 00:28:18 visual_prompt]: Epoch 40 / 100: avg data time: 5.43e-02, avg batch time: 0.4950, average train loss: 5.3105
[09/26 00:28:19 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1661, average loss: 5.2297
[09/26 00:28:19 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.50	
[09/26 00:28:19 visual_prompt]: Training 41 / 100 epoch, with learning rate 3.75
[09/26 00:28:26 visual_prompt]: Epoch 41 / 100: avg data time: 5.41e-02, avg batch time: 0.4953, average train loss: 5.3530
[09/26 00:28:27 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1662, average loss: 5.1477
[09/26 00:28:27 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 4.50	
[09/26 00:28:27 visual_prompt]: Training 42 / 100 epoch, with learning rate 3.673678906964727
[09/26 00:28:34 visual_prompt]: Epoch 42 / 100: avg data time: 5.42e-02, avg batch time: 0.4961, average train loss: 5.1676
[09/26 00:28:36 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1663, average loss: 4.9643
[09/26 00:28:36 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 8.00	
[09/26 00:28:36 visual_prompt]: Training 43 / 100 epoch, with learning rate 3.5959278669726933
[09/26 00:28:42 visual_prompt]: Epoch 43 / 100: avg data time: 5.86e-02, avg batch time: 0.4990, average train loss: 5.0629
[09/26 00:28:44 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1661, average loss: 4.9330
[09/26 00:28:44 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 7.00	
[09/26 00:28:44 visual_prompt]: Training 44 / 100 epoch, with learning rate 3.516841607689501
[09/26 00:28:50 visual_prompt]: Epoch 44 / 100: avg data time: 4.27e-02, avg batch time: 0.4857, average train loss: 5.0859
[09/26 00:28:52 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1663, average loss: 4.7757
[09/26 00:28:52 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.00	
[09/26 00:28:52 visual_prompt]: Training 45 / 100 epoch, with learning rate 3.4365164835397803
[09/26 00:28:59 visual_prompt]: Epoch 45 / 100: avg data time: 5.56e-02, avg batch time: 0.4977, average train loss: 5.0530
[09/26 00:29:00 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1662, average loss: 4.8880
[09/26 00:29:00 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 3.50	
[09/26 00:29:00 visual_prompt]: Training 46 / 100 epoch, with learning rate 3.3550503583141724
[09/26 00:29:07 visual_prompt]: Epoch 46 / 100: avg data time: 4.69e-02, avg batch time: 0.4883, average train loss: 5.1202
[09/26 00:29:08 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1659, average loss: 5.0593
[09/26 00:29:08 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.00	
[09/26 00:29:08 visual_prompt]: Training 47 / 100 epoch, with learning rate 3.2725424859373686
[09/26 00:29:15 visual_prompt]: Epoch 47 / 100: avg data time: 4.27e-02, avg batch time: 0.4846, average train loss: 5.4014
[09/26 00:29:16 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1658, average loss: 5.3101
[09/26 00:29:16 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 3.50	
[09/26 00:29:16 visual_prompt]: Training 48 / 100 epoch, with learning rate 3.1890933895424975
[09/26 00:29:23 visual_prompt]: Epoch 48 / 100: avg data time: 5.62e-02, avg batch time: 0.4978, average train loss: 5.4072
[09/26 00:29:24 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1660, average loss: 5.0323
[09/26 00:29:24 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 6.50	
[09/26 00:29:24 visual_prompt]: Training 49 / 100 epoch, with learning rate 3.104804738999169
[09/26 00:29:31 visual_prompt]: Epoch 49 / 100: avg data time: 5.25e-02, avg batch time: 0.4940, average train loss: 5.3355
[09/26 00:29:33 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1665, average loss: 5.0808
[09/26 00:29:33 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.50	
[09/26 00:29:33 visual_prompt]: Training 50 / 100 epoch, with learning rate 3.019779227044398
[09/26 00:29:39 visual_prompt]: Epoch 50 / 100: avg data time: 5.15e-02, avg batch time: 0.4935, average train loss: 5.2091
[09/26 00:29:41 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1664, average loss: 5.0006
[09/26 00:29:41 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 5.00	
[09/26 00:29:41 visual_prompt]: Training 51 / 100 epoch, with learning rate 2.934120444167326
[09/26 00:29:48 visual_prompt]: Epoch 51 / 100: avg data time: 5.55e-02, avg batch time: 0.4975, average train loss: 5.0763
[09/26 00:29:49 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1663, average loss: 4.8393
[09/26 00:29:49 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.50	
[09/26 00:29:49 visual_prompt]: Training 52 / 100 epoch, with learning rate 2.8479327524001636
[09/26 00:29:56 visual_prompt]: Epoch 52 / 100: avg data time: 5.36e-02, avg batch time: 0.4964, average train loss: 4.9911
[09/26 00:29:57 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1663, average loss: 4.7912
[09/26 00:29:57 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 5.00	
[09/26 00:29:57 visual_prompt]: Training 53 / 100 epoch, with learning rate 2.761321158169134
[09/26 00:30:04 visual_prompt]: Epoch 53 / 100: avg data time: 4.53e-02, avg batch time: 0.4889, average train loss: 4.8993
[09/26 00:30:05 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1661, average loss: 4.7186
[09/26 00:30:05 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 6.00	
[09/26 00:30:05 visual_prompt]: Training 54 / 100 epoch, with learning rate 2.6743911843603128
[09/26 00:30:12 visual_prompt]: Epoch 54 / 100: avg data time: 5.15e-02, avg batch time: 0.4945, average train loss: 4.7825
[09/26 00:30:14 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1665, average loss: 4.7819
[09/26 00:30:14 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.00	
[09/26 00:30:14 visual_prompt]: Training 55 / 100 epoch, with learning rate 2.5872487417562526
[09/26 00:30:20 visual_prompt]: Epoch 55 / 100: avg data time: 5.31e-02, avg batch time: 0.4947, average train loss: 4.7389
[09/26 00:30:22 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1663, average loss: 4.7130
[09/26 00:30:22 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 4.00	
[09/26 00:30:22 visual_prompt]: Training 56 / 100 epoch, with learning rate 2.5
[09/26 00:30:28 visual_prompt]: Epoch 56 / 100: avg data time: 4.43e-02, avg batch time: 0.4861, average train loss: 4.7875
[09/26 00:30:30 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1663, average loss: 4.7383
[09/26 00:30:30 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 6.00	
[09/26 00:30:30 visual_prompt]: Training 57 / 100 epoch, with learning rate 2.4127512582437483
[09/26 00:30:36 visual_prompt]: Epoch 57 / 100: avg data time: 5.70e-02, avg batch time: 0.4997, average train loss: 4.7843
[09/26 00:30:38 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1663, average loss: 4.8236
[09/26 00:30:38 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.50	
[09/26 00:30:38 visual_prompt]: Training 58 / 100 epoch, with learning rate 2.325608815639687
[09/26 00:30:45 visual_prompt]: Epoch 58 / 100: avg data time: 5.00e-02, avg batch time: 0.4928, average train loss: 4.7656
[09/26 00:30:46 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1664, average loss: 4.7273
[09/26 00:30:46 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.00	
[09/26 00:30:46 visual_prompt]: Training 59 / 100 epoch, with learning rate 2.2386788418308665
[09/26 00:30:53 visual_prompt]: Epoch 59 / 100: avg data time: 4.88e-02, avg batch time: 0.4931, average train loss: 4.7212
[09/26 00:30:54 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1663, average loss: 4.6997
[09/26 00:30:54 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 7.50	
[09/26 00:30:54 visual_prompt]: Training 60 / 100 epoch, with learning rate 2.1520672475998373
[09/26 00:31:01 visual_prompt]: Epoch 60 / 100: avg data time: 6.58e-02, avg batch time: 0.5070, average train loss: 4.7265
[09/26 00:31:03 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1664, average loss: 4.6974
[09/26 00:31:03 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.50	
[09/26 00:31:03 visual_prompt]: Training 61 / 100 epoch, with learning rate 2.0658795558326744
[09/26 00:31:09 visual_prompt]: Epoch 61 / 100: avg data time: 5.37e-02, avg batch time: 0.4968, average train loss: 4.7058
[09/26 00:31:11 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1666, average loss: 6.0641
[09/26 00:31:11 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.00	top5: 4.00	
[09/26 00:31:11 visual_prompt]: Training 62 / 100 epoch, with learning rate 1.980220772955602
[09/26 00:31:18 visual_prompt]: Epoch 62 / 100: avg data time: 4.62e-02, avg batch time: 0.4892, average train loss: 4.8718
[09/26 00:31:19 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1665, average loss: 4.6455
[09/26 00:31:19 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 6.00	
[09/26 00:31:19 visual_prompt]: Training 63 / 100 epoch, with learning rate 1.895195261000831
[09/26 00:31:26 visual_prompt]: Epoch 63 / 100: avg data time: 5.46e-02, avg batch time: 0.4975, average train loss: 4.7647
[09/26 00:31:27 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1664, average loss: 4.7112
[09/26 00:31:27 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.50	
[09/26 00:31:27 visual_prompt]: Training 64 / 100 epoch, with learning rate 1.8109066104575022
[09/26 00:31:34 visual_prompt]: Epoch 64 / 100: avg data time: 4.85e-02, avg batch time: 0.4899, average train loss: 4.7084
[09/26 00:31:35 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1662, average loss: 4.7236
[09/26 00:31:35 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 3.50	
[09/26 00:31:35 visual_prompt]: Training 65 / 100 epoch, with learning rate 1.7274575140626316
[09/26 00:31:42 visual_prompt]: Epoch 65 / 100: avg data time: 5.32e-02, avg batch time: 0.4944, average train loss: 4.6775
[09/26 00:31:44 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1662, average loss: 4.6669
[09/26 00:31:44 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.00	
[09/26 00:31:44 visual_prompt]: Training 66 / 100 epoch, with learning rate 1.6449496416858285
[09/26 00:31:50 visual_prompt]: Epoch 66 / 100: avg data time: 5.76e-02, avg batch time: 0.5002, average train loss: 4.7019
[09/26 00:31:52 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1665, average loss: 4.7887
[09/26 00:31:52 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 6.00	
[09/26 00:31:52 visual_prompt]: Training 67 / 100 epoch, with learning rate 1.5634835164602199
[09/26 00:31:59 visual_prompt]: Epoch 67 / 100: avg data time: 5.87e-02, avg batch time: 0.5002, average train loss: 4.7099
[09/26 00:32:00 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1663, average loss: 4.6647
[09/26 00:32:00 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.00	top5: 5.50	
[09/26 00:32:00 visual_prompt]: Training 68 / 100 epoch, with learning rate 1.4831583923104998
[09/26 00:32:07 visual_prompt]: Epoch 68 / 100: avg data time: 5.53e-02, avg batch time: 0.4967, average train loss: 4.6681
[09/26 00:32:08 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1662, average loss: 4.8477
[09/26 00:32:08 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 6.00	
[09/26 00:32:08 visual_prompt]: Training 69 / 100 epoch, with learning rate 1.4040721330273063
[09/26 00:32:15 visual_prompt]: Epoch 69 / 100: avg data time: 4.17e-02, avg batch time: 0.4862, average train loss: 4.7092
[09/26 00:32:16 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1663, average loss: 4.7120
[09/26 00:32:16 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.00	
[09/26 00:32:16 visual_prompt]: Training 70 / 100 epoch, with learning rate 1.3263210930352738
[09/26 00:32:23 visual_prompt]: Epoch 70 / 100: avg data time: 5.40e-02, avg batch time: 0.4960, average train loss: 4.6950
[09/26 00:32:25 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1661, average loss: 4.6373
[09/26 00:32:25 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 3.50	
[09/26 00:32:25 visual_prompt]: Training 71 / 100 epoch, with learning rate 1.2500000000000004
[09/26 00:32:32 visual_prompt]: Epoch 71 / 100: avg data time: 5.81e-02, avg batch time: 0.4993, average train loss: 4.6480
[09/26 00:32:33 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1662, average loss: 4.6991
[09/26 00:32:33 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.50	
[09/26 00:32:33 visual_prompt]: Training 72 / 100 epoch, with learning rate 1.175201839416988
[09/26 00:32:40 visual_prompt]: Epoch 72 / 100: avg data time: 4.90e-02, avg batch time: 0.4914, average train loss: 4.6598
[09/26 00:32:41 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1661, average loss: 4.6878
[09/26 00:32:41 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 5.50	
[09/26 00:32:41 visual_prompt]: Training 73 / 100 epoch, with learning rate 1.1020177413231333
[09/26 00:32:48 visual_prompt]: Epoch 73 / 100: avg data time: 4.39e-02, avg batch time: 0.4867, average train loss: 4.6556
[09/26 00:32:49 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1660, average loss: 4.6439
[09/26 00:32:49 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 6.00	
[09/26 00:32:49 visual_prompt]: Training 74 / 100 epoch, with learning rate 1.0305368692688175
[09/26 00:32:56 visual_prompt]: Epoch 74 / 100: avg data time: 6.43e-02, avg batch time: 0.5055, average train loss: 4.6455
[09/26 00:32:58 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1663, average loss: 4.6501
[09/26 00:32:58 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.50	
[09/26 00:32:58 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.9608463116858543
[09/26 00:33:04 visual_prompt]: Epoch 75 / 100: avg data time: 4.70e-02, avg batch time: 0.4882, average train loss: 4.6283
[09/26 00:33:06 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1664, average loss: 4.6660
[09/26 00:33:06 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/26 00:33:06 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.8930309757836516
[09/26 00:33:12 visual_prompt]: Epoch 76 / 100: avg data time: 5.76e-02, avg batch time: 0.4993, average train loss: 4.6298
[09/26 00:33:14 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1663, average loss: 4.6769
[09/26 00:33:14 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 3.50	
[09/26 00:33:14 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.8271734841028553
[09/26 00:33:21 visual_prompt]: Epoch 77 / 100: avg data time: 5.47e-02, avg batch time: 0.4967, average train loss: 4.6187
[09/26 00:33:22 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1661, average loss: 4.6531
[09/26 00:33:22 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.00	
[09/26 00:33:22 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.7633540738525066
[09/26 00:33:29 visual_prompt]: Epoch 78 / 100: avg data time: 5.43e-02, avg batch time: 0.4953, average train loss: 4.5897
[09/26 00:33:30 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1659, average loss: 4.6399
[09/26 00:33:30 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 3.50	
[09/26 00:33:30 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.7016504991533725
[09/26 00:33:37 visual_prompt]: Epoch 79 / 100: avg data time: 5.49e-02, avg batch time: 0.4962, average train loss: 4.5882
[09/26 00:33:38 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1659, average loss: 4.6553
[09/26 00:33:38 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 4.00	
[09/26 00:33:38 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.6421379363065141
[09/26 00:33:45 visual_prompt]: Epoch 80 / 100: avg data time: 4.56e-02, avg batch time: 0.4897, average train loss: 4.5835
[09/26 00:33:47 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1663, average loss: 4.7328
[09/26 00:33:47 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 3.50	
[09/26 00:33:47 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.5848888922025552
[09/26 00:33:53 visual_prompt]: Epoch 81 / 100: avg data time: 5.71e-02, avg batch time: 0.4993, average train loss: 4.6242
[09/26 00:33:55 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1661, average loss: 4.6442
[09/26 00:33:55 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.00	
[09/26 00:33:55 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.5299731159831953
[09/26 00:34:02 visual_prompt]: Epoch 82 / 100: avg data time: 5.41e-02, avg batch time: 0.4959, average train loss: 4.6079
[09/26 00:34:03 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1663, average loss: 4.6381
[09/26 00:34:03 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 4.00	
[09/26 00:34:03 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.47745751406263165
[09/26 00:34:10 visual_prompt]: Epoch 83 / 100: avg data time: 4.60e-02, avg batch time: 0.4898, average train loss: 4.5837
[09/26 00:34:11 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1663, average loss: 4.6691
[09/26 00:34:11 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.00	
[09/26 00:34:11 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.42740606861239594
[09/26 00:34:18 visual_prompt]: Epoch 84 / 100: avg data time: 4.69e-02, avg batch time: 0.4893, average train loss: 4.5934
[09/26 00:34:19 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1661, average loss: 4.6869
[09/26 00:34:19 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 5.00	
[09/26 00:34:19 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.3798797596089351
[09/26 00:34:26 visual_prompt]: Epoch 85 / 100: avg data time: 5.36e-02, avg batch time: 0.4958, average train loss: 4.5979
[09/26 00:34:28 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1661, average loss: 4.6468
[09/26 00:34:28 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.00	
[09/26 00:34:28 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.33493649053890323
[09/26 00:34:34 visual_prompt]: Epoch 86 / 100: avg data time: 6.03e-02, avg batch time: 0.5015, average train loss: 4.5851
[09/26 00:34:36 visual_prompt]: Inference (val):avg data time: 3.89e-05, avg batch time: 0.1662, average loss: 4.6412
[09/26 00:34:36 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.00	
[09/26 00:34:36 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.29263101785268253
[09/26 00:34:43 visual_prompt]: Epoch 87 / 100: avg data time: 5.30e-02, avg batch time: 0.4954, average train loss: 4.5836
[09/26 00:34:44 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1661, average loss: 4.6433
[09/26 00:34:44 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 3.50	
[09/26 00:34:44 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.25301488425208296
[09/26 00:34:51 visual_prompt]: Epoch 88 / 100: avg data time: 5.18e-02, avg batch time: 0.4926, average train loss: 4.5717
[09/26 00:34:52 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1662, average loss: 4.6326
[09/26 00:34:52 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.50	
[09/26 00:34:52 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.21613635589349756
[09/26 00:34:59 visual_prompt]: Epoch 89 / 100: avg data time: 5.25e-02, avg batch time: 0.4946, average train loss: 4.5654
[09/26 00:35:01 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1660, average loss: 4.6274
[09/26 00:35:01 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.50	
[09/26 00:35:01 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.18204036358303172
[09/26 00:35:07 visual_prompt]: Epoch 90 / 100: avg data time: 5.51e-02, avg batch time: 0.4959, average train loss: 4.5494
[09/26 00:35:09 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1662, average loss: 4.6213
[09/26 00:35:09 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.00	
[09/26 00:35:09 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.1507684480352292
[09/26 00:35:15 visual_prompt]: Epoch 91 / 100: avg data time: 5.47e-02, avg batch time: 0.4962, average train loss: 4.5422
[09/26 00:35:17 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1661, average loss: 4.6060
[09/26 00:35:17 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 6.00	
[09/26 00:35:17 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.12235870926211617
[09/26 00:35:24 visual_prompt]: Epoch 92 / 100: avg data time: 4.42e-02, avg batch time: 0.4852, average train loss: 4.5511
[09/26 00:35:25 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.1660, average loss: 4.6234
[09/26 00:35:25 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 4.00	
[09/26 00:35:25 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.09684576015420276
[09/26 00:35:32 visual_prompt]: Epoch 93 / 100: avg data time: 6.48e-02, avg batch time: 0.5055, average train loss: 4.5203
[09/26 00:35:33 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1660, average loss: 4.5904
[09/26 00:35:33 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 5.50	
[09/26 00:35:33 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.07426068431000882
[09/26 00:35:40 visual_prompt]: Epoch 94 / 100: avg data time: 4.82e-02, avg batch time: 0.4906, average train loss: 4.4879
[09/26 00:35:42 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1662, average loss: 4.5748
[09/26 00:35:42 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 11.00	
[09/26 00:35:42 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.05463099816548578
[09/26 00:35:48 visual_prompt]: Epoch 95 / 100: avg data time: 5.31e-02, avg batch time: 0.4951, average train loss: 4.4222
[09/26 00:35:50 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1662, average loss: 4.6935
[09/26 00:35:50 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 9.00	
[09/26 00:35:50 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.03798061746947995
[09/26 00:35:57 visual_prompt]: Epoch 96 / 100: avg data time: 5.70e-02, avg batch time: 0.4986, average train loss: 4.4088
[09/26 00:35:58 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1660, average loss: 4.5339
[09/26 00:35:58 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 3.00	top5: 9.50	
[09/26 00:35:58 visual_prompt]: Best epoch 96: best metric: 0.030
[09/26 00:35:58 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.024329828146074095
[09/26 00:36:05 visual_prompt]: Epoch 97 / 100: avg data time: 4.63e-02, avg batch time: 0.4889, average train loss: 4.3295
[09/26 00:36:06 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1661, average loss: 4.4932
[09/26 00:36:06 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 12.00	
[09/26 00:36:06 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.013695261579316775
[09/26 00:36:13 visual_prompt]: Epoch 98 / 100: avg data time: 5.07e-02, avg batch time: 0.4927, average train loss: 4.2665
[09/26 00:36:14 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1662, average loss: 4.4874
[09/26 00:36:14 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 12.00	
[09/26 00:36:14 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.006089874350439506
[09/26 00:36:21 visual_prompt]: Epoch 99 / 100: avg data time: 5.27e-02, avg batch time: 0.4947, average train loss: 4.2287
[09/26 00:36:22 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1661, average loss: 4.4708
[09/26 00:36:22 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 12.50	
[09/26 00:36:22 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0015229324522605947
[09/26 00:36:29 visual_prompt]: Epoch 100 / 100: avg data time: 5.73e-02, avg batch time: 0.5005, average train loss: 4.2059
[09/26 00:36:31 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1662, average loss: 4.4654
[09/26 00:36:31 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 13.50	
[09/26 00:36:31 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 00:36:31 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 00:36:31 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-cifar(num_classes=100)', 'DATA.NUMBER_CLASSES', '100', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 00:36:31 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 00:36:31 visual_prompt]: Training with config:
[09/26 00:36:31 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-cifar(num_classes=100)/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr5.0_wd0.001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 5.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-cifar(num_classes=100)', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 100, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 00:36:31 visual_prompt]: Loading training data...
[09/26 00:36:31 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[:800], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/26 00:36:32 visual_prompt]: Number of images: 800
[09/26 00:36:32 visual_prompt]: Number of classes: 100 / 100
[09/26 00:36:32 visual_prompt]: Loading validation data...
[09/26 00:36:32 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[45000:45200], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/26 00:36:32 visual_prompt]: Number of images: 200
[09/26 00:36:32 visual_prompt]: Number of classes: 90 / 100
[09/26 00:36:32 visual_prompt]: Constructing models...
[09/26 00:36:35 visual_prompt]: Total Parameters: 86336356	 Gradient Parameters: 537700
[09/26 00:36:35 visual_prompt]: tuned percent:0.623
[09/26 00:36:35 visual_prompt]: Device used for model: 0
[09/26 00:36:35 visual_prompt]: Setting up Evaluator...
[09/26 00:36:35 visual_prompt]: Setting up Trainer...
[09/26 00:36:35 visual_prompt]: 	Setting up the optimizer...
[09/26 00:36:35 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 00:36:41 visual_prompt]: Epoch 1 / 100: avg data time: 5.32e-02, avg batch time: 0.4963, average train loss: 4.6561
[09/26 00:36:43 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1659, average loss: 4.6218
[09/26 00:36:43 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 7.00	
[09/26 00:36:43 visual_prompt]: Best epoch 1: best metric: 0.010
[09/26 00:36:43 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.5
[09/26 00:36:50 visual_prompt]: Epoch 2 / 100: avg data time: 5.46e-02, avg batch time: 0.4954, average train loss: 4.6433
[09/26 00:36:51 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1660, average loss: 4.7014
[09/26 00:36:51 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.50	
[09/26 00:36:51 visual_prompt]: Training 3 / 100 epoch, with learning rate 1.0
[09/26 00:36:58 visual_prompt]: Epoch 3 / 100: avg data time: 6.37e-02, avg batch time: 0.5040, average train loss: 4.6490
[09/26 00:37:00 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1661, average loss: 4.6323
[09/26 00:37:00 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 8.50	
[09/26 00:37:00 visual_prompt]: Best epoch 3: best metric: 0.020
[09/26 00:37:00 visual_prompt]: Training 4 / 100 epoch, with learning rate 1.5
[09/26 00:37:06 visual_prompt]: Epoch 4 / 100: avg data time: 5.68e-02, avg batch time: 0.4985, average train loss: 4.6465
[09/26 00:37:08 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1662, average loss: 4.4879
[09/26 00:37:08 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.50	top5: 13.00	
[09/26 00:37:08 visual_prompt]: Best epoch 4: best metric: 0.025
[09/26 00:37:08 visual_prompt]: Training 5 / 100 epoch, with learning rate 2.0
[09/26 00:37:14 visual_prompt]: Epoch 5 / 100: avg data time: 5.49e-02, avg batch time: 0.4971, average train loss: 4.6811
[09/26 00:37:16 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1660, average loss: 4.7865
[09/26 00:37:16 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.00	
[09/26 00:37:16 visual_prompt]: Training 6 / 100 epoch, with learning rate 2.5
[09/26 00:37:23 visual_prompt]: Epoch 6 / 100: avg data time: 5.57e-02, avg batch time: 0.4962, average train loss: 4.8148
[09/26 00:37:24 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1660, average loss: 5.1443
[09/26 00:37:24 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 5.50	
[09/26 00:37:24 visual_prompt]: Training 7 / 100 epoch, with learning rate 3.0
[09/26 00:37:31 visual_prompt]: Epoch 7 / 100: avg data time: 4.30e-02, avg batch time: 0.4843, average train loss: 5.0551
[09/26 00:37:32 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1659, average loss: 5.6140
[09/26 00:37:32 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.00	
[09/26 00:37:32 visual_prompt]: Training 8 / 100 epoch, with learning rate 3.5
[09/26 00:37:39 visual_prompt]: Epoch 8 / 100: avg data time: 6.47e-02, avg batch time: 0.5054, average train loss: 5.3831
[09/26 00:37:40 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1659, average loss: 5.0829
[09/26 00:37:40 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 5.00	
[09/26 00:37:40 visual_prompt]: Training 9 / 100 epoch, with learning rate 4.0
[09/26 00:37:47 visual_prompt]: Epoch 9 / 100: avg data time: 4.76e-02, avg batch time: 0.4900, average train loss: 5.6325
[09/26 00:37:49 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1661, average loss: 5.6761
[09/26 00:37:49 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.00	top5: 4.50	
[09/26 00:37:49 visual_prompt]: Training 10 / 100 epoch, with learning rate 4.5
[09/26 00:37:55 visual_prompt]: Epoch 10 / 100: avg data time: 6.35e-02, avg batch time: 0.5033, average train loss: 6.7744
[09/26 00:37:57 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1657, average loss: 5.6162
[09/26 00:37:57 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.00	top5: 2.00	
[09/26 00:37:57 visual_prompt]: Training 11 / 100 epoch, with learning rate 5.0
[09/26 00:38:04 visual_prompt]: Epoch 11 / 100: avg data time: 4.90e-02, avg batch time: 0.4899, average train loss: 6.4816
[09/26 00:38:05 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1657, average loss: 5.8494
[09/26 00:38:05 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 4.50	
[09/26 00:38:05 visual_prompt]: Training 12 / 100 epoch, with learning rate 4.998477067547739
[09/26 00:38:12 visual_prompt]: Epoch 12 / 100: avg data time: 4.22e-02, avg batch time: 0.4842, average train loss: 5.8800
[09/26 00:38:13 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1659, average loss: 5.5276
[09/26 00:38:13 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.00	top5: 4.00	
[09/26 00:38:13 visual_prompt]: Training 13 / 100 epoch, with learning rate 4.993910125649561
[09/26 00:38:20 visual_prompt]: Epoch 13 / 100: avg data time: 5.65e-02, avg batch time: 0.4969, average train loss: 5.8253
[09/26 00:38:22 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1660, average loss: 5.4911
[09/26 00:38:22 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 5.50	
[09/26 00:38:22 visual_prompt]: Training 14 / 100 epoch, with learning rate 4.986304738420683
[09/26 00:38:28 visual_prompt]: Epoch 14 / 100: avg data time: 5.32e-02, avg batch time: 0.4936, average train loss: 6.9887
[09/26 00:38:30 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1659, average loss: 6.8885
[09/26 00:38:30 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 6.00	
[09/26 00:38:30 visual_prompt]: Training 15 / 100 epoch, with learning rate 4.975670171853926
[09/26 00:38:36 visual_prompt]: Epoch 15 / 100: avg data time: 5.05e-02, avg batch time: 0.4935, average train loss: 7.1989
[09/26 00:38:38 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1660, average loss: 7.1242
[09/26 00:38:38 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 7.00	
[09/26 00:38:38 visual_prompt]: Training 16 / 100 epoch, with learning rate 4.962019382530521
[09/26 00:38:45 visual_prompt]: Epoch 16 / 100: avg data time: 4.58e-02, avg batch time: 0.4891, average train loss: 6.4875
[09/26 00:38:46 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1660, average loss: 5.9122
[09/26 00:38:46 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.00	
[09/26 00:38:46 visual_prompt]: Training 17 / 100 epoch, with learning rate 4.945369001834514
[09/26 00:38:53 visual_prompt]: Epoch 17 / 100: avg data time: 5.62e-02, avg batch time: 0.4987, average train loss: 5.7180
[09/26 00:38:54 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1661, average loss: 5.6536
[09/26 00:38:54 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 6.00	
[09/26 00:38:54 visual_prompt]: Training 18 / 100 epoch, with learning rate 4.925739315689991
[09/26 00:39:01 visual_prompt]: Epoch 18 / 100: avg data time: 5.28e-02, avg batch time: 0.4946, average train loss: 5.7905
[09/26 00:39:03 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1661, average loss: 6.1952
[09/26 00:39:03 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 4.00	
[09/26 00:39:03 visual_prompt]: Training 19 / 100 epoch, with learning rate 4.903154239845797
[09/26 00:39:09 visual_prompt]: Epoch 19 / 100: avg data time: 5.82e-02, avg batch time: 0.4989, average train loss: 6.1299
[09/26 00:39:11 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1663, average loss: 6.1633
[09/26 00:39:11 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.00	
[09/26 00:39:11 visual_prompt]: Training 20 / 100 epoch, with learning rate 4.877641290737884
[09/26 00:39:18 visual_prompt]: Epoch 20 / 100: avg data time: 4.58e-02, avg batch time: 0.4890, average train loss: 6.3810
[09/26 00:39:19 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1658, average loss: 5.6550
[09/26 00:39:19 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 3.50	
[09/26 00:39:19 visual_prompt]: Training 21 / 100 epoch, with learning rate 4.849231551964771
[09/26 00:39:26 visual_prompt]: Epoch 21 / 100: avg data time: 5.63e-02, avg batch time: 0.4967, average train loss: 5.6385
[09/26 00:39:27 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1663, average loss: 5.1018
[09/26 00:39:27 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 7.50	
[09/26 00:39:27 visual_prompt]: Training 22 / 100 epoch, with learning rate 4.817959636416969
[09/26 00:39:34 visual_prompt]: Epoch 22 / 100: avg data time: 5.52e-02, avg batch time: 0.4973, average train loss: 5.2190
[09/26 00:39:35 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1660, average loss: 4.9531
[09/26 00:39:35 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.00	
[09/26 00:39:35 visual_prompt]: Training 23 / 100 epoch, with learning rate 4.783863644106502
[09/26 00:39:42 visual_prompt]: Epoch 23 / 100: avg data time: 4.43e-02, avg batch time: 0.4886, average train loss: 5.0368
[09/26 00:39:43 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1662, average loss: 4.9913
[09/26 00:39:43 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 3.00	
[09/26 00:39:43 visual_prompt]: Training 24 / 100 epoch, with learning rate 4.7469851157479175
[09/26 00:39:50 visual_prompt]: Epoch 24 / 100: avg data time: 5.58e-02, avg batch time: 0.4992, average train loss: 4.9804
[09/26 00:39:52 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1661, average loss: 4.8599
[09/26 00:39:52 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.50	
[09/26 00:39:52 visual_prompt]: Training 25 / 100 epoch, with learning rate 4.707368982147317
[09/26 00:39:59 visual_prompt]: Epoch 25 / 100: avg data time: 5.85e-02, avg batch time: 0.5006, average train loss: 4.9132
[09/26 00:40:00 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1660, average loss: 5.0160
[09/26 00:40:00 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 3.50	
[09/26 00:40:00 visual_prompt]: Training 26 / 100 epoch, with learning rate 4.665063509461097
[09/26 00:40:07 visual_prompt]: Epoch 26 / 100: avg data time: 5.41e-02, avg batch time: 0.4970, average train loss: 4.8696
[09/26 00:40:08 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1660, average loss: 4.8483
[09/26 00:40:08 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 4.50	
[09/26 00:40:08 visual_prompt]: Training 27 / 100 epoch, with learning rate 4.620120240391064
[09/26 00:40:15 visual_prompt]: Epoch 27 / 100: avg data time: 5.28e-02, avg batch time: 0.4942, average train loss: 4.8020
[09/26 00:40:16 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1661, average loss: 4.8615
[09/26 00:40:16 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 4.50	
[09/26 00:40:16 visual_prompt]: Training 28 / 100 epoch, with learning rate 4.572593931387604
[09/26 00:40:23 visual_prompt]: Epoch 28 / 100: avg data time: 4.27e-02, avg batch time: 0.4853, average train loss: 4.8671
[09/26 00:40:25 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1661, average loss: 4.8582
[09/26 00:40:25 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 5.50	
[09/26 00:40:25 visual_prompt]: Training 29 / 100 epoch, with learning rate 4.522542485937368
[09/26 00:40:31 visual_prompt]: Epoch 29 / 100: avg data time: 5.82e-02, avg batch time: 0.4986, average train loss: 4.8216
[09/26 00:40:33 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1661, average loss: 4.8260
[09/26 00:40:33 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 3.50	
[09/26 00:40:33 visual_prompt]: Training 30 / 100 epoch, with learning rate 4.4700268840168045
[09/26 00:40:40 visual_prompt]: Epoch 30 / 100: avg data time: 5.96e-02, avg batch time: 0.5014, average train loss: 4.8403
[09/26 00:40:41 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1660, average loss: 4.8375
[09/26 00:40:41 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 6.00	
[09/26 00:40:41 visual_prompt]: Training 31 / 100 epoch, with learning rate 4.415111107797445
[09/26 00:40:48 visual_prompt]: Epoch 31 / 100: avg data time: 5.79e-02, avg batch time: 0.4999, average train loss: 4.8213
[09/26 00:40:49 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1657, average loss: 4.9104
[09/26 00:40:49 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/26 00:40:49 visual_prompt]: Training 32 / 100 epoch, with learning rate 4.357862063693486
[09/26 00:40:56 visual_prompt]: Epoch 32 / 100: avg data time: 6.11e-02, avg batch time: 0.5016, average train loss: 4.8106
[09/26 00:40:58 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1660, average loss: 4.8231
[09/26 00:40:58 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 4.00	
[09/26 00:40:58 visual_prompt]: Training 33 / 100 epoch, with learning rate 4.298349500846628
[09/26 00:41:04 visual_prompt]: Epoch 33 / 100: avg data time: 4.88e-02, avg batch time: 0.4898, average train loss: 4.8029
[09/26 00:41:06 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1659, average loss: 5.0827
[09/26 00:41:06 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 4.00	
[09/26 00:41:06 visual_prompt]: Training 34 / 100 epoch, with learning rate 4.236645926147493
[09/26 00:41:13 visual_prompt]: Epoch 34 / 100: avg data time: 6.06e-02, avg batch time: 0.5021, average train loss: 4.8792
[09/26 00:41:14 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1660, average loss: 5.0936
[09/26 00:41:14 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 3.50	
[09/26 00:41:14 visual_prompt]: Training 35 / 100 epoch, with learning rate 4.172826515897146
[09/26 00:41:21 visual_prompt]: Epoch 35 / 100: avg data time: 4.77e-02, avg batch time: 0.4909, average train loss: 5.0131
[09/26 00:41:22 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1659, average loss: 4.9233
[09/26 00:41:22 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 6.50	
[09/26 00:41:22 visual_prompt]: Training 36 / 100 epoch, with learning rate 4.106969024216348
[09/26 00:41:29 visual_prompt]: Epoch 36 / 100: avg data time: 5.49e-02, avg batch time: 0.4969, average train loss: 4.9200
[09/26 00:41:31 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1662, average loss: 4.8023
[09/26 00:41:31 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.50	
[09/26 00:41:31 visual_prompt]: Training 37 / 100 epoch, with learning rate 4.039153688314146
[09/26 00:41:37 visual_prompt]: Epoch 37 / 100: avg data time: 4.23e-02, avg batch time: 0.4845, average train loss: 4.8037
[09/26 00:41:39 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1660, average loss: 4.7341
[09/26 00:41:39 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.00	
[09/26 00:41:39 visual_prompt]: Training 38 / 100 epoch, with learning rate 3.969463130731183
[09/26 00:41:46 visual_prompt]: Epoch 38 / 100: avg data time: 6.29e-02, avg batch time: 0.5033, average train loss: 4.7751
[09/26 00:41:47 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1659, average loss: 4.7611
[09/26 00:41:47 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 6.00	
[09/26 00:41:47 visual_prompt]: Training 39 / 100 epoch, with learning rate 3.897982258676867
[09/26 00:41:54 visual_prompt]: Epoch 39 / 100: avg data time: 5.76e-02, avg batch time: 0.5005, average train loss: 4.8166
[09/26 00:41:55 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1659, average loss: 5.3691
[09/26 00:41:55 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 5.00	
[09/26 00:41:55 visual_prompt]: Training 40 / 100 epoch, with learning rate 3.824798160583012
[09/26 00:42:02 visual_prompt]: Epoch 40 / 100: avg data time: 5.23e-02, avg batch time: 0.4930, average train loss: 4.9688
[09/26 00:42:04 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1661, average loss: 4.8159
[09/26 00:42:04 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.00	
[09/26 00:42:04 visual_prompt]: Training 41 / 100 epoch, with learning rate 3.75
[09/26 00:42:10 visual_prompt]: Epoch 41 / 100: avg data time: 4.99e-02, avg batch time: 0.4909, average train loss: 4.9468
[09/26 00:42:12 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1660, average loss: 4.9967
[09/26 00:42:12 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 6.00	
[09/26 00:42:12 visual_prompt]: Training 42 / 100 epoch, with learning rate 3.673678906964727
[09/26 00:42:19 visual_prompt]: Epoch 42 / 100: avg data time: 5.69e-02, avg batch time: 0.4986, average train loss: 5.0502
[09/26 00:42:20 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1661, average loss: 4.8642
[09/26 00:42:20 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 6.50	
[09/26 00:42:20 visual_prompt]: Training 43 / 100 epoch, with learning rate 3.5959278669726933
[09/26 00:42:27 visual_prompt]: Epoch 43 / 100: avg data time: 5.02e-02, avg batch time: 0.4928, average train loss: 4.9060
[09/26 00:42:28 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1663, average loss: 4.8557
[09/26 00:42:28 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 3.50	
[09/26 00:42:28 visual_prompt]: Training 44 / 100 epoch, with learning rate 3.516841607689501
[09/26 00:42:35 visual_prompt]: Epoch 44 / 100: avg data time: 5.92e-02, avg batch time: 0.5002, average train loss: 4.8801
[09/26 00:42:36 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1659, average loss: 4.9046
[09/26 00:42:36 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 5.00	
[09/26 00:42:36 visual_prompt]: Training 45 / 100 epoch, with learning rate 3.4365164835397803
[09/26 00:42:43 visual_prompt]: Epoch 45 / 100: avg data time: 5.19e-02, avg batch time: 0.4932, average train loss: 4.9307
[09/26 00:42:45 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1661, average loss: 5.1166
[09/26 00:42:45 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 7.00	
[09/26 00:42:45 visual_prompt]: Training 46 / 100 epoch, with learning rate 3.3550503583141724
[09/26 00:42:51 visual_prompt]: Epoch 46 / 100: avg data time: 5.73e-02, avg batch time: 0.4990, average train loss: 4.9161
[09/26 00:42:53 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1664, average loss: 4.8041
[09/26 00:42:53 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.00	
[09/26 00:42:53 visual_prompt]: Training 47 / 100 epoch, with learning rate 3.2725424859373686
[09/26 00:43:00 visual_prompt]: Epoch 47 / 100: avg data time: 5.34e-02, avg batch time: 0.4955, average train loss: 4.8804
[09/26 00:43:01 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1662, average loss: 4.7604
[09/26 00:43:01 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.00	
[09/26 00:43:01 visual_prompt]: Training 48 / 100 epoch, with learning rate 3.1890933895424975
[09/26 00:43:08 visual_prompt]: Epoch 48 / 100: avg data time: 5.41e-02, avg batch time: 0.4969, average train loss: 4.8178
[09/26 00:43:09 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1662, average loss: 4.8318
[09/26 00:43:09 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 4.50	
[09/26 00:43:09 visual_prompt]: Training 49 / 100 epoch, with learning rate 3.104804738999169
[09/26 00:43:16 visual_prompt]: Epoch 49 / 100: avg data time: 4.79e-02, avg batch time: 0.4888, average train loss: 4.8733
[09/26 00:43:17 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1661, average loss: 4.7706
[09/26 00:43:17 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 4.00	
[09/26 00:43:17 visual_prompt]: Training 50 / 100 epoch, with learning rate 3.019779227044398
[09/26 00:43:24 visual_prompt]: Epoch 50 / 100: avg data time: 5.61e-02, avg batch time: 0.4974, average train loss: 4.7722
[09/26 00:43:26 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1663, average loss: 4.8062
[09/26 00:43:26 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 4.00	
[09/26 00:43:26 visual_prompt]: Training 51 / 100 epoch, with learning rate 2.934120444167326
[09/26 00:43:32 visual_prompt]: Epoch 51 / 100: avg data time: 5.59e-02, avg batch time: 0.4976, average train loss: 4.7484
[09/26 00:43:34 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1661, average loss: 4.7266
[09/26 00:43:34 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.00	
[09/26 00:43:34 visual_prompt]: Training 52 / 100 epoch, with learning rate 2.8479327524001636
[09/26 00:43:41 visual_prompt]: Epoch 52 / 100: avg data time: 6.16e-02, avg batch time: 0.5029, average train loss: 4.7239
[09/26 00:43:42 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1662, average loss: 5.1935
[09/26 00:43:42 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 5.50	
[09/26 00:43:42 visual_prompt]: Training 53 / 100 epoch, with learning rate 2.761321158169134
[09/26 00:43:49 visual_prompt]: Epoch 53 / 100: avg data time: 5.80e-02, avg batch time: 0.5006, average train loss: 4.8199
[09/26 00:43:50 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1664, average loss: 4.8921
[09/26 00:43:50 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 7.50	
[09/26 00:43:50 visual_prompt]: Training 54 / 100 epoch, with learning rate 2.6743911843603128
[09/26 00:43:57 visual_prompt]: Epoch 54 / 100: avg data time: 5.77e-02, avg batch time: 0.4991, average train loss: 4.8585
[09/26 00:43:59 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1659, average loss: 4.8035
[09/26 00:43:59 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 6.50	
[09/26 00:43:59 visual_prompt]: Training 55 / 100 epoch, with learning rate 2.5872487417562526
[09/26 00:44:05 visual_prompt]: Epoch 55 / 100: avg data time: 5.93e-02, avg batch time: 0.5006, average train loss: 4.8363
[09/26 00:44:07 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1661, average loss: 4.6683
[09/26 00:44:07 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 6.50	
[09/26 00:44:07 visual_prompt]: Training 56 / 100 epoch, with learning rate 2.5
[09/26 00:44:14 visual_prompt]: Epoch 56 / 100: avg data time: 4.41e-02, avg batch time: 0.4861, average train loss: 4.7591
[09/26 00:44:15 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1662, average loss: 4.7407
[09/26 00:44:15 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 5.00	
[09/26 00:44:15 visual_prompt]: Training 57 / 100 epoch, with learning rate 2.4127512582437483
[09/26 00:44:22 visual_prompt]: Epoch 57 / 100: avg data time: 5.96e-02, avg batch time: 0.5012, average train loss: 4.6807
[09/26 00:44:23 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1664, average loss: 4.5747
[09/26 00:44:23 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 3.50	top5: 9.50	
[09/26 00:44:23 visual_prompt]: Best epoch 57: best metric: 0.035
[09/26 00:44:23 visual_prompt]: Training 58 / 100 epoch, with learning rate 2.325608815639687
[09/26 00:44:30 visual_prompt]: Epoch 58 / 100: avg data time: 5.64e-02, avg batch time: 0.4996, average train loss: 4.5594
[09/26 00:44:32 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1662, average loss: 4.6826
[09/26 00:44:32 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 10.00	
[09/26 00:44:32 visual_prompt]: Training 59 / 100 epoch, with learning rate 2.2386788418308665
[09/26 00:44:38 visual_prompt]: Epoch 59 / 100: avg data time: 5.49e-02, avg batch time: 0.4961, average train loss: 4.4867
[09/26 00:44:40 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1663, average loss: 4.6160
[09/26 00:44:40 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 8.00	
[09/26 00:44:40 visual_prompt]: Training 60 / 100 epoch, with learning rate 2.1520672475998373
[09/26 00:44:47 visual_prompt]: Epoch 60 / 100: avg data time: 5.44e-02, avg batch time: 0.4966, average train loss: 4.5395
[09/26 00:44:48 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1662, average loss: 4.5240
[09/26 00:44:48 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.50	top5: 9.50	
[09/26 00:44:48 visual_prompt]: Training 61 / 100 epoch, with learning rate 2.0658795558326744
[09/26 00:44:55 visual_prompt]: Epoch 61 / 100: avg data time: 6.03e-02, avg batch time: 0.5016, average train loss: 4.5273
[09/26 00:44:57 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1661, average loss: 4.7523
[09/26 00:44:57 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 8.50	
[09/26 00:44:57 visual_prompt]: Training 62 / 100 epoch, with learning rate 1.980220772955602
[09/26 00:45:03 visual_prompt]: Epoch 62 / 100: avg data time: 5.41e-02, avg batch time: 0.4966, average train loss: 4.7866
[09/26 00:45:05 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1660, average loss: 4.7748
[09/26 00:45:05 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.50	
[09/26 00:45:05 visual_prompt]: Training 63 / 100 epoch, with learning rate 1.895195261000831
[09/26 00:45:12 visual_prompt]: Epoch 63 / 100: avg data time: 5.67e-02, avg batch time: 0.4987, average train loss: 4.8437
[09/26 00:45:13 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1662, average loss: 4.7487
[09/26 00:45:13 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 7.00	
[09/26 00:45:13 visual_prompt]: Training 64 / 100 epoch, with learning rate 1.8109066104575022
[09/26 00:45:20 visual_prompt]: Epoch 64 / 100: avg data time: 4.29e-02, avg batch time: 0.4872, average train loss: 4.9400
[09/26 00:45:21 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1662, average loss: 4.7545
[09/26 00:45:21 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 7.00	
[09/26 00:45:21 visual_prompt]: Training 65 / 100 epoch, with learning rate 1.7274575140626316
[09/26 00:45:28 visual_prompt]: Epoch 65 / 100: avg data time: 5.33e-02, avg batch time: 0.4953, average train loss: 4.6787
[09/26 00:45:29 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1662, average loss: 4.7712
[09/26 00:45:29 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 7.50	
[09/26 00:45:29 visual_prompt]: Training 66 / 100 epoch, with learning rate 1.6449496416858285
[09/26 00:45:36 visual_prompt]: Epoch 66 / 100: avg data time: 4.93e-02, avg batch time: 0.4922, average train loss: 4.6584
[09/26 00:45:38 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1663, average loss: 4.5106
[09/26 00:45:38 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 7.00	
[09/26 00:45:38 visual_prompt]: Training 67 / 100 epoch, with learning rate 1.5634835164602199
[09/26 00:45:44 visual_prompt]: Epoch 67 / 100: avg data time: 5.42e-02, avg batch time: 0.4964, average train loss: 4.5362
[09/26 00:45:46 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1662, average loss: 4.5787
[09/26 00:45:46 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 4.50	top5: 11.00	
[09/26 00:45:46 visual_prompt]: Best epoch 67: best metric: 0.045
[09/26 00:45:46 visual_prompt]: Training 68 / 100 epoch, with learning rate 1.4831583923104998
[09/26 00:45:53 visual_prompt]: Epoch 68 / 100: avg data time: 5.48e-02, avg batch time: 0.4959, average train loss: 4.4387
[09/26 00:45:54 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1662, average loss: 4.4721
[09/26 00:45:54 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 4.00	top5: 16.50	
[09/26 00:45:54 visual_prompt]: Training 69 / 100 epoch, with learning rate 1.4040721330273063
[09/26 00:46:01 visual_prompt]: Epoch 69 / 100: avg data time: 5.62e-02, avg batch time: 0.4985, average train loss: 4.3720
[09/26 00:46:02 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1661, average loss: 4.4205
[09/26 00:46:02 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 15.50	
[09/26 00:46:02 visual_prompt]: Training 70 / 100 epoch, with learning rate 1.3263210930352738
[09/26 00:46:09 visual_prompt]: Epoch 70 / 100: avg data time: 4.64e-02, avg batch time: 0.4910, average train loss: 4.3281
[09/26 00:46:11 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1664, average loss: 4.4982
[09/26 00:46:11 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 3.00	top5: 12.00	
[09/26 00:46:11 visual_prompt]: Training 71 / 100 epoch, with learning rate 1.2500000000000004
[09/26 00:46:17 visual_prompt]: Epoch 71 / 100: avg data time: 4.56e-02, avg batch time: 0.4869, average train loss: 4.2659
[09/26 00:46:19 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1664, average loss: 4.4546
[09/26 00:46:19 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 3.50	top5: 14.50	
[09/26 00:46:19 visual_prompt]: Training 72 / 100 epoch, with learning rate 1.175201839416988
[09/26 00:46:25 visual_prompt]: Epoch 72 / 100: avg data time: 5.72e-02, avg batch time: 0.4987, average train loss: 4.2294
[09/26 00:46:27 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1661, average loss: 4.3926
[09/26 00:46:27 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 3.50	top5: 18.00	
[09/26 00:46:27 visual_prompt]: Training 73 / 100 epoch, with learning rate 1.1020177413231333
[09/26 00:46:34 visual_prompt]: Epoch 73 / 100: avg data time: 6.32e-02, avg batch time: 0.5058, average train loss: 4.0982
[09/26 00:46:35 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1663, average loss: 4.3404
[09/26 00:46:35 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 7.00	top5: 22.00	
[09/26 00:46:35 visual_prompt]: Best epoch 73: best metric: 0.070
[09/26 00:46:35 visual_prompt]: Training 74 / 100 epoch, with learning rate 1.0305368692688175
[09/26 00:46:42 visual_prompt]: Epoch 74 / 100: avg data time: 6.03e-02, avg batch time: 0.5015, average train loss: 3.9817
[09/26 00:46:43 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1663, average loss: 4.6542
[09/26 00:46:43 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 5.50	top5: 20.50	
[09/26 00:46:43 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.9608463116858543
[09/26 00:46:50 visual_prompt]: Epoch 75 / 100: avg data time: 5.18e-02, avg batch time: 0.4949, average train loss: 3.8102
[09/26 00:46:52 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1664, average loss: 4.4615
[09/26 00:46:52 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 13.00	
[09/26 00:46:52 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.8930309757836516
[09/26 00:46:58 visual_prompt]: Epoch 76 / 100: avg data time: 5.45e-02, avg batch time: 0.4968, average train loss: 3.8484
[09/26 00:47:00 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1662, average loss: 4.4450
[09/26 00:47:00 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 6.50	top5: 17.50	
[09/26 00:47:00 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.8271734841028553
[09/26 00:47:07 visual_prompt]: Epoch 77 / 100: avg data time: 5.40e-02, avg batch time: 0.4965, average train loss: 3.5857
[09/26 00:47:08 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1662, average loss: 4.1852
[09/26 00:47:08 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 8.50	top5: 27.00	
[09/26 00:47:08 visual_prompt]: Best epoch 77: best metric: 0.085
[09/26 00:47:08 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.7633540738525066
[09/26 00:47:15 visual_prompt]: Epoch 78 / 100: avg data time: 5.49e-02, avg batch time: 0.4974, average train loss: 3.1432
[09/26 00:47:16 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1663, average loss: 4.0045
[09/26 00:47:16 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 13.50	top5: 31.00	
[09/26 00:47:16 visual_prompt]: Best epoch 78: best metric: 0.135
[09/26 00:47:16 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.7016504991533725
[09/26 00:47:23 visual_prompt]: Epoch 79 / 100: avg data time: 5.68e-02, avg batch time: 0.4991, average train loss: 2.5294
[09/26 00:47:25 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1663, average loss: 4.0776
[09/26 00:47:25 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 12.00	top5: 35.00	
[09/26 00:47:25 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.6421379363065141
[09/26 00:47:31 visual_prompt]: Epoch 80 / 100: avg data time: 4.83e-02, avg batch time: 0.4921, average train loss: 1.9247
[09/26 00:47:33 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1662, average loss: 3.9246
[09/26 00:47:33 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 15.50	top5: 41.00	
[09/26 00:47:33 visual_prompt]: Best epoch 80: best metric: 0.155
[09/26 00:47:33 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.5848888922025552
[09/26 00:47:39 visual_prompt]: Epoch 81 / 100: avg data time: 4.40e-02, avg batch time: 0.4863, average train loss: 1.3483
[09/26 00:47:41 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1664, average loss: 3.9076
[09/26 00:47:41 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 15.00	top5: 41.00	
[09/26 00:47:41 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.5299731159831953
[09/26 00:47:47 visual_prompt]: Epoch 82 / 100: avg data time: 5.01e-02, avg batch time: 0.4919, average train loss: 0.9453
[09/26 00:47:49 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1662, average loss: 3.8011
[09/26 00:47:49 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 19.50	top5: 42.50	
[09/26 00:47:49 visual_prompt]: Best epoch 82: best metric: 0.195
[09/26 00:47:49 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.47745751406263165
[09/26 00:47:56 visual_prompt]: Epoch 83 / 100: avg data time: 5.36e-02, avg batch time: 0.4954, average train loss: 0.5806
[09/26 00:47:57 visual_prompt]: Inference (val):avg data time: 3.57e-05, avg batch time: 0.1662, average loss: 3.7600
[09/26 00:47:57 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 19.50	top5: 44.50	
[09/26 00:47:57 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.42740606861239594
[09/26 00:48:04 visual_prompt]: Epoch 84 / 100: avg data time: 5.51e-02, avg batch time: 0.4965, average train loss: 0.3878
[09/26 00:48:05 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1663, average loss: 3.7500
[09/26 00:48:05 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 19.00	top5: 46.50	
[09/26 00:48:05 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.3798797596089351
[09/26 00:48:12 visual_prompt]: Epoch 85 / 100: avg data time: 4.72e-02, avg batch time: 0.4895, average train loss: 0.2642
[09/26 00:48:13 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1661, average loss: 3.7166
[09/26 00:48:13 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 18.50	top5: 44.50	
[09/26 00:48:13 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.33493649053890323
[09/26 00:48:20 visual_prompt]: Epoch 86 / 100: avg data time: 4.59e-02, avg batch time: 0.4886, average train loss: 0.2026
[09/26 00:48:22 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1662, average loss: 3.6904
[09/26 00:48:22 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 16.50	top5: 45.00	
[09/26 00:48:22 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.29263101785268253
[09/26 00:48:28 visual_prompt]: Epoch 87 / 100: avg data time: 5.64e-02, avg batch time: 0.4974, average train loss: 0.1821
[09/26 00:48:30 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1661, average loss: 3.6951
[09/26 00:48:30 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 19.00	top5: 45.50	
[09/26 00:48:30 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.25301488425208296
[09/26 00:48:37 visual_prompt]: Epoch 88 / 100: avg data time: 5.58e-02, avg batch time: 0.4979, average train loss: 0.1587
[09/26 00:48:38 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1662, average loss: 3.6844
[09/26 00:48:38 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 18.50	top5: 46.00	
[09/26 00:48:38 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.21613635589349756
[09/26 00:48:45 visual_prompt]: Epoch 89 / 100: avg data time: 4.99e-02, avg batch time: 0.4927, average train loss: 0.1472
[09/26 00:48:46 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1660, average loss: 3.6485
[09/26 00:48:46 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 19.50	top5: 46.00	
[09/26 00:48:46 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.18204036358303172
[09/26 00:48:53 visual_prompt]: Epoch 90 / 100: avg data time: 5.40e-02, avg batch time: 0.4962, average train loss: 0.1386
[09/26 00:48:54 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1661, average loss: 3.6528
[09/26 00:48:54 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 17.50	top5: 48.50	
[09/26 00:48:54 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.1507684480352292
[09/26 00:49:01 visual_prompt]: Epoch 91 / 100: avg data time: 4.72e-02, avg batch time: 0.4890, average train loss: 0.1291
[09/26 00:49:03 visual_prompt]: Inference (val):avg data time: 2.02e-05, avg batch time: 0.1662, average loss: 3.6454
[09/26 00:49:03 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 17.50	top5: 47.50	
[09/26 00:49:03 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.12235870926211617
[09/26 00:49:09 visual_prompt]: Epoch 92 / 100: avg data time: 5.95e-02, avg batch time: 0.5015, average train loss: 0.1276
[09/26 00:49:11 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1661, average loss: 3.6567
[09/26 00:49:11 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 18.50	top5: 50.00	
[09/26 00:49:11 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.09684576015420276
[09/26 00:49:18 visual_prompt]: Epoch 93 / 100: avg data time: 4.94e-02, avg batch time: 0.4923, average train loss: 0.1222
[09/26 00:49:19 visual_prompt]: Inference (val):avg data time: 2.00e-05, avg batch time: 0.1662, average loss: 3.6349
[09/26 00:49:19 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 18.50	top5: 47.50	
[09/26 00:49:19 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.07426068431000882
[09/26 00:49:26 visual_prompt]: Epoch 94 / 100: avg data time: 4.23e-02, avg batch time: 0.4851, average train loss: 0.1202
[09/26 00:49:27 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1662, average loss: 3.6226
[09/26 00:49:27 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 20.00	top5: 47.00	
[09/26 00:49:27 visual_prompt]: Best epoch 94: best metric: 0.200
[09/26 00:49:27 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.05463099816548578
[09/26 00:49:34 visual_prompt]: Epoch 95 / 100: avg data time: 5.31e-02, avg batch time: 0.4962, average train loss: 0.1165
[09/26 00:49:35 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1662, average loss: 3.6079
[09/26 00:49:35 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 18.00	top5: 48.50	
[09/26 00:49:35 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.03798061746947995
[09/26 00:49:42 visual_prompt]: Epoch 96 / 100: avg data time: 4.95e-02, avg batch time: 0.4915, average train loss: 0.1147
[09/26 00:49:43 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1663, average loss: 3.6174
[09/26 00:49:43 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 19.00	top5: 48.50	
[09/26 00:49:43 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.024329828146074095
[09/26 00:49:50 visual_prompt]: Epoch 97 / 100: avg data time: 4.77e-02, avg batch time: 0.4903, average train loss: 0.1138
[09/26 00:49:51 visual_prompt]: Inference (val):avg data time: 1.92e-05, avg batch time: 0.1664, average loss: 3.6138
[09/26 00:49:51 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 19.50	top5: 49.00	
[09/26 00:49:51 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.013695261579316775
[09/26 00:49:58 visual_prompt]: Epoch 98 / 100: avg data time: 4.80e-02, avg batch time: 0.4930, average train loss: 0.1119
[09/26 00:50:00 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.1663, average loss: 3.6122
[09/26 00:50:00 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 19.00	top5: 49.00	
[09/26 00:50:00 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.006089874350439506
[09/26 00:50:06 visual_prompt]: Epoch 99 / 100: avg data time: 5.92e-02, avg batch time: 0.5004, average train loss: 0.1111
[09/26 00:50:08 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1663, average loss: 3.6121
[09/26 00:50:08 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 20.50	top5: 49.00	
[09/26 00:50:08 visual_prompt]: Best epoch 99: best metric: 0.205
[09/26 00:50:08 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0015229324522605947
[09/26 00:50:15 visual_prompt]: Epoch 100 / 100: avg data time: 5.99e-02, avg batch time: 0.5024, average train loss: 0.1098
[09/26 00:50:16 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1663, average loss: 3.6120
[09/26 00:50:16 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 20.50	top5: 49.00	
[09/26 00:50:16 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 00:50:16 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 00:50:16 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-cifar(num_classes=100)', 'DATA.NUMBER_CLASSES', '100', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 00:50:16 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 00:50:16 visual_prompt]: Training with config:
[09/26 00:50:16 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-cifar(num_classes=100)/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr5.0_wd0.0001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 5.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-cifar(num_classes=100)', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 100, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 00:50:16 visual_prompt]: Loading training data...
[09/26 00:50:16 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[:800], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/26 00:50:17 visual_prompt]: Number of images: 800
[09/26 00:50:17 visual_prompt]: Number of classes: 100 / 100
[09/26 00:50:17 visual_prompt]: Loading validation data...
[09/26 00:50:17 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[45000:45200], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/26 00:50:17 visual_prompt]: Number of images: 200
[09/26 00:50:17 visual_prompt]: Number of classes: 90 / 100
[09/26 00:50:17 visual_prompt]: Constructing models...
[09/26 00:50:20 visual_prompt]: Total Parameters: 86336356	 Gradient Parameters: 537700
[09/26 00:50:20 visual_prompt]: tuned percent:0.623
[09/26 00:50:20 visual_prompt]: Device used for model: 0
[09/26 00:50:20 visual_prompt]: Setting up Evaluator...
[09/26 00:50:20 visual_prompt]: Setting up Trainer...
[09/26 00:50:20 visual_prompt]: 	Setting up the optimizer...
[09/26 00:50:20 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 00:50:27 visual_prompt]: Epoch 1 / 100: avg data time: 5.81e-02, avg batch time: 0.4988, average train loss: 4.6523
[09/26 00:50:28 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1654, average loss: 4.6218
[09/26 00:50:28 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 7.00	
[09/26 00:50:28 visual_prompt]: Best epoch 1: best metric: 0.010
[09/26 00:50:28 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.5
[09/26 00:50:35 visual_prompt]: Epoch 2 / 100: avg data time: 5.88e-02, avg batch time: 0.4995, average train loss: 4.6551
[09/26 00:50:37 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1657, average loss: 4.7074
[09/26 00:50:37 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.00	
[09/26 00:50:37 visual_prompt]: Training 3 / 100 epoch, with learning rate 1.0
[09/26 00:50:43 visual_prompt]: Epoch 3 / 100: avg data time: 5.92e-02, avg batch time: 0.4995, average train loss: 4.6775
[09/26 00:50:45 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1656, average loss: 4.5928
[09/26 00:50:45 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 12.00	
[09/26 00:50:45 visual_prompt]: Best epoch 3: best metric: 0.020
[09/26 00:50:45 visual_prompt]: Training 4 / 100 epoch, with learning rate 1.5
[09/26 00:50:52 visual_prompt]: Epoch 4 / 100: avg data time: 5.54e-02, avg batch time: 0.4961, average train loss: 4.6175
[09/26 00:50:53 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1658, average loss: 5.7984
[09/26 00:50:53 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/26 00:50:53 visual_prompt]: Training 5 / 100 epoch, with learning rate 2.0
[09/26 00:51:00 visual_prompt]: Epoch 5 / 100: avg data time: 5.67e-02, avg batch time: 0.4986, average train loss: 4.8181
[09/26 00:51:01 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.1659, average loss: 4.5967
[09/26 00:51:01 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.50	top5: 9.50	
[09/26 00:51:01 visual_prompt]: Best epoch 5: best metric: 0.025
[09/26 00:51:01 visual_prompt]: Training 6 / 100 epoch, with learning rate 2.5
[09/26 00:51:08 visual_prompt]: Epoch 6 / 100: avg data time: 5.82e-02, avg batch time: 0.4997, average train loss: 4.6302
[09/26 00:51:09 visual_prompt]: Inference (val):avg data time: 2.11e-05, avg batch time: 0.1660, average loss: 4.4878
[09/26 00:51:09 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.50	top5: 13.50	
[09/26 00:51:09 visual_prompt]: Training 7 / 100 epoch, with learning rate 3.0
[09/26 00:51:16 visual_prompt]: Epoch 7 / 100: avg data time: 5.06e-02, avg batch time: 0.4934, average train loss: 4.5666
[09/26 00:51:18 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1660, average loss: 4.5952
[09/26 00:51:18 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 5.00	top5: 13.00	
[09/26 00:51:18 visual_prompt]: Best epoch 7: best metric: 0.050
[09/26 00:51:18 visual_prompt]: Training 8 / 100 epoch, with learning rate 3.5
[09/26 00:51:24 visual_prompt]: Epoch 8 / 100: avg data time: 5.69e-02, avg batch time: 0.4984, average train loss: 4.5028
[09/26 00:51:26 visual_prompt]: Inference (val):avg data time: 1.95e-05, avg batch time: 0.1660, average loss: 4.5801
[09/26 00:51:26 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 8.50	top5: 17.00	
[09/26 00:51:26 visual_prompt]: Best epoch 8: best metric: 0.085
[09/26 00:51:26 visual_prompt]: Training 9 / 100 epoch, with learning rate 4.0
[09/26 00:51:32 visual_prompt]: Epoch 9 / 100: avg data time: 4.84e-02, avg batch time: 0.4906, average train loss: 4.2409
[09/26 00:51:34 visual_prompt]: Inference (val):avg data time: 1.97e-05, avg batch time: 0.1663, average loss: 4.2116
[09/26 00:51:34 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 10.50	top5: 29.00	
[09/26 00:51:34 visual_prompt]: Best epoch 9: best metric: 0.105
[09/26 00:51:34 visual_prompt]: Training 10 / 100 epoch, with learning rate 4.5
[09/26 00:51:41 visual_prompt]: Epoch 10 / 100: avg data time: 4.62e-02, avg batch time: 0.4897, average train loss: 3.1564
[09/26 00:51:42 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1662, average loss: 3.4561
[09/26 00:51:42 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 22.50	top5: 50.00	
[09/26 00:51:42 visual_prompt]: Best epoch 10: best metric: 0.225
[09/26 00:51:42 visual_prompt]: Training 11 / 100 epoch, with learning rate 5.0
[09/26 00:51:49 visual_prompt]: Epoch 11 / 100: avg data time: 5.82e-02, avg batch time: 0.5009, average train loss: 2.0574
[09/26 00:51:50 visual_prompt]: Inference (val):avg data time: 1.93e-05, avg batch time: 0.1662, average loss: 2.7509
[09/26 00:51:50 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 39.00	top5: 73.00	
[09/26 00:51:50 visual_prompt]: Best epoch 11: best metric: 0.390
[09/26 00:51:50 visual_prompt]: Training 12 / 100 epoch, with learning rate 4.998477067547739
[09/26 00:51:57 visual_prompt]: Epoch 12 / 100: avg data time: 5.33e-02, avg batch time: 0.4951, average train loss: 0.8566
[09/26 00:51:59 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.1664, average loss: 3.0316
[09/26 00:51:59 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 41.50	top5: 75.50	
[09/26 00:51:59 visual_prompt]: Best epoch 12: best metric: 0.415
[09/26 00:51:59 visual_prompt]: Training 13 / 100 epoch, with learning rate 4.993910125649561
[09/26 00:52:05 visual_prompt]: Epoch 13 / 100: avg data time: 5.89e-02, avg batch time: 0.5008, average train loss: 0.5057
[09/26 00:52:07 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1662, average loss: 2.8100
[09/26 00:52:07 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 46.00	top5: 78.50	
[09/26 00:52:07 visual_prompt]: Best epoch 13: best metric: 0.460
[09/26 00:52:07 visual_prompt]: Training 14 / 100 epoch, with learning rate 4.986304738420683
[09/26 00:52:14 visual_prompt]: Epoch 14 / 100: avg data time: 5.98e-02, avg batch time: 0.5018, average train loss: 0.2109
[09/26 00:52:15 visual_prompt]: Inference (val):avg data time: 3.55e-05, avg batch time: 0.1663, average loss: 2.4593
[09/26 00:52:15 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 53.50	top5: 80.00	
[09/26 00:52:15 visual_prompt]: Best epoch 14: best metric: 0.535
[09/26 00:52:15 visual_prompt]: Training 15 / 100 epoch, with learning rate 4.975670171853926
[09/26 00:52:22 visual_prompt]: Epoch 15 / 100: avg data time: 5.57e-02, avg batch time: 0.4987, average train loss: 0.1841
[09/26 00:52:23 visual_prompt]: Inference (val):avg data time: 3.48e-05, avg batch time: 0.1665, average loss: 2.3723
[09/26 00:52:23 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 51.50	top5: 83.50	
[09/26 00:52:23 visual_prompt]: Training 16 / 100 epoch, with learning rate 4.962019382530521
[09/26 00:52:30 visual_prompt]: Epoch 16 / 100: avg data time: 5.38e-02, avg batch time: 0.4971, average train loss: 0.1704
[09/26 00:52:32 visual_prompt]: Inference (val):avg data time: 1.99e-05, avg batch time: 0.1666, average loss: 2.5952
[09/26 00:52:32 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 53.00	top5: 83.00	
[09/26 00:52:32 visual_prompt]: Training 17 / 100 epoch, with learning rate 4.945369001834514
[09/26 00:52:38 visual_prompt]: Epoch 17 / 100: avg data time: 5.84e-02, avg batch time: 0.5042, average train loss: 0.0750
[09/26 00:52:40 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1666, average loss: 2.3620
[09/26 00:52:40 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 52.50	top5: 81.50	
[09/26 00:52:40 visual_prompt]: Training 18 / 100 epoch, with learning rate 4.925739315689991
[09/26 00:52:47 visual_prompt]: Epoch 18 / 100: avg data time: 5.35e-02, avg batch time: 0.4963, average train loss: 0.0602
[09/26 00:52:48 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1663, average loss: 2.3553
[09/26 00:52:48 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 51.00	top5: 82.00	
[09/26 00:52:48 visual_prompt]: Training 19 / 100 epoch, with learning rate 4.903154239845797
[09/26 00:52:55 visual_prompt]: Epoch 19 / 100: avg data time: 4.33e-02, avg batch time: 0.4862, average train loss: 0.0484
[09/26 00:52:56 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1664, average loss: 2.1467
[09/26 00:52:56 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 55.50	top5: 85.00	
[09/26 00:52:56 visual_prompt]: Best epoch 19: best metric: 0.555
[09/26 00:52:56 visual_prompt]: Training 20 / 100 epoch, with learning rate 4.877641290737884
[09/26 00:53:03 visual_prompt]: Epoch 20 / 100: avg data time: 6.06e-02, avg batch time: 0.5036, average train loss: 0.1555
[09/26 00:53:04 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1662, average loss: 2.8719
[09/26 00:53:04 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 44.50	top5: 74.50	
[09/26 00:53:04 visual_prompt]: Training 21 / 100 epoch, with learning rate 4.849231551964771
[09/26 00:53:11 visual_prompt]: Epoch 21 / 100: avg data time: 5.69e-02, avg batch time: 0.4987, average train loss: 0.3241
[09/26 00:53:13 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1666, average loss: 2.3138
[09/26 00:53:13 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 52.50	top5: 81.00	
[09/26 00:53:13 visual_prompt]: Training 22 / 100 epoch, with learning rate 4.817959636416969
[09/26 00:53:20 visual_prompt]: Epoch 22 / 100: avg data time: 5.95e-02, avg batch time: 0.5033, average train loss: 0.1695
[09/26 00:53:21 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1665, average loss: 2.2903
[09/26 00:53:21 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.00	top5: 83.00	
[09/26 00:53:21 visual_prompt]: Training 23 / 100 epoch, with learning rate 4.783863644106502
[09/26 00:53:28 visual_prompt]: Epoch 23 / 100: avg data time: 4.24e-02, avg batch time: 0.4852, average train loss: 0.1133
[09/26 00:53:29 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1665, average loss: 2.1117
[09/26 00:53:29 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 56.50	top5: 81.50	
[09/26 00:53:29 visual_prompt]: Best epoch 23: best metric: 0.565
[09/26 00:53:29 visual_prompt]: Training 24 / 100 epoch, with learning rate 4.7469851157479175
[09/26 00:53:36 visual_prompt]: Epoch 24 / 100: avg data time: 4.65e-02, avg batch time: 0.4904, average train loss: 0.0586
[09/26 00:53:37 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1664, average loss: 1.8626
[09/26 00:53:37 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.50	top5: 86.00	
[09/26 00:53:37 visual_prompt]: Best epoch 24: best metric: 0.595
[09/26 00:53:37 visual_prompt]: Training 25 / 100 epoch, with learning rate 4.707368982147317
[09/26 00:53:44 visual_prompt]: Epoch 25 / 100: avg data time: 5.55e-02, avg batch time: 0.4984, average train loss: 0.0464
[09/26 00:53:46 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1664, average loss: 1.8698
[09/26 00:53:46 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 86.00	
[09/26 00:53:46 visual_prompt]: Best epoch 25: best metric: 0.625
[09/26 00:53:46 visual_prompt]: Training 26 / 100 epoch, with learning rate 4.665063509461097
[09/26 00:53:52 visual_prompt]: Epoch 26 / 100: avg data time: 4.56e-02, avg batch time: 0.4891, average train loss: 0.0279
[09/26 00:53:54 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1665, average loss: 2.1333
[09/26 00:53:54 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.00	top5: 84.00	
[09/26 00:53:54 visual_prompt]: Training 27 / 100 epoch, with learning rate 4.620120240391064
[09/26 00:54:01 visual_prompt]: Epoch 27 / 100: avg data time: 6.62e-02, avg batch time: 0.5081, average train loss: 0.0285
[09/26 00:54:02 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1664, average loss: 1.8242
[09/26 00:54:02 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 85.00	
[09/26 00:54:02 visual_prompt]: Training 28 / 100 epoch, with learning rate 4.572593931387604
[09/26 00:54:09 visual_prompt]: Epoch 28 / 100: avg data time: 5.89e-02, avg batch time: 0.5006, average train loss: 0.0403
[09/26 00:54:10 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1661, average loss: 1.8042
[09/26 00:54:10 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.50	top5: 86.00	
[09/26 00:54:10 visual_prompt]: Best epoch 28: best metric: 0.635
[09/26 00:54:10 visual_prompt]: Training 29 / 100 epoch, with learning rate 4.522542485937368
[09/26 00:54:17 visual_prompt]: Epoch 29 / 100: avg data time: 6.26e-02, avg batch time: 0.5039, average train loss: 0.0510
[09/26 00:54:19 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1664, average loss: 1.7310
[09/26 00:54:19 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.50	top5: 85.00	
[09/26 00:54:19 visual_prompt]: Training 30 / 100 epoch, with learning rate 4.4700268840168045
[09/26 00:54:25 visual_prompt]: Epoch 30 / 100: avg data time: 5.59e-02, avg batch time: 0.4981, average train loss: 0.0250
[09/26 00:54:27 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1664, average loss: 1.6108
[09/26 00:54:27 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.50	top5: 87.00	
[09/26 00:54:27 visual_prompt]: Training 31 / 100 epoch, with learning rate 4.415111107797445
[09/26 00:54:34 visual_prompt]: Epoch 31 / 100: avg data time: 5.83e-02, avg batch time: 0.4997, average train loss: 0.1008
[09/26 00:54:35 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1661, average loss: 1.5294
[09/26 00:54:35 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.50	top5: 86.50	
[09/26 00:54:35 visual_prompt]: Best epoch 31: best metric: 0.665
[09/26 00:54:35 visual_prompt]: Training 32 / 100 epoch, with learning rate 4.357862063693486
[09/26 00:54:42 visual_prompt]: Epoch 32 / 100: avg data time: 5.71e-02, avg batch time: 0.5003, average train loss: 0.0138
[09/26 00:54:43 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1664, average loss: 1.4349
[09/26 00:54:43 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.00	top5: 87.00	
[09/26 00:54:43 visual_prompt]: Best epoch 32: best metric: 0.670
[09/26 00:54:43 visual_prompt]: Training 33 / 100 epoch, with learning rate 4.298349500846628
[09/26 00:54:50 visual_prompt]: Epoch 33 / 100: avg data time: 5.79e-02, avg batch time: 0.5005, average train loss: 0.0163
[09/26 00:54:52 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1663, average loss: 1.3403
[09/26 00:54:52 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.50	top5: 88.50	
[09/26 00:54:52 visual_prompt]: Training 34 / 100 epoch, with learning rate 4.236645926147493
[09/26 00:54:59 visual_prompt]: Epoch 34 / 100: avg data time: 6.28e-02, avg batch time: 0.5042, average train loss: 0.0085
[09/26 00:55:00 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1662, average loss: 1.2278
[09/26 00:55:00 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 68.50	top5: 91.00	
[09/26 00:55:00 visual_prompt]: Best epoch 34: best metric: 0.685
[09/26 00:55:00 visual_prompt]: Training 35 / 100 epoch, with learning rate 4.172826515897146
[09/26 00:55:07 visual_prompt]: Epoch 35 / 100: avg data time: 6.10e-02, avg batch time: 0.5034, average train loss: 0.0083
[09/26 00:55:09 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1662, average loss: 1.1709
[09/26 00:55:09 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 70.00	top5: 89.50	
[09/26 00:55:09 visual_prompt]: Best epoch 35: best metric: 0.700
[09/26 00:55:09 visual_prompt]: Training 36 / 100 epoch, with learning rate 4.106969024216348
[09/26 00:55:15 visual_prompt]: Epoch 36 / 100: avg data time: 5.68e-02, avg batch time: 0.4991, average train loss: 0.0066
[09/26 00:55:17 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1661, average loss: 1.1246
[09/26 00:55:17 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 70.50	top5: 90.50	
[09/26 00:55:17 visual_prompt]: Best epoch 36: best metric: 0.705
[09/26 00:55:17 visual_prompt]: Training 37 / 100 epoch, with learning rate 4.039153688314146
[09/26 00:55:23 visual_prompt]: Epoch 37 / 100: avg data time: 4.71e-02, avg batch time: 0.4911, average train loss: 0.0060
[09/26 00:55:25 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1659, average loss: 1.1016
[09/26 00:55:25 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 73.00	top5: 91.00	
[09/26 00:55:25 visual_prompt]: Best epoch 37: best metric: 0.730
[09/26 00:55:25 visual_prompt]: Training 38 / 100 epoch, with learning rate 3.969463130731183
[09/26 00:55:32 visual_prompt]: Epoch 38 / 100: avg data time: 4.68e-02, avg batch time: 0.4888, average train loss: 0.0061
[09/26 00:55:33 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1661, average loss: 1.0948
[09/26 00:55:33 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 73.00	top5: 91.50	
[09/26 00:55:33 visual_prompt]: Training 39 / 100 epoch, with learning rate 3.897982258676867
[09/26 00:55:40 visual_prompt]: Epoch 39 / 100: avg data time: 6.23e-02, avg batch time: 0.5039, average train loss: 0.0066
[09/26 00:55:41 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1665, average loss: 1.0691
[09/26 00:55:41 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 72.50	top5: 91.00	
[09/26 00:55:41 visual_prompt]: Training 40 / 100 epoch, with learning rate 3.824798160583012
[09/26 00:55:48 visual_prompt]: Epoch 40 / 100: avg data time: 4.91e-02, avg batch time: 0.4913, average train loss: 0.0069
[09/26 00:55:50 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1661, average loss: 1.0607
[09/26 00:55:50 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 72.50	top5: 91.00	
[09/26 00:55:50 visual_prompt]: Training 41 / 100 epoch, with learning rate 3.75
[09/26 00:55:56 visual_prompt]: Epoch 41 / 100: avg data time: 5.57e-02, avg batch time: 0.4976, average train loss: 0.0074
[09/26 00:55:58 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1661, average loss: 1.0550
[09/26 00:55:58 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 73.50	top5: 91.00	
[09/26 00:55:58 visual_prompt]: Best epoch 41: best metric: 0.735
[09/26 00:55:58 visual_prompt]: Training 42 / 100 epoch, with learning rate 3.673678906964727
[09/26 00:56:05 visual_prompt]: Epoch 42 / 100: avg data time: 5.09e-02, avg batch time: 0.4933, average train loss: 0.0078
[09/26 00:56:06 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1662, average loss: 1.0251
[09/26 00:56:06 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 75.00	top5: 92.00	
[09/26 00:56:06 visual_prompt]: Best epoch 42: best metric: 0.750
[09/26 00:56:06 visual_prompt]: Training 43 / 100 epoch, with learning rate 3.5959278669726933
[09/26 00:56:13 visual_prompt]: Epoch 43 / 100: avg data time: 5.74e-02, avg batch time: 0.4999, average train loss: 0.0077
[09/26 00:56:14 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1661, average loss: 1.0203
[09/26 00:56:14 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 74.50	top5: 91.50	
[09/26 00:56:14 visual_prompt]: Training 44 / 100 epoch, with learning rate 3.516841607689501
[09/26 00:56:21 visual_prompt]: Epoch 44 / 100: avg data time: 5.48e-02, avg batch time: 0.4964, average train loss: 0.0078
[09/26 00:56:22 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1661, average loss: 0.9961
[09/26 00:56:22 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 77.00	top5: 92.50	
[09/26 00:56:22 visual_prompt]: Best epoch 44: best metric: 0.770
[09/26 00:56:22 visual_prompt]: Training 45 / 100 epoch, with learning rate 3.4365164835397803
[09/26 00:56:29 visual_prompt]: Epoch 45 / 100: avg data time: 4.76e-02, avg batch time: 0.4903, average train loss: 0.0079
[09/26 00:56:31 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1662, average loss: 1.0056
[09/26 00:56:31 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 77.00	top5: 92.00	
[09/26 00:56:31 visual_prompt]: Training 46 / 100 epoch, with learning rate 3.3550503583141724
[09/26 00:56:37 visual_prompt]: Epoch 46 / 100: avg data time: 5.47e-02, avg batch time: 0.4962, average train loss: 0.0079
[09/26 00:56:39 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.1661, average loss: 0.9836
[09/26 00:56:39 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 75.50	top5: 92.00	
[09/26 00:56:39 visual_prompt]: Training 47 / 100 epoch, with learning rate 3.2725424859373686
[09/26 00:56:46 visual_prompt]: Epoch 47 / 100: avg data time: 5.86e-02, avg batch time: 0.5005, average train loss: 0.0077
[09/26 00:56:47 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1665, average loss: 0.9693
[09/26 00:56:47 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 76.00	top5: 92.00	
[09/26 00:56:47 visual_prompt]: Training 48 / 100 epoch, with learning rate 3.1890933895424975
[09/26 00:56:54 visual_prompt]: Epoch 48 / 100: avg data time: 4.19e-02, avg batch time: 0.4839, average train loss: 0.0076
[09/26 00:56:55 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1662, average loss: 0.9621
[09/26 00:56:55 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 76.50	top5: 92.00	
[09/26 00:56:55 visual_prompt]: Training 49 / 100 epoch, with learning rate 3.104804738999169
[09/26 00:57:02 visual_prompt]: Epoch 49 / 100: avg data time: 5.72e-02, avg batch time: 0.5005, average train loss: 0.0076
[09/26 00:57:03 visual_prompt]: Inference (val):avg data time: 1.96e-05, avg batch time: 0.1662, average loss: 0.9549
[09/26 00:57:03 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 76.00	top5: 93.00	
[09/26 00:57:03 visual_prompt]: Training 50 / 100 epoch, with learning rate 3.019779227044398
[09/26 00:57:10 visual_prompt]: Epoch 50 / 100: avg data time: 6.05e-02, avg batch time: 0.5032, average train loss: 0.0075
[09/26 00:57:12 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1662, average loss: 0.9491
[09/26 00:57:12 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 78.00	top5: 93.50	
[09/26 00:57:12 visual_prompt]: Best epoch 50: best metric: 0.780
[09/26 00:57:12 visual_prompt]: Training 51 / 100 epoch, with learning rate 2.934120444167326
[09/26 00:57:18 visual_prompt]: Epoch 51 / 100: avg data time: 5.30e-02, avg batch time: 0.4955, average train loss: 0.0076
[09/26 00:57:20 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.1662, average loss: 0.9457
[09/26 00:57:20 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 76.50	top5: 93.50	
[09/26 00:57:20 visual_prompt]: Training 52 / 100 epoch, with learning rate 2.8479327524001636
[09/26 00:57:26 visual_prompt]: Epoch 52 / 100: avg data time: 4.66e-02, avg batch time: 0.4898, average train loss: 0.0074
[09/26 00:57:28 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1664, average loss: 0.9294
[09/26 00:57:28 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 75.50	top5: 94.50	
[09/26 00:57:28 visual_prompt]: Training 53 / 100 epoch, with learning rate 2.761321158169134
[09/26 00:57:35 visual_prompt]: Epoch 53 / 100: avg data time: 5.61e-02, avg batch time: 0.4998, average train loss: 0.0072
[09/26 00:57:36 visual_prompt]: Inference (val):avg data time: 1.97e-05, avg batch time: 0.1663, average loss: 0.9194
[09/26 00:57:36 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 78.00	top5: 94.00	
[09/26 00:57:36 visual_prompt]: Training 54 / 100 epoch, with learning rate 2.6743911843603128
[09/26 00:57:43 visual_prompt]: Epoch 54 / 100: avg data time: 5.63e-02, avg batch time: 0.4994, average train loss: 0.0072
[09/26 00:57:44 visual_prompt]: Inference (val):avg data time: 1.98e-05, avg batch time: 0.1665, average loss: 0.9183
[09/26 00:57:44 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 78.00	top5: 94.00	
[09/26 00:57:44 visual_prompt]: Training 55 / 100 epoch, with learning rate 2.5872487417562526
[09/26 00:57:51 visual_prompt]: Epoch 55 / 100: avg data time: 5.17e-02, avg batch time: 0.4934, average train loss: 0.0068
[09/26 00:57:53 visual_prompt]: Inference (val):avg data time: 1.97e-05, avg batch time: 0.1662, average loss: 0.9236
[09/26 00:57:53 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 77.50	top5: 94.00	
[09/26 00:57:53 visual_prompt]: Training 56 / 100 epoch, with learning rate 2.5
[09/26 00:57:59 visual_prompt]: Epoch 56 / 100: avg data time: 5.87e-02, avg batch time: 0.5028, average train loss: 0.0067
[09/26 00:58:01 visual_prompt]: Inference (val):avg data time: 2.11e-05, avg batch time: 0.1663, average loss: 0.9014
[09/26 00:58:01 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 77.50	top5: 94.00	
[09/26 00:58:01 visual_prompt]: Training 57 / 100 epoch, with learning rate 2.4127512582437483
[09/26 00:58:08 visual_prompt]: Epoch 57 / 100: avg data time: 5.82e-02, avg batch time: 0.5006, average train loss: 0.0065
[09/26 00:58:09 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1664, average loss: 0.9045
[09/26 00:58:09 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 78.50	top5: 94.00	
[09/26 00:58:09 visual_prompt]: Best epoch 57: best metric: 0.785
[09/26 00:58:09 visual_prompt]: Training 58 / 100 epoch, with learning rate 2.325608815639687
[09/26 00:58:16 visual_prompt]: Epoch 58 / 100: avg data time: 4.67e-02, avg batch time: 0.4906, average train loss: 0.0063
[09/26 00:58:17 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1664, average loss: 0.9166
[09/26 00:58:17 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 78.00	top5: 94.50	
[09/26 00:58:17 visual_prompt]: Training 59 / 100 epoch, with learning rate 2.2386788418308665
[09/26 00:58:24 visual_prompt]: Epoch 59 / 100: avg data time: 4.80e-02, avg batch time: 0.4905, average train loss: 0.0061
[09/26 00:58:25 visual_prompt]: Inference (val):avg data time: 2.01e-05, avg batch time: 0.1662, average loss: 0.8801
[09/26 00:58:25 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 79.00	top5: 95.00	
[09/26 00:58:25 visual_prompt]: Best epoch 59: best metric: 0.790
[09/26 00:58:25 visual_prompt]: Training 60 / 100 epoch, with learning rate 2.1520672475998373
[09/26 00:58:32 visual_prompt]: Epoch 60 / 100: avg data time: 4.85e-02, avg batch time: 0.4919, average train loss: 0.0060
[09/26 00:58:33 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1664, average loss: 0.9105
[09/26 00:58:33 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 77.00	top5: 94.50	
[09/26 00:58:33 visual_prompt]: Training 61 / 100 epoch, with learning rate 2.0658795558326744
[09/26 00:58:40 visual_prompt]: Epoch 61 / 100: avg data time: 5.77e-02, avg batch time: 0.4995, average train loss: 0.0060
[09/26 00:58:42 visual_prompt]: Inference (val):avg data time: 1.98e-05, avg batch time: 0.1664, average loss: 0.8958
[09/26 00:58:42 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 77.50	top5: 94.50	
[09/26 00:58:42 visual_prompt]: Training 62 / 100 epoch, with learning rate 1.980220772955602
[09/26 00:58:48 visual_prompt]: Epoch 62 / 100: avg data time: 5.43e-02, avg batch time: 0.4964, average train loss: 0.0060
[09/26 00:58:50 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1662, average loss: 0.8941
[09/26 00:58:50 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 79.00	top5: 95.00	
[09/26 00:58:50 visual_prompt]: Training 63 / 100 epoch, with learning rate 1.895195261000831
[09/26 00:58:57 visual_prompt]: Epoch 63 / 100: avg data time: 4.63e-02, avg batch time: 0.4910, average train loss: 0.0059
[09/26 00:58:58 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1662, average loss: 0.8955
[09/26 00:58:58 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 78.00	top5: 94.50	
[09/26 00:58:58 visual_prompt]: Training 64 / 100 epoch, with learning rate 1.8109066104575022
[09/26 00:59:05 visual_prompt]: Epoch 64 / 100: avg data time: 5.61e-02, avg batch time: 0.4988, average train loss: 0.0056
[09/26 00:59:06 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1663, average loss: 0.8807
[09/26 00:59:06 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 77.50	top5: 96.00	
[09/26 00:59:06 visual_prompt]: Training 65 / 100 epoch, with learning rate 1.7274575140626316
[09/26 00:59:13 visual_prompt]: Epoch 65 / 100: avg data time: 5.05e-02, avg batch time: 0.4929, average train loss: 0.0055
[09/26 00:59:14 visual_prompt]: Inference (val):avg data time: 2.01e-05, avg batch time: 0.1662, average loss: 0.9030
[09/26 00:59:14 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 78.00	top5: 96.00	
[09/26 00:59:14 visual_prompt]: Training 66 / 100 epoch, with learning rate 1.6449496416858285
[09/26 00:59:21 visual_prompt]: Epoch 66 / 100: avg data time: 5.97e-02, avg batch time: 0.5015, average train loss: 0.0054
[09/26 00:59:23 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1661, average loss: 0.8859
[09/26 00:59:23 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 76.00	top5: 95.50	
[09/26 00:59:23 visual_prompt]: Training 67 / 100 epoch, with learning rate 1.5634835164602199
[09/26 00:59:30 visual_prompt]: Epoch 67 / 100: avg data time: 6.85e-02, avg batch time: 0.5098, average train loss: 0.0052
[09/26 00:59:31 visual_prompt]: Inference (val):avg data time: 1.88e-05, avg batch time: 0.1660, average loss: 0.9176
[09/26 00:59:31 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 77.50	top5: 94.50	
[09/26 00:59:31 visual_prompt]: Training 68 / 100 epoch, with learning rate 1.4831583923104998
[09/26 00:59:38 visual_prompt]: Epoch 68 / 100: avg data time: 5.66e-02, avg batch time: 0.4993, average train loss: 0.0052
[09/26 00:59:39 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1662, average loss: 0.9094
[09/26 00:59:39 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 76.50	top5: 96.50	
[09/26 00:59:39 visual_prompt]: Training 69 / 100 epoch, with learning rate 1.4040721330273063
[09/26 00:59:46 visual_prompt]: Epoch 69 / 100: avg data time: 5.57e-02, avg batch time: 0.4969, average train loss: 0.0053
[09/26 00:59:48 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1662, average loss: 0.9274
[09/26 00:59:48 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 76.50	top5: 95.00	
[09/26 00:59:48 visual_prompt]: Training 70 / 100 epoch, with learning rate 1.3263210930352738
[09/26 00:59:54 visual_prompt]: Epoch 70 / 100: avg data time: 5.44e-02, avg batch time: 0.4955, average train loss: 0.0051
[09/26 00:59:56 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1660, average loss: 0.9326
[09/26 00:59:56 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 76.00	top5: 95.00	
[09/26 00:59:56 visual_prompt]: Training 71 / 100 epoch, with learning rate 1.2500000000000004
[09/26 01:00:03 visual_prompt]: Epoch 71 / 100: avg data time: 4.36e-02, avg batch time: 0.4880, average train loss: 0.0050
[09/26 01:00:04 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1663, average loss: 0.9233
[09/26 01:00:04 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 76.00	top5: 95.50	
[09/26 01:00:04 visual_prompt]: Training 72 / 100 epoch, with learning rate 1.175201839416988
[09/26 01:00:11 visual_prompt]: Epoch 72 / 100: avg data time: 6.83e-02, avg batch time: 0.5098, average train loss: 0.0049
[09/26 01:00:13 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1660, average loss: 0.9267
[09/26 01:00:13 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 78.00	top5: 95.50	
[09/26 01:00:13 visual_prompt]: Training 73 / 100 epoch, with learning rate 1.1020177413231333
[09/26 01:00:19 visual_prompt]: Epoch 73 / 100: avg data time: 5.35e-02, avg batch time: 0.4956, average train loss: 0.0049
[09/26 01:00:21 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1661, average loss: 0.9265
[09/26 01:00:21 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 77.50	top5: 95.00	
[09/26 01:00:21 visual_prompt]: Training 74 / 100 epoch, with learning rate 1.0305368692688175
[09/26 01:00:28 visual_prompt]: Epoch 74 / 100: avg data time: 6.50e-02, avg batch time: 0.5059, average train loss: 0.0048
[09/26 01:00:29 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1660, average loss: 0.9404
[09/26 01:00:29 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 78.00	top5: 95.00	
[09/26 01:00:29 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.9608463116858543
[09/26 01:00:36 visual_prompt]: Epoch 75 / 100: avg data time: 6.61e-02, avg batch time: 0.5091, average train loss: 0.0048
[09/26 01:00:38 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1660, average loss: 0.9481
[09/26 01:00:38 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 75.50	top5: 95.00	
[09/26 01:00:38 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.8930309757836516
[09/26 01:00:44 visual_prompt]: Epoch 76 / 100: avg data time: 5.59e-02, avg batch time: 0.4991, average train loss: 0.0048
[09/26 01:00:46 visual_prompt]: Inference (val):avg data time: 4.36e-05, avg batch time: 0.1661, average loss: 0.9447
[09/26 01:00:46 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 76.50	top5: 95.50	
[09/26 01:00:46 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.8271734841028553
[09/26 01:00:53 visual_prompt]: Epoch 77 / 100: avg data time: 6.12e-02, avg batch time: 0.5021, average train loss: 0.0048
[09/26 01:00:54 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1659, average loss: 0.9465
[09/26 01:00:54 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 77.50	top5: 95.50	
[09/26 01:00:54 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.7633540738525066
[09/26 01:01:01 visual_prompt]: Epoch 78 / 100: avg data time: 5.87e-02, avg batch time: 0.4996, average train loss: 0.0046
[09/26 01:01:02 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1660, average loss: 0.9689
[09/26 01:01:02 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 74.50	top5: 95.00	
[09/26 01:01:02 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.7016504991533725
[09/26 01:01:09 visual_prompt]: Epoch 79 / 100: avg data time: 5.74e-02, avg batch time: 0.4983, average train loss: 0.0046
[09/26 01:01:11 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1660, average loss: 0.9378
[09/26 01:01:11 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 77.00	top5: 96.00	
[09/26 01:01:11 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.6421379363065141
[09/26 01:01:17 visual_prompt]: Epoch 80 / 100: avg data time: 5.01e-02, avg batch time: 0.4920, average train loss: 0.0046
[09/26 01:01:19 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1661, average loss: 0.9546
[09/26 01:01:19 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 76.00	top5: 96.00	
[09/26 01:01:19 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.5848888922025552
[09/26 01:01:26 visual_prompt]: Epoch 81 / 100: avg data time: 5.06e-02, avg batch time: 0.4917, average train loss: 0.0045
[09/26 01:01:27 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1668, average loss: 0.9614
[09/26 01:01:27 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 76.50	top5: 95.50	
[09/26 01:01:27 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.5299731159831953
[09/26 01:01:34 visual_prompt]: Epoch 82 / 100: avg data time: 5.10e-02, avg batch time: 0.4930, average train loss: 0.0045
[09/26 01:01:35 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1662, average loss: 0.9665
[09/26 01:01:35 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 77.00	top5: 95.50	
[09/26 01:01:35 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.47745751406263165
[09/26 01:01:42 visual_prompt]: Epoch 83 / 100: avg data time: 5.86e-02, avg batch time: 0.5009, average train loss: 0.0045
[09/26 01:01:44 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1661, average loss: 0.9493
[09/26 01:01:44 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 77.50	top5: 96.00	
[09/26 01:01:44 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.42740606861239594
[09/26 01:01:50 visual_prompt]: Epoch 84 / 100: avg data time: 5.99e-02, avg batch time: 0.5012, average train loss: 0.0044
[09/26 01:01:52 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1660, average loss: 0.9655
[09/26 01:01:52 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 76.00	top5: 95.50	
[09/26 01:01:52 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.3798797596089351
[09/26 01:01:59 visual_prompt]: Epoch 85 / 100: avg data time: 5.38e-02, avg batch time: 0.4962, average train loss: 0.0044
[09/26 01:02:00 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1662, average loss: 0.9682
[09/26 01:02:00 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 76.00	top5: 95.50	
[09/26 01:02:00 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.33493649053890323
[09/26 01:02:07 visual_prompt]: Epoch 86 / 100: avg data time: 5.28e-02, avg batch time: 0.4951, average train loss: 0.0044
[09/26 01:02:08 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1662, average loss: 0.9637
[09/26 01:02:08 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 76.00	top5: 96.00	
[09/26 01:02:08 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.29263101785268253
[09/26 01:02:15 visual_prompt]: Epoch 87 / 100: avg data time: 5.29e-02, avg batch time: 0.4967, average train loss: 0.0044
[09/26 01:02:16 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1661, average loss: 0.9535
[09/26 01:02:16 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 77.00	top5: 96.00	
[09/26 01:02:16 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.25301488425208296
[09/26 01:02:23 visual_prompt]: Epoch 88 / 100: avg data time: 6.09e-02, avg batch time: 0.5027, average train loss: 0.0044
[09/26 01:02:25 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1660, average loss: 0.9665
[09/26 01:02:25 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 76.00	top5: 95.00	
[09/26 01:02:25 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.21613635589349756
[09/26 01:02:31 visual_prompt]: Epoch 89 / 100: avg data time: 5.96e-02, avg batch time: 0.5008, average train loss: 0.0044
[09/26 01:02:33 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1663, average loss: 0.9645
[09/26 01:02:33 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 77.00	top5: 95.50	
[09/26 01:02:33 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.18204036358303172
[09/26 01:02:40 visual_prompt]: Epoch 90 / 100: avg data time: 5.66e-02, avg batch time: 0.4982, average train loss: 0.0043
[09/26 01:02:41 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1662, average loss: 0.9580
[09/26 01:02:41 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 77.00	top5: 96.00	
[09/26 01:02:41 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.1507684480352292
[09/26 01:02:48 visual_prompt]: Epoch 91 / 100: avg data time: 5.70e-02, avg batch time: 0.4997, average train loss: 0.0044
[09/26 01:02:49 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1662, average loss: 0.9576
[09/26 01:02:49 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 76.50	top5: 95.50	
[09/26 01:02:49 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.12235870926211617
[09/26 01:02:56 visual_prompt]: Epoch 92 / 100: avg data time: 6.13e-02, avg batch time: 0.5027, average train loss: 0.0043
[09/26 01:02:58 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1664, average loss: 0.9596
[09/26 01:02:58 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 77.00	top5: 95.50	
[09/26 01:02:58 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.09684576015420276
[09/26 01:03:04 visual_prompt]: Epoch 93 / 100: avg data time: 5.34e-02, avg batch time: 0.4949, average train loss: 0.0043
[09/26 01:03:06 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1664, average loss: 0.9572
[09/26 01:03:06 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 76.50	top5: 95.50	
[09/26 01:03:06 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.07426068431000882
[09/26 01:03:13 visual_prompt]: Epoch 94 / 100: avg data time: 5.91e-02, avg batch time: 0.5017, average train loss: 0.0042
[09/26 01:03:14 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1659, average loss: 0.9567
[09/26 01:03:14 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 76.50	top5: 95.50	
[09/26 01:03:14 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.05463099816548578
[09/26 01:03:21 visual_prompt]: Epoch 95 / 100: avg data time: 6.21e-02, avg batch time: 0.5049, average train loss: 0.0042
[09/26 01:03:22 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1668, average loss: 0.9580
[09/26 01:03:22 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 76.50	top5: 95.50	
[09/26 01:03:22 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.03798061746947995
[09/26 01:03:29 visual_prompt]: Epoch 96 / 100: avg data time: 4.37e-02, avg batch time: 0.4854, average train loss: 0.0043
[09/26 01:03:30 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1664, average loss: 0.9595
[09/26 01:03:30 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 76.50	top5: 95.50	
[09/26 01:03:30 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.024329828146074095
[09/26 01:03:37 visual_prompt]: Epoch 97 / 100: avg data time: 4.63e-02, avg batch time: 0.4901, average train loss: 0.0043
[09/26 01:03:39 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1662, average loss: 0.9590
[09/26 01:03:39 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 76.50	top5: 95.50	
[09/26 01:03:39 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.013695261579316775
[09/26 01:03:45 visual_prompt]: Epoch 98 / 100: avg data time: 4.60e-02, avg batch time: 0.4907, average train loss: 0.0043
[09/26 01:03:47 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1665, average loss: 0.9589
[09/26 01:03:47 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 76.50	top5: 96.00	
[09/26 01:03:47 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.006089874350439506
[09/26 01:03:54 visual_prompt]: Epoch 99 / 100: avg data time: 6.58e-02, avg batch time: 0.5075, average train loss: 0.0043
[09/26 01:03:55 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1665, average loss: 0.9589
[09/26 01:03:55 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 76.50	top5: 96.00	
[09/26 01:03:55 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0015229324522605947
[09/26 01:04:02 visual_prompt]: Epoch 100 / 100: avg data time: 4.37e-02, avg batch time: 0.4870, average train loss: 0.0043
[09/26 01:04:03 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1664, average loss: 0.9589
[09/26 01:04:03 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 76.50	top5: 96.00	
[09/26 01:04:03 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 01:04:03 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 01:04:03 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-cifar(num_classes=100)', 'DATA.NUMBER_CLASSES', '100', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 01:04:03 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 01:04:03 visual_prompt]: Training with config:
[09/26 01:04:03 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-cifar(num_classes=100)/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr5.0_wd0.0/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 5.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-cifar(num_classes=100)', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 100, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 01:04:03 visual_prompt]: Loading training data...
[09/26 01:04:03 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[:800], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/26 01:04:04 visual_prompt]: Number of images: 800
[09/26 01:04:04 visual_prompt]: Number of classes: 100 / 100
[09/26 01:04:04 visual_prompt]: Loading validation data...
[09/26 01:04:04 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[45000:45200], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/26 01:04:04 visual_prompt]: Number of images: 200
[09/26 01:04:04 visual_prompt]: Number of classes: 90 / 100
[09/26 01:04:04 visual_prompt]: Constructing models...
[09/26 01:04:07 visual_prompt]: Total Parameters: 86336356	 Gradient Parameters: 537700
[09/26 01:04:07 visual_prompt]: tuned percent:0.623
[09/26 01:04:07 visual_prompt]: Device used for model: 0
[09/26 01:04:07 visual_prompt]: Setting up Evaluator...
[09/26 01:04:07 visual_prompt]: Setting up Trainer...
[09/26 01:04:07 visual_prompt]: 	Setting up the optimizer...
[09/26 01:04:07 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 01:04:14 visual_prompt]: Epoch 1 / 100: avg data time: 6.13e-02, avg batch time: 0.5024, average train loss: 4.6565
[09/26 01:04:15 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1659, average loss: 4.6218
[09/26 01:04:15 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 7.00	
[09/26 01:04:15 visual_prompt]: Best epoch 1: best metric: 0.010
[09/26 01:04:15 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.5
[09/26 01:04:22 visual_prompt]: Epoch 2 / 100: avg data time: 4.40e-02, avg batch time: 0.4866, average train loss: 4.6485
[09/26 01:04:23 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1662, average loss: 4.6997
[09/26 01:04:23 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.00	
[09/26 01:04:23 visual_prompt]: Training 3 / 100 epoch, with learning rate 1.0
[09/26 01:04:30 visual_prompt]: Epoch 3 / 100: avg data time: 5.72e-02, avg batch time: 0.4995, average train loss: 4.6681
[09/26 01:04:31 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1661, average loss: 4.6768
[09/26 01:04:31 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.00	
[09/26 01:04:31 visual_prompt]: Best epoch 3: best metric: 0.015
[09/26 01:04:31 visual_prompt]: Training 4 / 100 epoch, with learning rate 1.5
[09/26 01:04:38 visual_prompt]: Epoch 4 / 100: avg data time: 5.81e-02, avg batch time: 0.5002, average train loss: 4.6997
[09/26 01:04:40 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1661, average loss: 4.6692
[09/26 01:04:40 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 5.50	
[09/26 01:04:40 visual_prompt]: Training 5 / 100 epoch, with learning rate 2.0
[09/26 01:04:47 visual_prompt]: Epoch 5 / 100: avg data time: 5.90e-02, avg batch time: 0.5011, average train loss: 4.8062
[09/26 01:04:48 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1663, average loss: 4.6974
[09/26 01:04:48 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.00	
[09/26 01:04:48 visual_prompt]: Training 6 / 100 epoch, with learning rate 2.5
[09/26 01:04:55 visual_prompt]: Epoch 6 / 100: avg data time: 5.41e-02, avg batch time: 0.4959, average train loss: 4.7409
[09/26 01:04:56 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1662, average loss: 5.0740
[09/26 01:04:56 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 7.00	
[09/26 01:04:56 visual_prompt]: Training 7 / 100 epoch, with learning rate 3.0
[09/26 01:05:03 visual_prompt]: Epoch 7 / 100: avg data time: 4.82e-02, avg batch time: 0.4902, average train loss: 4.7444
[09/26 01:05:04 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1664, average loss: 4.5780
[09/26 01:05:04 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 12.50	
[09/26 01:05:04 visual_prompt]: Best epoch 7: best metric: 0.020
[09/26 01:05:04 visual_prompt]: Training 8 / 100 epoch, with learning rate 3.5
[09/26 01:05:11 visual_prompt]: Epoch 8 / 100: avg data time: 5.99e-02, avg batch time: 0.5018, average train loss: 4.5220
[09/26 01:05:13 visual_prompt]: Inference (val):avg data time: 2.11e-05, avg batch time: 0.1662, average loss: 4.4601
[09/26 01:05:13 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 6.00	top5: 17.00	
[09/26 01:05:13 visual_prompt]: Best epoch 8: best metric: 0.060
[09/26 01:05:13 visual_prompt]: Training 9 / 100 epoch, with learning rate 4.0
[09/26 01:05:19 visual_prompt]: Epoch 9 / 100: avg data time: 5.90e-02, avg batch time: 0.5005, average train loss: 4.3940
[09/26 01:05:21 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1660, average loss: 4.9257
[09/26 01:05:21 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 4.00	
[09/26 01:05:21 visual_prompt]: Training 10 / 100 epoch, with learning rate 4.5
[09/26 01:05:28 visual_prompt]: Epoch 10 / 100: avg data time: 4.86e-02, avg batch time: 0.4906, average train loss: 4.9398
[09/26 01:05:29 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1663, average loss: 4.8130
[09/26 01:05:29 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 3.00	top5: 8.50	
[09/26 01:05:29 visual_prompt]: Training 11 / 100 epoch, with learning rate 5.0
[09/26 01:05:36 visual_prompt]: Epoch 11 / 100: avg data time: 5.75e-02, avg batch time: 0.4988, average train loss: 4.3953
[09/26 01:05:37 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1663, average loss: 4.3008
[09/26 01:05:37 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 8.00	top5: 30.00	
[09/26 01:05:37 visual_prompt]: Best epoch 11: best metric: 0.080
[09/26 01:05:37 visual_prompt]: Training 12 / 100 epoch, with learning rate 4.998477067547739
[09/26 01:05:44 visual_prompt]: Epoch 12 / 100: avg data time: 4.47e-02, avg batch time: 0.4870, average train loss: 3.5969
[09/26 01:05:46 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1665, average loss: 3.6055
[09/26 01:05:46 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 19.50	top5: 51.00	
[09/26 01:05:46 visual_prompt]: Best epoch 12: best metric: 0.195
[09/26 01:05:46 visual_prompt]: Training 13 / 100 epoch, with learning rate 4.993910125649561
[09/26 01:05:52 visual_prompt]: Epoch 13 / 100: avg data time: 5.82e-02, avg batch time: 0.5000, average train loss: 2.2918
[09/26 01:05:54 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1662, average loss: 2.9799
[09/26 01:05:54 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 32.00	top5: 60.50	
[09/26 01:05:54 visual_prompt]: Best epoch 13: best metric: 0.320
[09/26 01:05:54 visual_prompt]: Training 14 / 100 epoch, with learning rate 4.986304738420683
[09/26 01:06:01 visual_prompt]: Epoch 14 / 100: avg data time: 5.91e-02, avg batch time: 0.5019, average train loss: 1.3960
[09/26 01:06:02 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1662, average loss: 2.6111
[09/26 01:06:02 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 38.50	top5: 76.50	
[09/26 01:06:02 visual_prompt]: Best epoch 14: best metric: 0.385
[09/26 01:06:02 visual_prompt]: Training 15 / 100 epoch, with learning rate 4.975670171853926
[09/26 01:06:09 visual_prompt]: Epoch 15 / 100: avg data time: 6.78e-02, avg batch time: 0.5095, average train loss: 0.5956
[09/26 01:06:10 visual_prompt]: Inference (val):avg data time: 1.87e-05, avg batch time: 0.1663, average loss: 2.7408
[09/26 01:06:11 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 44.00	top5: 80.50	
[09/26 01:06:11 visual_prompt]: Best epoch 15: best metric: 0.440
[09/26 01:06:11 visual_prompt]: Training 16 / 100 epoch, with learning rate 4.962019382530521
[09/26 01:06:17 visual_prompt]: Epoch 16 / 100: avg data time: 5.91e-02, avg batch time: 0.5017, average train loss: 0.3873
[09/26 01:06:19 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1663, average loss: 2.8530
[09/26 01:06:19 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 47.00	top5: 80.50	
[09/26 01:06:19 visual_prompt]: Best epoch 16: best metric: 0.470
[09/26 01:06:19 visual_prompt]: Training 17 / 100 epoch, with learning rate 4.945369001834514
[09/26 01:06:26 visual_prompt]: Epoch 17 / 100: avg data time: 5.45e-02, avg batch time: 0.4974, average train loss: 0.2424
[09/26 01:06:27 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1663, average loss: 2.5583
[09/26 01:06:27 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 53.50	top5: 84.00	
[09/26 01:06:27 visual_prompt]: Best epoch 17: best metric: 0.535
[09/26 01:06:27 visual_prompt]: Training 18 / 100 epoch, with learning rate 4.925739315689991
[09/26 01:06:34 visual_prompt]: Epoch 18 / 100: avg data time: 4.66e-02, avg batch time: 0.4916, average train loss: 0.1305
[09/26 01:06:35 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1664, average loss: 2.8732
[09/26 01:06:35 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 52.50	top5: 83.00	
[09/26 01:06:35 visual_prompt]: Training 19 / 100 epoch, with learning rate 4.903154239845797
[09/26 01:06:42 visual_prompt]: Epoch 19 / 100: avg data time: 5.90e-02, avg batch time: 0.5007, average train loss: 0.1185
[09/26 01:06:44 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1664, average loss: 2.7333
[09/26 01:06:44 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 51.50	top5: 82.00	
[09/26 01:06:44 visual_prompt]: Training 20 / 100 epoch, with learning rate 4.877641290737884
[09/26 01:06:50 visual_prompt]: Epoch 20 / 100: avg data time: 5.51e-02, avg batch time: 0.4978, average train loss: 0.1633
[09/26 01:06:52 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1663, average loss: 2.6467
[09/26 01:06:52 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 57.50	top5: 83.00	
[09/26 01:06:52 visual_prompt]: Best epoch 20: best metric: 0.575
[09/26 01:06:52 visual_prompt]: Training 21 / 100 epoch, with learning rate 4.849231551964771
[09/26 01:06:58 visual_prompt]: Epoch 21 / 100: avg data time: 5.38e-02, avg batch time: 0.4967, average train loss: 0.0661
[09/26 01:07:00 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1664, average loss: 2.5980
[09/26 01:07:00 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.50	top5: 81.50	
[09/26 01:07:00 visual_prompt]: Best epoch 21: best metric: 0.585
[09/26 01:07:00 visual_prompt]: Training 22 / 100 epoch, with learning rate 4.817959636416969
[09/26 01:07:07 visual_prompt]: Epoch 22 / 100: avg data time: 6.00e-02, avg batch time: 0.5026, average train loss: 0.0632
[09/26 01:07:08 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1664, average loss: 2.4369
[09/26 01:07:08 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.50	top5: 83.00	
[09/26 01:07:08 visual_prompt]: Training 23 / 100 epoch, with learning rate 4.783863644106502
[09/26 01:07:15 visual_prompt]: Epoch 23 / 100: avg data time: 5.46e-02, avg batch time: 0.4979, average train loss: 0.0347
[09/26 01:07:16 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1664, average loss: 2.7557
[09/26 01:07:16 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 55.00	top5: 82.50	
[09/26 01:07:16 visual_prompt]: Training 24 / 100 epoch, with learning rate 4.7469851157479175
[09/26 01:07:23 visual_prompt]: Epoch 24 / 100: avg data time: 5.91e-02, avg batch time: 0.5036, average train loss: 0.0077
[09/26 01:07:25 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1663, average loss: 2.8980
[09/26 01:07:25 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.00	top5: 80.50	
[09/26 01:07:25 visual_prompt]: Training 25 / 100 epoch, with learning rate 4.707368982147317
[09/26 01:07:31 visual_prompt]: Epoch 25 / 100: avg data time: 5.18e-02, avg batch time: 0.4937, average train loss: 0.0034
[09/26 01:07:33 visual_prompt]: Inference (val):avg data time: 1.93e-05, avg batch time: 0.1663, average loss: 2.7970
[09/26 01:07:33 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 57.00	top5: 82.50	
[09/26 01:07:33 visual_prompt]: Training 26 / 100 epoch, with learning rate 4.665063509461097
[09/26 01:07:40 visual_prompt]: Epoch 26 / 100: avg data time: 5.39e-02, avg batch time: 0.4959, average train loss: 0.0015
[09/26 01:07:41 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1663, average loss: 2.7589
[09/26 01:07:41 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 83.50	
[09/26 01:07:41 visual_prompt]: Training 27 / 100 epoch, with learning rate 4.620120240391064
[09/26 01:07:48 visual_prompt]: Epoch 27 / 100: avg data time: 4.89e-02, avg batch time: 0.4930, average train loss: 0.0004
[09/26 01:07:49 visual_prompt]: Inference (val):avg data time: 2.01e-05, avg batch time: 0.1663, average loss: 2.7591
[09/26 01:07:49 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 83.50	
[09/26 01:07:49 visual_prompt]: Training 28 / 100 epoch, with learning rate 4.572593931387604
[09/26 01:07:56 visual_prompt]: Epoch 28 / 100: avg data time: 5.76e-02, avg batch time: 0.4999, average train loss: 0.0006
[09/26 01:07:58 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1663, average loss: 2.7587
[09/26 01:07:58 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 57.50	top5: 83.50	
[09/26 01:07:58 visual_prompt]: Training 29 / 100 epoch, with learning rate 4.522542485937368
[09/26 01:08:04 visual_prompt]: Epoch 29 / 100: avg data time: 5.50e-02, avg batch time: 0.4977, average train loss: 0.0003
[09/26 01:08:06 visual_prompt]: Inference (val):avg data time: 1.99e-05, avg batch time: 0.1662, average loss: 2.7532
[09/26 01:08:06 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.50	top5: 83.50	
[09/26 01:08:06 visual_prompt]: Training 30 / 100 epoch, with learning rate 4.4700268840168045
[09/26 01:08:13 visual_prompt]: Epoch 30 / 100: avg data time: 5.97e-02, avg batch time: 0.5016, average train loss: 0.0003
[09/26 01:08:14 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1663, average loss: 2.7520
[09/26 01:08:14 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.00	top5: 83.50	
[09/26 01:08:14 visual_prompt]: Best epoch 30: best metric: 0.590
[09/26 01:08:14 visual_prompt]: Training 31 / 100 epoch, with learning rate 4.415111107797445
[09/26 01:08:21 visual_prompt]: Epoch 31 / 100: avg data time: 5.96e-02, avg batch time: 0.5022, average train loss: 0.0003
[09/26 01:08:22 visual_prompt]: Inference (val):avg data time: 1.96e-05, avg batch time: 0.1663, average loss: 2.7492
[09/26 01:08:22 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.00	top5: 84.00	
[09/26 01:08:22 visual_prompt]: Training 32 / 100 epoch, with learning rate 4.357862063693486
[09/26 01:08:29 visual_prompt]: Epoch 32 / 100: avg data time: 5.85e-02, avg batch time: 0.5002, average train loss: 0.0004
[09/26 01:08:31 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1661, average loss: 2.7387
[09/26 01:08:31 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.50	top5: 84.00	
[09/26 01:08:31 visual_prompt]: Best epoch 32: best metric: 0.595
[09/26 01:08:31 visual_prompt]: Training 33 / 100 epoch, with learning rate 4.298349500846628
[09/26 01:08:38 visual_prompt]: Epoch 33 / 100: avg data time: 5.82e-02, avg batch time: 0.5007, average train loss: 0.0002
[09/26 01:08:39 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1662, average loss: 2.7357
[09/26 01:08:39 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.50	top5: 84.00	
[09/26 01:08:39 visual_prompt]: Training 34 / 100 epoch, with learning rate 4.236645926147493
[09/26 01:08:46 visual_prompt]: Epoch 34 / 100: avg data time: 5.95e-02, avg batch time: 0.5018, average train loss: 0.0002
[09/26 01:08:47 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1662, average loss: 2.7369
[09/26 01:08:47 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.50	top5: 84.00	
[09/26 01:08:47 visual_prompt]: Training 35 / 100 epoch, with learning rate 4.172826515897146
[09/26 01:08:54 visual_prompt]: Epoch 35 / 100: avg data time: 5.62e-02, avg batch time: 0.4978, average train loss: 0.0002
[09/26 01:08:56 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1660, average loss: 2.7365
[09/26 01:08:56 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.50	top5: 83.50	
[09/26 01:08:56 visual_prompt]: Training 36 / 100 epoch, with learning rate 4.106969024216348
[09/26 01:09:02 visual_prompt]: Epoch 36 / 100: avg data time: 6.26e-02, avg batch time: 0.5040, average train loss: 0.0002
[09/26 01:09:04 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1661, average loss: 2.7368
[09/26 01:09:04 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.50	top5: 84.00	
[09/26 01:09:04 visual_prompt]: Training 37 / 100 epoch, with learning rate 4.039153688314146
[09/26 01:09:11 visual_prompt]: Epoch 37 / 100: avg data time: 4.50e-02, avg batch time: 0.4877, average train loss: 0.0001
[09/26 01:09:12 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1660, average loss: 2.7375
[09/26 01:09:12 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.50	top5: 84.00	
[09/26 01:09:12 visual_prompt]: Training 38 / 100 epoch, with learning rate 3.969463130731183
[09/26 01:09:19 visual_prompt]: Epoch 38 / 100: avg data time: 6.10e-02, avg batch time: 0.5026, average train loss: 0.0003
[09/26 01:09:20 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1661, average loss: 2.7431
[09/26 01:09:20 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.50	top5: 83.50	
[09/26 01:09:20 visual_prompt]: Training 39 / 100 epoch, with learning rate 3.897982258676867
[09/26 01:09:27 visual_prompt]: Epoch 39 / 100: avg data time: 4.55e-02, avg batch time: 0.4906, average train loss: 0.0002
[09/26 01:09:28 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1663, average loss: 2.7464
[09/26 01:09:28 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.50	top5: 83.50	
[09/26 01:09:28 visual_prompt]: Training 40 / 100 epoch, with learning rate 3.824798160583012
[09/26 01:09:35 visual_prompt]: Epoch 40 / 100: avg data time: 5.77e-02, avg batch time: 0.4996, average train loss: 0.0001
[09/26 01:09:37 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1659, average loss: 2.7476
[09/26 01:09:37 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.50	top5: 83.50	
[09/26 01:09:37 visual_prompt]: Training 41 / 100 epoch, with learning rate 3.75
[09/26 01:09:44 visual_prompt]: Epoch 41 / 100: avg data time: 5.72e-02, avg batch time: 0.4991, average train loss: 0.0002
[09/26 01:09:45 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.1661, average loss: 2.7467
[09/26 01:09:45 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 83.50	
[09/26 01:09:45 visual_prompt]: Training 42 / 100 epoch, with learning rate 3.673678906964727
[09/26 01:09:52 visual_prompt]: Epoch 42 / 100: avg data time: 6.14e-02, avg batch time: 0.5041, average train loss: 0.0001
[09/26 01:09:53 visual_prompt]: Inference (val):avg data time: 1.91e-05, avg batch time: 0.1660, average loss: 2.7472
[09/26 01:09:53 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 83.50	
[09/26 01:09:53 visual_prompt]: Training 43 / 100 epoch, with learning rate 3.5959278669726933
[09/26 01:10:00 visual_prompt]: Epoch 43 / 100: avg data time: 5.96e-02, avg batch time: 0.5007, average train loss: 0.0001
[09/26 01:10:02 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1663, average loss: 2.7466
[09/26 01:10:02 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 83.50	
[09/26 01:10:02 visual_prompt]: Training 44 / 100 epoch, with learning rate 3.516841607689501
[09/26 01:10:08 visual_prompt]: Epoch 44 / 100: avg data time: 6.61e-02, avg batch time: 0.5079, average train loss: 0.0001
[09/26 01:10:10 visual_prompt]: Inference (val):avg data time: 2.05e-05, avg batch time: 0.1660, average loss: 2.7453
[09/26 01:10:10 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 83.50	
[09/26 01:10:10 visual_prompt]: Training 45 / 100 epoch, with learning rate 3.4365164835397803
[09/26 01:10:17 visual_prompt]: Epoch 45 / 100: avg data time: 6.44e-02, avg batch time: 0.5059, average train loss: 0.0001
[09/26 01:10:18 visual_prompt]: Inference (val):avg data time: 2.00e-05, avg batch time: 0.1661, average loss: 2.7425
[09/26 01:10:18 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 83.50	
[09/26 01:10:18 visual_prompt]: Training 46 / 100 epoch, with learning rate 3.3550503583141724
[09/26 01:10:25 visual_prompt]: Epoch 46 / 100: avg data time: 6.15e-02, avg batch time: 0.5031, average train loss: 0.0002
[09/26 01:10:27 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1665, average loss: 2.7442
[09/26 01:10:27 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 83.50	
[09/26 01:10:27 visual_prompt]: Training 47 / 100 epoch, with learning rate 3.2725424859373686
[09/26 01:10:33 visual_prompt]: Epoch 47 / 100: avg data time: 6.16e-02, avg batch time: 0.5035, average train loss: 0.0001
[09/26 01:10:35 visual_prompt]: Inference (val):avg data time: 2.01e-05, avg batch time: 0.1662, average loss: 2.7454
[09/26 01:10:35 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 83.50	
[09/26 01:10:35 visual_prompt]: Training 48 / 100 epoch, with learning rate 3.1890933895424975
[09/26 01:10:42 visual_prompt]: Epoch 48 / 100: avg data time: 5.21e-02, avg batch time: 0.4945, average train loss: 0.0001
[09/26 01:10:43 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1664, average loss: 2.7447
[09/26 01:10:43 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 83.50	
[09/26 01:10:43 visual_prompt]: Training 49 / 100 epoch, with learning rate 3.104804738999169
[09/26 01:10:50 visual_prompt]: Epoch 49 / 100: avg data time: 6.29e-02, avg batch time: 0.5044, average train loss: 0.0001
[09/26 01:10:51 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1662, average loss: 2.7452
[09/26 01:10:51 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 83.50	
[09/26 01:10:51 visual_prompt]: Training 50 / 100 epoch, with learning rate 3.019779227044398
[09/26 01:10:58 visual_prompt]: Epoch 50 / 100: avg data time: 5.45e-02, avg batch time: 0.4962, average train loss: 0.0001
[09/26 01:11:00 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1663, average loss: 2.7465
[09/26 01:11:00 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 83.50	
[09/26 01:11:00 visual_prompt]: Training 51 / 100 epoch, with learning rate 2.934120444167326
[09/26 01:11:06 visual_prompt]: Epoch 51 / 100: avg data time: 4.82e-02, avg batch time: 0.4914, average train loss: 0.0001
[09/26 01:11:08 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1663, average loss: 2.7463
[09/26 01:11:08 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 83.50	
[09/26 01:11:08 visual_prompt]: Training 52 / 100 epoch, with learning rate 2.8479327524001636
[09/26 01:11:15 visual_prompt]: Epoch 52 / 100: avg data time: 4.55e-02, avg batch time: 0.4908, average train loss: 0.0002
[09/26 01:11:16 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1662, average loss: 2.7453
[09/26 01:11:16 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 83.50	
[09/26 01:11:16 visual_prompt]: Training 53 / 100 epoch, with learning rate 2.761321158169134
[09/26 01:11:23 visual_prompt]: Epoch 53 / 100: avg data time: 4.46e-02, avg batch time: 0.4902, average train loss: 0.0001
[09/26 01:11:24 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1669, average loss: 2.7453
[09/26 01:11:24 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 84.00	
[09/26 01:11:24 visual_prompt]: Training 54 / 100 epoch, with learning rate 2.6743911843603128
[09/26 01:11:31 visual_prompt]: Epoch 54 / 100: avg data time: 5.28e-02, avg batch time: 0.4952, average train loss: 0.0001
[09/26 01:11:32 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1662, average loss: 2.7458
[09/26 01:11:32 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 84.00	
[09/26 01:11:32 visual_prompt]: Training 55 / 100 epoch, with learning rate 2.5872487417562526
[09/26 01:11:39 visual_prompt]: Epoch 55 / 100: avg data time: 5.78e-02, avg batch time: 0.5001, average train loss: 0.0001
[09/26 01:11:41 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1663, average loss: 2.7468
[09/26 01:11:41 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 84.00	
[09/26 01:11:41 visual_prompt]: Training 56 / 100 epoch, with learning rate 2.5
[09/26 01:11:47 visual_prompt]: Epoch 56 / 100: avg data time: 5.49e-02, avg batch time: 0.4979, average train loss: 0.0001
[09/26 01:11:49 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1664, average loss: 2.7476
[09/26 01:11:49 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 84.00	
[09/26 01:11:49 visual_prompt]: Training 57 / 100 epoch, with learning rate 2.4127512582437483
[09/26 01:11:56 visual_prompt]: Epoch 57 / 100: avg data time: 5.80e-02, avg batch time: 0.5007, average train loss: 0.0002
[09/26 01:11:57 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1663, average loss: 2.7479
[09/26 01:11:57 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 84.00	
[09/26 01:11:57 visual_prompt]: Training 58 / 100 epoch, with learning rate 2.325608815639687
[09/26 01:12:04 visual_prompt]: Epoch 58 / 100: avg data time: 6.00e-02, avg batch time: 0.5016, average train loss: 0.0001
[09/26 01:12:05 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1662, average loss: 2.7477
[09/26 01:12:05 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 84.00	
[09/26 01:12:06 visual_prompt]: Training 59 / 100 epoch, with learning rate 2.2386788418308665
[09/26 01:12:12 visual_prompt]: Epoch 59 / 100: avg data time: 5.64e-02, avg batch time: 0.4983, average train loss: 0.0001
[09/26 01:12:14 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1662, average loss: 2.7481
[09/26 01:12:14 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 84.00	
[09/26 01:12:14 visual_prompt]: Training 60 / 100 epoch, with learning rate 2.1520672475998373
[09/26 01:12:20 visual_prompt]: Epoch 60 / 100: avg data time: 5.36e-02, avg batch time: 0.4963, average train loss: 0.0001
[09/26 01:12:22 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1664, average loss: 2.7485
[09/26 01:12:22 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 84.00	
[09/26 01:12:22 visual_prompt]: Training 61 / 100 epoch, with learning rate 2.0658795558326744
[09/26 01:12:29 visual_prompt]: Epoch 61 / 100: avg data time: 5.51e-02, avg batch time: 0.4970, average train loss: 0.0001
[09/26 01:12:30 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1661, average loss: 2.7496
[09/26 01:12:30 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 84.00	
[09/26 01:12:30 visual_prompt]: Training 62 / 100 epoch, with learning rate 1.980220772955602
[09/26 01:12:37 visual_prompt]: Epoch 62 / 100: avg data time: 6.49e-02, avg batch time: 0.5061, average train loss: 0.0001
[09/26 01:12:39 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1664, average loss: 2.7502
[09/26 01:12:39 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 84.00	
[09/26 01:12:39 visual_prompt]: Training 63 / 100 epoch, with learning rate 1.895195261000831
[09/26 01:12:46 visual_prompt]: Epoch 63 / 100: avg data time: 7.21e-02, avg batch time: 0.5133, average train loss: 0.0001
[09/26 01:12:47 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1661, average loss: 2.7508
[09/26 01:12:47 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 84.00	
[09/26 01:12:47 visual_prompt]: Training 64 / 100 epoch, with learning rate 1.8109066104575022
[09/26 01:12:54 visual_prompt]: Epoch 64 / 100: avg data time: 5.95e-02, avg batch time: 0.5015, average train loss: 0.0001
[09/26 01:12:56 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1660, average loss: 2.7510
[09/26 01:12:56 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 84.00	
[09/26 01:12:56 visual_prompt]: Training 65 / 100 epoch, with learning rate 1.7274575140626316
[09/26 01:13:02 visual_prompt]: Epoch 65 / 100: avg data time: 4.53e-02, avg batch time: 0.4897, average train loss: 0.0001
[09/26 01:13:04 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1662, average loss: 2.7513
[09/26 01:13:04 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 84.00	
[09/26 01:13:04 visual_prompt]: Training 66 / 100 epoch, with learning rate 1.6449496416858285
[09/26 01:13:10 visual_prompt]: Epoch 66 / 100: avg data time: 6.15e-02, avg batch time: 0.5037, average train loss: 0.0001
[09/26 01:13:12 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1664, average loss: 2.7516
[09/26 01:13:12 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 84.00	
[09/26 01:13:12 visual_prompt]: Training 67 / 100 epoch, with learning rate 1.5634835164602199
[09/26 01:13:19 visual_prompt]: Epoch 67 / 100: avg data time: 4.56e-02, avg batch time: 0.4867, average train loss: 0.0001
[09/26 01:13:20 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1661, average loss: 2.7512
[09/26 01:13:20 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 84.00	
[09/26 01:13:20 visual_prompt]: Training 68 / 100 epoch, with learning rate 1.4831583923104998
[09/26 01:13:27 visual_prompt]: Epoch 68 / 100: avg data time: 6.48e-02, avg batch time: 0.5060, average train loss: 0.0001
[09/26 01:13:29 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1660, average loss: 2.7509
[09/26 01:13:29 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 84.00	
[09/26 01:13:29 visual_prompt]: Training 69 / 100 epoch, with learning rate 1.4040721330273063
[09/26 01:13:35 visual_prompt]: Epoch 69 / 100: avg data time: 6.12e-02, avg batch time: 0.5036, average train loss: 0.0001
[09/26 01:13:37 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.1662, average loss: 2.7508
[09/26 01:13:37 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 84.00	
[09/26 01:13:37 visual_prompt]: Training 70 / 100 epoch, with learning rate 1.3263210930352738
[09/26 01:13:44 visual_prompt]: Epoch 70 / 100: avg data time: 4.90e-02, avg batch time: 0.4921, average train loss: 0.0001
[09/26 01:13:45 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1663, average loss: 2.7506
[09/26 01:13:45 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 84.00	
[09/26 01:13:45 visual_prompt]: Training 71 / 100 epoch, with learning rate 1.2500000000000004
[09/26 01:13:52 visual_prompt]: Epoch 71 / 100: avg data time: 6.38e-02, avg batch time: 0.5049, average train loss: 0.0001
[09/26 01:13:53 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1664, average loss: 2.7506
[09/26 01:13:53 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 84.00	
[09/26 01:13:53 visual_prompt]: Training 72 / 100 epoch, with learning rate 1.175201839416988
[09/26 01:14:00 visual_prompt]: Epoch 72 / 100: avg data time: 5.88e-02, avg batch time: 0.5023, average train loss: 0.0001
[09/26 01:14:02 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1663, average loss: 2.7510
[09/26 01:14:02 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 84.00	
[09/26 01:14:02 visual_prompt]: Training 73 / 100 epoch, with learning rate 1.1020177413231333
[09/26 01:14:09 visual_prompt]: Epoch 73 / 100: avg data time: 5.54e-02, avg batch time: 0.4977, average train loss: 0.0001
[09/26 01:14:10 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1661, average loss: 2.7514
[09/26 01:14:10 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 84.00	
[09/26 01:14:10 visual_prompt]: Training 74 / 100 epoch, with learning rate 1.0305368692688175
[09/26 01:14:17 visual_prompt]: Epoch 74 / 100: avg data time: 5.94e-02, avg batch time: 0.5022, average train loss: 0.0002
[09/26 01:14:19 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1663, average loss: 2.7506
[09/26 01:14:19 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 84.00	
[09/26 01:14:19 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.9608463116858543
[09/26 01:14:25 visual_prompt]: Epoch 75 / 100: avg data time: 5.70e-02, avg batch time: 0.5000, average train loss: 0.0001
[09/26 01:14:27 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1662, average loss: 2.7503
[09/26 01:14:27 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 84.00	
[09/26 01:14:27 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.8930309757836516
[09/26 01:14:34 visual_prompt]: Epoch 76 / 100: avg data time: 5.32e-02, avg batch time: 0.4962, average train loss: 0.0001
[09/26 01:14:35 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1663, average loss: 2.7504
[09/26 01:14:35 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 84.00	
[09/26 01:14:35 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.8271734841028553
[09/26 01:14:42 visual_prompt]: Epoch 77 / 100: avg data time: 6.28e-02, avg batch time: 0.5039, average train loss: 0.0001
[09/26 01:14:44 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1662, average loss: 2.7503
[09/26 01:14:44 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 84.00	
[09/26 01:14:44 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.7633540738525066
[09/26 01:14:50 visual_prompt]: Epoch 78 / 100: avg data time: 4.91e-02, avg batch time: 0.4923, average train loss: 0.0001
[09/26 01:14:52 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1667, average loss: 2.7502
[09/26 01:14:52 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 84.00	
[09/26 01:14:52 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.7016504991533725
[09/26 01:14:58 visual_prompt]: Epoch 79 / 100: avg data time: 4.54e-02, avg batch time: 0.4875, average train loss: 0.0001
[09/26 01:15:00 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1664, average loss: 2.7501
[09/26 01:15:00 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 84.00	
[09/26 01:15:00 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.6421379363065141
[09/26 01:15:07 visual_prompt]: Epoch 80 / 100: avg data time: 4.92e-02, avg batch time: 0.4920, average train loss: 0.0001
[09/26 01:15:08 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1662, average loss: 2.7500
[09/26 01:15:08 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 84.00	
[09/26 01:15:08 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.5848888922025552
[09/26 01:15:15 visual_prompt]: Epoch 81 / 100: avg data time: 5.51e-02, avg batch time: 0.4967, average train loss: 0.0001
[09/26 01:15:16 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1663, average loss: 2.7499
[09/26 01:15:16 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 84.00	
[09/26 01:15:17 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.5299731159831953
[09/26 01:15:23 visual_prompt]: Epoch 82 / 100: avg data time: 4.80e-02, avg batch time: 0.4904, average train loss: 0.0001
[09/26 01:15:25 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1666, average loss: 2.7499
[09/26 01:15:25 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 84.00	
[09/26 01:15:25 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.47745751406263165
[09/26 01:15:31 visual_prompt]: Epoch 83 / 100: avg data time: 4.53e-02, avg batch time: 0.4889, average train loss: 0.0001
[09/26 01:15:33 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1665, average loss: 2.7499
[09/26 01:15:33 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 84.00	
[09/26 01:15:33 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.42740606861239594
[09/26 01:15:40 visual_prompt]: Epoch 84 / 100: avg data time: 5.39e-02, avg batch time: 0.4986, average train loss: 0.0001
[09/26 01:15:41 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1665, average loss: 2.7500
[09/26 01:15:41 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 84.00	
[09/26 01:15:41 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.3798797596089351
[09/26 01:15:48 visual_prompt]: Epoch 85 / 100: avg data time: 5.14e-02, avg batch time: 0.4960, average train loss: 0.0001
[09/26 01:15:49 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1663, average loss: 2.7500
[09/26 01:15:49 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 84.00	
[09/26 01:15:49 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.33493649053890323
[09/26 01:15:56 visual_prompt]: Epoch 86 / 100: avg data time: 5.99e-02, avg batch time: 0.5040, average train loss: 0.0001
[09/26 01:15:58 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1662, average loss: 2.7500
[09/26 01:15:58 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 84.00	
[09/26 01:15:58 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.29263101785268253
[09/26 01:16:04 visual_prompt]: Epoch 87 / 100: avg data time: 4.80e-02, avg batch time: 0.4908, average train loss: 0.0001
[09/26 01:16:06 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1660, average loss: 2.7500
[09/26 01:16:06 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 84.00	
[09/26 01:16:06 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.25301488425208296
[09/26 01:16:13 visual_prompt]: Epoch 88 / 100: avg data time: 5.70e-02, avg batch time: 0.4986, average train loss: 0.0001
[09/26 01:16:14 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1662, average loss: 2.7501
[09/26 01:16:14 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 84.00	
[09/26 01:16:14 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.21613635589349756
[09/26 01:16:21 visual_prompt]: Epoch 89 / 100: avg data time: 6.06e-02, avg batch time: 0.5021, average train loss: 0.0001
[09/26 01:16:22 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1664, average loss: 2.7503
[09/26 01:16:22 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 84.00	
[09/26 01:16:22 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.18204036358303172
[09/26 01:16:29 visual_prompt]: Epoch 90 / 100: avg data time: 4.76e-02, avg batch time: 0.4901, average train loss: 0.0001
[09/26 01:16:31 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1663, average loss: 2.7504
[09/26 01:16:31 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 84.00	
[09/26 01:16:31 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.1507684480352292
[09/26 01:16:37 visual_prompt]: Epoch 91 / 100: avg data time: 6.46e-02, avg batch time: 0.5073, average train loss: 0.0001
[09/26 01:16:39 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1661, average loss: 2.7504
[09/26 01:16:39 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 84.00	
[09/26 01:16:39 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.12235870926211617
[09/26 01:16:46 visual_prompt]: Epoch 92 / 100: avg data time: 5.10e-02, avg batch time: 0.4924, average train loss: 0.0001
[09/26 01:16:47 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1661, average loss: 2.7504
[09/26 01:16:47 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 84.00	
[09/26 01:16:47 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.09684576015420276
[09/26 01:16:54 visual_prompt]: Epoch 93 / 100: avg data time: 6.16e-02, avg batch time: 0.5029, average train loss: 0.0001
[09/26 01:16:55 visual_prompt]: Inference (val):avg data time: 1.85e-05, avg batch time: 0.1660, average loss: 2.7504
[09/26 01:16:55 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 84.00	
[09/26 01:16:55 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.07426068431000882
[09/26 01:17:02 visual_prompt]: Epoch 94 / 100: avg data time: 5.77e-02, avg batch time: 0.4991, average train loss: 0.0001
[09/26 01:17:04 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1662, average loss: 2.7504
[09/26 01:17:04 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 84.00	
[09/26 01:17:04 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.05463099816548578
[09/26 01:17:11 visual_prompt]: Epoch 95 / 100: avg data time: 6.48e-02, avg batch time: 0.5057, average train loss: 0.0001
[09/26 01:17:12 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1661, average loss: 2.7504
[09/26 01:17:12 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 84.00	
[09/26 01:17:12 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.03798061746947995
[09/26 01:17:19 visual_prompt]: Epoch 96 / 100: avg data time: 6.34e-02, avg batch time: 0.5056, average train loss: 0.0001
[09/26 01:17:20 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1661, average loss: 2.7504
[09/26 01:17:20 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 84.00	
[09/26 01:17:20 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.024329828146074095
[09/26 01:17:27 visual_prompt]: Epoch 97 / 100: avg data time: 6.09e-02, avg batch time: 0.5018, average train loss: 0.0001
[09/26 01:17:29 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1661, average loss: 2.7504
[09/26 01:17:29 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 84.00	
[09/26 01:17:29 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.013695261579316775
[09/26 01:17:36 visual_prompt]: Epoch 98 / 100: avg data time: 5.61e-02, avg batch time: 0.4975, average train loss: 0.0001
[09/26 01:17:37 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1661, average loss: 2.7505
[09/26 01:17:37 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 84.00	
[09/26 01:17:37 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.006089874350439506
[09/26 01:17:44 visual_prompt]: Epoch 99 / 100: avg data time: 5.39e-02, avg batch time: 0.4963, average train loss: 0.0001
[09/26 01:17:45 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1662, average loss: 2.7505
[09/26 01:17:45 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 84.00	
[09/26 01:17:45 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0015229324522605947
[09/26 01:17:52 visual_prompt]: Epoch 100 / 100: avg data time: 5.69e-02, avg batch time: 0.5001, average train loss: 0.0001
[09/26 01:17:54 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1663, average loss: 2.7505
[09/26 01:17:54 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 84.00	
[09/26 01:17:54 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 01:17:54 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 01:17:54 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-cifar(num_classes=100)', 'DATA.NUMBER_CLASSES', '100', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 01:17:54 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 01:17:54 visual_prompt]: Training with config:
[09/26 01:17:54 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-cifar(num_classes=100)/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr2.5_wd0.01/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 2.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-cifar(num_classes=100)', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 100, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 01:17:54 visual_prompt]: Loading training data...
[09/26 01:17:54 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[:800], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/26 01:17:55 visual_prompt]: Number of images: 800
[09/26 01:17:55 visual_prompt]: Number of classes: 100 / 100
[09/26 01:17:55 visual_prompt]: Loading validation data...
[09/26 01:17:55 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[45000:45200], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/26 01:17:55 visual_prompt]: Number of images: 200
[09/26 01:17:55 visual_prompt]: Number of classes: 90 / 100
[09/26 01:17:55 visual_prompt]: Constructing models...
[09/26 01:17:57 visual_prompt]: Total Parameters: 86336356	 Gradient Parameters: 537700
[09/26 01:17:57 visual_prompt]: tuned percent:0.623
[09/26 01:17:57 visual_prompt]: Device used for model: 0
[09/26 01:17:57 visual_prompt]: Setting up Evaluator...
[09/26 01:17:57 visual_prompt]: Setting up Trainer...
[09/26 01:17:57 visual_prompt]: 	Setting up the optimizer...
[09/26 01:17:57 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 01:18:04 visual_prompt]: Epoch 1 / 100: avg data time: 5.95e-02, avg batch time: 0.5014, average train loss: 4.6562
[09/26 01:18:06 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1657, average loss: 4.6218
[09/26 01:18:06 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 7.00	
[09/26 01:18:06 visual_prompt]: Best epoch 1: best metric: 0.010
[09/26 01:18:06 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.25
[09/26 01:18:12 visual_prompt]: Epoch 2 / 100: avg data time: 5.79e-02, avg batch time: 0.4985, average train loss: 4.6266
[09/26 01:18:14 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1659, average loss: 4.6367
[09/26 01:18:14 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/26 01:18:14 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.5
[09/26 01:18:21 visual_prompt]: Epoch 3 / 100: avg data time: 5.57e-02, avg batch time: 0.4970, average train loss: 4.6176
[09/26 01:18:22 visual_prompt]: Inference (val):avg data time: 2.01e-05, avg batch time: 0.1659, average loss: 4.6437
[09/26 01:18:22 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 4.50	
[09/26 01:18:22 visual_prompt]: Best epoch 3: best metric: 0.015
[09/26 01:18:22 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.75
[09/26 01:18:29 visual_prompt]: Epoch 4 / 100: avg data time: 4.90e-02, avg batch time: 0.4901, average train loss: 4.6058
[09/26 01:18:30 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1658, average loss: 4.6475
[09/26 01:18:30 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.50	
[09/26 01:18:30 visual_prompt]: Training 5 / 100 epoch, with learning rate 1.0
[09/26 01:18:37 visual_prompt]: Epoch 5 / 100: avg data time: 6.26e-02, avg batch time: 0.5035, average train loss: 4.6476
[09/26 01:18:39 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1658, average loss: 4.6383
[09/26 01:18:39 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.00	
[09/26 01:18:39 visual_prompt]: Training 6 / 100 epoch, with learning rate 1.25
[09/26 01:18:45 visual_prompt]: Epoch 6 / 100: avg data time: 4.87e-02, avg batch time: 0.4901, average train loss: 4.6635
[09/26 01:18:47 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1658, average loss: 4.6710
[09/26 01:18:47 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 4.50	
[09/26 01:18:47 visual_prompt]: Training 7 / 100 epoch, with learning rate 1.5
[09/26 01:18:54 visual_prompt]: Epoch 7 / 100: avg data time: 5.74e-02, avg batch time: 0.4990, average train loss: 4.6534
[09/26 01:18:55 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1657, average loss: 4.6650
[09/26 01:18:55 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.50	
[09/26 01:18:55 visual_prompt]: Training 8 / 100 epoch, with learning rate 1.75
[09/26 01:19:02 visual_prompt]: Epoch 8 / 100: avg data time: 5.89e-02, avg batch time: 0.5020, average train loss: 4.6630
[09/26 01:19:03 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1658, average loss: 4.7060
[09/26 01:19:03 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/26 01:19:03 visual_prompt]: Training 9 / 100 epoch, with learning rate 2.0
[09/26 01:19:10 visual_prompt]: Epoch 9 / 100: avg data time: 5.47e-02, avg batch time: 0.4953, average train loss: 4.7857
[09/26 01:19:12 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1659, average loss: 4.7125
[09/26 01:19:12 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/26 01:19:12 visual_prompt]: Training 10 / 100 epoch, with learning rate 2.25
[09/26 01:19:18 visual_prompt]: Epoch 10 / 100: avg data time: 5.33e-02, avg batch time: 0.4947, average train loss: 4.7192
[09/26 01:19:20 visual_prompt]: Inference (val):avg data time: 1.91e-05, avg batch time: 0.1659, average loss: 4.8188
[09/26 01:19:20 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.00	
[09/26 01:19:20 visual_prompt]: Training 11 / 100 epoch, with learning rate 2.5
[09/26 01:19:27 visual_prompt]: Epoch 11 / 100: avg data time: 6.10e-02, avg batch time: 0.5024, average train loss: 4.7095
[09/26 01:19:28 visual_prompt]: Inference (val):avg data time: 1.87e-05, avg batch time: 0.1659, average loss: 4.7340
[09/26 01:19:28 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 5.00	
[09/26 01:19:28 visual_prompt]: Best epoch 11: best metric: 0.020
[09/26 01:19:28 visual_prompt]: Training 12 / 100 epoch, with learning rate 2.4992385337738696
[09/26 01:19:35 visual_prompt]: Epoch 12 / 100: avg data time: 5.61e-02, avg batch time: 0.4970, average train loss: 4.7356
[09/26 01:19:36 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1661, average loss: 4.6814
[09/26 01:19:36 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.00	top5: 5.00	
[09/26 01:19:36 visual_prompt]: Training 13 / 100 epoch, with learning rate 2.4969550628247803
[09/26 01:19:43 visual_prompt]: Epoch 13 / 100: avg data time: 4.37e-02, avg batch time: 0.4854, average train loss: 4.7688
[09/26 01:19:44 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1657, average loss: 4.8067
[09/26 01:19:44 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 6.50	
[09/26 01:19:44 visual_prompt]: Training 14 / 100 epoch, with learning rate 2.4931523692103417
[09/26 01:19:51 visual_prompt]: Epoch 14 / 100: avg data time: 5.70e-02, avg batch time: 0.4982, average train loss: 4.7696
[09/26 01:19:53 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1661, average loss: 4.6940
[09/26 01:19:53 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.50	
[09/26 01:19:53 visual_prompt]: Training 15 / 100 epoch, with learning rate 2.487835085926963
[09/26 01:19:59 visual_prompt]: Epoch 15 / 100: avg data time: 5.78e-02, avg batch time: 0.5002, average train loss: 4.7408
[09/26 01:20:01 visual_prompt]: Inference (val):avg data time: 1.86e-05, avg batch time: 0.1661, average loss: 4.7033
[09/26 01:20:01 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.50	
[09/26 01:20:01 visual_prompt]: Training 16 / 100 epoch, with learning rate 2.4810096912652604
[09/26 01:20:08 visual_prompt]: Epoch 16 / 100: avg data time: 6.14e-02, avg batch time: 0.5039, average train loss: 4.7831
[09/26 01:20:09 visual_prompt]: Inference (val):avg data time: 1.96e-05, avg batch time: 0.1658, average loss: 4.7467
[09/26 01:20:09 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/26 01:20:09 visual_prompt]: Training 17 / 100 epoch, with learning rate 2.472684500917257
[09/26 01:20:16 visual_prompt]: Epoch 17 / 100: avg data time: 5.63e-02, avg batch time: 0.4973, average train loss: 4.7913
[09/26 01:20:17 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1660, average loss: 4.8039
[09/26 01:20:17 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 4.50	
[09/26 01:20:17 visual_prompt]: Training 18 / 100 epoch, with learning rate 2.4628696578449953
[09/26 01:20:24 visual_prompt]: Epoch 18 / 100: avg data time: 6.35e-02, avg batch time: 0.5055, average train loss: 4.7183
[09/26 01:20:26 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1660, average loss: 4.7154
[09/26 01:20:26 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.00	
[09/26 01:20:26 visual_prompt]: Training 19 / 100 epoch, with learning rate 2.4515771199228986
[09/26 01:20:32 visual_prompt]: Epoch 19 / 100: avg data time: 5.61e-02, avg batch time: 0.4979, average train loss: 4.7155
[09/26 01:20:34 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1659, average loss: 4.9950
[09/26 01:20:34 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 6.00	
[09/26 01:20:34 visual_prompt]: Training 20 / 100 epoch, with learning rate 2.438820645368942
[09/26 01:20:41 visual_prompt]: Epoch 20 / 100: avg data time: 5.66e-02, avg batch time: 0.4997, average train loss: 4.7580
[09/26 01:20:42 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.1660, average loss: 4.7890
[09/26 01:20:42 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 5.50	
[09/26 01:20:42 visual_prompt]: Training 21 / 100 epoch, with learning rate 2.4246157759823856
[09/26 01:20:49 visual_prompt]: Epoch 21 / 100: avg data time: 6.00e-02, avg batch time: 0.5011, average train loss: 4.7187
[09/26 01:20:51 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1660, average loss: 4.6902
[09/26 01:20:51 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.00	top5: 5.50	
[09/26 01:20:51 visual_prompt]: Training 22 / 100 epoch, with learning rate 2.4089798182084845
[09/26 01:20:57 visual_prompt]: Epoch 22 / 100: avg data time: 6.27e-02, avg batch time: 0.5048, average train loss: 4.7538
[09/26 01:20:59 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1663, average loss: 4.6750
[09/26 01:20:59 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.00	
[09/26 01:20:59 visual_prompt]: Training 23 / 100 epoch, with learning rate 2.391931822053251
[09/26 01:21:06 visual_prompt]: Epoch 23 / 100: avg data time: 5.18e-02, avg batch time: 0.4930, average train loss: 4.7476
[09/26 01:21:07 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1658, average loss: 4.7925
[09/26 01:21:07 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.00	
[09/26 01:21:07 visual_prompt]: Training 24 / 100 epoch, with learning rate 2.3734925578739587
[09/26 01:21:14 visual_prompt]: Epoch 24 / 100: avg data time: 5.15e-02, avg batch time: 0.4924, average train loss: 4.7467
[09/26 01:21:15 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1661, average loss: 4.7188
[09/26 01:21:15 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 5.00	
[09/26 01:21:15 visual_prompt]: Training 25 / 100 epoch, with learning rate 2.3536844910736585
[09/26 01:21:22 visual_prompt]: Epoch 25 / 100: avg data time: 6.22e-02, avg batch time: 0.5052, average train loss: 4.7039
[09/26 01:21:24 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1661, average loss: 4.7311
[09/26 01:21:24 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 3.50	
[09/26 01:21:24 visual_prompt]: Training 26 / 100 epoch, with learning rate 2.3325317547305486
[09/26 01:21:30 visual_prompt]: Epoch 26 / 100: avg data time: 5.78e-02, avg batch time: 0.5008, average train loss: 4.6898
[09/26 01:21:32 visual_prompt]: Inference (val):avg data time: 1.98e-05, avg batch time: 0.1659, average loss: 4.7256
[09/26 01:21:32 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.00	
[09/26 01:21:32 visual_prompt]: Training 27 / 100 epoch, with learning rate 2.310060120195532
[09/26 01:21:39 visual_prompt]: Epoch 27 / 100: avg data time: 5.57e-02, avg batch time: 0.4980, average train loss: 4.8024
[09/26 01:21:40 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.1663, average loss: 4.8373
[09/26 01:21:40 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.00	
[09/26 01:21:40 visual_prompt]: Training 28 / 100 epoch, with learning rate 2.286296965693802
[09/26 01:21:47 visual_prompt]: Epoch 28 / 100: avg data time: 6.20e-02, avg batch time: 0.5029, average train loss: 4.7878
[09/26 01:21:48 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1659, average loss: 4.7301
[09/26 01:21:48 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.00	
[09/26 01:21:48 visual_prompt]: Training 29 / 100 epoch, with learning rate 2.261271242968684
[09/26 01:21:55 visual_prompt]: Epoch 29 / 100: avg data time: 5.79e-02, avg batch time: 0.4989, average train loss: 4.7178
[09/26 01:21:57 visual_prompt]: Inference (val):avg data time: 1.87e-05, avg batch time: 0.1657, average loss: 4.7141
[09/26 01:21:57 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 6.50	
[09/26 01:21:57 visual_prompt]: Training 30 / 100 epoch, with learning rate 2.2350134420084022
[09/26 01:22:03 visual_prompt]: Epoch 30 / 100: avg data time: 4.48e-02, avg batch time: 0.4887, average train loss: 4.6972
[09/26 01:22:05 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1660, average loss: 4.7138
[09/26 01:22:05 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.00	
[09/26 01:22:05 visual_prompt]: Training 31 / 100 epoch, with learning rate 2.2075555538987226
[09/26 01:22:12 visual_prompt]: Epoch 31 / 100: avg data time: 5.56e-02, avg batch time: 0.4981, average train loss: 4.7601
[09/26 01:22:13 visual_prompt]: Inference (val):avg data time: 2.08e-05, avg batch time: 0.1660, average loss: 4.6624
[09/26 01:22:13 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 6.50	
[09/26 01:22:13 visual_prompt]: Training 32 / 100 epoch, with learning rate 2.178931031846743
[09/26 01:22:20 visual_prompt]: Epoch 32 / 100: avg data time: 5.93e-02, avg batch time: 0.5009, average train loss: 4.7085
[09/26 01:22:21 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1658, average loss: 4.7052
[09/26 01:22:21 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.50	
[09/26 01:22:21 visual_prompt]: Training 33 / 100 epoch, with learning rate 2.149174750423314
[09/26 01:22:28 visual_prompt]: Epoch 33 / 100: avg data time: 5.94e-02, avg batch time: 0.4992, average train loss: 4.8526
[09/26 01:22:30 visual_prompt]: Inference (val):avg data time: 1.98e-05, avg batch time: 0.1655, average loss: 4.7180
[09/26 01:22:30 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.00	
[09/26 01:22:30 visual_prompt]: Training 34 / 100 epoch, with learning rate 2.1183229630737466
[09/26 01:22:36 visual_prompt]: Epoch 34 / 100: avg data time: 5.85e-02, avg batch time: 0.4994, average train loss: 4.7025
[09/26 01:22:38 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1660, average loss: 5.3161
[09/26 01:22:38 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 9.00	
[09/26 01:22:38 visual_prompt]: Training 35 / 100 epoch, with learning rate 2.086413257948573
[09/26 01:22:45 visual_prompt]: Epoch 35 / 100: avg data time: 5.96e-02, avg batch time: 0.5005, average train loss: 4.7882
[09/26 01:22:46 visual_prompt]: Inference (val):avg data time: 1.98e-05, avg batch time: 0.1656, average loss: 4.7147
[09/26 01:22:46 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 5.50	
[09/26 01:22:46 visual_prompt]: Training 36 / 100 epoch, with learning rate 2.053484512108174
[09/26 01:22:53 visual_prompt]: Epoch 36 / 100: avg data time: 5.39e-02, avg batch time: 0.4940, average train loss: 4.7718
[09/26 01:22:54 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1657, average loss: 4.7318
[09/26 01:22:54 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/26 01:22:54 visual_prompt]: Training 37 / 100 epoch, with learning rate 2.019576844157073
[09/26 01:23:01 visual_prompt]: Epoch 37 / 100: avg data time: 5.58e-02, avg batch time: 0.4979, average train loss: 4.7420
[09/26 01:23:03 visual_prompt]: Inference (val):avg data time: 1.92e-05, avg batch time: 0.1658, average loss: 4.7382
[09/26 01:23:03 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.00	
[09/26 01:23:03 visual_prompt]: Training 38 / 100 epoch, with learning rate 1.9847315653655915
[09/26 01:23:09 visual_prompt]: Epoch 38 / 100: avg data time: 6.07e-02, avg batch time: 0.5015, average train loss: 4.7260
[09/26 01:23:11 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1660, average loss: 5.0293
[09/26 01:23:11 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 5.00	
[09/26 01:23:11 visual_prompt]: Training 39 / 100 epoch, with learning rate 1.9489911293384334
[09/26 01:23:18 visual_prompt]: Epoch 39 / 100: avg data time: 5.25e-02, avg batch time: 0.4950, average train loss: 4.7176
[09/26 01:23:19 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1659, average loss: 4.7318
[09/26 01:23:19 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.00	
[09/26 01:23:19 visual_prompt]: Training 40 / 100 epoch, with learning rate 1.912399080291506
[09/26 01:23:26 visual_prompt]: Epoch 40 / 100: avg data time: 6.13e-02, avg batch time: 0.5017, average train loss: 4.6849
[09/26 01:23:27 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1656, average loss: 4.6902
[09/26 01:23:27 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 4.00	
[09/26 01:23:27 visual_prompt]: Training 41 / 100 epoch, with learning rate 1.875
[09/26 01:23:34 visual_prompt]: Epoch 41 / 100: avg data time: 6.16e-02, avg batch time: 0.5032, average train loss: 4.7245
[09/26 01:23:36 visual_prompt]: Inference (val):avg data time: 2.02e-05, avg batch time: 0.1657, average loss: 4.7164
[09/26 01:23:36 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.00	
[09/26 01:23:36 visual_prompt]: Training 42 / 100 epoch, with learning rate 1.8368394534823635
[09/26 01:23:42 visual_prompt]: Epoch 42 / 100: avg data time: 5.36e-02, avg batch time: 0.4953, average train loss: 4.6607
[09/26 01:23:44 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1658, average loss: 4.6827
[09/26 01:23:44 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.00	
[09/26 01:23:44 visual_prompt]: Training 43 / 100 epoch, with learning rate 1.7979639334863466
[09/26 01:23:51 visual_prompt]: Epoch 43 / 100: avg data time: 6.23e-02, avg batch time: 0.5033, average train loss: 4.6489
[09/26 01:23:52 visual_prompt]: Inference (val):avg data time: 1.96e-05, avg batch time: 0.1657, average loss: 4.6959
[09/26 01:23:52 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 3.50	
[09/26 01:23:52 visual_prompt]: Training 44 / 100 epoch, with learning rate 1.7584208038447504
[09/26 01:23:59 visual_prompt]: Epoch 44 / 100: avg data time: 6.25e-02, avg batch time: 0.5035, average train loss: 4.6867
[09/26 01:24:01 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1657, average loss: 4.7266
[09/26 01:24:01 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.50	
[09/26 01:24:01 visual_prompt]: Training 45 / 100 epoch, with learning rate 1.7182582417698902
[09/26 01:24:07 visual_prompt]: Epoch 45 / 100: avg data time: 6.52e-02, avg batch time: 0.5064, average train loss: 4.6547
[09/26 01:24:09 visual_prompt]: Inference (val):avg data time: 2.00e-05, avg batch time: 0.1660, average loss: 4.8360
[09/26 01:24:09 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.00	
[09/26 01:24:09 visual_prompt]: Training 46 / 100 epoch, with learning rate 1.6775251791570862
[09/26 01:24:16 visual_prompt]: Epoch 46 / 100: avg data time: 4.84e-02, avg batch time: 0.4895, average train loss: 4.6550
[09/26 01:24:17 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1660, average loss: 4.7251
[09/26 01:24:17 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.50	
[09/26 01:24:17 visual_prompt]: Training 47 / 100 epoch, with learning rate 1.6362712429686843
[09/26 01:24:24 visual_prompt]: Epoch 47 / 100: avg data time: 6.23e-02, avg batch time: 0.5024, average train loss: 4.6394
[09/26 01:24:25 visual_prompt]: Inference (val):avg data time: 1.99e-05, avg batch time: 0.1659, average loss: 4.6385
[09/26 01:24:25 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.50	
[09/26 01:24:25 visual_prompt]: Training 48 / 100 epoch, with learning rate 1.5945466947712488
[09/26 01:24:32 visual_prompt]: Epoch 48 / 100: avg data time: 4.79e-02, avg batch time: 0.4899, average train loss: 4.6654
[09/26 01:24:34 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1657, average loss: 4.7192
[09/26 01:24:34 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.00	
[09/26 01:24:34 visual_prompt]: Training 49 / 100 epoch, with learning rate 1.5524023694995845
[09/26 01:24:40 visual_prompt]: Epoch 49 / 100: avg data time: 5.89e-02, avg batch time: 0.5003, average train loss: 4.7204
[09/26 01:24:42 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1660, average loss: 4.6907
[09/26 01:24:42 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 6.00	
[09/26 01:24:42 visual_prompt]: Training 50 / 100 epoch, with learning rate 1.509889613522199
[09/26 01:24:49 visual_prompt]: Epoch 50 / 100: avg data time: 5.40e-02, avg batch time: 0.4951, average train loss: 4.6948
[09/26 01:24:50 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1659, average loss: 4.6848
[09/26 01:24:50 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.50	
[09/26 01:24:50 visual_prompt]: Training 51 / 100 epoch, with learning rate 1.467060222083663
[09/26 01:24:57 visual_prompt]: Epoch 51 / 100: avg data time: 5.85e-02, avg batch time: 0.5003, average train loss: 4.6777
[09/26 01:24:58 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1660, average loss: 4.6501
[09/26 01:24:58 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 4.00	
[09/26 01:24:58 visual_prompt]: Training 52 / 100 epoch, with learning rate 1.4239663762000818
[09/26 01:25:05 visual_prompt]: Epoch 52 / 100: avg data time: 4.61e-02, avg batch time: 0.4895, average train loss: 4.6462
[09/26 01:25:07 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1657, average loss: 4.6684
[09/26 01:25:07 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 5.00	
[09/26 01:25:07 visual_prompt]: Training 53 / 100 epoch, with learning rate 1.380660579084567
[09/26 01:25:13 visual_prompt]: Epoch 53 / 100: avg data time: 5.93e-02, avg batch time: 0.4997, average train loss: 4.6424
[09/26 01:25:15 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1658, average loss: 4.6973
[09/26 01:25:15 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 3.00	
[09/26 01:25:15 visual_prompt]: Training 54 / 100 epoch, with learning rate 1.3371955921801564
[09/26 01:25:22 visual_prompt]: Epoch 54 / 100: avg data time: 6.19e-02, avg batch time: 0.5036, average train loss: 4.6363
[09/26 01:25:23 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1660, average loss: 4.6549
[09/26 01:25:23 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.00	
[09/26 01:25:23 visual_prompt]: Training 55 / 100 epoch, with learning rate 1.2936243708781263
[09/26 01:25:30 visual_prompt]: Epoch 55 / 100: avg data time: 6.26e-02, avg batch time: 0.5033, average train loss: 4.6348
[09/26 01:25:32 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1661, average loss: 4.6920
[09/26 01:25:32 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 4.00	
[09/26 01:25:32 visual_prompt]: Training 56 / 100 epoch, with learning rate 1.25
[09/26 01:25:38 visual_prompt]: Epoch 56 / 100: avg data time: 6.15e-02, avg batch time: 0.5030, average train loss: 4.6355
[09/26 01:25:40 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1661, average loss: 4.6636
[09/26 01:25:40 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.50	
[09/26 01:25:40 visual_prompt]: Training 57 / 100 epoch, with learning rate 1.2063756291218741
[09/26 01:25:47 visual_prompt]: Epoch 57 / 100: avg data time: 6.42e-02, avg batch time: 0.5054, average train loss: 4.6270
[09/26 01:25:48 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1658, average loss: 4.7043
[09/26 01:25:48 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.00	
[09/26 01:25:48 visual_prompt]: Training 58 / 100 epoch, with learning rate 1.1628044078198434
[09/26 01:25:55 visual_prompt]: Epoch 58 / 100: avg data time: 4.98e-02, avg batch time: 0.4914, average train loss: 4.6467
[09/26 01:25:56 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.1661, average loss: 4.6797
[09/26 01:25:56 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 5.00	
[09/26 01:25:56 visual_prompt]: Training 59 / 100 epoch, with learning rate 1.1193394209154333
[09/26 01:26:03 visual_prompt]: Epoch 59 / 100: avg data time: 6.00e-02, avg batch time: 0.5024, average train loss: 4.6473
[09/26 01:26:05 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1662, average loss: 4.6474
[09/26 01:26:05 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.00	
[09/26 01:26:05 visual_prompt]: Training 60 / 100 epoch, with learning rate 1.0760336237999186
[09/26 01:26:11 visual_prompt]: Epoch 60 / 100: avg data time: 4.75e-02, avg batch time: 0.4909, average train loss: 4.6529
[09/26 01:26:13 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1658, average loss: 4.6713
[09/26 01:26:13 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 6.00	
[09/26 01:26:13 visual_prompt]: Training 61 / 100 epoch, with learning rate 1.0329397779163372
[09/26 01:26:20 visual_prompt]: Epoch 61 / 100: avg data time: 5.40e-02, avg batch time: 0.4954, average train loss: 4.6176
[09/26 01:26:21 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1660, average loss: 4.6533
[09/26 01:26:21 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.50	
[09/26 01:26:21 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.990110386477801
[09/26 01:26:28 visual_prompt]: Epoch 62 / 100: avg data time: 6.19e-02, avg batch time: 0.5050, average train loss: 4.6237
[09/26 01:26:29 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1658, average loss: 4.7875
[09/26 01:26:29 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.50	
[09/26 01:26:29 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.9475976305004155
[09/26 01:26:36 visual_prompt]: Epoch 63 / 100: avg data time: 6.12e-02, avg batch time: 0.5015, average train loss: 4.6243
[09/26 01:26:38 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1658, average loss: 4.6490
[09/26 01:26:38 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 6.50	
[09/26 01:26:38 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.9054533052287511
[09/26 01:26:44 visual_prompt]: Epoch 64 / 100: avg data time: 4.81e-02, avg batch time: 0.4893, average train loss: 4.6522
[09/26 01:26:46 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1658, average loss: 4.6526
[09/26 01:26:46 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/26 01:26:46 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.8637287570313158
[09/26 01:26:53 visual_prompt]: Epoch 65 / 100: avg data time: 6.80e-02, avg batch time: 0.5085, average train loss: 4.6222
[09/26 01:26:54 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1658, average loss: 4.6570
[09/26 01:26:54 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.00	
[09/26 01:26:54 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.8224748208429142
[09/26 01:27:01 visual_prompt]: Epoch 66 / 100: avg data time: 5.07e-02, avg batch time: 0.4927, average train loss: 4.6013
[09/26 01:27:03 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1659, average loss: 4.6723
[09/26 01:27:03 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.00	
[09/26 01:27:03 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.7817417582301099
[09/26 01:27:09 visual_prompt]: Epoch 67 / 100: avg data time: 5.92e-02, avg batch time: 0.4999, average train loss: 4.5981
[09/26 01:27:11 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1661, average loss: 4.6844
[09/26 01:27:11 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.00	
[09/26 01:27:11 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.7415791961552499
[09/26 01:27:18 visual_prompt]: Epoch 68 / 100: avg data time: 6.14e-02, avg batch time: 0.5020, average train loss: 4.6305
[09/26 01:27:19 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1659, average loss: 4.6398
[09/26 01:27:19 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 6.00	
[09/26 01:27:19 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.7020360665136531
[09/26 01:27:26 visual_prompt]: Epoch 69 / 100: avg data time: 6.33e-02, avg batch time: 0.5047, average train loss: 4.5858
[09/26 01:27:28 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1657, average loss: 4.6561
[09/26 01:27:28 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 4.00	
[09/26 01:27:28 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.6631605465176369
[09/26 01:27:34 visual_prompt]: Epoch 70 / 100: avg data time: 6.45e-02, avg batch time: 0.5046, average train loss: 4.6326
[09/26 01:27:36 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1658, average loss: 4.6820
[09/26 01:27:36 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.00	
[09/26 01:27:36 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.6250000000000002
[09/26 01:27:43 visual_prompt]: Epoch 71 / 100: avg data time: 5.16e-02, avg batch time: 0.4923, average train loss: 4.6240
[09/26 01:27:44 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1660, average loss: 4.6547
[09/26 01:27:44 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.00	
[09/26 01:27:44 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.587600919708494
[09/26 01:27:51 visual_prompt]: Epoch 72 / 100: avg data time: 4.59e-02, avg batch time: 0.4887, average train loss: 4.6131
[09/26 01:27:52 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1660, average loss: 4.6448
[09/26 01:27:52 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 3.50	
[09/26 01:27:52 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.5510088706615667
[09/26 01:27:59 visual_prompt]: Epoch 73 / 100: avg data time: 6.15e-02, avg batch time: 0.5026, average train loss: 4.5868
[09/26 01:28:01 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1661, average loss: 4.6820
[09/26 01:28:01 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 3.00	
[09/26 01:28:01 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.5152684346344087
[09/26 01:28:07 visual_prompt]: Epoch 74 / 100: avg data time: 6.04e-02, avg batch time: 0.5015, average train loss: 4.6143
[09/26 01:28:09 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1662, average loss: 4.6508
[09/26 01:28:09 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.00	
[09/26 01:28:09 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.48042315584292716
[09/26 01:28:16 visual_prompt]: Epoch 75 / 100: avg data time: 6.32e-02, avg batch time: 0.5042, average train loss: 4.6193
[09/26 01:28:17 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1660, average loss: 4.6394
[09/26 01:28:17 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 6.00	
[09/26 01:28:17 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.4465154878918258
[09/26 01:28:24 visual_prompt]: Epoch 76 / 100: avg data time: 5.20e-02, avg batch time: 0.4962, average train loss: 4.6024
[09/26 01:28:26 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1659, average loss: 4.6432
[09/26 01:28:26 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.00	
[09/26 01:28:26 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.41358674205142765
[09/26 01:28:32 visual_prompt]: Epoch 77 / 100: avg data time: 5.67e-02, avg batch time: 0.4988, average train loss: 4.5931
[09/26 01:28:34 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1659, average loss: 4.6466
[09/26 01:28:34 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.00	
[09/26 01:28:34 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.3816770369262533
[09/26 01:28:41 visual_prompt]: Epoch 78 / 100: avg data time: 6.06e-02, avg batch time: 0.5018, average train loss: 4.5837
[09/26 01:28:42 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1660, average loss: 4.6534
[09/26 01:28:42 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.00	
[09/26 01:28:42 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.35082524957668626
[09/26 01:28:49 visual_prompt]: Epoch 79 / 100: avg data time: 4.48e-02, avg batch time: 0.4885, average train loss: 4.5804
[09/26 01:28:50 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1658, average loss: 4.6598
[09/26 01:28:50 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/26 01:28:50 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.32106896815325703
[09/26 01:28:57 visual_prompt]: Epoch 80 / 100: avg data time: 4.94e-02, avg batch time: 0.4900, average train loss: 4.5810
[09/26 01:28:59 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1658, average loss: 4.6424
[09/26 01:28:59 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.00	
[09/26 01:28:59 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.2924444461012776
[09/26 01:29:05 visual_prompt]: Epoch 81 / 100: avg data time: 4.82e-02, avg batch time: 0.4897, average train loss: 4.5766
[09/26 01:29:07 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1659, average loss: 4.6375
[09/26 01:29:07 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.00	
[09/26 01:29:07 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.26498655799159765
[09/26 01:29:14 visual_prompt]: Epoch 82 / 100: avg data time: 5.85e-02, avg batch time: 0.4999, average train loss: 4.5774
[09/26 01:29:15 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1660, average loss: 4.6337
[09/26 01:29:15 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.50	
[09/26 01:29:15 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.23872875703131582
[09/26 01:29:22 visual_prompt]: Epoch 83 / 100: avg data time: 5.44e-02, avg batch time: 0.4957, average train loss: 4.5620
[09/26 01:29:23 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1660, average loss: 4.6369
[09/26 01:29:23 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.50	
[09/26 01:29:23 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.21370303430619797
[09/26 01:29:30 visual_prompt]: Epoch 84 / 100: avg data time: 4.92e-02, avg batch time: 0.4908, average train loss: 4.5670
[09/26 01:29:32 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1657, average loss: 4.6292
[09/26 01:29:32 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.00	top5: 6.50	
[09/26 01:29:32 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.18993987980446755
[09/26 01:29:38 visual_prompt]: Epoch 85 / 100: avg data time: 6.09e-02, avg batch time: 0.5020, average train loss: 4.5469
[09/26 01:29:40 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1658, average loss: 4.6026
[09/26 01:29:40 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 7.00	
[09/26 01:29:40 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.16746824526945162
[09/26 01:29:47 visual_prompt]: Epoch 86 / 100: avg data time: 5.33e-02, avg batch time: 0.4940, average train loss: 4.5352
[09/26 01:29:48 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1659, average loss: 4.5866
[09/26 01:29:48 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 7.00	
[09/26 01:29:48 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.14631550892634126
[09/26 01:29:55 visual_prompt]: Epoch 87 / 100: avg data time: 6.26e-02, avg batch time: 0.5029, average train loss: 4.5555
[09/26 01:29:57 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1657, average loss: 4.6331
[09/26 01:29:57 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/26 01:29:57 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.12650744212604148
[09/26 01:30:03 visual_prompt]: Epoch 88 / 100: avg data time: 5.25e-02, avg batch time: 0.4930, average train loss: 4.5529
[09/26 01:30:05 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1658, average loss: 4.6290
[09/26 01:30:05 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.50	
[09/26 01:30:05 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.10806817794674878
[09/26 01:30:12 visual_prompt]: Epoch 89 / 100: avg data time: 5.60e-02, avg batch time: 0.4970, average train loss: 4.5523
[09/26 01:30:13 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1657, average loss: 4.6076
[09/26 01:30:13 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 8.00	
[09/26 01:30:13 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.09102018179151586
[09/26 01:30:20 visual_prompt]: Epoch 90 / 100: avg data time: 4.92e-02, avg batch time: 0.4897, average train loss: 4.4672
[09/26 01:30:21 visual_prompt]: Inference (val):avg data time: 1.95e-05, avg batch time: 0.1658, average loss: 4.7612
[09/26 01:30:21 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 6.00	
[09/26 01:30:21 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.0753842240176146
[09/26 01:30:28 visual_prompt]: Epoch 91 / 100: avg data time: 5.07e-02, avg batch time: 0.4930, average train loss: 4.5310
[09/26 01:30:29 visual_prompt]: Inference (val):avg data time: 2.05e-05, avg batch time: 0.1659, average loss: 4.5592
[09/26 01:30:29 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 8.00	
[09/26 01:30:29 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.061179354631058086
[09/26 01:30:36 visual_prompt]: Epoch 92 / 100: avg data time: 6.58e-02, avg batch time: 0.5097, average train loss: 4.4110
[09/26 01:30:38 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1659, average loss: 4.5872
[09/26 01:30:38 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 9.50	
[09/26 01:30:38 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.04842288007710138
[09/26 01:30:45 visual_prompt]: Epoch 93 / 100: avg data time: 6.11e-02, avg batch time: 0.5027, average train loss: 4.3935
[09/26 01:30:46 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1660, average loss: 4.5254
[09/26 01:30:46 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 10.50	
[09/26 01:30:46 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.03713034215500441
[09/26 01:30:53 visual_prompt]: Epoch 94 / 100: avg data time: 5.60e-02, avg batch time: 0.4970, average train loss: 4.3610
[09/26 01:30:54 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.1658, average loss: 4.5746
[09/26 01:30:54 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 9.50	
[09/26 01:30:54 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.02731549908274289
[09/26 01:31:01 visual_prompt]: Epoch 95 / 100: avg data time: 5.81e-02, avg batch time: 0.4982, average train loss: 4.3392
[09/26 01:31:03 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1657, average loss: 4.5161
[09/26 01:31:03 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 10.00	
[09/26 01:31:03 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.018990308734739975
[09/26 01:31:09 visual_prompt]: Epoch 96 / 100: avg data time: 5.68e-02, avg batch time: 0.4981, average train loss: 4.3126
[09/26 01:31:11 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1657, average loss: 4.5289
[09/26 01:31:11 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 10.00	
[09/26 01:31:11 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.012164914073037048
[09/26 01:31:18 visual_prompt]: Epoch 97 / 100: avg data time: 4.80e-02, avg batch time: 0.4916, average train loss: 4.2858
[09/26 01:31:19 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1657, average loss: 4.5169
[09/26 01:31:19 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.50	top5: 11.00	
[09/26 01:31:19 visual_prompt]: Best epoch 97: best metric: 0.025
[09/26 01:31:19 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.006847630789658388
[09/26 01:31:26 visual_prompt]: Epoch 98 / 100: avg data time: 6.32e-02, avg batch time: 0.5039, average train loss: 4.2513
[09/26 01:31:27 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1658, average loss: 4.5214
[09/26 01:31:27 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 3.00	top5: 10.50	
[09/26 01:31:27 visual_prompt]: Best epoch 98: best metric: 0.030
[09/26 01:31:27 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.003044937175219753
[09/26 01:31:34 visual_prompt]: Epoch 99 / 100: avg data time: 6.14e-02, avg batch time: 0.5024, average train loss: 4.2455
[09/26 01:31:36 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1658, average loss: 4.5392
[09/26 01:31:36 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.50	top5: 10.50	
[09/26 01:31:36 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0007614662261302974
[09/26 01:31:43 visual_prompt]: Epoch 100 / 100: avg data time: 7.11e-02, avg batch time: 0.5111, average train loss: 4.2332
[09/26 01:31:44 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1658, average loss: 4.5178
[09/26 01:31:44 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.50	top5: 10.50	
[09/26 01:31:44 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 01:31:44 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 01:31:44 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-cifar(num_classes=100)', 'DATA.NUMBER_CLASSES', '100', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 01:31:44 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 01:31:44 visual_prompt]: Training with config:
[09/26 01:31:44 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-cifar(num_classes=100)/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr2.5_wd0.001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 2.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-cifar(num_classes=100)', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 100, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 01:31:44 visual_prompt]: Loading training data...
[09/26 01:31:44 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[:800], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/26 01:31:45 visual_prompt]: Number of images: 800
[09/26 01:31:45 visual_prompt]: Number of classes: 100 / 100
[09/26 01:31:45 visual_prompt]: Loading validation data...
[09/26 01:31:45 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[45000:45200], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/26 01:31:45 visual_prompt]: Number of images: 200
[09/26 01:31:45 visual_prompt]: Number of classes: 90 / 100
[09/26 01:31:45 visual_prompt]: Constructing models...
[09/26 01:31:48 visual_prompt]: Total Parameters: 86336356	 Gradient Parameters: 537700
[09/26 01:31:48 visual_prompt]: tuned percent:0.623
[09/26 01:31:48 visual_prompt]: Device used for model: 0
[09/26 01:31:48 visual_prompt]: Setting up Evaluator...
[09/26 01:31:48 visual_prompt]: Setting up Trainer...
[09/26 01:31:48 visual_prompt]: 	Setting up the optimizer...
[09/26 01:31:48 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 01:31:55 visual_prompt]: Epoch 1 / 100: avg data time: 6.52e-02, avg batch time: 0.5059, average train loss: 4.6566
[09/26 01:31:56 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1655, average loss: 4.6218
[09/26 01:31:56 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 7.00	
[09/26 01:31:56 visual_prompt]: Best epoch 1: best metric: 0.010
[09/26 01:31:56 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.25
[09/26 01:32:03 visual_prompt]: Epoch 2 / 100: avg data time: 4.96e-02, avg batch time: 0.4901, average train loss: 4.6269
[09/26 01:32:05 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1656, average loss: 4.6543
[09/26 01:32:05 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 6.50	
[09/26 01:32:05 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.5
[09/26 01:32:11 visual_prompt]: Epoch 3 / 100: avg data time: 5.89e-02, avg batch time: 0.5008, average train loss: 4.6220
[09/26 01:32:13 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1657, average loss: 4.6429
[09/26 01:32:13 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.50	top5: 5.00	
[09/26 01:32:13 visual_prompt]: Best epoch 3: best metric: 0.025
[09/26 01:32:13 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.75
[09/26 01:32:20 visual_prompt]: Epoch 4 / 100: avg data time: 5.90e-02, avg batch time: 0.5007, average train loss: 4.6554
[09/26 01:32:21 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1659, average loss: 4.5873
[09/26 01:32:21 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 3.00	top5: 10.50	
[09/26 01:32:21 visual_prompt]: Best epoch 4: best metric: 0.030
[09/26 01:32:21 visual_prompt]: Training 5 / 100 epoch, with learning rate 1.0
[09/26 01:32:28 visual_prompt]: Epoch 5 / 100: avg data time: 5.71e-02, avg batch time: 0.4996, average train loss: 4.5751
[09/26 01:32:30 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1660, average loss: 4.5732
[09/26 01:32:30 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 3.00	top5: 11.50	
[09/26 01:32:30 visual_prompt]: Training 6 / 100 epoch, with learning rate 1.25
[09/26 01:32:36 visual_prompt]: Epoch 6 / 100: avg data time: 5.42e-02, avg batch time: 0.4956, average train loss: 4.4130
[09/26 01:32:38 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1662, average loss: 4.6663
[09/26 01:32:38 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 3.00	top5: 12.00	
[09/26 01:32:38 visual_prompt]: Training 7 / 100 epoch, with learning rate 1.5
[09/26 01:32:45 visual_prompt]: Epoch 7 / 100: avg data time: 5.07e-02, avg batch time: 0.4938, average train loss: 4.3764
[09/26 01:32:46 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1660, average loss: 4.4478
[09/26 01:32:46 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 4.00	top5: 10.50	
[09/26 01:32:46 visual_prompt]: Best epoch 7: best metric: 0.040
[09/26 01:32:46 visual_prompt]: Training 8 / 100 epoch, with learning rate 1.75
[09/26 01:32:53 visual_prompt]: Epoch 8 / 100: avg data time: 5.77e-02, avg batch time: 0.4997, average train loss: 4.2160
[09/26 01:32:54 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1661, average loss: 4.5235
[09/26 01:32:54 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 6.00	top5: 21.50	
[09/26 01:32:54 visual_prompt]: Best epoch 8: best metric: 0.060
[09/26 01:32:54 visual_prompt]: Training 9 / 100 epoch, with learning rate 2.0
[09/26 01:33:01 visual_prompt]: Epoch 9 / 100: avg data time: 4.35e-02, avg batch time: 0.4859, average train loss: 4.1262
[09/26 01:33:02 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1662, average loss: 4.1264
[09/26 01:33:02 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 10.50	top5: 27.50	
[09/26 01:33:02 visual_prompt]: Best epoch 9: best metric: 0.105
[09/26 01:33:02 visual_prompt]: Training 10 / 100 epoch, with learning rate 2.25
[09/26 01:33:09 visual_prompt]: Epoch 10 / 100: avg data time: 4.64e-02, avg batch time: 0.4897, average train loss: 3.9086
[09/26 01:33:11 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1661, average loss: 4.2434
[09/26 01:33:11 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 9.00	top5: 31.50	
[09/26 01:33:11 visual_prompt]: Training 11 / 100 epoch, with learning rate 2.5
[09/26 01:33:17 visual_prompt]: Epoch 11 / 100: avg data time: 5.43e-02, avg batch time: 0.4965, average train loss: 3.8946
[09/26 01:33:19 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1661, average loss: 4.1358
[09/26 01:33:19 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 10.00	top5: 28.00	
[09/26 01:33:19 visual_prompt]: Training 12 / 100 epoch, with learning rate 2.4992385337738696
[09/26 01:33:26 visual_prompt]: Epoch 12 / 100: avg data time: 5.24e-02, avg batch time: 0.4938, average train loss: 2.7232
[09/26 01:33:27 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1663, average loss: 2.7062
[09/26 01:33:27 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 31.00	top5: 67.50	
[09/26 01:33:27 visual_prompt]: Best epoch 12: best metric: 0.310
[09/26 01:33:27 visual_prompt]: Training 13 / 100 epoch, with learning rate 2.4969550628247803
[09/26 01:33:34 visual_prompt]: Epoch 13 / 100: avg data time: 5.88e-02, avg batch time: 0.5032, average train loss: 1.1986
[09/26 01:33:35 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1663, average loss: 2.0014
[09/26 01:33:35 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 51.00	top5: 78.50	
[09/26 01:33:35 visual_prompt]: Best epoch 13: best metric: 0.510
[09/26 01:33:35 visual_prompt]: Training 14 / 100 epoch, with learning rate 2.4931523692103417
[09/26 01:33:42 visual_prompt]: Epoch 14 / 100: avg data time: 5.62e-02, avg batch time: 0.4998, average train loss: 0.4752
[09/26 01:33:44 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1661, average loss: 1.5358
[09/26 01:33:44 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.00	top5: 84.50	
[09/26 01:33:44 visual_prompt]: Best epoch 14: best metric: 0.630
[09/26 01:33:44 visual_prompt]: Training 15 / 100 epoch, with learning rate 2.487835085926963
[09/26 01:33:51 visual_prompt]: Epoch 15 / 100: avg data time: 6.15e-02, avg batch time: 0.5038, average train loss: 0.2598
[09/26 01:33:52 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1661, average loss: 1.4273
[09/26 01:33:52 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 60.50	top5: 86.00	
[09/26 01:33:52 visual_prompt]: Training 16 / 100 epoch, with learning rate 2.4810096912652604
[09/26 01:33:59 visual_prompt]: Epoch 16 / 100: avg data time: 5.86e-02, avg batch time: 0.5010, average train loss: 0.1928
[09/26 01:34:00 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1661, average loss: 1.3767
[09/26 01:34:00 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 68.00	top5: 89.00	
[09/26 01:34:00 visual_prompt]: Best epoch 16: best metric: 0.680
[09/26 01:34:00 visual_prompt]: Training 17 / 100 epoch, with learning rate 2.472684500917257
[09/26 01:34:07 visual_prompt]: Epoch 17 / 100: avg data time: 5.88e-02, avg batch time: 0.5009, average train loss: 0.1918
[09/26 01:34:09 visual_prompt]: Inference (val):avg data time: 1.90e-05, avg batch time: 0.1662, average loss: 1.1709
[09/26 01:34:09 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 74.00	top5: 92.50	
[09/26 01:34:09 visual_prompt]: Best epoch 17: best metric: 0.740
[09/26 01:34:09 visual_prompt]: Training 18 / 100 epoch, with learning rate 2.4628696578449953
[09/26 01:34:15 visual_prompt]: Epoch 18 / 100: avg data time: 5.92e-02, avg batch time: 0.5032, average train loss: 0.8568
[09/26 01:34:17 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1670, average loss: 4.6969
[09/26 01:34:17 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 6.00	top5: 21.00	
[09/26 01:34:17 visual_prompt]: Training 19 / 100 epoch, with learning rate 2.4515771199228986
[09/26 01:34:24 visual_prompt]: Epoch 19 / 100: avg data time: 5.74e-02, avg batch time: 0.4988, average train loss: 2.9819
[09/26 01:34:25 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1662, average loss: 3.1890
[09/26 01:34:25 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 28.00	top5: 60.50	
[09/26 01:34:25 visual_prompt]: Training 20 / 100 epoch, with learning rate 2.438820645368942
[09/26 01:34:32 visual_prompt]: Epoch 20 / 100: avg data time: 3.95e-02, avg batch time: 0.4837, average train loss: 1.2257
[09/26 01:34:33 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1662, average loss: 1.8638
[09/26 01:34:33 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.50	top5: 83.00	
[09/26 01:34:33 visual_prompt]: Training 21 / 100 epoch, with learning rate 2.4246157759823856
[09/26 01:34:40 visual_prompt]: Epoch 21 / 100: avg data time: 4.74e-02, avg batch time: 0.4889, average train loss: 0.4839
[09/26 01:34:41 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1662, average loss: 1.5149
[09/26 01:34:41 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.50	top5: 84.00	
[09/26 01:34:41 visual_prompt]: Training 22 / 100 epoch, with learning rate 2.4089798182084845
[09/26 01:34:48 visual_prompt]: Epoch 22 / 100: avg data time: 5.69e-02, avg batch time: 0.4995, average train loss: 0.4285
[09/26 01:34:50 visual_prompt]: Inference (val):avg data time: 1.92e-05, avg batch time: 0.1663, average loss: 1.4125
[09/26 01:34:50 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.50	top5: 90.00	
[09/26 01:34:50 visual_prompt]: Training 23 / 100 epoch, with learning rate 2.391931822053251
[09/26 01:34:57 visual_prompt]: Epoch 23 / 100: avg data time: 5.78e-02, avg batch time: 0.5006, average train loss: 0.1947
[09/26 01:34:58 visual_prompt]: Inference (val):avg data time: 1.92e-05, avg batch time: 0.1662, average loss: 1.1679
[09/26 01:34:58 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 69.00	top5: 91.50	
[09/26 01:34:58 visual_prompt]: Training 24 / 100 epoch, with learning rate 2.3734925578739587
[09/26 01:35:05 visual_prompt]: Epoch 24 / 100: avg data time: 6.38e-02, avg batch time: 0.5056, average train loss: 0.2997
[09/26 01:35:06 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1661, average loss: 1.4805
[09/26 01:35:06 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.50	top5: 88.00	
[09/26 01:35:06 visual_prompt]: Training 25 / 100 epoch, with learning rate 2.3536844910736585
[09/26 01:35:13 visual_prompt]: Epoch 25 / 100: avg data time: 6.10e-02, avg batch time: 0.5027, average train loss: 0.2862
[09/26 01:35:15 visual_prompt]: Inference (val):avg data time: 1.98e-05, avg batch time: 0.1663, average loss: 1.5089
[09/26 01:35:15 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.00	top5: 87.50	
[09/26 01:35:15 visual_prompt]: Training 26 / 100 epoch, with learning rate 2.3325317547305486
[09/26 01:35:22 visual_prompt]: Epoch 26 / 100: avg data time: 5.29e-02, avg batch time: 0.4961, average train loss: 0.5416
[09/26 01:35:23 visual_prompt]: Inference (val):avg data time: 2.11e-05, avg batch time: 0.1662, average loss: 1.4492
[09/26 01:35:23 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.00	top5: 89.50	
[09/26 01:35:23 visual_prompt]: Training 27 / 100 epoch, with learning rate 2.310060120195532
[09/26 01:35:30 visual_prompt]: Epoch 27 / 100: avg data time: 5.59e-02, avg batch time: 0.4989, average train loss: 0.2906
[09/26 01:35:31 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1663, average loss: 1.3055
[09/26 01:35:31 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.50	top5: 89.50	
[09/26 01:35:31 visual_prompt]: Training 28 / 100 epoch, with learning rate 2.286296965693802
[09/26 01:35:38 visual_prompt]: Epoch 28 / 100: avg data time: 6.00e-02, avg batch time: 0.5022, average train loss: 0.1694
[09/26 01:35:40 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1663, average loss: 1.0970
[09/26 01:35:40 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 72.50	top5: 91.50	
[09/26 01:35:40 visual_prompt]: Training 29 / 100 epoch, with learning rate 2.261271242968684
[09/26 01:35:46 visual_prompt]: Epoch 29 / 100: avg data time: 5.56e-02, avg batch time: 0.4986, average train loss: 0.1631
[09/26 01:35:48 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1664, average loss: 1.2513
[09/26 01:35:48 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 70.50	top5: 90.00	
[09/26 01:35:48 visual_prompt]: Training 30 / 100 epoch, with learning rate 2.2350134420084022
[09/26 01:35:54 visual_prompt]: Epoch 30 / 100: avg data time: 4.50e-02, avg batch time: 0.4889, average train loss: 0.4848
[09/26 01:35:56 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1664, average loss: 1.2315
[09/26 01:35:56 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 72.00	top5: 88.50	
[09/26 01:35:56 visual_prompt]: Training 31 / 100 epoch, with learning rate 2.2075555538987226
[09/26 01:36:03 visual_prompt]: Epoch 31 / 100: avg data time: 6.13e-02, avg batch time: 0.5031, average train loss: 0.1547
[09/26 01:36:04 visual_prompt]: Inference (val):avg data time: 2.01e-05, avg batch time: 0.1664, average loss: 1.0733
[09/26 01:36:04 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 77.00	top5: 94.00	
[09/26 01:36:04 visual_prompt]: Best epoch 31: best metric: 0.770
[09/26 01:36:04 visual_prompt]: Training 32 / 100 epoch, with learning rate 2.178931031846743
[09/26 01:36:11 visual_prompt]: Epoch 32 / 100: avg data time: 5.83e-02, avg batch time: 0.5006, average train loss: 0.1122
[09/26 01:36:13 visual_prompt]: Inference (val):avg data time: 2.02e-05, avg batch time: 0.1665, average loss: 1.1283
[09/26 01:36:13 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 72.00	top5: 92.50	
[09/26 01:36:13 visual_prompt]: Training 33 / 100 epoch, with learning rate 2.149174750423314
[09/26 01:36:19 visual_prompt]: Epoch 33 / 100: avg data time: 5.65e-02, avg batch time: 0.4997, average train loss: 0.2318
[09/26 01:36:21 visual_prompt]: Inference (val):avg data time: 1.86e-05, avg batch time: 0.1663, average loss: 1.4627
[09/26 01:36:21 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.00	top5: 89.50	
[09/26 01:36:21 visual_prompt]: Training 34 / 100 epoch, with learning rate 2.1183229630737466
[09/26 01:36:28 visual_prompt]: Epoch 34 / 100: avg data time: 6.36e-02, avg batch time: 0.5062, average train loss: 1.2976
[09/26 01:36:29 visual_prompt]: Inference (val):avg data time: 1.97e-05, avg batch time: 0.1660, average loss: 4.4973
[09/26 01:36:29 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 6.00	top5: 16.50	
[09/26 01:36:29 visual_prompt]: Training 35 / 100 epoch, with learning rate 2.086413257948573
[09/26 01:36:36 visual_prompt]: Epoch 35 / 100: avg data time: 5.75e-02, avg batch time: 0.5007, average train loss: 4.0255
[09/26 01:36:37 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1661, average loss: 4.6581
[09/26 01:36:37 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.50	top5: 8.50	
[09/26 01:36:37 visual_prompt]: Training 36 / 100 epoch, with learning rate 2.053484512108174
[09/26 01:36:44 visual_prompt]: Epoch 36 / 100: avg data time: 5.98e-02, avg batch time: 0.5028, average train loss: 4.0942
[09/26 01:36:46 visual_prompt]: Inference (val):avg data time: 2.08e-05, avg batch time: 0.1663, average loss: 4.3717
[09/26 01:36:46 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 9.50	top5: 26.00	
[09/26 01:36:46 visual_prompt]: Training 37 / 100 epoch, with learning rate 2.019576844157073
[09/26 01:36:53 visual_prompt]: Epoch 37 / 100: avg data time: 5.90e-02, avg batch time: 0.5016, average train loss: 4.0582
[09/26 01:36:54 visual_prompt]: Inference (val):avg data time: 1.97e-05, avg batch time: 0.1662, average loss: 4.2694
[09/26 01:36:54 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 6.00	top5: 19.00	
[09/26 01:36:54 visual_prompt]: Training 38 / 100 epoch, with learning rate 1.9847315653655915
[09/26 01:37:01 visual_prompt]: Epoch 38 / 100: avg data time: 6.06e-02, avg batch time: 0.5029, average train loss: 3.3248
[09/26 01:37:02 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1664, average loss: 3.2400
[09/26 01:37:02 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 22.50	top5: 53.00	
[09/26 01:37:02 visual_prompt]: Training 39 / 100 epoch, with learning rate 1.9489911293384334
[09/26 01:37:09 visual_prompt]: Epoch 39 / 100: avg data time: 5.79e-02, avg batch time: 0.4997, average train loss: 1.9544
[09/26 01:37:11 visual_prompt]: Inference (val):avg data time: 1.94e-05, avg batch time: 0.1663, average loss: 2.5724
[09/26 01:37:11 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 38.00	top5: 69.00	
[09/26 01:37:11 visual_prompt]: Training 40 / 100 epoch, with learning rate 1.912399080291506
[09/26 01:37:17 visual_prompt]: Epoch 40 / 100: avg data time: 4.63e-02, avg batch time: 0.4882, average train loss: 1.1183
[09/26 01:37:19 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1664, average loss: 2.3647
[09/26 01:37:19 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 40.50	top5: 77.00	
[09/26 01:37:19 visual_prompt]: Training 41 / 100 epoch, with learning rate 1.875
[09/26 01:37:26 visual_prompt]: Epoch 41 / 100: avg data time: 5.98e-02, avg batch time: 0.5027, average train loss: 0.5677
[09/26 01:37:27 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.1663, average loss: 1.9911
[09/26 01:37:27 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 52.00	top5: 81.50	
[09/26 01:37:27 visual_prompt]: Training 42 / 100 epoch, with learning rate 1.8368394534823635
[09/26 01:37:34 visual_prompt]: Epoch 42 / 100: avg data time: 5.94e-02, avg batch time: 0.5017, average train loss: 0.3514
[09/26 01:37:35 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1664, average loss: 1.7427
[09/26 01:37:35 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 60.50	top5: 85.50	
[09/26 01:37:35 visual_prompt]: Training 43 / 100 epoch, with learning rate 1.7979639334863466
[09/26 01:37:42 visual_prompt]: Epoch 43 / 100: avg data time: 6.30e-02, avg batch time: 0.5047, average train loss: 0.2540
[09/26 01:37:44 visual_prompt]: Inference (val):avg data time: 1.97e-05, avg batch time: 0.1662, average loss: 1.6418
[09/26 01:37:44 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 56.00	top5: 88.00	
[09/26 01:37:44 visual_prompt]: Training 44 / 100 epoch, with learning rate 1.7584208038447504
[09/26 01:37:51 visual_prompt]: Epoch 44 / 100: avg data time: 6.18e-02, avg batch time: 0.5049, average train loss: 0.1922
[09/26 01:37:52 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1664, average loss: 1.5590
[09/26 01:37:52 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.50	top5: 88.50	
[09/26 01:37:52 visual_prompt]: Training 45 / 100 epoch, with learning rate 1.7182582417698902
[09/26 01:37:59 visual_prompt]: Epoch 45 / 100: avg data time: 6.12e-02, avg batch time: 0.5031, average train loss: 0.1597
[09/26 01:38:00 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1662, average loss: 1.4861
[09/26 01:38:00 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 64.50	top5: 89.50	
[09/26 01:38:00 visual_prompt]: Training 46 / 100 epoch, with learning rate 1.6775251791570862
[09/26 01:38:07 visual_prompt]: Epoch 46 / 100: avg data time: 4.97e-02, avg batch time: 0.4917, average train loss: 0.1526
[09/26 01:38:09 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1663, average loss: 1.3240
[09/26 01:38:09 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 69.50	top5: 90.50	
[09/26 01:38:09 visual_prompt]: Training 47 / 100 epoch, with learning rate 1.6362712429686843
[09/26 01:38:15 visual_prompt]: Epoch 47 / 100: avg data time: 5.90e-02, avg batch time: 0.5009, average train loss: 0.1365
[09/26 01:38:17 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1664, average loss: 1.2604
[09/26 01:38:17 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.50	top5: 94.00	
[09/26 01:38:17 visual_prompt]: Training 48 / 100 epoch, with learning rate 1.5945466947712488
[09/26 01:38:24 visual_prompt]: Epoch 48 / 100: avg data time: 6.39e-02, avg batch time: 0.5059, average train loss: 0.1755
[09/26 01:38:25 visual_prompt]: Inference (val):avg data time: 1.94e-05, avg batch time: 0.1663, average loss: 1.3527
[09/26 01:38:25 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.50	top5: 89.50	
[09/26 01:38:25 visual_prompt]: Training 49 / 100 epoch, with learning rate 1.5524023694995845
[09/26 01:38:32 visual_prompt]: Epoch 49 / 100: avg data time: 5.48e-02, avg batch time: 0.4973, average train loss: 0.4145
[09/26 01:38:33 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1666, average loss: 1.8385
[09/26 01:38:33 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 53.50	top5: 86.00	
[09/26 01:38:33 visual_prompt]: Training 50 / 100 epoch, with learning rate 1.509889613522199
[09/26 01:38:40 visual_prompt]: Epoch 50 / 100: avg data time: 6.27e-02, avg batch time: 0.5050, average train loss: 1.3142
[09/26 01:38:42 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1666, average loss: 1.4036
[09/26 01:38:42 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 68.50	top5: 89.50	
[09/26 01:38:42 visual_prompt]: Training 51 / 100 epoch, with learning rate 1.467060222083663
[09/26 01:38:49 visual_prompt]: Epoch 51 / 100: avg data time: 5.69e-02, avg batch time: 0.4998, average train loss: 0.2596
[09/26 01:38:50 visual_prompt]: Inference (val):avg data time: 1.75e-05, avg batch time: 0.1664, average loss: 1.3170
[09/26 01:38:50 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 68.00	top5: 88.50	
[09/26 01:38:50 visual_prompt]: Training 52 / 100 epoch, with learning rate 1.4239663762000818
[09/26 01:38:57 visual_prompt]: Epoch 52 / 100: avg data time: 6.05e-02, avg batch time: 0.5024, average train loss: 0.1679
[09/26 01:38:58 visual_prompt]: Inference (val):avg data time: 2.08e-05, avg batch time: 0.1667, average loss: 1.0969
[09/26 01:38:58 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 75.00	top5: 92.00	
[09/26 01:38:58 visual_prompt]: Training 53 / 100 epoch, with learning rate 1.380660579084567
[09/26 01:39:05 visual_prompt]: Epoch 53 / 100: avg data time: 5.21e-02, avg batch time: 0.4948, average train loss: 0.1033
[09/26 01:39:06 visual_prompt]: Inference (val):avg data time: 1.99e-05, avg batch time: 0.1665, average loss: 1.0523
[09/26 01:39:06 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 73.50	top5: 94.00	
[09/26 01:39:06 visual_prompt]: Training 54 / 100 epoch, with learning rate 1.3371955921801564
[09/26 01:39:13 visual_prompt]: Epoch 54 / 100: avg data time: 6.37e-02, avg batch time: 0.5056, average train loss: 0.0899
[09/26 01:39:15 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1664, average loss: 1.0662
[09/26 01:39:15 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 74.00	top5: 93.50	
[09/26 01:39:15 visual_prompt]: Training 55 / 100 epoch, with learning rate 1.2936243708781263
[09/26 01:39:22 visual_prompt]: Epoch 55 / 100: avg data time: 6.31e-02, avg batch time: 0.5059, average train loss: 0.0779
[09/26 01:39:23 visual_prompt]: Inference (val):avg data time: 1.98e-05, avg batch time: 0.1664, average loss: 1.0127
[09/26 01:39:23 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 77.00	top5: 95.00	
[09/26 01:39:23 visual_prompt]: Training 56 / 100 epoch, with learning rate 1.25
[09/26 01:39:30 visual_prompt]: Epoch 56 / 100: avg data time: 4.73e-02, avg batch time: 0.4903, average train loss: 0.0706
[09/26 01:39:31 visual_prompt]: Inference (val):avg data time: 2.11e-05, avg batch time: 0.1664, average loss: 1.0081
[09/26 01:39:31 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 78.00	top5: 94.50	
[09/26 01:39:31 visual_prompt]: Best epoch 56: best metric: 0.780
[09/26 01:39:31 visual_prompt]: Training 57 / 100 epoch, with learning rate 1.2063756291218741
[09/26 01:39:38 visual_prompt]: Epoch 57 / 100: avg data time: 4.80e-02, avg batch time: 0.4922, average train loss: 0.0827
[09/26 01:39:40 visual_prompt]: Inference (val):avg data time: 1.89e-05, avg batch time: 0.1663, average loss: 1.0192
[09/26 01:39:40 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 78.00	top5: 95.00	
[09/26 01:39:40 visual_prompt]: Training 58 / 100 epoch, with learning rate 1.1628044078198434
[09/26 01:39:46 visual_prompt]: Epoch 58 / 100: avg data time: 6.13e-02, avg batch time: 0.5030, average train loss: 0.0913
[09/26 01:39:48 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1663, average loss: 1.0125
[09/26 01:39:48 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 77.00	top5: 96.50	
[09/26 01:39:48 visual_prompt]: Training 59 / 100 epoch, with learning rate 1.1193394209154333
[09/26 01:39:55 visual_prompt]: Epoch 59 / 100: avg data time: 6.55e-02, avg batch time: 0.5074, average train loss: 0.0921
[09/26 01:39:56 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1664, average loss: 1.0093
[09/26 01:39:56 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 77.00	top5: 95.00	
[09/26 01:39:56 visual_prompt]: Training 60 / 100 epoch, with learning rate 1.0760336237999186
[09/26 01:40:03 visual_prompt]: Epoch 60 / 100: avg data time: 5.73e-02, avg batch time: 0.4998, average train loss: 0.0946
[09/26 01:40:05 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1663, average loss: 1.0798
[09/26 01:40:05 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 77.00	top5: 94.50	
[09/26 01:40:05 visual_prompt]: Training 61 / 100 epoch, with learning rate 1.0329397779163372
[09/26 01:40:11 visual_prompt]: Epoch 61 / 100: avg data time: 6.16e-02, avg batch time: 0.5032, average train loss: 0.1058
[09/26 01:40:13 visual_prompt]: Inference (val):avg data time: 1.96e-05, avg batch time: 0.1663, average loss: 1.5877
[09/26 01:40:13 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 64.00	top5: 88.00	
[09/26 01:40:13 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.990110386477801
[09/26 01:40:20 visual_prompt]: Epoch 62 / 100: avg data time: 5.90e-02, avg batch time: 0.5007, average train loss: 1.6955
[09/26 01:40:21 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1662, average loss: 4.1084
[09/26 01:40:21 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 9.50	top5: 35.00	
[09/26 01:40:21 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.9475976305004155
[09/26 01:40:28 visual_prompt]: Epoch 63 / 100: avg data time: 5.88e-02, avg batch time: 0.5013, average train loss: 1.9183
[09/26 01:40:29 visual_prompt]: Inference (val):avg data time: 1.94e-05, avg batch time: 0.1662, average loss: 1.6819
[09/26 01:40:29 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 64.00	top5: 87.00	
[09/26 01:40:29 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.9054533052287511
[09/26 01:40:36 visual_prompt]: Epoch 64 / 100: avg data time: 5.41e-02, avg batch time: 0.4978, average train loss: 0.7022
[09/26 01:40:38 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1663, average loss: 1.1755
[09/26 01:40:38 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 72.00	top5: 91.50	
[09/26 01:40:38 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.8637287570313158
[09/26 01:40:45 visual_prompt]: Epoch 65 / 100: avg data time: 6.41e-02, avg batch time: 0.5063, average train loss: 0.1516
[09/26 01:40:46 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1665, average loss: 1.0265
[09/26 01:40:46 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 74.00	top5: 91.50	
[09/26 01:40:46 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.8224748208429142
[09/26 01:40:53 visual_prompt]: Epoch 66 / 100: avg data time: 5.17e-02, avg batch time: 0.4943, average train loss: 0.0777
[09/26 01:40:54 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1665, average loss: 0.9555
[09/26 01:40:54 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 74.50	top5: 95.50	
[09/26 01:40:54 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.7817417582301099
[09/26 01:41:01 visual_prompt]: Epoch 67 / 100: avg data time: 4.92e-02, avg batch time: 0.4921, average train loss: 0.0577
[09/26 01:41:03 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1663, average loss: 0.9425
[09/26 01:41:03 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 76.00	top5: 95.50	
[09/26 01:41:03 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.7415791961552499
[09/26 01:41:09 visual_prompt]: Epoch 68 / 100: avg data time: 6.56e-02, avg batch time: 0.5078, average train loss: 0.0560
[09/26 01:41:11 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1666, average loss: 0.9240
[09/26 01:41:11 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 78.00	top5: 94.00	
[09/26 01:41:11 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.7020360665136531
[09/26 01:41:18 visual_prompt]: Epoch 69 / 100: avg data time: 5.81e-02, avg batch time: 0.5003, average train loss: 0.0554
[09/26 01:41:19 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1666, average loss: 0.9356
[09/26 01:41:19 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 77.00	top5: 96.50	
[09/26 01:41:19 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.6631605465176369
[09/26 01:41:26 visual_prompt]: Epoch 70 / 100: avg data time: 5.42e-02, avg batch time: 0.4959, average train loss: 0.0571
[09/26 01:41:28 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1665, average loss: 0.9373
[09/26 01:41:28 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 76.50	top5: 96.50	
[09/26 01:41:28 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.6250000000000002
[09/26 01:41:34 visual_prompt]: Epoch 71 / 100: avg data time: 5.64e-02, avg batch time: 0.4982, average train loss: 0.0564
[09/26 01:41:36 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1666, average loss: 0.9544
[09/26 01:41:36 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 78.50	top5: 96.00	
[09/26 01:41:36 visual_prompt]: Best epoch 71: best metric: 0.785
[09/26 01:41:36 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.587600919708494
[09/26 01:41:43 visual_prompt]: Epoch 72 / 100: avg data time: 6.25e-02, avg batch time: 0.5047, average train loss: 0.0567
[09/26 01:41:44 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1666, average loss: 0.9403
[09/26 01:41:44 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 77.00	top5: 96.50	
[09/26 01:41:44 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.5510088706615667
[09/26 01:41:51 visual_prompt]: Epoch 73 / 100: avg data time: 5.35e-02, avg batch time: 0.4954, average train loss: 0.0595
[09/26 01:41:53 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1662, average loss: 0.9517
[09/26 01:41:53 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 74.50	top5: 97.00	
[09/26 01:41:53 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.5152684346344087
[09/26 01:41:59 visual_prompt]: Epoch 74 / 100: avg data time: 4.45e-02, avg batch time: 0.4885, average train loss: 0.0579
[09/26 01:42:01 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1664, average loss: 0.9623
[09/26 01:42:01 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 76.00	top5: 96.50	
[09/26 01:42:01 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.48042315584292716
[09/26 01:42:07 visual_prompt]: Epoch 75 / 100: avg data time: 4.75e-02, avg batch time: 0.4896, average train loss: 0.0555
[09/26 01:42:09 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1665, average loss: 0.9589
[09/26 01:42:09 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 76.00	top5: 96.00	
[09/26 01:42:09 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.4465154878918258
[09/26 01:42:16 visual_prompt]: Epoch 76 / 100: avg data time: 5.98e-02, avg batch time: 0.5019, average train loss: 0.0547
[09/26 01:42:17 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1663, average loss: 0.9257
[09/26 01:42:17 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 78.50	top5: 95.50	
[09/26 01:42:17 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.41358674205142765
[09/26 01:42:24 visual_prompt]: Epoch 77 / 100: avg data time: 5.72e-02, avg batch time: 0.4999, average train loss: 0.0509
[09/26 01:42:25 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1665, average loss: 0.9363
[09/26 01:42:25 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 77.50	top5: 96.50	
[09/26 01:42:25 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.3816770369262533
[09/26 01:42:32 visual_prompt]: Epoch 78 / 100: avg data time: 6.04e-02, avg batch time: 0.5023, average train loss: 0.0480
[09/26 01:42:34 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1667, average loss: 0.9311
[09/26 01:42:34 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 76.50	top5: 96.50	
[09/26 01:42:34 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.35082524957668626
[09/26 01:42:41 visual_prompt]: Epoch 79 / 100: avg data time: 6.21e-02, avg batch time: 0.5044, average train loss: 0.0448
[09/26 01:42:42 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1665, average loss: 0.9215
[09/26 01:42:42 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 79.00	top5: 95.50	
[09/26 01:42:42 visual_prompt]: Best epoch 79: best metric: 0.790
[09/26 01:42:42 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.32106896815325703
[09/26 01:42:49 visual_prompt]: Epoch 80 / 100: avg data time: 6.18e-02, avg batch time: 0.5048, average train loss: 0.0436
[09/26 01:42:50 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1665, average loss: 0.9252
[09/26 01:42:50 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 77.50	top5: 96.50	
[09/26 01:42:50 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.2924444461012776
[09/26 01:42:57 visual_prompt]: Epoch 81 / 100: avg data time: 6.69e-02, avg batch time: 0.5085, average train loss: 0.0413
[09/26 01:42:59 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1666, average loss: 0.9270
[09/26 01:42:59 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 76.50	top5: 96.00	
[09/26 01:42:59 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.26498655799159765
[09/26 01:43:06 visual_prompt]: Epoch 82 / 100: avg data time: 6.94e-02, avg batch time: 0.5117, average train loss: 0.0397
[09/26 01:43:07 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1663, average loss: 0.9261
[09/26 01:43:07 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 79.00	top5: 96.00	
[09/26 01:43:07 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.23872875703131582
[09/26 01:43:14 visual_prompt]: Epoch 83 / 100: avg data time: 5.82e-02, avg batch time: 0.5008, average train loss: 0.0382
[09/26 01:43:16 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1666, average loss: 0.9414
[09/26 01:43:16 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 79.00	top5: 96.50	
[09/26 01:43:16 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.21370303430619797
[09/26 01:43:23 visual_prompt]: Epoch 84 / 100: avg data time: 6.16e-02, avg batch time: 0.5032, average train loss: 0.0377
[09/26 01:43:24 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1664, average loss: 0.9674
[09/26 01:43:24 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 75.00	top5: 96.50	
[09/26 01:43:24 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.18993987980446755
[09/26 01:43:31 visual_prompt]: Epoch 85 / 100: avg data time: 6.30e-02, avg batch time: 0.5052, average train loss: 0.0370
[09/26 01:43:32 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1665, average loss: 0.9725
[09/26 01:43:32 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 75.00	top5: 95.50	
[09/26 01:43:32 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.16746824526945162
[09/26 01:43:39 visual_prompt]: Epoch 86 / 100: avg data time: 4.65e-02, avg batch time: 0.4889, average train loss: 0.0376
[09/26 01:43:40 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1667, average loss: 0.9769
[09/26 01:43:40 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 75.50	top5: 95.50	
[09/26 01:43:40 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.14631550892634126
[09/26 01:43:47 visual_prompt]: Epoch 87 / 100: avg data time: 5.40e-02, avg batch time: 0.4974, average train loss: 0.0360
[09/26 01:43:49 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1667, average loss: 0.9310
[09/26 01:43:49 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 77.50	top5: 96.50	
[09/26 01:43:49 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.12650744212604148
[09/26 01:43:56 visual_prompt]: Epoch 88 / 100: avg data time: 5.93e-02, avg batch time: 0.5011, average train loss: 0.0356
[09/26 01:43:57 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1665, average loss: 0.9541
[09/26 01:43:57 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 76.00	top5: 96.50	
[09/26 01:43:57 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.10806817794674878
[09/26 01:44:04 visual_prompt]: Epoch 89 / 100: avg data time: 4.04e-02, avg batch time: 0.4847, average train loss: 0.0346
[09/26 01:44:05 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1667, average loss: 0.9469
[09/26 01:44:05 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 77.50	top5: 96.50	
[09/26 01:44:05 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.09102018179151586
[09/26 01:44:12 visual_prompt]: Epoch 90 / 100: avg data time: 5.54e-02, avg batch time: 0.4975, average train loss: 0.0342
[09/26 01:44:13 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1665, average loss: 0.9379
[09/26 01:44:13 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 76.50	top5: 96.50	
[09/26 01:44:13 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.0753842240176146
[09/26 01:44:20 visual_prompt]: Epoch 91 / 100: avg data time: 6.23e-02, avg batch time: 0.5046, average train loss: 0.0337
[09/26 01:44:22 visual_prompt]: Inference (val):avg data time: 1.92e-05, avg batch time: 0.1663, average loss: 0.9578
[09/26 01:44:22 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 75.00	top5: 96.50	
[09/26 01:44:22 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.061179354631058086
[09/26 01:44:28 visual_prompt]: Epoch 92 / 100: avg data time: 5.48e-02, avg batch time: 0.4972, average train loss: 0.0333
[09/26 01:44:30 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1663, average loss: 0.9635
[09/26 01:44:30 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 75.50	top5: 96.50	
[09/26 01:44:30 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.04842288007710138
[09/26 01:44:37 visual_prompt]: Epoch 93 / 100: avg data time: 5.67e-02, avg batch time: 0.4988, average train loss: 0.0334
[09/26 01:44:38 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1664, average loss: 0.9612
[09/26 01:44:38 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 77.00	top5: 96.00	
[09/26 01:44:38 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.03713034215500441
[09/26 01:44:45 visual_prompt]: Epoch 94 / 100: avg data time: 5.43e-02, avg batch time: 0.4969, average train loss: 0.0327
[09/26 01:44:46 visual_prompt]: Inference (val):avg data time: 1.98e-05, avg batch time: 0.1663, average loss: 0.9557
[09/26 01:44:46 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 77.50	top5: 96.50	
[09/26 01:44:46 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.02731549908274289
[09/26 01:44:53 visual_prompt]: Epoch 95 / 100: avg data time: 4.88e-02, avg batch time: 0.4917, average train loss: 0.0327
[09/26 01:44:55 visual_prompt]: Inference (val):avg data time: 1.85e-05, avg batch time: 0.1662, average loss: 0.9557
[09/26 01:44:55 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 77.50	top5: 96.50	
[09/26 01:44:55 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.018990308734739975
[09/26 01:45:01 visual_prompt]: Epoch 96 / 100: avg data time: 4.73e-02, avg batch time: 0.4901, average train loss: 0.0327
[09/26 01:45:03 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1664, average loss: 0.9571
[09/26 01:45:03 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 77.00	top5: 96.50	
[09/26 01:45:03 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.012164914073037048
[09/26 01:45:10 visual_prompt]: Epoch 97 / 100: avg data time: 5.55e-02, avg batch time: 0.4994, average train loss: 0.0326
[09/26 01:45:11 visual_prompt]: Inference (val):avg data time: 1.96e-05, avg batch time: 0.1663, average loss: 0.9623
[09/26 01:45:11 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 76.50	top5: 96.50	
[09/26 01:45:11 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.006847630789658388
[09/26 01:45:18 visual_prompt]: Epoch 98 / 100: avg data time: 5.84e-02, avg batch time: 0.5004, average train loss: 0.0324
[09/26 01:45:19 visual_prompt]: Inference (val):avg data time: 2.00e-05, avg batch time: 0.1662, average loss: 0.9646
[09/26 01:45:19 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 76.50	top5: 96.50	
[09/26 01:45:19 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.003044937175219753
[09/26 01:45:26 visual_prompt]: Epoch 99 / 100: avg data time: 5.50e-02, avg batch time: 0.4981, average train loss: 0.0325
[09/26 01:45:28 visual_prompt]: Inference (val):avg data time: 1.97e-05, avg batch time: 0.1661, average loss: 0.9649
[09/26 01:45:28 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 76.50	top5: 96.50	
[09/26 01:45:28 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0007614662261302974
[09/26 01:45:34 visual_prompt]: Epoch 100 / 100: avg data time: 5.12e-02, avg batch time: 0.4937, average train loss: 0.0322
[09/26 01:45:36 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1664, average loss: 0.9649
[09/26 01:45:36 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 77.00	top5: 96.50	
[09/26 01:45:36 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 01:45:36 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 01:45:36 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-cifar(num_classes=100)', 'DATA.NUMBER_CLASSES', '100', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 01:45:36 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 01:45:36 visual_prompt]: Training with config:
[09/26 01:45:36 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-cifar(num_classes=100)/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr2.5_wd0.0001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 2.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-cifar(num_classes=100)', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 100, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 01:45:36 visual_prompt]: Loading training data...
[09/26 01:45:36 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[:800], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/26 01:45:37 visual_prompt]: Number of images: 800
[09/26 01:45:37 visual_prompt]: Number of classes: 100 / 100
[09/26 01:45:37 visual_prompt]: Loading validation data...
[09/26 01:45:37 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[45000:45200], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/26 01:45:37 visual_prompt]: Number of images: 200
[09/26 01:45:37 visual_prompt]: Number of classes: 90 / 100
[09/26 01:45:37 visual_prompt]: Constructing models...
[09/26 01:45:40 visual_prompt]: Total Parameters: 86336356	 Gradient Parameters: 537700
[09/26 01:45:40 visual_prompt]: tuned percent:0.623
[09/26 01:45:40 visual_prompt]: Device used for model: 0
[09/26 01:45:40 visual_prompt]: Setting up Evaluator...
[09/26 01:45:40 visual_prompt]: Setting up Trainer...
[09/26 01:45:40 visual_prompt]: 	Setting up the optimizer...
[09/26 01:45:40 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 01:45:47 visual_prompt]: Epoch 1 / 100: avg data time: 6.34e-02, avg batch time: 0.5047, average train loss: 4.6562
[09/26 01:45:48 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1659, average loss: 4.6218
[09/26 01:45:48 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 7.00	
[09/26 01:45:48 visual_prompt]: Best epoch 1: best metric: 0.010
[09/26 01:45:48 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.25
[09/26 01:45:55 visual_prompt]: Epoch 2 / 100: avg data time: 6.25e-02, avg batch time: 0.5043, average train loss: 4.6327
[09/26 01:45:57 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1662, average loss: 4.6496
[09/26 01:45:57 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.00	
[09/26 01:45:57 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.5
[09/26 01:46:03 visual_prompt]: Epoch 3 / 100: avg data time: 4.77e-02, avg batch time: 0.4905, average train loss: 4.6045
[09/26 01:46:05 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.1661, average loss: 4.6247
[09/26 01:46:05 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 6.00	
[09/26 01:46:05 visual_prompt]: Best epoch 3: best metric: 0.020
[09/26 01:46:05 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.75
[09/26 01:46:11 visual_prompt]: Epoch 4 / 100: avg data time: 4.87e-02, avg batch time: 0.4906, average train loss: 4.5548
[09/26 01:46:13 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1661, average loss: 4.4610
[09/26 01:46:13 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 3.00	top5: 14.00	
[09/26 01:46:13 visual_prompt]: Best epoch 4: best metric: 0.030
[09/26 01:46:13 visual_prompt]: Training 5 / 100 epoch, with learning rate 1.0
[09/26 01:46:20 visual_prompt]: Epoch 5 / 100: avg data time: 5.98e-02, avg batch time: 0.5019, average train loss: 4.5461
[09/26 01:46:21 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1662, average loss: 4.5044
[09/26 01:46:21 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 3.50	top5: 9.50	
[09/26 01:46:21 visual_prompt]: Best epoch 5: best metric: 0.035
[09/26 01:46:21 visual_prompt]: Training 6 / 100 epoch, with learning rate 1.25
[09/26 01:46:28 visual_prompt]: Epoch 6 / 100: avg data time: 6.04e-02, avg batch time: 0.5017, average train loss: 4.1355
[09/26 01:46:30 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1664, average loss: 3.9385
[09/26 01:46:30 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 3.50	top5: 24.50	
[09/26 01:46:30 visual_prompt]: Training 7 / 100 epoch, with learning rate 1.5
[09/26 01:46:36 visual_prompt]: Epoch 7 / 100: avg data time: 5.73e-02, avg batch time: 0.5011, average train loss: 3.7001
[09/26 01:46:38 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1663, average loss: 3.9244
[09/26 01:46:38 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 7.00	top5: 24.00	
[09/26 01:46:38 visual_prompt]: Best epoch 7: best metric: 0.070
[09/26 01:46:38 visual_prompt]: Training 8 / 100 epoch, with learning rate 1.75
[09/26 01:46:45 visual_prompt]: Epoch 8 / 100: avg data time: 5.54e-02, avg batch time: 0.4971, average train loss: 4.4241
[09/26 01:46:46 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1661, average loss: 4.7726
[09/26 01:46:46 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 8.00	
[09/26 01:46:46 visual_prompt]: Training 9 / 100 epoch, with learning rate 2.0
[09/26 01:46:53 visual_prompt]: Epoch 9 / 100: avg data time: 6.36e-02, avg batch time: 0.5050, average train loss: 4.6299
[09/26 01:46:55 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1663, average loss: 4.5503
[09/26 01:46:55 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 5.50	top5: 12.00	
[09/26 01:46:55 visual_prompt]: Training 10 / 100 epoch, with learning rate 2.25
[09/26 01:47:01 visual_prompt]: Epoch 10 / 100: avg data time: 5.60e-02, avg batch time: 0.4972, average train loss: 4.0832
[09/26 01:47:03 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1663, average loss: 3.6907
[09/26 01:47:03 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 13.50	top5: 43.00	
[09/26 01:47:03 visual_prompt]: Best epoch 10: best metric: 0.135
[09/26 01:47:03 visual_prompt]: Training 11 / 100 epoch, with learning rate 2.5
[09/26 01:47:10 visual_prompt]: Epoch 11 / 100: avg data time: 5.96e-02, avg batch time: 0.5015, average train loss: 2.9611
[09/26 01:47:11 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1664, average loss: 3.5224
[09/26 01:47:11 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 22.50	top5: 54.00	
[09/26 01:47:11 visual_prompt]: Best epoch 11: best metric: 0.225
[09/26 01:47:11 visual_prompt]: Training 12 / 100 epoch, with learning rate 2.4992385337738696
[09/26 01:47:18 visual_prompt]: Epoch 12 / 100: avg data time: 5.07e-02, avg batch time: 0.4941, average train loss: 1.7876
[09/26 01:47:19 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1665, average loss: 2.3926
[09/26 01:47:20 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 41.00	top5: 77.00	
[09/26 01:47:20 visual_prompt]: Best epoch 12: best metric: 0.410
[09/26 01:47:20 visual_prompt]: Training 13 / 100 epoch, with learning rate 2.4969550628247803
[09/26 01:47:26 visual_prompt]: Epoch 13 / 100: avg data time: 5.84e-02, avg batch time: 0.5011, average train loss: 0.7071
[09/26 01:47:28 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1663, average loss: 1.9564
[09/26 01:47:28 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.00	top5: 85.00	
[09/26 01:47:28 visual_prompt]: Best epoch 13: best metric: 0.540
[09/26 01:47:28 visual_prompt]: Training 14 / 100 epoch, with learning rate 2.4931523692103417
[09/26 01:47:35 visual_prompt]: Epoch 14 / 100: avg data time: 5.17e-02, avg batch time: 0.4937, average train loss: 0.3103
[09/26 01:47:36 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1666, average loss: 2.0277
[09/26 01:47:36 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 52.00	top5: 86.00	
[09/26 01:47:36 visual_prompt]: Training 15 / 100 epoch, with learning rate 2.487835085926963
[09/26 01:47:43 visual_prompt]: Epoch 15 / 100: avg data time: 5.85e-02, avg batch time: 0.5002, average train loss: 0.1380
[09/26 01:47:44 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1667, average loss: 1.8790
[09/26 01:47:44 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 57.50	top5: 86.00	
[09/26 01:47:44 visual_prompt]: Best epoch 15: best metric: 0.575
[09/26 01:47:44 visual_prompt]: Training 16 / 100 epoch, with learning rate 2.4810096912652604
[09/26 01:47:51 visual_prompt]: Epoch 16 / 100: avg data time: 5.86e-02, avg batch time: 0.5006, average train loss: 0.0561
[09/26 01:47:53 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1666, average loss: 1.9547
[09/26 01:47:53 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 56.50	top5: 84.50	
[09/26 01:47:53 visual_prompt]: Training 17 / 100 epoch, with learning rate 2.472684500917257
[09/26 01:48:00 visual_prompt]: Epoch 17 / 100: avg data time: 5.76e-02, avg batch time: 0.4995, average train loss: 0.0169
[09/26 01:48:01 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1669, average loss: 1.6943
[09/26 01:48:01 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 60.00	top5: 89.50	
[09/26 01:48:01 visual_prompt]: Best epoch 17: best metric: 0.600
[09/26 01:48:01 visual_prompt]: Training 18 / 100 epoch, with learning rate 2.4628696578449953
[09/26 01:48:08 visual_prompt]: Epoch 18 / 100: avg data time: 5.61e-02, avg batch time: 0.4988, average train loss: 0.0124
[09/26 01:48:10 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1666, average loss: 1.6269
[09/26 01:48:10 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.50	top5: 90.00	
[09/26 01:48:10 visual_prompt]: Best epoch 18: best metric: 0.615
[09/26 01:48:10 visual_prompt]: Training 19 / 100 epoch, with learning rate 2.4515771199228986
[09/26 01:48:16 visual_prompt]: Epoch 19 / 100: avg data time: 6.57e-02, avg batch time: 0.5076, average train loss: 0.0083
[09/26 01:48:18 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1667, average loss: 1.5487
[09/26 01:48:18 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 89.50	
[09/26 01:48:18 visual_prompt]: Best epoch 19: best metric: 0.620
[09/26 01:48:18 visual_prompt]: Training 20 / 100 epoch, with learning rate 2.438820645368942
[09/26 01:48:24 visual_prompt]: Epoch 20 / 100: avg data time: 4.19e-02, avg batch time: 0.4850, average train loss: 0.0047
[09/26 01:48:26 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1666, average loss: 1.4647
[09/26 01:48:26 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 90.00	
[09/26 01:48:26 visual_prompt]: Training 21 / 100 epoch, with learning rate 2.4246157759823856
[09/26 01:48:33 visual_prompt]: Epoch 21 / 100: avg data time: 6.07e-02, avg batch time: 0.5030, average train loss: 0.0034
[09/26 01:48:35 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1664, average loss: 1.4154
[09/26 01:48:35 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.50	top5: 90.00	
[09/26 01:48:35 visual_prompt]: Best epoch 21: best metric: 0.635
[09/26 01:48:35 visual_prompt]: Training 22 / 100 epoch, with learning rate 2.4089798182084845
[09/26 01:48:41 visual_prompt]: Epoch 22 / 100: avg data time: 5.70e-02, avg batch time: 0.5000, average train loss: 0.0033
[09/26 01:48:43 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1666, average loss: 1.3795
[09/26 01:48:43 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.50	top5: 89.50	
[09/26 01:48:43 visual_prompt]: Training 23 / 100 epoch, with learning rate 2.391931822053251
[09/26 01:48:50 visual_prompt]: Epoch 23 / 100: avg data time: 5.97e-02, avg batch time: 0.5022, average train loss: 0.0037
[09/26 01:48:51 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1667, average loss: 1.3593
[09/26 01:48:51 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.00	top5: 91.00	
[09/26 01:48:51 visual_prompt]: Training 24 / 100 epoch, with learning rate 2.3734925578739587
[09/26 01:48:58 visual_prompt]: Epoch 24 / 100: avg data time: 5.35e-02, avg batch time: 0.4953, average train loss: 0.0043
[09/26 01:49:00 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1665, average loss: 1.3342
[09/26 01:49:00 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.50	top5: 90.50	
[09/26 01:49:00 visual_prompt]: Training 25 / 100 epoch, with learning rate 2.3536844910736585
[09/26 01:49:06 visual_prompt]: Epoch 25 / 100: avg data time: 5.36e-02, avg batch time: 0.4959, average train loss: 0.0044
[09/26 01:49:08 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1666, average loss: 1.3292
[09/26 01:49:08 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 90.50	
[09/26 01:49:08 visual_prompt]: Best epoch 25: best metric: 0.650
[09/26 01:49:08 visual_prompt]: Training 26 / 100 epoch, with learning rate 2.3325317547305486
[09/26 01:49:15 visual_prompt]: Epoch 26 / 100: avg data time: 6.05e-02, avg batch time: 0.5027, average train loss: 0.0048
[09/26 01:49:16 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1663, average loss: 1.3223
[09/26 01:49:16 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.50	top5: 90.50	
[09/26 01:49:16 visual_prompt]: Training 27 / 100 epoch, with learning rate 2.310060120195532
[09/26 01:49:23 visual_prompt]: Epoch 27 / 100: avg data time: 5.18e-02, avg batch time: 0.4940, average train loss: 0.0051
[09/26 01:49:24 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1663, average loss: 1.3015
[09/26 01:49:24 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 64.50	top5: 91.00	
[09/26 01:49:24 visual_prompt]: Training 28 / 100 epoch, with learning rate 2.286296965693802
[09/26 01:49:31 visual_prompt]: Epoch 28 / 100: avg data time: 5.79e-02, avg batch time: 0.5005, average train loss: 0.0054
[09/26 01:49:33 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1666, average loss: 1.2848
[09/26 01:49:33 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 64.00	top5: 89.50	
[09/26 01:49:33 visual_prompt]: Training 29 / 100 epoch, with learning rate 2.261271242968684
[09/26 01:49:39 visual_prompt]: Epoch 29 / 100: avg data time: 4.79e-02, avg batch time: 0.4908, average train loss: 0.0058
[09/26 01:49:41 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1663, average loss: 1.2869
[09/26 01:49:41 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.50	top5: 90.50	
[09/26 01:49:41 visual_prompt]: Best epoch 29: best metric: 0.665
[09/26 01:49:41 visual_prompt]: Training 30 / 100 epoch, with learning rate 2.2350134420084022
[09/26 01:49:48 visual_prompt]: Epoch 30 / 100: avg data time: 5.21e-02, avg batch time: 0.4934, average train loss: 0.0061
[09/26 01:49:49 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1663, average loss: 1.2616
[09/26 01:49:49 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.00	top5: 90.50	
[09/26 01:49:49 visual_prompt]: Best epoch 30: best metric: 0.670
[09/26 01:49:49 visual_prompt]: Training 31 / 100 epoch, with learning rate 2.2075555538987226
[09/26 01:49:56 visual_prompt]: Epoch 31 / 100: avg data time: 5.71e-02, avg batch time: 0.4989, average train loss: 0.0066
[09/26 01:49:58 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1663, average loss: 1.2824
[09/26 01:49:58 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.00	top5: 90.00	
[09/26 01:49:58 visual_prompt]: Training 32 / 100 epoch, with learning rate 2.178931031846743
[09/26 01:50:04 visual_prompt]: Epoch 32 / 100: avg data time: 5.65e-02, avg batch time: 0.4986, average train loss: 0.0069
[09/26 01:50:06 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1665, average loss: 1.2586
[09/26 01:50:06 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.50	top5: 90.00	
[09/26 01:50:06 visual_prompt]: Training 33 / 100 epoch, with learning rate 2.149174750423314
[09/26 01:50:12 visual_prompt]: Epoch 33 / 100: avg data time: 5.06e-02, avg batch time: 0.4929, average train loss: 0.0071
[09/26 01:50:14 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1664, average loss: 1.2557
[09/26 01:50:14 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.00	top5: 90.00	
[09/26 01:50:14 visual_prompt]: Training 34 / 100 epoch, with learning rate 2.1183229630737466
[09/26 01:50:21 visual_prompt]: Epoch 34 / 100: avg data time: 5.73e-02, avg batch time: 0.4989, average train loss: 0.0074
[09/26 01:50:22 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1662, average loss: 1.2584
[09/26 01:50:22 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.00	top5: 90.50	
[09/26 01:50:22 visual_prompt]: Training 35 / 100 epoch, with learning rate 2.086413257948573
[09/26 01:50:29 visual_prompt]: Epoch 35 / 100: avg data time: 5.54e-02, avg batch time: 0.4973, average train loss: 0.0080
[09/26 01:50:31 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1663, average loss: 1.2401
[09/26 01:50:31 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.50	top5: 90.00	
[09/26 01:50:31 visual_prompt]: Best epoch 35: best metric: 0.675
[09/26 01:50:31 visual_prompt]: Training 36 / 100 epoch, with learning rate 2.053484512108174
[09/26 01:50:37 visual_prompt]: Epoch 36 / 100: avg data time: 6.27e-02, avg batch time: 0.5041, average train loss: 0.0077
[09/26 01:50:39 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1663, average loss: 1.2259
[09/26 01:50:39 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 68.50	top5: 91.50	
[09/26 01:50:39 visual_prompt]: Best epoch 36: best metric: 0.685
[09/26 01:50:39 visual_prompt]: Training 37 / 100 epoch, with learning rate 2.019576844157073
[09/26 01:50:46 visual_prompt]: Epoch 37 / 100: avg data time: 5.64e-02, avg batch time: 0.4985, average train loss: 0.0079
[09/26 01:50:47 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1663, average loss: 1.2267
[09/26 01:50:47 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.50	top5: 91.00	
[09/26 01:50:47 visual_prompt]: Training 38 / 100 epoch, with learning rate 1.9847315653655915
[09/26 01:50:54 visual_prompt]: Epoch 38 / 100: avg data time: 5.68e-02, avg batch time: 0.4990, average train loss: 0.0080
[09/26 01:50:56 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1661, average loss: 1.2325
[09/26 01:50:56 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 68.50	top5: 91.00	
[09/26 01:50:56 visual_prompt]: Training 39 / 100 epoch, with learning rate 1.9489911293384334
[09/26 01:51:02 visual_prompt]: Epoch 39 / 100: avg data time: 4.01e-02, avg batch time: 0.4823, average train loss: 0.0080
[09/26 01:51:04 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1665, average loss: 1.2120
[09/26 01:51:04 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 68.00	top5: 91.50	
[09/26 01:51:04 visual_prompt]: Training 40 / 100 epoch, with learning rate 1.912399080291506
[09/26 01:51:10 visual_prompt]: Epoch 40 / 100: avg data time: 5.53e-02, avg batch time: 0.4978, average train loss: 0.0081
[09/26 01:51:12 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1665, average loss: 1.2079
[09/26 01:51:12 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 68.50	top5: 90.50	
[09/26 01:51:12 visual_prompt]: Training 41 / 100 epoch, with learning rate 1.875
[09/26 01:51:19 visual_prompt]: Epoch 41 / 100: avg data time: 5.26e-02, avg batch time: 0.4940, average train loss: 0.0086
[09/26 01:51:20 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1663, average loss: 1.2269
[09/26 01:51:20 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 70.00	top5: 91.00	
[09/26 01:51:20 visual_prompt]: Best epoch 41: best metric: 0.700
[09/26 01:51:20 visual_prompt]: Training 42 / 100 epoch, with learning rate 1.8368394534823635
[09/26 01:51:27 visual_prompt]: Epoch 42 / 100: avg data time: 4.84e-02, avg batch time: 0.4902, average train loss: 0.0085
[09/26 01:51:28 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1665, average loss: 1.1901
[09/26 01:51:28 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 69.50	top5: 91.00	
[09/26 01:51:28 visual_prompt]: Training 43 / 100 epoch, with learning rate 1.7979639334863466
[09/26 01:51:35 visual_prompt]: Epoch 43 / 100: avg data time: 5.55e-02, avg batch time: 0.4982, average train loss: 0.0084
[09/26 01:51:37 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1663, average loss: 1.1994
[09/26 01:51:37 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 68.50	top5: 92.00	
[09/26 01:51:37 visual_prompt]: Training 44 / 100 epoch, with learning rate 1.7584208038447504
[09/26 01:51:43 visual_prompt]: Epoch 44 / 100: avg data time: 5.72e-02, avg batch time: 0.4996, average train loss: 0.0084
[09/26 01:51:45 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1664, average loss: 1.1938
[09/26 01:51:45 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 69.00	top5: 92.00	
[09/26 01:51:45 visual_prompt]: Training 45 / 100 epoch, with learning rate 1.7182582417698902
[09/26 01:51:52 visual_prompt]: Epoch 45 / 100: avg data time: 5.87e-02, avg batch time: 0.5011, average train loss: 0.0083
[09/26 01:51:53 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1662, average loss: 1.1703
[09/26 01:51:53 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 70.50	top5: 92.00	
[09/26 01:51:53 visual_prompt]: Best epoch 45: best metric: 0.705
[09/26 01:51:53 visual_prompt]: Training 46 / 100 epoch, with learning rate 1.6775251791570862
[09/26 01:52:00 visual_prompt]: Epoch 46 / 100: avg data time: 5.19e-02, avg batch time: 0.4951, average train loss: 0.0084
[09/26 01:52:02 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1664, average loss: 1.1644
[09/26 01:52:02 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 68.50	top5: 92.50	
[09/26 01:52:02 visual_prompt]: Training 47 / 100 epoch, with learning rate 1.6362712429686843
[09/26 01:52:08 visual_prompt]: Epoch 47 / 100: avg data time: 5.60e-02, avg batch time: 0.4980, average train loss: 0.0083
[09/26 01:52:10 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1664, average loss: 1.1883
[09/26 01:52:10 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 70.00	top5: 92.00	
[09/26 01:52:10 visual_prompt]: Training 48 / 100 epoch, with learning rate 1.5945466947712488
[09/26 01:52:17 visual_prompt]: Epoch 48 / 100: avg data time: 5.99e-02, avg batch time: 0.5022, average train loss: 0.0082
[09/26 01:52:18 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1661, average loss: 1.1647
[09/26 01:52:18 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 70.00	top5: 92.50	
[09/26 01:52:18 visual_prompt]: Training 49 / 100 epoch, with learning rate 1.5524023694995845
[09/26 01:52:25 visual_prompt]: Epoch 49 / 100: avg data time: 5.82e-02, avg batch time: 0.5012, average train loss: 0.0082
[09/26 01:52:26 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1664, average loss: 1.1670
[09/26 01:52:27 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 71.00	top5: 92.00	
[09/26 01:52:27 visual_prompt]: Best epoch 49: best metric: 0.710
[09/26 01:52:27 visual_prompt]: Training 50 / 100 epoch, with learning rate 1.509889613522199
[09/26 01:52:33 visual_prompt]: Epoch 50 / 100: avg data time: 5.11e-02, avg batch time: 0.4935, average train loss: 0.0083
[09/26 01:52:35 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1662, average loss: 1.1555
[09/26 01:52:35 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 68.50	top5: 92.00	
[09/26 01:52:35 visual_prompt]: Training 51 / 100 epoch, with learning rate 1.467060222083663
[09/26 01:52:42 visual_prompt]: Epoch 51 / 100: avg data time: 6.47e-02, avg batch time: 0.5059, average train loss: 0.0079
[09/26 01:52:43 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1664, average loss: 1.1390
[09/26 01:52:43 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 71.00	top5: 91.50	
[09/26 01:52:43 visual_prompt]: Training 52 / 100 epoch, with learning rate 1.4239663762000818
[09/26 01:52:50 visual_prompt]: Epoch 52 / 100: avg data time: 5.99e-02, avg batch time: 0.5011, average train loss: 0.0080
[09/26 01:52:51 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1662, average loss: 1.1323
[09/26 01:52:51 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 70.00	top5: 92.50	
[09/26 01:52:51 visual_prompt]: Training 53 / 100 epoch, with learning rate 1.380660579084567
[09/26 01:52:58 visual_prompt]: Epoch 53 / 100: avg data time: 4.77e-02, avg batch time: 0.4915, average train loss: 0.0079
[09/26 01:53:00 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1661, average loss: 1.1504
[09/26 01:53:00 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 68.50	top5: 92.50	
[09/26 01:53:00 visual_prompt]: Training 54 / 100 epoch, with learning rate 1.3371955921801564
[09/26 01:53:06 visual_prompt]: Epoch 54 / 100: avg data time: 6.04e-02, avg batch time: 0.5024, average train loss: 0.0076
[09/26 01:53:08 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1661, average loss: 1.1586
[09/26 01:53:08 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 70.50	top5: 93.00	
[09/26 01:53:08 visual_prompt]: Training 55 / 100 epoch, with learning rate 1.2936243708781263
[09/26 01:53:15 visual_prompt]: Epoch 55 / 100: avg data time: 6.05e-02, avg batch time: 0.5026, average train loss: 0.0076
[09/26 01:53:16 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1663, average loss: 1.1551
[09/26 01:53:16 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 69.50	top5: 92.50	
[09/26 01:53:16 visual_prompt]: Training 56 / 100 epoch, with learning rate 1.25
[09/26 01:53:23 visual_prompt]: Epoch 56 / 100: avg data time: 5.80e-02, avg batch time: 0.4993, average train loss: 0.0074
[09/26 01:53:25 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1663, average loss: 1.1308
[09/26 01:53:25 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 68.50	top5: 94.00	
[09/26 01:53:25 visual_prompt]: Training 57 / 100 epoch, with learning rate 1.2063756291218741
[09/26 01:53:31 visual_prompt]: Epoch 57 / 100: avg data time: 5.95e-02, avg batch time: 0.5006, average train loss: 0.0074
[09/26 01:53:33 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1662, average loss: 1.1150
[09/26 01:53:33 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 71.50	top5: 92.50	
[09/26 01:53:33 visual_prompt]: Best epoch 57: best metric: 0.715
[09/26 01:53:33 visual_prompt]: Training 58 / 100 epoch, with learning rate 1.1628044078198434
[09/26 01:53:40 visual_prompt]: Epoch 58 / 100: avg data time: 5.00e-02, avg batch time: 0.4919, average train loss: 0.0072
[09/26 01:53:41 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1662, average loss: 1.1210
[09/26 01:53:41 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 71.00	top5: 93.00	
[09/26 01:53:41 visual_prompt]: Training 59 / 100 epoch, with learning rate 1.1193394209154333
[09/26 01:53:48 visual_prompt]: Epoch 59 / 100: avg data time: 5.72e-02, avg batch time: 0.4989, average train loss: 0.0070
[09/26 01:53:49 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1661, average loss: 1.0998
[09/26 01:53:49 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 70.00	top5: 93.50	
[09/26 01:53:49 visual_prompt]: Training 60 / 100 epoch, with learning rate 1.0760336237999186
[09/26 01:53:56 visual_prompt]: Epoch 60 / 100: avg data time: 5.10e-02, avg batch time: 0.4930, average train loss: 0.0070
[09/26 01:53:58 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1663, average loss: 1.1300
[09/26 01:53:58 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 69.00	top5: 94.00	
[09/26 01:53:58 visual_prompt]: Training 61 / 100 epoch, with learning rate 1.0329397779163372
[09/26 01:54:05 visual_prompt]: Epoch 61 / 100: avg data time: 6.09e-02, avg batch time: 0.5037, average train loss: 0.0070
[09/26 01:54:06 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1662, average loss: 1.1121
[09/26 01:54:06 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 69.50	top5: 93.50	
[09/26 01:54:06 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.990110386477801
[09/26 01:54:13 visual_prompt]: Epoch 62 / 100: avg data time: 5.18e-02, avg batch time: 0.4939, average train loss: 0.0068
[09/26 01:54:14 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1662, average loss: 1.1167
[09/26 01:54:14 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 71.50	top5: 94.50	
[09/26 01:54:14 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.9475976305004155
[09/26 01:54:21 visual_prompt]: Epoch 63 / 100: avg data time: 5.10e-02, avg batch time: 0.4923, average train loss: 0.0068
[09/26 01:54:22 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1662, average loss: 1.1054
[09/26 01:54:22 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 71.00	top5: 94.00	
[09/26 01:54:22 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.9054533052287511
[09/26 01:54:29 visual_prompt]: Epoch 64 / 100: avg data time: 6.23e-02, avg batch time: 0.5041, average train loss: 0.0067
[09/26 01:54:31 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1663, average loss: 1.1038
[09/26 01:54:31 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 72.00	top5: 94.50	
[09/26 01:54:31 visual_prompt]: Best epoch 64: best metric: 0.720
[09/26 01:54:31 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.8637287570313158
[09/26 01:54:37 visual_prompt]: Epoch 65 / 100: avg data time: 6.15e-02, avg batch time: 0.5030, average train loss: 0.0067
[09/26 01:54:39 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1661, average loss: 1.1197
[09/26 01:54:39 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 70.00	top5: 93.50	
[09/26 01:54:39 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.8224748208429142
[09/26 01:54:46 visual_prompt]: Epoch 66 / 100: avg data time: 5.02e-02, avg batch time: 0.4923, average train loss: 0.0066
[09/26 01:54:47 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1663, average loss: 1.1121
[09/26 01:54:47 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 69.50	top5: 93.00	
[09/26 01:54:47 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.7817417582301099
[09/26 01:54:54 visual_prompt]: Epoch 67 / 100: avg data time: 5.07e-02, avg batch time: 0.4920, average train loss: 0.0064
[09/26 01:54:55 visual_prompt]: Inference (val):avg data time: 3.51e-05, avg batch time: 0.1661, average loss: 1.1094
[09/26 01:54:55 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 70.50	top5: 93.00	
[09/26 01:54:55 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.7415791961552499
[09/26 01:55:02 visual_prompt]: Epoch 68 / 100: avg data time: 5.59e-02, avg batch time: 0.4982, average train loss: 0.0064
[09/26 01:55:04 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1661, average loss: 1.1133
[09/26 01:55:04 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 69.50	top5: 93.50	
[09/26 01:55:04 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.7020360665136531
[09/26 01:55:10 visual_prompt]: Epoch 69 / 100: avg data time: 5.13e-02, avg batch time: 0.4935, average train loss: 0.0064
[09/26 01:55:12 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1662, average loss: 1.1096
[09/26 01:55:12 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 70.50	top5: 93.00	
[09/26 01:55:12 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.6631605465176369
[09/26 01:55:18 visual_prompt]: Epoch 70 / 100: avg data time: 4.63e-02, avg batch time: 0.4877, average train loss: 0.0062
[09/26 01:55:20 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1662, average loss: 1.1148
[09/26 01:55:20 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 69.50	top5: 94.50	
[09/26 01:55:20 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.6250000000000002
[09/26 01:55:27 visual_prompt]: Epoch 71 / 100: avg data time: 5.64e-02, avg batch time: 0.4980, average train loss: 0.0063
[09/26 01:55:28 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1662, average loss: 1.1091
[09/26 01:55:28 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 70.00	top5: 94.00	
[09/26 01:55:28 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.587600919708494
[09/26 01:55:35 visual_prompt]: Epoch 72 / 100: avg data time: 6.06e-02, avg batch time: 0.5019, average train loss: 0.0061
[09/26 01:55:37 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1662, average loss: 1.1069
[09/26 01:55:37 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 70.50	top5: 94.50	
[09/26 01:55:37 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.5510088706615667
[09/26 01:55:43 visual_prompt]: Epoch 73 / 100: avg data time: 4.74e-02, avg batch time: 0.4894, average train loss: 0.0061
[09/26 01:55:45 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1660, average loss: 1.1262
[09/26 01:55:45 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 68.00	top5: 94.00	
[09/26 01:55:45 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.5152684346344087
[09/26 01:55:51 visual_prompt]: Epoch 74 / 100: avg data time: 6.01e-02, avg batch time: 0.5023, average train loss: 0.0061
[09/26 01:55:53 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1663, average loss: 1.1242
[09/26 01:55:53 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 68.50	top5: 94.00	
[09/26 01:55:53 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.48042315584292716
[09/26 01:56:00 visual_prompt]: Epoch 75 / 100: avg data time: 5.80e-02, avg batch time: 0.4992, average train loss: 0.0061
[09/26 01:56:01 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1661, average loss: 1.1159
[09/26 01:56:01 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 68.00	top5: 94.50	
[09/26 01:56:01 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.4465154878918258
[09/26 01:56:08 visual_prompt]: Epoch 76 / 100: avg data time: 6.76e-02, avg batch time: 0.5086, average train loss: 0.0058
[09/26 01:56:10 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1662, average loss: 1.1323
[09/26 01:56:10 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.00	top5: 94.00	
[09/26 01:56:10 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.41358674205142765
[09/26 01:56:16 visual_prompt]: Epoch 77 / 100: avg data time: 4.28e-02, avg batch time: 0.4863, average train loss: 0.0060
[09/26 01:56:18 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1660, average loss: 1.1297
[09/26 01:56:18 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 68.00	top5: 94.00	
[09/26 01:56:18 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.3816770369262533
[09/26 01:56:24 visual_prompt]: Epoch 78 / 100: avg data time: 4.47e-02, avg batch time: 0.4861, average train loss: 0.0060
[09/26 01:56:26 visual_prompt]: Inference (val):avg data time: 2.11e-05, avg batch time: 0.1661, average loss: 1.1226
[09/26 01:56:26 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 68.50	top5: 94.00	
[09/26 01:56:26 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.35082524957668626
[09/26 01:56:33 visual_prompt]: Epoch 79 / 100: avg data time: 5.60e-02, avg batch time: 0.4974, average train loss: 0.0058
[09/26 01:56:34 visual_prompt]: Inference (val):avg data time: 2.01e-05, avg batch time: 0.1660, average loss: 1.1218
[09/26 01:56:34 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 68.00	top5: 94.00	
[09/26 01:56:34 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.32106896815325703
[09/26 01:56:41 visual_prompt]: Epoch 80 / 100: avg data time: 5.87e-02, avg batch time: 0.5006, average train loss: 0.0058
[09/26 01:56:43 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1660, average loss: 1.1241
[09/26 01:56:43 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 68.50	top5: 94.00	
[09/26 01:56:43 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.2924444461012776
[09/26 01:56:49 visual_prompt]: Epoch 81 / 100: avg data time: 5.82e-02, avg batch time: 0.4995, average train loss: 0.0059
[09/26 01:56:51 visual_prompt]: Inference (val):avg data time: 1.87e-05, avg batch time: 0.1658, average loss: 1.1157
[09/26 01:56:51 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 68.00	top5: 94.00	
[09/26 01:56:51 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.26498655799159765
[09/26 01:56:58 visual_prompt]: Epoch 82 / 100: avg data time: 5.95e-02, avg batch time: 0.5004, average train loss: 0.0059
[09/26 01:56:59 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1659, average loss: 1.1085
[09/26 01:56:59 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 68.00	top5: 93.50	
[09/26 01:56:59 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.23872875703131582
[09/26 01:57:06 visual_prompt]: Epoch 83 / 100: avg data time: 5.50e-02, avg batch time: 0.4965, average train loss: 0.0057
[09/26 01:57:07 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1661, average loss: 1.1112
[09/26 01:57:07 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 68.00	top5: 94.00	
[09/26 01:57:07 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.21370303430619797
[09/26 01:57:14 visual_prompt]: Epoch 84 / 100: avg data time: 5.01e-02, avg batch time: 0.4917, average train loss: 0.0057
[09/26 01:57:16 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1660, average loss: 1.1125
[09/26 01:57:16 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 68.00	top5: 94.50	
[09/26 01:57:16 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.18993987980446755
[09/26 01:57:22 visual_prompt]: Epoch 85 / 100: avg data time: 5.94e-02, avg batch time: 0.5019, average train loss: 0.0057
[09/26 01:57:24 visual_prompt]: Inference (val):avg data time: 1.93e-05, avg batch time: 0.1660, average loss: 1.1181
[09/26 01:57:24 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 68.00	top5: 94.00	
[09/26 01:57:24 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.16746824526945162
[09/26 01:57:31 visual_prompt]: Epoch 86 / 100: avg data time: 5.78e-02, avg batch time: 0.4989, average train loss: 0.0058
[09/26 01:57:32 visual_prompt]: Inference (val):avg data time: 4.04e-05, avg batch time: 0.1662, average loss: 1.1170
[09/26 01:57:32 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 68.00	top5: 94.00	
[09/26 01:57:32 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.14631550892634126
[09/26 01:57:39 visual_prompt]: Epoch 87 / 100: avg data time: 6.93e-02, avg batch time: 0.5099, average train loss: 0.0056
[09/26 01:57:41 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1661, average loss: 1.1079
[09/26 01:57:41 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 68.50	top5: 94.00	
[09/26 01:57:41 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.12650744212604148
[09/26 01:57:48 visual_prompt]: Epoch 88 / 100: avg data time: 6.16e-02, avg batch time: 0.5023, average train loss: 0.0056
[09/26 01:57:49 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1659, average loss: 1.1144
[09/26 01:57:49 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 68.50	top5: 93.50	
[09/26 01:57:49 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.10806817794674878
[09/26 01:57:56 visual_prompt]: Epoch 89 / 100: avg data time: 5.56e-02, avg batch time: 0.4983, average train loss: 0.0056
[09/26 01:57:58 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1660, average loss: 1.1185
[09/26 01:57:58 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.50	top5: 93.00	
[09/26 01:57:58 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.09102018179151586
[09/26 01:58:04 visual_prompt]: Epoch 90 / 100: avg data time: 6.36e-02, avg batch time: 0.5047, average train loss: 0.0056
[09/26 01:58:06 visual_prompt]: Inference (val):avg data time: 3.56e-05, avg batch time: 0.1662, average loss: 1.1196
[09/26 01:58:06 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.50	top5: 94.00	
[09/26 01:58:06 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.0753842240176146
[09/26 01:58:13 visual_prompt]: Epoch 91 / 100: avg data time: 5.56e-02, avg batch time: 0.4979, average train loss: 0.0056
[09/26 01:58:14 visual_prompt]: Inference (val):avg data time: 2.01e-05, avg batch time: 0.1661, average loss: 1.1166
[09/26 01:58:14 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.50	top5: 94.00	
[09/26 01:58:14 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.061179354631058086
[09/26 01:58:21 visual_prompt]: Epoch 92 / 100: avg data time: 5.72e-02, avg batch time: 0.4993, average train loss: 0.0056
[09/26 01:58:23 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1660, average loss: 1.1163
[09/26 01:58:23 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.50	top5: 94.00	
[09/26 01:58:23 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.04842288007710138
[09/26 01:58:29 visual_prompt]: Epoch 93 / 100: avg data time: 5.90e-02, avg batch time: 0.5009, average train loss: 0.0055
[09/26 01:58:31 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1658, average loss: 1.1166
[09/26 01:58:31 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.50	top5: 94.00	
[09/26 01:58:31 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.03713034215500441
[09/26 01:58:38 visual_prompt]: Epoch 94 / 100: avg data time: 5.92e-02, avg batch time: 0.4999, average train loss: 0.0055
[09/26 01:58:39 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1659, average loss: 1.1168
[09/26 01:58:39 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 68.00	top5: 94.00	
[09/26 01:58:39 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.02731549908274289
[09/26 01:58:46 visual_prompt]: Epoch 95 / 100: avg data time: 4.57e-02, avg batch time: 0.4893, average train loss: 0.0055
[09/26 01:58:47 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.1660, average loss: 1.1169
[09/26 01:58:47 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.50	top5: 94.00	
[09/26 01:58:47 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.018990308734739975
[09/26 01:58:54 visual_prompt]: Epoch 96 / 100: avg data time: 4.46e-02, avg batch time: 0.4863, average train loss: 0.0055
[09/26 01:58:56 visual_prompt]: Inference (val):avg data time: 2.00e-05, avg batch time: 0.1661, average loss: 1.1172
[09/26 01:58:56 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.50	top5: 94.00	
[09/26 01:58:56 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.012164914073037048
[09/26 01:59:03 visual_prompt]: Epoch 97 / 100: avg data time: 6.17e-02, avg batch time: 0.5025, average train loss: 0.0056
[09/26 01:59:04 visual_prompt]: Inference (val):avg data time: 2.00e-05, avg batch time: 0.1660, average loss: 1.1174
[09/26 01:59:04 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.50	top5: 94.00	
[09/26 01:59:04 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.006847630789658388
[09/26 01:59:11 visual_prompt]: Epoch 98 / 100: avg data time: 5.41e-02, avg batch time: 0.4947, average train loss: 0.0056
[09/26 01:59:12 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1661, average loss: 1.1176
[09/26 01:59:12 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.50	top5: 94.00	
[09/26 01:59:12 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.003044937175219753
[09/26 01:59:19 visual_prompt]: Epoch 99 / 100: avg data time: 5.90e-02, avg batch time: 0.5008, average train loss: 0.0056
[09/26 01:59:21 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1660, average loss: 1.1175
[09/26 01:59:21 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.50	top5: 94.00	
[09/26 01:59:21 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0007614662261302974
[09/26 01:59:27 visual_prompt]: Epoch 100 / 100: avg data time: 5.24e-02, avg batch time: 0.4938, average train loss: 0.0055
[09/26 01:59:29 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1659, average loss: 1.1175
[09/26 01:59:29 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.50	top5: 94.00	
[09/26 01:59:29 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 01:59:29 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 01:59:29 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-cifar(num_classes=100)', 'DATA.NUMBER_CLASSES', '100', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 01:59:29 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 01:59:29 visual_prompt]: Training with config:
[09/26 01:59:29 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-cifar(num_classes=100)/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr2.5_wd0.0/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 2.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-cifar(num_classes=100)', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 100, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 01:59:29 visual_prompt]: Loading training data...
[09/26 01:59:29 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[:800], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/26 01:59:30 visual_prompt]: Number of images: 800
[09/26 01:59:30 visual_prompt]: Number of classes: 100 / 100
[09/26 01:59:30 visual_prompt]: Loading validation data...
[09/26 01:59:30 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[45000:45200], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/26 01:59:30 visual_prompt]: Number of images: 200
[09/26 01:59:30 visual_prompt]: Number of classes: 90 / 100
[09/26 01:59:30 visual_prompt]: Constructing models...
[09/26 01:59:33 visual_prompt]: Total Parameters: 86336356	 Gradient Parameters: 537700
[09/26 01:59:33 visual_prompt]: tuned percent:0.623
[09/26 01:59:33 visual_prompt]: Device used for model: 0
[09/26 01:59:33 visual_prompt]: Setting up Evaluator...
[09/26 01:59:33 visual_prompt]: Setting up Trainer...
[09/26 01:59:33 visual_prompt]: 	Setting up the optimizer...
[09/26 01:59:33 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 01:59:39 visual_prompt]: Epoch 1 / 100: avg data time: 4.47e-02, avg batch time: 0.4854, average train loss: 4.6545
[09/26 01:59:41 visual_prompt]: Inference (val):avg data time: 1.94e-05, avg batch time: 0.1656, average loss: 4.6218
[09/26 01:59:41 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 7.00	
[09/26 01:59:41 visual_prompt]: Best epoch 1: best metric: 0.010
[09/26 01:59:41 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.25
[09/26 01:59:47 visual_prompt]: Epoch 2 / 100: avg data time: 5.69e-02, avg batch time: 0.4965, average train loss: 4.6347
[09/26 01:59:49 visual_prompt]: Inference (val):avg data time: 2.05e-05, avg batch time: 0.1656, average loss: 4.6516
[09/26 01:59:49 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 5.50	
[09/26 01:59:49 visual_prompt]: Best epoch 2: best metric: 0.015
[09/26 01:59:49 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.5
[09/26 01:59:56 visual_prompt]: Epoch 3 / 100: avg data time: 4.74e-02, avg batch time: 0.4890, average train loss: 4.6122
[09/26 01:59:57 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.1657, average loss: 4.6678
[09/26 01:59:57 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 4.00	
[09/26 01:59:57 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.75
[09/26 02:00:04 visual_prompt]: Epoch 4 / 100: avg data time: 5.51e-02, avg batch time: 0.4966, average train loss: 4.5868
[09/26 02:00:05 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1657, average loss: 4.5378
[09/26 02:00:05 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 8.00	
[09/26 02:00:05 visual_prompt]: Training 5 / 100 epoch, with learning rate 1.0
[09/26 02:00:12 visual_prompt]: Epoch 5 / 100: avg data time: 4.66e-02, avg batch time: 0.4885, average train loss: 4.5365
[09/26 02:00:13 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1659, average loss: 4.3599
[09/26 02:00:13 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 12.50	
[09/26 02:00:13 visual_prompt]: Training 6 / 100 epoch, with learning rate 1.25
[09/26 02:00:20 visual_prompt]: Epoch 6 / 100: avg data time: 4.03e-02, avg batch time: 0.4840, average train loss: 4.1949
[09/26 02:00:21 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1659, average loss: 4.2096
[09/26 02:00:21 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 5.00	top5: 19.50	
[09/26 02:00:21 visual_prompt]: Best epoch 6: best metric: 0.050
[09/26 02:00:21 visual_prompt]: Training 7 / 100 epoch, with learning rate 1.5
[09/26 02:00:28 visual_prompt]: Epoch 7 / 100: avg data time: 5.68e-02, avg batch time: 0.4975, average train loss: 3.9728
[09/26 02:00:30 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1662, average loss: 4.2657
[09/26 02:00:30 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 4.00	top5: 20.00	
[09/26 02:00:30 visual_prompt]: Training 8 / 100 epoch, with learning rate 1.75
[09/26 02:00:36 visual_prompt]: Epoch 8 / 100: avg data time: 5.70e-02, avg batch time: 0.4989, average train loss: 3.6828
[09/26 02:00:38 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1659, average loss: 3.3333
[09/26 02:00:38 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 14.00	top5: 48.50	
[09/26 02:00:38 visual_prompt]: Best epoch 8: best metric: 0.140
[09/26 02:00:38 visual_prompt]: Training 9 / 100 epoch, with learning rate 2.0
[09/26 02:00:45 visual_prompt]: Epoch 9 / 100: avg data time: 4.71e-02, avg batch time: 0.4898, average train loss: 3.2490
[09/26 02:00:46 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1661, average loss: 4.6217
[09/26 02:00:46 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 10.50	top5: 36.00	
[09/26 02:00:46 visual_prompt]: Training 10 / 100 epoch, with learning rate 2.25
[09/26 02:00:53 visual_prompt]: Epoch 10 / 100: avg data time: 5.31e-02, avg batch time: 0.4951, average train loss: 3.9004
[09/26 02:00:54 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.1663, average loss: 3.6949
[09/26 02:00:54 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 17.00	top5: 42.50	
[09/26 02:00:54 visual_prompt]: Best epoch 10: best metric: 0.170
[09/26 02:00:54 visual_prompt]: Training 11 / 100 epoch, with learning rate 2.5
[09/26 02:01:01 visual_prompt]: Epoch 11 / 100: avg data time: 5.76e-02, avg batch time: 0.4985, average train loss: 2.0527
[09/26 02:01:02 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1661, average loss: 2.6848
[09/26 02:01:02 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 35.50	top5: 68.50	
[09/26 02:01:02 visual_prompt]: Best epoch 11: best metric: 0.355
[09/26 02:01:02 visual_prompt]: Training 12 / 100 epoch, with learning rate 2.4992385337738696
[09/26 02:01:09 visual_prompt]: Epoch 12 / 100: avg data time: 4.89e-02, avg batch time: 0.4918, average train loss: 1.1764
[09/26 02:01:11 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1663, average loss: 1.9733
[09/26 02:01:11 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 53.50	top5: 84.50	
[09/26 02:01:11 visual_prompt]: Best epoch 12: best metric: 0.535
[09/26 02:01:11 visual_prompt]: Training 13 / 100 epoch, with learning rate 2.4969550628247803
[09/26 02:01:17 visual_prompt]: Epoch 13 / 100: avg data time: 4.83e-02, avg batch time: 0.4902, average train loss: 0.4577
[09/26 02:01:19 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1662, average loss: 2.2306
[09/26 02:01:19 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 52.00	top5: 82.00	
[09/26 02:01:19 visual_prompt]: Training 14 / 100 epoch, with learning rate 2.4931523692103417
[09/26 02:01:26 visual_prompt]: Epoch 14 / 100: avg data time: 5.49e-02, avg batch time: 0.4964, average train loss: 0.2343
[09/26 02:01:27 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1661, average loss: 1.6615
[09/26 02:01:27 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.00	top5: 88.50	
[09/26 02:01:27 visual_prompt]: Best epoch 14: best metric: 0.630
[09/26 02:01:27 visual_prompt]: Training 15 / 100 epoch, with learning rate 2.487835085926963
[09/26 02:01:34 visual_prompt]: Epoch 15 / 100: avg data time: 5.33e-02, avg batch time: 0.4943, average train loss: 0.1235
[09/26 02:01:35 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1661, average loss: 2.1216
[09/26 02:01:35 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 60.00	top5: 87.50	
[09/26 02:01:35 visual_prompt]: Training 16 / 100 epoch, with learning rate 2.4810096912652604
[09/26 02:01:42 visual_prompt]: Epoch 16 / 100: avg data time: 5.23e-02, avg batch time: 0.4944, average train loss: 0.0932
[09/26 02:01:43 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1661, average loss: 2.0845
[09/26 02:01:43 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 56.50	top5: 83.00	
[09/26 02:01:43 visual_prompt]: Training 17 / 100 epoch, with learning rate 2.472684500917257
[09/26 02:01:50 visual_prompt]: Epoch 17 / 100: avg data time: 5.23e-02, avg batch time: 0.4934, average train loss: 0.0426
[09/26 02:01:52 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1659, average loss: 1.6957
[09/26 02:01:52 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 88.50	
[09/26 02:01:52 visual_prompt]: Best epoch 17: best metric: 0.650
[09/26 02:01:52 visual_prompt]: Training 18 / 100 epoch, with learning rate 2.4628696578449953
[09/26 02:01:58 visual_prompt]: Epoch 18 / 100: avg data time: 5.51e-02, avg batch time: 0.4961, average train loss: 0.0091
[09/26 02:02:00 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1661, average loss: 1.6348
[09/26 02:02:00 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.50	top5: 89.50	
[09/26 02:02:00 visual_prompt]: Training 19 / 100 epoch, with learning rate 2.4515771199228986
[09/26 02:02:07 visual_prompt]: Epoch 19 / 100: avg data time: 5.46e-02, avg batch time: 0.4962, average train loss: 0.0061
[09/26 02:02:08 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1663, average loss: 1.6432
[09/26 02:02:08 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 89.50	
[09/26 02:02:08 visual_prompt]: Training 20 / 100 epoch, with learning rate 2.438820645368942
[09/26 02:02:15 visual_prompt]: Epoch 20 / 100: avg data time: 5.43e-02, avg batch time: 0.4965, average train loss: 0.0057
[09/26 02:02:16 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1661, average loss: 1.6148
[09/26 02:02:16 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.50	top5: 90.00	
[09/26 02:02:16 visual_prompt]: Training 21 / 100 epoch, with learning rate 2.4246157759823856
[09/26 02:02:23 visual_prompt]: Epoch 21 / 100: avg data time: 5.48e-02, avg batch time: 0.4968, average train loss: 0.0018
[09/26 02:02:25 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1661, average loss: 1.6102
[09/26 02:02:25 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.50	top5: 90.00	
[09/26 02:02:25 visual_prompt]: Training 22 / 100 epoch, with learning rate 2.4089798182084845
[09/26 02:02:31 visual_prompt]: Epoch 22 / 100: avg data time: 4.84e-02, avg batch time: 0.4896, average train loss: 0.0018
[09/26 02:02:33 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1661, average loss: 1.5891
[09/26 02:02:33 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 64.50	top5: 90.50	
[09/26 02:02:33 visual_prompt]: Training 23 / 100 epoch, with learning rate 2.391931822053251
[09/26 02:02:40 visual_prompt]: Epoch 23 / 100: avg data time: 5.92e-02, avg batch time: 0.5002, average train loss: 0.0010
[09/26 02:02:41 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.1660, average loss: 1.5850
[09/26 02:02:41 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 91.00	
[09/26 02:02:41 visual_prompt]: Training 24 / 100 epoch, with learning rate 2.3734925578739587
[09/26 02:02:48 visual_prompt]: Epoch 24 / 100: avg data time: 6.12e-02, avg batch time: 0.5023, average train loss: 0.0009
[09/26 02:02:49 visual_prompt]: Inference (val):avg data time: 3.76e-05, avg batch time: 0.1663, average loss: 1.5831
[09/26 02:02:49 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 91.00	
[09/26 02:02:49 visual_prompt]: Training 25 / 100 epoch, with learning rate 2.3536844910736585
[09/26 02:02:56 visual_prompt]: Epoch 25 / 100: avg data time: 5.26e-02, avg batch time: 0.4952, average train loss: 0.0007
[09/26 02:02:58 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1663, average loss: 1.5806
[09/26 02:02:58 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.50	top5: 91.00	
[09/26 02:02:58 visual_prompt]: Training 26 / 100 epoch, with learning rate 2.3325317547305486
[09/26 02:03:04 visual_prompt]: Epoch 26 / 100: avg data time: 5.82e-02, avg batch time: 0.4998, average train loss: 0.0008
[09/26 02:03:06 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1662, average loss: 1.5804
[09/26 02:03:06 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 64.00	top5: 91.00	
[09/26 02:03:06 visual_prompt]: Training 27 / 100 epoch, with learning rate 2.310060120195532
[09/26 02:03:13 visual_prompt]: Epoch 27 / 100: avg data time: 5.96e-02, avg batch time: 0.5009, average train loss: 0.0007
[09/26 02:03:14 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1661, average loss: 1.5797
[09/26 02:03:14 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 64.00	top5: 91.00	
[09/26 02:03:14 visual_prompt]: Training 28 / 100 epoch, with learning rate 2.286296965693802
[09/26 02:03:21 visual_prompt]: Epoch 28 / 100: avg data time: 5.29e-02, avg batch time: 0.4959, average train loss: 0.0007
[09/26 02:03:22 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1663, average loss: 1.5804
[09/26 02:03:22 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 64.00	top5: 91.00	
[09/26 02:03:22 visual_prompt]: Training 29 / 100 epoch, with learning rate 2.261271242968684
[09/26 02:03:29 visual_prompt]: Epoch 29 / 100: avg data time: 4.64e-02, avg batch time: 0.4892, average train loss: 0.0006
[09/26 02:03:31 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1662, average loss: 1.5829
[09/26 02:03:31 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.00	top5: 91.00	
[09/26 02:03:31 visual_prompt]: Training 30 / 100 epoch, with learning rate 2.2350134420084022
[09/26 02:03:37 visual_prompt]: Epoch 30 / 100: avg data time: 5.61e-02, avg batch time: 0.4983, average train loss: 0.0006
[09/26 02:03:39 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1663, average loss: 1.5830
[09/26 02:03:39 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.00	top5: 91.00	
[09/26 02:03:39 visual_prompt]: Training 31 / 100 epoch, with learning rate 2.2075555538987226
[09/26 02:03:45 visual_prompt]: Epoch 31 / 100: avg data time: 4.58e-02, avg batch time: 0.4879, average train loss: 0.0006
[09/26 02:03:47 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1663, average loss: 1.5824
[09/26 02:03:47 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 64.00	top5: 91.00	
[09/26 02:03:47 visual_prompt]: Training 32 / 100 epoch, with learning rate 2.178931031846743
[09/26 02:03:54 visual_prompt]: Epoch 32 / 100: avg data time: 5.46e-02, avg batch time: 0.4960, average train loss: 0.0006
[09/26 02:03:55 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1663, average loss: 1.5804
[09/26 02:03:55 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.50	top5: 91.00	
[09/26 02:03:55 visual_prompt]: Training 33 / 100 epoch, with learning rate 2.149174750423314
[09/26 02:04:02 visual_prompt]: Epoch 33 / 100: avg data time: 5.89e-02, avg batch time: 0.5007, average train loss: 0.0006
[09/26 02:04:03 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1663, average loss: 1.5787
[09/26 02:04:03 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.50	top5: 91.50	
[09/26 02:04:03 visual_prompt]: Training 34 / 100 epoch, with learning rate 2.1183229630737466
[09/26 02:04:10 visual_prompt]: Epoch 34 / 100: avg data time: 6.29e-02, avg batch time: 0.5043, average train loss: 0.0005
[09/26 02:04:12 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1664, average loss: 1.5774
[09/26 02:04:12 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 91.50	
[09/26 02:04:12 visual_prompt]: Training 35 / 100 epoch, with learning rate 2.086413257948573
[09/26 02:04:18 visual_prompt]: Epoch 35 / 100: avg data time: 5.84e-02, avg batch time: 0.4996, average train loss: 0.0005
[09/26 02:04:20 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1660, average loss: 1.5781
[09/26 02:04:20 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 64.50	top5: 91.50	
[09/26 02:04:20 visual_prompt]: Training 36 / 100 epoch, with learning rate 2.053484512108174
[09/26 02:04:27 visual_prompt]: Epoch 36 / 100: avg data time: 5.91e-02, avg batch time: 0.5010, average train loss: 0.0005
[09/26 02:04:28 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1663, average loss: 1.5770
[09/26 02:04:28 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 64.50	top5: 91.50	
[09/26 02:04:28 visual_prompt]: Training 37 / 100 epoch, with learning rate 2.019576844157073
[09/26 02:04:35 visual_prompt]: Epoch 37 / 100: avg data time: 5.59e-02, avg batch time: 0.4986, average train loss: 0.0005
[09/26 02:04:37 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1663, average loss: 1.5740
[09/26 02:04:37 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 64.50	top5: 91.50	
[09/26 02:04:37 visual_prompt]: Training 38 / 100 epoch, with learning rate 1.9847315653655915
[09/26 02:04:43 visual_prompt]: Epoch 38 / 100: avg data time: 6.23e-02, avg batch time: 0.5036, average train loss: 0.0004
[09/26 02:04:45 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1664, average loss: 1.5709
[09/26 02:04:45 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 91.50	
[09/26 02:04:45 visual_prompt]: Training 39 / 100 epoch, with learning rate 1.9489911293384334
[09/26 02:04:52 visual_prompt]: Epoch 39 / 100: avg data time: 4.82e-02, avg batch time: 0.4916, average train loss: 0.0005
[09/26 02:04:53 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1662, average loss: 1.5702
[09/26 02:04:53 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 91.50	
[09/26 02:04:53 visual_prompt]: Training 40 / 100 epoch, with learning rate 1.912399080291506
[09/26 02:05:00 visual_prompt]: Epoch 40 / 100: avg data time: 5.68e-02, avg batch time: 0.4987, average train loss: 0.0005
[09/26 02:05:01 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1661, average loss: 1.5698
[09/26 02:05:01 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 64.50	top5: 91.50	
[09/26 02:05:01 visual_prompt]: Training 41 / 100 epoch, with learning rate 1.875
[09/26 02:05:08 visual_prompt]: Epoch 41 / 100: avg data time: 4.61e-02, avg batch time: 0.4899, average train loss: 0.0005
[09/26 02:05:09 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1662, average loss: 1.5691
[09/26 02:05:09 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 91.50	
[09/26 02:05:09 visual_prompt]: Training 42 / 100 epoch, with learning rate 1.8368394534823635
[09/26 02:05:16 visual_prompt]: Epoch 42 / 100: avg data time: 5.16e-02, avg batch time: 0.4939, average train loss: 0.0005
[09/26 02:05:18 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1660, average loss: 1.5701
[09/26 02:05:18 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 91.00	
[09/26 02:05:18 visual_prompt]: Training 43 / 100 epoch, with learning rate 1.7979639334863466
[09/26 02:05:24 visual_prompt]: Epoch 43 / 100: avg data time: 5.46e-02, avg batch time: 0.4976, average train loss: 0.0004
[09/26 02:05:26 visual_prompt]: Inference (val):avg data time: 2.00e-05, avg batch time: 0.1664, average loss: 1.5707
[09/26 02:05:26 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 91.00	
[09/26 02:05:26 visual_prompt]: Training 44 / 100 epoch, with learning rate 1.7584208038447504
[09/26 02:05:33 visual_prompt]: Epoch 44 / 100: avg data time: 5.32e-02, avg batch time: 0.4955, average train loss: 0.0005
[09/26 02:05:34 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1664, average loss: 1.5724
[09/26 02:05:34 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 91.00	
[09/26 02:05:34 visual_prompt]: Training 45 / 100 epoch, with learning rate 1.7182582417698902
[09/26 02:05:41 visual_prompt]: Epoch 45 / 100: avg data time: 5.81e-02, avg batch time: 0.5001, average train loss: 0.0004
[09/26 02:05:43 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1663, average loss: 1.5718
[09/26 02:05:43 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 91.00	
[09/26 02:05:43 visual_prompt]: Training 46 / 100 epoch, with learning rate 1.6775251791570862
[09/26 02:05:49 visual_prompt]: Epoch 46 / 100: avg data time: 5.43e-02, avg batch time: 0.4964, average train loss: 0.0004
[09/26 02:05:51 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1661, average loss: 1.5712
[09/26 02:05:51 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 91.00	
[09/26 02:05:51 visual_prompt]: Training 47 / 100 epoch, with learning rate 1.6362712429686843
[09/26 02:05:57 visual_prompt]: Epoch 47 / 100: avg data time: 4.49e-02, avg batch time: 0.4883, average train loss: 0.0004
[09/26 02:05:59 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1663, average loss: 1.5712
[09/26 02:05:59 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 91.00	
[09/26 02:05:59 visual_prompt]: Training 48 / 100 epoch, with learning rate 1.5945466947712488
[09/26 02:06:06 visual_prompt]: Epoch 48 / 100: avg data time: 5.92e-02, avg batch time: 0.5006, average train loss: 0.0004
[09/26 02:06:07 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1662, average loss: 1.5717
[09/26 02:06:07 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 91.00	
[09/26 02:06:07 visual_prompt]: Training 49 / 100 epoch, with learning rate 1.5524023694995845
[09/26 02:06:14 visual_prompt]: Epoch 49 / 100: avg data time: 5.99e-02, avg batch time: 0.5012, average train loss: 0.0004
[09/26 02:06:15 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1662, average loss: 1.5711
[09/26 02:06:15 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 91.00	
[09/26 02:06:15 visual_prompt]: Training 50 / 100 epoch, with learning rate 1.509889613522199
[09/26 02:06:22 visual_prompt]: Epoch 50 / 100: avg data time: 5.55e-02, avg batch time: 0.4974, average train loss: 0.0004
[09/26 02:06:24 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1663, average loss: 1.5713
[09/26 02:06:24 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 91.00	
[09/26 02:06:24 visual_prompt]: Training 51 / 100 epoch, with learning rate 1.467060222083663
[09/26 02:06:30 visual_prompt]: Epoch 51 / 100: avg data time: 5.44e-02, avg batch time: 0.4974, average train loss: 0.0004
[09/26 02:06:32 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1665, average loss: 1.5711
[09/26 02:06:32 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 91.00	
[09/26 02:06:32 visual_prompt]: Training 52 / 100 epoch, with learning rate 1.4239663762000818
[09/26 02:06:39 visual_prompt]: Epoch 52 / 100: avg data time: 5.09e-02, avg batch time: 0.4936, average train loss: 0.0003
[09/26 02:06:40 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1663, average loss: 1.5703
[09/26 02:06:40 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.50	top5: 91.00	
[09/26 02:06:40 visual_prompt]: Best epoch 52: best metric: 0.655
[09/26 02:06:40 visual_prompt]: Training 53 / 100 epoch, with learning rate 1.380660579084567
[09/26 02:06:47 visual_prompt]: Epoch 53 / 100: avg data time: 5.51e-02, avg batch time: 0.4970, average train loss: 0.0003
[09/26 02:06:48 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1662, average loss: 1.5694
[09/26 02:06:48 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.50	top5: 91.00	
[09/26 02:06:48 visual_prompt]: Training 54 / 100 epoch, with learning rate 1.3371955921801564
[09/26 02:06:55 visual_prompt]: Epoch 54 / 100: avg data time: 4.02e-02, avg batch time: 0.4832, average train loss: 0.0004
[09/26 02:06:56 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1663, average loss: 1.5690
[09/26 02:06:56 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.00	top5: 91.00	
[09/26 02:06:56 visual_prompt]: Best epoch 54: best metric: 0.660
[09/26 02:06:56 visual_prompt]: Training 55 / 100 epoch, with learning rate 1.2936243708781263
[09/26 02:07:03 visual_prompt]: Epoch 55 / 100: avg data time: 5.31e-02, avg batch time: 0.4953, average train loss: 0.0004
[09/26 02:07:05 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1661, average loss: 1.5687
[09/26 02:07:05 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.00	top5: 91.00	
[09/26 02:07:05 visual_prompt]: Training 56 / 100 epoch, with learning rate 1.25
[09/26 02:07:11 visual_prompt]: Epoch 56 / 100: avg data time: 5.07e-02, avg batch time: 0.4930, average train loss: 0.0003
[09/26 02:07:13 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1664, average loss: 1.5684
[09/26 02:07:13 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.50	top5: 91.00	
[09/26 02:07:13 visual_prompt]: Training 57 / 100 epoch, with learning rate 1.2063756291218741
[09/26 02:07:20 visual_prompt]: Epoch 57 / 100: avg data time: 6.23e-02, avg batch time: 0.5036, average train loss: 0.0004
[09/26 02:07:21 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1664, average loss: 1.5679
[09/26 02:07:21 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.50	top5: 91.00	
[09/26 02:07:21 visual_prompt]: Training 58 / 100 epoch, with learning rate 1.1628044078198434
[09/26 02:07:28 visual_prompt]: Epoch 58 / 100: avg data time: 5.37e-02, avg batch time: 0.4965, average train loss: 0.0003
[09/26 02:07:29 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1663, average loss: 1.5673
[09/26 02:07:29 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.50	top5: 91.00	
[09/26 02:07:29 visual_prompt]: Training 59 / 100 epoch, with learning rate 1.1193394209154333
[09/26 02:07:36 visual_prompt]: Epoch 59 / 100: avg data time: 4.26e-02, avg batch time: 0.4845, average train loss: 0.0003
[09/26 02:07:37 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1666, average loss: 1.5673
[09/26 02:07:37 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.00	top5: 91.00	
[09/26 02:07:37 visual_prompt]: Training 60 / 100 epoch, with learning rate 1.0760336237999186
[09/26 02:07:44 visual_prompt]: Epoch 60 / 100: avg data time: 5.64e-02, avg batch time: 0.4980, average train loss: 0.0003
[09/26 02:07:46 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1663, average loss: 1.5670
[09/26 02:07:46 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.00	top5: 91.00	
[09/26 02:07:46 visual_prompt]: Training 61 / 100 epoch, with learning rate 1.0329397779163372
[09/26 02:07:52 visual_prompt]: Epoch 61 / 100: avg data time: 5.54e-02, avg batch time: 0.4972, average train loss: 0.0003
[09/26 02:07:54 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1663, average loss: 1.5669
[09/26 02:07:54 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.00	top5: 91.00	
[09/26 02:07:54 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.990110386477801
[09/26 02:08:01 visual_prompt]: Epoch 62 / 100: avg data time: 4.21e-02, avg batch time: 0.4850, average train loss: 0.0003
[09/26 02:08:02 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1664, average loss: 1.5666
[09/26 02:08:02 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.00	top5: 91.00	
[09/26 02:08:02 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.9475976305004155
[09/26 02:08:09 visual_prompt]: Epoch 63 / 100: avg data time: 5.65e-02, avg batch time: 0.4986, average train loss: 0.0003
[09/26 02:08:10 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1662, average loss: 1.5662
[09/26 02:08:10 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.00	top5: 91.00	
[09/26 02:08:10 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.9054533052287511
[09/26 02:08:17 visual_prompt]: Epoch 64 / 100: avg data time: 5.87e-02, avg batch time: 0.5017, average train loss: 0.0003
[09/26 02:08:19 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1661, average loss: 1.5659
[09/26 02:08:19 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.00	top5: 91.00	
[09/26 02:08:19 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.8637287570313158
[09/26 02:08:25 visual_prompt]: Epoch 65 / 100: avg data time: 5.30e-02, avg batch time: 0.4948, average train loss: 0.0003
[09/26 02:08:27 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1663, average loss: 1.5656
[09/26 02:08:27 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.50	top5: 91.00	
[09/26 02:08:27 visual_prompt]: Best epoch 65: best metric: 0.665
[09/26 02:08:27 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.8224748208429142
[09/26 02:08:34 visual_prompt]: Epoch 66 / 100: avg data time: 5.81e-02, avg batch time: 0.4995, average train loss: 0.0003
[09/26 02:08:35 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1662, average loss: 1.5652
[09/26 02:08:35 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.50	top5: 91.00	
[09/26 02:08:35 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.7817417582301099
[09/26 02:08:42 visual_prompt]: Epoch 67 / 100: avg data time: 5.17e-02, avg batch time: 0.4940, average train loss: 0.0003
[09/26 02:08:43 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1663, average loss: 1.5649
[09/26 02:08:43 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.50	top5: 91.00	
[09/26 02:08:43 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.7415791961552499
[09/26 02:08:50 visual_prompt]: Epoch 68 / 100: avg data time: 5.19e-02, avg batch time: 0.4930, average train loss: 0.0003
[09/26 02:08:52 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1662, average loss: 1.5645
[09/26 02:08:52 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.50	top5: 91.00	
[09/26 02:08:52 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.7020360665136531
[09/26 02:08:58 visual_prompt]: Epoch 69 / 100: avg data time: 4.85e-02, avg batch time: 0.4901, average train loss: 0.0003
[09/26 02:09:00 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1663, average loss: 1.5643
[09/26 02:09:00 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.50	top5: 91.00	
[09/26 02:09:00 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.6631605465176369
[09/26 02:09:06 visual_prompt]: Epoch 70 / 100: avg data time: 5.86e-02, avg batch time: 0.5002, average train loss: 0.0003
[09/26 02:09:08 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1661, average loss: 1.5641
[09/26 02:09:08 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.50	top5: 91.00	
[09/26 02:09:08 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.6250000000000002
[09/26 02:09:15 visual_prompt]: Epoch 71 / 100: avg data time: 5.85e-02, avg batch time: 0.4997, average train loss: 0.0003
[09/26 02:09:16 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1663, average loss: 1.5641
[09/26 02:09:16 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.50	top5: 91.00	
[09/26 02:09:16 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.587600919708494
[09/26 02:09:23 visual_prompt]: Epoch 72 / 100: avg data time: 5.57e-02, avg batch time: 0.4971, average train loss: 0.0003
[09/26 02:09:25 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1663, average loss: 1.5646
[09/26 02:09:25 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.50	top5: 91.00	
[09/26 02:09:25 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.5510088706615667
[09/26 02:09:31 visual_prompt]: Epoch 73 / 100: avg data time: 5.53e-02, avg batch time: 0.4968, average train loss: 0.0003
[09/26 02:09:33 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1662, average loss: 1.5647
[09/26 02:09:33 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.50	top5: 91.00	
[09/26 02:09:33 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.5152684346344087
[09/26 02:09:39 visual_prompt]: Epoch 74 / 100: avg data time: 4.62e-02, avg batch time: 0.4882, average train loss: 0.0003
[09/26 02:09:41 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1662, average loss: 1.5649
[09/26 02:09:41 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.50	top5: 91.00	
[09/26 02:09:41 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.48042315584292716
[09/26 02:09:48 visual_prompt]: Epoch 75 / 100: avg data time: 5.70e-02, avg batch time: 0.4995, average train loss: 0.0003
[09/26 02:09:49 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1660, average loss: 1.5648
[09/26 02:09:49 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.50	top5: 91.00	
[09/26 02:09:49 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.4465154878918258
[09/26 02:09:56 visual_prompt]: Epoch 76 / 100: avg data time: 5.20e-02, avg batch time: 0.4934, average train loss: 0.0003
[09/26 02:09:57 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1663, average loss: 1.5648
[09/26 02:09:57 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.50	top5: 91.00	
[09/26 02:09:57 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.41358674205142765
[09/26 02:10:04 visual_prompt]: Epoch 77 / 100: avg data time: 5.74e-02, avg batch time: 0.5006, average train loss: 0.0003
[09/26 02:10:06 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1662, average loss: 1.5646
[09/26 02:10:06 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.50	top5: 91.00	
[09/26 02:10:06 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.3816770369262533
[09/26 02:10:13 visual_prompt]: Epoch 78 / 100: avg data time: 5.62e-02, avg batch time: 0.4976, average train loss: 0.0003
[09/26 02:10:14 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1661, average loss: 1.5645
[09/26 02:10:14 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.50	top5: 91.00	
[09/26 02:10:14 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.35082524957668626
[09/26 02:10:21 visual_prompt]: Epoch 79 / 100: avg data time: 5.75e-02, avg batch time: 0.4991, average train loss: 0.0003
[09/26 02:10:22 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1662, average loss: 1.5645
[09/26 02:10:22 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.50	top5: 91.00	
[09/26 02:10:22 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.32106896815325703
[09/26 02:10:29 visual_prompt]: Epoch 80 / 100: avg data time: 5.92e-02, avg batch time: 0.5013, average train loss: 0.0003
[09/26 02:10:31 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1662, average loss: 1.5646
[09/26 02:10:31 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.50	top5: 91.00	
[09/26 02:10:31 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.2924444461012776
[09/26 02:10:37 visual_prompt]: Epoch 81 / 100: avg data time: 5.17e-02, avg batch time: 0.4938, average train loss: 0.0003
[09/26 02:10:39 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1661, average loss: 1.5647
[09/26 02:10:39 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.50	top5: 91.00	
[09/26 02:10:39 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.26498655799159765
[09/26 02:10:46 visual_prompt]: Epoch 82 / 100: avg data time: 6.11e-02, avg batch time: 0.5044, average train loss: 0.0003
[09/26 02:10:47 visual_prompt]: Inference (val):avg data time: 4.59e-05, avg batch time: 0.1662, average loss: 1.5648
[09/26 02:10:47 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.50	top5: 91.00	
[09/26 02:10:47 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.23872875703131582
[09/26 02:10:54 visual_prompt]: Epoch 83 / 100: avg data time: 4.67e-02, avg batch time: 0.4898, average train loss: 0.0003
[09/26 02:10:55 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1662, average loss: 1.5648
[09/26 02:10:55 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.50	top5: 91.00	
[09/26 02:10:55 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.21370303430619797
[09/26 02:11:02 visual_prompt]: Epoch 84 / 100: avg data time: 6.01e-02, avg batch time: 0.5025, average train loss: 0.0003
[09/26 02:11:04 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1662, average loss: 1.5647
[09/26 02:11:04 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.50	top5: 91.00	
[09/26 02:11:04 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.18993987980446755
[09/26 02:11:10 visual_prompt]: Epoch 85 / 100: avg data time: 5.33e-02, avg batch time: 0.4947, average train loss: 0.0003
[09/26 02:11:12 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1661, average loss: 1.5648
[09/26 02:11:12 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.50	top5: 91.00	
[09/26 02:11:12 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.16746824526945162
[09/26 02:11:19 visual_prompt]: Epoch 86 / 100: avg data time: 4.98e-02, avg batch time: 0.4934, average train loss: 0.0003
[09/26 02:11:20 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1663, average loss: 1.5648
[09/26 02:11:20 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.50	top5: 91.00	
[09/26 02:11:20 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.14631550892634126
[09/26 02:11:27 visual_prompt]: Epoch 87 / 100: avg data time: 5.02e-02, avg batch time: 0.4922, average train loss: 0.0003
[09/26 02:11:28 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1663, average loss: 1.5648
[09/26 02:11:28 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.50	top5: 91.00	
[09/26 02:11:28 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.12650744212604148
[09/26 02:11:35 visual_prompt]: Epoch 88 / 100: avg data time: 4.88e-02, avg batch time: 0.4914, average train loss: 0.0003
[09/26 02:11:36 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1661, average loss: 1.5648
[09/26 02:11:36 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.50	top5: 91.00	
[09/26 02:11:36 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.10806817794674878
[09/26 02:11:43 visual_prompt]: Epoch 89 / 100: avg data time: 5.91e-02, avg batch time: 0.5006, average train loss: 0.0003
[09/26 02:11:45 visual_prompt]: Inference (val):avg data time: 1.99e-05, avg batch time: 0.1663, average loss: 1.5648
[09/26 02:11:45 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.50	top5: 91.00	
[09/26 02:11:45 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.09102018179151586
[09/26 02:11:52 visual_prompt]: Epoch 90 / 100: avg data time: 5.49e-02, avg batch time: 0.4963, average train loss: 0.0003
[09/26 02:11:53 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1663, average loss: 1.5648
[09/26 02:11:53 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.50	top5: 91.00	
[09/26 02:11:53 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.0753842240176146
[09/26 02:12:00 visual_prompt]: Epoch 91 / 100: avg data time: 5.92e-02, avg batch time: 0.5011, average train loss: 0.0003
[09/26 02:12:01 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1666, average loss: 1.5648
[09/26 02:12:01 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.50	top5: 91.00	
[09/26 02:12:01 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.061179354631058086
[09/26 02:12:08 visual_prompt]: Epoch 92 / 100: avg data time: 5.19e-02, avg batch time: 0.4945, average train loss: 0.0003
[09/26 02:12:09 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1662, average loss: 1.5648
[09/26 02:12:09 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.50	top5: 91.00	
[09/26 02:12:09 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.04842288007710138
[09/26 02:12:16 visual_prompt]: Epoch 93 / 100: avg data time: 5.16e-02, avg batch time: 0.4946, average train loss: 0.0003
[09/26 02:12:18 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1662, average loss: 1.5648
[09/26 02:12:18 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.50	top5: 91.00	
[09/26 02:12:18 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.03713034215500441
[09/26 02:12:24 visual_prompt]: Epoch 94 / 100: avg data time: 5.78e-02, avg batch time: 0.5018, average train loss: 0.0003
[09/26 02:12:26 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1662, average loss: 1.5648
[09/26 02:12:26 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.50	top5: 91.00	
[09/26 02:12:26 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.02731549908274289
[09/26 02:12:33 visual_prompt]: Epoch 95 / 100: avg data time: 4.68e-02, avg batch time: 0.4896, average train loss: 0.0003
[09/26 02:12:34 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1661, average loss: 1.5648
[09/26 02:12:34 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.50	top5: 91.00	
[09/26 02:12:34 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.018990308734739975
[09/26 02:12:41 visual_prompt]: Epoch 96 / 100: avg data time: 5.84e-02, avg batch time: 0.5008, average train loss: 0.0003
[09/26 02:12:42 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1664, average loss: 1.5648
[09/26 02:12:42 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.50	top5: 91.00	
[09/26 02:12:42 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.012164914073037048
[09/26 02:12:49 visual_prompt]: Epoch 97 / 100: avg data time: 5.79e-02, avg batch time: 0.5005, average train loss: 0.0003
[09/26 02:12:51 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1664, average loss: 1.5648
[09/26 02:12:51 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.50	top5: 91.00	
[09/26 02:12:51 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.006847630789658388
[09/26 02:12:57 visual_prompt]: Epoch 98 / 100: avg data time: 5.68e-02, avg batch time: 0.4981, average train loss: 0.0003
[09/26 02:12:59 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1663, average loss: 1.5648
[09/26 02:12:59 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.50	top5: 91.00	
[09/26 02:12:59 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.003044937175219753
[09/26 02:13:06 visual_prompt]: Epoch 99 / 100: avg data time: 5.63e-02, avg batch time: 0.4980, average train loss: 0.0003
[09/26 02:13:07 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1663, average loss: 1.5648
[09/26 02:13:07 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.50	top5: 91.00	
[09/26 02:13:07 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0007614662261302974
[09/26 02:13:14 visual_prompt]: Epoch 100 / 100: avg data time: 4.86e-02, avg batch time: 0.4906, average train loss: 0.0003
[09/26 02:13:15 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1662, average loss: 1.5648
[09/26 02:13:15 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.50	top5: 91.00	
[09/26 02:13:15 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 02:13:15 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 02:13:15 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-cifar(num_classes=100)', 'DATA.NUMBER_CLASSES', '100', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 02:13:15 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 02:13:15 visual_prompt]: Training with config:
[09/26 02:13:15 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-cifar(num_classes=100)/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr1.0_wd0.01/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 1.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-cifar(num_classes=100)', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 100, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 02:13:15 visual_prompt]: Loading training data...
[09/26 02:13:15 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[:800], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/26 02:13:16 visual_prompt]: Number of images: 800
[09/26 02:13:16 visual_prompt]: Number of classes: 100 / 100
[09/26 02:13:16 visual_prompt]: Loading validation data...
[09/26 02:13:16 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[45000:45200], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/26 02:13:16 visual_prompt]: Number of images: 200
[09/26 02:13:16 visual_prompt]: Number of classes: 90 / 100
[09/26 02:13:16 visual_prompt]: Constructing models...
[09/26 02:13:19 visual_prompt]: Total Parameters: 86336356	 Gradient Parameters: 537700
[09/26 02:13:19 visual_prompt]: tuned percent:0.623
[09/26 02:13:19 visual_prompt]: Device used for model: 0
[09/26 02:13:19 visual_prompt]: Setting up Evaluator...
[09/26 02:13:19 visual_prompt]: Setting up Trainer...
[09/26 02:13:19 visual_prompt]: 	Setting up the optimizer...
[09/26 02:13:19 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 02:13:26 visual_prompt]: Epoch 1 / 100: avg data time: 4.91e-02, avg batch time: 0.4897, average train loss: 4.6579
[09/26 02:13:27 visual_prompt]: Inference (val):avg data time: 4.07e-05, avg batch time: 0.1658, average loss: 4.6218
[09/26 02:13:27 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 7.00	
[09/26 02:13:27 visual_prompt]: Best epoch 1: best metric: 0.010
[09/26 02:13:27 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.1
[09/26 02:13:34 visual_prompt]: Epoch 2 / 100: avg data time: 5.30e-02, avg batch time: 0.4928, average train loss: 4.6332
[09/26 02:13:35 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1661, average loss: 4.6345
[09/26 02:13:35 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.50	
[09/26 02:13:35 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.2
[09/26 02:13:42 visual_prompt]: Epoch 3 / 100: avg data time: 5.73e-02, avg batch time: 0.4979, average train loss: 4.5819
[09/26 02:13:44 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1659, average loss: 4.6396
[09/26 02:13:44 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 5.50	
[09/26 02:13:44 visual_prompt]: Best epoch 3: best metric: 0.015
[09/26 02:13:44 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.3
[09/26 02:13:50 visual_prompt]: Epoch 4 / 100: avg data time: 5.15e-02, avg batch time: 0.4926, average train loss: 4.5732
[09/26 02:13:52 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1660, average loss: 4.5965
[09/26 02:13:52 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 6.00	
[09/26 02:13:52 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.4
[09/26 02:13:59 visual_prompt]: Epoch 5 / 100: avg data time: 5.52e-02, avg batch time: 0.4968, average train loss: 4.5303
[09/26 02:14:00 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1659, average loss: 4.5495
[09/26 02:14:00 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 9.00	
[09/26 02:14:00 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.5
[09/26 02:14:07 visual_prompt]: Epoch 6 / 100: avg data time: 5.74e-02, avg batch time: 0.4975, average train loss: 4.5554
[09/26 02:14:08 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1656, average loss: 4.6526
[09/26 02:14:08 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 3.50	
[09/26 02:14:08 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.6
[09/26 02:14:15 visual_prompt]: Epoch 7 / 100: avg data time: 5.44e-02, avg batch time: 0.4949, average train loss: 4.6314
[09/26 02:14:16 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1660, average loss: 4.6379
[09/26 02:14:16 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.00	
[09/26 02:14:16 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.7
[09/26 02:14:23 visual_prompt]: Epoch 8 / 100: avg data time: 4.54e-02, avg batch time: 0.4896, average train loss: 4.6220
[09/26 02:14:25 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1658, average loss: 4.6543
[09/26 02:14:25 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.00	
[09/26 02:14:25 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.8
[09/26 02:14:31 visual_prompt]: Epoch 9 / 100: avg data time: 4.73e-02, avg batch time: 0.4895, average train loss: 4.6063
[09/26 02:14:33 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1656, average loss: 4.6374
[09/26 02:14:33 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 6.00	
[09/26 02:14:33 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.9
[09/26 02:14:40 visual_prompt]: Epoch 10 / 100: avg data time: 6.16e-02, avg batch time: 0.5027, average train loss: 4.6260
[09/26 02:14:41 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1655, average loss: 4.6780
[09/26 02:14:41 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.50	
[09/26 02:14:41 visual_prompt]: Training 11 / 100 epoch, with learning rate 1.0
[09/26 02:14:48 visual_prompt]: Epoch 11 / 100: avg data time: 6.12e-02, avg batch time: 0.5020, average train loss: 4.6348
[09/26 02:14:49 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1658, average loss: 4.6642
[09/26 02:14:49 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 4.00	
[09/26 02:14:49 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.9996954135095479
[09/26 02:14:56 visual_prompt]: Epoch 12 / 100: avg data time: 5.68e-02, avg batch time: 0.4977, average train loss: 4.6085
[09/26 02:14:58 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1656, average loss: 4.6813
[09/26 02:14:58 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.00	
[09/26 02:14:58 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.9987820251299121
[09/26 02:15:04 visual_prompt]: Epoch 13 / 100: avg data time: 5.35e-02, avg batch time: 0.4932, average train loss: 4.6280
[09/26 02:15:06 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1656, average loss: 4.6527
[09/26 02:15:06 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 5.00	
[09/26 02:15:06 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.9972609476841366
[09/26 02:15:12 visual_prompt]: Epoch 14 / 100: avg data time: 4.71e-02, avg batch time: 0.4895, average train loss: 4.6605
[09/26 02:15:14 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1656, average loss: 4.6987
[09/26 02:15:14 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.00	
[09/26 02:15:14 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.9951340343707852
[09/26 02:15:21 visual_prompt]: Epoch 15 / 100: avg data time: 5.32e-02, avg batch time: 0.4937, average train loss: 4.6448
[09/26 02:15:22 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1655, average loss: 4.6745
[09/26 02:15:22 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 6.50	
[09/26 02:15:22 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.9924038765061041
[09/26 02:15:29 visual_prompt]: Epoch 16 / 100: avg data time: 4.34e-02, avg batch time: 0.4846, average train loss: 4.6640
[09/26 02:15:30 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1656, average loss: 4.7250
[09/26 02:15:30 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 3.00	
[09/26 02:15:30 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.9890738003669028
[09/26 02:15:37 visual_prompt]: Epoch 17 / 100: avg data time: 5.38e-02, avg batch time: 0.4948, average train loss: 4.6339
[09/26 02:15:38 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1656, average loss: 4.6576
[09/26 02:15:38 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 3.50	
[09/26 02:15:38 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.9851478631379982
[09/26 02:15:45 visual_prompt]: Epoch 18 / 100: avg data time: 5.57e-02, avg batch time: 0.4960, average train loss: 4.6255
[09/26 02:15:47 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1657, average loss: 4.6613
[09/26 02:15:47 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/26 02:15:47 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.9806308479691594
[09/26 02:15:53 visual_prompt]: Epoch 19 / 100: avg data time: 5.84e-02, avg batch time: 0.4978, average train loss: 4.6184
[09/26 02:15:55 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1653, average loss: 4.6584
[09/26 02:15:55 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.50	
[09/26 02:15:55 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.9755282581475768
[09/26 02:16:02 visual_prompt]: Epoch 20 / 100: avg data time: 5.81e-02, avg batch time: 0.4978, average train loss: 4.6254
[09/26 02:16:03 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1659, average loss: 4.6649
[09/26 02:16:03 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 6.00	
[09/26 02:16:03 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.9698463103929542
[09/26 02:16:10 visual_prompt]: Epoch 21 / 100: avg data time: 5.38e-02, avg batch time: 0.4944, average train loss: 4.6567
[09/26 02:16:11 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1659, average loss: 4.6524
[09/26 02:16:11 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 5.50	
[09/26 02:16:11 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.9635919272833937
[09/26 02:16:18 visual_prompt]: Epoch 22 / 100: avg data time: 4.74e-02, avg batch time: 0.4897, average train loss: 4.6333
[09/26 02:16:20 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1658, average loss: 4.6638
[09/26 02:16:20 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.50	
[09/26 02:16:20 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.9567727288213004
[09/26 02:16:26 visual_prompt]: Epoch 23 / 100: avg data time: 5.84e-02, avg batch time: 0.4995, average train loss: 4.6225
[09/26 02:16:28 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1655, average loss: 4.6585
[09/26 02:16:28 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.00	
[09/26 02:16:28 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.9493970231495835
[09/26 02:16:35 visual_prompt]: Epoch 24 / 100: avg data time: 5.64e-02, avg batch time: 0.4969, average train loss: 4.6070
[09/26 02:16:36 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1657, average loss: 4.6397
[09/26 02:16:36 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.00	
[09/26 02:16:36 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.9414737964294635
[09/26 02:16:43 visual_prompt]: Epoch 25 / 100: avg data time: 4.81e-02, avg batch time: 0.4882, average train loss: 4.6303
[09/26 02:16:44 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1657, average loss: 4.6661
[09/26 02:16:44 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 6.00	
[09/26 02:16:44 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.9330127018922194
[09/26 02:16:51 visual_prompt]: Epoch 26 / 100: avg data time: 6.43e-02, avg batch time: 0.5043, average train loss: 4.6085
[09/26 02:16:53 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1660, average loss: 4.6772
[09/26 02:16:53 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 6.00	
[09/26 02:16:53 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.9240240480782129
[09/26 02:16:59 visual_prompt]: Epoch 27 / 100: avg data time: 4.82e-02, avg batch time: 0.4905, average train loss: 4.6791
[09/26 02:17:01 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1658, average loss: 4.6288
[09/26 02:17:01 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.50	
[09/26 02:17:01 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.9145187862775208
[09/26 02:17:07 visual_prompt]: Epoch 28 / 100: avg data time: 5.73e-02, avg batch time: 0.4980, average train loss: 4.6326
[09/26 02:17:09 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1658, average loss: 4.7258
[09/26 02:17:09 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 4.50	
[09/26 02:17:09 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.9045084971874737
[09/26 02:17:16 visual_prompt]: Epoch 29 / 100: avg data time: 6.04e-02, avg batch time: 0.5018, average train loss: 4.6225
[09/26 02:17:17 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1655, average loss: 4.6918
[09/26 02:17:17 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.00	
[09/26 02:17:17 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.8940053768033609
[09/26 02:17:24 visual_prompt]: Epoch 30 / 100: avg data time: 3.98e-02, avg batch time: 0.4838, average train loss: 4.6246
[09/26 02:17:25 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1656, average loss: 4.6831
[09/26 02:17:25 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.00	
[09/26 02:17:25 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.883022221559489
[09/26 02:17:32 visual_prompt]: Epoch 31 / 100: avg data time: 6.30e-02, avg batch time: 0.5029, average train loss: 4.6571
[09/26 02:17:34 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1658, average loss: 4.6538
[09/26 02:17:34 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 4.50	
[09/26 02:17:34 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.8715724127386971
[09/26 02:17:40 visual_prompt]: Epoch 32 / 100: avg data time: 6.19e-02, avg batch time: 0.5019, average train loss: 4.6418
[09/26 02:17:42 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.1657, average loss: 4.6766
[09/26 02:17:42 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.00	
[09/26 02:17:42 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.8596699001693255
[09/26 02:17:49 visual_prompt]: Epoch 33 / 100: avg data time: 6.10e-02, avg batch time: 0.5008, average train loss: 4.6343
[09/26 02:17:50 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1656, average loss: 4.6544
[09/26 02:17:50 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/26 02:17:50 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.8473291852294986
[09/26 02:17:57 visual_prompt]: Epoch 34 / 100: avg data time: 5.56e-02, avg batch time: 0.4961, average train loss: 4.6012
[09/26 02:17:59 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1660, average loss: 4.6565
[09/26 02:17:59 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.00	
[09/26 02:17:59 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.8345653031794291
[09/26 02:18:05 visual_prompt]: Epoch 35 / 100: avg data time: 5.16e-02, avg batch time: 0.4923, average train loss: 4.5990
[09/26 02:18:07 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1660, average loss: 4.7183
[09/26 02:18:07 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.00	
[09/26 02:18:07 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.8213938048432696
[09/26 02:18:13 visual_prompt]: Epoch 36 / 100: avg data time: 5.36e-02, avg batch time: 0.4953, average train loss: 4.6292
[09/26 02:18:15 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1656, average loss: 4.6598
[09/26 02:18:15 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 6.50	
[09/26 02:18:15 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.8078307376628291
[09/26 02:18:22 visual_prompt]: Epoch 37 / 100: avg data time: 4.80e-02, avg batch time: 0.4884, average train loss: 4.6217
[09/26 02:18:23 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1657, average loss: 4.6300
[09/26 02:18:23 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/26 02:18:23 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.7938926261462366
[09/26 02:18:30 visual_prompt]: Epoch 38 / 100: avg data time: 4.47e-02, avg batch time: 0.4863, average train loss: 4.6167
[09/26 02:18:31 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1657, average loss: 4.6608
[09/26 02:18:31 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 2.50	
[09/26 02:18:31 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.7795964517353734
[09/26 02:18:38 visual_prompt]: Epoch 39 / 100: avg data time: 5.30e-02, avg batch time: 0.4945, average train loss: 4.6067
[09/26 02:18:39 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1660, average loss: 4.6498
[09/26 02:18:39 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.50	
[09/26 02:18:39 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.7649596321166025
[09/26 02:18:46 visual_prompt]: Epoch 40 / 100: avg data time: 6.46e-02, avg batch time: 0.5043, average train loss: 4.6176
[09/26 02:18:48 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.1658, average loss: 4.6476
[09/26 02:18:48 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.50	
[09/26 02:18:48 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.75
[09/26 02:18:55 visual_prompt]: Epoch 41 / 100: avg data time: 5.61e-02, avg batch time: 0.4962, average train loss: 4.5841
[09/26 02:18:56 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1657, average loss: 4.7007
[09/26 02:18:56 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.50	top5: 5.00	
[09/26 02:18:56 visual_prompt]: Best epoch 41: best metric: 0.025
[09/26 02:18:56 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.7347357813929454
[09/26 02:19:03 visual_prompt]: Epoch 42 / 100: avg data time: 5.35e-02, avg batch time: 0.4940, average train loss: 4.6240
[09/26 02:19:04 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1661, average loss: 4.6473
[09/26 02:19:04 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/26 02:19:04 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.7191855733945387
[09/26 02:19:11 visual_prompt]: Epoch 43 / 100: avg data time: 5.95e-02, avg batch time: 0.5004, average train loss: 4.6252
[09/26 02:19:13 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1658, average loss: 4.6577
[09/26 02:19:13 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 3.50	
[09/26 02:19:13 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.7033683215379002
[09/26 02:19:19 visual_prompt]: Epoch 44 / 100: avg data time: 5.60e-02, avg batch time: 0.4970, average train loss: 4.6162
[09/26 02:19:21 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1659, average loss: 4.6579
[09/26 02:19:21 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.50	
[09/26 02:19:21 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.6873032967079561
[09/26 02:19:28 visual_prompt]: Epoch 45 / 100: avg data time: 5.36e-02, avg batch time: 0.4941, average train loss: 4.6117
[09/26 02:19:29 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1660, average loss: 4.6712
[09/26 02:19:29 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/26 02:19:29 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.6710100716628344
[09/26 02:19:36 visual_prompt]: Epoch 46 / 100: avg data time: 5.52e-02, avg batch time: 0.4956, average train loss: 4.6302
[09/26 02:19:37 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1661, average loss: 4.6546
[09/26 02:19:37 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.50	
[09/26 02:19:37 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.6545084971874737
[09/26 02:19:44 visual_prompt]: Epoch 47 / 100: avg data time: 5.91e-02, avg batch time: 0.5005, average train loss: 4.5971
[09/26 02:19:46 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1660, average loss: 4.6904
[09/26 02:19:46 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 3.00	
[09/26 02:19:46 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.6378186779084996
[09/26 02:19:52 visual_prompt]: Epoch 48 / 100: avg data time: 5.86e-02, avg batch time: 0.5009, average train loss: 4.6030
[09/26 02:19:54 visual_prompt]: Inference (val):avg data time: 3.77e-05, avg batch time: 0.1660, average loss: 4.6388
[09/26 02:19:54 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 4.50	
[09/26 02:19:54 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.6209609477998338
[09/26 02:20:01 visual_prompt]: Epoch 49 / 100: avg data time: 5.64e-02, avg batch time: 0.4976, average train loss: 4.6161
[09/26 02:20:02 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1659, average loss: 4.6422
[09/26 02:20:02 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 6.00	
[09/26 02:20:02 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.6039558454088796
[09/26 02:20:09 visual_prompt]: Epoch 50 / 100: avg data time: 5.52e-02, avg batch time: 0.4960, average train loss: 4.5980
[09/26 02:20:10 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1656, average loss: 4.6791
[09/26 02:20:10 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.50	
[09/26 02:20:10 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.5868240888334653
[09/26 02:20:17 visual_prompt]: Epoch 51 / 100: avg data time: 4.17e-02, avg batch time: 0.4847, average train loss: 4.6044
[09/26 02:20:18 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1660, average loss: 4.6425
[09/26 02:20:18 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/26 02:20:18 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.5695865504800327
[09/26 02:20:25 visual_prompt]: Epoch 52 / 100: avg data time: 4.74e-02, avg batch time: 0.4892, average train loss: 4.5973
[09/26 02:20:26 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1662, average loss: 4.6495
[09/26 02:20:26 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.50	
[09/26 02:20:26 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.5522642316338268
[09/26 02:20:33 visual_prompt]: Epoch 53 / 100: avg data time: 4.85e-02, avg batch time: 0.4915, average train loss: 4.5843
[09/26 02:20:35 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1659, average loss: 4.6551
[09/26 02:20:35 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 3.50	
[09/26 02:20:35 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.5348782368720626
[09/26 02:20:41 visual_prompt]: Epoch 54 / 100: avg data time: 5.97e-02, avg batch time: 0.4999, average train loss: 4.6075
[09/26 02:20:43 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1658, average loss: 4.6863
[09/26 02:20:43 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 6.00	
[09/26 02:20:43 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.5174497483512506
[09/26 02:20:49 visual_prompt]: Epoch 55 / 100: avg data time: 4.62e-02, avg batch time: 0.4866, average train loss: 4.5904
[09/26 02:20:51 visual_prompt]: Inference (val):avg data time: 2.08e-05, avg batch time: 0.1656, average loss: 4.6537
[09/26 02:20:51 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.00	
[09/26 02:20:51 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.5
[09/26 02:20:58 visual_prompt]: Epoch 56 / 100: avg data time: 5.22e-02, avg batch time: 0.4928, average train loss: 4.5836
[09/26 02:20:59 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1657, average loss: 4.6625
[09/26 02:20:59 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 4.50	
[09/26 02:20:59 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.48255025164874965
[09/26 02:21:06 visual_prompt]: Epoch 57 / 100: avg data time: 5.78e-02, avg batch time: 0.4983, average train loss: 4.6194
[09/26 02:21:07 visual_prompt]: Inference (val):avg data time: 3.83e-05, avg batch time: 0.1657, average loss: 4.6607
[09/26 02:21:07 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 4.00	
[09/26 02:21:07 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.46512176312793735
[09/26 02:21:14 visual_prompt]: Epoch 58 / 100: avg data time: 5.73e-02, avg batch time: 0.4974, average train loss: 4.6107
[09/26 02:21:16 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1656, average loss: 4.6880
[09/26 02:21:16 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.50	
[09/26 02:21:16 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.44773576836617335
[09/26 02:21:22 visual_prompt]: Epoch 59 / 100: avg data time: 6.12e-02, avg batch time: 0.5016, average train loss: 4.5880
[09/26 02:21:24 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1659, average loss: 4.6460
[09/26 02:21:24 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.00	
[09/26 02:21:24 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.4304134495199674
[09/26 02:21:31 visual_prompt]: Epoch 60 / 100: avg data time: 6.02e-02, avg batch time: 0.5006, average train loss: 4.5852
[09/26 02:21:32 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1657, average loss: 4.6634
[09/26 02:21:32 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.00	
[09/26 02:21:32 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.41317591116653485
[09/26 02:21:39 visual_prompt]: Epoch 61 / 100: avg data time: 5.54e-02, avg batch time: 0.4953, average train loss: 4.5915
[09/26 02:21:40 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.1658, average loss: 4.6661
[09/26 02:21:40 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.00	
[09/26 02:21:40 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.3960441545911204
[09/26 02:21:47 visual_prompt]: Epoch 62 / 100: avg data time: 4.77e-02, avg batch time: 0.4889, average train loss: 4.5938
[09/26 02:21:48 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1662, average loss: 4.6561
[09/26 02:21:48 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/26 02:21:48 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.3790390522001662
[09/26 02:21:55 visual_prompt]: Epoch 63 / 100: avg data time: 5.36e-02, avg batch time: 0.4947, average train loss: 4.5754
[09/26 02:21:57 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1659, average loss: 4.6420
[09/26 02:21:57 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.50	
[09/26 02:21:57 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.36218132209150045
[09/26 02:22:03 visual_prompt]: Epoch 64 / 100: avg data time: 4.50e-02, avg batch time: 0.4872, average train loss: 4.5749
[09/26 02:22:05 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1656, average loss: 4.6333
[09/26 02:22:05 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/26 02:22:05 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.34549150281252633
[09/26 02:22:12 visual_prompt]: Epoch 65 / 100: avg data time: 6.07e-02, avg batch time: 0.5016, average train loss: 4.5796
[09/26 02:22:13 visual_prompt]: Inference (val):avg data time: 2.02e-05, avg batch time: 0.1660, average loss: 4.6360
[09/26 02:22:13 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/26 02:22:13 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.32898992833716567
[09/26 02:22:20 visual_prompt]: Epoch 66 / 100: avg data time: 5.67e-02, avg batch time: 0.4989, average train loss: 4.5750
[09/26 02:22:21 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1662, average loss: 4.6390
[09/26 02:22:21 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 3.50	
[09/26 02:22:21 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.31269670329204396
[09/26 02:22:28 visual_prompt]: Epoch 67 / 100: avg data time: 5.29e-02, avg batch time: 0.4941, average train loss: 4.5779
[09/26 02:22:30 visual_prompt]: Inference (val):avg data time: 2.01e-05, avg batch time: 0.1657, average loss: 4.6443
[09/26 02:22:30 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 5.50	
[09/26 02:22:30 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.2966316784621
[09/26 02:22:36 visual_prompt]: Epoch 68 / 100: avg data time: 4.15e-02, avg batch time: 0.4875, average train loss: 4.5828
[09/26 02:22:38 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1658, average loss: 4.6516
[09/26 02:22:38 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.00	
[09/26 02:22:38 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.28081442660546124
[09/26 02:22:44 visual_prompt]: Epoch 69 / 100: avg data time: 4.84e-02, avg batch time: 0.4896, average train loss: 4.5731
[09/26 02:22:46 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1657, average loss: 4.6502
[09/26 02:22:46 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.50	
[09/26 02:22:46 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.26526421860705474
[09/26 02:22:53 visual_prompt]: Epoch 70 / 100: avg data time: 4.17e-02, avg batch time: 0.4843, average train loss: 4.5790
[09/26 02:22:54 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.1660, average loss: 4.6411
[09/26 02:22:54 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.00	
[09/26 02:22:54 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.2500000000000001
[09/26 02:23:01 visual_prompt]: Epoch 71 / 100: avg data time: 4.69e-02, avg batch time: 0.4919, average train loss: 4.5625
[09/26 02:23:02 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1660, average loss: 4.6344
[09/26 02:23:02 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 6.50	
[09/26 02:23:02 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.2350403678833976
[09/26 02:23:09 visual_prompt]: Epoch 72 / 100: avg data time: 5.49e-02, avg batch time: 0.4958, average train loss: 4.5711
[09/26 02:23:10 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1663, average loss: 4.6473
[09/26 02:23:10 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.00	
[09/26 02:23:10 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.22040354826462666
[09/26 02:23:17 visual_prompt]: Epoch 73 / 100: avg data time: 5.35e-02, avg batch time: 0.4946, average train loss: 4.5750
[09/26 02:23:19 visual_prompt]: Inference (val):avg data time: 1.99e-05, avg batch time: 0.1658, average loss: 4.6459
[09/26 02:23:19 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/26 02:23:19 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.2061073738537635
[09/26 02:23:25 visual_prompt]: Epoch 74 / 100: avg data time: 5.10e-02, avg batch time: 0.4922, average train loss: 4.5685
[09/26 02:23:27 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1655, average loss: 4.6238
[09/26 02:23:27 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.00	
[09/26 02:23:27 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.19216926233717085
[09/26 02:23:33 visual_prompt]: Epoch 75 / 100: avg data time: 5.49e-02, avg batch time: 0.4954, average train loss: 4.5526
[09/26 02:23:35 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1656, average loss: 4.5909
[09/26 02:23:35 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 8.00	
[09/26 02:23:35 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.17860619515673032
[09/26 02:23:42 visual_prompt]: Epoch 76 / 100: avg data time: 5.80e-02, avg batch time: 0.4988, average train loss: 4.5178
[09/26 02:23:43 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1655, average loss: 4.6213
[09/26 02:23:43 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 6.50	
[09/26 02:23:43 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.16543469682057105
[09/26 02:23:50 visual_prompt]: Epoch 77 / 100: avg data time: 5.71e-02, avg batch time: 0.4978, average train loss: 4.4977
[09/26 02:23:51 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1659, average loss: 4.7037
[09/26 02:23:51 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 3.00	
[09/26 02:23:51 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.15267081477050132
[09/26 02:23:58 visual_prompt]: Epoch 78 / 100: avg data time: 5.84e-02, avg batch time: 0.4986, average train loss: 4.5757
[09/26 02:24:00 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1656, average loss: 4.6337
[09/26 02:24:00 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.00	
[09/26 02:24:00 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.14033009983067452
[09/26 02:24:06 visual_prompt]: Epoch 79 / 100: avg data time: 5.22e-02, avg batch time: 0.4935, average train loss: 4.5043
[09/26 02:24:08 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1658, average loss: 4.6195
[09/26 02:24:08 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 6.50	
[09/26 02:24:08 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.12842758726130282
[09/26 02:24:14 visual_prompt]: Epoch 80 / 100: avg data time: 5.54e-02, avg batch time: 0.4955, average train loss: 4.4935
[09/26 02:24:16 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1656, average loss: 4.5542
[09/26 02:24:16 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 8.50	
[09/26 02:24:16 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.11697777844051105
[09/26 02:24:23 visual_prompt]: Epoch 81 / 100: avg data time: 5.37e-02, avg batch time: 0.4957, average train loss: 4.4370
[09/26 02:24:24 visual_prompt]: Inference (val):avg data time: 1.97e-05, avg batch time: 0.1656, average loss: 4.5442
[09/26 02:24:24 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 3.50	top5: 10.50	
[09/26 02:24:24 visual_prompt]: Best epoch 81: best metric: 0.035
[09/26 02:24:24 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.10599462319663905
[09/26 02:24:31 visual_prompt]: Epoch 82 / 100: avg data time: 4.86e-02, avg batch time: 0.4908, average train loss: 4.3856
[09/26 02:24:32 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1659, average loss: 4.5058
[09/26 02:24:32 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 12.00	
[09/26 02:24:32 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.09549150281252633
[09/26 02:24:39 visual_prompt]: Epoch 83 / 100: avg data time: 4.58e-02, avg batch time: 0.4873, average train loss: 4.3413
[09/26 02:24:40 visual_prompt]: Inference (val):avg data time: 1.96e-05, avg batch time: 0.1658, average loss: 4.4619
[09/26 02:24:40 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 14.00	
[09/26 02:24:40 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.08548121372247919
[09/26 02:24:47 visual_prompt]: Epoch 84 / 100: avg data time: 4.41e-02, avg batch time: 0.4858, average train loss: 4.3290
[09/26 02:24:49 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1659, average loss: 4.5105
[09/26 02:24:49 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 3.50	top5: 11.50	
[09/26 02:24:49 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.07597595192178702
[09/26 02:24:55 visual_prompt]: Epoch 85 / 100: avg data time: 5.31e-02, avg batch time: 0.4947, average train loss: 4.3425
[09/26 02:24:57 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1659, average loss: 4.4558
[09/26 02:24:57 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 3.00	top5: 12.00	
[09/26 02:24:57 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.06698729810778065
[09/26 02:25:04 visual_prompt]: Epoch 86 / 100: avg data time: 6.15e-02, avg batch time: 0.5051, average train loss: 4.3137
[09/26 02:25:05 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1659, average loss: 4.4448
[09/26 02:25:05 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.50	top5: 14.50	
[09/26 02:25:05 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.058526203570536506
[09/26 02:25:12 visual_prompt]: Epoch 87 / 100: avg data time: 5.86e-02, avg batch time: 0.5006, average train loss: 4.2689
[09/26 02:25:13 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1659, average loss: 4.6502
[09/26 02:25:13 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.50	
[09/26 02:25:13 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.05060297685041659
[09/26 02:25:20 visual_prompt]: Epoch 88 / 100: avg data time: 5.80e-02, avg batch time: 0.4983, average train loss: 4.3367
[09/26 02:25:22 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1658, average loss: 4.4472
[09/26 02:25:22 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 12.50	
[09/26 02:25:22 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.04322727117869951
[09/26 02:25:28 visual_prompt]: Epoch 89 / 100: avg data time: 4.76e-02, avg batch time: 0.4887, average train loss: 4.2689
[09/26 02:25:30 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1659, average loss: 4.4890
[09/26 02:25:30 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 11.00	
[09/26 02:25:30 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.03640807271660634
[09/26 02:25:37 visual_prompt]: Epoch 90 / 100: avg data time: 5.55e-02, avg batch time: 0.4980, average train loss: 4.2668
[09/26 02:25:38 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1660, average loss: 4.4334
[09/26 02:25:38 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.50	top5: 15.00	
[09/26 02:25:38 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.03015368960704584
[09/26 02:25:45 visual_prompt]: Epoch 91 / 100: avg data time: 5.06e-02, avg batch time: 0.4912, average train loss: 4.2477
[09/26 02:25:46 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1659, average loss: 4.4450
[09/26 02:25:46 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 14.50	
[09/26 02:25:46 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.024471741852423234
[09/26 02:25:53 visual_prompt]: Epoch 92 / 100: avg data time: 5.67e-02, avg batch time: 0.4971, average train loss: 4.2373
[09/26 02:25:55 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1661, average loss: 4.4647
[09/26 02:25:55 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 3.00	top5: 15.00	
[09/26 02:25:55 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.019369152030840553
[09/26 02:26:01 visual_prompt]: Epoch 93 / 100: avg data time: 5.85e-02, avg batch time: 0.5009, average train loss: 4.2019
[09/26 02:26:03 visual_prompt]: Inference (val):avg data time: 1.99e-05, avg batch time: 0.1658, average loss: 4.4295
[09/26 02:26:03 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 12.00	
[09/26 02:26:03 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.014852136862001764
[09/26 02:26:10 visual_prompt]: Epoch 94 / 100: avg data time: 5.16e-02, avg batch time: 0.4928, average train loss: 4.1782
[09/26 02:26:11 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1660, average loss: 4.4232
[09/26 02:26:11 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 3.00	top5: 14.50	
[09/26 02:26:11 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.010926199633097156
[09/26 02:26:18 visual_prompt]: Epoch 95 / 100: avg data time: 6.30e-02, avg batch time: 0.5035, average train loss: 4.1433
[09/26 02:26:19 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1658, average loss: 4.4161
[09/26 02:26:19 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.50	top5: 15.00	
[09/26 02:26:19 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.00759612349389599
[09/26 02:26:26 visual_prompt]: Epoch 96 / 100: avg data time: 6.00e-02, avg batch time: 0.5011, average train loss: 4.1375
[09/26 02:26:28 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1661, average loss: 4.4097
[09/26 02:26:28 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 4.00	top5: 17.50	
[09/26 02:26:28 visual_prompt]: Best epoch 96: best metric: 0.040
[09/26 02:26:28 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.004865965629214819
[09/26 02:26:35 visual_prompt]: Epoch 97 / 100: avg data time: 5.57e-02, avg batch time: 0.4968, average train loss: 4.1111
[09/26 02:26:36 visual_prompt]: Inference (val):avg data time: 2.02e-05, avg batch time: 0.1658, average loss: 4.4097
[09/26 02:26:36 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.50	top5: 17.50	
[09/26 02:26:36 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.002739052315863355
[09/26 02:26:43 visual_prompt]: Epoch 98 / 100: avg data time: 5.48e-02, avg batch time: 0.4958, average train loss: 4.0992
[09/26 02:26:44 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1660, average loss: 4.4061
[09/26 02:26:44 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.50	top5: 17.50	
[09/26 02:26:44 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.0012179748700879012
[09/26 02:26:51 visual_prompt]: Epoch 99 / 100: avg data time: 4.90e-02, avg batch time: 0.4903, average train loss: 4.0917
[09/26 02:26:52 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1660, average loss: 4.4073
[09/26 02:26:52 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 3.50	top5: 17.00	
[09/26 02:26:52 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.00030458649045211894
[09/26 02:26:59 visual_prompt]: Epoch 100 / 100: avg data time: 5.55e-02, avg batch time: 0.4962, average train loss: 4.0877
[09/26 02:27:00 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.1661, average loss: 4.4069
[09/26 02:27:00 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 4.00	top5: 17.00	
[09/26 02:27:01 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 02:27:01 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 02:27:01 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-cifar(num_classes=100)', 'DATA.NUMBER_CLASSES', '100', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 02:27:01 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 02:27:01 visual_prompt]: Training with config:
[09/26 02:27:01 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-cifar(num_classes=100)/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr1.0_wd0.001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 1.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-cifar(num_classes=100)', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 100, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 02:27:01 visual_prompt]: Loading training data...
[09/26 02:27:01 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[:800], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/26 02:27:01 visual_prompt]: Number of images: 800
[09/26 02:27:01 visual_prompt]: Number of classes: 100 / 100
[09/26 02:27:01 visual_prompt]: Loading validation data...
[09/26 02:27:01 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[45000:45200], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/26 02:27:02 visual_prompt]: Number of images: 200
[09/26 02:27:02 visual_prompt]: Number of classes: 90 / 100
[09/26 02:27:02 visual_prompt]: Constructing models...
[09/26 02:27:04 visual_prompt]: Total Parameters: 86336356	 Gradient Parameters: 537700
[09/26 02:27:04 visual_prompt]: tuned percent:0.623
[09/26 02:27:04 visual_prompt]: Device used for model: 0
[09/26 02:27:04 visual_prompt]: Setting up Evaluator...
[09/26 02:27:04 visual_prompt]: Setting up Trainer...
[09/26 02:27:04 visual_prompt]: 	Setting up the optimizer...
[09/26 02:27:04 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 02:27:11 visual_prompt]: Epoch 1 / 100: avg data time: 6.04e-02, avg batch time: 0.5008, average train loss: 4.6576
[09/26 02:27:13 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1655, average loss: 4.6218
[09/26 02:27:13 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 7.00	
[09/26 02:27:13 visual_prompt]: Best epoch 1: best metric: 0.010
[09/26 02:27:13 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.1
[09/26 02:27:19 visual_prompt]: Epoch 2 / 100: avg data time: 5.60e-02, avg batch time: 0.4969, average train loss: 4.6365
[09/26 02:27:21 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1660, average loss: 4.6281
[09/26 02:27:21 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/26 02:27:21 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.2
[09/26 02:27:28 visual_prompt]: Epoch 3 / 100: avg data time: 5.39e-02, avg batch time: 0.4959, average train loss: 4.5794
[09/26 02:27:29 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1658, average loss: 4.6630
[09/26 02:27:29 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.00	
[09/26 02:27:29 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.3
[09/26 02:27:36 visual_prompt]: Epoch 4 / 100: avg data time: 5.03e-02, avg batch time: 0.4920, average train loss: 4.5852
[09/26 02:27:37 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1661, average loss: 4.6095
[09/26 02:27:37 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 7.00	
[09/26 02:27:37 visual_prompt]: Best epoch 4: best metric: 0.015
[09/26 02:27:37 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.4
[09/26 02:27:44 visual_prompt]: Epoch 5 / 100: avg data time: 5.70e-02, avg batch time: 0.4977, average train loss: 4.5254
[09/26 02:27:45 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1661, average loss: 4.5021
[09/26 02:27:45 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 3.00	top5: 16.00	
[09/26 02:27:45 visual_prompt]: Best epoch 5: best metric: 0.030
[09/26 02:27:45 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.5
[09/26 02:27:52 visual_prompt]: Epoch 6 / 100: avg data time: 5.74e-02, avg batch time: 0.4983, average train loss: 4.3224
[09/26 02:27:54 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1661, average loss: 4.1934
[09/26 02:27:54 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 6.50	top5: 22.00	
[09/26 02:27:54 visual_prompt]: Best epoch 6: best metric: 0.065
[09/26 02:27:54 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.6
[09/26 02:28:00 visual_prompt]: Epoch 7 / 100: avg data time: 5.75e-02, avg batch time: 0.4994, average train loss: 3.7583
[09/26 02:28:02 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1660, average loss: 3.9238
[09/26 02:28:02 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 8.50	top5: 27.50	
[09/26 02:28:02 visual_prompt]: Best epoch 7: best metric: 0.085
[09/26 02:28:02 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.7
[09/26 02:28:09 visual_prompt]: Epoch 8 / 100: avg data time: 6.02e-02, avg batch time: 0.5026, average train loss: 3.0262
[09/26 02:28:10 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1662, average loss: 3.2409
[09/26 02:28:10 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 21.00	top5: 50.50	
[09/26 02:28:10 visual_prompt]: Best epoch 8: best metric: 0.210
[09/26 02:28:10 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.8
[09/26 02:28:17 visual_prompt]: Epoch 9 / 100: avg data time: 5.36e-02, avg batch time: 0.4959, average train loss: 1.9189
[09/26 02:28:19 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1663, average loss: 2.0254
[09/26 02:28:19 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 48.50	top5: 79.50	
[09/26 02:28:19 visual_prompt]: Best epoch 9: best metric: 0.485
[09/26 02:28:19 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.9
[09/26 02:28:25 visual_prompt]: Epoch 10 / 100: avg data time: 5.81e-02, avg batch time: 0.5005, average train loss: 0.7816
[09/26 02:28:27 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1663, average loss: 1.3948
[09/26 02:28:27 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.50	top5: 89.00	
[09/26 02:28:27 visual_prompt]: Best epoch 10: best metric: 0.615
[09/26 02:28:27 visual_prompt]: Training 11 / 100 epoch, with learning rate 1.0
[09/26 02:28:34 visual_prompt]: Epoch 11 / 100: avg data time: 5.53e-02, avg batch time: 0.4963, average train loss: 0.2620
[09/26 02:28:35 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1662, average loss: 1.2337
[09/26 02:28:35 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.00	top5: 93.00	
[09/26 02:28:35 visual_prompt]: Best epoch 11: best metric: 0.670
[09/26 02:28:35 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.9996954135095479
[09/26 02:28:42 visual_prompt]: Epoch 12 / 100: avg data time: 5.46e-02, avg batch time: 0.4962, average train loss: 0.0961
[09/26 02:28:43 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1665, average loss: 1.0490
[09/26 02:28:43 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 74.00	top5: 95.00	
[09/26 02:28:43 visual_prompt]: Best epoch 12: best metric: 0.740
[09/26 02:28:43 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.9987820251299121
[09/26 02:28:50 visual_prompt]: Epoch 13 / 100: avg data time: 4.88e-02, avg batch time: 0.4915, average train loss: 0.0587
[09/26 02:28:51 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1663, average loss: 1.0054
[09/26 02:28:51 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 74.50	top5: 94.50	
[09/26 02:28:51 visual_prompt]: Best epoch 13: best metric: 0.745
[09/26 02:28:51 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.9972609476841366
[09/26 02:28:58 visual_prompt]: Epoch 14 / 100: avg data time: 5.84e-02, avg batch time: 0.5003, average train loss: 0.0547
[09/26 02:29:00 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1665, average loss: 1.0106
[09/26 02:29:00 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 73.50	top5: 95.50	
[09/26 02:29:00 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.9951340343707852
[09/26 02:29:06 visual_prompt]: Epoch 15 / 100: avg data time: 5.35e-02, avg batch time: 0.4947, average train loss: 0.0590
[09/26 02:29:08 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1663, average loss: 1.0077
[09/26 02:29:08 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 73.50	top5: 95.00	
[09/26 02:29:08 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.9924038765061041
[09/26 02:29:15 visual_prompt]: Epoch 16 / 100: avg data time: 6.00e-02, avg batch time: 0.5018, average train loss: 0.0624
[09/26 02:29:16 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1663, average loss: 0.9858
[09/26 02:29:16 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 76.50	top5: 95.50	
[09/26 02:29:16 visual_prompt]: Best epoch 16: best metric: 0.765
[09/26 02:29:16 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.9890738003669028
[09/26 02:29:23 visual_prompt]: Epoch 17 / 100: avg data time: 5.31e-02, avg batch time: 0.4959, average train loss: 0.0684
[09/26 02:29:24 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1664, average loss: 1.0388
[09/26 02:29:24 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 72.50	top5: 96.00	
[09/26 02:29:24 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.9851478631379982
[09/26 02:29:31 visual_prompt]: Epoch 18 / 100: avg data time: 4.57e-02, avg batch time: 0.4881, average train loss: 0.0750
[09/26 02:29:33 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1666, average loss: 1.0244
[09/26 02:29:33 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 76.50	top5: 96.00	
[09/26 02:29:33 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.9806308479691594
[09/26 02:29:39 visual_prompt]: Epoch 19 / 100: avg data time: 5.38e-02, avg batch time: 0.4954, average train loss: 0.0977
[09/26 02:29:41 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1666, average loss: 1.0595
[09/26 02:29:41 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 75.00	top5: 94.00	
[09/26 02:29:41 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.9755282581475768
[09/26 02:29:47 visual_prompt]: Epoch 20 / 100: avg data time: 5.18e-02, avg batch time: 0.4955, average train loss: 1.1504
[09/26 02:29:49 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1662, average loss: 4.6430
[09/26 02:29:49 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 7.50	
[09/26 02:29:49 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.9698463103929542
[09/26 02:29:56 visual_prompt]: Epoch 21 / 100: avg data time: 5.53e-02, avg batch time: 0.4984, average train loss: 2.6413
[09/26 02:29:57 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1663, average loss: 3.8687
[09/26 02:29:57 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 11.00	top5: 35.00	
[09/26 02:29:57 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.9635919272833937
[09/26 02:30:04 visual_prompt]: Epoch 22 / 100: avg data time: 5.59e-02, avg batch time: 0.4998, average train loss: 1.2173
[09/26 02:30:06 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1664, average loss: 1.4240
[09/26 02:30:06 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 69.00	top5: 87.50	
[09/26 02:30:06 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.9567727288213004
[09/26 02:30:12 visual_prompt]: Epoch 23 / 100: avg data time: 5.70e-02, avg batch time: 0.5001, average train loss: 0.2590
[09/26 02:30:14 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1663, average loss: 1.1625
[09/26 02:30:14 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 69.00	top5: 92.50	
[09/26 02:30:14 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.9493970231495835
[09/26 02:30:21 visual_prompt]: Epoch 24 / 100: avg data time: 5.68e-02, avg batch time: 0.4996, average train loss: 0.0951
[09/26 02:30:22 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1663, average loss: 0.9643
[09/26 02:30:22 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 76.00	top5: 94.50	
[09/26 02:30:22 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.9414737964294635
[09/26 02:30:29 visual_prompt]: Epoch 25 / 100: avg data time: 4.65e-02, avg batch time: 0.4889, average train loss: 0.0633
[09/26 02:30:30 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1664, average loss: 0.9513
[09/26 02:30:30 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 76.00	top5: 95.50	
[09/26 02:30:30 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.9330127018922194
[09/26 02:30:37 visual_prompt]: Epoch 26 / 100: avg data time: 5.61e-02, avg batch time: 0.4988, average train loss: 0.0556
[09/26 02:30:39 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1666, average loss: 0.9171
[09/26 02:30:39 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 77.50	top5: 95.00	
[09/26 02:30:39 visual_prompt]: Best epoch 26: best metric: 0.775
[09/26 02:30:39 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.9240240480782129
[09/26 02:30:45 visual_prompt]: Epoch 27 / 100: avg data time: 4.56e-02, avg batch time: 0.4877, average train loss: 0.0564
[09/26 02:30:47 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1665, average loss: 0.9208
[09/26 02:30:47 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 77.50	top5: 94.50	
[09/26 02:30:47 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.9145187862775208
[09/26 02:30:53 visual_prompt]: Epoch 28 / 100: avg data time: 4.79e-02, avg batch time: 0.4918, average train loss: 0.0588
[09/26 02:30:55 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1665, average loss: 0.9640
[09/26 02:30:55 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 76.50	top5: 95.50	
[09/26 02:30:55 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.9045084971874737
[09/26 02:31:02 visual_prompt]: Epoch 29 / 100: avg data time: 5.48e-02, avg batch time: 0.4982, average train loss: 0.0598
[09/26 02:31:03 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1664, average loss: 0.9448
[09/26 02:31:03 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 78.00	top5: 96.50	
[09/26 02:31:03 visual_prompt]: Best epoch 29: best metric: 0.780
[09/26 02:31:03 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.8940053768033609
[09/26 02:31:10 visual_prompt]: Epoch 30 / 100: avg data time: 5.54e-02, avg batch time: 0.4978, average train loss: 0.0576
[09/26 02:31:11 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1664, average loss: 0.9091
[09/26 02:31:11 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 77.50	top5: 97.00	
[09/26 02:31:11 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.883022221559489
[09/26 02:31:18 visual_prompt]: Epoch 31 / 100: avg data time: 4.15e-02, avg batch time: 0.4855, average train loss: 0.0574
[09/26 02:31:20 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1666, average loss: 0.9008
[09/26 02:31:20 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 80.50	top5: 97.00	
[09/26 02:31:20 visual_prompt]: Best epoch 31: best metric: 0.805
[09/26 02:31:20 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.8715724127386971
[09/26 02:31:26 visual_prompt]: Epoch 32 / 100: avg data time: 5.59e-02, avg batch time: 0.4995, average train loss: 0.0637
[09/26 02:31:28 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1663, average loss: 0.8856
[09/26 02:31:28 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 80.00	top5: 97.00	
[09/26 02:31:28 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.8596699001693255
[09/26 02:31:35 visual_prompt]: Epoch 33 / 100: avg data time: 5.64e-02, avg batch time: 0.4989, average train loss: 0.0656
[09/26 02:31:36 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1662, average loss: 0.9578
[09/26 02:31:36 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 75.50	top5: 96.00	
[09/26 02:31:36 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.8473291852294986
[09/26 02:31:43 visual_prompt]: Epoch 34 / 100: avg data time: 5.51e-02, avg batch time: 0.4976, average train loss: 0.0730
[09/26 02:31:45 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1664, average loss: 0.8853
[09/26 02:31:45 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 82.00	top5: 96.00	
[09/26 02:31:45 visual_prompt]: Best epoch 34: best metric: 0.820
[09/26 02:31:45 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.8345653031794291
[09/26 02:31:51 visual_prompt]: Epoch 35 / 100: avg data time: 5.05e-02, avg batch time: 0.4938, average train loss: 0.1039
[09/26 02:31:53 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1662, average loss: 1.0541
[09/26 02:31:53 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 72.00	top5: 93.50	
[09/26 02:31:53 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.8213938048432696
[09/26 02:31:59 visual_prompt]: Epoch 36 / 100: avg data time: 5.48e-02, avg batch time: 0.4968, average train loss: 0.1684
[09/26 02:32:01 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1664, average loss: 1.0438
[09/26 02:32:01 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 76.50	top5: 92.50	
[09/26 02:32:01 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.8078307376628291
[09/26 02:32:08 visual_prompt]: Epoch 37 / 100: avg data time: 5.88e-02, avg batch time: 0.5000, average train loss: 0.1715
[09/26 02:32:09 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1663, average loss: 0.8819
[09/26 02:32:09 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 80.00	top5: 95.50	
[09/26 02:32:09 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.7938926261462366
[09/26 02:32:16 visual_prompt]: Epoch 38 / 100: avg data time: 5.10e-02, avg batch time: 0.4932, average train loss: 0.1057
[09/26 02:32:18 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1662, average loss: 0.8606
[09/26 02:32:18 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 78.50	top5: 96.00	
[09/26 02:32:18 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.7795964517353734
[09/26 02:32:24 visual_prompt]: Epoch 39 / 100: avg data time: 5.72e-02, avg batch time: 0.5027, average train loss: 0.0786
[09/26 02:32:26 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1661, average loss: 0.8056
[09/26 02:32:26 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 81.50	top5: 95.00	
[09/26 02:32:26 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.7649596321166025
[09/26 02:32:33 visual_prompt]: Epoch 40 / 100: avg data time: 5.21e-02, avg batch time: 0.4933, average train loss: 0.0607
[09/26 02:32:34 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1662, average loss: 0.8563
[09/26 02:32:34 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 78.50	top5: 96.00	
[09/26 02:32:34 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.75
[09/26 02:32:41 visual_prompt]: Epoch 41 / 100: avg data time: 5.68e-02, avg batch time: 0.4978, average train loss: 0.0485
[09/26 02:32:42 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1662, average loss: 0.7893
[09/26 02:32:42 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 79.50	top5: 96.00	
[09/26 02:32:42 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.7347357813929454
[09/26 02:32:49 visual_prompt]: Epoch 42 / 100: avg data time: 4.59e-02, avg batch time: 0.4886, average train loss: 0.0404
[09/26 02:32:50 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1662, average loss: 0.7529
[09/26 02:32:51 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 81.50	top5: 97.00	
[09/26 02:32:51 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.7191855733945387
[09/26 02:32:57 visual_prompt]: Epoch 43 / 100: avg data time: 5.54e-02, avg batch time: 0.4967, average train loss: 0.0385
[09/26 02:32:59 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1661, average loss: 0.7495
[09/26 02:32:59 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 82.50	top5: 96.50	
[09/26 02:32:59 visual_prompt]: Best epoch 43: best metric: 0.825
[09/26 02:32:59 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.7033683215379002
[09/26 02:33:05 visual_prompt]: Epoch 44 / 100: avg data time: 4.55e-02, avg batch time: 0.4883, average train loss: 0.0380
[09/26 02:33:07 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1663, average loss: 0.8003
[09/26 02:33:07 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 80.00	top5: 96.50	
[09/26 02:33:07 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.6873032967079561
[09/26 02:33:13 visual_prompt]: Epoch 45 / 100: avg data time: 4.42e-02, avg batch time: 0.4872, average train loss: 0.0389
[09/26 02:33:15 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1663, average loss: 0.7690
[09/26 02:33:15 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 81.00	top5: 97.50	
[09/26 02:33:15 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.6710100716628344
[09/26 02:33:22 visual_prompt]: Epoch 46 / 100: avg data time: 4.51e-02, avg batch time: 0.4889, average train loss: 0.0404
[09/26 02:33:23 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1662, average loss: 0.8134
[09/26 02:33:23 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 80.50	top5: 95.00	
[09/26 02:33:23 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.6545084971874737
[09/26 02:33:30 visual_prompt]: Epoch 47 / 100: avg data time: 5.56e-02, avg batch time: 0.4969, average train loss: 0.0448
[09/26 02:33:31 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1663, average loss: 0.8059
[09/26 02:33:31 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 80.50	top5: 96.00	
[09/26 02:33:31 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.6378186779084996
[09/26 02:33:38 visual_prompt]: Epoch 48 / 100: avg data time: 5.64e-02, avg batch time: 0.4979, average train loss: 0.0526
[09/26 02:33:40 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1664, average loss: 0.9677
[09/26 02:33:40 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 75.50	top5: 95.50	
[09/26 02:33:40 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.6209609477998338
[09/26 02:33:46 visual_prompt]: Epoch 49 / 100: avg data time: 5.84e-02, avg batch time: 0.5004, average train loss: 0.0723
[09/26 02:33:48 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1662, average loss: 0.9766
[09/26 02:33:48 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 78.50	top5: 94.50	
[09/26 02:33:48 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.6039558454088796
[09/26 02:33:55 visual_prompt]: Epoch 50 / 100: avg data time: 4.87e-02, avg batch time: 0.4913, average train loss: 0.1984
[09/26 02:33:56 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1663, average loss: 4.0982
[09/26 02:33:56 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 20.00	top5: 45.50	
[09/26 02:33:56 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.5868240888334653
[09/26 02:34:03 visual_prompt]: Epoch 51 / 100: avg data time: 5.89e-02, avg batch time: 0.5007, average train loss: 3.7067
[09/26 02:34:04 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1662, average loss: 4.2216
[09/26 02:34:04 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 10.00	top5: 26.50	
[09/26 02:34:04 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.5695865504800327
[09/26 02:34:11 visual_prompt]: Epoch 52 / 100: avg data time: 5.05e-02, avg batch time: 0.4919, average train loss: 1.5595
[09/26 02:34:13 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1664, average loss: 1.5795
[09/26 02:34:13 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.50	top5: 87.50	
[09/26 02:34:13 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.5522642316338268
[09/26 02:34:19 visual_prompt]: Epoch 53 / 100: avg data time: 5.55e-02, avg batch time: 0.4968, average train loss: 0.4707
[09/26 02:34:21 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1664, average loss: 1.0900
[09/26 02:34:21 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 70.00	top5: 93.00	
[09/26 02:34:21 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.5348782368720626
[09/26 02:34:28 visual_prompt]: Epoch 54 / 100: avg data time: 5.24e-02, avg batch time: 0.4943, average train loss: 0.1736
[09/26 02:34:29 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1664, average loss: 1.0273
[09/26 02:34:29 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 75.50	top5: 93.50	
[09/26 02:34:29 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.5174497483512506
[09/26 02:34:36 visual_prompt]: Epoch 55 / 100: avg data time: 5.63e-02, avg batch time: 0.4986, average train loss: 0.0989
[09/26 02:34:37 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1665, average loss: 1.0047
[09/26 02:34:37 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 76.00	top5: 94.00	
[09/26 02:34:37 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.5
[09/26 02:34:44 visual_prompt]: Epoch 56 / 100: avg data time: 5.55e-02, avg batch time: 0.4979, average train loss: 0.0671
[09/26 02:34:46 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1664, average loss: 0.9777
[09/26 02:34:46 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 76.50	top5: 93.00	
[09/26 02:34:46 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.48255025164874965
[09/26 02:34:52 visual_prompt]: Epoch 57 / 100: avg data time: 5.18e-02, avg batch time: 0.4929, average train loss: 0.0557
[09/26 02:34:54 visual_prompt]: Inference (val):avg data time: 4.19e-05, avg batch time: 0.1663, average loss: 0.9633
[09/26 02:34:54 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 76.00	top5: 94.00	
[09/26 02:34:54 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.46512176312793735
[09/26 02:35:01 visual_prompt]: Epoch 58 / 100: avg data time: 4.97e-02, avg batch time: 0.4916, average train loss: 0.0485
[09/26 02:35:02 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1664, average loss: 0.9664
[09/26 02:35:02 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 76.50	top5: 93.50	
[09/26 02:35:02 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.44773576836617335
[09/26 02:35:09 visual_prompt]: Epoch 59 / 100: avg data time: 5.27e-02, avg batch time: 0.4951, average train loss: 0.0468
[09/26 02:35:10 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1664, average loss: 0.9577
[09/26 02:35:10 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 76.00	top5: 93.50	
[09/26 02:35:10 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.4304134495199674
[09/26 02:35:17 visual_prompt]: Epoch 60 / 100: avg data time: 4.56e-02, avg batch time: 0.4882, average train loss: 0.0469
[09/26 02:35:18 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1666, average loss: 0.9524
[09/26 02:35:18 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 76.50	top5: 93.50	
[09/26 02:35:18 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.41317591116653485
[09/26 02:35:25 visual_prompt]: Epoch 61 / 100: avg data time: 6.34e-02, avg batch time: 0.5050, average train loss: 0.0463
[09/26 02:35:27 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1666, average loss: 0.9451
[09/26 02:35:27 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 78.50	top5: 93.00	
[09/26 02:35:27 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.3960441545911204
[09/26 02:35:33 visual_prompt]: Epoch 62 / 100: avg data time: 5.20e-02, avg batch time: 0.4956, average train loss: 0.0459
[09/26 02:35:35 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1664, average loss: 0.9519
[09/26 02:35:35 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 79.50	top5: 94.00	
[09/26 02:35:35 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.3790390522001662
[09/26 02:35:42 visual_prompt]: Epoch 63 / 100: avg data time: 5.89e-02, avg batch time: 0.5005, average train loss: 0.0466
[09/26 02:35:43 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1666, average loss: 0.9410
[09/26 02:35:43 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 79.50	top5: 94.00	
[09/26 02:35:43 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.36218132209150045
[09/26 02:35:50 visual_prompt]: Epoch 64 / 100: avg data time: 5.71e-02, avg batch time: 0.4989, average train loss: 0.0466
[09/26 02:35:51 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1666, average loss: 0.9838
[09/26 02:35:51 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 78.50	top5: 94.50	
[09/26 02:35:51 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.34549150281252633
[09/26 02:35:58 visual_prompt]: Epoch 65 / 100: avg data time: 5.55e-02, avg batch time: 0.4978, average train loss: 0.0453
[09/26 02:36:00 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1665, average loss: 0.9896
[09/26 02:36:00 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 76.50	top5: 93.50	
[09/26 02:36:00 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.32898992833716567
[09/26 02:36:06 visual_prompt]: Epoch 66 / 100: avg data time: 5.35e-02, avg batch time: 0.4969, average train loss: 0.0485
[09/26 02:36:08 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1665, average loss: 0.9691
[09/26 02:36:08 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 76.00	top5: 95.00	
[09/26 02:36:08 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.31269670329204396
[09/26 02:36:15 visual_prompt]: Epoch 67 / 100: avg data time: 5.79e-02, avg batch time: 0.4995, average train loss: 0.0494
[09/26 02:36:16 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1666, average loss: 0.9535
[09/26 02:36:16 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 76.00	top5: 94.00	
[09/26 02:36:16 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.2966316784621
[09/26 02:36:23 visual_prompt]: Epoch 68 / 100: avg data time: 5.96e-02, avg batch time: 0.5029, average train loss: 0.0449
[09/26 02:36:25 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1663, average loss: 0.9966
[09/26 02:36:25 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 74.50	top5: 94.00	
[09/26 02:36:25 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.28081442660546124
[09/26 02:36:31 visual_prompt]: Epoch 69 / 100: avg data time: 5.79e-02, avg batch time: 0.4994, average train loss: 0.0419
[09/26 02:36:33 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1664, average loss: 0.9463
[09/26 02:36:33 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 76.50	top5: 94.50	
[09/26 02:36:33 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.26526421860705474
[09/26 02:36:40 visual_prompt]: Epoch 70 / 100: avg data time: 5.44e-02, avg batch time: 0.4961, average train loss: 0.0405
[09/26 02:36:41 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1663, average loss: 0.9836
[09/26 02:36:41 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 76.50	top5: 93.50	
[09/26 02:36:41 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.2500000000000001
[09/26 02:36:48 visual_prompt]: Epoch 71 / 100: avg data time: 5.78e-02, avg batch time: 0.4994, average train loss: 0.0386
[09/26 02:36:49 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1664, average loss: 0.9731
[09/26 02:36:49 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 76.50	top5: 93.50	
[09/26 02:36:49 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.2350403678833976
[09/26 02:36:56 visual_prompt]: Epoch 72 / 100: avg data time: 4.46e-02, avg batch time: 0.4876, average train loss: 0.0375
[09/26 02:36:57 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1664, average loss: 0.9856
[09/26 02:36:57 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 75.00	top5: 94.50	
[09/26 02:36:57 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.22040354826462666
[09/26 02:37:04 visual_prompt]: Epoch 73 / 100: avg data time: 5.04e-02, avg batch time: 0.4922, average train loss: 0.0380
[09/26 02:37:06 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1668, average loss: 0.9766
[09/26 02:37:06 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 75.50	top5: 94.00	
[09/26 02:37:06 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.2061073738537635
[09/26 02:37:12 visual_prompt]: Epoch 74 / 100: avg data time: 5.55e-02, avg batch time: 0.4980, average train loss: 0.0368
[09/26 02:37:14 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1665, average loss: 0.9813
[09/26 02:37:14 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 77.00	top5: 94.00	
[09/26 02:37:14 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.19216926233717085
[09/26 02:37:21 visual_prompt]: Epoch 75 / 100: avg data time: 5.86e-02, avg batch time: 0.5001, average train loss: 0.0365
[09/26 02:37:22 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1664, average loss: 0.9997
[09/26 02:37:22 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 74.50	top5: 95.00	
[09/26 02:37:22 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.17860619515673032
[09/26 02:37:29 visual_prompt]: Epoch 76 / 100: avg data time: 5.58e-02, avg batch time: 0.4978, average train loss: 0.0355
[09/26 02:37:31 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1666, average loss: 0.9917
[09/26 02:37:31 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 75.00	top5: 94.50	
[09/26 02:37:31 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.16543469682057105
[09/26 02:37:37 visual_prompt]: Epoch 77 / 100: avg data time: 4.30e-02, avg batch time: 0.4855, average train loss: 0.0348
[09/26 02:37:39 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1666, average loss: 1.0348
[09/26 02:37:39 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 72.00	top5: 94.50	
[09/26 02:37:39 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.15267081477050132
[09/26 02:37:45 visual_prompt]: Epoch 78 / 100: avg data time: 5.80e-02, avg batch time: 0.4993, average train loss: 0.0344
[09/26 02:37:47 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1666, average loss: 0.9965
[09/26 02:37:47 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 76.00	top5: 94.50	
[09/26 02:37:47 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.14033009983067452
[09/26 02:37:54 visual_prompt]: Epoch 79 / 100: avg data time: 4.77e-02, avg batch time: 0.4907, average train loss: 0.0341
[09/26 02:37:55 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1665, average loss: 0.9969
[09/26 02:37:55 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 75.50	top5: 94.50	
[09/26 02:37:55 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.12842758726130282
[09/26 02:38:02 visual_prompt]: Epoch 80 / 100: avg data time: 6.02e-02, avg batch time: 0.5016, average train loss: 0.0337
[09/26 02:38:04 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1667, average loss: 1.0307
[09/26 02:38:04 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 75.50	top5: 94.50	
[09/26 02:38:04 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.11697777844051105
[09/26 02:38:10 visual_prompt]: Epoch 81 / 100: avg data time: 5.59e-02, avg batch time: 0.4982, average train loss: 0.0335
[09/26 02:38:12 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1664, average loss: 1.0264
[09/26 02:38:12 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 75.00	top5: 94.50	
[09/26 02:38:12 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.10599462319663905
[09/26 02:38:18 visual_prompt]: Epoch 82 / 100: avg data time: 5.46e-02, avg batch time: 0.4960, average train loss: 0.0336
[09/26 02:38:20 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1666, average loss: 1.0389
[09/26 02:38:20 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 75.50	top5: 94.00	
[09/26 02:38:20 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.09549150281252633
[09/26 02:38:27 visual_prompt]: Epoch 83 / 100: avg data time: 6.10e-02, avg batch time: 0.5026, average train loss: 0.0330
[09/26 02:38:28 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1665, average loss: 1.0438
[09/26 02:38:28 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 75.50	top5: 94.00	
[09/26 02:38:28 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.08548121372247919
[09/26 02:38:35 visual_prompt]: Epoch 84 / 100: avg data time: 5.70e-02, avg batch time: 0.4996, average train loss: 0.0327
[09/26 02:38:37 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1664, average loss: 1.0370
[09/26 02:38:37 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 76.50	top5: 94.50	
[09/26 02:38:37 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.07597595192178702
[09/26 02:38:43 visual_prompt]: Epoch 85 / 100: avg data time: 5.71e-02, avg batch time: 0.4985, average train loss: 0.0327
[09/26 02:38:45 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1664, average loss: 1.0498
[09/26 02:38:45 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 76.00	top5: 94.50	
[09/26 02:38:45 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.06698729810778065
[09/26 02:38:52 visual_prompt]: Epoch 86 / 100: avg data time: 4.96e-02, avg batch time: 0.4923, average train loss: 0.0325
[09/26 02:38:53 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1664, average loss: 1.0480
[09/26 02:38:53 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 74.50	top5: 93.50	
[09/26 02:38:53 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.058526203570536506
[09/26 02:39:00 visual_prompt]: Epoch 87 / 100: avg data time: 4.68e-02, avg batch time: 0.4905, average train loss: 0.0324
[09/26 02:39:01 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1664, average loss: 1.0567
[09/26 02:39:01 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 74.00	top5: 94.00	
[09/26 02:39:01 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.05060297685041659
[09/26 02:39:08 visual_prompt]: Epoch 88 / 100: avg data time: 4.45e-02, avg batch time: 0.4886, average train loss: 0.0319
[09/26 02:39:10 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1662, average loss: 1.0492
[09/26 02:39:10 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 76.00	top5: 93.50	
[09/26 02:39:10 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.04322727117869951
[09/26 02:39:16 visual_prompt]: Epoch 89 / 100: avg data time: 6.28e-02, avg batch time: 0.5046, average train loss: 0.0319
[09/26 02:39:18 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1664, average loss: 1.0558
[09/26 02:39:18 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 75.00	top5: 93.50	
[09/26 02:39:18 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.03640807271660634
[09/26 02:39:25 visual_prompt]: Epoch 90 / 100: avg data time: 5.65e-02, avg batch time: 0.4978, average train loss: 0.0319
[09/26 02:39:26 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1664, average loss: 1.0691
[09/26 02:39:26 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 75.00	top5: 93.50	
[09/26 02:39:26 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.03015368960704584
[09/26 02:39:33 visual_prompt]: Epoch 91 / 100: avg data time: 4.83e-02, avg batch time: 0.4912, average train loss: 0.0313
[09/26 02:39:34 visual_prompt]: Inference (val):avg data time: 2.11e-05, avg batch time: 0.1665, average loss: 1.0705
[09/26 02:39:34 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 76.00	top5: 94.00	
[09/26 02:39:34 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.024471741852423234
[09/26 02:39:41 visual_prompt]: Epoch 92 / 100: avg data time: 5.59e-02, avg batch time: 0.4975, average train loss: 0.0315
[09/26 02:39:42 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1665, average loss: 1.0614
[09/26 02:39:42 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 76.00	top5: 94.00	
[09/26 02:39:42 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.019369152030840553
[09/26 02:39:49 visual_prompt]: Epoch 93 / 100: avg data time: 5.31e-02, avg batch time: 0.4949, average train loss: 0.0315
[09/26 02:39:51 visual_prompt]: Inference (val):avg data time: 2.01e-05, avg batch time: 0.1663, average loss: 1.0637
[09/26 02:39:51 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 76.00	top5: 94.00	
[09/26 02:39:51 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.014852136862001764
[09/26 02:39:57 visual_prompt]: Epoch 94 / 100: avg data time: 5.20e-02, avg batch time: 0.4938, average train loss: 0.0312
[09/26 02:39:59 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1663, average loss: 1.0647
[09/26 02:39:59 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 76.00	top5: 94.00	
[09/26 02:39:59 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.010926199633097156
[09/26 02:40:06 visual_prompt]: Epoch 95 / 100: avg data time: 5.38e-02, avg batch time: 0.4973, average train loss: 0.0314
[09/26 02:40:07 visual_prompt]: Inference (val):avg data time: 1.97e-05, avg batch time: 0.1663, average loss: 1.0617
[09/26 02:40:07 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 76.50	top5: 94.00	
[09/26 02:40:07 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.00759612349389599
[09/26 02:40:14 visual_prompt]: Epoch 96 / 100: avg data time: 4.79e-02, avg batch time: 0.4904, average train loss: 0.0313
[09/26 02:40:15 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1664, average loss: 1.0620
[09/26 02:40:15 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 76.00	top5: 94.00	
[09/26 02:40:15 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.004865965629214819
[09/26 02:40:22 visual_prompt]: Epoch 97 / 100: avg data time: 5.79e-02, avg batch time: 0.5007, average train loss: 0.0312
[09/26 02:40:24 visual_prompt]: Inference (val):avg data time: 1.94e-05, avg batch time: 0.1662, average loss: 1.0630
[09/26 02:40:24 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 75.50	top5: 94.00	
[09/26 02:40:24 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.002739052315863355
[09/26 02:40:30 visual_prompt]: Epoch 98 / 100: avg data time: 4.30e-02, avg batch time: 0.4858, average train loss: 0.0311
[09/26 02:40:32 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1663, average loss: 1.0631
[09/26 02:40:32 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 75.50	top5: 94.00	
[09/26 02:40:32 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.0012179748700879012
[09/26 02:40:38 visual_prompt]: Epoch 99 / 100: avg data time: 4.69e-02, avg batch time: 0.4903, average train loss: 0.0313
[09/26 02:40:40 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1662, average loss: 1.0631
[09/26 02:40:40 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 75.50	top5: 94.00	
[09/26 02:40:40 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.00030458649045211894
[09/26 02:40:47 visual_prompt]: Epoch 100 / 100: avg data time: 5.58e-02, avg batch time: 0.4994, average train loss: 0.0310
[09/26 02:40:48 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1663, average loss: 1.0630
[09/26 02:40:48 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 75.50	top5: 94.00	
[09/26 02:40:48 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 02:40:48 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 02:40:48 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-cifar(num_classes=100)', 'DATA.NUMBER_CLASSES', '100', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 02:40:48 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 02:40:48 visual_prompt]: Training with config:
[09/26 02:40:48 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-cifar(num_classes=100)/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr1.0_wd0.0001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 1.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-cifar(num_classes=100)', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 100, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 02:40:48 visual_prompt]: Loading training data...
[09/26 02:40:48 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[:800], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/26 02:40:49 visual_prompt]: Number of images: 800
[09/26 02:40:49 visual_prompt]: Number of classes: 100 / 100
[09/26 02:40:49 visual_prompt]: Loading validation data...
[09/26 02:40:49 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[45000:45200], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/26 02:40:49 visual_prompt]: Number of images: 200
[09/26 02:40:49 visual_prompt]: Number of classes: 90 / 100
[09/26 02:40:49 visual_prompt]: Constructing models...
[09/26 02:40:52 visual_prompt]: Total Parameters: 86336356	 Gradient Parameters: 537700
[09/26 02:40:52 visual_prompt]: tuned percent:0.623
[09/26 02:40:52 visual_prompt]: Device used for model: 0
[09/26 02:40:52 visual_prompt]: Setting up Evaluator...
[09/26 02:40:52 visual_prompt]: Setting up Trainer...
[09/26 02:40:52 visual_prompt]: 	Setting up the optimizer...
[09/26 02:40:52 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 02:40:59 visual_prompt]: Epoch 1 / 100: avg data time: 5.24e-02, avg batch time: 0.4933, average train loss: 4.6551
[09/26 02:41:00 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1659, average loss: 4.6218
[09/26 02:41:00 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 7.00	
[09/26 02:41:00 visual_prompt]: Best epoch 1: best metric: 0.010
[09/26 02:41:00 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.1
[09/26 02:41:07 visual_prompt]: Epoch 2 / 100: avg data time: 4.46e-02, avg batch time: 0.4878, average train loss: 4.6245
[09/26 02:41:08 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1661, average loss: 4.6217
[09/26 02:41:08 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.50	
[09/26 02:41:08 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.2
[09/26 02:41:15 visual_prompt]: Epoch 3 / 100: avg data time: 5.56e-02, avg batch time: 0.4963, average train loss: 4.5726
[09/26 02:41:17 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1662, average loss: 4.5868
[09/26 02:41:17 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 7.50	
[09/26 02:41:17 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.3
[09/26 02:41:23 visual_prompt]: Epoch 4 / 100: avg data time: 5.36e-02, avg batch time: 0.4952, average train loss: 4.4540
[09/26 02:41:25 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1663, average loss: 4.4751
[09/26 02:41:25 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 3.00	top5: 12.50	
[09/26 02:41:25 visual_prompt]: Best epoch 4: best metric: 0.030
[09/26 02:41:25 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.4
[09/26 02:41:32 visual_prompt]: Epoch 5 / 100: avg data time: 5.61e-02, avg batch time: 0.4976, average train loss: 4.1356
[09/26 02:41:33 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1661, average loss: 4.5775
[09/26 02:41:33 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 4.00	top5: 17.50	
[09/26 02:41:33 visual_prompt]: Best epoch 5: best metric: 0.040
[09/26 02:41:33 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.5
[09/26 02:41:40 visual_prompt]: Epoch 6 / 100: avg data time: 5.27e-02, avg batch time: 0.4946, average train loss: 4.1842
[09/26 02:41:41 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1662, average loss: 3.9428
[09/26 02:41:41 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 8.00	top5: 28.50	
[09/26 02:41:41 visual_prompt]: Best epoch 6: best metric: 0.080
[09/26 02:41:41 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.6
[09/26 02:41:48 visual_prompt]: Epoch 7 / 100: avg data time: 5.18e-02, avg batch time: 0.4936, average train loss: 3.1916
[09/26 02:41:49 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1662, average loss: 3.0102
[09/26 02:41:49 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 21.50	top5: 58.00	
[09/26 02:41:49 visual_prompt]: Best epoch 7: best metric: 0.215
[09/26 02:41:49 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.7
[09/26 02:41:56 visual_prompt]: Epoch 8 / 100: avg data time: 4.58e-02, avg batch time: 0.4882, average train loss: 1.9677
[09/26 02:41:58 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1661, average loss: 1.8120
[09/26 02:41:58 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 48.00	top5: 81.00	
[09/26 02:41:58 visual_prompt]: Best epoch 8: best metric: 0.480
[09/26 02:41:58 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.8
[09/26 02:42:04 visual_prompt]: Epoch 9 / 100: avg data time: 6.05e-02, avg batch time: 0.5016, average train loss: 2.1772
[09/26 02:42:06 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1662, average loss: 2.7699
[09/26 02:42:06 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 32.00	top5: 63.50	
[09/26 02:42:06 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.9
[09/26 02:42:13 visual_prompt]: Epoch 10 / 100: avg data time: 5.73e-02, avg batch time: 0.4982, average train loss: 1.0756
[09/26 02:42:14 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1662, average loss: 1.9411
[09/26 02:42:14 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 44.50	top5: 82.00	
[09/26 02:42:14 visual_prompt]: Training 11 / 100 epoch, with learning rate 1.0
[09/26 02:42:21 visual_prompt]: Epoch 11 / 100: avg data time: 5.41e-02, avg batch time: 0.4954, average train loss: 0.3279
[09/26 02:42:22 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1662, average loss: 1.3541
[09/26 02:42:22 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.50	top5: 90.50	
[09/26 02:42:22 visual_prompt]: Best epoch 11: best metric: 0.635
[09/26 02:42:22 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.9996954135095479
[09/26 02:42:29 visual_prompt]: Epoch 12 / 100: avg data time: 5.42e-02, avg batch time: 0.4961, average train loss: 0.1026
[09/26 02:42:31 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1663, average loss: 1.2935
[09/26 02:42:31 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.00	top5: 91.00	
[09/26 02:42:31 visual_prompt]: Best epoch 12: best metric: 0.670
[09/26 02:42:31 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.9987820251299121
[09/26 02:42:37 visual_prompt]: Epoch 13 / 100: avg data time: 5.64e-02, avg batch time: 0.4996, average train loss: 0.0452
[09/26 02:42:39 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1663, average loss: 1.2209
[09/26 02:42:39 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 68.50	top5: 92.00	
[09/26 02:42:39 visual_prompt]: Best epoch 13: best metric: 0.685
[09/26 02:42:39 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.9972609476841366
[09/26 02:42:46 visual_prompt]: Epoch 14 / 100: avg data time: 5.78e-02, avg batch time: 0.4992, average train loss: 0.0205
[09/26 02:42:47 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1663, average loss: 1.2498
[09/26 02:42:47 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 68.50	top5: 89.50	
[09/26 02:42:47 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.9951340343707852
[09/26 02:42:54 visual_prompt]: Epoch 15 / 100: avg data time: 5.82e-02, avg batch time: 0.4993, average train loss: 0.0137
[09/26 02:42:55 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1663, average loss: 1.1851
[09/26 02:42:55 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 71.00	top5: 91.50	
[09/26 02:42:55 visual_prompt]: Best epoch 15: best metric: 0.710
[09/26 02:42:55 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.9924038765061041
[09/26 02:43:02 visual_prompt]: Epoch 16 / 100: avg data time: 5.53e-02, avg batch time: 0.4963, average train loss: 0.0111
[09/26 02:43:04 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1665, average loss: 1.1697
[09/26 02:43:04 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 71.50	top5: 92.50	
[09/26 02:43:04 visual_prompt]: Best epoch 16: best metric: 0.715
[09/26 02:43:04 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.9890738003669028
[09/26 02:43:10 visual_prompt]: Epoch 17 / 100: avg data time: 4.75e-02, avg batch time: 0.4919, average train loss: 0.0094
[09/26 02:43:12 visual_prompt]: Inference (val):avg data time: 1.92e-05, avg batch time: 0.1662, average loss: 1.1844
[09/26 02:43:12 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 71.50	top5: 91.00	
[09/26 02:43:12 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.9851478631379982
[09/26 02:43:19 visual_prompt]: Epoch 18 / 100: avg data time: 6.00e-02, avg batch time: 0.5012, average train loss: 0.0083
[09/26 02:43:20 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1663, average loss: 1.1653
[09/26 02:43:20 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 72.00	top5: 91.50	
[09/26 02:43:20 visual_prompt]: Best epoch 18: best metric: 0.720
[09/26 02:43:20 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.9806308479691594
[09/26 02:43:27 visual_prompt]: Epoch 19 / 100: avg data time: 4.85e-02, avg batch time: 0.4925, average train loss: 0.0081
[09/26 02:43:28 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1660, average loss: 1.1500
[09/26 02:43:28 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 72.00	top5: 92.00	
[09/26 02:43:28 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.9755282581475768
[09/26 02:43:35 visual_prompt]: Epoch 20 / 100: avg data time: 4.86e-02, avg batch time: 0.4900, average train loss: 0.0077
[09/26 02:43:37 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1664, average loss: 1.1442
[09/26 02:43:37 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 71.50	top5: 92.00	
[09/26 02:43:37 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.9698463103929542
[09/26 02:43:43 visual_prompt]: Epoch 21 / 100: avg data time: 4.50e-02, avg batch time: 0.4884, average train loss: 0.0079
[09/26 02:43:45 visual_prompt]: Inference (val):avg data time: 1.97e-05, avg batch time: 0.1662, average loss: 1.1435
[09/26 02:43:45 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 72.00	top5: 92.00	
[09/26 02:43:45 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.9635919272833937
[09/26 02:43:52 visual_prompt]: Epoch 22 / 100: avg data time: 6.40e-02, avg batch time: 0.5056, average train loss: 0.0077
[09/26 02:43:53 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1661, average loss: 1.1326
[09/26 02:43:53 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 71.50	top5: 92.50	
[09/26 02:43:53 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.9567727288213004
[09/26 02:44:00 visual_prompt]: Epoch 23 / 100: avg data time: 5.72e-02, avg batch time: 0.4991, average train loss: 0.0073
[09/26 02:44:02 visual_prompt]: Inference (val):avg data time: 1.94e-05, avg batch time: 0.1664, average loss: 1.1445
[09/26 02:44:02 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 71.00	top5: 92.50	
[09/26 02:44:02 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.9493970231495835
[09/26 02:44:08 visual_prompt]: Epoch 24 / 100: avg data time: 5.82e-02, avg batch time: 0.5022, average train loss: 0.0072
[09/26 02:44:10 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1663, average loss: 1.1442
[09/26 02:44:10 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 70.00	top5: 92.50	
[09/26 02:44:10 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.9414737964294635
[09/26 02:44:17 visual_prompt]: Epoch 25 / 100: avg data time: 5.59e-02, avg batch time: 0.4976, average train loss: 0.0071
[09/26 02:44:18 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1662, average loss: 1.1289
[09/26 02:44:18 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 71.00	top5: 91.50	
[09/26 02:44:18 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.9330127018922194
[09/26 02:44:25 visual_prompt]: Epoch 26 / 100: avg data time: 5.32e-02, avg batch time: 0.4965, average train loss: 0.0070
[09/26 02:44:26 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1663, average loss: 1.1295
[09/26 02:44:26 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 71.00	top5: 92.50	
[09/26 02:44:26 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.9240240480782129
[09/26 02:44:33 visual_prompt]: Epoch 27 / 100: avg data time: 4.25e-02, avg batch time: 0.4846, average train loss: 0.0069
[09/26 02:44:34 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1663, average loss: 1.1237
[09/26 02:44:34 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 71.00	top5: 92.50	
[09/26 02:44:34 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.9145187862775208
[09/26 02:44:41 visual_prompt]: Epoch 28 / 100: avg data time: 4.81e-02, avg batch time: 0.4921, average train loss: 0.0071
[09/26 02:44:43 visual_prompt]: Inference (val):avg data time: 1.98e-05, avg batch time: 0.1664, average loss: 1.1158
[09/26 02:44:43 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 71.00	top5: 92.50	
[09/26 02:44:43 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.9045084971874737
[09/26 02:44:49 visual_prompt]: Epoch 29 / 100: avg data time: 5.86e-02, avg batch time: 0.5010, average train loss: 0.0071
[09/26 02:44:51 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1664, average loss: 1.1147
[09/26 02:44:51 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 71.50	top5: 92.50	
[09/26 02:44:51 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.8940053768033609
[09/26 02:44:58 visual_prompt]: Epoch 30 / 100: avg data time: 5.63e-02, avg batch time: 0.4981, average train loss: 0.0071
[09/26 02:44:59 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1659, average loss: 1.1046
[09/26 02:44:59 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 71.50	top5: 92.50	
[09/26 02:44:59 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.883022221559489
[09/26 02:45:06 visual_prompt]: Epoch 31 / 100: avg data time: 5.72e-02, avg batch time: 0.4995, average train loss: 0.0072
[09/26 02:45:07 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1664, average loss: 1.0997
[09/26 02:45:07 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 71.00	top5: 93.00	
[09/26 02:45:07 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.8715724127386971
[09/26 02:45:14 visual_prompt]: Epoch 32 / 100: avg data time: 6.07e-02, avg batch time: 0.5029, average train loss: 0.0070
[09/26 02:45:16 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1662, average loss: 1.1036
[09/26 02:45:16 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 71.00	top5: 92.50	
[09/26 02:45:16 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.8596699001693255
[09/26 02:45:22 visual_prompt]: Epoch 33 / 100: avg data time: 4.52e-02, avg batch time: 0.4875, average train loss: 0.0069
[09/26 02:45:24 visual_prompt]: Inference (val):avg data time: 1.94e-05, avg batch time: 0.1663, average loss: 1.1029
[09/26 02:45:24 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 71.00	top5: 92.50	
[09/26 02:45:24 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.8473291852294986
[09/26 02:45:31 visual_prompt]: Epoch 34 / 100: avg data time: 5.55e-02, avg batch time: 0.4982, average train loss: 0.0070
[09/26 02:45:32 visual_prompt]: Inference (val):avg data time: 1.98e-05, avg batch time: 0.1665, average loss: 1.1038
[09/26 02:45:32 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 71.50	top5: 92.50	
[09/26 02:45:32 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.8345653031794291
[09/26 02:45:39 visual_prompt]: Epoch 35 / 100: avg data time: 4.39e-02, avg batch time: 0.4877, average train loss: 0.0069
[09/26 02:45:40 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1666, average loss: 1.0910
[09/26 02:45:40 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 72.00	top5: 92.50	
[09/26 02:45:40 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.8213938048432696
[09/26 02:45:47 visual_prompt]: Epoch 36 / 100: avg data time: 6.68e-02, avg batch time: 0.5086, average train loss: 0.0068
[09/26 02:45:49 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1665, average loss: 1.0958
[09/26 02:45:49 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 71.50	top5: 92.00	
[09/26 02:45:49 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.8078307376628291
[09/26 02:45:55 visual_prompt]: Epoch 37 / 100: avg data time: 6.17e-02, avg batch time: 0.5042, average train loss: 0.0068
[09/26 02:45:57 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1662, average loss: 1.0969
[09/26 02:45:57 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 72.00	top5: 92.50	
[09/26 02:45:57 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.7938926261462366
[09/26 02:46:04 visual_prompt]: Epoch 38 / 100: avg data time: 5.88e-02, avg batch time: 0.5019, average train loss: 0.0068
[09/26 02:46:05 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1663, average loss: 1.0857
[09/26 02:46:05 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 72.50	top5: 92.00	
[09/26 02:46:05 visual_prompt]: Best epoch 38: best metric: 0.725
[09/26 02:46:05 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.7795964517353734
[09/26 02:46:12 visual_prompt]: Epoch 39 / 100: avg data time: 5.80e-02, avg batch time: 0.5000, average train loss: 0.0067
[09/26 02:46:14 visual_prompt]: Inference (val):avg data time: 1.99e-05, avg batch time: 0.1663, average loss: 1.0872
[09/26 02:46:14 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 72.00	top5: 93.00	
[09/26 02:46:14 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.7649596321166025
[09/26 02:46:20 visual_prompt]: Epoch 40 / 100: avg data time: 4.91e-02, avg batch time: 0.4914, average train loss: 0.0067
[09/26 02:46:22 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1661, average loss: 1.0937
[09/26 02:46:22 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 72.50	top5: 93.00	
[09/26 02:46:22 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.75
[09/26 02:46:29 visual_prompt]: Epoch 41 / 100: avg data time: 5.55e-02, avg batch time: 0.4974, average train loss: 0.0068
[09/26 02:46:30 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1665, average loss: 1.0964
[09/26 02:46:30 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 71.00	top5: 92.50	
[09/26 02:46:30 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.7347357813929454
[09/26 02:46:37 visual_prompt]: Epoch 42 / 100: avg data time: 6.44e-02, avg batch time: 0.5057, average train loss: 0.0068
[09/26 02:46:38 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1664, average loss: 1.0883
[09/26 02:46:38 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 71.00	top5: 93.00	
[09/26 02:46:38 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.7191855733945387
[09/26 02:46:45 visual_prompt]: Epoch 43 / 100: avg data time: 5.37e-02, avg batch time: 0.4967, average train loss: 0.0068
[09/26 02:46:47 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1662, average loss: 1.0912
[09/26 02:46:47 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 73.00	top5: 92.50	
[09/26 02:46:47 visual_prompt]: Best epoch 43: best metric: 0.730
[09/26 02:46:47 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.7033683215379002
[09/26 02:46:53 visual_prompt]: Epoch 44 / 100: avg data time: 6.14e-02, avg batch time: 0.5032, average train loss: 0.0065
[09/26 02:46:55 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1660, average loss: 1.0908
[09/26 02:46:55 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 71.00	top5: 93.00	
[09/26 02:46:55 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.6873032967079561
[09/26 02:47:02 visual_prompt]: Epoch 45 / 100: avg data time: 6.59e-02, avg batch time: 0.5071, average train loss: 0.0067
[09/26 02:47:03 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.1664, average loss: 1.0958
[09/26 02:47:03 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 70.50	top5: 93.00	
[09/26 02:47:03 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.6710100716628344
[09/26 02:47:10 visual_prompt]: Epoch 46 / 100: avg data time: 5.90e-02, avg batch time: 0.5004, average train loss: 0.0067
[09/26 02:47:12 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1663, average loss: 1.0892
[09/26 02:47:12 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 71.00	top5: 93.00	
[09/26 02:47:12 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.6545084971874737
[09/26 02:47:18 visual_prompt]: Epoch 47 / 100: avg data time: 5.43e-02, avg batch time: 0.4961, average train loss: 0.0065
[09/26 02:47:20 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1662, average loss: 1.0884
[09/26 02:47:20 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 71.00	top5: 93.00	
[09/26 02:47:20 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.6378186779084996
[09/26 02:47:27 visual_prompt]: Epoch 48 / 100: avg data time: 5.85e-02, avg batch time: 0.5009, average train loss: 0.0064
[09/26 02:47:28 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1662, average loss: 1.0876
[09/26 02:47:28 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 70.00	top5: 93.00	
[09/26 02:47:28 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.6209609477998338
[09/26 02:47:35 visual_prompt]: Epoch 49 / 100: avg data time: 5.45e-02, avg batch time: 0.4983, average train loss: 0.0066
[09/26 02:47:36 visual_prompt]: Inference (val):avg data time: 1.93e-05, avg batch time: 0.1662, average loss: 1.0910
[09/26 02:47:36 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 70.50	top5: 93.00	
[09/26 02:47:36 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.6039558454088796
[09/26 02:47:43 visual_prompt]: Epoch 50 / 100: avg data time: 5.75e-02, avg batch time: 0.4995, average train loss: 0.0065
[09/26 02:47:45 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1664, average loss: 1.0771
[09/26 02:47:45 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 70.50	top5: 93.00	
[09/26 02:47:45 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.5868240888334653
[09/26 02:47:52 visual_prompt]: Epoch 51 / 100: avg data time: 6.70e-02, avg batch time: 0.5084, average train loss: 0.0064
[09/26 02:47:53 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1662, average loss: 1.0940
[09/26 02:47:53 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 68.50	top5: 92.00	
[09/26 02:47:53 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.5695865504800327
[09/26 02:48:00 visual_prompt]: Epoch 52 / 100: avg data time: 5.69e-02, avg batch time: 0.4992, average train loss: 0.0066
[09/26 02:48:01 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1662, average loss: 1.0896
[09/26 02:48:01 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 70.50	top5: 93.00	
[09/26 02:48:01 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.5522642316338268
[09/26 02:48:08 visual_prompt]: Epoch 53 / 100: avg data time: 4.82e-02, avg batch time: 0.4911, average train loss: 0.0067
[09/26 02:48:09 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1664, average loss: 1.0837
[09/26 02:48:09 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 70.50	top5: 93.00	
[09/26 02:48:09 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.5348782368720626
[09/26 02:48:16 visual_prompt]: Epoch 54 / 100: avg data time: 5.91e-02, avg batch time: 0.5007, average train loss: 0.0065
[09/26 02:48:18 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1663, average loss: 1.0858
[09/26 02:48:18 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 69.00	top5: 93.50	
[09/26 02:48:18 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.5174497483512506
[09/26 02:48:25 visual_prompt]: Epoch 55 / 100: avg data time: 6.56e-02, avg batch time: 0.5073, average train loss: 0.0064
[09/26 02:48:26 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1662, average loss: 1.0933
[09/26 02:48:26 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 71.00	top5: 93.00	
[09/26 02:48:26 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.5
[09/26 02:48:33 visual_prompt]: Epoch 56 / 100: avg data time: 5.44e-02, avg batch time: 0.4970, average train loss: 0.0065
[09/26 02:48:34 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1661, average loss: 1.0905
[09/26 02:48:34 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 70.50	top5: 93.50	
[09/26 02:48:34 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.48255025164874965
[09/26 02:48:41 visual_prompt]: Epoch 57 / 100: avg data time: 5.02e-02, avg batch time: 0.4924, average train loss: 0.0065
[09/26 02:48:43 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1664, average loss: 1.0878
[09/26 02:48:43 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 71.50	top5: 92.50	
[09/26 02:48:43 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.46512176312793735
[09/26 02:48:49 visual_prompt]: Epoch 58 / 100: avg data time: 5.95e-02, avg batch time: 0.5013, average train loss: 0.0063
[09/26 02:48:51 visual_prompt]: Inference (val):avg data time: 2.05e-05, avg batch time: 0.1662, average loss: 1.0879
[09/26 02:48:51 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 71.50	top5: 92.50	
[09/26 02:48:51 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.44773576836617335
[09/26 02:48:58 visual_prompt]: Epoch 59 / 100: avg data time: 5.26e-02, avg batch time: 0.4953, average train loss: 0.0063
[09/26 02:48:59 visual_prompt]: Inference (val):avg data time: 1.98e-05, avg batch time: 0.1663, average loss: 1.0833
[09/26 02:48:59 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 70.50	top5: 93.00	
[09/26 02:48:59 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.4304134495199674
[09/26 02:49:06 visual_prompt]: Epoch 60 / 100: avg data time: 5.43e-02, avg batch time: 0.4971, average train loss: 0.0063
[09/26 02:49:07 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1663, average loss: 1.0863
[09/26 02:49:07 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 71.00	top5: 93.00	
[09/26 02:49:07 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.41317591116653485
[09/26 02:49:14 visual_prompt]: Epoch 61 / 100: avg data time: 5.70e-02, avg batch time: 0.4997, average train loss: 0.0063
[09/26 02:49:16 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1663, average loss: 1.0930
[09/26 02:49:16 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 71.50	top5: 93.00	
[09/26 02:49:16 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.3960441545911204
[09/26 02:49:22 visual_prompt]: Epoch 62 / 100: avg data time: 5.27e-02, avg batch time: 0.4955, average train loss: 0.0064
[09/26 02:49:24 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1663, average loss: 1.0838
[09/26 02:49:24 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 72.00	top5: 93.00	
[09/26 02:49:24 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.3790390522001662
[09/26 02:49:31 visual_prompt]: Epoch 63 / 100: avg data time: 5.80e-02, avg batch time: 0.5004, average train loss: 0.0064
[09/26 02:49:32 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1665, average loss: 1.0747
[09/26 02:49:32 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 72.00	top5: 93.00	
[09/26 02:49:32 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.36218132209150045
[09/26 02:49:39 visual_prompt]: Epoch 64 / 100: avg data time: 6.09e-02, avg batch time: 0.5033, average train loss: 0.0064
[09/26 02:49:40 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1663, average loss: 1.0837
[09/26 02:49:40 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 71.50	top5: 93.00	
[09/26 02:49:40 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.34549150281252633
[09/26 02:49:47 visual_prompt]: Epoch 65 / 100: avg data time: 5.44e-02, avg batch time: 0.4972, average train loss: 0.0062
[09/26 02:49:49 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1664, average loss: 1.0896
[09/26 02:49:49 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 71.00	top5: 93.00	
[09/26 02:49:49 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.32898992833716567
[09/26 02:49:55 visual_prompt]: Epoch 66 / 100: avg data time: 5.51e-02, avg batch time: 0.4976, average train loss: 0.0063
[09/26 02:49:57 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1663, average loss: 1.0844
[09/26 02:49:57 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 71.00	top5: 93.00	
[09/26 02:49:57 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.31269670329204396
[09/26 02:50:04 visual_prompt]: Epoch 67 / 100: avg data time: 5.94e-02, avg batch time: 0.5014, average train loss: 0.0062
[09/26 02:50:05 visual_prompt]: Inference (val):avg data time: 1.95e-05, avg batch time: 0.1661, average loss: 1.0771
[09/26 02:50:05 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 72.00	top5: 93.50	
[09/26 02:50:05 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.2966316784621
[09/26 02:50:12 visual_prompt]: Epoch 68 / 100: avg data time: 5.93e-02, avg batch time: 0.5017, average train loss: 0.0061
[09/26 02:50:14 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1664, average loss: 1.0870
[09/26 02:50:14 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 71.50	top5: 93.50	
[09/26 02:50:14 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.28081442660546124
[09/26 02:50:20 visual_prompt]: Epoch 69 / 100: avg data time: 5.71e-02, avg batch time: 0.4996, average train loss: 0.0063
[09/26 02:50:22 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1662, average loss: 1.0761
[09/26 02:50:22 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 73.00	top5: 93.50	
[09/26 02:50:22 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.26526421860705474
[09/26 02:50:29 visual_prompt]: Epoch 70 / 100: avg data time: 6.07e-02, avg batch time: 0.5036, average train loss: 0.0061
[09/26 02:50:30 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1661, average loss: 1.0742
[09/26 02:50:30 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 72.50	top5: 93.00	
[09/26 02:50:30 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.2500000000000001
[09/26 02:50:37 visual_prompt]: Epoch 71 / 100: avg data time: 5.41e-02, avg batch time: 0.4965, average train loss: 0.0062
[09/26 02:50:38 visual_prompt]: Inference (val):avg data time: 3.67e-05, avg batch time: 0.1664, average loss: 1.0821
[09/26 02:50:38 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 72.50	top5: 93.00	
[09/26 02:50:38 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.2350403678833976
[09/26 02:50:45 visual_prompt]: Epoch 72 / 100: avg data time: 4.50e-02, avg batch time: 0.4875, average train loss: 0.0061
[09/26 02:50:46 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1662, average loss: 1.0870
[09/26 02:50:46 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 71.50	top5: 93.50	
[09/26 02:50:46 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.22040354826462666
[09/26 02:50:53 visual_prompt]: Epoch 73 / 100: avg data time: 5.91e-02, avg batch time: 0.5013, average train loss: 0.0062
[09/26 02:50:55 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1663, average loss: 1.0871
[09/26 02:50:55 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 71.50	top5: 93.50	
[09/26 02:50:55 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.2061073738537635
[09/26 02:51:02 visual_prompt]: Epoch 74 / 100: avg data time: 5.61e-02, avg batch time: 0.4985, average train loss: 0.0062
[09/26 02:51:03 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1663, average loss: 1.0831
[09/26 02:51:03 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 73.00	top5: 93.50	
[09/26 02:51:03 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.19216926233717085
[09/26 02:51:10 visual_prompt]: Epoch 75 / 100: avg data time: 5.55e-02, avg batch time: 0.4967, average train loss: 0.0062
[09/26 02:51:11 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1663, average loss: 1.0790
[09/26 02:51:11 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 72.50	top5: 93.50	
[09/26 02:51:11 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.17860619515673032
[09/26 02:51:18 visual_prompt]: Epoch 76 / 100: avg data time: 6.15e-02, avg batch time: 0.5031, average train loss: 0.0060
[09/26 02:51:20 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1662, average loss: 1.0777
[09/26 02:51:20 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 72.50	top5: 93.50	
[09/26 02:51:20 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.16543469682057105
[09/26 02:51:26 visual_prompt]: Epoch 77 / 100: avg data time: 4.96e-02, avg batch time: 0.4912, average train loss: 0.0061
[09/26 02:51:28 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1661, average loss: 1.0806
[09/26 02:51:28 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 72.00	top5: 93.50	
[09/26 02:51:28 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.15267081477050132
[09/26 02:51:34 visual_prompt]: Epoch 78 / 100: avg data time: 5.77e-02, avg batch time: 0.4992, average train loss: 0.0060
[09/26 02:51:36 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1663, average loss: 1.0756
[09/26 02:51:36 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 72.00	top5: 93.50	
[09/26 02:51:36 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.14033009983067452
[09/26 02:51:43 visual_prompt]: Epoch 79 / 100: avg data time: 5.67e-02, avg batch time: 0.4991, average train loss: 0.0060
[09/26 02:51:44 visual_prompt]: Inference (val):avg data time: 2.11e-05, avg batch time: 0.1661, average loss: 1.0759
[09/26 02:51:44 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 73.00	top5: 93.50	
[09/26 02:51:44 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.12842758726130282
[09/26 02:51:51 visual_prompt]: Epoch 80 / 100: avg data time: 6.21e-02, avg batch time: 0.5034, average train loss: 0.0060
[09/26 02:51:53 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1662, average loss: 1.0760
[09/26 02:51:53 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 73.00	top5: 93.50	
[09/26 02:51:53 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.11697777844051105
[09/26 02:51:59 visual_prompt]: Epoch 81 / 100: avg data time: 6.04e-02, avg batch time: 0.5034, average train loss: 0.0060
[09/26 02:52:01 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1661, average loss: 1.0744
[09/26 02:52:01 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 72.50	top5: 93.50	
[09/26 02:52:01 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.10599462319663905
[09/26 02:52:08 visual_prompt]: Epoch 82 / 100: avg data time: 5.32e-02, avg batch time: 0.4948, average train loss: 0.0060
[09/26 02:52:09 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1661, average loss: 1.0730
[09/26 02:52:09 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 72.00	top5: 93.50	
[09/26 02:52:09 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.09549150281252633
[09/26 02:52:16 visual_prompt]: Epoch 83 / 100: avg data time: 5.71e-02, avg batch time: 0.4991, average train loss: 0.0060
[09/26 02:52:17 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1660, average loss: 1.0734
[09/26 02:52:17 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 72.00	top5: 93.50	
[09/26 02:52:17 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.08548121372247919
[09/26 02:52:24 visual_prompt]: Epoch 84 / 100: avg data time: 5.77e-02, avg batch time: 0.4988, average train loss: 0.0059
[09/26 02:52:26 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1661, average loss: 1.0725
[09/26 02:52:26 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 73.00	top5: 93.50	
[09/26 02:52:26 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.07597595192178702
[09/26 02:52:32 visual_prompt]: Epoch 85 / 100: avg data time: 5.91e-02, avg batch time: 0.5010, average train loss: 0.0060
[09/26 02:52:34 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.1662, average loss: 1.0724
[09/26 02:52:34 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 73.00	top5: 93.50	
[09/26 02:52:34 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.06698729810778065
[09/26 02:52:41 visual_prompt]: Epoch 86 / 100: avg data time: 6.09e-02, avg batch time: 0.5027, average train loss: 0.0062
[09/26 02:52:42 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1662, average loss: 1.0737
[09/26 02:52:42 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 73.00	top5: 93.50	
[09/26 02:52:42 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.058526203570536506
[09/26 02:52:49 visual_prompt]: Epoch 87 / 100: avg data time: 6.19e-02, avg batch time: 0.5030, average train loss: 0.0060
[09/26 02:52:51 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1660, average loss: 1.0727
[09/26 02:52:51 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 73.00	top5: 93.50	
[09/26 02:52:51 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.05060297685041659
[09/26 02:52:57 visual_prompt]: Epoch 88 / 100: avg data time: 5.34e-02, avg batch time: 0.4964, average train loss: 0.0060
[09/26 02:52:59 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1660, average loss: 1.0725
[09/26 02:52:59 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 73.00	top5: 93.50	
[09/26 02:52:59 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.04322727117869951
[09/26 02:53:06 visual_prompt]: Epoch 89 / 100: avg data time: 6.44e-02, avg batch time: 0.5055, average train loss: 0.0061
[09/26 02:53:07 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1662, average loss: 1.0730
[09/26 02:53:07 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 73.00	top5: 93.50	
[09/26 02:53:07 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.03640807271660634
[09/26 02:53:14 visual_prompt]: Epoch 90 / 100: avg data time: 4.85e-02, avg batch time: 0.4903, average train loss: 0.0061
[09/26 02:53:15 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1660, average loss: 1.0744
[09/26 02:53:15 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 72.50	top5: 93.50	
[09/26 02:53:15 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.03015368960704584
[09/26 02:53:22 visual_prompt]: Epoch 91 / 100: avg data time: 4.39e-02, avg batch time: 0.4870, average train loss: 0.0061
[09/26 02:53:24 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1661, average loss: 1.0751
[09/26 02:53:24 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 72.50	top5: 93.50	
[09/26 02:53:24 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.024471741852423234
[09/26 02:53:30 visual_prompt]: Epoch 92 / 100: avg data time: 5.71e-02, avg batch time: 0.4987, average train loss: 0.0060
[09/26 02:53:32 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1664, average loss: 1.0748
[09/26 02:53:32 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 72.50	top5: 93.50	
[09/26 02:53:32 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.019369152030840553
[09/26 02:53:38 visual_prompt]: Epoch 93 / 100: avg data time: 4.23e-02, avg batch time: 0.4847, average train loss: 0.0060
[09/26 02:53:40 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1663, average loss: 1.0759
[09/26 02:53:40 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 72.50	top5: 93.50	
[09/26 02:53:40 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.014852136862001764
[09/26 02:53:47 visual_prompt]: Epoch 94 / 100: avg data time: 5.91e-02, avg batch time: 0.5001, average train loss: 0.0060
[09/26 02:53:48 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1661, average loss: 1.0761
[09/26 02:53:48 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 72.50	top5: 93.50	
[09/26 02:53:48 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.010926199633097156
[09/26 02:53:55 visual_prompt]: Epoch 95 / 100: avg data time: 4.62e-02, avg batch time: 0.4890, average train loss: 0.0061
[09/26 02:53:57 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1662, average loss: 1.0760
[09/26 02:53:57 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 72.50	top5: 93.50	
[09/26 02:53:57 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.00759612349389599
[09/26 02:54:03 visual_prompt]: Epoch 96 / 100: avg data time: 5.40e-02, avg batch time: 0.4950, average train loss: 0.0059
[09/26 02:54:05 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1665, average loss: 1.0757
[09/26 02:54:05 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 72.50	top5: 93.50	
[09/26 02:54:05 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.004865965629214819
[09/26 02:54:12 visual_prompt]: Epoch 97 / 100: avg data time: 5.90e-02, avg batch time: 0.5013, average train loss: 0.0059
[09/26 02:54:13 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1663, average loss: 1.0758
[09/26 02:54:13 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 72.50	top5: 93.50	
[09/26 02:54:13 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.002739052315863355
[09/26 02:54:20 visual_prompt]: Epoch 98 / 100: avg data time: 5.65e-02, avg batch time: 0.4993, average train loss: 0.0060
[09/26 02:54:21 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1661, average loss: 1.0759
[09/26 02:54:21 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 72.50	top5: 93.50	
[09/26 02:54:21 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.0012179748700879012
[09/26 02:54:28 visual_prompt]: Epoch 99 / 100: avg data time: 5.69e-02, avg batch time: 0.4981, average train loss: 0.0059
[09/26 02:54:30 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1663, average loss: 1.0759
[09/26 02:54:30 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 72.50	top5: 93.50	
[09/26 02:54:30 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.00030458649045211894
[09/26 02:54:37 visual_prompt]: Epoch 100 / 100: avg data time: 6.32e-02, avg batch time: 0.5041, average train loss: 0.0059
[09/26 02:54:38 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1662, average loss: 1.0759
[09/26 02:54:38 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 72.50	top5: 93.50	
[09/26 02:54:38 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 02:54:38 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 02:54:38 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-cifar(num_classes=100)', 'DATA.NUMBER_CLASSES', '100', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 02:54:38 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 02:54:38 visual_prompt]: Training with config:
[09/26 02:54:38 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-cifar(num_classes=100)/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr1.0_wd0.0/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 1.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-cifar(num_classes=100)', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 100, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 02:54:38 visual_prompt]: Loading training data...
[09/26 02:54:38 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[:800], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/26 02:54:39 visual_prompt]: Number of images: 800
[09/26 02:54:39 visual_prompt]: Number of classes: 100 / 100
[09/26 02:54:39 visual_prompt]: Loading validation data...
[09/26 02:54:39 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[45000:45200], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/26 02:54:39 visual_prompt]: Number of images: 200
[09/26 02:54:39 visual_prompt]: Number of classes: 90 / 100
[09/26 02:54:39 visual_prompt]: Constructing models...
[09/26 02:54:42 visual_prompt]: Total Parameters: 86336356	 Gradient Parameters: 537700
[09/26 02:54:42 visual_prompt]: tuned percent:0.623
[09/26 02:54:42 visual_prompt]: Device used for model: 0
[09/26 02:54:42 visual_prompt]: Setting up Evaluator...
[09/26 02:54:42 visual_prompt]: Setting up Trainer...
[09/26 02:54:42 visual_prompt]: 	Setting up the optimizer...
[09/26 02:54:42 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 02:54:49 visual_prompt]: Epoch 1 / 100: avg data time: 5.80e-02, avg batch time: 0.4989, average train loss: 4.6561
[09/26 02:54:50 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1659, average loss: 4.6218
[09/26 02:54:50 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 7.00	
[09/26 02:54:50 visual_prompt]: Best epoch 1: best metric: 0.010
[09/26 02:54:50 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.1
[09/26 02:54:57 visual_prompt]: Epoch 2 / 100: avg data time: 5.65e-02, avg batch time: 0.4978, average train loss: 4.6350
[09/26 02:54:58 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1657, average loss: 4.6363
[09/26 02:54:58 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/26 02:54:58 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.2
[09/26 02:55:05 visual_prompt]: Epoch 3 / 100: avg data time: 4.94e-02, avg batch time: 0.4918, average train loss: 4.5896
[09/26 02:55:07 visual_prompt]: Inference (val):avg data time: 1.97e-05, avg batch time: 0.1658, average loss: 4.6247
[09/26 02:55:07 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.00	
[09/26 02:55:07 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.3
[09/26 02:55:13 visual_prompt]: Epoch 4 / 100: avg data time: 5.85e-02, avg batch time: 0.4995, average train loss: 4.5745
[09/26 02:55:15 visual_prompt]: Inference (val):avg data time: 4.33e-05, avg batch time: 0.1659, average loss: 4.6024
[09/26 02:55:15 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.50	top5: 9.50	
[09/26 02:55:15 visual_prompt]: Best epoch 4: best metric: 0.025
[09/26 02:55:15 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.4
[09/26 02:55:22 visual_prompt]: Epoch 5 / 100: avg data time: 5.66e-02, avg batch time: 0.4973, average train loss: 4.5432
[09/26 02:55:23 visual_prompt]: Inference (val):avg data time: 1.90e-05, avg batch time: 0.1659, average loss: 4.6305
[09/26 02:55:23 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 5.00	top5: 11.50	
[09/26 02:55:23 visual_prompt]: Best epoch 5: best metric: 0.050
[09/26 02:55:23 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.5
[09/26 02:55:30 visual_prompt]: Epoch 6 / 100: avg data time: 5.38e-02, avg batch time: 0.4965, average train loss: 4.6192
[09/26 02:55:31 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1659, average loss: 4.5987
[09/26 02:55:31 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/26 02:55:31 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.6
[09/26 02:55:38 visual_prompt]: Epoch 7 / 100: avg data time: 6.06e-02, avg batch time: 0.5020, average train loss: 4.5643
[09/26 02:55:40 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1661, average loss: 4.5002
[09/26 02:55:40 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.50	top5: 12.50	
[09/26 02:55:40 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.7
[09/26 02:55:46 visual_prompt]: Epoch 8 / 100: avg data time: 4.92e-02, avg batch time: 0.4909, average train loss: 4.2865
[09/26 02:55:48 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1661, average loss: 4.2098
[09/26 02:55:48 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 5.00	top5: 20.00	
[09/26 02:55:48 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.8
[09/26 02:55:54 visual_prompt]: Epoch 9 / 100: avg data time: 6.04e-02, avg batch time: 0.5018, average train loss: 3.8332
[09/26 02:55:56 visual_prompt]: Inference (val):avg data time: 2.00e-05, avg batch time: 0.1660, average loss: 3.7610
[09/26 02:55:56 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 7.00	top5: 27.50	
[09/26 02:55:56 visual_prompt]: Best epoch 9: best metric: 0.070
[09/26 02:55:56 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.9
[09/26 02:56:03 visual_prompt]: Epoch 10 / 100: avg data time: 5.79e-02, avg batch time: 0.5003, average train loss: 3.4785
[09/26 02:56:04 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1661, average loss: 3.5255
[09/26 02:56:04 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 12.50	top5: 38.50	
[09/26 02:56:04 visual_prompt]: Best epoch 10: best metric: 0.125
[09/26 02:56:04 visual_prompt]: Training 11 / 100 epoch, with learning rate 1.0
[09/26 02:56:11 visual_prompt]: Epoch 11 / 100: avg data time: 5.34e-02, avg batch time: 0.4956, average train loss: 2.7764
[09/26 02:56:12 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1660, average loss: 2.7373
[09/26 02:56:12 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 26.00	top5: 64.50	
[09/26 02:56:12 visual_prompt]: Best epoch 11: best metric: 0.260
[09/26 02:56:12 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.9996954135095479
[09/26 02:56:19 visual_prompt]: Epoch 12 / 100: avg data time: 4.10e-02, avg batch time: 0.4855, average train loss: 1.7474
[09/26 02:56:20 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1661, average loss: 2.1153
[09/26 02:56:20 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 39.50	top5: 78.50	
[09/26 02:56:20 visual_prompt]: Best epoch 12: best metric: 0.395
[09/26 02:56:20 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.9987820251299121
[09/26 02:56:27 visual_prompt]: Epoch 13 / 100: avg data time: 6.03e-02, avg batch time: 0.5040, average train loss: 0.6409
[09/26 02:56:29 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1660, average loss: 1.7140
[09/26 02:56:29 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.00	top5: 87.00	
[09/26 02:56:29 visual_prompt]: Best epoch 13: best metric: 0.540
[09/26 02:56:29 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.9972609476841366
[09/26 02:56:36 visual_prompt]: Epoch 14 / 100: avg data time: 5.71e-02, avg batch time: 0.4981, average train loss: 0.2496
[09/26 02:56:37 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.1662, average loss: 1.4596
[09/26 02:56:37 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.00	top5: 87.00	
[09/26 02:56:37 visual_prompt]: Best epoch 14: best metric: 0.610
[09/26 02:56:37 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.9951340343707852
[09/26 02:56:44 visual_prompt]: Epoch 15 / 100: avg data time: 5.51e-02, avg batch time: 0.4964, average train loss: 0.0964
[09/26 02:56:45 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1661, average loss: 1.2444
[09/26 02:56:45 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 64.50	top5: 90.00	
[09/26 02:56:45 visual_prompt]: Best epoch 15: best metric: 0.645
[09/26 02:56:45 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.9924038765061041
[09/26 02:56:52 visual_prompt]: Epoch 16 / 100: avg data time: 5.19e-02, avg batch time: 0.4940, average train loss: 0.0424
[09/26 02:56:53 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1661, average loss: 1.3395
[09/26 02:56:53 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 64.50	top5: 90.50	
[09/26 02:56:53 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.9890738003669028
[09/26 02:57:00 visual_prompt]: Epoch 17 / 100: avg data time: 5.72e-02, avg batch time: 0.4979, average train loss: 0.0217
[09/26 02:57:02 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1661, average loss: 1.2956
[09/26 02:57:02 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.00	top5: 88.50	
[09/26 02:57:02 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.9851478631379982
[09/26 02:57:08 visual_prompt]: Epoch 18 / 100: avg data time: 5.89e-02, avg batch time: 0.4997, average train loss: 0.0114
[09/26 02:57:10 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1659, average loss: 1.2808
[09/26 02:57:10 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.50	top5: 90.50	
[09/26 02:57:10 visual_prompt]: Best epoch 18: best metric: 0.655
[09/26 02:57:10 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.9806308479691594
[09/26 02:57:17 visual_prompt]: Epoch 19 / 100: avg data time: 4.28e-02, avg batch time: 0.4858, average train loss: 0.0081
[09/26 02:57:18 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1660, average loss: 1.2632
[09/26 02:57:18 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 64.50	top5: 91.00	
[09/26 02:57:18 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.9755282581475768
[09/26 02:57:25 visual_prompt]: Epoch 20 / 100: avg data time: 5.56e-02, avg batch time: 0.4965, average train loss: 0.0067
[09/26 02:57:26 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1661, average loss: 1.2541
[09/26 02:57:26 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.50	top5: 91.00	
[09/26 02:57:26 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.9698463103929542
[09/26 02:57:33 visual_prompt]: Epoch 21 / 100: avg data time: 4.16e-02, avg batch time: 0.4849, average train loss: 0.0060
[09/26 02:57:34 visual_prompt]: Inference (val):avg data time: 2.08e-05, avg batch time: 0.1660, average loss: 1.2508
[09/26 02:57:34 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.00	top5: 91.50	
[09/26 02:57:34 visual_prompt]: Best epoch 21: best metric: 0.660
[09/26 02:57:34 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.9635919272833937
[09/26 02:57:41 visual_prompt]: Epoch 22 / 100: avg data time: 5.44e-02, avg batch time: 0.4952, average train loss: 0.0053
[09/26 02:57:43 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1659, average loss: 1.2502
[09/26 02:57:43 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.00	top5: 91.00	
[09/26 02:57:43 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.9567727288213004
[09/26 02:57:49 visual_prompt]: Epoch 23 / 100: avg data time: 5.67e-02, avg batch time: 0.4986, average train loss: 0.0049
[09/26 02:57:51 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.1660, average loss: 1.2484
[09/26 02:57:51 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.00	top5: 91.50	
[09/26 02:57:51 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.9493970231495835
[09/26 02:57:58 visual_prompt]: Epoch 24 / 100: avg data time: 5.35e-02, avg batch time: 0.4944, average train loss: 0.0045
[09/26 02:57:59 visual_prompt]: Inference (val):avg data time: 2.02e-05, avg batch time: 0.1659, average loss: 1.2440
[09/26 02:57:59 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.00	top5: 91.50	
[09/26 02:57:59 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.9414737964294635
[09/26 02:58:06 visual_prompt]: Epoch 25 / 100: avg data time: 5.45e-02, avg batch time: 0.4956, average train loss: 0.0043
[09/26 02:58:07 visual_prompt]: Inference (val):avg data time: 1.85e-05, avg batch time: 0.1660, average loss: 1.2391
[09/26 02:58:07 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.00	top5: 91.50	
[09/26 02:58:07 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.9330127018922194
[09/26 02:58:14 visual_prompt]: Epoch 26 / 100: avg data time: 5.16e-02, avg batch time: 0.4942, average train loss: 0.0039
[09/26 02:58:16 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1659, average loss: 1.2324
[09/26 02:58:16 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.50	top5: 91.50	
[09/26 02:58:16 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.9240240480782129
[09/26 02:58:22 visual_prompt]: Epoch 27 / 100: avg data time: 6.01e-02, avg batch time: 0.5015, average train loss: 0.0039
[09/26 02:58:24 visual_prompt]: Inference (val):avg data time: 2.01e-05, avg batch time: 0.1659, average loss: 1.2290
[09/26 02:58:24 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.00	top5: 91.50	
[09/26 02:58:24 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.9145187862775208
[09/26 02:58:31 visual_prompt]: Epoch 28 / 100: avg data time: 5.49e-02, avg batch time: 0.4954, average train loss: 0.0035
[09/26 02:58:32 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1660, average loss: 1.2320
[09/26 02:58:32 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.00	top5: 91.50	
[09/26 02:58:32 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.9045084971874737
[09/26 02:58:39 visual_prompt]: Epoch 29 / 100: avg data time: 5.15e-02, avg batch time: 0.4926, average train loss: 0.0033
[09/26 02:58:40 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1657, average loss: 1.2325
[09/26 02:58:40 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 91.50	
[09/26 02:58:40 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.8940053768033609
[09/26 02:58:47 visual_prompt]: Epoch 30 / 100: avg data time: 6.14e-02, avg batch time: 0.5021, average train loss: 0.0031
[09/26 02:58:49 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1658, average loss: 1.2326
[09/26 02:58:49 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.50	top5: 91.50	
[09/26 02:58:49 visual_prompt]: Best epoch 30: best metric: 0.665
[09/26 02:58:49 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.883022221559489
[09/26 02:58:55 visual_prompt]: Epoch 31 / 100: avg data time: 5.71e-02, avg batch time: 0.4991, average train loss: 0.0031
[09/26 02:58:57 visual_prompt]: Inference (val):avg data time: 2.11e-05, avg batch time: 0.1661, average loss: 1.2322
[09/26 02:58:57 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.00	top5: 91.50	
[09/26 02:58:57 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.8715724127386971
[09/26 02:59:04 visual_prompt]: Epoch 32 / 100: avg data time: 5.52e-02, avg batch time: 0.4971, average train loss: 0.0030
[09/26 02:59:05 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1663, average loss: 1.2308
[09/26 02:59:05 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.50	top5: 91.50	
[09/26 02:59:05 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.8596699001693255
[09/26 02:59:12 visual_prompt]: Epoch 33 / 100: avg data time: 5.63e-02, avg batch time: 0.4973, average train loss: 0.0029
[09/26 02:59:13 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1661, average loss: 1.2326
[09/26 02:59:13 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.50	top5: 92.00	
[09/26 02:59:13 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.8473291852294986
[09/26 02:59:20 visual_prompt]: Epoch 34 / 100: avg data time: 4.84e-02, avg batch time: 0.4904, average train loss: 0.0027
[09/26 02:59:22 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1661, average loss: 1.2330
[09/26 02:59:22 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 92.00	
[09/26 02:59:22 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.8345653031794291
[09/26 02:59:28 visual_prompt]: Epoch 35 / 100: avg data time: 5.90e-02, avg batch time: 0.4999, average train loss: 0.0027
[09/26 02:59:30 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1662, average loss: 1.2321
[09/26 02:59:30 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 92.00	
[09/26 02:59:30 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.8213938048432696
[09/26 02:59:37 visual_prompt]: Epoch 36 / 100: avg data time: 6.21e-02, avg batch time: 0.5034, average train loss: 0.0026
[09/26 02:59:38 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1660, average loss: 1.2315
[09/26 02:59:38 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.50	top5: 92.00	
[09/26 02:59:38 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.8078307376628291
[09/26 02:59:45 visual_prompt]: Epoch 37 / 100: avg data time: 5.72e-02, avg batch time: 0.4990, average train loss: 0.0025
[09/26 02:59:46 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1661, average loss: 1.2316
[09/26 02:59:46 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 64.50	top5: 92.00	
[09/26 02:59:46 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.7938926261462366
[09/26 02:59:53 visual_prompt]: Epoch 38 / 100: avg data time: 5.84e-02, avg batch time: 0.4996, average train loss: 0.0024
[09/26 02:59:55 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1663, average loss: 1.2313
[09/26 02:59:55 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 64.50	top5: 92.00	
[09/26 02:59:55 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.7795964517353734
[09/26 03:00:01 visual_prompt]: Epoch 39 / 100: avg data time: 5.77e-02, avg batch time: 0.4989, average train loss: 0.0024
[09/26 03:00:03 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1660, average loss: 1.2303
[09/26 03:00:03 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 92.00	
[09/26 03:00:03 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.7649596321166025
[09/26 03:00:10 visual_prompt]: Epoch 40 / 100: avg data time: 5.54e-02, avg batch time: 0.4978, average train loss: 0.0023
[09/26 03:00:11 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1663, average loss: 1.2291
[09/26 03:00:11 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 92.00	
[09/26 03:00:11 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.75
[09/26 03:00:18 visual_prompt]: Epoch 41 / 100: avg data time: 5.59e-02, avg batch time: 0.4971, average train loss: 0.0022
[09/26 03:00:19 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1664, average loss: 1.2289
[09/26 03:00:19 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 92.00	
[09/26 03:00:19 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.7347357813929454
[09/26 03:00:26 visual_prompt]: Epoch 42 / 100: avg data time: 5.66e-02, avg batch time: 0.4980, average train loss: 0.0022
[09/26 03:00:28 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1661, average loss: 1.2269
[09/26 03:00:28 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 92.00	
[09/26 03:00:28 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.7191855733945387
[09/26 03:00:34 visual_prompt]: Epoch 43 / 100: avg data time: 5.53e-02, avg batch time: 0.4973, average train loss: 0.0022
[09/26 03:00:36 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1663, average loss: 1.2271
[09/26 03:00:36 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 92.00	
[09/26 03:00:36 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.7033683215379002
[09/26 03:00:43 visual_prompt]: Epoch 44 / 100: avg data time: 5.67e-02, avg batch time: 0.4987, average train loss: 0.0021
[09/26 03:00:44 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1663, average loss: 1.2256
[09/26 03:00:44 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 92.00	
[09/26 03:00:44 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.6873032967079561
[09/26 03:00:51 visual_prompt]: Epoch 45 / 100: avg data time: 5.57e-02, avg batch time: 0.4969, average train loss: 0.0021
[09/26 03:00:52 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1664, average loss: 1.2237
[09/26 03:00:52 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 92.00	
[09/26 03:00:52 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.6710100716628344
[09/26 03:00:59 visual_prompt]: Epoch 46 / 100: avg data time: 5.21e-02, avg batch time: 0.4950, average train loss: 0.0020
[09/26 03:01:01 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1664, average loss: 1.2216
[09/26 03:01:01 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 92.00	
[09/26 03:01:01 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.6545084971874737
[09/26 03:01:07 visual_prompt]: Epoch 47 / 100: avg data time: 5.14e-02, avg batch time: 0.4933, average train loss: 0.0020
[09/26 03:01:09 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1663, average loss: 1.2210
[09/26 03:01:09 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 92.00	
[09/26 03:01:09 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.6378186779084996
[09/26 03:01:16 visual_prompt]: Epoch 48 / 100: avg data time: 5.29e-02, avg batch time: 0.4962, average train loss: 0.0019
[09/26 03:01:17 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1664, average loss: 1.2211
[09/26 03:01:17 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 92.00	
[09/26 03:01:17 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.6209609477998338
[09/26 03:01:24 visual_prompt]: Epoch 49 / 100: avg data time: 5.87e-02, avg batch time: 0.5017, average train loss: 0.0019
[09/26 03:01:26 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1666, average loss: 1.2201
[09/26 03:01:26 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 92.00	
[09/26 03:01:26 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.6039558454088796
[09/26 03:01:32 visual_prompt]: Epoch 50 / 100: avg data time: 6.14e-02, avg batch time: 0.5044, average train loss: 0.0019
[09/26 03:01:34 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1662, average loss: 1.2202
[09/26 03:01:34 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 92.00	
[09/26 03:01:34 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.5868240888334653
[09/26 03:01:41 visual_prompt]: Epoch 51 / 100: avg data time: 5.63e-02, avg batch time: 0.4989, average train loss: 0.0018
[09/26 03:01:42 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1666, average loss: 1.2213
[09/26 03:01:42 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 92.00	
[09/26 03:01:42 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.5695865504800327
[09/26 03:01:49 visual_prompt]: Epoch 52 / 100: avg data time: 4.61e-02, avg batch time: 0.4922, average train loss: 0.0018
[09/26 03:01:50 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1663, average loss: 1.2206
[09/26 03:01:50 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 92.00	
[09/26 03:01:50 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.5522642316338268
[09/26 03:01:57 visual_prompt]: Epoch 53 / 100: avg data time: 5.72e-02, avg batch time: 0.4999, average train loss: 0.0018
[09/26 03:01:59 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1664, average loss: 1.2206
[09/26 03:01:59 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 92.00	
[09/26 03:01:59 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.5348782368720626
[09/26 03:02:05 visual_prompt]: Epoch 54 / 100: avg data time: 5.83e-02, avg batch time: 0.4997, average train loss: 0.0018
[09/26 03:02:07 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1663, average loss: 1.2203
[09/26 03:02:07 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 92.00	
[09/26 03:02:07 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.5174497483512506
[09/26 03:02:14 visual_prompt]: Epoch 55 / 100: avg data time: 5.12e-02, avg batch time: 0.4930, average train loss: 0.0018
[09/26 03:02:15 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1665, average loss: 1.2198
[09/26 03:02:15 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 92.00	
[09/26 03:02:15 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.5
[09/26 03:02:22 visual_prompt]: Epoch 56 / 100: avg data time: 5.27e-02, avg batch time: 0.4951, average train loss: 0.0017
[09/26 03:02:23 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1663, average loss: 1.2197
[09/26 03:02:23 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 92.00	
[09/26 03:02:23 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.48255025164874965
[09/26 03:02:30 visual_prompt]: Epoch 57 / 100: avg data time: 6.34e-02, avg batch time: 0.5046, average train loss: 0.0018
[09/26 03:02:32 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1662, average loss: 1.2201
[09/26 03:02:32 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 92.00	
[09/26 03:02:32 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.46512176312793735
[09/26 03:02:38 visual_prompt]: Epoch 58 / 100: avg data time: 4.74e-02, avg batch time: 0.4900, average train loss: 0.0016
[09/26 03:02:40 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1662, average loss: 1.2204
[09/26 03:02:40 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.50	top5: 92.00	
[09/26 03:02:40 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.44773576836617335
[09/26 03:02:46 visual_prompt]: Epoch 59 / 100: avg data time: 4.98e-02, avg batch time: 0.4923, average train loss: 0.0016
[09/26 03:02:48 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1663, average loss: 1.2195
[09/26 03:02:48 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 92.00	
[09/26 03:02:48 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.4304134495199674
[09/26 03:02:55 visual_prompt]: Epoch 60 / 100: avg data time: 4.86e-02, avg batch time: 0.4915, average train loss: 0.0017
[09/26 03:02:56 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1663, average loss: 1.2189
[09/26 03:02:56 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 92.00	
[09/26 03:02:56 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.41317591116653485
[09/26 03:03:03 visual_prompt]: Epoch 61 / 100: avg data time: 5.68e-02, avg batch time: 0.4987, average train loss: 0.0016
[09/26 03:03:04 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1663, average loss: 1.2187
[09/26 03:03:04 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 92.00	
[09/26 03:03:04 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.3960441545911204
[09/26 03:03:11 visual_prompt]: Epoch 62 / 100: avg data time: 5.40e-02, avg batch time: 0.4951, average train loss: 0.0016
[09/26 03:03:13 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1661, average loss: 1.2187
[09/26 03:03:13 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 92.00	
[09/26 03:03:13 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.3790390522001662
[09/26 03:03:20 visual_prompt]: Epoch 63 / 100: avg data time: 6.06e-02, avg batch time: 0.5020, average train loss: 0.0016
[09/26 03:03:21 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1661, average loss: 1.2182
[09/26 03:03:21 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 92.00	
[09/26 03:03:21 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.36218132209150045
[09/26 03:03:28 visual_prompt]: Epoch 64 / 100: avg data time: 5.98e-02, avg batch time: 0.5006, average train loss: 0.0016
[09/26 03:03:29 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1661, average loss: 1.2187
[09/26 03:03:29 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 92.00	
[09/26 03:03:29 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.34549150281252633
[09/26 03:03:36 visual_prompt]: Epoch 65 / 100: avg data time: 6.41e-02, avg batch time: 0.5050, average train loss: 0.0016
[09/26 03:03:38 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1663, average loss: 1.2184
[09/26 03:03:38 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 92.00	
[09/26 03:03:38 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.32898992833716567
[09/26 03:03:45 visual_prompt]: Epoch 66 / 100: avg data time: 5.70e-02, avg batch time: 0.4985, average train loss: 0.0016
[09/26 03:03:46 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1663, average loss: 1.2178
[09/26 03:03:46 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 92.00	
[09/26 03:03:46 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.31269670329204396
[09/26 03:03:53 visual_prompt]: Epoch 67 / 100: avg data time: 6.08e-02, avg batch time: 0.5019, average train loss: 0.0015
[09/26 03:03:54 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1661, average loss: 1.2178
[09/26 03:03:54 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 92.00	
[09/26 03:03:54 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.2966316784621
[09/26 03:04:01 visual_prompt]: Epoch 68 / 100: avg data time: 4.21e-02, avg batch time: 0.4858, average train loss: 0.0015
[09/26 03:04:03 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1662, average loss: 1.2177
[09/26 03:04:03 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 92.00	
[09/26 03:04:03 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.28081442660546124
[09/26 03:04:09 visual_prompt]: Epoch 69 / 100: avg data time: 4.44e-02, avg batch time: 0.4875, average train loss: 0.0015
[09/26 03:04:11 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1661, average loss: 1.2171
[09/26 03:04:11 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 92.00	
[09/26 03:04:11 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.26526421860705474
[09/26 03:04:17 visual_prompt]: Epoch 70 / 100: avg data time: 5.65e-02, avg batch time: 0.4979, average train loss: 0.0015
[09/26 03:04:19 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1661, average loss: 1.2171
[09/26 03:04:19 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 92.00	
[09/26 03:04:19 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.2500000000000001
[09/26 03:04:26 visual_prompt]: Epoch 71 / 100: avg data time: 4.73e-02, avg batch time: 0.4908, average train loss: 0.0015
[09/26 03:04:27 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1663, average loss: 1.2172
[09/26 03:04:27 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 92.00	
[09/26 03:04:27 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.2350403678833976
[09/26 03:04:34 visual_prompt]: Epoch 72 / 100: avg data time: 5.81e-02, avg batch time: 0.5001, average train loss: 0.0015
[09/26 03:04:36 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1660, average loss: 1.2177
[09/26 03:04:36 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 92.00	
[09/26 03:04:36 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.22040354826462666
[09/26 03:04:42 visual_prompt]: Epoch 73 / 100: avg data time: 5.67e-02, avg batch time: 0.4982, average train loss: 0.0015
[09/26 03:04:44 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1662, average loss: 1.2176
[09/26 03:04:44 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 92.00	
[09/26 03:04:44 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.2061073738537635
[09/26 03:04:50 visual_prompt]: Epoch 74 / 100: avg data time: 4.95e-02, avg batch time: 0.4910, average train loss: 0.0015
[09/26 03:04:52 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1662, average loss: 1.2177
[09/26 03:04:52 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 92.00	
[09/26 03:04:52 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.19216926233717085
[09/26 03:04:59 visual_prompt]: Epoch 75 / 100: avg data time: 4.44e-02, avg batch time: 0.4880, average train loss: 0.0015
[09/26 03:05:00 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1661, average loss: 1.2171
[09/26 03:05:00 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 92.00	
[09/26 03:05:00 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.17860619515673032
[09/26 03:05:07 visual_prompt]: Epoch 76 / 100: avg data time: 5.60e-02, avg batch time: 0.4969, average train loss: 0.0014
[09/26 03:05:08 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.1662, average loss: 1.2167
[09/26 03:05:08 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 92.00	
[09/26 03:05:08 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.16543469682057105
[09/26 03:05:15 visual_prompt]: Epoch 77 / 100: avg data time: 5.63e-02, avg batch time: 0.4975, average train loss: 0.0014
[09/26 03:05:17 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1661, average loss: 1.2163
[09/26 03:05:17 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 92.00	
[09/26 03:05:17 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.15267081477050132
[09/26 03:05:24 visual_prompt]: Epoch 78 / 100: avg data time: 6.57e-02, avg batch time: 0.5073, average train loss: 0.0014
[09/26 03:05:25 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1660, average loss: 1.2163
[09/26 03:05:25 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 92.00	
[09/26 03:05:25 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.14033009983067452
[09/26 03:05:32 visual_prompt]: Epoch 79 / 100: avg data time: 4.95e-02, avg batch time: 0.4914, average train loss: 0.0015
[09/26 03:05:33 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1662, average loss: 1.2164
[09/26 03:05:33 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 92.00	
[09/26 03:05:33 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.12842758726130282
[09/26 03:05:40 visual_prompt]: Epoch 80 / 100: avg data time: 5.73e-02, avg batch time: 0.4978, average train loss: 0.0015
[09/26 03:05:42 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1661, average loss: 1.2163
[09/26 03:05:42 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 92.00	
[09/26 03:05:42 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.11697777844051105
[09/26 03:05:48 visual_prompt]: Epoch 81 / 100: avg data time: 5.52e-02, avg batch time: 0.4965, average train loss: 0.0014
[09/26 03:05:50 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1661, average loss: 1.2163
[09/26 03:05:50 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 92.00	
[09/26 03:05:50 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.10599462319663905
[09/26 03:05:57 visual_prompt]: Epoch 82 / 100: avg data time: 5.56e-02, avg batch time: 0.4964, average train loss: 0.0014
[09/26 03:05:58 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1662, average loss: 1.2163
[09/26 03:05:58 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 92.00	
[09/26 03:05:58 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.09549150281252633
[09/26 03:06:05 visual_prompt]: Epoch 83 / 100: avg data time: 5.53e-02, avg batch time: 0.4960, average train loss: 0.0014
[09/26 03:06:06 visual_prompt]: Inference (val):avg data time: 4.64e-05, avg batch time: 0.1660, average loss: 1.2164
[09/26 03:06:06 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 92.00	
[09/26 03:06:06 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.08548121372247919
[09/26 03:06:13 visual_prompt]: Epoch 84 / 100: avg data time: 4.19e-02, avg batch time: 0.4848, average train loss: 0.0015
[09/26 03:06:15 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1662, average loss: 1.2165
[09/26 03:06:15 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 92.00	
[09/26 03:06:15 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.07597595192178702
[09/26 03:06:21 visual_prompt]: Epoch 85 / 100: avg data time: 5.54e-02, avg batch time: 0.4972, average train loss: 0.0014
[09/26 03:06:23 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1662, average loss: 1.2165
[09/26 03:06:23 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 92.00	
[09/26 03:06:23 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.06698729810778065
[09/26 03:06:30 visual_prompt]: Epoch 86 / 100: avg data time: 5.37e-02, avg batch time: 0.4961, average train loss: 0.0014
[09/26 03:06:31 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1663, average loss: 1.2164
[09/26 03:06:31 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 92.00	
[09/26 03:06:31 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.058526203570536506
[09/26 03:06:38 visual_prompt]: Epoch 87 / 100: avg data time: 4.25e-02, avg batch time: 0.4861, average train loss: 0.0014
[09/26 03:06:39 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1663, average loss: 1.2164
[09/26 03:06:39 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 92.00	
[09/26 03:06:39 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.05060297685041659
[09/26 03:06:46 visual_prompt]: Epoch 88 / 100: avg data time: 4.24e-02, avg batch time: 0.4864, average train loss: 0.0014
[09/26 03:06:47 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1666, average loss: 1.2164
[09/26 03:06:47 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 92.00	
[09/26 03:06:47 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.04322727117869951
[09/26 03:06:54 visual_prompt]: Epoch 89 / 100: avg data time: 4.38e-02, avg batch time: 0.4868, average train loss: 0.0014
[09/26 03:06:55 visual_prompt]: Inference (val):avg data time: 1.95e-05, avg batch time: 0.1663, average loss: 1.2165
[09/26 03:06:55 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 92.00	
[09/26 03:06:55 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.03640807271660634
[09/26 03:07:02 visual_prompt]: Epoch 90 / 100: avg data time: 5.11e-02, avg batch time: 0.4926, average train loss: 0.0014
[09/26 03:07:04 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1663, average loss: 1.2165
[09/26 03:07:04 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 92.00	
[09/26 03:07:04 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.03015368960704584
[09/26 03:07:10 visual_prompt]: Epoch 91 / 100: avg data time: 4.91e-02, avg batch time: 0.4903, average train loss: 0.0015
[09/26 03:07:12 visual_prompt]: Inference (val):avg data time: 1.89e-05, avg batch time: 0.1660, average loss: 1.2165
[09/26 03:07:12 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 92.00	
[09/26 03:07:12 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.024471741852423234
[09/26 03:07:19 visual_prompt]: Epoch 92 / 100: avg data time: 5.40e-02, avg batch time: 0.4956, average train loss: 0.0014
[09/26 03:07:20 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.1664, average loss: 1.2165
[09/26 03:07:20 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 92.00	
[09/26 03:07:20 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.019369152030840553
[09/26 03:07:27 visual_prompt]: Epoch 93 / 100: avg data time: 5.45e-02, avg batch time: 0.4960, average train loss: 0.0014
[09/26 03:07:28 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1661, average loss: 1.2165
[09/26 03:07:28 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 92.00	
[09/26 03:07:28 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.014852136862001764
[09/26 03:07:35 visual_prompt]: Epoch 94 / 100: avg data time: 5.33e-02, avg batch time: 0.4952, average train loss: 0.0014
[09/26 03:07:37 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1663, average loss: 1.2165
[09/26 03:07:37 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 92.00	
[09/26 03:07:37 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.010926199633097156
[09/26 03:07:43 visual_prompt]: Epoch 95 / 100: avg data time: 4.92e-02, avg batch time: 0.4918, average train loss: 0.0014
[09/26 03:07:45 visual_prompt]: Inference (val):avg data time: 1.81e-05, avg batch time: 0.1663, average loss: 1.2165
[09/26 03:07:45 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 92.00	
[09/26 03:07:45 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.00759612349389599
[09/26 03:07:51 visual_prompt]: Epoch 96 / 100: avg data time: 5.15e-02, avg batch time: 0.4947, average train loss: 0.0014
[09/26 03:07:53 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1664, average loss: 1.2165
[09/26 03:07:53 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 92.00	
[09/26 03:07:53 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.004865965629214819
[09/26 03:08:00 visual_prompt]: Epoch 97 / 100: avg data time: 5.75e-02, avg batch time: 0.4997, average train loss: 0.0014
[09/26 03:08:01 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1665, average loss: 1.2165
[09/26 03:08:01 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 92.00	
[09/26 03:08:01 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.002739052315863355
[09/26 03:08:08 visual_prompt]: Epoch 98 / 100: avg data time: 4.26e-02, avg batch time: 0.4852, average train loss: 0.0014
[09/26 03:08:09 visual_prompt]: Inference (val):avg data time: 2.01e-05, avg batch time: 0.1662, average loss: 1.2165
[09/26 03:08:09 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 92.00	
[09/26 03:08:09 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.0012179748700879012
[09/26 03:08:16 visual_prompt]: Epoch 99 / 100: avg data time: 4.86e-02, avg batch time: 0.4906, average train loss: 0.0014
[09/26 03:08:18 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1664, average loss: 1.2165
[09/26 03:08:18 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 92.00	
[09/26 03:08:18 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.00030458649045211894
[09/26 03:08:24 visual_prompt]: Epoch 100 / 100: avg data time: 5.23e-02, avg batch time: 0.4938, average train loss: 0.0014
[09/26 03:08:26 visual_prompt]: Inference (val):avg data time: 1.97e-05, avg batch time: 0.1662, average loss: 1.2165
[09/26 03:08:26 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 92.00	
[09/26 03:08:26 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 03:08:26 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 03:08:26 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-cifar(num_classes=100)', 'DATA.NUMBER_CLASSES', '100', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 03:08:26 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 03:08:26 visual_prompt]: Training with config:
[09/26 03:08:26 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-cifar(num_classes=100)/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.5_wd0.01/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 0.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-cifar(num_classes=100)', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 100, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 03:08:26 visual_prompt]: Loading training data...
[09/26 03:08:26 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[:800], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/26 03:08:27 visual_prompt]: Number of images: 800
[09/26 03:08:27 visual_prompt]: Number of classes: 100 / 100
[09/26 03:08:27 visual_prompt]: Loading validation data...
[09/26 03:08:27 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[45000:45200], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/26 03:08:27 visual_prompt]: Number of images: 200
[09/26 03:08:27 visual_prompt]: Number of classes: 90 / 100
[09/26 03:08:27 visual_prompt]: Constructing models...
[09/26 03:08:29 visual_prompt]: Total Parameters: 86336356	 Gradient Parameters: 537700
[09/26 03:08:29 visual_prompt]: tuned percent:0.623
[09/26 03:08:29 visual_prompt]: Device used for model: 0
[09/26 03:08:29 visual_prompt]: Setting up Evaluator...
[09/26 03:08:29 visual_prompt]: Setting up Trainer...
[09/26 03:08:29 visual_prompt]: 	Setting up the optimizer...
[09/26 03:08:29 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 03:08:37 visual_prompt]: Epoch 1 / 100: avg data time: 1.06e-01, avg batch time: 0.5497, average train loss: 4.6579
[09/26 03:08:38 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1659, average loss: 4.6218
[09/26 03:08:38 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 7.00	
[09/26 03:08:38 visual_prompt]: Best epoch 1: best metric: 0.010
[09/26 03:08:38 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.05
[09/26 03:08:45 visual_prompt]: Epoch 2 / 100: avg data time: 5.70e-02, avg batch time: 0.4975, average train loss: 4.6213
[09/26 03:08:47 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1658, average loss: 4.6069
[09/26 03:08:47 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.00	
[09/26 03:08:47 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.1
[09/26 03:08:53 visual_prompt]: Epoch 3 / 100: avg data time: 5.76e-02, avg batch time: 0.4986, average train loss: 4.5670
[09/26 03:08:55 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1659, average loss: 4.6088
[09/26 03:08:55 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.00	top5: 5.00	
[09/26 03:08:55 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.15
[09/26 03:09:02 visual_prompt]: Epoch 4 / 100: avg data time: 5.39e-02, avg batch time: 0.4953, average train loss: 4.5640
[09/26 03:09:03 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1660, average loss: 4.6013
[09/26 03:09:03 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 8.00	
[09/26 03:09:03 visual_prompt]: Best epoch 4: best metric: 0.020
[09/26 03:09:03 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.2
[09/26 03:09:10 visual_prompt]: Epoch 5 / 100: avg data time: 5.77e-02, avg batch time: 0.4983, average train loss: 4.4654
[09/26 03:09:12 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1660, average loss: 4.6277
[09/26 03:09:12 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.00	
[09/26 03:09:12 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.25
[09/26 03:09:18 visual_prompt]: Epoch 6 / 100: avg data time: 4.59e-02, avg batch time: 0.4883, average train loss: 4.4090
[09/26 03:09:20 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1659, average loss: 4.3868
[09/26 03:09:20 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 4.50	top5: 14.50	
[09/26 03:09:20 visual_prompt]: Best epoch 6: best metric: 0.045
[09/26 03:09:20 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.3
[09/26 03:09:26 visual_prompt]: Epoch 7 / 100: avg data time: 5.07e-02, avg batch time: 0.4920, average train loss: 4.2840
[09/26 03:09:28 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1660, average loss: 4.3941
[09/26 03:09:28 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 4.00	top5: 16.00	
[09/26 03:09:28 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.35
[09/26 03:09:35 visual_prompt]: Epoch 8 / 100: avg data time: 5.62e-02, avg batch time: 0.4966, average train loss: 4.5425
[09/26 03:09:36 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1658, average loss: 4.6305
[09/26 03:09:36 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.50	top5: 6.50	
[09/26 03:09:36 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.4
[09/26 03:09:43 visual_prompt]: Epoch 9 / 100: avg data time: 4.92e-02, avg batch time: 0.4919, average train loss: 4.5889
[09/26 03:09:44 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1658, average loss: 4.6473
[09/26 03:09:44 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.50	
[09/26 03:09:44 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.45
[09/26 03:09:51 visual_prompt]: Epoch 10 / 100: avg data time: 5.46e-02, avg batch time: 0.4956, average train loss: 4.6314
[09/26 03:09:53 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1656, average loss: 4.6367
[09/26 03:09:53 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.00	
[09/26 03:09:53 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.5
[09/26 03:09:59 visual_prompt]: Epoch 11 / 100: avg data time: 5.54e-02, avg batch time: 0.4958, average train loss: 4.5949
[09/26 03:10:01 visual_prompt]: Inference (val):avg data time: 2.00e-05, avg batch time: 0.1657, average loss: 4.6287
[09/26 03:10:01 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.00	
[09/26 03:10:01 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.49984770675477397
[09/26 03:10:08 visual_prompt]: Epoch 12 / 100: avg data time: 4.93e-02, avg batch time: 0.4913, average train loss: 4.6071
[09/26 03:10:09 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1659, average loss: 4.6539
[09/26 03:10:09 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.00	
[09/26 03:10:09 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.49939101256495605
[09/26 03:10:16 visual_prompt]: Epoch 13 / 100: avg data time: 5.48e-02, avg batch time: 0.4950, average train loss: 4.6164
[09/26 03:10:17 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1659, average loss: 4.6367
[09/26 03:10:17 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 4.50	
[09/26 03:10:17 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.4986304738420683
[09/26 03:10:24 visual_prompt]: Epoch 14 / 100: avg data time: 5.72e-02, avg batch time: 0.4973, average train loss: 4.5880
[09/26 03:10:26 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1658, average loss: 4.6504
[09/26 03:10:26 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.50	
[09/26 03:10:26 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.4975670171853926
[09/26 03:10:32 visual_prompt]: Epoch 15 / 100: avg data time: 5.66e-02, avg batch time: 0.4968, average train loss: 4.5994
[09/26 03:10:34 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1655, average loss: 4.6396
[09/26 03:10:34 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/26 03:10:34 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.49620193825305203
[09/26 03:10:41 visual_prompt]: Epoch 16 / 100: avg data time: 6.48e-02, avg batch time: 0.5053, average train loss: 4.5769
[09/26 03:10:42 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1655, average loss: 4.6635
[09/26 03:10:42 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 5.50	
[09/26 03:10:42 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.4945369001834514
[09/26 03:10:49 visual_prompt]: Epoch 17 / 100: avg data time: 4.35e-02, avg batch time: 0.4844, average train loss: 4.5974
[09/26 03:10:50 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1656, average loss: 4.6388
[09/26 03:10:50 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 5.50	
[09/26 03:10:50 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.4925739315689991
[09/26 03:10:57 visual_prompt]: Epoch 18 / 100: avg data time: 5.81e-02, avg batch time: 0.4988, average train loss: 4.5813
[09/26 03:10:59 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1656, average loss: 4.6499
[09/26 03:10:59 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 2.50	
[09/26 03:10:59 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.4903154239845797
[09/26 03:11:05 visual_prompt]: Epoch 19 / 100: avg data time: 4.59e-02, avg batch time: 0.4879, average train loss: 4.5778
[09/26 03:11:07 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1652, average loss: 4.6708
[09/26 03:11:07 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.00	
[09/26 03:11:07 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.4877641290737884
[09/26 03:11:14 visual_prompt]: Epoch 20 / 100: avg data time: 5.49e-02, avg batch time: 0.4952, average train loss: 4.5833
[09/26 03:11:15 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1657, average loss: 4.6894
[09/26 03:11:15 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 6.00	
[09/26 03:11:15 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.4849231551964771
[09/26 03:11:22 visual_prompt]: Epoch 21 / 100: avg data time: 4.93e-02, avg batch time: 0.4901, average train loss: 4.6149
[09/26 03:11:23 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1656, average loss: 4.6531
[09/26 03:11:23 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 2.50	
[09/26 03:11:23 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.48179596364169686
[09/26 03:11:30 visual_prompt]: Epoch 22 / 100: avg data time: 5.08e-02, avg batch time: 0.4910, average train loss: 4.6167
[09/26 03:11:32 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1656, average loss: 4.6716
[09/26 03:11:32 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.00	
[09/26 03:11:32 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.4783863644106502
[09/26 03:11:38 visual_prompt]: Epoch 23 / 100: avg data time: 4.74e-02, avg batch time: 0.4906, average train loss: 4.6066
[09/26 03:11:40 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1656, average loss: 4.6732
[09/26 03:11:40 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/26 03:11:40 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.47469851157479176
[09/26 03:11:46 visual_prompt]: Epoch 24 / 100: avg data time: 5.38e-02, avg batch time: 0.4934, average train loss: 4.6198
[09/26 03:11:48 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1655, average loss: 4.6382
[09/26 03:11:48 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/26 03:11:48 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.47073689821473175
[09/26 03:11:55 visual_prompt]: Epoch 25 / 100: avg data time: 5.61e-02, avg batch time: 0.4970, average train loss: 4.6016
[09/26 03:11:56 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1658, average loss: 4.6410
[09/26 03:11:56 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.50	
[09/26 03:11:56 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.4665063509461097
[09/26 03:12:03 visual_prompt]: Epoch 26 / 100: avg data time: 5.96e-02, avg batch time: 0.4998, average train loss: 4.5874
[09/26 03:12:04 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1657, average loss: 4.6447
[09/26 03:12:04 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 3.50	
[09/26 03:12:04 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.46201202403910646
[09/26 03:12:11 visual_prompt]: Epoch 27 / 100: avg data time: 5.75e-02, avg batch time: 0.4989, average train loss: 4.6083
[09/26 03:12:13 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1656, average loss: 4.6354
[09/26 03:12:13 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.00	
[09/26 03:12:13 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.4572593931387604
[09/26 03:12:19 visual_prompt]: Epoch 28 / 100: avg data time: 5.78e-02, avg batch time: 0.4990, average train loss: 4.5861
[09/26 03:12:21 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1658, average loss: 4.6552
[09/26 03:12:21 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/26 03:12:21 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.45225424859373686
[09/26 03:12:28 visual_prompt]: Epoch 29 / 100: avg data time: 5.25e-02, avg batch time: 0.4940, average train loss: 4.5859
[09/26 03:12:29 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1657, average loss: 4.6883
[09/26 03:12:29 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 3.50	
[09/26 03:12:29 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.44700268840168045
[09/26 03:12:36 visual_prompt]: Epoch 30 / 100: avg data time: 4.44e-02, avg batch time: 0.4871, average train loss: 4.5974
[09/26 03:12:37 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1655, average loss: 4.6527
[09/26 03:12:37 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/26 03:12:37 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.4415111107797445
[09/26 03:12:44 visual_prompt]: Epoch 31 / 100: avg data time: 5.87e-02, avg batch time: 0.5005, average train loss: 4.5972
[09/26 03:12:46 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1656, average loss: 4.6424
[09/26 03:12:46 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/26 03:12:46 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.43578620636934856
[09/26 03:12:52 visual_prompt]: Epoch 32 / 100: avg data time: 5.66e-02, avg batch time: 0.4990, average train loss: 4.5986
[09/26 03:12:54 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1658, average loss: 4.6453
[09/26 03:12:54 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 5.50	
[09/26 03:12:54 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.42983495008466277
[09/26 03:13:01 visual_prompt]: Epoch 33 / 100: avg data time: 5.76e-02, avg batch time: 0.4978, average train loss: 4.5842
[09/26 03:13:02 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1654, average loss: 4.6494
[09/26 03:13:02 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.00	
[09/26 03:13:02 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.4236645926147493
[09/26 03:13:09 visual_prompt]: Epoch 34 / 100: avg data time: 4.59e-02, avg batch time: 0.4875, average train loss: 4.5776
[09/26 03:13:10 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1656, average loss: 4.6486
[09/26 03:13:10 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.00	
[09/26 03:13:10 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.41728265158971456
[09/26 03:13:17 visual_prompt]: Epoch 35 / 100: avg data time: 4.68e-02, avg batch time: 0.4877, average train loss: 4.5881
[09/26 03:13:18 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1656, average loss: 4.6642
[09/26 03:13:18 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 3.50	
[09/26 03:13:18 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.4106969024216348
[09/26 03:13:25 visual_prompt]: Epoch 36 / 100: avg data time: 4.90e-02, avg batch time: 0.4913, average train loss: 4.5776
[09/26 03:13:26 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1660, average loss: 4.6417
[09/26 03:13:26 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/26 03:13:26 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.40391536883141455
[09/26 03:13:33 visual_prompt]: Epoch 37 / 100: avg data time: 5.40e-02, avg batch time: 0.4957, average train loss: 4.5770
[09/26 03:13:35 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1658, average loss: 4.6615
[09/26 03:13:35 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/26 03:13:35 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.3969463130731183
[09/26 03:13:41 visual_prompt]: Epoch 38 / 100: avg data time: 5.82e-02, avg batch time: 0.4995, average train loss: 4.5953
[09/26 03:13:43 visual_prompt]: Inference (val):avg data time: 2.11e-05, avg batch time: 0.1657, average loss: 4.6602
[09/26 03:13:43 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.50	
[09/26 03:13:43 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.3897982258676867
[09/26 03:13:50 visual_prompt]: Epoch 39 / 100: avg data time: 5.53e-02, avg batch time: 0.4955, average train loss: 4.5930
[09/26 03:13:51 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1656, average loss: 4.6415
[09/26 03:13:51 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 4.00	
[09/26 03:13:51 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.3824798160583012
[09/26 03:13:58 visual_prompt]: Epoch 40 / 100: avg data time: 5.51e-02, avg batch time: 0.4950, average train loss: 4.5874
[09/26 03:13:59 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1657, average loss: 4.6488
[09/26 03:13:59 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.50	
[09/26 03:13:59 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.375
[09/26 03:14:06 visual_prompt]: Epoch 41 / 100: avg data time: 5.55e-02, avg batch time: 0.4971, average train loss: 4.5815
[09/26 03:14:07 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1660, average loss: 4.6567
[09/26 03:14:07 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/26 03:14:07 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.3673678906964727
[09/26 03:14:14 visual_prompt]: Epoch 42 / 100: avg data time: 5.13e-02, avg batch time: 0.4942, average train loss: 4.5782
[09/26 03:14:15 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1657, average loss: 4.6342
[09/26 03:14:15 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 3.50	
[09/26 03:14:15 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.35959278669726935
[09/26 03:14:22 visual_prompt]: Epoch 43 / 100: avg data time: 6.37e-02, avg batch time: 0.5045, average train loss: 4.5878
[09/26 03:14:24 visual_prompt]: Inference (val):avg data time: 2.01e-05, avg batch time: 0.1658, average loss: 4.6468
[09/26 03:14:24 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 3.50	
[09/26 03:14:24 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.3516841607689501
[09/26 03:14:31 visual_prompt]: Epoch 44 / 100: avg data time: 5.75e-02, avg batch time: 0.4980, average train loss: 4.5753
[09/26 03:14:32 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1657, average loss: 4.6435
[09/26 03:14:32 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 3.00	
[09/26 03:14:32 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.34365164835397805
[09/26 03:14:39 visual_prompt]: Epoch 45 / 100: avg data time: 5.87e-02, avg batch time: 0.5005, average train loss: 4.5803
[09/26 03:14:40 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1657, average loss: 4.6404
[09/26 03:14:40 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.00	
[09/26 03:14:40 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.3355050358314172
[09/26 03:14:47 visual_prompt]: Epoch 46 / 100: avg data time: 6.10e-02, avg batch time: 0.5011, average train loss: 4.5750
[09/26 03:14:49 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1654, average loss: 4.6625
[09/26 03:14:49 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 5.50	
[09/26 03:14:49 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.32725424859373686
[09/26 03:14:56 visual_prompt]: Epoch 47 / 100: avg data time: 6.41e-02, avg batch time: 0.5051, average train loss: 4.5901
[09/26 03:14:57 visual_prompt]: Inference (val):avg data time: 1.94e-05, avg batch time: 0.1655, average loss: 4.6475
[09/26 03:14:57 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.50	
[09/26 03:14:57 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.3189093389542498
[09/26 03:15:04 visual_prompt]: Epoch 48 / 100: avg data time: 5.58e-02, avg batch time: 0.4969, average train loss: 4.5765
[09/26 03:15:05 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1656, average loss: 4.6504
[09/26 03:15:05 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/26 03:15:05 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.3104804738999169
[09/26 03:15:12 visual_prompt]: Epoch 49 / 100: avg data time: 5.43e-02, avg batch time: 0.4956, average train loss: 4.5785
[09/26 03:15:13 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1657, average loss: 4.6477
[09/26 03:15:14 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 4.50	
[09/26 03:15:14 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.3019779227044398
[09/26 03:15:20 visual_prompt]: Epoch 50 / 100: avg data time: 4.69e-02, avg batch time: 0.4896, average train loss: 4.5827
[09/26 03:15:22 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1655, average loss: 4.6490
[09/26 03:15:22 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 4.00	
[09/26 03:15:22 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.29341204441673263
[09/26 03:15:29 visual_prompt]: Epoch 51 / 100: avg data time: 6.21e-02, avg batch time: 0.5019, average train loss: 4.5847
[09/26 03:15:30 visual_prompt]: Inference (val):avg data time: 1.98e-05, avg batch time: 0.1655, average loss: 4.6457
[09/26 03:15:30 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 4.50	
[09/26 03:15:30 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.28479327524001635
[09/26 03:15:37 visual_prompt]: Epoch 52 / 100: avg data time: 5.52e-02, avg batch time: 0.4962, average train loss: 4.5818
[09/26 03:15:38 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1655, average loss: 4.6445
[09/26 03:15:38 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.00	
[09/26 03:15:38 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.2761321158169134
[09/26 03:15:45 visual_prompt]: Epoch 53 / 100: avg data time: 5.35e-02, avg batch time: 0.4946, average train loss: 4.5757
[09/26 03:15:46 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1659, average loss: 4.6619
[09/26 03:15:46 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 6.50	
[09/26 03:15:46 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.2674391184360313
[09/26 03:15:53 visual_prompt]: Epoch 54 / 100: avg data time: 5.05e-02, avg batch time: 0.4927, average train loss: 4.5784
[09/26 03:15:55 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1657, average loss: 4.6540
[09/26 03:15:55 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/26 03:15:55 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.2587248741756253
[09/26 03:16:01 visual_prompt]: Epoch 55 / 100: avg data time: 5.85e-02, avg batch time: 0.4986, average train loss: 4.5743
[09/26 03:16:03 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1657, average loss: 4.6302
[09/26 03:16:03 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.50	
[09/26 03:16:03 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.25
[09/26 03:16:10 visual_prompt]: Epoch 56 / 100: avg data time: 5.52e-02, avg batch time: 0.4969, average train loss: 4.5505
[09/26 03:16:11 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1658, average loss: 4.6192
[09/26 03:16:11 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 6.00	
[09/26 03:16:11 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.24127512582437483
[09/26 03:16:18 visual_prompt]: Epoch 57 / 100: avg data time: 5.22e-02, avg batch time: 0.4941, average train loss: 4.5718
[09/26 03:16:19 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1661, average loss: 4.6042
[09/26 03:16:19 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 7.50	
[09/26 03:16:19 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.23256088156396867
[09/26 03:16:26 visual_prompt]: Epoch 58 / 100: avg data time: 6.08e-02, avg batch time: 0.5010, average train loss: 4.5736
[09/26 03:16:28 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1656, average loss: 4.6547
[09/26 03:16:28 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 6.50	
[09/26 03:16:28 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.22386788418308667
[09/26 03:16:34 visual_prompt]: Epoch 59 / 100: avg data time: 5.71e-02, avg batch time: 0.5004, average train loss: 4.5827
[09/26 03:16:36 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1660, average loss: 4.6297
[09/26 03:16:36 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 4.00	
[09/26 03:16:36 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.2152067247599837
[09/26 03:16:43 visual_prompt]: Epoch 60 / 100: avg data time: 5.72e-02, avg batch time: 0.4985, average train loss: 4.5566
[09/26 03:16:44 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1656, average loss: 4.6485
[09/26 03:16:44 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.00	
[09/26 03:16:44 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.20658795558326742
[09/26 03:16:51 visual_prompt]: Epoch 61 / 100: avg data time: 5.19e-02, avg batch time: 0.4938, average train loss: 4.5687
[09/26 03:16:52 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1657, average loss: 4.6393
[09/26 03:16:52 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/26 03:16:52 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.1980220772955602
[09/26 03:16:59 visual_prompt]: Epoch 62 / 100: avg data time: 4.69e-02, avg batch time: 0.4890, average train loss: 4.5709
[09/26 03:17:01 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1657, average loss: 4.6417
[09/26 03:17:01 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/26 03:17:01 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.1895195261000831
[09/26 03:17:07 visual_prompt]: Epoch 63 / 100: avg data time: 6.18e-02, avg batch time: 0.5030, average train loss: 4.5779
[09/26 03:17:09 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1657, average loss: 4.6355
[09/26 03:17:09 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.50	
[09/26 03:17:09 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.18109066104575022
[09/26 03:17:16 visual_prompt]: Epoch 64 / 100: avg data time: 4.74e-02, avg batch time: 0.4898, average train loss: 4.5714
[09/26 03:17:17 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1657, average loss: 4.6418
[09/26 03:17:17 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 3.50	
[09/26 03:17:17 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.17274575140626316
[09/26 03:17:24 visual_prompt]: Epoch 65 / 100: avg data time: 5.75e-02, avg batch time: 0.4985, average train loss: 4.5703
[09/26 03:17:25 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1658, average loss: 4.6340
[09/26 03:17:25 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.00	
[09/26 03:17:25 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.16449496416858284
[09/26 03:17:32 visual_prompt]: Epoch 66 / 100: avg data time: 5.76e-02, avg batch time: 0.4992, average train loss: 4.5630
[09/26 03:17:34 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1656, average loss: 4.6274
[09/26 03:17:34 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 7.00	
[09/26 03:17:34 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.15634835164602198
[09/26 03:17:40 visual_prompt]: Epoch 67 / 100: avg data time: 5.52e-02, avg batch time: 0.4955, average train loss: 4.5621
[09/26 03:17:42 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1658, average loss: 4.6363
[09/26 03:17:42 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.50	
[09/26 03:17:42 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.14831583923105
[09/26 03:17:49 visual_prompt]: Epoch 68 / 100: avg data time: 5.41e-02, avg batch time: 0.4952, average train loss: 4.5664
[09/26 03:17:50 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1657, average loss: 4.6166
[09/26 03:17:50 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/26 03:17:50 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.14040721330273062
[09/26 03:17:57 visual_prompt]: Epoch 69 / 100: avg data time: 6.03e-02, avg batch time: 0.5017, average train loss: 4.5610
[09/26 03:17:58 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1656, average loss: 4.6282
[09/26 03:17:58 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.00	
[09/26 03:17:58 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.13263210930352737
[09/26 03:18:05 visual_prompt]: Epoch 70 / 100: avg data time: 5.77e-02, avg batch time: 0.4992, average train loss: 4.5511
[09/26 03:18:07 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1658, average loss: 4.6126
[09/26 03:18:07 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 6.00	
[09/26 03:18:07 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.12500000000000006
[09/26 03:18:13 visual_prompt]: Epoch 71 / 100: avg data time: 5.25e-02, avg batch time: 0.4948, average train loss: 4.5392
[09/26 03:18:15 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1657, average loss: 4.5789
[09/26 03:18:15 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 7.50	
[09/26 03:18:15 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.1175201839416988
[09/26 03:18:22 visual_prompt]: Epoch 72 / 100: avg data time: 6.40e-02, avg batch time: 0.5044, average train loss: 4.4926
[09/26 03:18:23 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1659, average loss: 4.6018
[09/26 03:18:23 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 6.50	
[09/26 03:18:23 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.11020177413231333
[09/26 03:18:30 visual_prompt]: Epoch 73 / 100: avg data time: 5.44e-02, avg batch time: 0.4964, average train loss: 4.4744
[09/26 03:18:31 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1658, average loss: 4.5659
[09/26 03:18:31 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.50	top5: 9.00	
[09/26 03:18:31 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.10305368692688174
[09/26 03:18:38 visual_prompt]: Epoch 74 / 100: avg data time: 6.42e-02, avg batch time: 0.5048, average train loss: 4.4109
[09/26 03:18:40 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1660, average loss: 4.5976
[09/26 03:18:40 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 6.50	
[09/26 03:18:40 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.09608463116858543
[09/26 03:18:46 visual_prompt]: Epoch 75 / 100: avg data time: 5.58e-02, avg batch time: 0.4964, average train loss: 4.5110
[09/26 03:18:48 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1657, average loss: 4.5962
[09/26 03:18:48 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 6.00	
[09/26 03:18:48 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.08930309757836516
[09/26 03:18:55 visual_prompt]: Epoch 76 / 100: avg data time: 5.38e-02, avg batch time: 0.4958, average train loss: 4.4888
[09/26 03:18:56 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1658, average loss: 4.6208
[09/26 03:18:56 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 7.50	
[09/26 03:18:56 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.08271734841028552
[09/26 03:19:03 visual_prompt]: Epoch 77 / 100: avg data time: 5.73e-02, avg batch time: 0.4989, average train loss: 4.4056
[09/26 03:19:04 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1656, average loss: 4.5907
[09/26 03:19:04 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 10.00	
[09/26 03:19:04 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.07633540738525066
[09/26 03:19:11 visual_prompt]: Epoch 78 / 100: avg data time: 5.68e-02, avg batch time: 0.4983, average train loss: 4.3915
[09/26 03:19:13 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1658, average loss: 4.7585
[09/26 03:19:13 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 10.00	
[09/26 03:19:13 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.07016504991533726
[09/26 03:19:19 visual_prompt]: Epoch 79 / 100: avg data time: 4.61e-02, avg batch time: 0.4883, average train loss: 4.4734
[09/26 03:19:21 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1656, average loss: 4.6394
[09/26 03:19:21 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 6.00	
[09/26 03:19:21 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.06421379363065141
[09/26 03:19:28 visual_prompt]: Epoch 80 / 100: avg data time: 5.61e-02, avg batch time: 0.4973, average train loss: 4.5670
[09/26 03:19:29 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1658, average loss: 4.6146
[09/26 03:19:29 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 7.00	
[09/26 03:19:29 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.058488889220255524
[09/26 03:19:36 visual_prompt]: Epoch 81 / 100: avg data time: 4.95e-02, avg batch time: 0.4914, average train loss: 4.5534
[09/26 03:19:37 visual_prompt]: Inference (val):avg data time: 1.99e-05, avg batch time: 0.1654, average loss: 4.6389
[09/26 03:19:37 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.00	
[09/26 03:19:37 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.052997311598319524
[09/26 03:19:44 visual_prompt]: Epoch 82 / 100: avg data time: 5.45e-02, avg batch time: 0.4948, average train loss: 4.5536
[09/26 03:19:45 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1658, average loss: 4.6351
[09/26 03:19:45 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.00	
[09/26 03:19:45 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.047745751406263165
[09/26 03:19:52 visual_prompt]: Epoch 83 / 100: avg data time: 5.66e-02, avg batch time: 0.4980, average train loss: 4.4843
[09/26 03:19:54 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.1658, average loss: 4.5755
[09/26 03:19:54 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 7.50	
[09/26 03:19:54 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.042740606861239594
[09/26 03:20:00 visual_prompt]: Epoch 84 / 100: avg data time: 5.18e-02, avg batch time: 0.4934, average train loss: 4.4482
[09/26 03:20:02 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1660, average loss: 4.5639
[09/26 03:20:02 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 8.50	
[09/26 03:20:02 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.03798797596089351
[09/26 03:20:09 visual_prompt]: Epoch 85 / 100: avg data time: 5.48e-02, avg batch time: 0.4961, average train loss: 4.3981
[09/26 03:20:10 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1660, average loss: 4.5206
[09/26 03:20:10 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 9.50	
[09/26 03:20:10 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.03349364905389032
[09/26 03:20:17 visual_prompt]: Epoch 86 / 100: avg data time: 4.83e-02, avg batch time: 0.4904, average train loss: 4.3643
[09/26 03:20:18 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1661, average loss: 4.4897
[09/26 03:20:18 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 12.50	
[09/26 03:20:18 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.029263101785268253
[09/26 03:20:25 visual_prompt]: Epoch 87 / 100: avg data time: 5.85e-02, avg batch time: 0.4997, average train loss: 4.3408
[09/26 03:20:27 visual_prompt]: Inference (val):avg data time: 1.95e-05, avg batch time: 0.1659, average loss: 4.5065
[09/26 03:20:27 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 10.50	
[09/26 03:20:27 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.025301488425208296
[09/26 03:20:33 visual_prompt]: Epoch 88 / 100: avg data time: 5.45e-02, avg batch time: 0.4968, average train loss: 4.3204
[09/26 03:20:35 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1659, average loss: 4.4970
[09/26 03:20:35 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 13.50	
[09/26 03:20:35 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.021613635589349756
[09/26 03:20:42 visual_prompt]: Epoch 89 / 100: avg data time: 4.93e-02, avg batch time: 0.4904, average train loss: 4.3199
[09/26 03:20:43 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1662, average loss: 4.5171
[09/26 03:20:43 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 9.00	
[09/26 03:20:43 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.01820403635830317
[09/26 03:20:50 visual_prompt]: Epoch 90 / 100: avg data time: 5.71e-02, avg batch time: 0.4992, average train loss: 4.2987
[09/26 03:20:51 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1661, average loss: 4.5182
[09/26 03:20:51 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 10.50	
[09/26 03:20:51 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.01507684480352292
[09/26 03:20:58 visual_prompt]: Epoch 91 / 100: avg data time: 5.50e-02, avg batch time: 0.4975, average train loss: 4.2804
[09/26 03:21:00 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1664, average loss: 4.5372
[09/26 03:21:00 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 10.50	
[09/26 03:21:00 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.012235870926211617
[09/26 03:21:07 visual_prompt]: Epoch 92 / 100: avg data time: 6.76e-02, avg batch time: 0.5095, average train loss: 4.2504
[09/26 03:21:08 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1660, average loss: 4.4982
[09/26 03:21:08 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 12.50	
[09/26 03:21:08 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.009684576015420276
[09/26 03:21:15 visual_prompt]: Epoch 93 / 100: avg data time: 4.84e-02, avg batch time: 0.4924, average train loss: 4.2348
[09/26 03:21:16 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1662, average loss: 4.5605
[09/26 03:21:16 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 10.00	
[09/26 03:21:16 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.007426068431000882
[09/26 03:21:23 visual_prompt]: Epoch 94 / 100: avg data time: 4.64e-02, avg batch time: 0.4890, average train loss: 4.2276
[09/26 03:21:24 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1663, average loss: 4.4802
[09/26 03:21:24 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 13.00	
[09/26 03:21:24 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.005463099816548578
[09/26 03:21:31 visual_prompt]: Epoch 95 / 100: avg data time: 5.97e-02, avg batch time: 0.5006, average train loss: 4.2006
[09/26 03:21:33 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1661, average loss: 4.4921
[09/26 03:21:33 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 11.50	
[09/26 03:21:33 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.003798061746947995
[09/26 03:21:39 visual_prompt]: Epoch 96 / 100: avg data time: 4.41e-02, avg batch time: 0.4870, average train loss: 4.1713
[09/26 03:21:41 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1664, average loss: 4.4753
[09/26 03:21:41 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 14.50	
[09/26 03:21:41 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.0024329828146074095
[09/26 03:21:48 visual_prompt]: Epoch 97 / 100: avg data time: 6.18e-02, avg batch time: 0.5045, average train loss: 4.1631
[09/26 03:21:49 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1662, average loss: 4.4744
[09/26 03:21:49 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 14.50	
[09/26 03:21:49 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.0013695261579316775
[09/26 03:21:56 visual_prompt]: Epoch 98 / 100: avg data time: 5.46e-02, avg batch time: 0.4960, average train loss: 4.1609
[09/26 03:21:57 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1663, average loss: 4.4837
[09/26 03:21:57 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 12.50	
[09/26 03:21:57 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.0006089874350439506
[09/26 03:22:04 visual_prompt]: Epoch 99 / 100: avg data time: 5.55e-02, avg batch time: 0.4981, average train loss: 4.1572
[09/26 03:22:06 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1660, average loss: 4.4717
[09/26 03:22:06 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 13.50	
[09/26 03:22:06 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.00015229324522605947
[09/26 03:22:12 visual_prompt]: Epoch 100 / 100: avg data time: 6.02e-02, avg batch time: 0.5023, average train loss: 4.1463
[09/26 03:22:14 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1660, average loss: 4.4717
[09/26 03:22:14 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 13.50	
[09/26 03:22:14 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 03:22:14 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 03:22:14 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-cifar(num_classes=100)', 'DATA.NUMBER_CLASSES', '100', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 03:22:14 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 03:22:14 visual_prompt]: Training with config:
[09/26 03:22:14 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-cifar(num_classes=100)/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.5_wd0.001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 0.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-cifar(num_classes=100)', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 100, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 03:22:14 visual_prompt]: Loading training data...
[09/26 03:22:14 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[:800], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/26 03:22:15 visual_prompt]: Number of images: 800
[09/26 03:22:15 visual_prompt]: Number of classes: 100 / 100
[09/26 03:22:15 visual_prompt]: Loading validation data...
[09/26 03:22:15 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[45000:45200], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/26 03:22:15 visual_prompt]: Number of images: 200
[09/26 03:22:15 visual_prompt]: Number of classes: 90 / 100
[09/26 03:22:15 visual_prompt]: Constructing models...
[09/26 03:22:18 visual_prompt]: Total Parameters: 86336356	 Gradient Parameters: 537700
[09/26 03:22:18 visual_prompt]: tuned percent:0.623
[09/26 03:22:18 visual_prompt]: Device used for model: 0
[09/26 03:22:18 visual_prompt]: Setting up Evaluator...
[09/26 03:22:18 visual_prompt]: Setting up Trainer...
[09/26 03:22:18 visual_prompt]: 	Setting up the optimizer...
[09/26 03:22:18 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 03:22:24 visual_prompt]: Epoch 1 / 100: avg data time: 4.62e-02, avg batch time: 0.4904, average train loss: 4.6584
[09/26 03:22:26 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1660, average loss: 4.6218
[09/26 03:22:26 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 7.00	
[09/26 03:22:26 visual_prompt]: Best epoch 1: best metric: 0.010
[09/26 03:22:26 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.05
[09/26 03:22:33 visual_prompt]: Epoch 2 / 100: avg data time: 4.36e-02, avg batch time: 0.4847, average train loss: 4.6278
[09/26 03:22:34 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1660, average loss: 4.6080
[09/26 03:22:34 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.50	
[09/26 03:22:34 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.1
[09/26 03:22:41 visual_prompt]: Epoch 3 / 100: avg data time: 4.35e-02, avg batch time: 0.4869, average train loss: 4.5847
[09/26 03:22:42 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1660, average loss: 4.6247
[09/26 03:22:42 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 5.00	
[09/26 03:22:42 visual_prompt]: Best epoch 3: best metric: 0.015
[09/26 03:22:42 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.15
[09/26 03:22:49 visual_prompt]: Epoch 4 / 100: avg data time: 6.18e-02, avg batch time: 0.5041, average train loss: 4.5663
[09/26 03:22:51 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1661, average loss: 4.6006
[09/26 03:22:51 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 9.50	
[09/26 03:22:51 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.2
[09/26 03:22:57 visual_prompt]: Epoch 5 / 100: avg data time: 5.87e-02, avg batch time: 0.4998, average train loss: 4.4865
[09/26 03:22:59 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1659, average loss: 4.5097
[09/26 03:22:59 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 3.00	top5: 13.50	
[09/26 03:22:59 visual_prompt]: Best epoch 5: best metric: 0.030
[09/26 03:22:59 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.25
[09/26 03:23:06 visual_prompt]: Epoch 6 / 100: avg data time: 6.14e-02, avg batch time: 0.5028, average train loss: 4.2090
[09/26 03:23:07 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1661, average loss: 4.2077
[09/26 03:23:07 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 3.50	top5: 16.50	
[09/26 03:23:07 visual_prompt]: Best epoch 6: best metric: 0.035
[09/26 03:23:07 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.3
[09/26 03:23:14 visual_prompt]: Epoch 7 / 100: avg data time: 6.31e-02, avg batch time: 0.5042, average train loss: 3.6858
[09/26 03:23:16 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1662, average loss: 3.9461
[09/26 03:23:16 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 8.50	top5: 26.50	
[09/26 03:23:16 visual_prompt]: Best epoch 7: best metric: 0.085
[09/26 03:23:16 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.35
[09/26 03:23:22 visual_prompt]: Epoch 8 / 100: avg data time: 4.62e-02, avg batch time: 0.4895, average train loss: 3.0965
[09/26 03:23:24 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1662, average loss: 3.1709
[09/26 03:23:24 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 18.50	top5: 50.50	
[09/26 03:23:24 visual_prompt]: Best epoch 8: best metric: 0.185
[09/26 03:23:24 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.4
[09/26 03:23:31 visual_prompt]: Epoch 9 / 100: avg data time: 4.36e-02, avg batch time: 0.4867, average train loss: 2.5851
[09/26 03:23:32 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1663, average loss: 2.4956
[09/26 03:23:32 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 33.50	top5: 70.00	
[09/26 03:23:32 visual_prompt]: Best epoch 9: best metric: 0.335
[09/26 03:23:32 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.45
[09/26 03:23:39 visual_prompt]: Epoch 10 / 100: avg data time: 5.51e-02, avg batch time: 0.4965, average train loss: 1.4551
[09/26 03:23:40 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1666, average loss: 1.7670
[09/26 03:23:40 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 55.50	top5: 83.50	
[09/26 03:23:40 visual_prompt]: Best epoch 10: best metric: 0.555
[09/26 03:23:40 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.5
[09/26 03:23:47 visual_prompt]: Epoch 11 / 100: avg data time: 5.78e-02, avg batch time: 0.4994, average train loss: 0.6457
[09/26 03:23:49 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1663, average loss: 1.7011
[09/26 03:23:49 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 85.50	
[09/26 03:23:49 visual_prompt]: Best epoch 11: best metric: 0.580
[09/26 03:23:49 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.49984770675477397
[09/26 03:23:55 visual_prompt]: Epoch 12 / 100: avg data time: 4.84e-02, avg batch time: 0.4901, average train loss: 0.3321
[09/26 03:23:57 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1664, average loss: 1.2293
[09/26 03:23:57 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.50	top5: 93.00	
[09/26 03:23:57 visual_prompt]: Best epoch 12: best metric: 0.655
[09/26 03:23:57 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.49939101256495605
[09/26 03:24:03 visual_prompt]: Epoch 13 / 100: avg data time: 5.38e-02, avg batch time: 0.4960, average train loss: 0.1323
[09/26 03:24:05 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1663, average loss: 1.0970
[09/26 03:24:05 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 73.00	top5: 92.00	
[09/26 03:24:05 visual_prompt]: Best epoch 13: best metric: 0.730
[09/26 03:24:05 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.4986304738420683
[09/26 03:24:12 visual_prompt]: Epoch 14 / 100: avg data time: 5.80e-02, avg batch time: 0.5000, average train loss: 0.0858
[09/26 03:24:13 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1664, average loss: 1.2028
[09/26 03:24:13 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.00	top5: 90.50	
[09/26 03:24:13 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.4975670171853926
[09/26 03:24:20 visual_prompt]: Epoch 15 / 100: avg data time: 6.40e-02, avg batch time: 0.5056, average train loss: 0.0607
[09/26 03:24:22 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1664, average loss: 1.0803
[09/26 03:24:22 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 72.00	top5: 93.50	
[09/26 03:24:22 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.49620193825305203
[09/26 03:24:29 visual_prompt]: Epoch 16 / 100: avg data time: 5.94e-02, avg batch time: 0.5013, average train loss: 0.0534
[09/26 03:24:30 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1663, average loss: 1.0739
[09/26 03:24:30 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 70.50	top5: 93.50	
[09/26 03:24:30 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.4945369001834514
[09/26 03:24:37 visual_prompt]: Epoch 17 / 100: avg data time: 4.77e-02, avg batch time: 0.4902, average train loss: 0.0496
[09/26 03:24:38 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1662, average loss: 1.0894
[09/26 03:24:38 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 71.00	top5: 94.00	
[09/26 03:24:38 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.4925739315689991
[09/26 03:24:45 visual_prompt]: Epoch 18 / 100: avg data time: 4.87e-02, avg batch time: 0.4915, average train loss: 0.0494
[09/26 03:24:47 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1662, average loss: 1.0817
[09/26 03:24:47 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 71.50	top5: 95.00	
[09/26 03:24:47 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.4903154239845797
[09/26 03:24:53 visual_prompt]: Epoch 19 / 100: avg data time: 5.39e-02, avg batch time: 0.4961, average train loss: 0.0485
[09/26 03:24:55 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1664, average loss: 1.0548
[09/26 03:24:55 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 71.50	top5: 95.50	
[09/26 03:24:55 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.4877641290737884
[09/26 03:25:02 visual_prompt]: Epoch 20 / 100: avg data time: 5.88e-02, avg batch time: 0.5011, average train loss: 0.0480
[09/26 03:25:03 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1661, average loss: 1.0666
[09/26 03:25:03 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 72.50	top5: 95.00	
[09/26 03:25:03 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.4849231551964771
[09/26 03:25:10 visual_prompt]: Epoch 21 / 100: avg data time: 5.83e-02, avg batch time: 0.5017, average train loss: 0.0490
[09/26 03:25:12 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.1662, average loss: 1.0261
[09/26 03:25:12 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 73.00	top5: 95.50	
[09/26 03:25:12 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.48179596364169686
[09/26 03:25:18 visual_prompt]: Epoch 22 / 100: avg data time: 5.83e-02, avg batch time: 0.4997, average train loss: 0.0492
[09/26 03:25:20 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1661, average loss: 1.0672
[09/26 03:25:20 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 71.00	top5: 95.00	
[09/26 03:25:20 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.4783863644106502
[09/26 03:25:27 visual_prompt]: Epoch 23 / 100: avg data time: 4.67e-02, avg batch time: 0.4918, average train loss: 0.0507
[09/26 03:25:28 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1663, average loss: 1.1162
[09/26 03:25:28 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 68.50	top5: 94.50	
[09/26 03:25:28 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.47469851157479176
[09/26 03:25:35 visual_prompt]: Epoch 24 / 100: avg data time: 4.97e-02, avg batch time: 0.4925, average train loss: 0.0508
[09/26 03:25:36 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1663, average loss: 1.0982
[09/26 03:25:36 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 70.00	top5: 95.50	
[09/26 03:25:36 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.47073689821473175
[09/26 03:25:43 visual_prompt]: Epoch 25 / 100: avg data time: 4.67e-02, avg batch time: 0.4884, average train loss: 0.0502
[09/26 03:25:45 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1664, average loss: 1.1158
[09/26 03:25:45 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 72.00	top5: 95.00	
[09/26 03:25:45 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.4665063509461097
[09/26 03:25:51 visual_prompt]: Epoch 26 / 100: avg data time: 5.52e-02, avg batch time: 0.4965, average train loss: 0.0535
[09/26 03:25:53 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1664, average loss: 1.0918
[09/26 03:25:53 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 72.00	top5: 95.50	
[09/26 03:25:53 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.46201202403910646
[09/26 03:26:00 visual_prompt]: Epoch 27 / 100: avg data time: 4.64e-02, avg batch time: 0.4886, average train loss: 0.0691
[09/26 03:26:01 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1665, average loss: 1.3713
[09/26 03:26:01 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 69.00	top5: 89.00	
[09/26 03:26:01 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.4572593931387604
[09/26 03:26:08 visual_prompt]: Epoch 28 / 100: avg data time: 5.31e-02, avg batch time: 0.4950, average train loss: 0.2022
[09/26 03:26:09 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1662, average loss: 1.3703
[09/26 03:26:09 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 70.00	top5: 89.50	
[09/26 03:26:09 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.45225424859373686
[09/26 03:26:16 visual_prompt]: Epoch 29 / 100: avg data time: 5.45e-02, avg batch time: 0.4966, average train loss: 0.4272
[09/26 03:26:18 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1664, average loss: 1.2751
[09/26 03:26:18 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 73.00	top5: 91.00	
[09/26 03:26:18 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.44700268840168045
[09/26 03:26:24 visual_prompt]: Epoch 30 / 100: avg data time: 4.51e-02, avg batch time: 0.4889, average train loss: 0.5457
[09/26 03:26:26 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1661, average loss: 1.1294
[09/26 03:26:26 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 74.00	top5: 94.00	
[09/26 03:26:26 visual_prompt]: Best epoch 30: best metric: 0.740
[09/26 03:26:26 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.4415111107797445
[09/26 03:26:32 visual_prompt]: Epoch 31 / 100: avg data time: 5.73e-02, avg batch time: 0.4984, average train loss: 0.1803
[09/26 03:26:34 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1662, average loss: 0.9623
[09/26 03:26:34 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 77.00	top5: 93.50	
[09/26 03:26:34 visual_prompt]: Best epoch 31: best metric: 0.770
[09/26 03:26:34 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.43578620636934856
[09/26 03:26:41 visual_prompt]: Epoch 32 / 100: avg data time: 4.09e-02, avg batch time: 0.4852, average train loss: 0.0778
[09/26 03:26:42 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1663, average loss: 0.9254
[09/26 03:26:42 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 77.00	top5: 95.50	
[09/26 03:26:42 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.42983495008466277
[09/26 03:26:49 visual_prompt]: Epoch 33 / 100: avg data time: 4.82e-02, avg batch time: 0.4923, average train loss: 0.0484
[09/26 03:26:50 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1663, average loss: 0.8341
[09/26 03:26:50 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 79.00	top5: 95.00	
[09/26 03:26:50 visual_prompt]: Best epoch 33: best metric: 0.790
[09/26 03:26:50 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.4236645926147493
[09/26 03:26:57 visual_prompt]: Epoch 34 / 100: avg data time: 5.01e-02, avg batch time: 0.4949, average train loss: 0.0382
[09/26 03:26:58 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1663, average loss: 0.8410
[09/26 03:26:58 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 78.50	top5: 96.00	
[09/26 03:26:58 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.41728265158971456
[09/26 03:27:05 visual_prompt]: Epoch 35 / 100: avg data time: 5.47e-02, avg batch time: 0.4978, average train loss: 0.0350
[09/26 03:27:07 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1671, average loss: 0.8683
[09/26 03:27:07 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 78.50	top5: 95.00	
[09/26 03:27:07 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.4106969024216348
[09/26 03:27:13 visual_prompt]: Epoch 36 / 100: avg data time: 4.65e-02, avg batch time: 0.4897, average train loss: 0.0346
[09/26 03:27:15 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1664, average loss: 0.8501
[09/26 03:27:15 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 77.50	top5: 95.00	
[09/26 03:27:15 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.40391536883141455
[09/26 03:27:22 visual_prompt]: Epoch 37 / 100: avg data time: 5.70e-02, avg batch time: 0.5007, average train loss: 0.0351
[09/26 03:27:23 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1667, average loss: 0.9016
[09/26 03:27:23 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 78.50	top5: 95.50	
[09/26 03:27:23 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.3969463130731183
[09/26 03:27:30 visual_prompt]: Epoch 38 / 100: avg data time: 4.36e-02, avg batch time: 0.4861, average train loss: 0.0362
[09/26 03:27:31 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1664, average loss: 0.8801
[09/26 03:27:31 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 79.50	top5: 95.00	
[09/26 03:27:31 visual_prompt]: Best epoch 38: best metric: 0.795
[09/26 03:27:31 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.3897982258676867
[09/26 03:27:38 visual_prompt]: Epoch 39 / 100: avg data time: 4.68e-02, avg batch time: 0.4894, average train loss: 0.0368
[09/26 03:27:40 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1664, average loss: 0.8925
[09/26 03:27:40 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 77.00	top5: 95.00	
[09/26 03:27:40 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.3824798160583012
[09/26 03:27:46 visual_prompt]: Epoch 40 / 100: avg data time: 5.02e-02, avg batch time: 0.4929, average train loss: 0.0369
[09/26 03:27:48 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1663, average loss: 0.8982
[09/26 03:27:48 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 77.00	top5: 95.50	
[09/26 03:27:48 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.375
[09/26 03:27:55 visual_prompt]: Epoch 41 / 100: avg data time: 5.22e-02, avg batch time: 0.4954, average train loss: 0.0370
[09/26 03:27:56 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1663, average loss: 0.9292
[09/26 03:27:56 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 77.00	top5: 94.50	
[09/26 03:27:56 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.3673678906964727
[09/26 03:28:03 visual_prompt]: Epoch 42 / 100: avg data time: 5.23e-02, avg batch time: 0.4949, average train loss: 0.0376
[09/26 03:28:04 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1665, average loss: 0.9234
[09/26 03:28:04 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 78.00	top5: 95.00	
[09/26 03:28:04 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.35959278669726935
[09/26 03:28:11 visual_prompt]: Epoch 43 / 100: avg data time: 5.71e-02, avg batch time: 0.4995, average train loss: 0.0375
[09/26 03:28:13 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1661, average loss: 0.9845
[09/26 03:28:13 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 77.00	top5: 95.00	
[09/26 03:28:13 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.3516841607689501
[09/26 03:28:19 visual_prompt]: Epoch 44 / 100: avg data time: 6.19e-02, avg batch time: 0.5060, average train loss: 0.0371
[09/26 03:28:21 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1662, average loss: 0.9739
[09/26 03:28:21 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 78.00	top5: 94.50	
[09/26 03:28:21 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.34365164835397805
[09/26 03:28:28 visual_prompt]: Epoch 45 / 100: avg data time: 6.10e-02, avg batch time: 0.5031, average train loss: 0.0373
[09/26 03:28:29 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1665, average loss: 0.9368
[09/26 03:28:29 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 77.00	top5: 95.00	
[09/26 03:28:29 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.3355050358314172
[09/26 03:28:36 visual_prompt]: Epoch 46 / 100: avg data time: 5.30e-02, avg batch time: 0.4967, average train loss: 0.0364
[09/26 03:28:38 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1663, average loss: 0.9375
[09/26 03:28:38 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 78.00	top5: 95.00	
[09/26 03:28:38 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.32725424859373686
[09/26 03:28:45 visual_prompt]: Epoch 47 / 100: avg data time: 6.01e-02, avg batch time: 0.5021, average train loss: 0.0352
[09/26 03:28:46 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1662, average loss: 0.9754
[09/26 03:28:46 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 77.00	top5: 95.00	
[09/26 03:28:46 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.3189093389542498
[09/26 03:28:53 visual_prompt]: Epoch 48 / 100: avg data time: 5.40e-02, avg batch time: 0.4980, average train loss: 0.0346
[09/26 03:28:54 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1663, average loss: 0.9600
[09/26 03:28:54 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 79.50	top5: 95.00	
[09/26 03:28:54 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.3104804738999169
[09/26 03:29:01 visual_prompt]: Epoch 49 / 100: avg data time: 5.54e-02, avg batch time: 0.4972, average train loss: 0.0343
[09/26 03:29:02 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1662, average loss: 0.9945
[09/26 03:29:02 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 76.50	top5: 94.00	
[09/26 03:29:02 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.3019779227044398
[09/26 03:29:09 visual_prompt]: Epoch 50 / 100: avg data time: 5.15e-02, avg batch time: 0.4951, average train loss: 0.0337
[09/26 03:29:11 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1662, average loss: 0.9850
[09/26 03:29:11 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 76.00	top5: 95.00	
[09/26 03:29:11 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.29341204441673263
[09/26 03:29:17 visual_prompt]: Epoch 51 / 100: avg data time: 5.43e-02, avg batch time: 0.4981, average train loss: 0.0335
[09/26 03:29:19 visual_prompt]: Inference (val):avg data time: 2.01e-05, avg batch time: 0.1663, average loss: 0.9259
[09/26 03:29:19 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 77.00	top5: 95.00	
[09/26 03:29:19 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.28479327524001635
[09/26 03:29:26 visual_prompt]: Epoch 52 / 100: avg data time: 4.82e-02, avg batch time: 0.4908, average train loss: 0.0344
[09/26 03:29:27 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1663, average loss: 0.9517
[09/26 03:29:27 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 79.50	top5: 94.00	
[09/26 03:29:27 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.2761321158169134
[09/26 03:29:34 visual_prompt]: Epoch 53 / 100: avg data time: 5.80e-02, avg batch time: 0.4999, average train loss: 0.0334
[09/26 03:29:35 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1662, average loss: 0.9862
[09/26 03:29:35 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 78.50	top5: 95.00	
[09/26 03:29:35 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.2674391184360313
[09/26 03:29:42 visual_prompt]: Epoch 54 / 100: avg data time: 4.40e-02, avg batch time: 0.4874, average train loss: 0.0328
[09/26 03:29:44 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1665, average loss: 0.9892
[09/26 03:29:44 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 79.00	top5: 93.50	
[09/26 03:29:44 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.2587248741756253
[09/26 03:29:50 visual_prompt]: Epoch 55 / 100: avg data time: 5.30e-02, avg batch time: 0.4959, average train loss: 0.0330
[09/26 03:29:52 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1662, average loss: 0.9268
[09/26 03:29:52 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 77.00	top5: 95.00	
[09/26 03:29:52 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.25
[09/26 03:29:59 visual_prompt]: Epoch 56 / 100: avg data time: 6.32e-02, avg batch time: 0.5058, average train loss: 0.0332
[09/26 03:30:00 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1665, average loss: 0.9759
[09/26 03:30:00 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 76.50	top5: 95.00	
[09/26 03:30:00 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.24127512582437483
[09/26 03:30:07 visual_prompt]: Epoch 57 / 100: avg data time: 6.20e-02, avg batch time: 0.5036, average train loss: 0.0329
[09/26 03:30:09 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1665, average loss: 0.9715
[09/26 03:30:09 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 77.00	top5: 94.50	
[09/26 03:30:09 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.23256088156396867
[09/26 03:30:15 visual_prompt]: Epoch 58 / 100: avg data time: 6.14e-02, avg batch time: 0.5034, average train loss: 0.0325
[09/26 03:30:17 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1663, average loss: 0.9547
[09/26 03:30:17 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 79.00	top5: 95.00	
[09/26 03:30:17 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.22386788418308667
[09/26 03:30:24 visual_prompt]: Epoch 59 / 100: avg data time: 6.19e-02, avg batch time: 0.5036, average train loss: 0.0318
[09/26 03:30:25 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1663, average loss: 0.9621
[09/26 03:30:25 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 76.50	top5: 95.00	
[09/26 03:30:25 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.2152067247599837
[09/26 03:30:32 visual_prompt]: Epoch 60 / 100: avg data time: 5.43e-02, avg batch time: 0.4965, average train loss: 0.0312
[09/26 03:30:33 visual_prompt]: Inference (val):avg data time: 2.08e-05, avg batch time: 0.1662, average loss: 0.9548
[09/26 03:30:33 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 79.00	top5: 94.50	
[09/26 03:30:33 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.20658795558326742
[09/26 03:30:40 visual_prompt]: Epoch 61 / 100: avg data time: 4.99e-02, avg batch time: 0.4933, average train loss: 0.0312
[09/26 03:30:42 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1666, average loss: 0.9708
[09/26 03:30:42 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 78.00	top5: 94.50	
[09/26 03:30:42 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.1980220772955602
[09/26 03:30:48 visual_prompt]: Epoch 62 / 100: avg data time: 6.23e-02, avg batch time: 0.5043, average train loss: 0.0309
[09/26 03:30:50 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1663, average loss: 0.9923
[09/26 03:30:50 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 78.00	top5: 95.00	
[09/26 03:30:50 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.1895195261000831
[09/26 03:30:57 visual_prompt]: Epoch 63 / 100: avg data time: 5.66e-02, avg batch time: 0.4988, average train loss: 0.0303
[09/26 03:30:58 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1662, average loss: 0.9877
[09/26 03:30:58 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 77.50	top5: 94.00	
[09/26 03:30:58 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.18109066104575022
[09/26 03:31:05 visual_prompt]: Epoch 64 / 100: avg data time: 5.42e-02, avg batch time: 0.4969, average train loss: 0.0301
[09/26 03:31:06 visual_prompt]: Inference (val):avg data time: 4.07e-05, avg batch time: 0.1663, average loss: 0.9642
[09/26 03:31:06 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 78.50	top5: 95.00	
[09/26 03:31:06 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.17274575140626316
[09/26 03:31:13 visual_prompt]: Epoch 65 / 100: avg data time: 6.16e-02, avg batch time: 0.5036, average train loss: 0.0294
[09/26 03:31:15 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1662, average loss: 0.9884
[09/26 03:31:15 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 77.50	top5: 94.50	
[09/26 03:31:15 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.16449496416858284
[09/26 03:31:21 visual_prompt]: Epoch 66 / 100: avg data time: 4.54e-02, avg batch time: 0.4909, average train loss: 0.0295
[09/26 03:31:23 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1662, average loss: 1.0011
[09/26 03:31:23 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 77.00	top5: 95.00	
[09/26 03:31:23 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.15634835164602198
[09/26 03:31:30 visual_prompt]: Epoch 67 / 100: avg data time: 5.41e-02, avg batch time: 0.4959, average train loss: 0.0292
[09/26 03:31:31 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1662, average loss: 0.9821
[09/26 03:31:31 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 77.50	top5: 95.00	
[09/26 03:31:31 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.14831583923105
[09/26 03:31:38 visual_prompt]: Epoch 68 / 100: avg data time: 6.32e-02, avg batch time: 0.5046, average train loss: 0.0291
[09/26 03:31:40 visual_prompt]: Inference (val):avg data time: 2.11e-05, avg batch time: 0.1661, average loss: 1.0111
[09/26 03:31:40 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 77.50	top5: 95.00	
[09/26 03:31:40 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.14040721330273062
[09/26 03:31:46 visual_prompt]: Epoch 69 / 100: avg data time: 4.82e-02, avg batch time: 0.4925, average train loss: 0.0292
[09/26 03:31:48 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1663, average loss: 0.9982
[09/26 03:31:48 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 77.50	top5: 94.50	
[09/26 03:31:48 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.13263210930352737
[09/26 03:31:55 visual_prompt]: Epoch 70 / 100: avg data time: 5.83e-02, avg batch time: 0.5010, average train loss: 0.0291
[09/26 03:31:56 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1665, average loss: 0.9970
[09/26 03:31:56 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 77.50	top5: 95.00	
[09/26 03:31:56 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.12500000000000006
[09/26 03:32:03 visual_prompt]: Epoch 71 / 100: avg data time: 5.49e-02, avg batch time: 0.4985, average train loss: 0.0290
[09/26 03:32:04 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1667, average loss: 1.0317
[09/26 03:32:04 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 76.50	top5: 94.50	
[09/26 03:32:04 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.1175201839416988
[09/26 03:32:11 visual_prompt]: Epoch 72 / 100: avg data time: 5.76e-02, avg batch time: 0.4993, average train loss: 0.0291
[09/26 03:32:13 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1666, average loss: 1.0186
[09/26 03:32:13 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 77.00	top5: 95.00	
[09/26 03:32:13 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.11020177413231333
[09/26 03:32:19 visual_prompt]: Epoch 73 / 100: avg data time: 5.19e-02, avg batch time: 0.4957, average train loss: 0.0295
[09/26 03:32:21 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1664, average loss: 1.1241
[09/26 03:32:21 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 74.00	top5: 93.00	
[09/26 03:32:21 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.10305368692688174
[09/26 03:32:28 visual_prompt]: Epoch 74 / 100: avg data time: 5.29e-02, avg batch time: 0.4967, average train loss: 0.0326
[09/26 03:32:29 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1664, average loss: 1.4651
[09/26 03:32:29 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.50	top5: 90.00	
[09/26 03:32:29 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.09608463116858543
[09/26 03:32:36 visual_prompt]: Epoch 75 / 100: avg data time: 5.93e-02, avg batch time: 0.5012, average train loss: 1.7520
[09/26 03:32:37 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1663, average loss: 3.2952
[09/26 03:32:37 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 24.50	top5: 57.50	
[09/26 03:32:37 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.08930309757836516
[09/26 03:32:44 visual_prompt]: Epoch 76 / 100: avg data time: 5.82e-02, avg batch time: 0.5006, average train loss: 1.3118
[09/26 03:32:46 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1666, average loss: 1.3695
[09/26 03:32:46 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 76.00	top5: 94.50	
[09/26 03:32:46 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.08271734841028552
[09/26 03:32:53 visual_prompt]: Epoch 77 / 100: avg data time: 6.02e-02, avg batch time: 0.5031, average train loss: 0.5562
[09/26 03:32:54 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1666, average loss: 1.0947
[09/26 03:32:54 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 79.50	top5: 96.00	
[09/26 03:32:54 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.07633540738525066
[09/26 03:33:01 visual_prompt]: Epoch 78 / 100: avg data time: 5.42e-02, avg batch time: 0.4960, average train loss: 0.3025
[09/26 03:33:02 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1664, average loss: 0.9956
[09/26 03:33:02 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 79.50	top5: 95.50	
[09/26 03:33:02 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.07016504991533726
[09/26 03:33:09 visual_prompt]: Epoch 79 / 100: avg data time: 5.54e-02, avg batch time: 0.4987, average train loss: 0.1813
[09/26 03:33:11 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.1664, average loss: 0.8968
[09/26 03:33:11 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 81.50	top5: 96.00	
[09/26 03:33:11 visual_prompt]: Best epoch 79: best metric: 0.815
[09/26 03:33:11 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.06421379363065141
[09/26 03:33:17 visual_prompt]: Epoch 80 / 100: avg data time: 6.11e-02, avg batch time: 0.5038, average train loss: 0.1230
[09/26 03:33:19 visual_prompt]: Inference (val):avg data time: 2.11e-05, avg batch time: 0.1663, average loss: 0.8868
[09/26 03:33:19 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 81.50	top5: 96.00	
[09/26 03:33:19 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.058488889220255524
[09/26 03:33:26 visual_prompt]: Epoch 81 / 100: avg data time: 5.60e-02, avg batch time: 0.4989, average train loss: 0.0940
[09/26 03:33:27 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.1665, average loss: 0.8744
[09/26 03:33:27 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 81.50	top5: 96.00	
[09/26 03:33:27 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.052997311598319524
[09/26 03:33:34 visual_prompt]: Epoch 82 / 100: avg data time: 5.64e-02, avg batch time: 0.5001, average train loss: 0.0789
[09/26 03:33:36 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1666, average loss: 0.8604
[09/26 03:33:36 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 82.00	top5: 95.50	
[09/26 03:33:36 visual_prompt]: Best epoch 82: best metric: 0.820
[09/26 03:33:36 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.047745751406263165
[09/26 03:33:42 visual_prompt]: Epoch 83 / 100: avg data time: 5.62e-02, avg batch time: 0.4994, average train loss: 0.0691
[09/26 03:33:44 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1666, average loss: 0.8706
[09/26 03:33:44 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 80.50	top5: 96.00	
[09/26 03:33:44 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.042740606861239594
[09/26 03:33:51 visual_prompt]: Epoch 84 / 100: avg data time: 5.71e-02, avg batch time: 0.4995, average train loss: 0.0620
[09/26 03:33:52 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1666, average loss: 0.8642
[09/26 03:33:52 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 81.50	top5: 96.00	
[09/26 03:33:52 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.03798797596089351
[09/26 03:33:59 visual_prompt]: Epoch 85 / 100: avg data time: 6.19e-02, avg batch time: 0.5041, average train loss: 0.0582
[09/26 03:34:01 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1664, average loss: 0.8528
[09/26 03:34:01 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 82.00	top5: 96.00	
[09/26 03:34:01 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.03349364905389032
[09/26 03:34:07 visual_prompt]: Epoch 86 / 100: avg data time: 5.89e-02, avg batch time: 0.5009, average train loss: 0.0543
[09/26 03:34:09 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1665, average loss: 0.8492
[09/26 03:34:09 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 82.00	top5: 96.00	
[09/26 03:34:09 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.029263101785268253
[09/26 03:34:16 visual_prompt]: Epoch 87 / 100: avg data time: 6.51e-02, avg batch time: 0.5071, average train loss: 0.0520
[09/26 03:34:17 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1665, average loss: 0.8470
[09/26 03:34:17 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 82.50	top5: 96.00	
[09/26 03:34:17 visual_prompt]: Best epoch 87: best metric: 0.825
[09/26 03:34:17 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.025301488425208296
[09/26 03:34:24 visual_prompt]: Epoch 88 / 100: avg data time: 5.57e-02, avg batch time: 0.4983, average train loss: 0.0504
[09/26 03:34:25 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1666, average loss: 0.8581
[09/26 03:34:25 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 82.00	top5: 96.00	
[09/26 03:34:25 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.021613635589349756
[09/26 03:34:32 visual_prompt]: Epoch 89 / 100: avg data time: 4.84e-02, avg batch time: 0.4954, average train loss: 0.0481
[09/26 03:34:34 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1665, average loss: 0.8601
[09/26 03:34:34 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 82.00	top5: 96.00	
[09/26 03:34:34 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.01820403635830317
[09/26 03:34:40 visual_prompt]: Epoch 90 / 100: avg data time: 4.81e-02, avg batch time: 0.4920, average train loss: 0.0478
[09/26 03:34:42 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1666, average loss: 0.8575
[09/26 03:34:42 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 82.00	top5: 95.50	
[09/26 03:34:42 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.01507684480352292
[09/26 03:34:49 visual_prompt]: Epoch 91 / 100: avg data time: 5.72e-02, avg batch time: 0.5005, average train loss: 0.0468
[09/26 03:34:50 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.1666, average loss: 0.8577
[09/26 03:34:50 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 82.50	top5: 96.00	
[09/26 03:34:50 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.012235870926211617
[09/26 03:34:57 visual_prompt]: Epoch 92 / 100: avg data time: 5.34e-02, avg batch time: 0.4955, average train loss: 0.0459
[09/26 03:34:59 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1664, average loss: 0.8570
[09/26 03:34:59 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 82.50	top5: 96.00	
[09/26 03:34:59 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.009684576015420276
[09/26 03:35:05 visual_prompt]: Epoch 93 / 100: avg data time: 4.42e-02, avg batch time: 0.4877, average train loss: 0.0455
[09/26 03:35:07 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1664, average loss: 0.8569
[09/26 03:35:07 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 82.50	top5: 95.50	
[09/26 03:35:07 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.007426068431000882
[09/26 03:35:13 visual_prompt]: Epoch 94 / 100: avg data time: 5.26e-02, avg batch time: 0.4956, average train loss: 0.0454
[09/26 03:35:15 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1664, average loss: 0.8553
[09/26 03:35:15 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 82.50	top5: 95.50	
[09/26 03:35:15 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.005463099816548578
[09/26 03:35:22 visual_prompt]: Epoch 95 / 100: avg data time: 5.67e-02, avg batch time: 0.4996, average train loss: 0.0449
[09/26 03:35:23 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1665, average loss: 0.8541
[09/26 03:35:23 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 82.50	top5: 95.50	
[09/26 03:35:23 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.003798061746947995
[09/26 03:35:30 visual_prompt]: Epoch 96 / 100: avg data time: 5.64e-02, avg batch time: 0.4997, average train loss: 0.0443
[09/26 03:35:32 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1663, average loss: 0.8543
[09/26 03:35:32 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 82.50	top5: 96.00	
[09/26 03:35:32 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.0024329828146074095
[09/26 03:35:38 visual_prompt]: Epoch 97 / 100: avg data time: 6.54e-02, avg batch time: 0.5077, average train loss: 0.0445
[09/26 03:35:40 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1664, average loss: 0.8544
[09/26 03:35:40 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 82.50	top5: 96.00	
[09/26 03:35:40 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.0013695261579316775
[09/26 03:35:47 visual_prompt]: Epoch 98 / 100: avg data time: 4.56e-02, avg batch time: 0.4886, average train loss: 0.0437
[09/26 03:35:48 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1666, average loss: 0.8548
[09/26 03:35:48 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 82.50	top5: 96.00	
[09/26 03:35:48 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.0006089874350439506
[09/26 03:35:55 visual_prompt]: Epoch 99 / 100: avg data time: 5.80e-02, avg batch time: 0.5000, average train loss: 0.0439
[09/26 03:35:56 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1666, average loss: 0.8550
[09/26 03:35:57 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 82.50	top5: 96.00	
[09/26 03:35:57 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.00015229324522605947
[09/26 03:36:03 visual_prompt]: Epoch 100 / 100: avg data time: 6.31e-02, avg batch time: 0.5056, average train loss: 0.0440
[09/26 03:36:05 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1663, average loss: 0.8551
[09/26 03:36:05 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 82.50	top5: 96.00	
[09/26 03:36:05 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 03:36:05 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 03:36:05 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-cifar(num_classes=100)', 'DATA.NUMBER_CLASSES', '100', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 03:36:05 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 03:36:05 visual_prompt]: Training with config:
[09/26 03:36:05 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-cifar(num_classes=100)/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.5_wd0.0001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 0.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-cifar(num_classes=100)', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 100, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 03:36:05 visual_prompt]: Loading training data...
[09/26 03:36:05 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[:800], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/26 03:36:06 visual_prompt]: Number of images: 800
[09/26 03:36:06 visual_prompt]: Number of classes: 100 / 100
[09/26 03:36:06 visual_prompt]: Loading validation data...
[09/26 03:36:06 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[45000:45200], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/26 03:36:06 visual_prompt]: Number of images: 200
[09/26 03:36:06 visual_prompt]: Number of classes: 90 / 100
[09/26 03:36:06 visual_prompt]: Constructing models...
[09/26 03:36:09 visual_prompt]: Total Parameters: 86336356	 Gradient Parameters: 537700
[09/26 03:36:09 visual_prompt]: tuned percent:0.623
[09/26 03:36:09 visual_prompt]: Device used for model: 0
[09/26 03:36:09 visual_prompt]: Setting up Evaluator...
[09/26 03:36:09 visual_prompt]: Setting up Trainer...
[09/26 03:36:09 visual_prompt]: 	Setting up the optimizer...
[09/26 03:36:09 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 03:36:16 visual_prompt]: Epoch 1 / 100: avg data time: 6.27e-02, avg batch time: 0.5061, average train loss: 4.6607
[09/26 03:36:17 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1660, average loss: 4.6218
[09/26 03:36:17 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 7.00	
[09/26 03:36:17 visual_prompt]: Best epoch 1: best metric: 0.010
[09/26 03:36:17 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.05
[09/26 03:36:24 visual_prompt]: Epoch 2 / 100: avg data time: 5.08e-02, avg batch time: 0.4925, average train loss: 4.6342
[09/26 03:36:25 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1659, average loss: 4.6259
[09/26 03:36:25 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 6.50	
[09/26 03:36:25 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.1
[09/26 03:36:32 visual_prompt]: Epoch 3 / 100: avg data time: 5.90e-02, avg batch time: 0.4999, average train loss: 4.5834
[09/26 03:36:34 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1660, average loss: 4.6199
[09/26 03:36:34 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 4.50	
[09/26 03:36:34 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.15
[09/26 03:36:40 visual_prompt]: Epoch 4 / 100: avg data time: 5.70e-02, avg batch time: 0.4976, average train loss: 4.5837
[09/26 03:36:42 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1661, average loss: 4.6874
[09/26 03:36:42 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 8.00	
[09/26 03:36:42 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.2
[09/26 03:36:49 visual_prompt]: Epoch 5 / 100: avg data time: 5.05e-02, avg batch time: 0.4957, average train loss: 4.5615
[09/26 03:36:50 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1663, average loss: 4.5999
[09/26 03:36:50 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 8.00	
[09/26 03:36:50 visual_prompt]: Best epoch 5: best metric: 0.015
[09/26 03:36:50 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.25
[09/26 03:36:57 visual_prompt]: Epoch 6 / 100: avg data time: 5.85e-02, avg batch time: 0.4996, average train loss: 4.4232
[09/26 03:36:58 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1661, average loss: 4.3060
[09/26 03:36:58 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 5.50	top5: 18.00	
[09/26 03:36:58 visual_prompt]: Best epoch 6: best metric: 0.055
[09/26 03:36:58 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.3
[09/26 03:37:05 visual_prompt]: Epoch 7 / 100: avg data time: 4.47e-02, avg batch time: 0.4879, average train loss: 3.9972
[09/26 03:37:07 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1662, average loss: 3.9729
[09/26 03:37:07 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 6.50	top5: 23.50	
[09/26 03:37:07 visual_prompt]: Best epoch 7: best metric: 0.065
[09/26 03:37:07 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.35
[09/26 03:37:13 visual_prompt]: Epoch 8 / 100: avg data time: 4.78e-02, avg batch time: 0.4928, average train loss: 3.3996
[09/26 03:37:15 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1664, average loss: 3.5197
[09/26 03:37:15 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 11.50	top5: 37.00	
[09/26 03:37:15 visual_prompt]: Best epoch 8: best metric: 0.115
[09/26 03:37:15 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.4
[09/26 03:37:21 visual_prompt]: Epoch 9 / 100: avg data time: 4.49e-02, avg batch time: 0.4875, average train loss: 2.6699
[09/26 03:37:23 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1664, average loss: 2.7230
[09/26 03:37:23 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 28.00	top5: 62.50	
[09/26 03:37:23 visual_prompt]: Best epoch 9: best metric: 0.280
[09/26 03:37:23 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.45
[09/26 03:37:30 visual_prompt]: Epoch 10 / 100: avg data time: 4.40e-02, avg batch time: 0.4882, average train loss: 1.8124
[09/26 03:37:31 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1663, average loss: 2.1589
[09/26 03:37:31 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 44.50	top5: 80.00	
[09/26 03:37:31 visual_prompt]: Best epoch 10: best metric: 0.445
[09/26 03:37:31 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.5
[09/26 03:37:38 visual_prompt]: Epoch 11 / 100: avg data time: 4.84e-02, avg batch time: 0.4922, average train loss: 0.9029
[09/26 03:37:39 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1662, average loss: 1.6696
[09/26 03:37:39 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 53.00	top5: 84.50	
[09/26 03:37:39 visual_prompt]: Best epoch 11: best metric: 0.530
[09/26 03:37:39 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.49984770675477397
[09/26 03:37:46 visual_prompt]: Epoch 12 / 100: avg data time: 4.89e-02, avg batch time: 0.4920, average train loss: 0.3571
[09/26 03:37:48 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1663, average loss: 1.4791
[09/26 03:37:48 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.00	top5: 86.50	
[09/26 03:37:48 visual_prompt]: Best epoch 12: best metric: 0.590
[09/26 03:37:48 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.49939101256495605
[09/26 03:37:54 visual_prompt]: Epoch 13 / 100: avg data time: 5.03e-02, avg batch time: 0.4928, average train loss: 0.1638
[09/26 03:37:56 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1664, average loss: 1.3600
[09/26 03:37:56 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 60.50	top5: 88.50	
[09/26 03:37:56 visual_prompt]: Best epoch 13: best metric: 0.605
[09/26 03:37:56 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.4986304738420683
[09/26 03:38:02 visual_prompt]: Epoch 14 / 100: avg data time: 4.74e-02, avg batch time: 0.4892, average train loss: 0.0775
[09/26 03:38:04 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1664, average loss: 1.2868
[09/26 03:38:04 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 91.00	
[09/26 03:38:04 visual_prompt]: Best epoch 14: best metric: 0.625
[09/26 03:38:04 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.4975670171853926
[09/26 03:38:11 visual_prompt]: Epoch 15 / 100: avg data time: 6.19e-02, avg batch time: 0.5033, average train loss: 0.0455
[09/26 03:38:12 visual_prompt]: Inference (val):avg data time: 4.14e-05, avg batch time: 0.1665, average loss: 1.2830
[09/26 03:38:12 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.00	top5: 90.00	
[09/26 03:38:12 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.49620193825305203
[09/26 03:38:19 visual_prompt]: Epoch 16 / 100: avg data time: 4.86e-02, avg batch time: 0.4906, average train loss: 0.0284
[09/26 03:38:21 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1665, average loss: 1.2846
[09/26 03:38:21 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 88.00	
[09/26 03:38:21 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.4945369001834514
[09/26 03:38:27 visual_prompt]: Epoch 17 / 100: avg data time: 5.49e-02, avg batch time: 0.4970, average train loss: 0.0221
[09/26 03:38:29 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1664, average loss: 1.2797
[09/26 03:38:29 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.50	top5: 90.50	
[09/26 03:38:29 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.4925739315689991
[09/26 03:38:36 visual_prompt]: Epoch 18 / 100: avg data time: 5.09e-02, avg batch time: 0.4935, average train loss: 0.0187
[09/26 03:38:37 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1665, average loss: 1.2763
[09/26 03:38:37 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.00	top5: 90.50	
[09/26 03:38:37 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.4903154239845797
[09/26 03:38:44 visual_prompt]: Epoch 19 / 100: avg data time: 5.51e-02, avg batch time: 0.4971, average train loss: 0.0163
[09/26 03:38:45 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1665, average loss: 1.2600
[09/26 03:38:45 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.50	top5: 91.00	
[09/26 03:38:45 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.4877641290737884
[09/26 03:38:52 visual_prompt]: Epoch 20 / 100: avg data time: 5.26e-02, avg batch time: 0.4955, average train loss: 0.0154
[09/26 03:38:54 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1663, average loss: 1.2576
[09/26 03:38:54 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.50	top5: 91.00	
[09/26 03:38:54 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.4849231551964771
[09/26 03:39:01 visual_prompt]: Epoch 21 / 100: avg data time: 5.89e-02, avg batch time: 0.5015, average train loss: 0.0136
[09/26 03:39:02 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1661, average loss: 1.2454
[09/26 03:39:02 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 91.50	
[09/26 03:39:02 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.48179596364169686
[09/26 03:39:09 visual_prompt]: Epoch 22 / 100: avg data time: 4.59e-02, avg batch time: 0.4884, average train loss: 0.0132
[09/26 03:39:10 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1664, average loss: 1.2473
[09/26 03:39:10 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.50	top5: 91.50	
[09/26 03:39:10 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.4783863644106502
[09/26 03:39:17 visual_prompt]: Epoch 23 / 100: avg data time: 4.55e-02, avg batch time: 0.4909, average train loss: 0.0125
[09/26 03:39:19 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1664, average loss: 1.2544
[09/26 03:39:19 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 91.50	
[09/26 03:39:19 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.47469851157479176
[09/26 03:39:25 visual_prompt]: Epoch 24 / 100: avg data time: 5.81e-02, avg batch time: 0.5001, average train loss: 0.0117
[09/26 03:39:27 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1665, average loss: 1.2507
[09/26 03:39:27 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.50	top5: 92.00	
[09/26 03:39:27 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.47073689821473175
[09/26 03:39:34 visual_prompt]: Epoch 25 / 100: avg data time: 5.48e-02, avg batch time: 0.4978, average train loss: 0.0110
[09/26 03:39:35 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1663, average loss: 1.2457
[09/26 03:39:35 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 92.00	
[09/26 03:39:35 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.4665063509461097
[09/26 03:39:42 visual_prompt]: Epoch 26 / 100: avg data time: 5.62e-02, avg batch time: 0.4986, average train loss: 0.0106
[09/26 03:39:44 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1664, average loss: 1.2422
[09/26 03:39:44 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.00	top5: 92.00	
[09/26 03:39:44 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.46201202403910646
[09/26 03:39:50 visual_prompt]: Epoch 27 / 100: avg data time: 4.48e-02, avg batch time: 0.4885, average train loss: 0.0099
[09/26 03:39:52 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1663, average loss: 1.2443
[09/26 03:39:52 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 92.50	
[09/26 03:39:52 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.4572593931387604
[09/26 03:39:58 visual_prompt]: Epoch 28 / 100: avg data time: 5.54e-02, avg batch time: 0.4982, average train loss: 0.0097
[09/26 03:40:00 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1666, average loss: 1.2340
[09/26 03:40:00 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 92.00	
[09/26 03:40:00 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.45225424859373686
[09/26 03:40:07 visual_prompt]: Epoch 29 / 100: avg data time: 5.83e-02, avg batch time: 0.5011, average train loss: 0.0095
[09/26 03:40:08 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1662, average loss: 1.2317
[09/26 03:40:08 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.50	top5: 92.00	
[09/26 03:40:08 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.44700268840168045
[09/26 03:40:15 visual_prompt]: Epoch 30 / 100: avg data time: 6.26e-02, avg batch time: 0.5040, average train loss: 0.0093
[09/26 03:40:17 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1664, average loss: 1.2415
[09/26 03:40:17 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.50	top5: 92.00	
[09/26 03:40:17 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.4415111107797445
[09/26 03:40:23 visual_prompt]: Epoch 31 / 100: avg data time: 5.36e-02, avg batch time: 0.4947, average train loss: 0.0089
[09/26 03:40:25 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1672, average loss: 1.2429
[09/26 03:40:25 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.50	top5: 92.00	
[09/26 03:40:25 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.43578620636934856
[09/26 03:40:32 visual_prompt]: Epoch 32 / 100: avg data time: 4.71e-02, avg batch time: 0.4890, average train loss: 0.0088
[09/26 03:40:33 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1662, average loss: 1.2355
[09/26 03:40:33 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 92.50	
[09/26 03:40:33 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.42983495008466277
[09/26 03:40:40 visual_prompt]: Epoch 33 / 100: avg data time: 6.07e-02, avg batch time: 0.5021, average train loss: 0.0084
[09/26 03:40:42 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1664, average loss: 1.2486
[09/26 03:40:42 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.50	top5: 92.00	
[09/26 03:40:42 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.4236645926147493
[09/26 03:40:48 visual_prompt]: Epoch 34 / 100: avg data time: 5.66e-02, avg batch time: 0.4988, average train loss: 0.0082
[09/26 03:40:50 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1664, average loss: 1.2546
[09/26 03:40:50 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.50	top5: 92.00	
[09/26 03:40:50 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.41728265158971456
[09/26 03:40:57 visual_prompt]: Epoch 35 / 100: avg data time: 4.69e-02, avg batch time: 0.4902, average train loss: 0.0080
[09/26 03:40:58 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1665, average loss: 1.2546
[09/26 03:40:58 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.50	top5: 92.50	
[09/26 03:40:58 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.4106969024216348
[09/26 03:41:05 visual_prompt]: Epoch 36 / 100: avg data time: 5.35e-02, avg batch time: 0.4971, average train loss: 0.0079
[09/26 03:41:06 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1666, average loss: 1.2528
[09/26 03:41:06 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.50	top5: 92.50	
[09/26 03:41:06 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.40391536883141455
[09/26 03:41:13 visual_prompt]: Epoch 37 / 100: avg data time: 6.59e-02, avg batch time: 0.5072, average train loss: 0.0078
[09/26 03:41:15 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1669, average loss: 1.2548
[09/26 03:41:15 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.00	top5: 92.50	
[09/26 03:41:15 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.3969463130731183
[09/26 03:41:22 visual_prompt]: Epoch 38 / 100: avg data time: 5.65e-02, avg batch time: 0.4983, average train loss: 0.0075
[09/26 03:41:23 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1666, average loss: 1.2551
[09/26 03:41:23 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.00	top5: 92.50	
[09/26 03:41:23 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.3897982258676867
[09/26 03:41:30 visual_prompt]: Epoch 39 / 100: avg data time: 4.75e-02, avg batch time: 0.4919, average train loss: 0.0074
[09/26 03:41:31 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1663, average loss: 1.2526
[09/26 03:41:31 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.50	top5: 92.50	
[09/26 03:41:31 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.3824798160583012
[09/26 03:41:38 visual_prompt]: Epoch 40 / 100: avg data time: 5.91e-02, avg batch time: 0.5008, average train loss: 0.0077
[09/26 03:41:40 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1664, average loss: 1.2521
[09/26 03:41:40 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.00	top5: 92.50	
[09/26 03:41:40 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.375
[09/26 03:41:46 visual_prompt]: Epoch 41 / 100: avg data time: 5.50e-02, avg batch time: 0.4965, average train loss: 0.0073
[09/26 03:41:48 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1663, average loss: 1.2580
[09/26 03:41:48 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.00	top5: 92.00	
[09/26 03:41:48 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.3673678906964727
[09/26 03:41:55 visual_prompt]: Epoch 42 / 100: avg data time: 5.82e-02, avg batch time: 0.5015, average train loss: 0.0073
[09/26 03:41:56 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1666, average loss: 1.2601
[09/26 03:41:56 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 60.00	top5: 92.50	
[09/26 03:41:56 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.35959278669726935
[09/26 03:42:03 visual_prompt]: Epoch 43 / 100: avg data time: 5.23e-02, avg batch time: 0.4943, average train loss: 0.0074
[09/26 03:42:05 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1666, average loss: 1.2604
[09/26 03:42:05 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.50	top5: 93.00	
[09/26 03:42:05 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.3516841607689501
[09/26 03:42:11 visual_prompt]: Epoch 44 / 100: avg data time: 4.49e-02, avg batch time: 0.4881, average train loss: 0.0071
[09/26 03:42:13 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1662, average loss: 1.2532
[09/26 03:42:13 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.00	top5: 93.50	
[09/26 03:42:13 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.34365164835397805
[09/26 03:42:19 visual_prompt]: Epoch 45 / 100: avg data time: 5.55e-02, avg batch time: 0.4976, average train loss: 0.0071
[09/26 03:42:21 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1665, average loss: 1.2499
[09/26 03:42:21 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 60.50	top5: 93.00	
[09/26 03:42:21 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.3355050358314172
[09/26 03:42:28 visual_prompt]: Epoch 46 / 100: avg data time: 5.76e-02, avg batch time: 0.5004, average train loss: 0.0070
[09/26 03:42:29 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1666, average loss: 1.2467
[09/26 03:42:29 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 92.50	
[09/26 03:42:29 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.32725424859373686
[09/26 03:42:36 visual_prompt]: Epoch 47 / 100: avg data time: 6.23e-02, avg batch time: 0.5045, average train loss: 0.0067
[09/26 03:42:38 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1661, average loss: 1.2515
[09/26 03:42:38 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 92.00	
[09/26 03:42:38 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.3189093389542498
[09/26 03:42:44 visual_prompt]: Epoch 48 / 100: avg data time: 6.52e-02, avg batch time: 0.5062, average train loss: 0.0068
[09/26 03:42:46 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1663, average loss: 1.2521
[09/26 03:42:46 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 92.50	
[09/26 03:42:46 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.3104804738999169
[09/26 03:42:53 visual_prompt]: Epoch 49 / 100: avg data time: 5.46e-02, avg batch time: 0.4972, average train loss: 0.0067
[09/26 03:42:54 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1663, average loss: 1.2483
[09/26 03:42:54 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 92.50	
[09/26 03:42:54 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.3019779227044398
[09/26 03:43:01 visual_prompt]: Epoch 50 / 100: avg data time: 5.98e-02, avg batch time: 0.5022, average train loss: 0.0067
[09/26 03:43:03 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1664, average loss: 1.2491
[09/26 03:43:03 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.50	top5: 92.50	
[09/26 03:43:03 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.29341204441673263
[09/26 03:43:09 visual_prompt]: Epoch 51 / 100: avg data time: 5.55e-02, avg batch time: 0.4980, average train loss: 0.0066
[09/26 03:43:11 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1663, average loss: 1.2477
[09/26 03:43:11 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.50	top5: 92.00	
[09/26 03:43:11 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.28479327524001635
[09/26 03:43:18 visual_prompt]: Epoch 52 / 100: avg data time: 5.76e-02, avg batch time: 0.4997, average train loss: 0.0065
[09/26 03:43:19 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1662, average loss: 1.2559
[09/26 03:43:19 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.50	top5: 92.00	
[09/26 03:43:19 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.2761321158169134
[09/26 03:43:26 visual_prompt]: Epoch 53 / 100: avg data time: 6.15e-02, avg batch time: 0.5039, average train loss: 0.0064
[09/26 03:43:28 visual_prompt]: Inference (val):avg data time: 2.00e-05, avg batch time: 0.1663, average loss: 1.2568
[09/26 03:43:28 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.50	top5: 92.00	
[09/26 03:43:28 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.2674391184360313
[09/26 03:43:34 visual_prompt]: Epoch 54 / 100: avg data time: 6.34e-02, avg batch time: 0.5053, average train loss: 0.0065
[09/26 03:43:36 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1664, average loss: 1.2571
[09/26 03:43:36 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.00	top5: 92.50	
[09/26 03:43:36 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.2587248741756253
[09/26 03:43:43 visual_prompt]: Epoch 55 / 100: avg data time: 6.19e-02, avg batch time: 0.5039, average train loss: 0.0065
[09/26 03:43:44 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1662, average loss: 1.2615
[09/26 03:43:44 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.00	top5: 92.00	
[09/26 03:43:44 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.25
[09/26 03:43:51 visual_prompt]: Epoch 56 / 100: avg data time: 5.81e-02, avg batch time: 0.4994, average train loss: 0.0063
[09/26 03:43:53 visual_prompt]: Inference (val):avg data time: 3.45e-05, avg batch time: 0.1664, average loss: 1.2647
[09/26 03:43:53 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 92.00	
[09/26 03:43:53 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.24127512582437483
[09/26 03:43:59 visual_prompt]: Epoch 57 / 100: avg data time: 4.74e-02, avg batch time: 0.4917, average train loss: 0.0064
[09/26 03:44:01 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1662, average loss: 1.2704
[09/26 03:44:01 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.00	top5: 92.00	
[09/26 03:44:01 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.23256088156396867
[09/26 03:44:08 visual_prompt]: Epoch 58 / 100: avg data time: 6.84e-02, avg batch time: 0.5106, average train loss: 0.0063
[09/26 03:44:09 visual_prompt]: Inference (val):avg data time: 2.00e-05, avg batch time: 0.1662, average loss: 1.2648
[09/26 03:44:09 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.50	top5: 92.50	
[09/26 03:44:09 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.22386788418308667
[09/26 03:44:16 visual_prompt]: Epoch 59 / 100: avg data time: 5.48e-02, avg batch time: 0.4970, average train loss: 0.0064
[09/26 03:44:18 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1662, average loss: 1.2594
[09/26 03:44:18 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 92.00	
[09/26 03:44:18 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.2152067247599837
[09/26 03:44:24 visual_prompt]: Epoch 60 / 100: avg data time: 6.09e-02, avg batch time: 0.5023, average train loss: 0.0064
[09/26 03:44:26 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1662, average loss: 1.2602
[09/26 03:44:26 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.00	top5: 92.00	
[09/26 03:44:26 visual_prompt]: Best epoch 60: best metric: 0.630
[09/26 03:44:26 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.20658795558326742
[09/26 03:44:33 visual_prompt]: Epoch 61 / 100: avg data time: 5.36e-02, avg batch time: 0.4964, average train loss: 0.0063
[09/26 03:44:34 visual_prompt]: Inference (val):avg data time: 1.99e-05, avg batch time: 0.1664, average loss: 1.2577
[09/26 03:44:34 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.00	top5: 92.00	
[09/26 03:44:34 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.1980220772955602
[09/26 03:44:41 visual_prompt]: Epoch 62 / 100: avg data time: 5.96e-02, avg batch time: 0.5023, average train loss: 0.0062
[09/26 03:44:43 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1663, average loss: 1.2548
[09/26 03:44:43 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.00	top5: 92.00	
[09/26 03:44:43 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.1895195261000831
[09/26 03:44:49 visual_prompt]: Epoch 63 / 100: avg data time: 5.73e-02, avg batch time: 0.4995, average train loss: 0.0062
[09/26 03:44:51 visual_prompt]: Inference (val):avg data time: 1.88e-05, avg batch time: 0.1662, average loss: 1.2535
[09/26 03:44:51 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.00	top5: 92.00	
[09/26 03:44:51 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.18109066104575022
[09/26 03:44:58 visual_prompt]: Epoch 64 / 100: avg data time: 5.10e-02, avg batch time: 0.4957, average train loss: 0.0061
[09/26 03:44:59 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1662, average loss: 1.2520
[09/26 03:44:59 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 92.00	
[09/26 03:44:59 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.17274575140626316
[09/26 03:45:06 visual_prompt]: Epoch 65 / 100: avg data time: 4.65e-02, avg batch time: 0.4886, average train loss: 0.0062
[09/26 03:45:07 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1665, average loss: 1.2563
[09/26 03:45:07 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 92.00	
[09/26 03:45:07 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.16449496416858284
[09/26 03:45:14 visual_prompt]: Epoch 66 / 100: avg data time: 5.07e-02, avg batch time: 0.4948, average train loss: 0.0062
[09/26 03:45:15 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1665, average loss: 1.2606
[09/26 03:45:15 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 91.50	
[09/26 03:45:15 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.15634835164602198
[09/26 03:45:22 visual_prompt]: Epoch 67 / 100: avg data time: 5.05e-02, avg batch time: 0.4937, average train loss: 0.0061
[09/26 03:45:24 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1664, average loss: 1.2583
[09/26 03:45:24 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 91.50	
[09/26 03:45:24 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.14831583923105
[09/26 03:45:30 visual_prompt]: Epoch 68 / 100: avg data time: 4.55e-02, avg batch time: 0.4903, average train loss: 0.0060
[09/26 03:45:32 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1665, average loss: 1.2547
[09/26 03:45:32 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 91.50	
[09/26 03:45:32 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.14040721330273062
[09/26 03:45:39 visual_prompt]: Epoch 69 / 100: avg data time: 5.38e-02, avg batch time: 0.4958, average train loss: 0.0061
[09/26 03:45:40 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1664, average loss: 1.2554
[09/26 03:45:40 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 92.00	
[09/26 03:45:40 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.13263210930352737
[09/26 03:45:47 visual_prompt]: Epoch 70 / 100: avg data time: 6.17e-02, avg batch time: 0.5044, average train loss: 0.0059
[09/26 03:45:48 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1663, average loss: 1.2554
[09/26 03:45:48 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 92.00	
[09/26 03:45:48 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.12500000000000006
[09/26 03:45:55 visual_prompt]: Epoch 71 / 100: avg data time: 5.48e-02, avg batch time: 0.4970, average train loss: 0.0060
[09/26 03:45:57 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1662, average loss: 1.2560
[09/26 03:45:57 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 92.00	
[09/26 03:45:57 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.1175201839416988
[09/26 03:46:04 visual_prompt]: Epoch 72 / 100: avg data time: 6.29e-02, avg batch time: 0.5054, average train loss: 0.0059
[09/26 03:46:05 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1663, average loss: 1.2535
[09/26 03:46:05 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 92.00	
[09/26 03:46:05 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.11020177413231333
[09/26 03:46:12 visual_prompt]: Epoch 73 / 100: avg data time: 4.64e-02, avg batch time: 0.4912, average train loss: 0.0061
[09/26 03:46:13 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1663, average loss: 1.2533
[09/26 03:46:13 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 92.00	
[09/26 03:46:13 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.10305368692688174
[09/26 03:46:20 visual_prompt]: Epoch 74 / 100: avg data time: 6.00e-02, avg batch time: 0.5014, average train loss: 0.0059
[09/26 03:46:22 visual_prompt]: Inference (val):avg data time: 2.00e-05, avg batch time: 0.1664, average loss: 1.2524
[09/26 03:46:22 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 92.00	
[09/26 03:46:22 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.09608463116858543
[09/26 03:46:28 visual_prompt]: Epoch 75 / 100: avg data time: 5.56e-02, avg batch time: 0.4978, average train loss: 0.0059
[09/26 03:46:30 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1663, average loss: 1.2531
[09/26 03:46:30 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 92.00	
[09/26 03:46:30 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.08930309757836516
[09/26 03:46:36 visual_prompt]: Epoch 76 / 100: avg data time: 4.36e-02, avg batch time: 0.4869, average train loss: 0.0060
[09/26 03:46:38 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1662, average loss: 1.2548
[09/26 03:46:38 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 92.00	
[09/26 03:46:38 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.08271734841028552
[09/26 03:46:45 visual_prompt]: Epoch 77 / 100: avg data time: 6.55e-02, avg batch time: 0.5066, average train loss: 0.0058
[09/26 03:46:46 visual_prompt]: Inference (val):avg data time: 1.99e-05, avg batch time: 0.1663, average loss: 1.2563
[09/26 03:46:46 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 92.00	
[09/26 03:46:46 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.07633540738525066
[09/26 03:46:53 visual_prompt]: Epoch 78 / 100: avg data time: 4.64e-02, avg batch time: 0.4906, average train loss: 0.0059
[09/26 03:46:55 visual_prompt]: Inference (val):avg data time: 1.94e-05, avg batch time: 0.1664, average loss: 1.2564
[09/26 03:46:55 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 92.00	
[09/26 03:46:55 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.07016504991533726
[09/26 03:47:01 visual_prompt]: Epoch 79 / 100: avg data time: 4.62e-02, avg batch time: 0.4886, average train loss: 0.0058
[09/26 03:47:03 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1664, average loss: 1.2572
[09/26 03:47:03 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 92.00	
[09/26 03:47:03 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.06421379363065141
[09/26 03:47:10 visual_prompt]: Epoch 80 / 100: avg data time: 5.37e-02, avg batch time: 0.4964, average train loss: 0.0059
[09/26 03:47:11 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1662, average loss: 1.2565
[09/26 03:47:11 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 92.00	
[09/26 03:47:11 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.058488889220255524
[09/26 03:47:18 visual_prompt]: Epoch 81 / 100: avg data time: 4.72e-02, avg batch time: 0.4904, average train loss: 0.0058
[09/26 03:47:19 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.1665, average loss: 1.2568
[09/26 03:47:19 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 92.00	
[09/26 03:47:19 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.052997311598319524
[09/26 03:47:26 visual_prompt]: Epoch 82 / 100: avg data time: 5.94e-02, avg batch time: 0.5017, average train loss: 0.0059
[09/26 03:47:27 visual_prompt]: Inference (val):avg data time: 2.00e-05, avg batch time: 0.1664, average loss: 1.2570
[09/26 03:47:27 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 92.00	
[09/26 03:47:27 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.047745751406263165
[09/26 03:47:34 visual_prompt]: Epoch 83 / 100: avg data time: 5.95e-02, avg batch time: 0.5009, average train loss: 0.0058
[09/26 03:47:36 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.1664, average loss: 1.2577
[09/26 03:47:36 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 92.00	
[09/26 03:47:36 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.042740606861239594
[09/26 03:47:43 visual_prompt]: Epoch 84 / 100: avg data time: 4.97e-02, avg batch time: 0.4940, average train loss: 0.0059
[09/26 03:47:44 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1663, average loss: 1.2573
[09/26 03:47:44 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 92.00	
[09/26 03:47:44 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.03798797596089351
[09/26 03:47:51 visual_prompt]: Epoch 85 / 100: avg data time: 6.05e-02, avg batch time: 0.5032, average train loss: 0.0058
[09/26 03:47:52 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1663, average loss: 1.2569
[09/26 03:47:52 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 92.00	
[09/26 03:47:52 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.03349364905389032
[09/26 03:47:59 visual_prompt]: Epoch 86 / 100: avg data time: 5.57e-02, avg batch time: 0.5001, average train loss: 0.0059
[09/26 03:48:01 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1663, average loss: 1.2574
[09/26 03:48:01 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 92.00	
[09/26 03:48:01 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.029263101785268253
[09/26 03:48:07 visual_prompt]: Epoch 87 / 100: avg data time: 4.56e-02, avg batch time: 0.4905, average train loss: 0.0059
[09/26 03:48:09 visual_prompt]: Inference (val):avg data time: 2.00e-05, avg batch time: 0.1667, average loss: 1.2567
[09/26 03:48:09 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 92.00	
[09/26 03:48:09 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.025301488425208296
[09/26 03:48:16 visual_prompt]: Epoch 88 / 100: avg data time: 5.45e-02, avg batch time: 0.4971, average train loss: 0.0059
[09/26 03:48:17 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1664, average loss: 1.2563
[09/26 03:48:17 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 92.00	
[09/26 03:48:17 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.021613635589349756
[09/26 03:48:24 visual_prompt]: Epoch 89 / 100: avg data time: 5.59e-02, avg batch time: 0.4978, average train loss: 0.0057
[09/26 03:48:25 visual_prompt]: Inference (val):avg data time: 1.98e-05, avg batch time: 0.1664, average loss: 1.2558
[09/26 03:48:25 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 92.00	
[09/26 03:48:25 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.01820403635830317
[09/26 03:48:32 visual_prompt]: Epoch 90 / 100: avg data time: 5.42e-02, avg batch time: 0.4957, average train loss: 0.0059
[09/26 03:48:34 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1663, average loss: 1.2559
[09/26 03:48:34 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 92.00	
[09/26 03:48:34 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.01507684480352292
[09/26 03:48:40 visual_prompt]: Epoch 91 / 100: avg data time: 5.89e-02, avg batch time: 0.5016, average train loss: 0.0059
[09/26 03:48:42 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1665, average loss: 1.2561
[09/26 03:48:42 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 92.00	
[09/26 03:48:42 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.012235870926211617
[09/26 03:48:49 visual_prompt]: Epoch 92 / 100: avg data time: 6.33e-02, avg batch time: 0.5056, average train loss: 0.0059
[09/26 03:48:50 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1666, average loss: 1.2561
[09/26 03:48:50 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 92.00	
[09/26 03:48:50 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.009684576015420276
[09/26 03:48:57 visual_prompt]: Epoch 93 / 100: avg data time: 5.64e-02, avg batch time: 0.4979, average train loss: 0.0058
[09/26 03:48:59 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1665, average loss: 1.2561
[09/26 03:48:59 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 92.00	
[09/26 03:48:59 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.007426068431000882
[09/26 03:49:05 visual_prompt]: Epoch 94 / 100: avg data time: 5.32e-02, avg batch time: 0.4953, average train loss: 0.0059
[09/26 03:49:07 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1666, average loss: 1.2559
[09/26 03:49:07 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 92.00	
[09/26 03:49:07 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.005463099816548578
[09/26 03:49:14 visual_prompt]: Epoch 95 / 100: avg data time: 4.98e-02, avg batch time: 0.4946, average train loss: 0.0059
[09/26 03:49:15 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1663, average loss: 1.2559
[09/26 03:49:15 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 92.00	
[09/26 03:49:15 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.003798061746947995
[09/26 03:49:22 visual_prompt]: Epoch 96 / 100: avg data time: 5.83e-02, avg batch time: 0.4998, average train loss: 0.0060
[09/26 03:49:24 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1665, average loss: 1.2559
[09/26 03:49:24 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 92.00	
[09/26 03:49:24 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.0024329828146074095
[09/26 03:49:30 visual_prompt]: Epoch 97 / 100: avg data time: 5.90e-02, avg batch time: 0.5005, average train loss: 0.0059
[09/26 03:49:32 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1666, average loss: 1.2559
[09/26 03:49:32 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 92.00	
[09/26 03:49:32 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.0013695261579316775
[09/26 03:49:39 visual_prompt]: Epoch 98 / 100: avg data time: 5.52e-02, avg batch time: 0.4979, average train loss: 0.0059
[09/26 03:49:40 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1665, average loss: 1.2558
[09/26 03:49:40 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 92.00	
[09/26 03:49:40 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.0006089874350439506
[09/26 03:49:47 visual_prompt]: Epoch 99 / 100: avg data time: 5.96e-02, avg batch time: 0.5016, average train loss: 0.0058
[09/26 03:49:48 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1665, average loss: 1.2558
[09/26 03:49:48 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 92.00	
[09/26 03:49:48 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.00015229324522605947
[09/26 03:49:55 visual_prompt]: Epoch 100 / 100: avg data time: 5.77e-02, avg batch time: 0.5003, average train loss: 0.0058
[09/26 03:49:57 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.1665, average loss: 1.2558
[09/26 03:49:57 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 92.00	
[09/26 03:49:57 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 03:49:57 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 03:49:57 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-cifar(num_classes=100)', 'DATA.NUMBER_CLASSES', '100', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 03:49:57 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 03:49:57 visual_prompt]: Training with config:
[09/26 03:49:57 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-cifar(num_classes=100)/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.5_wd0.0/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 0.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-cifar(num_classes=100)', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 100, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 03:49:57 visual_prompt]: Loading training data...
[09/26 03:49:57 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[:800], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/26 03:49:58 visual_prompt]: Number of images: 800
[09/26 03:49:58 visual_prompt]: Number of classes: 100 / 100
[09/26 03:49:58 visual_prompt]: Loading validation data...
[09/26 03:49:58 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[45000:45200], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/26 03:49:58 visual_prompt]: Number of images: 200
[09/26 03:49:58 visual_prompt]: Number of classes: 90 / 100
[09/26 03:49:58 visual_prompt]: Constructing models...
[09/26 03:50:00 visual_prompt]: Total Parameters: 86336356	 Gradient Parameters: 537700
[09/26 03:50:00 visual_prompt]: tuned percent:0.623
[09/26 03:50:00 visual_prompt]: Device used for model: 0
[09/26 03:50:00 visual_prompt]: Setting up Evaluator...
[09/26 03:50:00 visual_prompt]: Setting up Trainer...
[09/26 03:50:00 visual_prompt]: 	Setting up the optimizer...
[09/26 03:50:00 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 03:50:07 visual_prompt]: Epoch 1 / 100: avg data time: 6.44e-02, avg batch time: 0.5043, average train loss: 4.6604
[09/26 03:50:09 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1658, average loss: 4.6218
[09/26 03:50:09 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 7.00	
[09/26 03:50:09 visual_prompt]: Best epoch 1: best metric: 0.010
[09/26 03:50:09 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.05
[09/26 03:50:16 visual_prompt]: Epoch 2 / 100: avg data time: 5.90e-02, avg batch time: 0.4992, average train loss: 4.6204
[09/26 03:50:17 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1659, average loss: 4.6049
[09/26 03:50:17 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 4.50	
[09/26 03:50:17 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.1
[09/26 03:50:24 visual_prompt]: Epoch 3 / 100: avg data time: 5.90e-02, avg batch time: 0.5007, average train loss: 4.5830
[09/26 03:50:25 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1662, average loss: 4.6091
[09/26 03:50:25 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 4.50	
[09/26 03:50:25 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.15
[09/26 03:50:32 visual_prompt]: Epoch 4 / 100: avg data time: 5.58e-02, avg batch time: 0.4970, average train loss: 4.5857
[09/26 03:50:34 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1662, average loss: 4.5994
[09/26 03:50:34 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 3.00	top5: 9.00	
[09/26 03:50:34 visual_prompt]: Best epoch 4: best metric: 0.030
[09/26 03:50:34 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.2
[09/26 03:50:41 visual_prompt]: Epoch 5 / 100: avg data time: 5.60e-02, avg batch time: 0.4972, average train loss: 4.4995
[09/26 03:50:42 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1660, average loss: 4.4710
[09/26 03:50:42 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 3.50	top5: 14.00	
[09/26 03:50:42 visual_prompt]: Best epoch 5: best metric: 0.035
[09/26 03:50:42 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.25
[09/26 03:50:49 visual_prompt]: Epoch 6 / 100: avg data time: 5.34e-02, avg batch time: 0.4957, average train loss: 4.2115
[09/26 03:50:50 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1662, average loss: 4.1150
[09/26 03:50:50 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 3.50	top5: 23.00	
[09/26 03:50:50 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.3
[09/26 03:50:57 visual_prompt]: Epoch 7 / 100: avg data time: 6.05e-02, avg batch time: 0.5021, average train loss: 3.5643
[09/26 03:50:59 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1661, average loss: 3.5659
[09/26 03:50:59 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 9.00	top5: 40.50	
[09/26 03:50:59 visual_prompt]: Best epoch 7: best metric: 0.090
[09/26 03:50:59 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.35
[09/26 03:51:05 visual_prompt]: Epoch 8 / 100: avg data time: 4.24e-02, avg batch time: 0.4849, average train loss: 2.7088
[09/26 03:51:07 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1663, average loss: 2.7482
[09/26 03:51:07 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 24.00	top5: 63.50	
[09/26 03:51:07 visual_prompt]: Best epoch 8: best metric: 0.240
[09/26 03:51:07 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.4
[09/26 03:51:14 visual_prompt]: Epoch 9 / 100: avg data time: 5.42e-02, avg batch time: 0.4956, average train loss: 1.5627
[09/26 03:51:15 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1663, average loss: 2.1620
[09/26 03:51:15 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 42.50	top5: 76.50	
[09/26 03:51:15 visual_prompt]: Best epoch 9: best metric: 0.425
[09/26 03:51:15 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.45
[09/26 03:51:22 visual_prompt]: Epoch 10 / 100: avg data time: 5.57e-02, avg batch time: 0.4970, average train loss: 0.7874
[09/26 03:51:23 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1663, average loss: 1.5852
[09/26 03:51:23 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.00	top5: 86.50	
[09/26 03:51:23 visual_prompt]: Best epoch 10: best metric: 0.540
[09/26 03:51:23 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.5
[09/26 03:51:30 visual_prompt]: Epoch 11 / 100: avg data time: 5.72e-02, avg batch time: 0.4984, average train loss: 0.3287
[09/26 03:51:32 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1663, average loss: 1.3937
[09/26 03:51:32 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.50	top5: 89.00	
[09/26 03:51:32 visual_prompt]: Best epoch 11: best metric: 0.615
[09/26 03:51:32 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.49984770675477397
[09/26 03:51:38 visual_prompt]: Epoch 12 / 100: avg data time: 4.26e-02, avg batch time: 0.4871, average train loss: 0.1413
[09/26 03:51:40 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1665, average loss: 1.2695
[09/26 03:51:40 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 64.50	top5: 89.50	
[09/26 03:51:40 visual_prompt]: Best epoch 12: best metric: 0.645
[09/26 03:51:40 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.49939101256495605
[09/26 03:51:47 visual_prompt]: Epoch 13 / 100: avg data time: 5.34e-02, avg batch time: 0.4959, average train loss: 0.0585
[09/26 03:51:48 visual_prompt]: Inference (val):avg data time: 4.47e-05, avg batch time: 0.1664, average loss: 1.2240
[09/26 03:51:48 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.50	top5: 90.50	
[09/26 03:51:48 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.4986304738420683
[09/26 03:51:55 visual_prompt]: Epoch 14 / 100: avg data time: 6.16e-02, avg batch time: 0.5029, average train loss: 0.0330
[09/26 03:51:57 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1666, average loss: 1.2540
[09/26 03:51:57 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.50	top5: 91.00	
[09/26 03:51:57 visual_prompt]: Best epoch 14: best metric: 0.655
[09/26 03:51:57 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.4975670171853926
[09/26 03:52:03 visual_prompt]: Epoch 15 / 100: avg data time: 4.76e-02, avg batch time: 0.4904, average train loss: 0.0224
[09/26 03:52:05 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1665, average loss: 1.2039
[09/26 03:52:05 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.00	top5: 90.50	
[09/26 03:52:05 visual_prompt]: Best epoch 15: best metric: 0.660
[09/26 03:52:05 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.49620193825305203
[09/26 03:52:12 visual_prompt]: Epoch 16 / 100: avg data time: 5.84e-02, avg batch time: 0.5013, average train loss: 0.0166
[09/26 03:52:13 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1664, average loss: 1.1995
[09/26 03:52:13 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.00	top5: 91.00	
[09/26 03:52:13 visual_prompt]: Best epoch 16: best metric: 0.670
[09/26 03:52:13 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.4945369001834514
[09/26 03:52:20 visual_prompt]: Epoch 17 / 100: avg data time: 4.86e-02, avg batch time: 0.4911, average train loss: 0.0134
[09/26 03:52:21 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1666, average loss: 1.2106
[09/26 03:52:21 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.00	top5: 91.00	
[09/26 03:52:21 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.4925739315689991
[09/26 03:52:28 visual_prompt]: Epoch 18 / 100: avg data time: 4.39e-02, avg batch time: 0.4879, average train loss: 0.0120
[09/26 03:52:30 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1668, average loss: 1.2119
[09/26 03:52:30 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.50	top5: 91.50	
[09/26 03:52:30 visual_prompt]: Best epoch 18: best metric: 0.675
[09/26 03:52:30 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.4903154239845797
[09/26 03:52:36 visual_prompt]: Epoch 19 / 100: avg data time: 5.70e-02, avg batch time: 0.4990, average train loss: 0.0104
[09/26 03:52:38 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1666, average loss: 1.2058
[09/26 03:52:38 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.50	top5: 90.50	
[09/26 03:52:38 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.4877641290737884
[09/26 03:52:45 visual_prompt]: Epoch 20 / 100: avg data time: 5.85e-02, avg batch time: 0.4997, average train loss: 0.0093
[09/26 03:52:46 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1665, average loss: 1.1983
[09/26 03:52:46 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.00	top5: 91.50	
[09/26 03:52:46 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.4849231551964771
[09/26 03:52:53 visual_prompt]: Epoch 21 / 100: avg data time: 5.78e-02, avg batch time: 0.4992, average train loss: 0.0085
[09/26 03:52:54 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1667, average loss: 1.2004
[09/26 03:52:54 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.00	top5: 91.50	
[09/26 03:52:54 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.48179596364169686
[09/26 03:53:01 visual_prompt]: Epoch 22 / 100: avg data time: 5.94e-02, avg batch time: 0.5013, average train loss: 0.0079
[09/26 03:53:03 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1663, average loss: 1.1982
[09/26 03:53:03 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.50	top5: 91.00	
[09/26 03:53:03 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.4783863644106502
[09/26 03:53:10 visual_prompt]: Epoch 23 / 100: avg data time: 6.20e-02, avg batch time: 0.5039, average train loss: 0.0073
[09/26 03:53:11 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1664, average loss: 1.1966
[09/26 03:53:11 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.00	top5: 90.50	
[09/26 03:53:11 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.47469851157479176
[09/26 03:53:18 visual_prompt]: Epoch 24 / 100: avg data time: 4.59e-02, avg batch time: 0.4876, average train loss: 0.0071
[09/26 03:53:19 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1665, average loss: 1.2007
[09/26 03:53:19 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.50	top5: 91.00	
[09/26 03:53:19 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.47073689821473175
[09/26 03:53:26 visual_prompt]: Epoch 25 / 100: avg data time: 6.02e-02, avg batch time: 0.5026, average train loss: 0.0065
[09/26 03:53:28 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1665, average loss: 1.1996
[09/26 03:53:28 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.00	top5: 90.50	
[09/26 03:53:28 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.4665063509461097
[09/26 03:53:34 visual_prompt]: Epoch 26 / 100: avg data time: 4.72e-02, avg batch time: 0.4904, average train loss: 0.0061
[09/26 03:53:36 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1666, average loss: 1.2007
[09/26 03:53:36 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.00	top5: 90.50	
[09/26 03:53:36 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.46201202403910646
[09/26 03:53:43 visual_prompt]: Epoch 27 / 100: avg data time: 5.69e-02, avg batch time: 0.4987, average train loss: 0.0059
[09/26 03:53:44 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1664, average loss: 1.2027
[09/26 03:53:44 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.50	top5: 91.00	
[09/26 03:53:44 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.4572593931387604
[09/26 03:53:51 visual_prompt]: Epoch 28 / 100: avg data time: 4.58e-02, avg batch time: 0.4887, average train loss: 0.0055
[09/26 03:53:52 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1667, average loss: 1.2037
[09/26 03:53:52 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.00	top5: 90.00	
[09/26 03:53:52 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.45225424859373686
[09/26 03:53:59 visual_prompt]: Epoch 29 / 100: avg data time: 4.78e-02, avg batch time: 0.4925, average train loss: 0.0055
[09/26 03:54:01 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1665, average loss: 1.2082
[09/26 03:54:01 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.00	top5: 90.00	
[09/26 03:54:01 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.44700268840168045
[09/26 03:54:07 visual_prompt]: Epoch 30 / 100: avg data time: 5.62e-02, avg batch time: 0.4985, average train loss: 0.0051
[09/26 03:54:09 visual_prompt]: Inference (val):avg data time: 3.26e-05, avg batch time: 0.1663, average loss: 1.2070
[09/26 03:54:09 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 68.00	top5: 90.00	
[09/26 03:54:09 visual_prompt]: Best epoch 30: best metric: 0.680
[09/26 03:54:09 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.4415111107797445
[09/26 03:54:16 visual_prompt]: Epoch 31 / 100: avg data time: 5.64e-02, avg batch time: 0.4988, average train loss: 0.0050
[09/26 03:54:17 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1664, average loss: 1.2068
[09/26 03:54:17 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 68.00	top5: 90.00	
[09/26 03:54:17 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.43578620636934856
[09/26 03:54:24 visual_prompt]: Epoch 32 / 100: avg data time: 6.39e-02, avg batch time: 0.5060, average train loss: 0.0047
[09/26 03:54:26 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1665, average loss: 1.2079
[09/26 03:54:26 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 68.00	top5: 90.00	
[09/26 03:54:26 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.42983495008466277
[09/26 03:54:33 visual_prompt]: Epoch 33 / 100: avg data time: 5.82e-02, avg batch time: 0.5002, average train loss: 0.0045
[09/26 03:54:34 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1665, average loss: 1.2072
[09/26 03:54:34 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 68.00	top5: 90.50	
[09/26 03:54:34 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.4236645926147493
[09/26 03:54:41 visual_prompt]: Epoch 34 / 100: avg data time: 5.73e-02, avg batch time: 0.4993, average train loss: 0.0044
[09/26 03:54:42 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1664, average loss: 1.2093
[09/26 03:54:42 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 68.00	top5: 90.00	
[09/26 03:54:42 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.41728265158971456
[09/26 03:54:49 visual_prompt]: Epoch 35 / 100: avg data time: 5.89e-02, avg batch time: 0.5002, average train loss: 0.0043
[09/26 03:54:51 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1664, average loss: 1.2068
[09/26 03:54:51 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.50	top5: 90.00	
[09/26 03:54:51 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.4106969024216348
[09/26 03:54:57 visual_prompt]: Epoch 36 / 100: avg data time: 5.63e-02, avg batch time: 0.4990, average train loss: 0.0040
[09/26 03:54:59 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1664, average loss: 1.2081
[09/26 03:54:59 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.50	top5: 89.50	
[09/26 03:54:59 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.40391536883141455
[09/26 03:55:06 visual_prompt]: Epoch 37 / 100: avg data time: 3.99e-02, avg batch time: 0.4857, average train loss: 0.0040
[09/26 03:55:07 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1663, average loss: 1.2085
[09/26 03:55:07 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.50	top5: 89.50	
[09/26 03:55:07 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.3969463130731183
[09/26 03:55:14 visual_prompt]: Epoch 38 / 100: avg data time: 5.23e-02, avg batch time: 0.4953, average train loss: 0.0039
[09/26 03:55:15 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1663, average loss: 1.2112
[09/26 03:55:15 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.00	top5: 90.00	
[09/26 03:55:15 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.3897982258676867
[09/26 03:55:22 visual_prompt]: Epoch 39 / 100: avg data time: 5.83e-02, avg batch time: 0.4995, average train loss: 0.0038
[09/26 03:55:24 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1663, average loss: 1.2126
[09/26 03:55:24 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 68.00	top5: 90.00	
[09/26 03:55:24 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.3824798160583012
[09/26 03:55:30 visual_prompt]: Epoch 40 / 100: avg data time: 5.07e-02, avg batch time: 0.4923, average train loss: 0.0036
[09/26 03:55:32 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1661, average loss: 1.2139
[09/26 03:55:32 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.50	top5: 90.00	
[09/26 03:55:32 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.375
[09/26 03:55:39 visual_prompt]: Epoch 41 / 100: avg data time: 5.84e-02, avg batch time: 0.5002, average train loss: 0.0035
[09/26 03:55:40 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1663, average loss: 1.2134
[09/26 03:55:40 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.00	top5: 90.00	
[09/26 03:55:40 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.3673678906964727
[09/26 03:55:47 visual_prompt]: Epoch 42 / 100: avg data time: 5.62e-02, avg batch time: 0.4989, average train loss: 0.0035
[09/26 03:55:49 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1664, average loss: 1.2144
[09/26 03:55:49 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.50	top5: 89.00	
[09/26 03:55:49 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.35959278669726935
[09/26 03:55:55 visual_prompt]: Epoch 43 / 100: avg data time: 3.94e-02, avg batch time: 0.4824, average train loss: 0.0034
[09/26 03:55:57 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1664, average loss: 1.2152
[09/26 03:55:57 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.00	top5: 89.00	
[09/26 03:55:57 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.3516841607689501
[09/26 03:56:03 visual_prompt]: Epoch 44 / 100: avg data time: 5.48e-02, avg batch time: 0.4962, average train loss: 0.0033
[09/26 03:56:05 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1664, average loss: 1.2150
[09/26 03:56:05 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.00	top5: 90.00	
[09/26 03:56:05 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.34365164835397805
[09/26 03:56:12 visual_prompt]: Epoch 45 / 100: avg data time: 6.00e-02, avg batch time: 0.5009, average train loss: 0.0033
[09/26 03:56:13 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1663, average loss: 1.2181
[09/26 03:56:13 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.50	top5: 89.00	
[09/26 03:56:13 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.3355050358314172
[09/26 03:56:20 visual_prompt]: Epoch 46 / 100: avg data time: 4.51e-02, avg batch time: 0.4882, average train loss: 0.0032
[09/26 03:56:21 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1663, average loss: 1.2226
[09/26 03:56:22 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.50	top5: 89.00	
[09/26 03:56:22 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.32725424859373686
[09/26 03:56:28 visual_prompt]: Epoch 47 / 100: avg data time: 5.15e-02, avg batch time: 0.4933, average train loss: 0.0031
[09/26 03:56:30 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1662, average loss: 1.2231
[09/26 03:56:30 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.50	top5: 89.50	
[09/26 03:56:30 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.3189093389542498
[09/26 03:56:36 visual_prompt]: Epoch 48 / 100: avg data time: 4.83e-02, avg batch time: 0.4914, average train loss: 0.0030
[09/26 03:56:38 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1662, average loss: 1.2239
[09/26 03:56:38 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.50	top5: 89.50	
[09/26 03:56:38 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.3104804738999169
[09/26 03:56:45 visual_prompt]: Epoch 49 / 100: avg data time: 5.53e-02, avg batch time: 0.4966, average train loss: 0.0030
[09/26 03:56:46 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1663, average loss: 1.2232
[09/26 03:56:46 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.00	top5: 89.50	
[09/26 03:56:46 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.3019779227044398
[09/26 03:56:53 visual_prompt]: Epoch 50 / 100: avg data time: 4.88e-02, avg batch time: 0.4918, average train loss: 0.0030
[09/26 03:56:54 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1663, average loss: 1.2220
[09/26 03:56:54 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.50	top5: 89.50	
[09/26 03:56:54 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.29341204441673263
[09/26 03:57:01 visual_prompt]: Epoch 51 / 100: avg data time: 6.16e-02, avg batch time: 0.5033, average train loss: 0.0030
[09/26 03:57:03 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.1662, average loss: 1.2177
[09/26 03:57:03 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.50	top5: 89.50	
[09/26 03:57:03 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.28479327524001635
[09/26 03:57:10 visual_prompt]: Epoch 52 / 100: avg data time: 6.02e-02, avg batch time: 0.5018, average train loss: 0.0029
[09/26 03:57:11 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1664, average loss: 1.2173
[09/26 03:57:11 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.50	top5: 89.50	
[09/26 03:57:11 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.2761321158169134
[09/26 03:57:18 visual_prompt]: Epoch 53 / 100: avg data time: 6.16e-02, avg batch time: 0.5035, average train loss: 0.0028
[09/26 03:57:19 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1663, average loss: 1.2174
[09/26 03:57:19 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 68.00	top5: 89.50	
[09/26 03:57:19 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.2674391184360313
[09/26 03:57:26 visual_prompt]: Epoch 54 / 100: avg data time: 5.23e-02, avg batch time: 0.4946, average train loss: 0.0028
[09/26 03:57:28 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1663, average loss: 1.2179
[09/26 03:57:28 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 68.00	top5: 89.50	
[09/26 03:57:28 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.2587248741756253
[09/26 03:57:35 visual_prompt]: Epoch 55 / 100: avg data time: 6.14e-02, avg batch time: 0.5033, average train loss: 0.0028
[09/26 03:57:36 visual_prompt]: Inference (val):avg data time: 1.93e-05, avg batch time: 0.1664, average loss: 1.2186
[09/26 03:57:36 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 68.00	top5: 90.50	
[09/26 03:57:36 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.25
[09/26 03:57:43 visual_prompt]: Epoch 56 / 100: avg data time: 5.53e-02, avg batch time: 0.4971, average train loss: 0.0028
[09/26 03:57:44 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1666, average loss: 1.2196
[09/26 03:57:44 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 68.00	top5: 90.50	
[09/26 03:57:44 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.24127512582437483
[09/26 03:57:51 visual_prompt]: Epoch 57 / 100: avg data time: 5.37e-02, avg batch time: 0.4967, average train loss: 0.0027
[09/26 03:57:53 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1665, average loss: 1.2199
[09/26 03:57:53 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.00	top5: 90.50	
[09/26 03:57:53 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.23256088156396867
[09/26 03:57:59 visual_prompt]: Epoch 58 / 100: avg data time: 6.24e-02, avg batch time: 0.5048, average train loss: 0.0026
[09/26 03:58:01 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1665, average loss: 1.2202
[09/26 03:58:01 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.50	top5: 90.50	
[09/26 03:58:01 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.22386788418308667
[09/26 03:58:08 visual_prompt]: Epoch 59 / 100: avg data time: 4.66e-02, avg batch time: 0.4905, average train loss: 0.0026
[09/26 03:58:09 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1664, average loss: 1.2213
[09/26 03:58:09 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.50	top5: 90.50	
[09/26 03:58:09 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.2152067247599837
[09/26 03:58:16 visual_prompt]: Epoch 60 / 100: avg data time: 6.06e-02, avg batch time: 0.5048, average train loss: 0.0026
[09/26 03:58:17 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1662, average loss: 1.2214
[09/26 03:58:17 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 68.00	top5: 90.50	
[09/26 03:58:17 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.20658795558326742
[09/26 03:58:24 visual_prompt]: Epoch 61 / 100: avg data time: 5.01e-02, avg batch time: 0.4941, average train loss: 0.0025
[09/26 03:58:26 visual_prompt]: Inference (val):avg data time: 1.98e-05, avg batch time: 0.1665, average loss: 1.2203
[09/26 03:58:26 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 68.00	top5: 90.50	
[09/26 03:58:26 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.1980220772955602
[09/26 03:58:32 visual_prompt]: Epoch 62 / 100: avg data time: 4.39e-02, avg batch time: 0.4858, average train loss: 0.0025
[09/26 03:58:34 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1664, average loss: 1.2204
[09/26 03:58:34 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.50	top5: 90.50	
[09/26 03:58:34 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.1895195261000831
[09/26 03:58:41 visual_prompt]: Epoch 63 / 100: avg data time: 5.41e-02, avg batch time: 0.4973, average train loss: 0.0025
[09/26 03:58:42 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1664, average loss: 1.2225
[09/26 03:58:42 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.50	top5: 90.50	
[09/26 03:58:42 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.18109066104575022
[09/26 03:58:49 visual_prompt]: Epoch 64 / 100: avg data time: 5.27e-02, avg batch time: 0.4947, average train loss: 0.0025
[09/26 03:58:50 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1664, average loss: 1.2236
[09/26 03:58:50 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.00	top5: 90.00	
[09/26 03:58:50 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.17274575140626316
[09/26 03:58:57 visual_prompt]: Epoch 65 / 100: avg data time: 4.57e-02, avg batch time: 0.4894, average train loss: 0.0024
[09/26 03:58:59 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1664, average loss: 1.2250
[09/26 03:58:59 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.00	top5: 90.00	
[09/26 03:58:59 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.16449496416858284
[09/26 03:59:05 visual_prompt]: Epoch 66 / 100: avg data time: 4.92e-02, avg batch time: 0.4910, average train loss: 0.0024
[09/26 03:59:07 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1665, average loss: 1.2251
[09/26 03:59:07 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.00	top5: 89.50	
[09/26 03:59:07 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.15634835164602198
[09/26 03:59:13 visual_prompt]: Epoch 67 / 100: avg data time: 4.90e-02, avg batch time: 0.4917, average train loss: 0.0025
[09/26 03:59:15 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1662, average loss: 1.2263
[09/26 03:59:15 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.00	top5: 90.00	
[09/26 03:59:15 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.14831583923105
[09/26 03:59:22 visual_prompt]: Epoch 68 / 100: avg data time: 5.84e-02, avg batch time: 0.5011, average train loss: 0.0024
[09/26 03:59:23 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1663, average loss: 1.2264
[09/26 03:59:23 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.50	top5: 90.00	
[09/26 03:59:23 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.14040721330273062
[09/26 03:59:30 visual_prompt]: Epoch 69 / 100: avg data time: 6.04e-02, avg batch time: 0.5019, average train loss: 0.0024
[09/26 03:59:32 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1666, average loss: 1.2264
[09/26 03:59:32 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.00	top5: 90.00	
[09/26 03:59:32 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.13263210930352737
[09/26 03:59:38 visual_prompt]: Epoch 70 / 100: avg data time: 5.82e-02, avg batch time: 0.5007, average train loss: 0.0024
[09/26 03:59:40 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1663, average loss: 1.2275
[09/26 03:59:40 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.50	top5: 90.00	
[09/26 03:59:40 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.12500000000000006
[09/26 03:59:47 visual_prompt]: Epoch 71 / 100: avg data time: 5.82e-02, avg batch time: 0.5016, average train loss: 0.0024
[09/26 03:59:48 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1664, average loss: 1.2279
[09/26 03:59:48 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.50	top5: 90.00	
[09/26 03:59:48 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.1175201839416988
[09/26 03:59:55 visual_prompt]: Epoch 72 / 100: avg data time: 4.40e-02, avg batch time: 0.4866, average train loss: 0.0024
[09/26 03:59:56 visual_prompt]: Inference (val):avg data time: 2.02e-05, avg batch time: 0.1664, average loss: 1.2285
[09/26 03:59:56 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.50	top5: 90.50	
[09/26 03:59:56 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.11020177413231333
[09/26 04:00:03 visual_prompt]: Epoch 73 / 100: avg data time: 5.73e-02, avg batch time: 0.4990, average train loss: 0.0022
[09/26 04:00:05 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1665, average loss: 1.2286
[09/26 04:00:05 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.50	top5: 90.50	
[09/26 04:00:05 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.10305368692688174
[09/26 04:00:11 visual_prompt]: Epoch 74 / 100: avg data time: 5.60e-02, avg batch time: 0.4984, average train loss: 0.0022
[09/26 04:00:13 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1664, average loss: 1.2285
[09/26 04:00:13 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.50	top5: 90.50	
[09/26 04:00:13 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.09608463116858543
[09/26 04:00:20 visual_prompt]: Epoch 75 / 100: avg data time: 5.80e-02, avg batch time: 0.4999, average train loss: 0.0023
[09/26 04:00:21 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1663, average loss: 1.2276
[09/26 04:00:21 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.50	top5: 90.50	
[09/26 04:00:21 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.08930309757836516
[09/26 04:00:28 visual_prompt]: Epoch 76 / 100: avg data time: 5.49e-02, avg batch time: 0.4982, average train loss: 0.0022
[09/26 04:00:29 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1667, average loss: 1.2268
[09/26 04:00:29 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.50	top5: 90.50	
[09/26 04:00:29 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.08271734841028552
[09/26 04:00:36 visual_prompt]: Epoch 77 / 100: avg data time: 5.32e-02, avg batch time: 0.4958, average train loss: 0.0023
[09/26 04:00:38 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1663, average loss: 1.2268
[09/26 04:00:38 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.50	top5: 90.50	
[09/26 04:00:38 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.07633540738525066
[09/26 04:00:44 visual_prompt]: Epoch 78 / 100: avg data time: 6.01e-02, avg batch time: 0.5020, average train loss: 0.0022
[09/26 04:00:46 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1665, average loss: 1.2269
[09/26 04:00:46 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.50	top5: 90.50	
[09/26 04:00:46 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.07016504991533726
[09/26 04:00:53 visual_prompt]: Epoch 79 / 100: avg data time: 6.23e-02, avg batch time: 0.5048, average train loss: 0.0023
[09/26 04:00:54 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1664, average loss: 1.2263
[09/26 04:00:54 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.50	top5: 90.50	
[09/26 04:00:54 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.06421379363065141
[09/26 04:01:01 visual_prompt]: Epoch 80 / 100: avg data time: 5.91e-02, avg batch time: 0.5013, average train loss: 0.0022
[09/26 04:01:03 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1662, average loss: 1.2262
[09/26 04:01:03 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.50	top5: 90.50	
[09/26 04:01:03 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.058488889220255524
[09/26 04:01:10 visual_prompt]: Epoch 81 / 100: avg data time: 5.89e-02, avg batch time: 0.5007, average train loss: 0.0023
[09/26 04:01:11 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1663, average loss: 1.2262
[09/26 04:01:11 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.50	top5: 90.50	
[09/26 04:01:11 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.052997311598319524
[09/26 04:01:18 visual_prompt]: Epoch 82 / 100: avg data time: 5.25e-02, avg batch time: 0.4944, average train loss: 0.0021
[09/26 04:01:19 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1663, average loss: 1.2262
[09/26 04:01:19 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.50	top5: 90.50	
[09/26 04:01:19 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.047745751406263165
[09/26 04:01:26 visual_prompt]: Epoch 83 / 100: avg data time: 6.10e-02, avg batch time: 0.5034, average train loss: 0.0023
[09/26 04:01:28 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1663, average loss: 1.2264
[09/26 04:01:28 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.50	top5: 90.00	
[09/26 04:01:28 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.042740606861239594
[09/26 04:01:34 visual_prompt]: Epoch 84 / 100: avg data time: 5.15e-02, avg batch time: 0.4944, average train loss: 0.0022
[09/26 04:01:36 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1663, average loss: 1.2263
[09/26 04:01:36 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.50	top5: 90.00	
[09/26 04:01:36 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.03798797596089351
[09/26 04:01:43 visual_prompt]: Epoch 85 / 100: avg data time: 5.86e-02, avg batch time: 0.4997, average train loss: 0.0022
[09/26 04:01:44 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1663, average loss: 1.2263
[09/26 04:01:44 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.50	top5: 90.50	
[09/26 04:01:44 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.03349364905389032
[09/26 04:01:51 visual_prompt]: Epoch 86 / 100: avg data time: 4.45e-02, avg batch time: 0.4882, average train loss: 0.0022
[09/26 04:01:52 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1661, average loss: 1.2263
[09/26 04:01:52 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.50	top5: 90.50	
[09/26 04:01:52 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.029263101785268253
[09/26 04:01:59 visual_prompt]: Epoch 87 / 100: avg data time: 6.01e-02, avg batch time: 0.5026, average train loss: 0.0023
[09/26 04:02:01 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1662, average loss: 1.2263
[09/26 04:02:01 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.50	top5: 90.50	
[09/26 04:02:01 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.025301488425208296
[09/26 04:02:07 visual_prompt]: Epoch 88 / 100: avg data time: 5.81e-02, avg batch time: 0.5011, average train loss: 0.0022
[09/26 04:02:09 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1665, average loss: 1.2264
[09/26 04:02:09 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.50	top5: 90.50	
[09/26 04:02:09 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.021613635589349756
[09/26 04:02:16 visual_prompt]: Epoch 89 / 100: avg data time: 4.97e-02, avg batch time: 0.4930, average train loss: 0.0023
[09/26 04:02:17 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1663, average loss: 1.2265
[09/26 04:02:17 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.50	top5: 90.50	
[09/26 04:02:17 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.01820403635830317
[09/26 04:02:24 visual_prompt]: Epoch 90 / 100: avg data time: 5.47e-02, avg batch time: 0.4964, average train loss: 0.0022
[09/26 04:02:25 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1662, average loss: 1.2266
[09/26 04:02:25 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.50	top5: 90.50	
[09/26 04:02:25 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.01507684480352292
[09/26 04:02:32 visual_prompt]: Epoch 91 / 100: avg data time: 5.65e-02, avg batch time: 0.4982, average train loss: 0.0022
[09/26 04:02:34 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1662, average loss: 1.2268
[09/26 04:02:34 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.50	top5: 90.50	
[09/26 04:02:34 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.012235870926211617
[09/26 04:02:40 visual_prompt]: Epoch 92 / 100: avg data time: 5.58e-02, avg batch time: 0.4966, average train loss: 0.0023
[09/26 04:02:42 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1663, average loss: 1.2268
[09/26 04:02:42 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.50	top5: 90.50	
[09/26 04:02:42 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.009684576015420276
[09/26 04:02:49 visual_prompt]: Epoch 93 / 100: avg data time: 4.43e-02, avg batch time: 0.4891, average train loss: 0.0022
[09/26 04:02:50 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1664, average loss: 1.2269
[09/26 04:02:50 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.50	top5: 90.50	
[09/26 04:02:50 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.007426068431000882
[09/26 04:02:57 visual_prompt]: Epoch 94 / 100: avg data time: 6.23e-02, avg batch time: 0.5057, average train loss: 0.0022
[09/26 04:02:59 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1662, average loss: 1.2269
[09/26 04:02:59 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.50	top5: 90.50	
[09/26 04:02:59 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.005463099816548578
[09/26 04:03:05 visual_prompt]: Epoch 95 / 100: avg data time: 5.49e-02, avg batch time: 0.4961, average train loss: 0.0022
[09/26 04:03:07 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1662, average loss: 1.2270
[09/26 04:03:07 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.50	top5: 90.50	
[09/26 04:03:07 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.003798061746947995
[09/26 04:03:14 visual_prompt]: Epoch 96 / 100: avg data time: 5.98e-02, avg batch time: 0.5013, average train loss: 0.0022
[09/26 04:03:15 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1661, average loss: 1.2270
[09/26 04:03:15 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.50	top5: 90.50	
[09/26 04:03:15 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.0024329828146074095
[09/26 04:03:22 visual_prompt]: Epoch 97 / 100: avg data time: 6.12e-02, avg batch time: 0.5040, average train loss: 0.0022
[09/26 04:03:23 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1663, average loss: 1.2270
[09/26 04:03:23 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.50	top5: 90.50	
[09/26 04:03:23 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.0013695261579316775
[09/26 04:03:30 visual_prompt]: Epoch 98 / 100: avg data time: 5.60e-02, avg batch time: 0.4980, average train loss: 0.0021
[09/26 04:03:32 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1660, average loss: 1.2270
[09/26 04:03:32 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.50	top5: 90.50	
[09/26 04:03:32 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.0006089874350439506
[09/26 04:03:38 visual_prompt]: Epoch 99 / 100: avg data time: 5.65e-02, avg batch time: 0.4974, average train loss: 0.0022
[09/26 04:03:40 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1662, average loss: 1.2270
[09/26 04:03:40 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.50	top5: 90.50	
[09/26 04:03:40 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.00015229324522605947
[09/26 04:03:47 visual_prompt]: Epoch 100 / 100: avg data time: 6.19e-02, avg batch time: 0.5032, average train loss: 0.0022
[09/26 04:03:48 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1663, average loss: 1.2270
[09/26 04:03:48 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.50	top5: 90.50	
[09/26 04:03:48 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 04:03:48 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 04:03:48 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-cifar(num_classes=100)', 'DATA.NUMBER_CLASSES', '100', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 04:03:48 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 04:03:48 visual_prompt]: Training with config:
[09/26 04:03:48 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-cifar(num_classes=100)/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.25_wd0.01/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 0.25, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-cifar(num_classes=100)', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 100, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 04:03:48 visual_prompt]: Loading training data...
[09/26 04:03:48 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[:800], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/26 04:03:49 visual_prompt]: Number of images: 800
[09/26 04:03:49 visual_prompt]: Number of classes: 100 / 100
[09/26 04:03:49 visual_prompt]: Loading validation data...
[09/26 04:03:49 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[45000:45200], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/26 04:03:49 visual_prompt]: Number of images: 200
[09/26 04:03:49 visual_prompt]: Number of classes: 90 / 100
[09/26 04:03:49 visual_prompt]: Constructing models...
[09/26 04:03:52 visual_prompt]: Total Parameters: 86336356	 Gradient Parameters: 537700
[09/26 04:03:52 visual_prompt]: tuned percent:0.623
[09/26 04:03:52 visual_prompt]: Device used for model: 0
[09/26 04:03:52 visual_prompt]: Setting up Evaluator...
[09/26 04:03:52 visual_prompt]: Setting up Trainer...
[09/26 04:03:52 visual_prompt]: 	Setting up the optimizer...
[09/26 04:03:52 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 04:03:59 visual_prompt]: Epoch 1 / 100: avg data time: 6.06e-02, avg batch time: 0.5011, average train loss: 4.6600
[09/26 04:04:00 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1660, average loss: 4.6218
[09/26 04:04:00 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 7.00	
[09/26 04:04:00 visual_prompt]: Best epoch 1: best metric: 0.010
[09/26 04:04:00 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.025
[09/26 04:04:07 visual_prompt]: Epoch 2 / 100: avg data time: 4.74e-02, avg batch time: 0.4889, average train loss: 4.6272
[09/26 04:04:08 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1662, average loss: 4.6088
[09/26 04:04:08 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 7.00	
[09/26 04:04:08 visual_prompt]: Best epoch 2: best metric: 0.015
[09/26 04:04:08 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.05
[09/26 04:04:15 visual_prompt]: Epoch 3 / 100: avg data time: 4.92e-02, avg batch time: 0.4917, average train loss: 4.5890
[09/26 04:04:17 visual_prompt]: Inference (val):avg data time: 4.88e-05, avg batch time: 0.1664, average loss: 4.6046
[09/26 04:04:17 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 6.50	
[09/26 04:04:17 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.075
[09/26 04:04:23 visual_prompt]: Epoch 4 / 100: avg data time: 5.69e-02, avg batch time: 0.5001, average train loss: 4.5446
[09/26 04:04:25 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1666, average loss: 4.5685
[09/26 04:04:25 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 10.50	
[09/26 04:04:25 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.1
[09/26 04:04:32 visual_prompt]: Epoch 5 / 100: avg data time: 5.33e-02, avg batch time: 0.4951, average train loss: 4.4145
[09/26 04:04:33 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1665, average loss: 4.2464
[09/26 04:04:33 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 4.00	top5: 19.50	
[09/26 04:04:33 visual_prompt]: Best epoch 5: best metric: 0.040
[09/26 04:04:33 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.125
[09/26 04:04:40 visual_prompt]: Epoch 6 / 100: avg data time: 4.91e-02, avg batch time: 0.4917, average train loss: 4.0717
[09/26 04:04:41 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1665, average loss: 3.9039
[09/26 04:04:41 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 9.50	top5: 29.50	
[09/26 04:04:41 visual_prompt]: Best epoch 6: best metric: 0.095
[09/26 04:04:41 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.15
[09/26 04:04:48 visual_prompt]: Epoch 7 / 100: avg data time: 5.82e-02, avg batch time: 0.4997, average train loss: 3.5613
[09/26 04:04:50 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1667, average loss: 3.3863
[09/26 04:04:50 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 12.00	top5: 46.50	
[09/26 04:04:50 visual_prompt]: Best epoch 7: best metric: 0.120
[09/26 04:04:50 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.175
[09/26 04:04:57 visual_prompt]: Epoch 8 / 100: avg data time: 5.96e-02, avg batch time: 0.5022, average train loss: 2.9350
[09/26 04:04:58 visual_prompt]: Inference (val):avg data time: 3.56e-05, avg batch time: 0.1665, average loss: 3.0098
[09/26 04:04:58 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 28.00	top5: 57.50	
[09/26 04:04:58 visual_prompt]: Best epoch 8: best metric: 0.280
[09/26 04:04:58 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.2
[09/26 04:05:05 visual_prompt]: Epoch 9 / 100: avg data time: 4.91e-02, avg batch time: 0.4923, average train loss: 3.2617
[09/26 04:05:06 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1666, average loss: 4.7165
[09/26 04:05:06 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 7.50	
[09/26 04:05:06 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.225
[09/26 04:05:13 visual_prompt]: Epoch 10 / 100: avg data time: 6.05e-02, avg batch time: 0.5027, average train loss: 4.1432
[09/26 04:05:15 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1667, average loss: 3.8036
[09/26 04:05:15 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 10.50	top5: 35.50	
[09/26 04:05:15 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.25
[09/26 04:05:21 visual_prompt]: Epoch 11 / 100: avg data time: 5.47e-02, avg batch time: 0.4964, average train loss: 3.2772
[09/26 04:05:23 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1666, average loss: 3.8035
[09/26 04:05:23 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 17.00	top5: 39.50	
[09/26 04:05:23 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.24992385337738698
[09/26 04:05:30 visual_prompt]: Epoch 12 / 100: avg data time: 5.50e-02, avg batch time: 0.4965, average train loss: 3.1239
[09/26 04:05:31 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1668, average loss: 3.0363
[09/26 04:05:31 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 31.00	top5: 62.00	
[09/26 04:05:31 visual_prompt]: Best epoch 12: best metric: 0.310
[09/26 04:05:31 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.24969550628247802
[09/26 04:05:38 visual_prompt]: Epoch 13 / 100: avg data time: 4.42e-02, avg batch time: 0.4870, average train loss: 2.0056
[09/26 04:05:39 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1668, average loss: 2.1742
[09/26 04:05:39 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 52.00	top5: 87.00	
[09/26 04:05:39 visual_prompt]: Best epoch 13: best metric: 0.520
[09/26 04:05:39 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.24931523692103416
[09/26 04:05:46 visual_prompt]: Epoch 14 / 100: avg data time: 6.04e-02, avg batch time: 0.5033, average train loss: 1.4478
[09/26 04:05:48 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1669, average loss: 1.8553
[09/26 04:05:48 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 60.50	top5: 89.50	
[09/26 04:05:48 visual_prompt]: Best epoch 14: best metric: 0.605
[09/26 04:05:48 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.2487835085926963
[09/26 04:05:55 visual_prompt]: Epoch 15 / 100: avg data time: 5.63e-02, avg batch time: 0.4984, average train loss: 1.0268
[09/26 04:05:56 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1669, average loss: 1.8865
[09/26 04:05:56 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.50	top5: 88.00	
[09/26 04:05:56 visual_prompt]: Best epoch 15: best metric: 0.615
[09/26 04:05:56 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.24810096912652602
[09/26 04:06:03 visual_prompt]: Epoch 16 / 100: avg data time: 5.79e-02, avg batch time: 0.5008, average train loss: 0.9885
[09/26 04:06:04 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1668, average loss: 1.7340
[09/26 04:06:04 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.00	top5: 91.50	
[09/26 04:06:04 visual_prompt]: Best epoch 16: best metric: 0.630
[09/26 04:06:04 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.2472684500917257
[09/26 04:06:11 visual_prompt]: Epoch 17 / 100: avg data time: 5.65e-02, avg batch time: 0.4991, average train loss: 0.8755
[09/26 04:06:13 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1668, average loss: 1.5508
[09/26 04:06:13 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 71.00	top5: 94.00	
[09/26 04:06:13 visual_prompt]: Best epoch 17: best metric: 0.710
[09/26 04:06:13 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.24628696578449955
[09/26 04:06:20 visual_prompt]: Epoch 18 / 100: avg data time: 5.88e-02, avg batch time: 0.5016, average train loss: 1.7848
[09/26 04:06:21 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1665, average loss: 4.5988
[09/26 04:06:21 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.50	top5: 5.00	
[09/26 04:06:21 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.24515771199228986
[09/26 04:06:28 visual_prompt]: Epoch 19 / 100: avg data time: 5.67e-02, avg batch time: 0.4986, average train loss: 4.5662
[09/26 04:06:30 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1664, average loss: 4.5810
[09/26 04:06:30 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 8.50	
[09/26 04:06:30 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.2438820645368942
[09/26 04:06:36 visual_prompt]: Epoch 20 / 100: avg data time: 5.90e-02, avg batch time: 0.5023, average train loss: 4.4250
[09/26 04:06:38 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1667, average loss: 4.2898
[09/26 04:06:38 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 6.50	top5: 24.50	
[09/26 04:06:38 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.24246157759823855
[09/26 04:06:45 visual_prompt]: Epoch 21 / 100: avg data time: 5.45e-02, avg batch time: 0.4964, average train loss: 3.4798
[09/26 04:06:46 visual_prompt]: Inference (val):avg data time: 1.85e-05, avg batch time: 0.1666, average loss: 3.1701
[09/26 04:06:46 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 41.50	top5: 72.50	
[09/26 04:06:46 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.24089798182084843
[09/26 04:06:53 visual_prompt]: Epoch 22 / 100: avg data time: 5.74e-02, avg batch time: 0.5017, average train loss: 2.9799
[09/26 04:06:55 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.1666, average loss: 2.7556
[09/26 04:06:55 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 45.00	top5: 77.50	
[09/26 04:06:55 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.2391931822053251
[09/26 04:07:01 visual_prompt]: Epoch 23 / 100: avg data time: 4.97e-02, avg batch time: 0.4933, average train loss: 1.7776
[09/26 04:07:03 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1668, average loss: 1.9187
[09/26 04:07:03 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.00	top5: 88.00	
[09/26 04:07:03 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.23734925578739588
[09/26 04:07:10 visual_prompt]: Epoch 24 / 100: avg data time: 5.84e-02, avg batch time: 0.5017, average train loss: 1.2113
[09/26 04:07:11 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1670, average loss: 1.7204
[09/26 04:07:11 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 64.50	top5: 88.50	
[09/26 04:07:11 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.23536844910736587
[09/26 04:07:18 visual_prompt]: Epoch 25 / 100: avg data time: 5.08e-02, avg batch time: 0.4962, average train loss: 1.0066
[09/26 04:07:19 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1668, average loss: 1.4981
[09/26 04:07:19 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 71.00	top5: 93.50	
[09/26 04:07:19 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.23325317547305485
[09/26 04:07:26 visual_prompt]: Epoch 26 / 100: avg data time: 5.86e-02, avg batch time: 0.5006, average train loss: 0.8236
[09/26 04:07:28 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1668, average loss: 1.7166
[09/26 04:07:28 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.50	top5: 88.00	
[09/26 04:07:28 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.23100601201955323
[09/26 04:07:34 visual_prompt]: Epoch 27 / 100: avg data time: 5.59e-02, avg batch time: 0.4996, average train loss: 0.8631
[09/26 04:07:36 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1668, average loss: 1.5220
[09/26 04:07:36 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 71.50	top5: 92.50	
[09/26 04:07:36 visual_prompt]: Best epoch 27: best metric: 0.715
[09/26 04:07:36 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.2286296965693802
[09/26 04:07:43 visual_prompt]: Epoch 28 / 100: avg data time: 5.65e-02, avg batch time: 0.4998, average train loss: 0.7918
[09/26 04:07:44 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1670, average loss: 1.4873
[09/26 04:07:44 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 73.50	top5: 94.50	
[09/26 04:07:44 visual_prompt]: Best epoch 28: best metric: 0.735
[09/26 04:07:44 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.22612712429686843
[09/26 04:07:51 visual_prompt]: Epoch 29 / 100: avg data time: 6.00e-02, avg batch time: 0.5032, average train loss: 0.7140
[09/26 04:07:53 visual_prompt]: Inference (val):avg data time: 1.87e-05, avg batch time: 0.1668, average loss: 1.5305
[09/26 04:07:53 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 71.50	top5: 91.00	
[09/26 04:07:53 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.22350134420084022
[09/26 04:07:59 visual_prompt]: Epoch 30 / 100: avg data time: 4.42e-02, avg batch time: 0.4865, average train loss: 2.3769
[09/26 04:08:01 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1667, average loss: 2.6458
[09/26 04:08:01 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 43.50	top5: 75.50	
[09/26 04:08:01 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.22075555538987224
[09/26 04:08:07 visual_prompt]: Epoch 31 / 100: avg data time: 5.22e-02, avg batch time: 0.4961, average train loss: 1.6145
[09/26 04:08:09 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1666, average loss: 1.9698
[09/26 04:08:09 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.50	top5: 89.50	
[09/26 04:08:09 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.21789310318467428
[09/26 04:08:16 visual_prompt]: Epoch 32 / 100: avg data time: 5.86e-02, avg batch time: 0.5030, average train loss: 1.0671
[09/26 04:08:17 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1668, average loss: 1.5763
[09/26 04:08:17 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 73.00	top5: 92.00	
[09/26 04:08:17 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.21491747504233139
[09/26 04:08:24 visual_prompt]: Epoch 33 / 100: avg data time: 5.83e-02, avg batch time: 0.5033, average train loss: 0.8038
[09/26 04:08:25 visual_prompt]: Inference (val):avg data time: 2.05e-05, avg batch time: 0.1672, average loss: 1.3660
[09/26 04:08:25 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 74.00	top5: 96.00	
[09/26 04:08:25 visual_prompt]: Best epoch 33: best metric: 0.740
[09/26 04:08:25 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.21183229630737466
[09/26 04:08:32 visual_prompt]: Epoch 34 / 100: avg data time: 5.26e-02, avg batch time: 0.4968, average train loss: 0.6350
[09/26 04:08:34 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1668, average loss: 1.2786
[09/26 04:08:34 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 78.50	top5: 95.50	
[09/26 04:08:34 visual_prompt]: Best epoch 34: best metric: 0.785
[09/26 04:08:34 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.20864132579485728
[09/26 04:08:41 visual_prompt]: Epoch 35 / 100: avg data time: 5.65e-02, avg batch time: 0.5017, average train loss: 0.5772
[09/26 04:08:42 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1669, average loss: 1.3241
[09/26 04:08:42 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 75.50	top5: 95.00	
[09/26 04:08:42 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.2053484512108174
[09/26 04:08:49 visual_prompt]: Epoch 36 / 100: avg data time: 4.78e-02, avg batch time: 0.4921, average train loss: 0.5856
[09/26 04:08:50 visual_prompt]: Inference (val):avg data time: 2.05e-05, avg batch time: 0.1668, average loss: 1.3226
[09/26 04:08:50 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 78.50	top5: 96.00	
[09/26 04:08:50 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.20195768441570727
[09/26 04:08:57 visual_prompt]: Epoch 37 / 100: avg data time: 4.45e-02, avg batch time: 0.4894, average train loss: 0.7319
[09/26 04:08:58 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1670, average loss: 1.7260
[09/26 04:08:58 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 68.50	top5: 91.00	
[09/26 04:08:58 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.19847315653655914
[09/26 04:09:05 visual_prompt]: Epoch 38 / 100: avg data time: 4.79e-02, avg batch time: 0.4917, average train loss: 1.9291
[09/26 04:09:07 visual_prompt]: Inference (val):avg data time: 2.05e-05, avg batch time: 0.1669, average loss: 2.1750
[09/26 04:09:07 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 56.50	top5: 84.00	
[09/26 04:09:07 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.19489911293384335
[09/26 04:09:13 visual_prompt]: Epoch 39 / 100: avg data time: 5.54e-02, avg batch time: 0.4980, average train loss: 1.3145
[09/26 04:09:15 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1667, average loss: 1.8285
[09/26 04:09:15 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 71.00	top5: 92.50	
[09/26 04:09:15 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.1912399080291506
[09/26 04:09:22 visual_prompt]: Epoch 40 / 100: avg data time: 5.37e-02, avg batch time: 0.4978, average train loss: 0.9846
[09/26 04:09:23 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1668, average loss: 1.3422
[09/26 04:09:23 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 75.50	top5: 94.50	
[09/26 04:09:23 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.1875
[09/26 04:09:30 visual_prompt]: Epoch 41 / 100: avg data time: 5.50e-02, avg batch time: 0.4978, average train loss: 0.6800
[09/26 04:09:31 visual_prompt]: Inference (val):avg data time: 1.90e-05, avg batch time: 0.1669, average loss: 2.4654
[09/26 04:09:31 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 73.00	top5: 93.50	
[09/26 04:09:31 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.18368394534823634
[09/26 04:09:38 visual_prompt]: Epoch 42 / 100: avg data time: 5.98e-02, avg batch time: 0.5021, average train loss: 2.8150
[09/26 04:09:40 visual_prompt]: Inference (val):avg data time: 1.97e-05, avg batch time: 0.1670, average loss: 2.0417
[09/26 04:09:40 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 57.00	top5: 88.50	
[09/26 04:09:40 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.17979639334863468
[09/26 04:09:46 visual_prompt]: Epoch 43 / 100: avg data time: 5.66e-02, avg batch time: 0.4992, average train loss: 1.2743
[09/26 04:09:48 visual_prompt]: Inference (val):avg data time: 2.01e-05, avg batch time: 0.1668, average loss: 1.5168
[09/26 04:09:48 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 70.50	top5: 92.50	
[09/26 04:09:48 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.17584208038447505
[09/26 04:09:55 visual_prompt]: Epoch 44 / 100: avg data time: 5.51e-02, avg batch time: 0.4973, average train loss: 0.8640
[09/26 04:09:56 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1667, average loss: 1.3684
[09/26 04:09:56 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 74.00	top5: 93.50	
[09/26 04:09:56 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.17182582417698902
[09/26 04:10:03 visual_prompt]: Epoch 45 / 100: avg data time: 5.80e-02, avg batch time: 0.5001, average train loss: 0.6640
[09/26 04:10:05 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1666, average loss: 1.2150
[09/26 04:10:05 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 76.00	top5: 94.50	
[09/26 04:10:05 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.1677525179157086
[09/26 04:10:11 visual_prompt]: Epoch 46 / 100: avg data time: 5.63e-02, avg batch time: 0.4994, average train loss: 0.5478
[09/26 04:10:13 visual_prompt]: Inference (val):avg data time: 1.96e-05, avg batch time: 0.1668, average loss: 1.1549
[09/26 04:10:13 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 79.50	top5: 95.00	
[09/26 04:10:13 visual_prompt]: Best epoch 46: best metric: 0.795
[09/26 04:10:13 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.16362712429686843
[09/26 04:10:20 visual_prompt]: Epoch 47 / 100: avg data time: 5.79e-02, avg batch time: 0.5005, average train loss: 0.5130
[09/26 04:10:21 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.1667, average loss: 1.1802
[09/26 04:10:21 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 82.50	top5: 96.00	
[09/26 04:10:21 visual_prompt]: Best epoch 47: best metric: 0.825
[09/26 04:10:21 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.1594546694771249
[09/26 04:10:28 visual_prompt]: Epoch 48 / 100: avg data time: 5.53e-02, avg batch time: 0.4979, average train loss: 0.5093
[09/26 04:10:30 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1666, average loss: 1.1592
[09/26 04:10:30 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 80.50	top5: 95.50	
[09/26 04:10:30 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.15524023694995845
[09/26 04:10:36 visual_prompt]: Epoch 49 / 100: avg data time: 5.56e-02, avg batch time: 0.4993, average train loss: 1.9394
[09/26 04:10:38 visual_prompt]: Inference (val):avg data time: 3.57e-05, avg batch time: 0.1668, average loss: 3.6894
[09/26 04:10:38 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 22.50	top5: 46.50	
[09/26 04:10:38 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.1509889613522199
[09/26 04:10:45 visual_prompt]: Epoch 50 / 100: avg data time: 6.66e-02, avg batch time: 0.5090, average train loss: 2.9659
[09/26 04:10:46 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1673, average loss: 3.4068
[09/26 04:10:46 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 26.00	top5: 57.00	
[09/26 04:10:46 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.14670602220836632
[09/26 04:10:53 visual_prompt]: Epoch 51 / 100: avg data time: 6.50e-02, avg batch time: 0.5070, average train loss: 2.0444
[09/26 04:10:55 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1670, average loss: 1.8245
[09/26 04:10:55 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.50	top5: 89.50	
[09/26 04:10:55 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.14239663762000818
[09/26 04:11:01 visual_prompt]: Epoch 52 / 100: avg data time: 4.76e-02, avg batch time: 0.4912, average train loss: 1.1404
[09/26 04:11:03 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1667, average loss: 1.5254
[09/26 04:11:03 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 74.00	top5: 92.00	
[09/26 04:11:03 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.1380660579084567
[09/26 04:11:10 visual_prompt]: Epoch 53 / 100: avg data time: 4.47e-02, avg batch time: 0.4877, average train loss: 0.8263
[09/26 04:11:11 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1668, average loss: 1.3827
[09/26 04:11:11 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 76.00	top5: 92.50	
[09/26 04:11:11 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.13371955921801565
[09/26 04:11:18 visual_prompt]: Epoch 54 / 100: avg data time: 5.53e-02, avg batch time: 0.4987, average train loss: 0.6270
[09/26 04:11:19 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1669, average loss: 1.2360
[09/26 04:11:19 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 78.50	top5: 94.00	
[09/26 04:11:19 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.12936243708781264
[09/26 04:11:26 visual_prompt]: Epoch 55 / 100: avg data time: 4.67e-02, avg batch time: 0.4906, average train loss: 0.5162
[09/26 04:11:28 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1667, average loss: 1.2211
[09/26 04:11:28 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 76.00	top5: 95.00	
[09/26 04:11:28 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.125
[09/26 04:11:34 visual_prompt]: Epoch 56 / 100: avg data time: 5.03e-02, avg batch time: 0.4931, average train loss: 0.5079
[09/26 04:11:36 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1667, average loss: 1.2535
[09/26 04:11:36 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 77.50	top5: 94.50	
[09/26 04:11:36 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.12063756291218741
[09/26 04:11:43 visual_prompt]: Epoch 57 / 100: avg data time: 5.95e-02, avg batch time: 0.5018, average train loss: 0.4956
[09/26 04:11:44 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1666, average loss: 1.2717
[09/26 04:11:44 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 76.50	top5: 94.50	
[09/26 04:11:44 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.11628044078198434
[09/26 04:11:51 visual_prompt]: Epoch 58 / 100: avg data time: 5.44e-02, avg batch time: 0.4972, average train loss: 0.4477
[09/26 04:11:53 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1671, average loss: 1.2863
[09/26 04:11:53 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 72.50	top5: 94.50	
[09/26 04:11:53 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.11193394209154334
[09/26 04:11:59 visual_prompt]: Epoch 59 / 100: avg data time: 5.43e-02, avg batch time: 0.4972, average train loss: 1.3231
[09/26 04:12:01 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1670, average loss: 1.9192
[09/26 04:12:01 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 73.00	top5: 91.00	
[09/26 04:12:01 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.10760336237999185
[09/26 04:12:08 visual_prompt]: Epoch 60 / 100: avg data time: 5.48e-02, avg batch time: 0.4974, average train loss: 0.9323
[09/26 04:12:09 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1667, average loss: 1.8573
[09/26 04:12:09 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.00	top5: 87.00	
[09/26 04:12:09 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.10329397779163371
[09/26 04:12:16 visual_prompt]: Epoch 61 / 100: avg data time: 5.41e-02, avg batch time: 0.4963, average train loss: 0.8432
[09/26 04:12:17 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1670, average loss: 1.4227
[09/26 04:12:17 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 73.50	top5: 93.50	
[09/26 04:12:17 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.0990110386477801
[09/26 04:12:24 visual_prompt]: Epoch 62 / 100: avg data time: 6.05e-02, avg batch time: 0.5029, average train loss: 0.5923
[09/26 04:12:26 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1669, average loss: 1.2234
[09/26 04:12:26 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 79.00	top5: 94.50	
[09/26 04:12:26 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.09475976305004155
[09/26 04:12:33 visual_prompt]: Epoch 63 / 100: avg data time: 6.07e-02, avg batch time: 0.5038, average train loss: 0.4665
[09/26 04:12:34 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1669, average loss: 1.1709
[09/26 04:12:34 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 79.50	top5: 96.00	
[09/26 04:12:34 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.09054533052287511
[09/26 04:12:41 visual_prompt]: Epoch 64 / 100: avg data time: 5.28e-02, avg batch time: 0.4952, average train loss: 0.4082
[09/26 04:12:42 visual_prompt]: Inference (val):avg data time: 4.17e-05, avg batch time: 0.1669, average loss: 1.1460
[09/26 04:12:42 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 80.50	top5: 95.50	
[09/26 04:12:42 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.08637287570313158
[09/26 04:12:49 visual_prompt]: Epoch 65 / 100: avg data time: 5.45e-02, avg batch time: 0.4966, average train loss: 0.3811
[09/26 04:12:51 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1669, average loss: 1.1848
[09/26 04:12:51 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 80.50	top5: 96.50	
[09/26 04:12:51 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.08224748208429142
[09/26 04:12:57 visual_prompt]: Epoch 66 / 100: avg data time: 5.31e-02, avg batch time: 0.4958, average train loss: 0.3606
[09/26 04:12:59 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1672, average loss: 1.1857
[09/26 04:12:59 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 78.00	top5: 96.00	
[09/26 04:12:59 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.07817417582301099
[09/26 04:13:06 visual_prompt]: Epoch 67 / 100: avg data time: 5.81e-02, avg batch time: 0.5003, average train loss: 0.3593
[09/26 04:13:07 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1669, average loss: 1.2239
[09/26 04:13:07 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 79.00	top5: 96.00	
[09/26 04:13:07 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.074157919615525
[09/26 04:13:14 visual_prompt]: Epoch 68 / 100: avg data time: 6.39e-02, avg batch time: 0.5063, average train loss: 0.3548
[09/26 04:13:16 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1670, average loss: 1.2358
[09/26 04:13:16 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 80.50	top5: 94.50	
[09/26 04:13:16 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.07020360665136531
[09/26 04:13:22 visual_prompt]: Epoch 69 / 100: avg data time: 6.11e-02, avg batch time: 0.5041, average train loss: 0.3525
[09/26 04:13:24 visual_prompt]: Inference (val):avg data time: 4.06e-05, avg batch time: 0.1669, average loss: 1.2088
[09/26 04:13:24 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 78.00	top5: 95.50	
[09/26 04:13:24 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.06631605465176368
[09/26 04:13:31 visual_prompt]: Epoch 70 / 100: avg data time: 4.45e-02, avg batch time: 0.4880, average train loss: 0.3629
[09/26 04:13:32 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1669, average loss: 1.2114
[09/26 04:13:32 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 78.50	top5: 96.00	
[09/26 04:13:32 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.06250000000000003
[09/26 04:13:39 visual_prompt]: Epoch 71 / 100: avg data time: 5.48e-02, avg batch time: 0.4983, average train loss: 0.3833
[09/26 04:13:41 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1668, average loss: 1.2344
[09/26 04:13:41 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 81.00	top5: 95.50	
[09/26 04:13:41 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.0587600919708494
[09/26 04:13:47 visual_prompt]: Epoch 72 / 100: avg data time: 5.72e-02, avg batch time: 0.5007, average train loss: 0.3815
[09/26 04:13:49 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1668, average loss: 1.2190
[09/26 04:13:49 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 78.00	top5: 95.50	
[09/26 04:13:49 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.055100887066156665
[09/26 04:13:56 visual_prompt]: Epoch 73 / 100: avg data time: 6.08e-02, avg batch time: 0.5043, average train loss: 0.3593
[09/26 04:13:57 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1670, average loss: 1.2201
[09/26 04:13:57 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 78.50	top5: 94.50	
[09/26 04:13:57 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.05152684346344087
[09/26 04:14:04 visual_prompt]: Epoch 74 / 100: avg data time: 6.16e-02, avg batch time: 0.5040, average train loss: 0.3411
[09/26 04:14:06 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1670, average loss: 1.2407
[09/26 04:14:06 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 79.50	top5: 95.00	
[09/26 04:14:06 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.048042315584292714
[09/26 04:14:13 visual_prompt]: Epoch 75 / 100: avg data time: 5.90e-02, avg batch time: 0.5016, average train loss: 0.3114
[09/26 04:14:14 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1668, average loss: 1.1901
[09/26 04:14:14 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 80.00	top5: 95.00	
[09/26 04:14:14 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.04465154878918258
[09/26 04:14:21 visual_prompt]: Epoch 76 / 100: avg data time: 5.67e-02, avg batch time: 0.4993, average train loss: 0.2805
[09/26 04:14:22 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1669, average loss: 1.1798
[09/26 04:14:22 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 78.50	top5: 95.00	
[09/26 04:14:22 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.04135867420514276
[09/26 04:14:29 visual_prompt]: Epoch 77 / 100: avg data time: 5.97e-02, avg batch time: 0.5033, average train loss: 0.2710
[09/26 04:14:31 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1669, average loss: 1.2435
[09/26 04:14:31 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 81.50	top5: 94.50	
[09/26 04:14:31 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.03816770369262533
[09/26 04:14:38 visual_prompt]: Epoch 78 / 100: avg data time: 5.45e-02, avg batch time: 0.4991, average train loss: 0.2617
[09/26 04:14:39 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1672, average loss: 1.1710
[09/26 04:14:39 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 80.50	top5: 95.00	
[09/26 04:14:39 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.03508252495766863
[09/26 04:14:46 visual_prompt]: Epoch 79 / 100: avg data time: 6.30e-02, avg batch time: 0.5062, average train loss: 0.2566
[09/26 04:14:47 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1670, average loss: 1.2364
[09/26 04:14:47 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 77.00	top5: 94.00	
[09/26 04:14:47 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.032106896815325706
[09/26 04:14:54 visual_prompt]: Epoch 80 / 100: avg data time: 5.13e-02, avg batch time: 0.4951, average train loss: 0.2548
[09/26 04:14:56 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1671, average loss: 1.2142
[09/26 04:14:56 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 82.50	top5: 94.50	
[09/26 04:14:56 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.029244444610127762
[09/26 04:15:02 visual_prompt]: Epoch 81 / 100: avg data time: 5.65e-02, avg batch time: 0.4998, average train loss: 0.2524
[09/26 04:15:04 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1669, average loss: 1.2385
[09/26 04:15:04 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 81.00	top5: 94.00	
[09/26 04:15:04 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.026498655799159762
[09/26 04:15:11 visual_prompt]: Epoch 82 / 100: avg data time: 5.22e-02, avg batch time: 0.4944, average train loss: 0.2525
[09/26 04:15:12 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1671, average loss: 1.2769
[09/26 04:15:12 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 78.00	top5: 94.00	
[09/26 04:15:12 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.023872875703131582
[09/26 04:15:19 visual_prompt]: Epoch 83 / 100: avg data time: 5.62e-02, avg batch time: 0.4995, average train loss: 0.2495
[09/26 04:15:21 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1669, average loss: 1.2692
[09/26 04:15:21 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 77.00	top5: 94.50	
[09/26 04:15:21 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.021370303430619797
[09/26 04:15:27 visual_prompt]: Epoch 84 / 100: avg data time: 5.66e-02, avg batch time: 0.4995, average train loss: 0.2496
[09/26 04:15:29 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1667, average loss: 1.2798
[09/26 04:15:29 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 77.00	top5: 94.50	
[09/26 04:15:29 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.018993987980446755
[09/26 04:15:35 visual_prompt]: Epoch 85 / 100: avg data time: 4.52e-02, avg batch time: 0.4881, average train loss: 0.2467
[09/26 04:15:37 visual_prompt]: Inference (val):avg data time: 1.98e-05, avg batch time: 0.1669, average loss: 1.2790
[09/26 04:15:37 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 77.50	top5: 94.00	
[09/26 04:15:37 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.01674682452694516
[09/26 04:15:44 visual_prompt]: Epoch 86 / 100: avg data time: 5.34e-02, avg batch time: 0.4972, average train loss: 0.2424
[09/26 04:15:45 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1671, average loss: 1.2982
[09/26 04:15:45 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 77.00	top5: 94.50	
[09/26 04:15:45 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.014631550892634126
[09/26 04:15:52 visual_prompt]: Epoch 87 / 100: avg data time: 5.41e-02, avg batch time: 0.4985, average train loss: 0.2399
[09/26 04:15:53 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1671, average loss: 1.2589
[09/26 04:15:53 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 76.50	top5: 95.00	
[09/26 04:15:53 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.012650744212604148
[09/26 04:16:00 visual_prompt]: Epoch 88 / 100: avg data time: 5.60e-02, avg batch time: 0.5001, average train loss: 0.2394
[09/26 04:16:02 visual_prompt]: Inference (val):avg data time: 2.05e-05, avg batch time: 0.1672, average loss: 1.2987
[09/26 04:16:02 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 76.50	top5: 94.50	
[09/26 04:16:02 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.010806817794674878
[09/26 04:16:09 visual_prompt]: Epoch 89 / 100: avg data time: 5.53e-02, avg batch time: 0.4993, average train loss: 0.2365
[09/26 04:16:10 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1669, average loss: 1.2768
[09/26 04:16:10 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 76.50	top5: 95.00	
[09/26 04:16:10 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.009102018179151586
[09/26 04:16:17 visual_prompt]: Epoch 90 / 100: avg data time: 5.98e-02, avg batch time: 0.5041, average train loss: 0.2344
[09/26 04:16:18 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1668, average loss: 1.2822
[09/26 04:16:18 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 75.00	top5: 95.50	
[09/26 04:16:18 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.00753842240176146
[09/26 04:16:25 visual_prompt]: Epoch 91 / 100: avg data time: 6.04e-02, avg batch time: 0.5041, average train loss: 0.2337
[09/26 04:16:27 visual_prompt]: Inference (val):avg data time: 1.90e-05, avg batch time: 0.1668, average loss: 1.3189
[09/26 04:16:27 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 74.50	top5: 94.50	
[09/26 04:16:27 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.006117935463105809
[09/26 04:16:34 visual_prompt]: Epoch 92 / 100: avg data time: 5.18e-02, avg batch time: 0.4943, average train loss: 0.2318
[09/26 04:16:35 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.1670, average loss: 1.3255
[09/26 04:16:35 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 74.00	top5: 94.00	
[09/26 04:16:35 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.004842288007710138
[09/26 04:16:42 visual_prompt]: Epoch 93 / 100: avg data time: 4.81e-02, avg batch time: 0.4913, average train loss: 0.2311
[09/26 04:16:43 visual_prompt]: Inference (val):avg data time: 2.08e-05, avg batch time: 0.1668, average loss: 1.3253
[09/26 04:16:43 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 73.50	top5: 94.00	
[09/26 04:16:43 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.003713034215500441
[09/26 04:16:50 visual_prompt]: Epoch 94 / 100: avg data time: 5.79e-02, avg batch time: 0.5029, average train loss: 0.2299
[09/26 04:16:52 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1670, average loss: 1.3322
[09/26 04:16:52 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 73.50	top5: 94.50	
[09/26 04:16:52 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.002731549908274289
[09/26 04:16:58 visual_prompt]: Epoch 95 / 100: avg data time: 6.39e-02, avg batch time: 0.5062, average train loss: 0.2291
[09/26 04:17:00 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1669, average loss: 1.3325
[09/26 04:17:00 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 73.50	top5: 94.50	
[09/26 04:17:00 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.0018990308734739975
[09/26 04:17:07 visual_prompt]: Epoch 96 / 100: avg data time: 5.51e-02, avg batch time: 0.4994, average train loss: 0.2286
[09/26 04:17:08 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1670, average loss: 1.3301
[09/26 04:17:08 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 73.50	top5: 94.50	
[09/26 04:17:08 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.0012164914073037048
[09/26 04:17:15 visual_prompt]: Epoch 97 / 100: avg data time: 5.41e-02, avg batch time: 0.4971, average train loss: 0.2287
[09/26 04:17:17 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1667, average loss: 1.3313
[09/26 04:17:17 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 73.00	top5: 94.50	
[09/26 04:17:17 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.0006847630789658388
[09/26 04:17:23 visual_prompt]: Epoch 98 / 100: avg data time: 6.33e-02, avg batch time: 0.5064, average train loss: 0.2277
[09/26 04:17:25 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1668, average loss: 1.3386
[09/26 04:17:25 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 73.50	top5: 94.50	
[09/26 04:17:25 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.0003044937175219753
[09/26 04:17:32 visual_prompt]: Epoch 99 / 100: avg data time: 6.22e-02, avg batch time: 0.5046, average train loss: 0.2279
[09/26 04:17:33 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1667, average loss: 1.3373
[09/26 04:17:33 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 73.50	top5: 94.50	
[09/26 04:17:33 visual_prompt]: Training 100 / 100 epoch, with learning rate 7.614662261302974e-05
[09/26 04:17:40 visual_prompt]: Epoch 100 / 100: avg data time: 5.62e-02, avg batch time: 0.4986, average train loss: 0.2276
[09/26 04:17:42 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1668, average loss: 1.3369
[09/26 04:17:42 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 73.50	top5: 94.50	
[09/26 04:17:42 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 04:17:42 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 04:17:42 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-cifar(num_classes=100)', 'DATA.NUMBER_CLASSES', '100', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 04:17:42 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 04:17:42 visual_prompt]: Training with config:
[09/26 04:17:42 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-cifar(num_classes=100)/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.25_wd0.001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 0.25, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-cifar(num_classes=100)', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 100, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 04:17:42 visual_prompt]: Loading training data...
[09/26 04:17:42 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[:800], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/26 04:17:43 visual_prompt]: Number of images: 800
[09/26 04:17:43 visual_prompt]: Number of classes: 100 / 100
[09/26 04:17:43 visual_prompt]: Loading validation data...
[09/26 04:17:43 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[45000:45200], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/26 04:17:43 visual_prompt]: Number of images: 200
[09/26 04:17:43 visual_prompt]: Number of classes: 90 / 100
[09/26 04:17:43 visual_prompt]: Constructing models...
[09/26 04:17:45 visual_prompt]: Total Parameters: 86336356	 Gradient Parameters: 537700
[09/26 04:17:45 visual_prompt]: tuned percent:0.623
[09/26 04:17:45 visual_prompt]: Device used for model: 0
[09/26 04:17:45 visual_prompt]: Setting up Evaluator...
[09/26 04:17:45 visual_prompt]: Setting up Trainer...
[09/26 04:17:45 visual_prompt]: 	Setting up the optimizer...
[09/26 04:17:45 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 04:17:52 visual_prompt]: Epoch 1 / 100: avg data time: 5.94e-02, avg batch time: 0.5016, average train loss: 4.6546
[09/26 04:17:54 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1658, average loss: 4.6218
[09/26 04:17:54 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 7.00	
[09/26 04:17:54 visual_prompt]: Best epoch 1: best metric: 0.010
[09/26 04:17:54 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.025
[09/26 04:18:01 visual_prompt]: Epoch 2 / 100: avg data time: 5.50e-02, avg batch time: 0.4969, average train loss: 4.6366
[09/26 04:18:02 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1660, average loss: 4.6084
[09/26 04:18:02 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 7.00	
[09/26 04:18:02 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.05
[09/26 04:18:09 visual_prompt]: Epoch 3 / 100: avg data time: 5.45e-02, avg batch time: 0.4964, average train loss: 4.5835
[09/26 04:18:10 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1661, average loss: 4.6372
[09/26 04:18:10 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 2.50	
[09/26 04:18:10 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.075
[09/26 04:18:17 visual_prompt]: Epoch 4 / 100: avg data time: 5.99e-02, avg batch time: 0.5008, average train loss: 4.5680
[09/26 04:18:19 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1661, average loss: 4.6138
[09/26 04:18:19 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 6.00	
[09/26 04:18:19 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.1
[09/26 04:18:25 visual_prompt]: Epoch 5 / 100: avg data time: 5.80e-02, avg batch time: 0.5008, average train loss: 4.5256
[09/26 04:18:27 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1662, average loss: 4.5456
[09/26 04:18:27 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 12.00	
[09/26 04:18:27 visual_prompt]: Best epoch 5: best metric: 0.015
[09/26 04:18:27 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.125
[09/26 04:18:34 visual_prompt]: Epoch 6 / 100: avg data time: 6.06e-02, avg batch time: 0.5016, average train loss: 4.3158
[09/26 04:18:35 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1661, average loss: 4.2656
[09/26 04:18:35 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 6.50	top5: 20.50	
[09/26 04:18:35 visual_prompt]: Best epoch 6: best metric: 0.065
[09/26 04:18:35 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.15
[09/26 04:18:42 visual_prompt]: Epoch 7 / 100: avg data time: 5.72e-02, avg batch time: 0.4997, average train loss: 3.7913
[09/26 04:18:44 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1663, average loss: 3.8593
[09/26 04:18:44 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 10.50	top5: 29.00	
[09/26 04:18:44 visual_prompt]: Best epoch 7: best metric: 0.105
[09/26 04:18:44 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.175
[09/26 04:18:50 visual_prompt]: Epoch 8 / 100: avg data time: 5.16e-02, avg batch time: 0.4939, average train loss: 3.3295
[09/26 04:18:52 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1663, average loss: 3.3241
[09/26 04:18:52 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 17.50	top5: 45.50	
[09/26 04:18:52 visual_prompt]: Best epoch 8: best metric: 0.175
[09/26 04:18:52 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.2
[09/26 04:18:59 visual_prompt]: Epoch 9 / 100: avg data time: 5.27e-02, avg batch time: 0.4949, average train loss: 2.5816
[09/26 04:19:00 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1664, average loss: 2.7290
[09/26 04:19:00 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 32.00	top5: 63.00	
[09/26 04:19:00 visual_prompt]: Best epoch 9: best metric: 0.320
[09/26 04:19:00 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.225
[09/26 04:19:07 visual_prompt]: Epoch 10 / 100: avg data time: 5.67e-02, avg batch time: 0.4979, average train loss: 1.8353
[09/26 04:19:08 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1663, average loss: 2.1255
[09/26 04:19:08 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 43.00	top5: 77.50	
[09/26 04:19:08 visual_prompt]: Best epoch 10: best metric: 0.430
[09/26 04:19:08 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.25
[09/26 04:19:15 visual_prompt]: Epoch 11 / 100: avg data time: 4.93e-02, avg batch time: 0.4926, average train loss: 1.1706
[09/26 04:19:17 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.1664, average loss: 1.8900
[09/26 04:19:17 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 49.50	top5: 81.50	
[09/26 04:19:17 visual_prompt]: Best epoch 11: best metric: 0.495
[09/26 04:19:17 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.24992385337738698
[09/26 04:19:23 visual_prompt]: Epoch 12 / 100: avg data time: 5.75e-02, avg batch time: 0.4994, average train loss: 0.6768
[09/26 04:19:25 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1663, average loss: 1.6794
[09/26 04:19:25 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.50	top5: 86.50	
[09/26 04:19:25 visual_prompt]: Best epoch 12: best metric: 0.585
[09/26 04:19:25 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.24969550628247802
[09/26 04:19:32 visual_prompt]: Epoch 13 / 100: avg data time: 4.34e-02, avg batch time: 0.4864, average train loss: 0.4061
[09/26 04:19:33 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1664, average loss: 1.4974
[09/26 04:19:33 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.00	top5: 87.50	
[09/26 04:19:33 visual_prompt]: Best epoch 13: best metric: 0.610
[09/26 04:19:33 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.24931523692103416
[09/26 04:19:40 visual_prompt]: Epoch 14 / 100: avg data time: 5.67e-02, avg batch time: 0.4983, average train loss: 0.2128
[09/26 04:19:42 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1666, average loss: 1.3580
[09/26 04:19:42 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 64.50	top5: 89.00	
[09/26 04:19:42 visual_prompt]: Best epoch 14: best metric: 0.645
[09/26 04:19:42 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.2487835085926963
[09/26 04:19:48 visual_prompt]: Epoch 15 / 100: avg data time: 4.59e-02, avg batch time: 0.4895, average train loss: 0.1646
[09/26 04:19:50 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1663, average loss: 1.3878
[09/26 04:19:50 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.00	top5: 88.50	
[09/26 04:19:50 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.24810096912652602
[09/26 04:19:57 visual_prompt]: Epoch 16 / 100: avg data time: 5.89e-02, avg batch time: 0.5012, average train loss: 0.1221
[09/26 04:19:58 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1662, average loss: 1.3546
[09/26 04:19:58 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.50	top5: 89.00	
[09/26 04:19:58 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.2472684500917257
[09/26 04:20:05 visual_prompt]: Epoch 17 / 100: avg data time: 5.92e-02, avg batch time: 0.5009, average train loss: 0.0973
[09/26 04:20:06 visual_prompt]: Inference (val):avg data time: 2.01e-05, avg batch time: 0.1662, average loss: 1.3522
[09/26 04:20:06 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.00	top5: 89.50	
[09/26 04:20:06 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.24628696578449955
[09/26 04:20:13 visual_prompt]: Epoch 18 / 100: avg data time: 6.41e-02, avg batch time: 0.5053, average train loss: 0.0762
[09/26 04:20:15 visual_prompt]: Inference (val):avg data time: 4.52e-05, avg batch time: 0.1664, average loss: 1.3062
[09/26 04:20:15 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.50	top5: 89.50	
[09/26 04:20:15 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.24515771199228986
[09/26 04:20:22 visual_prompt]: Epoch 19 / 100: avg data time: 5.81e-02, avg batch time: 0.4998, average train loss: 0.0609
[09/26 04:20:23 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1660, average loss: 1.2623
[09/26 04:20:23 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 90.00	
[09/26 04:20:23 visual_prompt]: Best epoch 19: best metric: 0.650
[09/26 04:20:23 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.2438820645368942
[09/26 04:20:30 visual_prompt]: Epoch 20 / 100: avg data time: 5.27e-02, avg batch time: 0.4947, average train loss: 0.0555
[09/26 04:20:32 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1663, average loss: 1.2619
[09/26 04:20:32 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 64.50	top5: 91.50	
[09/26 04:20:32 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.24246157759823855
[09/26 04:20:38 visual_prompt]: Epoch 21 / 100: avg data time: 4.68e-02, avg batch time: 0.4900, average train loss: 0.0500
[09/26 04:20:40 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1663, average loss: 1.2550
[09/26 04:20:40 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.50	top5: 91.00	
[09/26 04:20:40 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.24089798182084843
[09/26 04:20:46 visual_prompt]: Epoch 22 / 100: avg data time: 5.96e-02, avg batch time: 0.5004, average train loss: 0.0465
[09/26 04:20:48 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1663, average loss: 1.2543
[09/26 04:20:48 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.50	top5: 92.00	
[09/26 04:20:48 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.2391931822053251
[09/26 04:20:55 visual_prompt]: Epoch 23 / 100: avg data time: 6.46e-02, avg batch time: 0.5053, average train loss: 0.0436
[09/26 04:20:56 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1663, average loss: 1.2579
[09/26 04:20:56 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 91.00	
[09/26 04:20:56 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.23734925578739588
[09/26 04:21:03 visual_prompt]: Epoch 24 / 100: avg data time: 5.42e-02, avg batch time: 0.4958, average train loss: 0.0416
[09/26 04:21:05 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1663, average loss: 1.2405
[09/26 04:21:05 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 92.00	
[09/26 04:21:05 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.23536844910736587
[09/26 04:21:11 visual_prompt]: Epoch 25 / 100: avg data time: 5.57e-02, avg batch time: 0.4978, average train loss: 0.0415
[09/26 04:21:13 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1662, average loss: 1.2572
[09/26 04:21:13 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 64.50	top5: 92.00	
[09/26 04:21:13 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.23325317547305485
[09/26 04:21:20 visual_prompt]: Epoch 26 / 100: avg data time: 5.78e-02, avg batch time: 0.5001, average train loss: 0.0404
[09/26 04:21:21 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1660, average loss: 1.2605
[09/26 04:21:21 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.00	top5: 91.50	
[09/26 04:21:21 visual_prompt]: Best epoch 26: best metric: 0.660
[09/26 04:21:21 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.23100601201955323
[09/26 04:21:28 visual_prompt]: Epoch 27 / 100: avg data time: 4.76e-02, avg batch time: 0.4901, average train loss: 0.0404
[09/26 04:21:29 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1662, average loss: 1.2833
[09/26 04:21:29 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 92.00	
[09/26 04:21:29 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.2286296965693802
[09/26 04:21:36 visual_prompt]: Epoch 28 / 100: avg data time: 5.87e-02, avg batch time: 0.4998, average train loss: 0.0396
[09/26 04:21:38 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1663, average loss: 1.2700
[09/26 04:21:38 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 92.50	
[09/26 04:21:38 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.22612712429686843
[09/26 04:21:44 visual_prompt]: Epoch 29 / 100: avg data time: 5.04e-02, avg batch time: 0.4937, average train loss: 0.0401
[09/26 04:21:46 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1662, average loss: 1.3027
[09/26 04:21:46 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 64.50	top5: 92.50	
[09/26 04:21:46 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.22350134420084022
[09/26 04:21:53 visual_prompt]: Epoch 30 / 100: avg data time: 6.36e-02, avg batch time: 0.5061, average train loss: 0.0393
[09/26 04:21:54 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.1662, average loss: 1.2740
[09/26 04:21:54 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 64.00	top5: 92.00	
[09/26 04:21:54 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.22075555538987224
[09/26 04:22:01 visual_prompt]: Epoch 31 / 100: avg data time: 4.40e-02, avg batch time: 0.4855, average train loss: 0.0391
[09/26 04:22:02 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1663, average loss: 1.2701
[09/26 04:22:02 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.00	top5: 92.00	
[09/26 04:22:02 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.21789310318467428
[09/26 04:22:09 visual_prompt]: Epoch 32 / 100: avg data time: 5.49e-02, avg batch time: 0.4977, average train loss: 0.0385
[09/26 04:22:10 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1664, average loss: 1.3490
[09/26 04:22:10 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 90.00	
[09/26 04:22:10 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.21491747504233139
[09/26 04:22:17 visual_prompt]: Epoch 33 / 100: avg data time: 5.70e-02, avg batch time: 0.4985, average train loss: 0.0377
[09/26 04:22:19 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1662, average loss: 1.2700
[09/26 04:22:19 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.50	top5: 92.00	
[09/26 04:22:19 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.21183229630737466
[09/26 04:22:26 visual_prompt]: Epoch 34 / 100: avg data time: 5.82e-02, avg batch time: 0.4998, average train loss: 0.0374
[09/26 04:22:27 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1662, average loss: 1.2926
[09/26 04:22:27 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 64.00	top5: 90.50	
[09/26 04:22:27 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.20864132579485728
[09/26 04:22:34 visual_prompt]: Epoch 35 / 100: avg data time: 5.26e-02, avg batch time: 0.4970, average train loss: 0.0373
[09/26 04:22:35 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1662, average loss: 1.2701
[09/26 04:22:35 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.50	top5: 90.50	
[09/26 04:22:35 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.2053484512108174
[09/26 04:22:42 visual_prompt]: Epoch 36 / 100: avg data time: 5.00e-02, avg batch time: 0.4941, average train loss: 0.0381
[09/26 04:22:44 visual_prompt]: Inference (val):avg data time: 1.96e-05, avg batch time: 0.1662, average loss: 1.2774
[09/26 04:22:44 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 90.00	
[09/26 04:22:44 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.20195768441570727
[09/26 04:22:50 visual_prompt]: Epoch 37 / 100: avg data time: 5.54e-02, avg batch time: 0.4971, average train loss: 0.0380
[09/26 04:22:52 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1663, average loss: 1.3243
[09/26 04:22:52 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 90.00	
[09/26 04:22:52 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.19847315653655914
[09/26 04:22:59 visual_prompt]: Epoch 38 / 100: avg data time: 5.85e-02, avg batch time: 0.5007, average train loss: 0.0373
[09/26 04:23:00 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1663, average loss: 1.2920
[09/26 04:23:00 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 68.50	top5: 91.50	
[09/26 04:23:00 visual_prompt]: Best epoch 38: best metric: 0.685
[09/26 04:23:00 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.19489911293384335
[09/26 04:23:07 visual_prompt]: Epoch 39 / 100: avg data time: 5.44e-02, avg batch time: 0.4975, average train loss: 0.0370
[09/26 04:23:08 visual_prompt]: Inference (val):avg data time: 1.98e-05, avg batch time: 0.1663, average loss: 1.2901
[09/26 04:23:08 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.00	top5: 92.50	
[09/26 04:23:08 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.1912399080291506
[09/26 04:23:15 visual_prompt]: Epoch 40 / 100: avg data time: 4.58e-02, avg batch time: 0.4885, average train loss: 0.0374
[09/26 04:23:17 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1663, average loss: 1.2976
[09/26 04:23:17 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.00	top5: 91.00	
[09/26 04:23:17 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.1875
[09/26 04:23:23 visual_prompt]: Epoch 41 / 100: avg data time: 5.92e-02, avg batch time: 0.5029, average train loss: 0.0364
[09/26 04:23:25 visual_prompt]: Inference (val):avg data time: 1.99e-05, avg batch time: 0.1662, average loss: 1.3178
[09/26 04:23:25 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.00	top5: 90.50	
[09/26 04:23:25 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.18368394534823634
[09/26 04:23:32 visual_prompt]: Epoch 42 / 100: avg data time: 5.03e-02, avg batch time: 0.4936, average train loss: 0.0366
[09/26 04:23:33 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1663, average loss: 1.2981
[09/26 04:23:33 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.50	top5: 90.50	
[09/26 04:23:33 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.17979639334863468
[09/26 04:23:40 visual_prompt]: Epoch 43 / 100: avg data time: 5.79e-02, avg batch time: 0.5000, average train loss: 0.0349
[09/26 04:23:41 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1662, average loss: 1.2685
[09/26 04:23:41 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.50	top5: 91.00	
[09/26 04:23:41 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.17584208038447505
[09/26 04:23:48 visual_prompt]: Epoch 44 / 100: avg data time: 5.61e-02, avg batch time: 0.4974, average train loss: 0.0351
[09/26 04:23:50 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1663, average loss: 1.3526
[09/26 04:23:50 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.00	top5: 90.00	
[09/26 04:23:50 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.17182582417698902
[09/26 04:23:56 visual_prompt]: Epoch 45 / 100: avg data time: 5.76e-02, avg batch time: 0.4990, average train loss: 0.0352
[09/26 04:23:58 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1660, average loss: 1.3405
[09/26 04:23:58 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 91.00	
[09/26 04:23:58 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.1677525179157086
[09/26 04:24:05 visual_prompt]: Epoch 46 / 100: avg data time: 4.73e-02, avg batch time: 0.4929, average train loss: 0.0362
[09/26 04:24:06 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1663, average loss: 1.3297
[09/26 04:24:06 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 64.00	top5: 91.00	
[09/26 04:24:06 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.16362712429686843
[09/26 04:24:13 visual_prompt]: Epoch 47 / 100: avg data time: 5.29e-02, avg batch time: 0.4942, average train loss: 0.0368
[09/26 04:24:14 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1664, average loss: 1.3209
[09/26 04:24:14 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.00	top5: 90.50	
[09/26 04:24:14 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.1594546694771249
[09/26 04:24:21 visual_prompt]: Epoch 48 / 100: avg data time: 5.55e-02, avg batch time: 0.4969, average train loss: 0.0367
[09/26 04:24:23 visual_prompt]: Inference (val):avg data time: 3.74e-05, avg batch time: 0.1661, average loss: 1.3601
[09/26 04:24:23 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.50	top5: 91.00	
[09/26 04:24:23 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.15524023694995845
[09/26 04:24:30 visual_prompt]: Epoch 49 / 100: avg data time: 5.91e-02, avg batch time: 0.5015, average train loss: 0.0605
[09/26 04:24:31 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1662, average loss: 1.3679
[09/26 04:24:31 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 68.00	top5: 90.00	
[09/26 04:24:31 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.1509889613522199
[09/26 04:24:38 visual_prompt]: Epoch 50 / 100: avg data time: 4.35e-02, avg batch time: 0.4868, average train loss: 0.1668
[09/26 04:24:39 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1662, average loss: 1.6939
[09/26 04:24:39 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.50	top5: 85.00	
[09/26 04:24:39 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.14670602220836632
[09/26 04:24:46 visual_prompt]: Epoch 51 / 100: avg data time: 5.36e-02, avg batch time: 0.4964, average train loss: 0.4374
[09/26 04:24:48 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1665, average loss: 1.5539
[09/26 04:24:48 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 88.00	
[09/26 04:24:48 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.14239663762000818
[09/26 04:24:54 visual_prompt]: Epoch 52 / 100: avg data time: 5.38e-02, avg batch time: 0.4959, average train loss: 0.5043
[09/26 04:24:56 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1662, average loss: 3.1185
[09/26 04:24:56 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 30.00	top5: 55.00	
[09/26 04:24:56 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.1380660579084567
[09/26 04:25:03 visual_prompt]: Epoch 53 / 100: avg data time: 6.30e-02, avg batch time: 0.5042, average train loss: 0.8134
[09/26 04:25:04 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1664, average loss: 1.2992
[09/26 04:25:04 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 71.00	top5: 91.00	
[09/26 04:25:04 visual_prompt]: Best epoch 53: best metric: 0.710
[09/26 04:25:04 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.13371955921801565
[09/26 04:25:11 visual_prompt]: Epoch 54 / 100: avg data time: 5.47e-02, avg batch time: 0.4966, average train loss: 0.2493
[09/26 04:25:12 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1665, average loss: 1.1295
[09/26 04:25:12 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 70.00	top5: 91.50	
[09/26 04:25:12 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.12936243708781264
[09/26 04:25:19 visual_prompt]: Epoch 55 / 100: avg data time: 6.08e-02, avg batch time: 0.5030, average train loss: 0.1130
[09/26 04:25:21 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1664, average loss: 1.0613
[09/26 04:25:21 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 71.00	top5: 92.50	
[09/26 04:25:21 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.125
[09/26 04:25:27 visual_prompt]: Epoch 56 / 100: avg data time: 4.98e-02, avg batch time: 0.4912, average train loss: 0.0686
[09/26 04:25:29 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1664, average loss: 1.1011
[09/26 04:25:29 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 68.50	top5: 92.00	
[09/26 04:25:29 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.12063756291218741
[09/26 04:25:36 visual_prompt]: Epoch 57 / 100: avg data time: 4.50e-02, avg batch time: 0.4868, average train loss: 0.0539
[09/26 04:25:37 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1662, average loss: 1.0366
[09/26 04:25:37 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 71.00	top5: 93.50	
[09/26 04:25:37 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.11628044078198434
[09/26 04:25:44 visual_prompt]: Epoch 58 / 100: avg data time: 6.46e-02, avg batch time: 0.5064, average train loss: 0.0495
[09/26 04:25:45 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1665, average loss: 1.1067
[09/26 04:25:45 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 68.50	top5: 92.00	
[09/26 04:25:45 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.11193394209154334
[09/26 04:25:52 visual_prompt]: Epoch 59 / 100: avg data time: 4.71e-02, avg batch time: 0.4888, average train loss: 0.0389
[09/26 04:25:54 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1663, average loss: 1.0488
[09/26 04:25:54 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 70.50	top5: 93.00	
[09/26 04:25:54 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.10760336237999185
[09/26 04:26:00 visual_prompt]: Epoch 60 / 100: avg data time: 6.06e-02, avg batch time: 0.5019, average train loss: 0.0356
[09/26 04:26:02 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1663, average loss: 1.0489
[09/26 04:26:02 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 71.50	top5: 92.50	
[09/26 04:26:02 visual_prompt]: Best epoch 60: best metric: 0.715
[09/26 04:26:02 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.10329397779163371
[09/26 04:26:09 visual_prompt]: Epoch 61 / 100: avg data time: 4.89e-02, avg batch time: 0.4916, average train loss: 0.0338
[09/26 04:26:10 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1665, average loss: 1.0446
[09/26 04:26:10 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 70.50	top5: 93.00	
[09/26 04:26:10 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.0990110386477801
[09/26 04:26:17 visual_prompt]: Epoch 62 / 100: avg data time: 5.52e-02, avg batch time: 0.4965, average train loss: 0.0326
[09/26 04:26:18 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1664, average loss: 1.0427
[09/26 04:26:18 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 71.50	top5: 93.50	
[09/26 04:26:18 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.09475976305004155
[09/26 04:26:25 visual_prompt]: Epoch 63 / 100: avg data time: 5.36e-02, avg batch time: 0.4961, average train loss: 0.0319
[09/26 04:26:27 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1663, average loss: 1.0615
[09/26 04:26:27 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 71.00	top5: 93.50	
[09/26 04:26:27 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.09054533052287511
[09/26 04:26:34 visual_prompt]: Epoch 64 / 100: avg data time: 6.63e-02, avg batch time: 0.5076, average train loss: 0.0310
[09/26 04:26:35 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1663, average loss: 1.0650
[09/26 04:26:35 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 70.00	top5: 94.00	
[09/26 04:26:35 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.08637287570313158
[09/26 04:26:42 visual_prompt]: Epoch 65 / 100: avg data time: 5.48e-02, avg batch time: 0.4966, average train loss: 0.0306
[09/26 04:26:43 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1665, average loss: 1.0578
[09/26 04:26:43 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 71.00	top5: 94.00	
[09/26 04:26:43 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.08224748208429142
[09/26 04:26:50 visual_prompt]: Epoch 66 / 100: avg data time: 5.95e-02, avg batch time: 0.5017, average train loss: 0.0303
[09/26 04:26:52 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1664, average loss: 1.0605
[09/26 04:26:52 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 71.00	top5: 94.00	
[09/26 04:26:52 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.07817417582301099
[09/26 04:26:59 visual_prompt]: Epoch 67 / 100: avg data time: 6.52e-02, avg batch time: 0.5066, average train loss: 0.0302
[09/26 04:27:00 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1664, average loss: 1.0639
[09/26 04:27:00 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 72.50	top5: 93.00	
[09/26 04:27:00 visual_prompt]: Best epoch 67: best metric: 0.725
[09/26 04:27:00 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.074157919615525
[09/26 04:27:07 visual_prompt]: Epoch 68 / 100: avg data time: 5.06e-02, avg batch time: 0.4935, average train loss: 0.0297
[09/26 04:27:08 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1662, average loss: 1.0766
[09/26 04:27:08 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 70.00	top5: 93.50	
[09/26 04:27:08 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.07020360665136531
[09/26 04:27:15 visual_prompt]: Epoch 69 / 100: avg data time: 6.10e-02, avg batch time: 0.5030, average train loss: 0.0298
[09/26 04:27:17 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1663, average loss: 1.0788
[09/26 04:27:17 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 70.50	top5: 94.00	
[09/26 04:27:17 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.06631605465176368
[09/26 04:27:23 visual_prompt]: Epoch 70 / 100: avg data time: 5.58e-02, avg batch time: 0.4978, average train loss: 0.0295
[09/26 04:27:25 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1662, average loss: 1.0716
[09/26 04:27:25 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 71.00	top5: 93.00	
[09/26 04:27:25 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.06250000000000003
[09/26 04:27:32 visual_prompt]: Epoch 71 / 100: avg data time: 5.53e-02, avg batch time: 0.4974, average train loss: 0.0294
[09/26 04:27:33 visual_prompt]: Inference (val):avg data time: 1.87e-05, avg batch time: 0.1664, average loss: 1.0785
[09/26 04:27:33 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 70.50	top5: 93.00	
[09/26 04:27:33 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.0587600919708494
[09/26 04:27:40 visual_prompt]: Epoch 72 / 100: avg data time: 6.42e-02, avg batch time: 0.5064, average train loss: 0.0297
[09/26 04:27:42 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1663, average loss: 1.0851
[09/26 04:27:42 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 70.00	top5: 93.00	
[09/26 04:27:42 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.055100887066156665
[09/26 04:27:48 visual_prompt]: Epoch 73 / 100: avg data time: 5.75e-02, avg batch time: 0.4999, average train loss: 0.0293
[09/26 04:27:50 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1667, average loss: 1.0848
[09/26 04:27:50 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 70.00	top5: 93.50	
[09/26 04:27:50 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.05152684346344087
[09/26 04:27:56 visual_prompt]: Epoch 74 / 100: avg data time: 4.79e-02, avg batch time: 0.4914, average train loss: 0.0290
[09/26 04:27:58 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1664, average loss: 1.0870
[09/26 04:27:58 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 70.50	top5: 92.50	
[09/26 04:27:58 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.048042315584292714
[09/26 04:28:05 visual_prompt]: Epoch 75 / 100: avg data time: 4.97e-02, avg batch time: 0.4934, average train loss: 0.0295
[09/26 04:28:06 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1665, average loss: 1.0958
[09/26 04:28:06 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 70.50	top5: 92.50	
[09/26 04:28:06 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.04465154878918258
[09/26 04:28:13 visual_prompt]: Epoch 76 / 100: avg data time: 5.79e-02, avg batch time: 0.4991, average train loss: 0.0291
[09/26 04:28:14 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1664, average loss: 1.1060
[09/26 04:28:14 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 70.00	top5: 92.50	
[09/26 04:28:14 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.04135867420514276
[09/26 04:28:21 visual_prompt]: Epoch 77 / 100: avg data time: 4.89e-02, avg batch time: 0.4917, average train loss: 0.0296
[09/26 04:28:23 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1663, average loss: 1.1061
[09/26 04:28:23 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 70.00	top5: 92.50	
[09/26 04:28:23 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.03816770369262533
[09/26 04:28:29 visual_prompt]: Epoch 78 / 100: avg data time: 5.98e-02, avg batch time: 0.5017, average train loss: 0.0291
[09/26 04:28:31 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1662, average loss: 1.1046
[09/26 04:28:31 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 70.00	top5: 92.50	
[09/26 04:28:31 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.03508252495766863
[09/26 04:28:38 visual_prompt]: Epoch 79 / 100: avg data time: 5.38e-02, avg batch time: 0.4963, average train loss: 0.0288
[09/26 04:28:39 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1662, average loss: 1.0985
[09/26 04:28:39 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 70.50	top5: 92.00	
[09/26 04:28:39 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.032106896815325706
[09/26 04:28:46 visual_prompt]: Epoch 80 / 100: avg data time: 5.97e-02, avg batch time: 0.5014, average train loss: 0.0291
[09/26 04:28:47 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1665, average loss: 1.1068
[09/26 04:28:47 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 69.50	top5: 92.00	
[09/26 04:28:47 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.029244444610127762
[09/26 04:28:54 visual_prompt]: Epoch 81 / 100: avg data time: 5.56e-02, avg batch time: 0.4975, average train loss: 0.0290
[09/26 04:28:56 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1662, average loss: 1.1132
[09/26 04:28:56 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 69.50	top5: 92.00	
[09/26 04:28:56 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.026498655799159762
[09/26 04:29:02 visual_prompt]: Epoch 82 / 100: avg data time: 4.81e-02, avg batch time: 0.4903, average train loss: 0.0290
[09/26 04:29:04 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1664, average loss: 1.1126
[09/26 04:29:04 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 69.00	top5: 92.00	
[09/26 04:29:04 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.023872875703131582
[09/26 04:29:11 visual_prompt]: Epoch 83 / 100: avg data time: 6.16e-02, avg batch time: 0.5040, average train loss: 0.0292
[09/26 04:29:12 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1662, average loss: 1.1124
[09/26 04:29:12 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 69.00	top5: 92.00	
[09/26 04:29:12 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.021370303430619797
[09/26 04:29:19 visual_prompt]: Epoch 84 / 100: avg data time: 4.72e-02, avg batch time: 0.4897, average train loss: 0.0289
[09/26 04:29:20 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1662, average loss: 1.1156
[09/26 04:29:20 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 70.00	top5: 92.00	
[09/26 04:29:20 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.018993987980446755
[09/26 04:29:27 visual_prompt]: Epoch 85 / 100: avg data time: 5.93e-02, avg batch time: 0.5009, average train loss: 0.0289
[09/26 04:29:29 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1663, average loss: 1.1156
[09/26 04:29:29 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 70.00	top5: 92.00	
[09/26 04:29:29 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.01674682452694516
[09/26 04:29:36 visual_prompt]: Epoch 86 / 100: avg data time: 5.81e-02, avg batch time: 0.4993, average train loss: 0.0290
[09/26 04:29:37 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1664, average loss: 1.1118
[09/26 04:29:37 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 70.50	top5: 92.00	
[09/26 04:29:37 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.014631550892634126
[09/26 04:29:44 visual_prompt]: Epoch 87 / 100: avg data time: 5.69e-02, avg batch time: 0.4978, average train loss: 0.0286
[09/26 04:29:45 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1663, average loss: 1.1099
[09/26 04:29:45 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 71.00	top5: 92.00	
[09/26 04:29:45 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.012650744212604148
[09/26 04:29:52 visual_prompt]: Epoch 88 / 100: avg data time: 4.30e-02, avg batch time: 0.4862, average train loss: 0.0289
[09/26 04:29:53 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1664, average loss: 1.1144
[09/26 04:29:53 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 71.00	top5: 92.00	
[09/26 04:29:53 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.010806817794674878
[09/26 04:30:00 visual_prompt]: Epoch 89 / 100: avg data time: 5.51e-02, avg batch time: 0.4990, average train loss: 0.0292
[09/26 04:30:02 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1665, average loss: 1.1165
[09/26 04:30:02 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 70.50	top5: 92.00	
[09/26 04:30:02 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.009102018179151586
[09/26 04:30:08 visual_prompt]: Epoch 90 / 100: avg data time: 5.43e-02, avg batch time: 0.4964, average train loss: 0.0288
[09/26 04:30:10 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1662, average loss: 1.1174
[09/26 04:30:10 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 71.00	top5: 92.00	
[09/26 04:30:10 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.00753842240176146
[09/26 04:30:17 visual_prompt]: Epoch 91 / 100: avg data time: 5.57e-02, avg batch time: 0.4979, average train loss: 0.0285
[09/26 04:30:18 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1665, average loss: 1.1180
[09/26 04:30:18 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 71.00	top5: 92.00	
[09/26 04:30:18 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.006117935463105809
[09/26 04:30:25 visual_prompt]: Epoch 92 / 100: avg data time: 6.28e-02, avg batch time: 0.5042, average train loss: 0.0288
[09/26 04:30:27 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1665, average loss: 1.1182
[09/26 04:30:27 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 71.00	top5: 92.00	
[09/26 04:30:27 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.004842288007710138
[09/26 04:30:34 visual_prompt]: Epoch 93 / 100: avg data time: 5.93e-02, avg batch time: 0.5022, average train loss: 0.0290
[09/26 04:30:35 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1661, average loss: 1.1172
[09/26 04:30:35 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 71.00	top5: 92.00	
[09/26 04:30:35 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.003713034215500441
[09/26 04:30:42 visual_prompt]: Epoch 94 / 100: avg data time: 5.67e-02, avg batch time: 0.4985, average train loss: 0.0288
[09/26 04:30:43 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1664, average loss: 1.1168
[09/26 04:30:43 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 71.00	top5: 92.00	
[09/26 04:30:43 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.002731549908274289
[09/26 04:30:50 visual_prompt]: Epoch 95 / 100: avg data time: 4.68e-02, avg batch time: 0.4890, average train loss: 0.0285
[09/26 04:30:52 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1664, average loss: 1.1168
[09/26 04:30:52 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 71.00	top5: 92.00	
[09/26 04:30:52 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.0018990308734739975
[09/26 04:30:58 visual_prompt]: Epoch 96 / 100: avg data time: 4.25e-02, avg batch time: 0.4862, average train loss: 0.0287
[09/26 04:31:00 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1663, average loss: 1.1169
[09/26 04:31:00 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 71.00	top5: 92.00	
[09/26 04:31:00 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.0012164914073037048
[09/26 04:31:06 visual_prompt]: Epoch 97 / 100: avg data time: 5.21e-02, avg batch time: 0.4947, average train loss: 0.0290
[09/26 04:31:08 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1662, average loss: 1.1169
[09/26 04:31:08 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 71.00	top5: 92.00	
[09/26 04:31:08 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.0006847630789658388
[09/26 04:31:15 visual_prompt]: Epoch 98 / 100: avg data time: 4.95e-02, avg batch time: 0.4917, average train loss: 0.0289
[09/26 04:31:16 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1664, average loss: 1.1169
[09/26 04:31:16 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 71.00	top5: 92.00	
[09/26 04:31:16 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.0003044937175219753
[09/26 04:31:23 visual_prompt]: Epoch 99 / 100: avg data time: 4.53e-02, avg batch time: 0.4878, average train loss: 0.0287
[09/26 04:31:24 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1663, average loss: 1.1169
[09/26 04:31:24 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 71.00	top5: 92.00	
[09/26 04:31:24 visual_prompt]: Training 100 / 100 epoch, with learning rate 7.614662261302974e-05
[09/26 04:31:31 visual_prompt]: Epoch 100 / 100: avg data time: 5.57e-02, avg batch time: 0.4977, average train loss: 0.0291
[09/26 04:31:32 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1664, average loss: 1.1169
[09/26 04:31:32 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 71.00	top5: 92.00	
[09/26 04:31:33 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 04:31:33 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 04:31:33 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-cifar(num_classes=100)', 'DATA.NUMBER_CLASSES', '100', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 04:31:33 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 04:31:33 visual_prompt]: Training with config:
[09/26 04:31:33 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-cifar(num_classes=100)/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.25_wd0.0001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 0.25, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-cifar(num_classes=100)', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 100, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 04:31:33 visual_prompt]: Loading training data...
[09/26 04:31:33 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[:800], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/26 04:31:33 visual_prompt]: Number of images: 800
[09/26 04:31:33 visual_prompt]: Number of classes: 100 / 100
[09/26 04:31:33 visual_prompt]: Loading validation data...
[09/26 04:31:33 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[45000:45200], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/26 04:31:34 visual_prompt]: Number of images: 200
[09/26 04:31:34 visual_prompt]: Number of classes: 90 / 100
[09/26 04:31:34 visual_prompt]: Constructing models...
[09/26 04:31:36 visual_prompt]: Total Parameters: 86336356	 Gradient Parameters: 537700
[09/26 04:31:36 visual_prompt]: tuned percent:0.623
[09/26 04:31:36 visual_prompt]: Device used for model: 0
[09/26 04:31:36 visual_prompt]: Setting up Evaluator...
[09/26 04:31:36 visual_prompt]: Setting up Trainer...
[09/26 04:31:36 visual_prompt]: 	Setting up the optimizer...
[09/26 04:31:36 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 04:31:43 visual_prompt]: Epoch 1 / 100: avg data time: 6.09e-02, avg batch time: 0.5034, average train loss: 4.6557
[09/26 04:31:45 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1657, average loss: 4.6218
[09/26 04:31:45 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 7.00	
[09/26 04:31:45 visual_prompt]: Best epoch 1: best metric: 0.010
[09/26 04:31:45 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.025
[09/26 04:31:51 visual_prompt]: Epoch 2 / 100: avg data time: 5.94e-02, avg batch time: 0.4994, average train loss: 4.6343
[09/26 04:31:53 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1660, average loss: 4.6019
[09/26 04:31:53 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.50	top5: 4.50	
[09/26 04:31:53 visual_prompt]: Best epoch 2: best metric: 0.025
[09/26 04:31:53 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.05
[09/26 04:32:00 visual_prompt]: Epoch 3 / 100: avg data time: 6.43e-02, avg batch time: 0.5044, average train loss: 4.5902
[09/26 04:32:01 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1657, average loss: 4.6126
[09/26 04:32:01 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 5.00	
[09/26 04:32:01 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.075
[09/26 04:32:08 visual_prompt]: Epoch 4 / 100: avg data time: 5.59e-02, avg batch time: 0.4968, average train loss: 4.5685
[09/26 04:32:10 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1659, average loss: 4.5973
[09/26 04:32:10 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 7.50	
[09/26 04:32:10 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.1
[09/26 04:32:16 visual_prompt]: Epoch 5 / 100: avg data time: 5.36e-02, avg batch time: 0.4951, average train loss: 4.4688
[09/26 04:32:18 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1660, average loss: 4.5689
[09/26 04:32:18 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.50	top5: 17.00	
[09/26 04:32:18 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.125
[09/26 04:32:25 visual_prompt]: Epoch 6 / 100: avg data time: 5.93e-02, avg batch time: 0.5007, average train loss: 4.1420
[09/26 04:32:26 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1659, average loss: 3.9967
[09/26 04:32:26 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 10.00	top5: 26.50	
[09/26 04:32:26 visual_prompt]: Best epoch 6: best metric: 0.100
[09/26 04:32:26 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.15
[09/26 04:32:33 visual_prompt]: Epoch 7 / 100: avg data time: 5.43e-02, avg batch time: 0.4963, average train loss: 3.5436
[09/26 04:32:34 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1660, average loss: 3.6229
[09/26 04:32:34 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 11.50	top5: 36.50	
[09/26 04:32:34 visual_prompt]: Best epoch 7: best metric: 0.115
[09/26 04:32:34 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.175
[09/26 04:32:41 visual_prompt]: Epoch 8 / 100: avg data time: 5.70e-02, avg batch time: 0.4979, average train loss: 2.9058
[09/26 04:32:43 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1661, average loss: 3.0586
[09/26 04:32:43 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 22.00	top5: 54.50	
[09/26 04:32:43 visual_prompt]: Best epoch 8: best metric: 0.220
[09/26 04:32:43 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.2
[09/26 04:32:49 visual_prompt]: Epoch 9 / 100: avg data time: 5.06e-02, avg batch time: 0.4930, average train loss: 2.0712
[09/26 04:32:51 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1660, average loss: 2.5307
[09/26 04:32:51 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 33.00	top5: 68.50	
[09/26 04:32:51 visual_prompt]: Best epoch 9: best metric: 0.330
[09/26 04:32:51 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.225
[09/26 04:32:58 visual_prompt]: Epoch 10 / 100: avg data time: 5.79e-02, avg batch time: 0.4990, average train loss: 1.3956
[09/26 04:32:59 visual_prompt]: Inference (val):avg data time: 2.08e-05, avg batch time: 0.1662, average loss: 2.1447
[09/26 04:32:59 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 40.00	top5: 74.50	
[09/26 04:32:59 visual_prompt]: Best epoch 10: best metric: 0.400
[09/26 04:32:59 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.25
[09/26 04:33:06 visual_prompt]: Epoch 11 / 100: avg data time: 4.61e-02, avg batch time: 0.4885, average train loss: 0.8056
[09/26 04:33:07 visual_prompt]: Inference (val):avg data time: 1.97e-05, avg batch time: 0.1661, average loss: 1.9225
[09/26 04:33:07 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 50.50	top5: 78.00	
[09/26 04:33:07 visual_prompt]: Best epoch 11: best metric: 0.505
[09/26 04:33:07 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.24992385337738698
[09/26 04:33:14 visual_prompt]: Epoch 12 / 100: avg data time: 5.50e-02, avg batch time: 0.4963, average train loss: 0.4261
[09/26 04:33:16 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1662, average loss: 1.6708
[09/26 04:33:16 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.50	top5: 84.50	
[09/26 04:33:16 visual_prompt]: Best epoch 12: best metric: 0.545
[09/26 04:33:16 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.24969550628247802
[09/26 04:33:22 visual_prompt]: Epoch 13 / 100: avg data time: 6.03e-02, avg batch time: 0.5016, average train loss: 0.2423
[09/26 04:33:24 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1660, average loss: 1.5707
[09/26 04:33:24 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 86.00	
[09/26 04:33:24 visual_prompt]: Best epoch 13: best metric: 0.580
[09/26 04:33:24 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.24931523692103416
[09/26 04:33:31 visual_prompt]: Epoch 14 / 100: avg data time: 5.87e-02, avg batch time: 0.5026, average train loss: 0.1396
[09/26 04:33:32 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1662, average loss: 1.4046
[09/26 04:33:32 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.50	top5: 91.50	
[09/26 04:33:32 visual_prompt]: Best epoch 14: best metric: 0.585
[09/26 04:33:32 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.2487835085926963
[09/26 04:33:39 visual_prompt]: Epoch 15 / 100: avg data time: 6.35e-02, avg batch time: 0.5053, average train loss: 0.0812
[09/26 04:33:40 visual_prompt]: Inference (val):avg data time: 2.11e-05, avg batch time: 0.1663, average loss: 1.3712
[09/26 04:33:40 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 90.00	
[09/26 04:33:40 visual_prompt]: Best epoch 15: best metric: 0.620
[09/26 04:33:40 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.24810096912652602
[09/26 04:33:47 visual_prompt]: Epoch 16 / 100: avg data time: 4.98e-02, avg batch time: 0.4919, average train loss: 0.0529
[09/26 04:33:49 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1663, average loss: 1.3866
[09/26 04:33:49 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.50	top5: 90.00	
[09/26 04:33:49 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.2472684500917257
[09/26 04:33:55 visual_prompt]: Epoch 17 / 100: avg data time: 5.58e-02, avg batch time: 0.4984, average train loss: 0.0419
[09/26 04:33:57 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1662, average loss: 1.3712
[09/26 04:33:57 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 60.50	top5: 90.00	
[09/26 04:33:57 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.24628696578449955
[09/26 04:34:04 visual_prompt]: Epoch 18 / 100: avg data time: 6.28e-02, avg batch time: 0.5044, average train loss: 0.0339
[09/26 04:34:05 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1661, average loss: 1.3632
[09/26 04:34:05 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.00	top5: 91.00	
[09/26 04:34:05 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.24515771199228986
[09/26 04:34:12 visual_prompt]: Epoch 19 / 100: avg data time: 5.33e-02, avg batch time: 0.4962, average train loss: 0.0279
[09/26 04:34:14 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.1662, average loss: 1.3342
[09/26 04:34:14 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.00	top5: 90.50	
[09/26 04:34:14 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.2438820645368942
[09/26 04:34:20 visual_prompt]: Epoch 20 / 100: avg data time: 6.14e-02, avg batch time: 0.5048, average train loss: 0.0245
[09/26 04:34:22 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1664, average loss: 1.3298
[09/26 04:34:22 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 91.00	
[09/26 04:34:22 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.24246157759823855
[09/26 04:34:29 visual_prompt]: Epoch 21 / 100: avg data time: 6.24e-02, avg batch time: 0.5037, average train loss: 0.0217
[09/26 04:34:30 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1663, average loss: 1.3326
[09/26 04:34:30 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 60.00	top5: 90.50	
[09/26 04:34:30 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.24089798182084843
[09/26 04:34:37 visual_prompt]: Epoch 22 / 100: avg data time: 5.35e-02, avg batch time: 0.4955, average train loss: 0.0199
[09/26 04:34:39 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1663, average loss: 1.3398
[09/26 04:34:39 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 60.50	top5: 90.50	
[09/26 04:34:39 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.2391931822053251
[09/26 04:34:45 visual_prompt]: Epoch 23 / 100: avg data time: 5.97e-02, avg batch time: 0.5011, average train loss: 0.0181
[09/26 04:34:47 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1662, average loss: 1.3590
[09/26 04:34:47 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 60.00	top5: 91.00	
[09/26 04:34:47 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.23734925578739588
[09/26 04:34:54 visual_prompt]: Epoch 24 / 100: avg data time: 5.87e-02, avg batch time: 0.5003, average train loss: 0.0174
[09/26 04:34:55 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1665, average loss: 1.3479
[09/26 04:34:55 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 60.00	top5: 91.00	
[09/26 04:34:55 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.23536844910736587
[09/26 04:35:02 visual_prompt]: Epoch 25 / 100: avg data time: 6.01e-02, avg batch time: 0.5020, average train loss: 0.0159
[09/26 04:35:03 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1665, average loss: 1.3564
[09/26 04:35:03 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.00	top5: 90.50	
[09/26 04:35:03 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.23325317547305485
[09/26 04:35:10 visual_prompt]: Epoch 26 / 100: avg data time: 5.76e-02, avg batch time: 0.5003, average train loss: 0.0149
[09/26 04:35:12 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1664, average loss: 1.3660
[09/26 04:35:12 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.00	top5: 91.00	
[09/26 04:35:12 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.23100601201955323
[09/26 04:35:19 visual_prompt]: Epoch 27 / 100: avg data time: 5.29e-02, avg batch time: 0.4944, average train loss: 0.0140
[09/26 04:35:20 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1664, average loss: 1.3625
[09/26 04:35:20 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.50	top5: 91.00	
[09/26 04:35:20 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.2286296965693802
[09/26 04:35:27 visual_prompt]: Epoch 28 / 100: avg data time: 5.34e-02, avg batch time: 0.4953, average train loss: 0.0137
[09/26 04:35:28 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1663, average loss: 1.3611
[09/26 04:35:28 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 90.50	
[09/26 04:35:28 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.22612712429686843
[09/26 04:35:35 visual_prompt]: Epoch 29 / 100: avg data time: 4.46e-02, avg batch time: 0.4878, average train loss: 0.0130
[09/26 04:35:36 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1664, average loss: 1.3581
[09/26 04:35:36 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.00	top5: 91.00	
[09/26 04:35:36 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.22350134420084022
[09/26 04:35:43 visual_prompt]: Epoch 30 / 100: avg data time: 5.82e-02, avg batch time: 0.5004, average train loss: 0.0125
[09/26 04:35:45 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.1664, average loss: 1.3638
[09/26 04:35:45 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 90.50	
[09/26 04:35:45 visual_prompt]: Best epoch 30: best metric: 0.625
[09/26 04:35:45 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.22075555538987224
[09/26 04:35:52 visual_prompt]: Epoch 31 / 100: avg data time: 5.99e-02, avg batch time: 0.5025, average train loss: 0.0118
[09/26 04:35:53 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1666, average loss: 1.3688
[09/26 04:35:53 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 91.00	
[09/26 04:35:53 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.21789310318467428
[09/26 04:36:00 visual_prompt]: Epoch 32 / 100: avg data time: 6.10e-02, avg batch time: 0.5024, average train loss: 0.0116
[09/26 04:36:02 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1665, average loss: 1.3498
[09/26 04:36:02 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.50	top5: 91.00	
[09/26 04:36:02 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.21491747504233139
[09/26 04:36:08 visual_prompt]: Epoch 33 / 100: avg data time: 5.32e-02, avg batch time: 0.4966, average train loss: 0.0111
[09/26 04:36:10 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1666, average loss: 1.3488
[09/26 04:36:10 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.00	top5: 91.50	
[09/26 04:36:10 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.21183229630737466
[09/26 04:36:16 visual_prompt]: Epoch 34 / 100: avg data time: 4.50e-02, avg batch time: 0.4874, average train loss: 0.0108
[09/26 04:36:18 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1666, average loss: 1.3517
[09/26 04:36:18 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.50	top5: 91.00	
[09/26 04:36:18 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.20864132579485728
[09/26 04:36:25 visual_prompt]: Epoch 35 / 100: avg data time: 4.47e-02, avg batch time: 0.4882, average train loss: 0.0106
[09/26 04:36:26 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1665, average loss: 1.3535
[09/26 04:36:26 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.50	top5: 92.00	
[09/26 04:36:26 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.2053484512108174
[09/26 04:36:33 visual_prompt]: Epoch 36 / 100: avg data time: 4.74e-02, avg batch time: 0.4887, average train loss: 0.0100
[09/26 04:36:34 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1662, average loss: 1.3626
[09/26 04:36:34 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 60.50	top5: 91.00	
[09/26 04:36:34 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.20195768441570727
[09/26 04:36:41 visual_prompt]: Epoch 37 / 100: avg data time: 5.37e-02, avg batch time: 0.4975, average train loss: 0.0099
[09/26 04:36:43 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1664, average loss: 1.3603
[09/26 04:36:43 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.00	top5: 91.00	
[09/26 04:36:43 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.19847315653655914
[09/26 04:36:49 visual_prompt]: Epoch 38 / 100: avg data time: 5.61e-02, avg batch time: 0.4992, average train loss: 0.0093
[09/26 04:36:51 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1663, average loss: 1.3612
[09/26 04:36:51 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.00	top5: 92.50	
[09/26 04:36:51 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.19489911293384335
[09/26 04:36:58 visual_prompt]: Epoch 39 / 100: avg data time: 4.89e-02, avg batch time: 0.4915, average train loss: 0.0092
[09/26 04:36:59 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1666, average loss: 1.3581
[09/26 04:36:59 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 60.00	top5: 92.00	
[09/26 04:36:59 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.1912399080291506
[09/26 04:37:06 visual_prompt]: Epoch 40 / 100: avg data time: 5.42e-02, avg batch time: 0.4962, average train loss: 0.0090
[09/26 04:37:07 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1666, average loss: 1.3543
[09/26 04:37:07 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 60.00	top5: 92.00	
[09/26 04:37:07 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.1875
[09/26 04:37:14 visual_prompt]: Epoch 41 / 100: avg data time: 5.80e-02, avg batch time: 0.5007, average train loss: 0.0091
[09/26 04:37:16 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1664, average loss: 1.3569
[09/26 04:37:16 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 92.00	
[09/26 04:37:16 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.18368394534823634
[09/26 04:37:23 visual_prompt]: Epoch 42 / 100: avg data time: 5.86e-02, avg batch time: 0.5004, average train loss: 0.0089
[09/26 04:37:24 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1662, average loss: 1.3584
[09/26 04:37:24 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.00	top5: 92.00	
[09/26 04:37:24 visual_prompt]: Best epoch 42: best metric: 0.630
[09/26 04:37:24 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.17979639334863468
[09/26 04:37:31 visual_prompt]: Epoch 43 / 100: avg data time: 5.74e-02, avg batch time: 0.4985, average train loss: 0.0086
[09/26 04:37:32 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1663, average loss: 1.3551
[09/26 04:37:32 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 92.00	
[09/26 04:37:32 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.17584208038447505
[09/26 04:37:39 visual_prompt]: Epoch 44 / 100: avg data time: 5.82e-02, avg batch time: 0.5001, average train loss: 0.0084
[09/26 04:37:41 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1662, average loss: 1.3548
[09/26 04:37:41 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.00	top5: 92.00	
[09/26 04:37:41 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.17182582417698902
[09/26 04:37:47 visual_prompt]: Epoch 45 / 100: avg data time: 4.64e-02, avg batch time: 0.4892, average train loss: 0.0080
[09/26 04:37:49 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1662, average loss: 1.3539
[09/26 04:37:49 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 92.00	
[09/26 04:37:49 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.1677525179157086
[09/26 04:37:56 visual_prompt]: Epoch 46 / 100: avg data time: 4.68e-02, avg batch time: 0.4910, average train loss: 0.0085
[09/26 04:37:57 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1663, average loss: 1.3438
[09/26 04:37:57 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.00	top5: 91.50	
[09/26 04:37:57 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.16362712429686843
[09/26 04:38:04 visual_prompt]: Epoch 47 / 100: avg data time: 6.15e-02, avg batch time: 0.5035, average train loss: 0.0082
[09/26 04:38:06 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1662, average loss: 1.3614
[09/26 04:38:06 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.00	top5: 92.00	
[09/26 04:38:06 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.1594546694771249
[09/26 04:38:12 visual_prompt]: Epoch 48 / 100: avg data time: 4.59e-02, avg batch time: 0.4872, average train loss: 0.0080
[09/26 04:38:14 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1662, average loss: 1.3591
[09/26 04:38:14 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 92.00	
[09/26 04:38:14 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.15524023694995845
[09/26 04:38:20 visual_prompt]: Epoch 49 / 100: avg data time: 6.05e-02, avg batch time: 0.5018, average train loss: 0.0078
[09/26 04:38:22 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1661, average loss: 1.3546
[09/26 04:38:22 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.00	top5: 92.50	
[09/26 04:38:22 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.1509889613522199
[09/26 04:38:29 visual_prompt]: Epoch 50 / 100: avg data time: 4.99e-02, avg batch time: 0.4935, average train loss: 0.0077
[09/26 04:38:30 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1663, average loss: 1.3538
[09/26 04:38:30 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 91.00	
[09/26 04:38:30 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.14670602220836632
[09/26 04:38:37 visual_prompt]: Epoch 51 / 100: avg data time: 4.47e-02, avg batch time: 0.4885, average train loss: 0.0077
[09/26 04:38:38 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1661, average loss: 1.3535
[09/26 04:38:38 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.50	top5: 91.50	
[09/26 04:38:38 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.14239663762000818
[09/26 04:38:45 visual_prompt]: Epoch 52 / 100: avg data time: 5.26e-02, avg batch time: 0.4952, average train loss: 0.0075
[09/26 04:38:47 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1662, average loss: 1.3550
[09/26 04:38:47 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.00	top5: 91.50	
[09/26 04:38:47 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.1380660579084567
[09/26 04:38:53 visual_prompt]: Epoch 53 / 100: avg data time: 5.95e-02, avg batch time: 0.5015, average train loss: 0.0075
[09/26 04:38:55 visual_prompt]: Inference (val):avg data time: 2.02e-05, avg batch time: 0.1662, average loss: 1.3544
[09/26 04:38:55 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 92.00	
[09/26 04:38:55 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.13371955921801565
[09/26 04:39:02 visual_prompt]: Epoch 54 / 100: avg data time: 5.76e-02, avg batch time: 0.5010, average train loss: 0.0076
[09/26 04:39:03 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1662, average loss: 1.3558
[09/26 04:39:03 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.50	top5: 92.00	
[09/26 04:39:03 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.12936243708781264
[09/26 04:39:10 visual_prompt]: Epoch 55 / 100: avg data time: 6.23e-02, avg batch time: 0.5033, average train loss: 0.0074
[09/26 04:39:12 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1661, average loss: 1.3669
[09/26 04:39:12 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.50	top5: 92.00	
[09/26 04:39:12 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.125
[09/26 04:39:18 visual_prompt]: Epoch 56 / 100: avg data time: 5.62e-02, avg batch time: 0.4980, average train loss: 0.0072
[09/26 04:39:20 visual_prompt]: Inference (val):avg data time: 2.08e-05, avg batch time: 0.1660, average loss: 1.3663
[09/26 04:39:20 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.50	top5: 92.00	
[09/26 04:39:20 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.12063756291218741
[09/26 04:39:27 visual_prompt]: Epoch 57 / 100: avg data time: 5.90e-02, avg batch time: 0.5001, average train loss: 0.0072
[09/26 04:39:28 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1661, average loss: 1.3564
[09/26 04:39:28 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 92.00	
[09/26 04:39:28 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.11628044078198434
[09/26 04:39:35 visual_prompt]: Epoch 58 / 100: avg data time: 4.61e-02, avg batch time: 0.4904, average train loss: 0.0071
[09/26 04:39:36 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1662, average loss: 1.3564
[09/26 04:39:36 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 92.00	
[09/26 04:39:36 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.11193394209154334
[09/26 04:39:43 visual_prompt]: Epoch 59 / 100: avg data time: 4.23e-02, avg batch time: 0.4854, average train loss: 0.0071
[09/26 04:39:44 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1664, average loss: 1.3593
[09/26 04:39:44 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 92.00	
[09/26 04:39:44 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.10760336237999185
[09/26 04:39:51 visual_prompt]: Epoch 60 / 100: avg data time: 5.97e-02, avg batch time: 0.5010, average train loss: 0.0069
[09/26 04:39:53 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1662, average loss: 1.3636
[09/26 04:39:53 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 92.50	
[09/26 04:39:53 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.10329397779163371
[09/26 04:40:00 visual_prompt]: Epoch 61 / 100: avg data time: 5.56e-02, avg batch time: 0.4980, average train loss: 0.0069
[09/26 04:40:01 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1665, average loss: 1.3663
[09/26 04:40:01 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 92.50	
[09/26 04:40:01 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.0990110386477801
[09/26 04:40:08 visual_prompt]: Epoch 62 / 100: avg data time: 4.51e-02, avg batch time: 0.4904, average train loss: 0.0069
[09/26 04:40:09 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1663, average loss: 1.3681
[09/26 04:40:09 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 92.50	
[09/26 04:40:09 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.09475976305004155
[09/26 04:40:16 visual_prompt]: Epoch 63 / 100: avg data time: 5.63e-02, avg batch time: 0.4997, average train loss: 0.0070
[09/26 04:40:18 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1664, average loss: 1.3634
[09/26 04:40:18 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 92.50	
[09/26 04:40:18 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.09054533052287511
[09/26 04:40:24 visual_prompt]: Epoch 64 / 100: avg data time: 4.25e-02, avg batch time: 0.4857, average train loss: 0.0068
[09/26 04:40:26 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1663, average loss: 1.3672
[09/26 04:40:26 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.50	top5: 92.50	
[09/26 04:40:26 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.08637287570313158
[09/26 04:40:33 visual_prompt]: Epoch 65 / 100: avg data time: 6.03e-02, avg batch time: 0.5035, average train loss: 0.0068
[09/26 04:40:34 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1665, average loss: 1.3700
[09/26 04:40:34 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.50	top5: 92.50	
[09/26 04:40:34 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.08224748208429142
[09/26 04:40:41 visual_prompt]: Epoch 66 / 100: avg data time: 5.55e-02, avg batch time: 0.4983, average train loss: 0.0067
[09/26 04:40:42 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1664, average loss: 1.3692
[09/26 04:40:42 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 92.50	
[09/26 04:40:42 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.07817417582301099
[09/26 04:40:49 visual_prompt]: Epoch 67 / 100: avg data time: 5.60e-02, avg batch time: 0.4981, average train loss: 0.0066
[09/26 04:40:51 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1665, average loss: 1.3706
[09/26 04:40:51 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.50	top5: 92.00	
[09/26 04:40:51 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.074157919615525
[09/26 04:40:57 visual_prompt]: Epoch 68 / 100: avg data time: 5.94e-02, avg batch time: 0.5013, average train loss: 0.0066
[09/26 04:40:59 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1664, average loss: 1.3683
[09/26 04:40:59 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 91.50	
[09/26 04:40:59 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.07020360665136531
[09/26 04:41:06 visual_prompt]: Epoch 69 / 100: avg data time: 5.13e-02, avg batch time: 0.4949, average train loss: 0.0065
[09/26 04:41:07 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1663, average loss: 1.3702
[09/26 04:41:07 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.50	top5: 92.50	
[09/26 04:41:07 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.06631605465176368
[09/26 04:41:14 visual_prompt]: Epoch 70 / 100: avg data time: 5.59e-02, avg batch time: 0.4976, average train loss: 0.0068
[09/26 04:41:16 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1663, average loss: 1.3699
[09/26 04:41:16 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.50	top5: 92.50	
[09/26 04:41:16 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.06250000000000003
[09/26 04:41:22 visual_prompt]: Epoch 71 / 100: avg data time: 6.56e-02, avg batch time: 0.5072, average train loss: 0.0066
[09/26 04:41:24 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1665, average loss: 1.3707
[09/26 04:41:24 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 93.00	
[09/26 04:41:24 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.0587600919708494
[09/26 04:41:31 visual_prompt]: Epoch 72 / 100: avg data time: 4.66e-02, avg batch time: 0.4886, average train loss: 0.0066
[09/26 04:41:32 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1665, average loss: 1.3717
[09/26 04:41:32 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 93.00	
[09/26 04:41:32 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.055100887066156665
[09/26 04:41:39 visual_prompt]: Epoch 73 / 100: avg data time: 6.08e-02, avg batch time: 0.5028, average train loss: 0.0064
[09/26 04:41:40 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1665, average loss: 1.3718
[09/26 04:41:40 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 93.00	
[09/26 04:41:40 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.05152684346344087
[09/26 04:41:47 visual_prompt]: Epoch 74 / 100: avg data time: 5.90e-02, avg batch time: 0.5011, average train loss: 0.0064
[09/26 04:41:49 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1662, average loss: 1.3712
[09/26 04:41:49 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 93.00	
[09/26 04:41:49 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.048042315584292714
[09/26 04:41:56 visual_prompt]: Epoch 75 / 100: avg data time: 6.34e-02, avg batch time: 0.5050, average train loss: 0.0066
[09/26 04:41:57 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1661, average loss: 1.3735
[09/26 04:41:57 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 93.00	
[09/26 04:41:57 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.04465154878918258
[09/26 04:42:04 visual_prompt]: Epoch 76 / 100: avg data time: 6.25e-02, avg batch time: 0.5037, average train loss: 0.0064
[09/26 04:42:05 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1663, average loss: 1.3761
[09/26 04:42:05 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 93.00	
[09/26 04:42:05 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.04135867420514276
[09/26 04:42:12 visual_prompt]: Epoch 77 / 100: avg data time: 5.54e-02, avg batch time: 0.4967, average train loss: 0.0065
[09/26 04:42:14 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1662, average loss: 1.3762
[09/26 04:42:14 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 93.00	
[09/26 04:42:14 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.03816770369262533
[09/26 04:42:20 visual_prompt]: Epoch 78 / 100: avg data time: 4.67e-02, avg batch time: 0.4896, average train loss: 0.0064
[09/26 04:42:22 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1661, average loss: 1.3735
[09/26 04:42:22 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.50	top5: 93.00	
[09/26 04:42:22 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.03508252495766863
[09/26 04:42:29 visual_prompt]: Epoch 79 / 100: avg data time: 4.68e-02, avg batch time: 0.4902, average train loss: 0.0064
[09/26 04:42:30 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1664, average loss: 1.3749
[09/26 04:42:30 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.50	top5: 93.00	
[09/26 04:42:30 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.032106896815325706
[09/26 04:42:37 visual_prompt]: Epoch 80 / 100: avg data time: 5.41e-02, avg batch time: 0.4966, average train loss: 0.0064
[09/26 04:42:38 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1664, average loss: 1.3759
[09/26 04:42:38 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.50	top5: 93.00	
[09/26 04:42:38 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.029244444610127762
[09/26 04:42:45 visual_prompt]: Epoch 81 / 100: avg data time: 5.95e-02, avg batch time: 0.5007, average train loss: 0.0063
[09/26 04:42:47 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1661, average loss: 1.3753
[09/26 04:42:47 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.50	top5: 93.00	
[09/26 04:42:47 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.026498655799159762
[09/26 04:42:53 visual_prompt]: Epoch 82 / 100: avg data time: 5.97e-02, avg batch time: 0.5018, average train loss: 0.0062
[09/26 04:42:55 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1662, average loss: 1.3745
[09/26 04:42:55 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.50	top5: 93.00	
[09/26 04:42:55 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.023872875703131582
[09/26 04:43:02 visual_prompt]: Epoch 83 / 100: avg data time: 4.58e-02, avg batch time: 0.4909, average train loss: 0.0062
[09/26 04:43:03 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1658, average loss: 1.3738
[09/26 04:43:03 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 93.00	
[09/26 04:43:03 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.021370303430619797
[09/26 04:43:10 visual_prompt]: Epoch 84 / 100: avg data time: 5.45e-02, avg batch time: 0.4976, average train loss: 0.0064
[09/26 04:43:11 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1664, average loss: 1.3728
[09/26 04:43:11 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 93.00	
[09/26 04:43:11 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.018993987980446755
[09/26 04:43:18 visual_prompt]: Epoch 85 / 100: avg data time: 5.27e-02, avg batch time: 0.4944, average train loss: 0.0064
[09/26 04:43:20 visual_prompt]: Inference (val):avg data time: 2.11e-05, avg batch time: 0.1662, average loss: 1.3733
[09/26 04:43:20 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 93.00	
[09/26 04:43:20 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.01674682452694516
[09/26 04:43:26 visual_prompt]: Epoch 86 / 100: avg data time: 5.11e-02, avg batch time: 0.4927, average train loss: 0.0063
[09/26 04:43:28 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1659, average loss: 1.3725
[09/26 04:43:28 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 93.00	
[09/26 04:43:28 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.014631550892634126
[09/26 04:43:35 visual_prompt]: Epoch 87 / 100: avg data time: 5.71e-02, avg batch time: 0.5003, average train loss: 0.0062
[09/26 04:43:36 visual_prompt]: Inference (val):avg data time: 1.88e-05, avg batch time: 0.1663, average loss: 1.3722
[09/26 04:43:36 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 93.00	
[09/26 04:43:36 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.012650744212604148
[09/26 04:43:43 visual_prompt]: Epoch 88 / 100: avg data time: 4.40e-02, avg batch time: 0.4894, average train loss: 0.0064
[09/26 04:43:44 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1661, average loss: 1.3725
[09/26 04:43:44 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 93.00	
[09/26 04:43:44 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.010806817794674878
[09/26 04:43:51 visual_prompt]: Epoch 89 / 100: avg data time: 5.77e-02, avg batch time: 0.5004, average train loss: 0.0064
[09/26 04:43:53 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1662, average loss: 1.3727
[09/26 04:43:53 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 93.00	
[09/26 04:43:53 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.009102018179151586
[09/26 04:43:59 visual_prompt]: Epoch 90 / 100: avg data time: 5.48e-02, avg batch time: 0.4965, average train loss: 0.0063
[09/26 04:44:01 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1661, average loss: 1.3725
[09/26 04:44:01 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.50	top5: 93.00	
[09/26 04:44:01 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.00753842240176146
[09/26 04:44:08 visual_prompt]: Epoch 91 / 100: avg data time: 5.23e-02, avg batch time: 0.4937, average train loss: 0.0065
[09/26 04:44:09 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1661, average loss: 1.3723
[09/26 04:44:09 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.50	top5: 93.00	
[09/26 04:44:09 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.006117935463105809
[09/26 04:44:16 visual_prompt]: Epoch 92 / 100: avg data time: 6.77e-02, avg batch time: 0.5090, average train loss: 0.0064
[09/26 04:44:18 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1664, average loss: 1.3725
[09/26 04:44:18 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.50	top5: 93.00	
[09/26 04:44:18 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.004842288007710138
[09/26 04:44:24 visual_prompt]: Epoch 93 / 100: avg data time: 5.94e-02, avg batch time: 0.5024, average train loss: 0.0063
[09/26 04:44:26 visual_prompt]: Inference (val):avg data time: 1.96e-05, avg batch time: 0.1661, average loss: 1.3725
[09/26 04:44:26 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.50	top5: 93.00	
[09/26 04:44:26 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.003713034215500441
[09/26 04:44:33 visual_prompt]: Epoch 94 / 100: avg data time: 5.83e-02, avg batch time: 0.5010, average train loss: 0.0063
[09/26 04:44:34 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1661, average loss: 1.3725
[09/26 04:44:34 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.50	top5: 93.00	
[09/26 04:44:34 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.002731549908274289
[09/26 04:44:41 visual_prompt]: Epoch 95 / 100: avg data time: 5.41e-02, avg batch time: 0.4975, average train loss: 0.0063
[09/26 04:44:43 visual_prompt]: Inference (val):avg data time: 2.02e-05, avg batch time: 0.1660, average loss: 1.3725
[09/26 04:44:43 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.50	top5: 93.00	
[09/26 04:44:43 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.0018990308734739975
[09/26 04:44:49 visual_prompt]: Epoch 96 / 100: avg data time: 5.84e-02, avg batch time: 0.4997, average train loss: 0.0063
[09/26 04:44:51 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1661, average loss: 1.3726
[09/26 04:44:51 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.50	top5: 93.00	
[09/26 04:44:51 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.0012164914073037048
[09/26 04:44:58 visual_prompt]: Epoch 97 / 100: avg data time: 5.27e-02, avg batch time: 0.4965, average train loss: 0.0062
[09/26 04:44:59 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1661, average loss: 1.3727
[09/26 04:44:59 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.50	top5: 93.00	
[09/26 04:44:59 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.0006847630789658388
[09/26 04:45:06 visual_prompt]: Epoch 98 / 100: avg data time: 5.01e-02, avg batch time: 0.4933, average train loss: 0.0063
[09/26 04:45:07 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1662, average loss: 1.3727
[09/26 04:45:07 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.50	top5: 93.00	
[09/26 04:45:07 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.0003044937175219753
[09/26 04:45:14 visual_prompt]: Epoch 99 / 100: avg data time: 5.68e-02, avg batch time: 0.5004, average train loss: 0.0062
[09/26 04:45:16 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1665, average loss: 1.3727
[09/26 04:45:16 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.50	top5: 93.00	
[09/26 04:45:16 visual_prompt]: Training 100 / 100 epoch, with learning rate 7.614662261302974e-05
[09/26 04:45:22 visual_prompt]: Epoch 100 / 100: avg data time: 4.63e-02, avg batch time: 0.4881, average train loss: 0.0062
[09/26 04:45:24 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1663, average loss: 1.3727
[09/26 04:45:24 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.50	top5: 93.00	
[09/26 04:45:24 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 04:45:24 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 04:45:24 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-cifar(num_classes=100)', 'DATA.NUMBER_CLASSES', '100', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 04:45:24 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 04:45:24 visual_prompt]: Training with config:
[09/26 04:45:24 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-cifar(num_classes=100)/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.25_wd0.0/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 0.25, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-cifar(num_classes=100)', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 100, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 04:45:24 visual_prompt]: Loading training data...
[09/26 04:45:24 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[:800], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/26 04:45:25 visual_prompt]: Number of images: 800
[09/26 04:45:25 visual_prompt]: Number of classes: 100 / 100
[09/26 04:45:25 visual_prompt]: Loading validation data...
[09/26 04:45:25 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[45000:45200], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/26 04:45:25 visual_prompt]: Number of images: 200
[09/26 04:45:25 visual_prompt]: Number of classes: 90 / 100
[09/26 04:45:25 visual_prompt]: Constructing models...
[09/26 04:45:27 visual_prompt]: Total Parameters: 86336356	 Gradient Parameters: 537700
[09/26 04:45:27 visual_prompt]: tuned percent:0.623
[09/26 04:45:28 visual_prompt]: Device used for model: 0
[09/26 04:45:28 visual_prompt]: Setting up Evaluator...
[09/26 04:45:28 visual_prompt]: Setting up Trainer...
[09/26 04:45:28 visual_prompt]: 	Setting up the optimizer...
[09/26 04:45:28 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 04:45:34 visual_prompt]: Epoch 1 / 100: avg data time: 5.73e-02, avg batch time: 0.4988, average train loss: 4.6541
[09/26 04:45:36 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1658, average loss: 4.6218
[09/26 04:45:36 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 7.00	
[09/26 04:45:36 visual_prompt]: Best epoch 1: best metric: 0.010
[09/26 04:45:36 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.025
[09/26 04:45:43 visual_prompt]: Epoch 2 / 100: avg data time: 5.70e-02, avg batch time: 0.4984, average train loss: 4.6317
[09/26 04:45:44 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1658, average loss: 4.5968
[09/26 04:45:44 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 6.50	
[09/26 04:45:44 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.05
[09/26 04:45:51 visual_prompt]: Epoch 3 / 100: avg data time: 5.25e-02, avg batch time: 0.4939, average train loss: 4.5822
[09/26 04:45:52 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1659, average loss: 4.6247
[09/26 04:45:52 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 5.50	
[09/26 04:45:52 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.075
[09/26 04:45:59 visual_prompt]: Epoch 4 / 100: avg data time: 5.68e-02, avg batch time: 0.4982, average train loss: 4.5355
[09/26 04:46:01 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1660, average loss: 4.5520
[09/26 04:46:01 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.50	top5: 12.50	
[09/26 04:46:01 visual_prompt]: Best epoch 4: best metric: 0.025
[09/26 04:46:01 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.1
[09/26 04:46:07 visual_prompt]: Epoch 5 / 100: avg data time: 5.11e-02, avg batch time: 0.4939, average train loss: 4.3488
[09/26 04:46:09 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1661, average loss: 4.1954
[09/26 04:46:09 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 6.50	top5: 21.50	
[09/26 04:46:09 visual_prompt]: Best epoch 5: best metric: 0.065
[09/26 04:46:09 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.125
[09/26 04:46:16 visual_prompt]: Epoch 6 / 100: avg data time: 6.08e-02, avg batch time: 0.5023, average train loss: 3.9774
[09/26 04:46:17 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1663, average loss: 3.9824
[09/26 04:46:17 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 10.00	top5: 24.00	
[09/26 04:46:17 visual_prompt]: Best epoch 6: best metric: 0.100
[09/26 04:46:17 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.15
[09/26 04:46:24 visual_prompt]: Epoch 7 / 100: avg data time: 5.63e-02, avg batch time: 0.4981, average train loss: 3.4657
[09/26 04:46:26 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1663, average loss: 3.4570
[09/26 04:46:26 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 13.00	top5: 40.50	
[09/26 04:46:26 visual_prompt]: Best epoch 7: best metric: 0.130
[09/26 04:46:26 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.175
[09/26 04:46:32 visual_prompt]: Epoch 8 / 100: avg data time: 5.68e-02, avg batch time: 0.4991, average train loss: 2.7332
[09/26 04:46:34 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1666, average loss: 2.8695
[09/26 04:46:34 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 21.00	top5: 62.50	
[09/26 04:46:34 visual_prompt]: Best epoch 8: best metric: 0.210
[09/26 04:46:34 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.2
[09/26 04:46:41 visual_prompt]: Epoch 9 / 100: avg data time: 6.24e-02, avg batch time: 0.5035, average train loss: 2.1233
[09/26 04:46:42 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1663, average loss: 2.5047
[09/26 04:46:42 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 33.50	top5: 72.00	
[09/26 04:46:42 visual_prompt]: Best epoch 9: best metric: 0.335
[09/26 04:46:42 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.225
[09/26 04:46:49 visual_prompt]: Epoch 10 / 100: avg data time: 5.19e-02, avg batch time: 0.4947, average train loss: 1.4473
[09/26 04:46:51 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1663, average loss: 2.1939
[09/26 04:46:51 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 37.50	top5: 78.00	
[09/26 04:46:51 visual_prompt]: Best epoch 10: best metric: 0.375
[09/26 04:46:51 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.25
[09/26 04:46:57 visual_prompt]: Epoch 11 / 100: avg data time: 5.40e-02, avg batch time: 0.4978, average train loss: 0.9264
[09/26 04:46:59 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1664, average loss: 1.8110
[09/26 04:46:59 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 51.50	top5: 79.50	
[09/26 04:46:59 visual_prompt]: Best epoch 11: best metric: 0.515
[09/26 04:46:59 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.24992385337738698
[09/26 04:47:06 visual_prompt]: Epoch 12 / 100: avg data time: 6.08e-02, avg batch time: 0.5030, average train loss: 0.5583
[09/26 04:47:07 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1662, average loss: 1.7479
[09/26 04:47:07 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 53.50	top5: 81.50	
[09/26 04:47:07 visual_prompt]: Best epoch 12: best metric: 0.535
[09/26 04:47:07 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.24969550628247802
[09/26 04:47:14 visual_prompt]: Epoch 13 / 100: avg data time: 4.71e-02, avg batch time: 0.4917, average train loss: 0.3304
[09/26 04:47:15 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1664, average loss: 1.6425
[09/26 04:47:15 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 55.50	top5: 86.00	
[09/26 04:47:15 visual_prompt]: Best epoch 13: best metric: 0.555
[09/26 04:47:15 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.24931523692103416
[09/26 04:47:22 visual_prompt]: Epoch 14 / 100: avg data time: 5.67e-02, avg batch time: 0.4995, average train loss: 0.2114
[09/26 04:47:24 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1663, average loss: 1.5892
[09/26 04:47:24 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 87.50	
[09/26 04:47:24 visual_prompt]: Best epoch 14: best metric: 0.580
[09/26 04:47:24 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.2487835085926963
[09/26 04:47:30 visual_prompt]: Epoch 15 / 100: avg data time: 5.81e-02, avg batch time: 0.5001, average train loss: 0.1300
[09/26 04:47:32 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1663, average loss: 1.5867
[09/26 04:47:32 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 60.50	top5: 85.50	
[09/26 04:47:32 visual_prompt]: Best epoch 15: best metric: 0.605
[09/26 04:47:32 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.24810096912652602
[09/26 04:47:39 visual_prompt]: Epoch 16 / 100: avg data time: 5.47e-02, avg batch time: 0.4967, average train loss: 0.0775
[09/26 04:47:40 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1663, average loss: 1.4745
[09/26 04:47:40 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.50	top5: 86.00	
[09/26 04:47:40 visual_prompt]: Best epoch 16: best metric: 0.615
[09/26 04:47:40 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.2472684500917257
[09/26 04:47:47 visual_prompt]: Epoch 17 / 100: avg data time: 5.91e-02, avg batch time: 0.5000, average train loss: 0.0484
[09/26 04:47:49 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1662, average loss: 1.4806
[09/26 04:47:49 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 86.00	
[09/26 04:47:49 visual_prompt]: Best epoch 17: best metric: 0.620
[09/26 04:47:49 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.24628696578449955
[09/26 04:47:55 visual_prompt]: Epoch 18 / 100: avg data time: 6.40e-02, avg batch time: 0.5055, average train loss: 0.0366
[09/26 04:47:57 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1663, average loss: 1.4536
[09/26 04:47:57 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.00	top5: 87.50	
[09/26 04:47:57 visual_prompt]: Best epoch 18: best metric: 0.630
[09/26 04:47:57 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.24515771199228986
[09/26 04:48:04 visual_prompt]: Epoch 19 / 100: avg data time: 5.78e-02, avg batch time: 0.5002, average train loss: 0.0299
[09/26 04:48:05 visual_prompt]: Inference (val):avg data time: 2.11e-05, avg batch time: 0.1662, average loss: 1.4349
[09/26 04:48:05 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 87.00	
[09/26 04:48:05 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.2438820645368942
[09/26 04:48:12 visual_prompt]: Epoch 20 / 100: avg data time: 5.60e-02, avg batch time: 0.4986, average train loss: 0.0250
[09/26 04:48:14 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1662, average loss: 1.4631
[09/26 04:48:14 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 87.00	
[09/26 04:48:14 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.24246157759823855
[09/26 04:48:20 visual_prompt]: Epoch 21 / 100: avg data time: 5.71e-02, avg batch time: 0.4992, average train loss: 0.0210
[09/26 04:48:22 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1661, average loss: 1.4535
[09/26 04:48:22 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 86.50	
[09/26 04:48:22 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.24089798182084843
[09/26 04:48:29 visual_prompt]: Epoch 22 / 100: avg data time: 5.68e-02, avg batch time: 0.4993, average train loss: 0.0186
[09/26 04:48:30 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1664, average loss: 1.4461
[09/26 04:48:30 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 86.00	
[09/26 04:48:30 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.2391931822053251
[09/26 04:48:37 visual_prompt]: Epoch 23 / 100: avg data time: 5.44e-02, avg batch time: 0.4957, average train loss: 0.0171
[09/26 04:48:38 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1661, average loss: 1.4477
[09/26 04:48:38 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.50	top5: 87.50	
[09/26 04:48:38 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.23734925578739588
[09/26 04:48:45 visual_prompt]: Epoch 24 / 100: avg data time: 5.62e-02, avg batch time: 0.4985, average train loss: 0.0155
[09/26 04:48:47 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1662, average loss: 1.4767
[09/26 04:48:47 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 60.50	top5: 87.00	
[09/26 04:48:47 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.23536844910736587
[09/26 04:48:53 visual_prompt]: Epoch 25 / 100: avg data time: 4.45e-02, avg batch time: 0.4879, average train loss: 0.0146
[09/26 04:48:55 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1663, average loss: 1.4691
[09/26 04:48:55 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.00	top5: 86.50	
[09/26 04:48:55 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.23325317547305485
[09/26 04:49:02 visual_prompt]: Epoch 26 / 100: avg data time: 5.81e-02, avg batch time: 0.5021, average train loss: 0.0135
[09/26 04:49:03 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1664, average loss: 1.4544
[09/26 04:49:03 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 87.00	
[09/26 04:49:03 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.23100601201955323
[09/26 04:49:10 visual_prompt]: Epoch 27 / 100: avg data time: 4.65e-02, avg batch time: 0.4894, average train loss: 0.0124
[09/26 04:49:11 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1664, average loss: 1.4542
[09/26 04:49:11 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 86.50	
[09/26 04:49:11 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.2286296965693802
[09/26 04:49:18 visual_prompt]: Epoch 28 / 100: avg data time: 5.51e-02, avg batch time: 0.4970, average train loss: 0.0119
[09/26 04:49:19 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1662, average loss: 1.4576
[09/26 04:49:19 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 87.00	
[09/26 04:49:19 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.22612712429686843
[09/26 04:49:26 visual_prompt]: Epoch 29 / 100: avg data time: 5.47e-02, avg batch time: 0.4965, average train loss: 0.0111
[09/26 04:49:28 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1665, average loss: 1.4518
[09/26 04:49:28 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 86.50	
[09/26 04:49:28 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.22350134420084022
[09/26 04:49:35 visual_prompt]: Epoch 30 / 100: avg data time: 6.05e-02, avg batch time: 0.5018, average train loss: 0.0107
[09/26 04:49:36 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1663, average loss: 1.4573
[09/26 04:49:36 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.00	top5: 87.00	
[09/26 04:49:36 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.22075555538987224
[09/26 04:49:43 visual_prompt]: Epoch 31 / 100: avg data time: 5.90e-02, avg batch time: 0.5005, average train loss: 0.0103
[09/26 04:49:44 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1664, average loss: 1.4689
[09/26 04:49:44 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 87.00	
[09/26 04:49:44 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.21789310318467428
[09/26 04:49:51 visual_prompt]: Epoch 32 / 100: avg data time: 4.78e-02, avg batch time: 0.4908, average train loss: 0.0097
[09/26 04:49:52 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1663, average loss: 1.4773
[09/26 04:49:52 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.00	top5: 87.00	
[09/26 04:49:52 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.21491747504233139
[09/26 04:49:59 visual_prompt]: Epoch 33 / 100: avg data time: 5.76e-02, avg batch time: 0.5007, average train loss: 0.0089
[09/26 04:50:01 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1662, average loss: 1.4727
[09/26 04:50:01 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.00	top5: 86.50	
[09/26 04:50:01 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.21183229630737466
[09/26 04:50:08 visual_prompt]: Epoch 34 / 100: avg data time: 5.41e-02, avg batch time: 0.4966, average train loss: 0.0088
[09/26 04:50:09 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1663, average loss: 1.4700
[09/26 04:50:09 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 86.00	
[09/26 04:50:09 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.20864132579485728
[09/26 04:50:16 visual_prompt]: Epoch 35 / 100: avg data time: 5.13e-02, avg batch time: 0.4943, average train loss: 0.0085
[09/26 04:50:17 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1664, average loss: 1.4769
[09/26 04:50:17 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.00	top5: 86.00	
[09/26 04:50:17 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.2053484512108174
[09/26 04:50:24 visual_prompt]: Epoch 36 / 100: avg data time: 5.28e-02, avg batch time: 0.4957, average train loss: 0.0081
[09/26 04:50:25 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1664, average loss: 1.4807
[09/26 04:50:25 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.00	top5: 86.50	
[09/26 04:50:25 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.20195768441570727
[09/26 04:50:32 visual_prompt]: Epoch 37 / 100: avg data time: 5.05e-02, avg batch time: 0.4936, average train loss: 0.0077
[09/26 04:50:34 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1664, average loss: 1.4776
[09/26 04:50:34 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 87.00	
[09/26 04:50:34 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.19847315653655914
[09/26 04:50:40 visual_prompt]: Epoch 38 / 100: avg data time: 5.81e-02, avg batch time: 0.5000, average train loss: 0.0075
[09/26 04:50:42 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1665, average loss: 1.4752
[09/26 04:50:42 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 87.50	
[09/26 04:50:42 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.19489911293384335
[09/26 04:50:49 visual_prompt]: Epoch 39 / 100: avg data time: 5.49e-02, avg batch time: 0.4962, average train loss: 0.0072
[09/26 04:50:50 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1665, average loss: 1.4768
[09/26 04:50:50 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.00	top5: 87.50	
[09/26 04:50:50 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.1912399080291506
[09/26 04:50:57 visual_prompt]: Epoch 40 / 100: avg data time: 5.76e-02, avg batch time: 0.5003, average train loss: 0.0070
[09/26 04:50:59 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1662, average loss: 1.4750
[09/26 04:50:59 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.00	top5: 87.00	
[09/26 04:50:59 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.1875
[09/26 04:51:05 visual_prompt]: Epoch 41 / 100: avg data time: 5.40e-02, avg batch time: 0.4977, average train loss: 0.0070
[09/26 04:51:07 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1665, average loss: 1.4773
[09/26 04:51:07 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 87.00	
[09/26 04:51:07 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.18368394534823634
[09/26 04:51:14 visual_prompt]: Epoch 42 / 100: avg data time: 5.37e-02, avg batch time: 0.4960, average train loss: 0.0067
[09/26 04:51:15 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1663, average loss: 1.4852
[09/26 04:51:15 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 87.50	
[09/26 04:51:15 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.17979639334863468
[09/26 04:51:22 visual_prompt]: Epoch 43 / 100: avg data time: 5.36e-02, avg batch time: 0.4949, average train loss: 0.0064
[09/26 04:51:23 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1664, average loss: 1.4869
[09/26 04:51:23 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.00	top5: 87.50	
[09/26 04:51:23 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.17584208038447505
[09/26 04:51:30 visual_prompt]: Epoch 44 / 100: avg data time: 5.66e-02, avg batch time: 0.4982, average train loss: 0.0064
[09/26 04:51:32 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1666, average loss: 1.4879
[09/26 04:51:32 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 87.00	
[09/26 04:51:32 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.17182582417698902
[09/26 04:51:39 visual_prompt]: Epoch 45 / 100: avg data time: 5.93e-02, avg batch time: 0.5026, average train loss: 0.0061
[09/26 04:51:40 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1664, average loss: 1.4842
[09/26 04:51:40 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 86.50	
[09/26 04:51:40 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.1677525179157086
[09/26 04:51:47 visual_prompt]: Epoch 46 / 100: avg data time: 6.54e-02, avg batch time: 0.5066, average train loss: 0.0062
[09/26 04:51:48 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1662, average loss: 1.4771
[09/26 04:51:48 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 87.00	
[09/26 04:51:48 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.16362712429686843
[09/26 04:51:55 visual_prompt]: Epoch 47 / 100: avg data time: 6.41e-02, avg batch time: 0.5052, average train loss: 0.0060
[09/26 04:51:57 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1664, average loss: 1.4790
[09/26 04:51:57 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 87.50	
[09/26 04:51:57 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.1594546694771249
[09/26 04:52:04 visual_prompt]: Epoch 48 / 100: avg data time: 5.90e-02, avg batch time: 0.5017, average train loss: 0.0059
[09/26 04:52:05 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1663, average loss: 1.4836
[09/26 04:52:05 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 87.00	
[09/26 04:52:05 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.15524023694995845
[09/26 04:52:12 visual_prompt]: Epoch 49 / 100: avg data time: 6.14e-02, avg batch time: 0.5038, average train loss: 0.0058
[09/26 04:52:14 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1664, average loss: 1.4899
[09/26 04:52:14 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 87.50	
[09/26 04:52:14 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.1509889613522199
[09/26 04:52:20 visual_prompt]: Epoch 50 / 100: avg data time: 6.29e-02, avg batch time: 0.5043, average train loss: 0.0055
[09/26 04:52:22 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.1663, average loss: 1.4908
[09/26 04:52:22 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 87.50	
[09/26 04:52:22 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.14670602220836632
[09/26 04:52:29 visual_prompt]: Epoch 51 / 100: avg data time: 5.72e-02, avg batch time: 0.4988, average train loss: 0.0055
[09/26 04:52:30 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1665, average loss: 1.4849
[09/26 04:52:30 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 86.50	
[09/26 04:52:30 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.14239663762000818
[09/26 04:52:37 visual_prompt]: Epoch 52 / 100: avg data time: 5.15e-02, avg batch time: 0.4945, average train loss: 0.0053
[09/26 04:52:38 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1664, average loss: 1.4785
[09/26 04:52:38 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.00	top5: 87.00	
[09/26 04:52:38 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.1380660579084567
[09/26 04:52:45 visual_prompt]: Epoch 53 / 100: avg data time: 4.57e-02, avg batch time: 0.4890, average train loss: 0.0053
[09/26 04:52:47 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1663, average loss: 1.4741
[09/26 04:52:47 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 87.00	
[09/26 04:52:47 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.13371955921801565
[09/26 04:52:53 visual_prompt]: Epoch 54 / 100: avg data time: 5.58e-02, avg batch time: 0.4971, average train loss: 0.0051
[09/26 04:52:55 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1664, average loss: 1.4760
[09/26 04:52:55 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.00	top5: 87.00	
[09/26 04:52:55 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.12936243708781264
[09/26 04:53:02 visual_prompt]: Epoch 55 / 100: avg data time: 6.05e-02, avg batch time: 0.5029, average train loss: 0.0052
[09/26 04:53:03 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1664, average loss: 1.4830
[09/26 04:53:03 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.00	top5: 87.50	
[09/26 04:53:03 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.125
[09/26 04:53:10 visual_prompt]: Epoch 56 / 100: avg data time: 5.32e-02, avg batch time: 0.4945, average train loss: 0.0051
[09/26 04:53:11 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1662, average loss: 1.4872
[09/26 04:53:11 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.00	top5: 86.50	
[09/26 04:53:11 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.12063756291218741
[09/26 04:53:18 visual_prompt]: Epoch 57 / 100: avg data time: 4.70e-02, avg batch time: 0.4914, average train loss: 0.0051
[09/26 04:53:20 visual_prompt]: Inference (val):avg data time: 1.98e-05, avg batch time: 0.1661, average loss: 1.4907
[09/26 04:53:20 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 87.00	
[09/26 04:53:20 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.11628044078198434
[09/26 04:53:26 visual_prompt]: Epoch 58 / 100: avg data time: 5.65e-02, avg batch time: 0.4987, average train loss: 0.0049
[09/26 04:53:28 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1663, average loss: 1.4962
[09/26 04:53:28 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 87.50	
[09/26 04:53:28 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.11193394209154334
[09/26 04:53:35 visual_prompt]: Epoch 59 / 100: avg data time: 5.30e-02, avg batch time: 0.4976, average train loss: 0.0050
[09/26 04:53:36 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1661, average loss: 1.4937
[09/26 04:53:36 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 88.00	
[09/26 04:53:36 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.10760336237999185
[09/26 04:53:43 visual_prompt]: Epoch 60 / 100: avg data time: 5.52e-02, avg batch time: 0.4970, average train loss: 0.0048
[09/26 04:53:44 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1662, average loss: 1.4909
[09/26 04:53:44 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 87.50	
[09/26 04:53:44 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.10329397779163371
[09/26 04:53:51 visual_prompt]: Epoch 61 / 100: avg data time: 4.56e-02, avg batch time: 0.4880, average train loss: 0.0048
[09/26 04:53:52 visual_prompt]: Inference (val):avg data time: 2.00e-05, avg batch time: 0.1663, average loss: 1.4934
[09/26 04:53:52 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 87.50	
[09/26 04:53:52 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.0990110386477801
[09/26 04:53:59 visual_prompt]: Epoch 62 / 100: avg data time: 5.72e-02, avg batch time: 0.4995, average train loss: 0.0047
[09/26 04:54:01 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1663, average loss: 1.4940
[09/26 04:54:01 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 88.00	
[09/26 04:54:01 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.09475976305004155
[09/26 04:54:07 visual_prompt]: Epoch 63 / 100: avg data time: 5.88e-02, avg batch time: 0.5004, average train loss: 0.0047
[09/26 04:54:09 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1663, average loss: 1.4937
[09/26 04:54:09 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 88.00	
[09/26 04:54:09 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.09054533052287511
[09/26 04:54:16 visual_prompt]: Epoch 64 / 100: avg data time: 5.62e-02, avg batch time: 0.4976, average train loss: 0.0046
[09/26 04:54:17 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1663, average loss: 1.4950
[09/26 04:54:17 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 87.50	
[09/26 04:54:17 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.08637287570313158
[09/26 04:54:24 visual_prompt]: Epoch 65 / 100: avg data time: 5.90e-02, avg batch time: 0.5025, average train loss: 0.0046
[09/26 04:54:25 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1663, average loss: 1.4944
[09/26 04:54:25 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 87.50	
[09/26 04:54:25 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.08224748208429142
[09/26 04:54:32 visual_prompt]: Epoch 66 / 100: avg data time: 5.47e-02, avg batch time: 0.4966, average train loss: 0.0047
[09/26 04:54:34 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1662, average loss: 1.4959
[09/26 04:54:34 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 87.50	
[09/26 04:54:34 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.07817417582301099
[09/26 04:54:40 visual_prompt]: Epoch 67 / 100: avg data time: 5.33e-02, avg batch time: 0.4949, average train loss: 0.0045
[09/26 04:54:42 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1663, average loss: 1.5019
[09/26 04:54:42 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 88.00	
[09/26 04:54:42 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.074157919615525
[09/26 04:54:49 visual_prompt]: Epoch 68 / 100: avg data time: 5.85e-02, avg batch time: 0.5012, average train loss: 0.0045
[09/26 04:54:50 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.1664, average loss: 1.5036
[09/26 04:54:50 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 88.00	
[09/26 04:54:50 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.07020360665136531
[09/26 04:54:57 visual_prompt]: Epoch 69 / 100: avg data time: 4.58e-02, avg batch time: 0.4882, average train loss: 0.0045
[09/26 04:54:58 visual_prompt]: Inference (val):avg data time: 2.00e-05, avg batch time: 0.1665, average loss: 1.5014
[09/26 04:54:58 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 87.50	
[09/26 04:54:58 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.06631605465176368
[09/26 04:55:05 visual_prompt]: Epoch 70 / 100: avg data time: 4.72e-02, avg batch time: 0.4907, average train loss: 0.0045
[09/26 04:55:06 visual_prompt]: Inference (val):avg data time: 3.77e-05, avg batch time: 0.1662, average loss: 1.5010
[09/26 04:55:07 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 87.50	
[09/26 04:55:07 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.06250000000000003
[09/26 04:55:13 visual_prompt]: Epoch 71 / 100: avg data time: 5.08e-02, avg batch time: 0.4934, average train loss: 0.0044
[09/26 04:55:15 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1661, average loss: 1.4994
[09/26 04:55:15 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 88.00	
[09/26 04:55:15 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.0587600919708494
[09/26 04:55:21 visual_prompt]: Epoch 72 / 100: avg data time: 4.66e-02, avg batch time: 0.4908, average train loss: 0.0044
[09/26 04:55:23 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1663, average loss: 1.4989
[09/26 04:55:23 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 88.00	
[09/26 04:55:23 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.055100887066156665
[09/26 04:55:30 visual_prompt]: Epoch 73 / 100: avg data time: 5.66e-02, avg batch time: 0.4990, average train loss: 0.0043
[09/26 04:55:31 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1664, average loss: 1.4983
[09/26 04:55:31 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 87.50	
[09/26 04:55:31 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.05152684346344087
[09/26 04:55:38 visual_prompt]: Epoch 74 / 100: avg data time: 4.95e-02, avg batch time: 0.4923, average train loss: 0.0043
[09/26 04:55:39 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1662, average loss: 1.4991
[09/26 04:55:39 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 88.00	
[09/26 04:55:39 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.048042315584292714
[09/26 04:55:46 visual_prompt]: Epoch 75 / 100: avg data time: 5.48e-02, avg batch time: 0.4970, average train loss: 0.0045
[09/26 04:55:48 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1663, average loss: 1.4989
[09/26 04:55:48 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 88.00	
[09/26 04:55:48 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.04465154878918258
[09/26 04:55:54 visual_prompt]: Epoch 76 / 100: avg data time: 6.12e-02, avg batch time: 0.5029, average train loss: 0.0043
[09/26 04:55:56 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1664, average loss: 1.4978
[09/26 04:55:56 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 88.00	
[09/26 04:55:56 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.04135867420514276
[09/26 04:56:03 visual_prompt]: Epoch 77 / 100: avg data time: 5.79e-02, avg batch time: 0.4997, average train loss: 0.0043
[09/26 04:56:04 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1662, average loss: 1.4964
[09/26 04:56:04 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 88.00	
[09/26 04:56:04 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.03816770369262533
[09/26 04:56:11 visual_prompt]: Epoch 78 / 100: avg data time: 6.00e-02, avg batch time: 0.5017, average train loss: 0.0043
[09/26 04:56:13 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1662, average loss: 1.4965
[09/26 04:56:13 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 88.00	
[09/26 04:56:13 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.03508252495766863
[09/26 04:56:19 visual_prompt]: Epoch 79 / 100: avg data time: 5.57e-02, avg batch time: 0.4970, average train loss: 0.0042
[09/26 04:56:21 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1663, average loss: 1.4966
[09/26 04:56:21 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 88.00	
[09/26 04:56:21 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.032106896815325706
[09/26 04:56:28 visual_prompt]: Epoch 80 / 100: avg data time: 5.50e-02, avg batch time: 0.4962, average train loss: 0.0042
[09/26 04:56:29 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1663, average loss: 1.4947
[09/26 04:56:29 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 88.00	
[09/26 04:56:29 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.029244444610127762
[09/26 04:56:36 visual_prompt]: Epoch 81 / 100: avg data time: 5.25e-02, avg batch time: 0.4953, average train loss: 0.0041
[09/26 04:56:37 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1665, average loss: 1.4934
[09/26 04:56:37 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 88.00	
[09/26 04:56:37 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.026498655799159762
[09/26 04:56:44 visual_prompt]: Epoch 82 / 100: avg data time: 5.95e-02, avg batch time: 0.5029, average train loss: 0.0041
[09/26 04:56:46 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1662, average loss: 1.4929
[09/26 04:56:46 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 88.00	
[09/26 04:56:46 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.023872875703131582
[09/26 04:56:52 visual_prompt]: Epoch 83 / 100: avg data time: 4.57e-02, avg batch time: 0.4883, average train loss: 0.0041
[09/26 04:56:54 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1664, average loss: 1.4935
[09/26 04:56:54 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 88.00	
[09/26 04:56:54 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.021370303430619797
[09/26 04:57:01 visual_prompt]: Epoch 84 / 100: avg data time: 4.90e-02, avg batch time: 0.4904, average train loss: 0.0043
[09/26 04:57:02 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1661, average loss: 1.4937
[09/26 04:57:02 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 88.00	
[09/26 04:57:02 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.018993987980446755
[09/26 04:57:09 visual_prompt]: Epoch 85 / 100: avg data time: 5.61e-02, avg batch time: 0.4982, average train loss: 0.0041
[09/26 04:57:10 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1663, average loss: 1.4936
[09/26 04:57:10 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 88.00	
[09/26 04:57:10 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.01674682452694516
[09/26 04:57:17 visual_prompt]: Epoch 86 / 100: avg data time: 5.79e-02, avg batch time: 0.4995, average train loss: 0.0042
[09/26 04:57:19 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1663, average loss: 1.4940
[09/26 04:57:19 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 88.00	
[09/26 04:57:19 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.014631550892634126
[09/26 04:57:25 visual_prompt]: Epoch 87 / 100: avg data time: 5.44e-02, avg batch time: 0.4961, average train loss: 0.0042
[09/26 04:57:27 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1664, average loss: 1.4941
[09/26 04:57:27 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 88.00	
[09/26 04:57:27 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.012650744212604148
[09/26 04:57:34 visual_prompt]: Epoch 88 / 100: avg data time: 5.02e-02, avg batch time: 0.4925, average train loss: 0.0042
[09/26 04:57:35 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1663, average loss: 1.4941
[09/26 04:57:35 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 88.00	
[09/26 04:57:35 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.010806817794674878
[09/26 04:57:42 visual_prompt]: Epoch 89 / 100: avg data time: 5.60e-02, avg batch time: 0.4977, average train loss: 0.0041
[09/26 04:57:43 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1661, average loss: 1.4940
[09/26 04:57:43 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 88.00	
[09/26 04:57:43 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.009102018179151586
[09/26 04:57:50 visual_prompt]: Epoch 90 / 100: avg data time: 5.20e-02, avg batch time: 0.4947, average train loss: 0.0042
[09/26 04:57:52 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1659, average loss: 1.4941
[09/26 04:57:52 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 88.00	
[09/26 04:57:52 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.00753842240176146
[09/26 04:57:59 visual_prompt]: Epoch 91 / 100: avg data time: 6.36e-02, avg batch time: 0.5044, average train loss: 0.0042
[09/26 04:58:00 visual_prompt]: Inference (val):avg data time: 2.05e-05, avg batch time: 0.1661, average loss: 1.4940
[09/26 04:58:00 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 88.00	
[09/26 04:58:00 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.006117935463105809
[09/26 04:58:07 visual_prompt]: Epoch 92 / 100: avg data time: 5.60e-02, avg batch time: 0.4971, average train loss: 0.0041
[09/26 04:58:08 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1662, average loss: 1.4938
[09/26 04:58:08 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 88.00	
[09/26 04:58:08 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.004842288007710138
[09/26 04:58:15 visual_prompt]: Epoch 93 / 100: avg data time: 6.02e-02, avg batch time: 0.5019, average train loss: 0.0041
[09/26 04:58:17 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.1660, average loss: 1.4937
[09/26 04:58:17 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 88.00	
[09/26 04:58:17 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.003713034215500441
[09/26 04:58:23 visual_prompt]: Epoch 94 / 100: avg data time: 5.39e-02, avg batch time: 0.4953, average train loss: 0.0041
[09/26 04:58:25 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1661, average loss: 1.4936
[09/26 04:58:25 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 88.00	
[09/26 04:58:25 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.002731549908274289
[09/26 04:58:31 visual_prompt]: Epoch 95 / 100: avg data time: 4.84e-02, avg batch time: 0.4913, average train loss: 0.0041
[09/26 04:58:33 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1663, average loss: 1.4936
[09/26 04:58:33 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 88.00	
[09/26 04:58:33 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.0018990308734739975
[09/26 04:58:40 visual_prompt]: Epoch 96 / 100: avg data time: 4.65e-02, avg batch time: 0.4895, average train loss: 0.0041
[09/26 04:58:41 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1663, average loss: 1.4935
[09/26 04:58:41 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 88.00	
[09/26 04:58:41 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.0012164914073037048
[09/26 04:58:48 visual_prompt]: Epoch 97 / 100: avg data time: 4.47e-02, avg batch time: 0.4890, average train loss: 0.0041
[09/26 04:58:49 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1662, average loss: 1.4935
[09/26 04:58:49 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 88.00	
[09/26 04:58:49 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.0006847630789658388
[09/26 04:58:56 visual_prompt]: Epoch 98 / 100: avg data time: 4.78e-02, avg batch time: 0.4901, average train loss: 0.0041
[09/26 04:58:57 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1662, average loss: 1.4936
[09/26 04:58:57 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 88.00	
[09/26 04:58:57 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.0003044937175219753
[09/26 04:59:04 visual_prompt]: Epoch 99 / 100: avg data time: 6.02e-02, avg batch time: 0.5016, average train loss: 0.0042
[09/26 04:59:06 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1661, average loss: 1.4936
[09/26 04:59:06 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 88.00	
[09/26 04:59:06 visual_prompt]: Training 100 / 100 epoch, with learning rate 7.614662261302974e-05
[09/26 04:59:12 visual_prompt]: Epoch 100 / 100: avg data time: 5.67e-02, avg batch time: 0.4987, average train loss: 0.0041
[09/26 04:59:14 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1663, average loss: 1.4936
[09/26 04:59:14 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 88.00	
[09/26 04:59:14 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 04:59:14 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 04:59:14 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-cifar(num_classes=100)', 'DATA.NUMBER_CLASSES', '100', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 04:59:14 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 04:59:14 visual_prompt]: Training with config:
[09/26 04:59:14 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-cifar(num_classes=100)/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.1_wd0.01/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 0.1, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-cifar(num_classes=100)', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 100, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 04:59:14 visual_prompt]: Loading training data...
[09/26 04:59:14 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[:800], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/26 04:59:15 visual_prompt]: Number of images: 800
[09/26 04:59:15 visual_prompt]: Number of classes: 100 / 100
[09/26 04:59:15 visual_prompt]: Loading validation data...
[09/26 04:59:15 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[45000:45200], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/26 04:59:15 visual_prompt]: Number of images: 200
[09/26 04:59:15 visual_prompt]: Number of classes: 90 / 100
[09/26 04:59:15 visual_prompt]: Constructing models...
[09/26 04:59:18 visual_prompt]: Total Parameters: 86336356	 Gradient Parameters: 537700
[09/26 04:59:18 visual_prompt]: tuned percent:0.623
[09/26 04:59:18 visual_prompt]: Device used for model: 0
[09/26 04:59:18 visual_prompt]: Setting up Evaluator...
[09/26 04:59:18 visual_prompt]: Setting up Trainer...
[09/26 04:59:18 visual_prompt]: 	Setting up the optimizer...
[09/26 04:59:18 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 04:59:24 visual_prompt]: Epoch 1 / 100: avg data time: 4.74e-02, avg batch time: 0.4931, average train loss: 4.6586
[09/26 04:59:26 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1659, average loss: 4.6218
[09/26 04:59:26 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 7.00	
[09/26 04:59:26 visual_prompt]: Best epoch 1: best metric: 0.010
[09/26 04:59:26 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.010000000000000002
[09/26 04:59:33 visual_prompt]: Epoch 2 / 100: avg data time: 5.29e-02, avg batch time: 0.4944, average train loss: 4.6411
[09/26 04:59:34 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1659, average loss: 4.6127
[09/26 04:59:34 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.50	top5: 7.00	
[09/26 04:59:34 visual_prompt]: Best epoch 2: best metric: 0.025
[09/26 04:59:34 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.020000000000000004
[09/26 04:59:41 visual_prompt]: Epoch 3 / 100: avg data time: 5.96e-02, avg batch time: 0.5010, average train loss: 4.6054
[09/26 04:59:43 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1658, average loss: 4.5909
[09/26 04:59:43 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 6.50	
[09/26 04:59:43 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.03
[09/26 04:59:49 visual_prompt]: Epoch 4 / 100: avg data time: 5.58e-02, avg batch time: 0.4965, average train loss: 4.5615
[09/26 04:59:51 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1662, average loss: 4.6152
[09/26 04:59:51 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.50	
[09/26 04:59:51 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.04000000000000001
[09/26 04:59:58 visual_prompt]: Epoch 5 / 100: avg data time: 6.22e-02, avg batch time: 0.5031, average train loss: 4.5159
[09/26 04:59:59 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1661, average loss: 4.5575
[09/26 04:59:59 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 10.00	
[09/26 04:59:59 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.05
[09/26 05:00:06 visual_prompt]: Epoch 6 / 100: avg data time: 6.11e-02, avg batch time: 0.5029, average train loss: 4.4184
[09/26 05:00:08 visual_prompt]: Inference (val):avg data time: 4.04e-05, avg batch time: 0.1661, average loss: 4.3676
[09/26 05:00:08 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 7.00	top5: 19.50	
[09/26 05:00:08 visual_prompt]: Best epoch 6: best metric: 0.070
[09/26 05:00:08 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.06
[09/26 05:00:14 visual_prompt]: Epoch 7 / 100: avg data time: 5.19e-02, avg batch time: 0.4943, average train loss: 4.1626
[09/26 05:00:16 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1660, average loss: 4.1948
[09/26 05:00:16 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 7.00	top5: 22.50	
[09/26 05:00:16 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.06999999999999999
[09/26 05:00:23 visual_prompt]: Epoch 8 / 100: avg data time: 6.72e-02, avg batch time: 0.5092, average train loss: 3.7522
[09/26 05:00:24 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1659, average loss: 3.7763
[09/26 05:00:24 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 9.50	top5: 31.00	
[09/26 05:00:24 visual_prompt]: Best epoch 8: best metric: 0.095
[09/26 05:00:24 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.08000000000000002
[09/26 05:00:31 visual_prompt]: Epoch 9 / 100: avg data time: 5.36e-02, avg batch time: 0.4969, average train loss: 3.2566
[09/26 05:00:32 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1663, average loss: 3.4322
[09/26 05:00:32 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 15.50	top5: 45.00	
[09/26 05:00:32 visual_prompt]: Best epoch 9: best metric: 0.155
[09/26 05:00:32 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.09000000000000001
[09/26 05:00:39 visual_prompt]: Epoch 10 / 100: avg data time: 5.88e-02, avg batch time: 0.5000, average train loss: 2.7787
[09/26 05:00:41 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1663, average loss: 3.0465
[09/26 05:00:41 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 21.00	top5: 57.00	
[09/26 05:00:41 visual_prompt]: Best epoch 10: best metric: 0.210
[09/26 05:00:41 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.1
[09/26 05:00:48 visual_prompt]: Epoch 11 / 100: avg data time: 5.48e-02, avg batch time: 0.4963, average train loss: 2.3381
[09/26 05:00:49 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1664, average loss: 2.7402
[09/26 05:00:49 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 34.00	top5: 66.00	
[09/26 05:00:49 visual_prompt]: Best epoch 11: best metric: 0.340
[09/26 05:00:49 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0999695413509548
[09/26 05:00:56 visual_prompt]: Epoch 12 / 100: avg data time: 5.83e-02, avg batch time: 0.4998, average train loss: 1.9167
[09/26 05:00:57 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1664, average loss: 2.3460
[09/26 05:00:57 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 40.50	top5: 77.00	
[09/26 05:00:57 visual_prompt]: Best epoch 12: best metric: 0.405
[09/26 05:00:57 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.09987820251299122
[09/26 05:01:04 visual_prompt]: Epoch 13 / 100: avg data time: 6.05e-02, avg batch time: 0.5032, average train loss: 1.5644
[09/26 05:01:06 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1663, average loss: 2.2672
[09/26 05:01:06 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 47.00	top5: 82.50	
[09/26 05:01:06 visual_prompt]: Best epoch 13: best metric: 0.470
[09/26 05:01:06 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.09972609476841367
[09/26 05:01:12 visual_prompt]: Epoch 14 / 100: avg data time: 4.73e-02, avg batch time: 0.4902, average train loss: 1.3415
[09/26 05:01:14 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1665, average loss: 2.1288
[09/26 05:01:14 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 48.50	top5: 80.50	
[09/26 05:01:14 visual_prompt]: Best epoch 14: best metric: 0.485
[09/26 05:01:14 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.09951340343707853
[09/26 05:01:21 visual_prompt]: Epoch 15 / 100: avg data time: 6.05e-02, avg batch time: 0.5033, average train loss: 1.1735
[09/26 05:01:22 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1663, average loss: 1.9572
[09/26 05:01:22 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 51.00	top5: 85.50	
[09/26 05:01:22 visual_prompt]: Best epoch 15: best metric: 0.510
[09/26 05:01:22 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.09924038765061041
[09/26 05:01:29 visual_prompt]: Epoch 16 / 100: avg data time: 5.73e-02, avg batch time: 0.5008, average train loss: 1.0678
[09/26 05:01:31 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1664, average loss: 2.0586
[09/26 05:01:31 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 52.50	top5: 82.50	
[09/26 05:01:31 visual_prompt]: Best epoch 16: best metric: 0.525
[09/26 05:01:31 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.09890738003669029
[09/26 05:01:37 visual_prompt]: Epoch 17 / 100: avg data time: 5.28e-02, avg batch time: 0.4951, average train loss: 1.0226
[09/26 05:01:39 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1665, average loss: 2.0650
[09/26 05:01:39 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 51.00	top5: 84.00	
[09/26 05:01:39 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.09851478631379983
[09/26 05:01:46 visual_prompt]: Epoch 18 / 100: avg data time: 5.92e-02, avg batch time: 0.5015, average train loss: 0.9752
[09/26 05:01:47 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1664, average loss: 1.7758
[09/26 05:01:47 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.00	top5: 88.00	
[09/26 05:01:47 visual_prompt]: Best epoch 18: best metric: 0.610
[09/26 05:01:47 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.09806308479691594
[09/26 05:01:54 visual_prompt]: Epoch 19 / 100: avg data time: 6.27e-02, avg batch time: 0.5044, average train loss: 0.8297
[09/26 05:01:55 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1664, average loss: 1.7546
[09/26 05:01:55 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.50	top5: 88.00	
[09/26 05:01:55 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.09755282581475769
[09/26 05:02:02 visual_prompt]: Epoch 20 / 100: avg data time: 4.43e-02, avg batch time: 0.4889, average train loss: 0.7221
[09/26 05:02:04 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1665, average loss: 1.6267
[09/26 05:02:04 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 89.50	
[09/26 05:02:04 visual_prompt]: Best epoch 20: best metric: 0.625
[09/26 05:02:04 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.09698463103929543
[09/26 05:02:10 visual_prompt]: Epoch 21 / 100: avg data time: 5.91e-02, avg batch time: 0.5007, average train loss: 0.6161
[09/26 05:02:12 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1665, average loss: 1.6151
[09/26 05:02:12 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.00	top5: 88.50	
[09/26 05:02:12 visual_prompt]: Best epoch 21: best metric: 0.630
[09/26 05:02:12 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.09635919272833937
[09/26 05:02:19 visual_prompt]: Epoch 22 / 100: avg data time: 5.82e-02, avg batch time: 0.5005, average train loss: 0.5719
[09/26 05:02:20 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1666, average loss: 1.5820
[09/26 05:02:20 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.00	top5: 91.00	
[09/26 05:02:20 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.09567727288213004
[09/26 05:02:27 visual_prompt]: Epoch 23 / 100: avg data time: 6.20e-02, avg batch time: 0.5037, average train loss: 0.5495
[09/26 05:02:29 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1664, average loss: 1.6633
[09/26 05:02:29 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 88.50	
[09/26 05:02:29 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.09493970231495835
[09/26 05:02:35 visual_prompt]: Epoch 24 / 100: avg data time: 5.68e-02, avg batch time: 0.4984, average train loss: 0.5586
[09/26 05:02:37 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1664, average loss: 1.5002
[09/26 05:02:37 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 91.50	
[09/26 05:02:37 visual_prompt]: Best epoch 24: best metric: 0.650
[09/26 05:02:37 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.09414737964294635
[09/26 05:02:44 visual_prompt]: Epoch 25 / 100: avg data time: 4.98e-02, avg batch time: 0.4930, average train loss: 0.5571
[09/26 05:02:45 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.1663, average loss: 1.4689
[09/26 05:02:45 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.00	top5: 93.00	
[09/26 05:02:45 visual_prompt]: Best epoch 25: best metric: 0.670
[09/26 05:02:45 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.09330127018922195
[09/26 05:02:52 visual_prompt]: Epoch 26 / 100: avg data time: 6.32e-02, avg batch time: 0.5052, average train loss: 0.5283
[09/26 05:02:53 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1665, average loss: 1.5290
[09/26 05:02:53 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 68.50	top5: 90.50	
[09/26 05:02:53 visual_prompt]: Best epoch 26: best metric: 0.685
[09/26 05:02:53 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.0924024048078213
[09/26 05:03:00 visual_prompt]: Epoch 27 / 100: avg data time: 6.00e-02, avg batch time: 0.5030, average train loss: 0.5585
[09/26 05:03:02 visual_prompt]: Inference (val):avg data time: 1.96e-05, avg batch time: 0.1664, average loss: 1.6220
[09/26 05:03:02 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.00	top5: 89.00	
[09/26 05:03:02 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.09145187862775209
[09/26 05:03:08 visual_prompt]: Epoch 28 / 100: avg data time: 5.82e-02, avg batch time: 0.5000, average train loss: 0.6197
[09/26 05:03:10 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1663, average loss: 1.5311
[09/26 05:03:10 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 90.50	
[09/26 05:03:10 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.09045084971874738
[09/26 05:03:17 visual_prompt]: Epoch 29 / 100: avg data time: 5.67e-02, avg batch time: 0.4988, average train loss: 0.5590
[09/26 05:03:18 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.1665, average loss: 1.5496
[09/26 05:03:18 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.00	top5: 87.50	
[09/26 05:03:18 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.0894005376803361
[09/26 05:03:25 visual_prompt]: Epoch 30 / 100: avg data time: 5.79e-02, avg batch time: 0.5013, average train loss: 0.5063
[09/26 05:03:27 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1661, average loss: 1.5324
[09/26 05:03:27 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.00	top5: 90.00	
[09/26 05:03:27 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.0883022221559489
[09/26 05:03:33 visual_prompt]: Epoch 31 / 100: avg data time: 5.68e-02, avg batch time: 0.4990, average train loss: 0.4882
[09/26 05:03:35 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1662, average loss: 1.4388
[09/26 05:03:35 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 69.50	top5: 91.50	
[09/26 05:03:35 visual_prompt]: Best epoch 31: best metric: 0.695
[09/26 05:03:35 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.08715724127386971
[09/26 05:03:42 visual_prompt]: Epoch 32 / 100: avg data time: 5.97e-02, avg batch time: 0.5017, average train loss: 0.4828
[09/26 05:03:43 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1661, average loss: 1.3875
[09/26 05:03:43 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 68.50	top5: 91.50	
[09/26 05:03:43 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.08596699001693256
[09/26 05:03:50 visual_prompt]: Epoch 33 / 100: avg data time: 5.85e-02, avg batch time: 0.4998, average train loss: 0.4448
[09/26 05:03:51 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1670, average loss: 1.3942
[09/26 05:03:51 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 69.50	top5: 92.00	
[09/26 05:03:51 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.08473291852294987
[09/26 05:03:58 visual_prompt]: Epoch 34 / 100: avg data time: 5.23e-02, avg batch time: 0.4946, average train loss: 0.4271
[09/26 05:04:00 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1661, average loss: 1.4232
[09/26 05:04:00 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 70.00	top5: 91.50	
[09/26 05:04:00 visual_prompt]: Best epoch 34: best metric: 0.700
[09/26 05:04:00 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.08345653031794292
[09/26 05:04:06 visual_prompt]: Epoch 35 / 100: avg data time: 5.85e-02, avg batch time: 0.4997, average train loss: 0.4376
[09/26 05:04:08 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1662, average loss: 1.3581
[09/26 05:04:08 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 71.00	top5: 93.00	
[09/26 05:04:08 visual_prompt]: Best epoch 35: best metric: 0.710
[09/26 05:04:08 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.08213938048432697
[09/26 05:04:15 visual_prompt]: Epoch 36 / 100: avg data time: 5.91e-02, avg batch time: 0.5032, average train loss: 0.4368
[09/26 05:04:16 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1660, average loss: 1.3023
[09/26 05:04:16 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 75.00	top5: 94.00	
[09/26 05:04:16 visual_prompt]: Best epoch 36: best metric: 0.750
[09/26 05:04:16 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.08078307376628291
[09/26 05:04:23 visual_prompt]: Epoch 37 / 100: avg data time: 6.74e-02, avg batch time: 0.5100, average train loss: 0.4455
[09/26 05:04:25 visual_prompt]: Inference (val):avg data time: 2.00e-05, avg batch time: 0.1662, average loss: 1.4286
[09/26 05:04:25 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 72.00	top5: 90.50	
[09/26 05:04:25 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.07938926261462366
[09/26 05:04:31 visual_prompt]: Epoch 38 / 100: avg data time: 5.28e-02, avg batch time: 0.4958, average train loss: 0.4253
[09/26 05:04:33 visual_prompt]: Inference (val):avg data time: 4.05e-05, avg batch time: 0.1663, average loss: 1.3961
[09/26 05:04:33 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 69.00	top5: 89.50	
[09/26 05:04:33 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.07795964517353735
[09/26 05:04:40 visual_prompt]: Epoch 39 / 100: avg data time: 5.87e-02, avg batch time: 0.5005, average train loss: 0.4294
[09/26 05:04:41 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1661, average loss: 1.3565
[09/26 05:04:41 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.50	top5: 93.00	
[09/26 05:04:41 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.07649596321166025
[09/26 05:04:48 visual_prompt]: Epoch 40 / 100: avg data time: 5.63e-02, avg batch time: 0.4988, average train loss: 0.4515
[09/26 05:04:49 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1663, average loss: 1.4533
[09/26 05:04:49 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.00	top5: 91.00	
[09/26 05:04:49 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.07500000000000001
[09/26 05:04:56 visual_prompt]: Epoch 41 / 100: avg data time: 5.51e-02, avg batch time: 0.4971, average train loss: 0.4518
[09/26 05:04:58 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1663, average loss: 1.3405
[09/26 05:04:58 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 70.00	top5: 91.00	
[09/26 05:04:58 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.07347357813929455
[09/26 05:05:04 visual_prompt]: Epoch 42 / 100: avg data time: 4.09e-02, avg batch time: 0.4857, average train loss: 0.4639
[09/26 05:05:06 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1662, average loss: 1.4245
[09/26 05:05:06 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 70.50	top5: 91.50	
[09/26 05:05:06 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.07191855733945388
[09/26 05:05:13 visual_prompt]: Epoch 43 / 100: avg data time: 5.48e-02, avg batch time: 0.4975, average train loss: 0.4525
[09/26 05:05:14 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1661, average loss: 1.3837
[09/26 05:05:14 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 69.00	top5: 93.50	
[09/26 05:05:14 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.07033683215379002
[09/26 05:05:21 visual_prompt]: Epoch 44 / 100: avg data time: 5.49e-02, avg batch time: 0.4970, average train loss: 0.4130
[09/26 05:05:22 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1662, average loss: 1.4242
[09/26 05:05:22 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 69.00	top5: 91.50	
[09/26 05:05:22 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.0687303296707956
[09/26 05:05:29 visual_prompt]: Epoch 45 / 100: avg data time: 5.45e-02, avg batch time: 0.4966, average train loss: 0.3842
[09/26 05:05:31 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1663, average loss: 1.3605
[09/26 05:05:31 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 72.00	top5: 92.00	
[09/26 05:05:31 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.06710100716628345
[09/26 05:05:37 visual_prompt]: Epoch 46 / 100: avg data time: 5.45e-02, avg batch time: 0.4966, average train loss: 0.3812
[09/26 05:05:39 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1662, average loss: 1.3927
[09/26 05:05:39 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 69.50	top5: 92.50	
[09/26 05:05:39 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.06545084971874737
[09/26 05:05:46 visual_prompt]: Epoch 47 / 100: avg data time: 5.63e-02, avg batch time: 0.4979, average train loss: 0.3455
[09/26 05:05:47 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1662, average loss: 1.2853
[09/26 05:05:47 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 74.50	top5: 93.50	
[09/26 05:05:47 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.06378186779084996
[09/26 05:05:54 visual_prompt]: Epoch 48 / 100: avg data time: 4.62e-02, avg batch time: 0.4887, average train loss: 0.3335
[09/26 05:05:55 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1662, average loss: 1.2855
[09/26 05:05:55 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 72.50	top5: 93.00	
[09/26 05:05:55 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.06209609477998338
[09/26 05:06:02 visual_prompt]: Epoch 49 / 100: avg data time: 5.18e-02, avg batch time: 0.4932, average train loss: 0.3011
[09/26 05:06:04 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1663, average loss: 1.2704
[09/26 05:06:04 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 71.50	top5: 91.50	
[09/26 05:06:04 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.06039558454088796
[09/26 05:06:10 visual_prompt]: Epoch 50 / 100: avg data time: 4.49e-02, avg batch time: 0.4881, average train loss: 0.2800
[09/26 05:06:12 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1662, average loss: 1.2720
[09/26 05:06:12 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 74.00	top5: 92.50	
[09/26 05:06:12 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.058682408883346526
[09/26 05:06:19 visual_prompt]: Epoch 51 / 100: avg data time: 5.75e-02, avg batch time: 0.4998, average train loss: 0.2693
[09/26 05:06:20 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1662, average loss: 1.2768
[09/26 05:06:20 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 75.00	top5: 93.00	
[09/26 05:06:20 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.05695865504800327
[09/26 05:06:27 visual_prompt]: Epoch 52 / 100: avg data time: 6.43e-02, avg batch time: 0.5049, average train loss: 0.2599
[09/26 05:06:28 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1662, average loss: 1.2406
[09/26 05:06:28 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 74.50	top5: 94.50	
[09/26 05:06:28 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.05522642316338268
[09/26 05:06:35 visual_prompt]: Epoch 53 / 100: avg data time: 5.21e-02, avg batch time: 0.4931, average train loss: 0.2559
[09/26 05:06:37 visual_prompt]: Inference (val):avg data time: 4.21e-05, avg batch time: 0.1661, average loss: 1.2152
[09/26 05:06:37 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 74.50	top5: 91.50	
[09/26 05:06:37 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.05348782368720626
[09/26 05:06:43 visual_prompt]: Epoch 54 / 100: avg data time: 4.60e-02, avg batch time: 0.4880, average train loss: 0.2665
[09/26 05:06:45 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1662, average loss: 1.2777
[09/26 05:06:45 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 74.00	top5: 94.00	
[09/26 05:06:45 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.05174497483512506
[09/26 05:06:51 visual_prompt]: Epoch 55 / 100: avg data time: 5.76e-02, avg batch time: 0.4987, average train loss: 0.2673
[09/26 05:06:53 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1662, average loss: 1.2436
[09/26 05:06:53 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 74.00	top5: 93.50	
[09/26 05:06:53 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.05
[09/26 05:07:00 visual_prompt]: Epoch 56 / 100: avg data time: 6.39e-02, avg batch time: 0.5048, average train loss: 0.2690
[09/26 05:07:01 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1665, average loss: 1.3523
[09/26 05:07:01 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 71.50	top5: 93.50	
[09/26 05:07:01 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.04825502516487497
[09/26 05:07:08 visual_prompt]: Epoch 57 / 100: avg data time: 5.98e-02, avg batch time: 0.5021, average train loss: 0.3083
[09/26 05:07:10 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1661, average loss: 1.3612
[09/26 05:07:10 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 71.50	top5: 92.00	
[09/26 05:07:10 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.04651217631279374
[09/26 05:07:16 visual_prompt]: Epoch 58 / 100: avg data time: 6.15e-02, avg batch time: 0.5036, average train loss: 0.4140
[09/26 05:07:18 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1662, average loss: 1.9288
[09/26 05:07:18 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 60.00	top5: 88.00	
[09/26 05:07:18 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.04477357683661734
[09/26 05:07:25 visual_prompt]: Epoch 59 / 100: avg data time: 4.70e-02, avg batch time: 0.4886, average train loss: 1.2227
[09/26 05:07:26 visual_prompt]: Inference (val):avg data time: 1.85e-05, avg batch time: 0.1661, average loss: 2.2620
[09/26 05:07:26 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.50	top5: 81.00	
[09/26 05:07:26 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.04304134495199674
[09/26 05:07:33 visual_prompt]: Epoch 60 / 100: avg data time: 4.77e-02, avg batch time: 0.4906, average train loss: 1.6959
[09/26 05:07:34 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1662, average loss: 1.8038
[09/26 05:07:34 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.00	top5: 89.00	
[09/26 05:07:34 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.041317591116653486
[09/26 05:07:41 visual_prompt]: Epoch 61 / 100: avg data time: 6.18e-02, avg batch time: 0.5041, average train loss: 0.9086
[09/26 05:07:43 visual_prompt]: Inference (val):avg data time: 1.93e-05, avg batch time: 0.1663, average loss: 1.5058
[09/26 05:07:43 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 71.00	top5: 92.50	
[09/26 05:07:43 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.039604415459112044
[09/26 05:07:49 visual_prompt]: Epoch 62 / 100: avg data time: 4.45e-02, avg batch time: 0.4883, average train loss: 0.5941
[09/26 05:07:51 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1661, average loss: 1.3709
[09/26 05:07:51 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 72.00	top5: 90.50	
[09/26 05:07:51 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.037903905220016625
[09/26 05:07:58 visual_prompt]: Epoch 63 / 100: avg data time: 5.58e-02, avg batch time: 0.4982, average train loss: 0.4264
[09/26 05:07:59 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1661, average loss: 1.3299
[09/26 05:07:59 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 72.50	top5: 92.00	
[09/26 05:07:59 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.036218132209150045
[09/26 05:08:06 visual_prompt]: Epoch 64 / 100: avg data time: 4.58e-02, avg batch time: 0.4882, average train loss: 0.3364
[09/26 05:08:07 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1660, average loss: 1.2397
[09/26 05:08:07 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 72.00	top5: 93.50	
[09/26 05:08:07 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.03454915028125263
[09/26 05:08:14 visual_prompt]: Epoch 65 / 100: avg data time: 5.55e-02, avg batch time: 0.4975, average train loss: 0.2902
[09/26 05:08:15 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1663, average loss: 1.2570
[09/26 05:08:15 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 71.50	top5: 93.50	
[09/26 05:08:15 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.03289899283371657
[09/26 05:08:22 visual_prompt]: Epoch 66 / 100: avg data time: 5.77e-02, avg batch time: 0.4989, average train loss: 0.2688
[09/26 05:08:24 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1661, average loss: 1.2033
[09/26 05:08:24 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 73.00	top5: 93.50	
[09/26 05:08:24 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.0312696703292044
[09/26 05:08:31 visual_prompt]: Epoch 67 / 100: avg data time: 5.58e-02, avg batch time: 0.4971, average train loss: 0.2536
[09/26 05:08:32 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1662, average loss: 1.2163
[09/26 05:08:32 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 76.00	top5: 94.00	
[09/26 05:08:32 visual_prompt]: Best epoch 67: best metric: 0.760
[09/26 05:08:32 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.02966316784621
[09/26 05:08:39 visual_prompt]: Epoch 68 / 100: avg data time: 4.43e-02, avg batch time: 0.4868, average train loss: 0.2469
[09/26 05:08:40 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1662, average loss: 1.2507
[09/26 05:08:40 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 72.00	top5: 94.50	
[09/26 05:08:40 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.028081442660546126
[09/26 05:08:47 visual_prompt]: Epoch 69 / 100: avg data time: 5.29e-02, avg batch time: 0.4964, average train loss: 0.2435
[09/26 05:08:48 visual_prompt]: Inference (val):avg data time: 3.47e-05, avg batch time: 0.1661, average loss: 1.2279
[09/26 05:08:49 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 74.50	top5: 93.00	
[09/26 05:08:49 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.026526421860705474
[09/26 05:08:55 visual_prompt]: Epoch 70 / 100: avg data time: 6.25e-02, avg batch time: 0.5037, average train loss: 0.2410
[09/26 05:08:57 visual_prompt]: Inference (val):avg data time: 2.00e-05, avg batch time: 0.1663, average loss: 1.2434
[09/26 05:08:57 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 73.00	top5: 94.00	
[09/26 05:08:57 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.025000000000000012
[09/26 05:09:04 visual_prompt]: Epoch 71 / 100: avg data time: 5.38e-02, avg batch time: 0.4954, average train loss: 0.2404
[09/26 05:09:05 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1663, average loss: 1.2313
[09/26 05:09:05 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 74.00	top5: 94.50	
[09/26 05:09:05 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.02350403678833976
[09/26 05:09:12 visual_prompt]: Epoch 72 / 100: avg data time: 6.32e-02, avg batch time: 0.5045, average train loss: 0.2399
[09/26 05:09:13 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1662, average loss: 1.2489
[09/26 05:09:13 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 74.00	top5: 93.50	
[09/26 05:09:13 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.022040354826462667
[09/26 05:09:20 visual_prompt]: Epoch 73 / 100: avg data time: 6.02e-02, avg batch time: 0.5028, average train loss: 0.2409
[09/26 05:09:22 visual_prompt]: Inference (val):avg data time: 1.98e-05, avg batch time: 0.1661, average loss: 1.2456
[09/26 05:09:22 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 73.00	top5: 93.00	
[09/26 05:09:22 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.02061073738537635
[09/26 05:09:28 visual_prompt]: Epoch 74 / 100: avg data time: 4.35e-02, avg batch time: 0.4868, average train loss: 0.2402
[09/26 05:09:30 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1663, average loss: 1.2479
[09/26 05:09:30 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 74.50	top5: 93.00	
[09/26 05:09:30 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.019216926233717086
[09/26 05:09:36 visual_prompt]: Epoch 75 / 100: avg data time: 5.47e-02, avg batch time: 0.4967, average train loss: 0.2399
[09/26 05:09:38 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1663, average loss: 1.2253
[09/26 05:09:38 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 75.50	top5: 93.00	
[09/26 05:09:38 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.017860619515673033
[09/26 05:09:45 visual_prompt]: Epoch 76 / 100: avg data time: 5.69e-02, avg batch time: 0.4995, average train loss: 0.2397
[09/26 05:09:46 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1663, average loss: 1.2416
[09/26 05:09:46 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 76.00	top5: 93.00	
[09/26 05:09:46 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.016543469682057107
[09/26 05:09:53 visual_prompt]: Epoch 77 / 100: avg data time: 4.25e-02, avg batch time: 0.4858, average train loss: 0.2387
[09/26 05:09:54 visual_prompt]: Inference (val):avg data time: 4.20e-05, avg batch time: 0.1664, average loss: 1.2382
[09/26 05:09:54 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 73.50	top5: 93.50	
[09/26 05:09:54 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.015267081477050132
[09/26 05:10:01 visual_prompt]: Epoch 78 / 100: avg data time: 5.92e-02, avg batch time: 0.5007, average train loss: 0.2387
[09/26 05:10:03 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1662, average loss: 1.2744
[09/26 05:10:03 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 73.00	top5: 92.50	
[09/26 05:10:03 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.014033009983067453
[09/26 05:10:10 visual_prompt]: Epoch 79 / 100: avg data time: 6.06e-02, avg batch time: 0.5030, average train loss: 0.2378
[09/26 05:10:11 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1663, average loss: 1.2602
[09/26 05:10:11 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 73.50	top5: 92.00	
[09/26 05:10:11 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.012842758726130284
[09/26 05:10:18 visual_prompt]: Epoch 80 / 100: avg data time: 5.85e-02, avg batch time: 0.5005, average train loss: 0.2386
[09/26 05:10:20 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1663, average loss: 1.2648
[09/26 05:10:20 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 74.00	top5: 92.00	
[09/26 05:10:20 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.011697777844051106
[09/26 05:10:26 visual_prompt]: Epoch 81 / 100: avg data time: 5.24e-02, avg batch time: 0.4958, average train loss: 0.2380
[09/26 05:10:28 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1661, average loss: 1.2619
[09/26 05:10:28 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 74.50	top5: 91.50	
[09/26 05:10:28 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.010599462319663905
[09/26 05:10:35 visual_prompt]: Epoch 82 / 100: avg data time: 5.56e-02, avg batch time: 0.4968, average train loss: 0.2369
[09/26 05:10:36 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1663, average loss: 1.2699
[09/26 05:10:36 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 72.00	top5: 93.50	
[09/26 05:10:36 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.009549150281252633
[09/26 05:10:43 visual_prompt]: Epoch 83 / 100: avg data time: 5.60e-02, avg batch time: 0.4971, average train loss: 0.2361
[09/26 05:10:44 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1664, average loss: 1.2642
[09/26 05:10:44 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 74.00	top5: 92.50	
[09/26 05:10:44 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.008548121372247919
[09/26 05:10:51 visual_prompt]: Epoch 84 / 100: avg data time: 5.50e-02, avg batch time: 0.4973, average train loss: 0.2353
[09/26 05:10:53 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1661, average loss: 1.2634
[09/26 05:10:53 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 73.50	top5: 92.00	
[09/26 05:10:53 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.007597595192178702
[09/26 05:11:00 visual_prompt]: Epoch 85 / 100: avg data time: 6.03e-02, avg batch time: 0.5025, average train loss: 0.2358
[09/26 05:11:01 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1663, average loss: 1.2764
[09/26 05:11:01 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 73.00	top5: 92.50	
[09/26 05:11:01 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.006698729810778065
[09/26 05:11:08 visual_prompt]: Epoch 86 / 100: avg data time: 4.46e-02, avg batch time: 0.4872, average train loss: 0.2357
[09/26 05:11:09 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1662, average loss: 1.2741
[09/26 05:11:09 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 72.50	top5: 91.50	
[09/26 05:11:09 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.005852620357053651
[09/26 05:11:16 visual_prompt]: Epoch 87 / 100: avg data time: 5.26e-02, avg batch time: 0.4961, average train loss: 0.2360
[09/26 05:11:18 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1661, average loss: 1.2863
[09/26 05:11:18 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 71.00	top5: 92.50	
[09/26 05:11:18 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.00506029768504166
[09/26 05:11:24 visual_prompt]: Epoch 88 / 100: avg data time: 6.51e-02, avg batch time: 0.5058, average train loss: 0.2360
[09/26 05:11:26 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1661, average loss: 1.2791
[09/26 05:11:26 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 72.00	top5: 92.00	
[09/26 05:11:26 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.004322727117869951
[09/26 05:11:33 visual_prompt]: Epoch 89 / 100: avg data time: 5.99e-02, avg batch time: 0.5005, average train loss: 0.2349
[09/26 05:11:34 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1659, average loss: 1.2788
[09/26 05:11:34 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 73.00	top5: 91.50	
[09/26 05:11:34 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.0036408072716606343
[09/26 05:11:41 visual_prompt]: Epoch 90 / 100: avg data time: 5.83e-02, avg batch time: 0.4992, average train loss: 0.2351
[09/26 05:11:43 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1662, average loss: 1.2890
[09/26 05:11:43 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 72.50	top5: 91.50	
[09/26 05:11:43 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.0030153689607045845
[09/26 05:11:49 visual_prompt]: Epoch 91 / 100: avg data time: 4.36e-02, avg batch time: 0.4866, average train loss: 0.2343
[09/26 05:11:51 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1662, average loss: 1.2740
[09/26 05:11:51 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 72.50	top5: 92.50	
[09/26 05:11:51 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.0024471741852423235
[09/26 05:11:57 visual_prompt]: Epoch 92 / 100: avg data time: 5.28e-02, avg batch time: 0.4943, average train loss: 0.2340
[09/26 05:11:59 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1665, average loss: 1.2722
[09/26 05:11:59 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 73.00	top5: 91.50	
[09/26 05:11:59 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.0019369152030840554
[09/26 05:12:06 visual_prompt]: Epoch 93 / 100: avg data time: 4.89e-02, avg batch time: 0.4903, average train loss: 0.2338
[09/26 05:12:07 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1662, average loss: 1.2826
[09/26 05:12:07 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 72.50	top5: 92.50	
[09/26 05:12:07 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.0014852136862001765
[09/26 05:12:14 visual_prompt]: Epoch 94 / 100: avg data time: 5.48e-02, avg batch time: 0.4964, average train loss: 0.2338
[09/26 05:12:15 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1661, average loss: 1.2878
[09/26 05:12:15 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 72.50	top5: 93.00	
[09/26 05:12:15 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.0010926199633097156
[09/26 05:12:22 visual_prompt]: Epoch 95 / 100: avg data time: 6.20e-02, avg batch time: 0.5029, average train loss: 0.2341
[09/26 05:12:24 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1662, average loss: 1.2828
[09/26 05:12:24 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 72.50	top5: 92.50	
[09/26 05:12:24 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.0007596123493895991
[09/26 05:12:31 visual_prompt]: Epoch 96 / 100: avg data time: 5.67e-02, avg batch time: 0.4997, average train loss: 0.2343
[09/26 05:12:32 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1661, average loss: 1.2784
[09/26 05:12:32 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 73.00	top5: 92.00	
[09/26 05:12:32 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.00048659656292148194
[09/26 05:12:39 visual_prompt]: Epoch 97 / 100: avg data time: 4.88e-02, avg batch time: 0.4910, average train loss: 0.2336
[09/26 05:12:40 visual_prompt]: Inference (val):avg data time: 1.99e-05, avg batch time: 0.1662, average loss: 1.2775
[09/26 05:12:40 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 73.00	top5: 92.00	
[09/26 05:12:40 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.0002739052315863355
[09/26 05:12:47 visual_prompt]: Epoch 98 / 100: avg data time: 5.74e-02, avg batch time: 0.4993, average train loss: 0.2330
[09/26 05:12:48 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1661, average loss: 1.2784
[09/26 05:12:48 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 73.00	top5: 92.00	
[09/26 05:12:48 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.00012179748700879012
[09/26 05:12:55 visual_prompt]: Epoch 99 / 100: avg data time: 5.55e-02, avg batch time: 0.4970, average train loss: 0.2340
[09/26 05:12:57 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1660, average loss: 1.2786
[09/26 05:12:57 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 73.00	top5: 92.00	
[09/26 05:12:57 visual_prompt]: Training 100 / 100 epoch, with learning rate 3.0458649045211895e-05
[09/26 05:13:03 visual_prompt]: Epoch 100 / 100: avg data time: 5.49e-02, avg batch time: 0.4969, average train loss: 0.2333
[09/26 05:13:05 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1661, average loss: 1.2787
[09/26 05:13:05 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 73.00	top5: 92.50	
[09/26 05:13:05 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 05:13:05 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 05:13:05 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-cifar(num_classes=100)', 'DATA.NUMBER_CLASSES', '100', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 05:13:05 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 05:13:05 visual_prompt]: Training with config:
[09/26 05:13:05 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-cifar(num_classes=100)/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.1_wd0.001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 0.1, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-cifar(num_classes=100)', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 100, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 05:13:05 visual_prompt]: Loading training data...
[09/26 05:13:05 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[:800], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/26 05:13:06 visual_prompt]: Number of images: 800
[09/26 05:13:06 visual_prompt]: Number of classes: 100 / 100
[09/26 05:13:06 visual_prompt]: Loading validation data...
[09/26 05:13:06 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[45000:45200], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/26 05:13:06 visual_prompt]: Number of images: 200
[09/26 05:13:06 visual_prompt]: Number of classes: 90 / 100
[09/26 05:13:06 visual_prompt]: Constructing models...
[09/26 05:13:09 visual_prompt]: Total Parameters: 86336356	 Gradient Parameters: 537700
[09/26 05:13:09 visual_prompt]: tuned percent:0.623
[09/26 05:13:09 visual_prompt]: Device used for model: 0
[09/26 05:13:09 visual_prompt]: Setting up Evaluator...
[09/26 05:13:09 visual_prompt]: Setting up Trainer...
[09/26 05:13:09 visual_prompt]: 	Setting up the optimizer...
[09/26 05:13:09 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 05:13:16 visual_prompt]: Epoch 1 / 100: avg data time: 6.21e-02, avg batch time: 0.5060, average train loss: 4.6544
[09/26 05:13:17 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1657, average loss: 4.6218
[09/26 05:13:17 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 7.00	
[09/26 05:13:17 visual_prompt]: Best epoch 1: best metric: 0.010
[09/26 05:13:17 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.010000000000000002
[09/26 05:13:24 visual_prompt]: Epoch 2 / 100: avg data time: 5.64e-02, avg batch time: 0.4985, average train loss: 4.6447
[09/26 05:13:25 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1656, average loss: 4.6074
[09/26 05:13:25 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 7.00	
[09/26 05:13:25 visual_prompt]: Best epoch 2: best metric: 0.020
[09/26 05:13:25 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.020000000000000004
[09/26 05:13:32 visual_prompt]: Epoch 3 / 100: avg data time: 6.52e-02, avg batch time: 0.5052, average train loss: 4.5933
[09/26 05:13:34 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1657, average loss: 4.6003
[09/26 05:13:34 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 6.50	
[09/26 05:13:34 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.03
[09/26 05:13:41 visual_prompt]: Epoch 4 / 100: avg data time: 5.71e-02, avg batch time: 0.4980, average train loss: 4.5394
[09/26 05:13:42 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1657, average loss: 4.5718
[09/26 05:13:42 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 5.00	top5: 10.50	
[09/26 05:13:42 visual_prompt]: Best epoch 4: best metric: 0.050
[09/26 05:13:42 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.04000000000000001
[09/26 05:13:49 visual_prompt]: Epoch 5 / 100: avg data time: 4.68e-02, avg batch time: 0.4885, average train loss: 4.4567
[09/26 05:13:50 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1657, average loss: 4.4851
[09/26 05:13:50 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 5.00	top5: 15.00	
[09/26 05:13:50 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.05
[09/26 05:13:57 visual_prompt]: Epoch 6 / 100: avg data time: 5.58e-02, avg batch time: 0.4984, average train loss: 4.2753
[09/26 05:13:59 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1661, average loss: 4.2081
[09/26 05:13:59 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 6.50	top5: 20.00	
[09/26 05:13:59 visual_prompt]: Best epoch 6: best metric: 0.065
[09/26 05:13:59 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.06
[09/26 05:14:05 visual_prompt]: Epoch 7 / 100: avg data time: 5.68e-02, avg batch time: 0.4988, average train loss: 3.9600
[09/26 05:14:07 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1662, average loss: 3.9116
[09/26 05:14:07 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 13.50	top5: 29.50	
[09/26 05:14:07 visual_prompt]: Best epoch 7: best metric: 0.135
[09/26 05:14:07 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.06999999999999999
[09/26 05:14:14 visual_prompt]: Epoch 8 / 100: avg data time: 6.25e-02, avg batch time: 0.5040, average train loss: 3.4635
[09/26 05:14:15 visual_prompt]: Inference (val):avg data time: 3.98e-05, avg batch time: 0.1660, average loss: 3.6903
[09/26 05:14:15 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 8.50	top5: 33.50	
[09/26 05:14:15 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.08000000000000002
[09/26 05:14:22 visual_prompt]: Epoch 9 / 100: avg data time: 4.60e-02, avg batch time: 0.4876, average train loss: 2.9615
[09/26 05:14:23 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1660, average loss: 3.0883
[09/26 05:14:23 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 21.50	top5: 54.50	
[09/26 05:14:23 visual_prompt]: Best epoch 9: best metric: 0.215
[09/26 05:14:23 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.09000000000000001
[09/26 05:14:30 visual_prompt]: Epoch 10 / 100: avg data time: 6.40e-02, avg batch time: 0.5046, average train loss: 2.4104
[09/26 05:14:32 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1661, average loss: 2.7735
[09/26 05:14:32 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 30.00	top5: 61.50	
[09/26 05:14:32 visual_prompt]: Best epoch 10: best metric: 0.300
[09/26 05:14:32 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.1
[09/26 05:14:39 visual_prompt]: Epoch 11 / 100: avg data time: 5.83e-02, avg batch time: 0.5000, average train loss: 1.8344
[09/26 05:14:40 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1662, average loss: 2.4998
[09/26 05:14:40 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 32.00	top5: 69.00	
[09/26 05:14:40 visual_prompt]: Best epoch 11: best metric: 0.320
[09/26 05:14:40 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0999695413509548
[09/26 05:14:47 visual_prompt]: Epoch 12 / 100: avg data time: 5.93e-02, avg batch time: 0.5023, average train loss: 1.3179
[09/26 05:14:48 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1661, average loss: 2.2421
[09/26 05:14:48 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 45.50	top5: 76.00	
[09/26 05:14:48 visual_prompt]: Best epoch 12: best metric: 0.455
[09/26 05:14:48 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.09987820251299122
[09/26 05:14:55 visual_prompt]: Epoch 13 / 100: avg data time: 5.36e-02, avg batch time: 0.4947, average train loss: 0.9281
[09/26 05:14:57 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1659, average loss: 1.9835
[09/26 05:14:57 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 47.50	top5: 80.00	
[09/26 05:14:57 visual_prompt]: Best epoch 13: best metric: 0.475
[09/26 05:14:57 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.09972609476841367
[09/26 05:15:03 visual_prompt]: Epoch 14 / 100: avg data time: 6.04e-02, avg batch time: 0.5012, average train loss: 0.6391
[09/26 05:15:05 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1663, average loss: 1.9149
[09/26 05:15:05 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 49.50	top5: 80.00	
[09/26 05:15:05 visual_prompt]: Best epoch 14: best metric: 0.495
[09/26 05:15:05 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.09951340343707853
[09/26 05:15:12 visual_prompt]: Epoch 15 / 100: avg data time: 5.46e-02, avg batch time: 0.4960, average train loss: 0.4645
[09/26 05:15:13 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1661, average loss: 1.7223
[09/26 05:15:13 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.00	top5: 84.50	
[09/26 05:15:13 visual_prompt]: Best epoch 15: best metric: 0.540
[09/26 05:15:13 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.09924038765061041
[09/26 05:15:20 visual_prompt]: Epoch 16 / 100: avg data time: 5.41e-02, avg batch time: 0.4949, average train loss: 0.3190
[09/26 05:15:21 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1663, average loss: 1.6831
[09/26 05:15:21 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 57.50	top5: 83.00	
[09/26 05:15:21 visual_prompt]: Best epoch 16: best metric: 0.575
[09/26 05:15:21 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.09890738003669029
[09/26 05:15:28 visual_prompt]: Epoch 17 / 100: avg data time: 5.26e-02, avg batch time: 0.4944, average train loss: 0.2280
[09/26 05:15:30 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1662, average loss: 1.6594
[09/26 05:15:30 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.00	top5: 86.00	
[09/26 05:15:30 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.09851478631379983
[09/26 05:15:36 visual_prompt]: Epoch 18 / 100: avg data time: 4.96e-02, avg batch time: 0.4916, average train loss: 0.1703
[09/26 05:15:38 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1662, average loss: 1.6224
[09/26 05:15:38 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.00	top5: 82.00	
[09/26 05:15:38 visual_prompt]: Best epoch 18: best metric: 0.590
[09/26 05:15:38 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.09806308479691594
[09/26 05:15:45 visual_prompt]: Epoch 19 / 100: avg data time: 5.21e-02, avg batch time: 0.4936, average train loss: 0.1290
[09/26 05:15:46 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1663, average loss: 1.5553
[09/26 05:15:46 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.00	top5: 87.50	
[09/26 05:15:46 visual_prompt]: Best epoch 19: best metric: 0.610
[09/26 05:15:46 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.09755282581475769
[09/26 05:15:53 visual_prompt]: Epoch 20 / 100: avg data time: 4.29e-02, avg batch time: 0.4857, average train loss: 0.1026
[09/26 05:15:54 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1662, average loss: 1.5491
[09/26 05:15:54 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 60.00	top5: 85.50	
[09/26 05:15:54 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.09698463103929543
[09/26 05:16:01 visual_prompt]: Epoch 21 / 100: avg data time: 5.42e-02, avg batch time: 0.4971, average train loss: 0.0868
[09/26 05:16:03 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1663, average loss: 1.5329
[09/26 05:16:03 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 60.00	top5: 87.00	
[09/26 05:16:03 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.09635919272833937
[09/26 05:16:10 visual_prompt]: Epoch 22 / 100: avg data time: 6.23e-02, avg batch time: 0.5029, average train loss: 0.0776
[09/26 05:16:11 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1662, average loss: 1.5529
[09/26 05:16:11 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.00	top5: 83.00	
[09/26 05:16:11 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.09567727288213004
[09/26 05:16:18 visual_prompt]: Epoch 23 / 100: avg data time: 6.28e-02, avg batch time: 0.5040, average train loss: 0.0685
[09/26 05:16:20 visual_prompt]: Inference (val):avg data time: 4.32e-05, avg batch time: 0.1661, average loss: 1.5413
[09/26 05:16:20 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.50	top5: 86.50	
[09/26 05:16:20 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.09493970231495835
[09/26 05:16:26 visual_prompt]: Epoch 24 / 100: avg data time: 4.31e-02, avg batch time: 0.4861, average train loss: 0.0597
[09/26 05:16:28 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1661, average loss: 1.5294
[09/26 05:16:28 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.50	top5: 87.00	
[09/26 05:16:28 visual_prompt]: Best epoch 24: best metric: 0.635
[09/26 05:16:28 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.09414737964294635
[09/26 05:16:34 visual_prompt]: Epoch 25 / 100: avg data time: 5.75e-02, avg batch time: 0.4983, average train loss: 0.0571
[09/26 05:16:36 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1671, average loss: 1.5188
[09/26 05:16:36 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.00	top5: 86.50	
[09/26 05:16:36 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.09330127018922195
[09/26 05:16:43 visual_prompt]: Epoch 26 / 100: avg data time: 5.75e-02, avg batch time: 0.4998, average train loss: 0.0537
[09/26 05:16:44 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1661, average loss: 1.4983
[09/26 05:16:44 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 87.00	
[09/26 05:16:44 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.0924024048078213
[09/26 05:16:51 visual_prompt]: Epoch 27 / 100: avg data time: 4.97e-02, avg batch time: 0.4921, average train loss: 0.0488
[09/26 05:16:53 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1660, average loss: 1.4791
[09/26 05:16:53 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.50	top5: 88.00	
[09/26 05:16:53 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.09145187862775209
[09/26 05:16:59 visual_prompt]: Epoch 28 / 100: avg data time: 4.62e-02, avg batch time: 0.4874, average train loss: 0.0479
[09/26 05:17:01 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1661, average loss: 1.4826
[09/26 05:17:01 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 64.00	top5: 88.00	
[09/26 05:17:01 visual_prompt]: Best epoch 28: best metric: 0.640
[09/26 05:17:01 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.09045084971874738
[09/26 05:17:08 visual_prompt]: Epoch 29 / 100: avg data time: 5.78e-02, avg batch time: 0.4998, average train loss: 0.0473
[09/26 05:17:09 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1662, average loss: 1.5139
[09/26 05:17:09 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.50	top5: 87.00	
[09/26 05:17:09 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.0894005376803361
[09/26 05:17:16 visual_prompt]: Epoch 30 / 100: avg data time: 5.45e-02, avg batch time: 0.4960, average train loss: 0.0443
[09/26 05:17:17 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1662, average loss: 1.4704
[09/26 05:17:17 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.50	top5: 87.00	
[09/26 05:17:17 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.0883022221559489
[09/26 05:17:24 visual_prompt]: Epoch 31 / 100: avg data time: 6.01e-02, avg batch time: 0.5011, average train loss: 0.0430
[09/26 05:17:26 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1663, average loss: 1.4669
[09/26 05:17:26 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 87.50	
[09/26 05:17:26 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.08715724127386971
[09/26 05:17:32 visual_prompt]: Epoch 32 / 100: avg data time: 5.34e-02, avg batch time: 0.4953, average train loss: 0.0422
[09/26 05:17:34 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1664, average loss: 1.4685
[09/26 05:17:34 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.00	top5: 88.00	
[09/26 05:17:34 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.08596699001693256
[09/26 05:17:41 visual_prompt]: Epoch 33 / 100: avg data time: 5.66e-02, avg batch time: 0.4977, average train loss: 0.0415
[09/26 05:17:42 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1663, average loss: 1.4702
[09/26 05:17:42 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 64.00	top5: 88.50	
[09/26 05:17:42 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.08473291852294987
[09/26 05:17:49 visual_prompt]: Epoch 34 / 100: avg data time: 5.42e-02, avg batch time: 0.4956, average train loss: 0.0407
[09/26 05:17:50 visual_prompt]: Inference (val):avg data time: 4.32e-05, avg batch time: 0.1661, average loss: 1.4527
[09/26 05:17:50 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.50	top5: 89.00	
[09/26 05:17:50 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.08345653031794292
[09/26 05:17:57 visual_prompt]: Epoch 35 / 100: avg data time: 6.11e-02, avg batch time: 0.5034, average train loss: 0.0403
[09/26 05:17:59 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1663, average loss: 1.4561
[09/26 05:17:59 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 87.50	
[09/26 05:17:59 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.08213938048432697
[09/26 05:18:05 visual_prompt]: Epoch 36 / 100: avg data time: 6.18e-02, avg batch time: 0.5037, average train loss: 0.0381
[09/26 05:18:07 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1661, average loss: 1.4608
[09/26 05:18:07 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 87.00	
[09/26 05:18:07 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.08078307376628291
[09/26 05:18:14 visual_prompt]: Epoch 37 / 100: avg data time: 6.08e-02, avg batch time: 0.5037, average train loss: 0.0385
[09/26 05:18:15 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1663, average loss: 1.4409
[09/26 05:18:15 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.00	top5: 89.50	
[09/26 05:18:15 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.07938926261462366
[09/26 05:18:22 visual_prompt]: Epoch 38 / 100: avg data time: 5.80e-02, avg batch time: 0.4993, average train loss: 0.0384
[09/26 05:18:24 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1660, average loss: 1.4872
[09/26 05:18:24 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.50	top5: 87.50	
[09/26 05:18:24 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.07795964517353735
[09/26 05:18:31 visual_prompt]: Epoch 39 / 100: avg data time: 6.45e-02, avg batch time: 0.5065, average train loss: 0.0385
[09/26 05:18:32 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1663, average loss: 1.4335
[09/26 05:18:32 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 90.00	
[09/26 05:18:32 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.07649596321166025
[09/26 05:18:39 visual_prompt]: Epoch 40 / 100: avg data time: 4.99e-02, avg batch time: 0.4910, average train loss: 0.0380
[09/26 05:18:40 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1662, average loss: 1.4479
[09/26 05:18:40 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.00	top5: 89.50	
[09/26 05:18:40 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.07500000000000001
[09/26 05:18:47 visual_prompt]: Epoch 41 / 100: avg data time: 5.91e-02, avg batch time: 0.5002, average train loss: 0.0373
[09/26 05:18:49 visual_prompt]: Inference (val):avg data time: 2.02e-05, avg batch time: 0.1663, average loss: 1.4437
[09/26 05:18:49 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 89.00	
[09/26 05:18:49 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.07347357813929455
[09/26 05:18:55 visual_prompt]: Epoch 42 / 100: avg data time: 5.91e-02, avg batch time: 0.5011, average train loss: 0.0373
[09/26 05:18:57 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1663, average loss: 1.4218
[09/26 05:18:57 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 60.50	top5: 90.50	
[09/26 05:18:57 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.07191855733945388
[09/26 05:19:04 visual_prompt]: Epoch 43 / 100: avg data time: 4.91e-02, avg batch time: 0.4914, average train loss: 0.0363
[09/26 05:19:05 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1662, average loss: 1.4535
[09/26 05:19:05 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.50	top5: 88.00	
[09/26 05:19:05 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.07033683215379002
[09/26 05:19:12 visual_prompt]: Epoch 44 / 100: avg data time: 4.64e-02, avg batch time: 0.4886, average train loss: 0.0364
[09/26 05:19:13 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1662, average loss: 1.4334
[09/26 05:19:13 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 60.00	top5: 89.50	
[09/26 05:19:13 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.0687303296707956
[09/26 05:19:20 visual_prompt]: Epoch 45 / 100: avg data time: 5.41e-02, avg batch time: 0.4964, average train loss: 0.0363
[09/26 05:19:21 visual_prompt]: Inference (val):avg data time: 1.87e-05, avg batch time: 0.1663, average loss: 1.4421
[09/26 05:19:21 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.50	top5: 90.00	
[09/26 05:19:21 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.06710100716628345
[09/26 05:19:28 visual_prompt]: Epoch 46 / 100: avg data time: 5.54e-02, avg batch time: 0.4982, average train loss: 0.0354
[09/26 05:19:30 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1665, average loss: 1.4433
[09/26 05:19:30 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 89.00	
[09/26 05:19:30 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.06545084971874737
[09/26 05:19:36 visual_prompt]: Epoch 47 / 100: avg data time: 5.64e-02, avg batch time: 0.4992, average train loss: 0.0354
[09/26 05:19:38 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1663, average loss: 1.4388
[09/26 05:19:38 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.50	top5: 89.00	
[09/26 05:19:38 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.06378186779084996
[09/26 05:19:45 visual_prompt]: Epoch 48 / 100: avg data time: 5.50e-02, avg batch time: 0.4973, average train loss: 0.0350
[09/26 05:19:46 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1662, average loss: 1.4569
[09/26 05:19:46 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 88.50	
[09/26 05:19:46 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.06209609477998338
[09/26 05:19:53 visual_prompt]: Epoch 49 / 100: avg data time: 5.62e-02, avg batch time: 0.4977, average train loss: 0.0351
[09/26 05:19:54 visual_prompt]: Inference (val):avg data time: 2.05e-05, avg batch time: 0.1665, average loss: 1.4330
[09/26 05:19:54 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 90.00	
[09/26 05:19:54 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.06039558454088796
[09/26 05:20:01 visual_prompt]: Epoch 50 / 100: avg data time: 5.89e-02, avg batch time: 0.5021, average train loss: 0.0348
[09/26 05:20:03 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1701, average loss: 1.4349
[09/26 05:20:03 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 90.00	
[09/26 05:20:03 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.058682408883346526
[09/26 05:20:10 visual_prompt]: Epoch 51 / 100: avg data time: 6.00e-02, avg batch time: 0.5022, average train loss: 0.0348
[09/26 05:20:11 visual_prompt]: Inference (val):avg data time: 2.00e-05, avg batch time: 0.1664, average loss: 1.4499
[09/26 05:20:11 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 89.50	
[09/26 05:20:11 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.05695865504800327
[09/26 05:20:18 visual_prompt]: Epoch 52 / 100: avg data time: 4.90e-02, avg batch time: 0.4928, average train loss: 0.0335
[09/26 05:20:19 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1664, average loss: 1.4249
[09/26 05:20:19 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.00	top5: 91.00	
[09/26 05:20:19 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.05522642316338268
[09/26 05:20:26 visual_prompt]: Epoch 53 / 100: avg data time: 4.99e-02, avg batch time: 0.4921, average train loss: 0.0338
[09/26 05:20:28 visual_prompt]: Inference (val):avg data time: 2.00e-05, avg batch time: 0.1661, average loss: 1.4290
[09/26 05:20:28 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 90.50	
[09/26 05:20:28 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.05348782368720626
[09/26 05:20:34 visual_prompt]: Epoch 54 / 100: avg data time: 5.70e-02, avg batch time: 0.5016, average train loss: 0.0339
[09/26 05:20:36 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1662, average loss: 1.4211
[09/26 05:20:36 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.00	top5: 90.50	
[09/26 05:20:36 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.05174497483512506
[09/26 05:20:43 visual_prompt]: Epoch 55 / 100: avg data time: 5.15e-02, avg batch time: 0.4931, average train loss: 0.0344
[09/26 05:20:44 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1664, average loss: 1.4313
[09/26 05:20:44 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 90.00	
[09/26 05:20:44 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.05
[09/26 05:20:51 visual_prompt]: Epoch 56 / 100: avg data time: 4.63e-02, avg batch time: 0.4894, average train loss: 0.0335
[09/26 05:20:52 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1664, average loss: 1.4372
[09/26 05:20:52 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.00	top5: 89.00	
[09/26 05:20:52 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.04825502516487497
[09/26 05:20:59 visual_prompt]: Epoch 57 / 100: avg data time: 6.25e-02, avg batch time: 0.5050, average train loss: 0.0344
[09/26 05:21:01 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1664, average loss: 1.4518
[09/26 05:21:01 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 88.50	
[09/26 05:21:01 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.04651217631279374
[09/26 05:21:07 visual_prompt]: Epoch 58 / 100: avg data time: 5.07e-02, avg batch time: 0.4937, average train loss: 0.0337
[09/26 05:21:09 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1664, average loss: 1.4342
[09/26 05:21:09 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 90.00	
[09/26 05:21:09 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.04477357683661734
[09/26 05:21:16 visual_prompt]: Epoch 59 / 100: avg data time: 6.21e-02, avg batch time: 0.5041, average train loss: 0.0341
[09/26 05:21:17 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1664, average loss: 1.4467
[09/26 05:21:17 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 88.50	
[09/26 05:21:17 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.04304134495199674
[09/26 05:21:24 visual_prompt]: Epoch 60 / 100: avg data time: 5.83e-02, avg batch time: 0.5000, average train loss: 0.0339
[09/26 05:21:26 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1665, average loss: 1.4471
[09/26 05:21:26 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 89.50	
[09/26 05:21:26 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.041317591116653486
[09/26 05:21:32 visual_prompt]: Epoch 61 / 100: avg data time: 6.03e-02, avg batch time: 0.5018, average train loss: 0.0338
[09/26 05:21:34 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1666, average loss: 1.4365
[09/26 05:21:34 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.00	top5: 88.50	
[09/26 05:21:34 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.039604415459112044
[09/26 05:21:41 visual_prompt]: Epoch 62 / 100: avg data time: 5.93e-02, avg batch time: 0.5029, average train loss: 0.0334
[09/26 05:21:42 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1665, average loss: 1.4366
[09/26 05:21:42 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.50	top5: 89.50	
[09/26 05:21:42 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.037903905220016625
[09/26 05:21:49 visual_prompt]: Epoch 63 / 100: avg data time: 5.49e-02, avg batch time: 0.4973, average train loss: 0.0332
[09/26 05:21:50 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1662, average loss: 1.4177
[09/26 05:21:50 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.50	top5: 89.50	
[09/26 05:21:50 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.036218132209150045
[09/26 05:21:57 visual_prompt]: Epoch 64 / 100: avg data time: 4.77e-02, avg batch time: 0.4909, average train loss: 0.0334
[09/26 05:21:59 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1665, average loss: 1.4132
[09/26 05:21:59 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.50	top5: 88.50	
[09/26 05:21:59 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.03454915028125263
[09/26 05:22:05 visual_prompt]: Epoch 65 / 100: avg data time: 5.94e-02, avg batch time: 0.5025, average train loss: 0.0330
[09/26 05:22:07 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1663, average loss: 1.4454
[09/26 05:22:07 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 88.50	
[09/26 05:22:07 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.03289899283371657
[09/26 05:22:14 visual_prompt]: Epoch 66 / 100: avg data time: 5.94e-02, avg batch time: 0.5017, average train loss: 0.0329
[09/26 05:22:15 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1665, average loss: 1.4336
[09/26 05:22:15 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.00	top5: 88.50	
[09/26 05:22:15 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.0312696703292044
[09/26 05:22:22 visual_prompt]: Epoch 67 / 100: avg data time: 5.28e-02, avg batch time: 0.4958, average train loss: 0.0327
[09/26 05:22:24 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1664, average loss: 1.4465
[09/26 05:22:24 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 88.50	
[09/26 05:22:24 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.02966316784621
[09/26 05:22:30 visual_prompt]: Epoch 68 / 100: avg data time: 4.35e-02, avg batch time: 0.4869, average train loss: 0.0326
[09/26 05:22:32 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1666, average loss: 1.4436
[09/26 05:22:32 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 89.50	
[09/26 05:22:32 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.028081442660546126
[09/26 05:22:39 visual_prompt]: Epoch 69 / 100: avg data time: 5.43e-02, avg batch time: 0.4968, average train loss: 0.0324
[09/26 05:22:40 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1665, average loss: 1.4246
[09/26 05:22:40 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.50	top5: 89.00	
[09/26 05:22:40 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.026526421860705474
[09/26 05:22:47 visual_prompt]: Epoch 70 / 100: avg data time: 4.69e-02, avg batch time: 0.4924, average train loss: 0.0324
[09/26 05:22:48 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1666, average loss: 1.4314
[09/26 05:22:48 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.50	top5: 89.00	
[09/26 05:22:48 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.025000000000000012
[09/26 05:22:55 visual_prompt]: Epoch 71 / 100: avg data time: 5.77e-02, avg batch time: 0.4998, average train loss: 0.0324
[09/26 05:22:57 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1664, average loss: 1.4183
[09/26 05:22:57 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 89.50	
[09/26 05:22:57 visual_prompt]: Best epoch 71: best metric: 0.650
[09/26 05:22:57 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.02350403678833976
[09/26 05:23:03 visual_prompt]: Epoch 72 / 100: avg data time: 5.83e-02, avg batch time: 0.5026, average train loss: 0.0325
[09/26 05:23:05 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1665, average loss: 1.4060
[09/26 05:23:05 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.00	top5: 89.50	
[09/26 05:23:05 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.022040354826462667
[09/26 05:23:12 visual_prompt]: Epoch 73 / 100: avg data time: 5.53e-02, avg batch time: 0.4973, average train loss: 0.0324
[09/26 05:23:13 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1666, average loss: 1.4131
[09/26 05:23:13 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.50	top5: 88.50	
[09/26 05:23:13 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.02061073738537635
[09/26 05:23:20 visual_prompt]: Epoch 74 / 100: avg data time: 5.66e-02, avg batch time: 0.4983, average train loss: 0.0325
[09/26 05:23:22 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1669, average loss: 1.4265
[09/26 05:23:22 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.00	top5: 89.50	
[09/26 05:23:22 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.019216926233717086
[09/26 05:23:28 visual_prompt]: Epoch 75 / 100: avg data time: 4.62e-02, avg batch time: 0.4890, average train loss: 0.0325
[09/26 05:23:30 visual_prompt]: Inference (val):avg data time: 3.95e-05, avg batch time: 0.1667, average loss: 1.4316
[09/26 05:23:30 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 64.50	top5: 89.00	
[09/26 05:23:30 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.017860619515673033
[09/26 05:23:36 visual_prompt]: Epoch 76 / 100: avg data time: 5.33e-02, avg batch time: 0.4966, average train loss: 0.0323
[09/26 05:23:38 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.1665, average loss: 1.4271
[09/26 05:23:38 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 64.50	top5: 89.50	
[09/26 05:23:38 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.016543469682057107
[09/26 05:23:45 visual_prompt]: Epoch 77 / 100: avg data time: 6.16e-02, avg batch time: 0.5045, average train loss: 0.0325
[09/26 05:23:46 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1666, average loss: 1.4277
[09/26 05:23:46 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 64.00	top5: 89.50	
[09/26 05:23:46 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.015267081477050132
[09/26 05:23:53 visual_prompt]: Epoch 78 / 100: avg data time: 4.95e-02, avg batch time: 0.4939, average train loss: 0.0323
[09/26 05:23:55 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1668, average loss: 1.4152
[09/26 05:23:55 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.50	top5: 89.50	
[09/26 05:23:55 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.014033009983067453
[09/26 05:24:01 visual_prompt]: Epoch 79 / 100: avg data time: 4.70e-02, avg batch time: 0.4906, average train loss: 0.0323
[09/26 05:24:03 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1666, average loss: 1.4133
[09/26 05:24:03 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 64.00	top5: 89.50	
[09/26 05:24:03 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.012842758726130284
[09/26 05:24:09 visual_prompt]: Epoch 80 / 100: avg data time: 4.36e-02, avg batch time: 0.4859, average train loss: 0.0319
[09/26 05:24:11 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1667, average loss: 1.4151
[09/26 05:24:11 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 64.50	top5: 89.50	
[09/26 05:24:11 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.011697777844051106
[09/26 05:24:18 visual_prompt]: Epoch 81 / 100: avg data time: 5.67e-02, avg batch time: 0.5000, average train loss: 0.0319
[09/26 05:24:19 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1666, average loss: 1.4180
[09/26 05:24:19 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 89.50	
[09/26 05:24:19 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.010599462319663905
[09/26 05:24:26 visual_prompt]: Epoch 82 / 100: avg data time: 5.30e-02, avg batch time: 0.4950, average train loss: 0.0322
[09/26 05:24:27 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1666, average loss: 1.4171
[09/26 05:24:27 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 64.00	top5: 90.00	
[09/26 05:24:27 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.009549150281252633
[09/26 05:24:34 visual_prompt]: Epoch 83 / 100: avg data time: 5.73e-02, avg batch time: 0.4994, average train loss: 0.0318
[09/26 05:24:36 visual_prompt]: Inference (val):avg data time: 2.11e-05, avg batch time: 0.1667, average loss: 1.4156
[09/26 05:24:36 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 64.00	top5: 89.00	
[09/26 05:24:36 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.008548121372247919
[09/26 05:24:43 visual_prompt]: Epoch 84 / 100: avg data time: 5.50e-02, avg batch time: 0.4979, average train loss: 0.0318
[09/26 05:24:44 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1665, average loss: 1.4162
[09/26 05:24:44 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 64.50	top5: 89.50	
[09/26 05:24:44 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.007597595192178702
[09/26 05:24:51 visual_prompt]: Epoch 85 / 100: avg data time: 4.97e-02, avg batch time: 0.4927, average train loss: 0.0315
[09/26 05:24:52 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1664, average loss: 1.4153
[09/26 05:24:52 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 64.50	top5: 89.50	
[09/26 05:24:52 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.006698729810778065
[09/26 05:24:59 visual_prompt]: Epoch 86 / 100: avg data time: 5.61e-02, avg batch time: 0.4984, average train loss: 0.0320
[09/26 05:25:00 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1664, average loss: 1.4166
[09/26 05:25:00 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 90.00	
[09/26 05:25:00 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.005852620357053651
[09/26 05:25:07 visual_prompt]: Epoch 87 / 100: avg data time: 5.41e-02, avg batch time: 0.4980, average train loss: 0.0318
[09/26 05:25:09 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1663, average loss: 1.4227
[09/26 05:25:09 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.50	top5: 90.00	
[09/26 05:25:09 visual_prompt]: Best epoch 87: best metric: 0.655
[09/26 05:25:09 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.00506029768504166
[09/26 05:25:15 visual_prompt]: Epoch 88 / 100: avg data time: 5.41e-02, avg batch time: 0.4960, average train loss: 0.0316
[09/26 05:25:17 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.1665, average loss: 1.4282
[09/26 05:25:17 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 90.00	
[09/26 05:25:17 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.004322727117869951
[09/26 05:25:24 visual_prompt]: Epoch 89 / 100: avg data time: 5.84e-02, avg batch time: 0.5007, average train loss: 0.0315
[09/26 05:25:25 visual_prompt]: Inference (val):avg data time: 1.81e-05, avg batch time: 0.1665, average loss: 1.4296
[09/26 05:25:25 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 90.00	
[09/26 05:25:25 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.0036408072716606343
[09/26 05:25:32 visual_prompt]: Epoch 90 / 100: avg data time: 6.20e-02, avg batch time: 0.5044, average train loss: 0.0317
[09/26 05:25:34 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1664, average loss: 1.4286
[09/26 05:25:34 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 90.00	
[09/26 05:25:34 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.0030153689607045845
[09/26 05:25:40 visual_prompt]: Epoch 91 / 100: avg data time: 5.55e-02, avg batch time: 0.4980, average train loss: 0.0321
[09/26 05:25:42 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1664, average loss: 1.4267
[09/26 05:25:42 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 90.00	
[09/26 05:25:42 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.0024471741852423235
[09/26 05:25:49 visual_prompt]: Epoch 92 / 100: avg data time: 5.28e-02, avg batch time: 0.4948, average train loss: 0.0317
[09/26 05:25:50 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1666, average loss: 1.4242
[09/26 05:25:50 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 90.00	
[09/26 05:25:50 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.0019369152030840554
[09/26 05:25:57 visual_prompt]: Epoch 93 / 100: avg data time: 4.37e-02, avg batch time: 0.4858, average train loss: 0.0315
[09/26 05:25:58 visual_prompt]: Inference (val):avg data time: 1.91e-05, avg batch time: 0.1667, average loss: 1.4236
[09/26 05:25:58 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 90.00	
[09/26 05:25:58 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.0014852136862001765
[09/26 05:26:05 visual_prompt]: Epoch 94 / 100: avg data time: 5.77e-02, avg batch time: 0.5009, average train loss: 0.0314
[09/26 05:26:06 visual_prompt]: Inference (val):avg data time: 2.11e-05, avg batch time: 0.1664, average loss: 1.4232
[09/26 05:26:06 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 90.00	
[09/26 05:26:06 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.0010926199633097156
[09/26 05:26:13 visual_prompt]: Epoch 95 / 100: avg data time: 4.28e-02, avg batch time: 0.4849, average train loss: 0.0312
[09/26 05:26:15 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1664, average loss: 1.4229
[09/26 05:26:15 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 90.00	
[09/26 05:26:15 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.0007596123493895991
[09/26 05:26:21 visual_prompt]: Epoch 96 / 100: avg data time: 5.97e-02, avg batch time: 0.5032, average train loss: 0.0323
[09/26 05:26:23 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1665, average loss: 1.4228
[09/26 05:26:23 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 90.00	
[09/26 05:26:23 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.00048659656292148194
[09/26 05:26:30 visual_prompt]: Epoch 97 / 100: avg data time: 5.97e-02, avg batch time: 0.5019, average train loss: 0.0319
[09/26 05:26:31 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1663, average loss: 1.4227
[09/26 05:26:31 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 90.00	
[09/26 05:26:31 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.0002739052315863355
[09/26 05:26:38 visual_prompt]: Epoch 98 / 100: avg data time: 5.95e-02, avg batch time: 0.5017, average train loss: 0.0311
[09/26 05:26:40 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1665, average loss: 1.4227
[09/26 05:26:40 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 90.00	
[09/26 05:26:40 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.00012179748700879012
[09/26 05:26:46 visual_prompt]: Epoch 99 / 100: avg data time: 5.46e-02, avg batch time: 0.4968, average train loss: 0.0318
[09/26 05:26:48 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1666, average loss: 1.4227
[09/26 05:26:48 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 90.00	
[09/26 05:26:48 visual_prompt]: Training 100 / 100 epoch, with learning rate 3.0458649045211895e-05
[09/26 05:26:55 visual_prompt]: Epoch 100 / 100: avg data time: 5.64e-02, avg batch time: 0.4997, average train loss: 0.0317
[09/26 05:26:56 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1665, average loss: 1.4227
[09/26 05:26:56 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 90.00	
[09/26 05:26:56 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 05:26:56 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 05:26:56 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-cifar(num_classes=100)', 'DATA.NUMBER_CLASSES', '100', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 05:26:56 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 05:26:56 visual_prompt]: Training with config:
[09/26 05:26:56 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-cifar(num_classes=100)/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.1_wd0.0001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 0.1, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-cifar(num_classes=100)', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 100, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 05:26:56 visual_prompt]: Loading training data...
[09/26 05:26:56 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[:800], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/26 05:26:57 visual_prompt]: Number of images: 800
[09/26 05:26:57 visual_prompt]: Number of classes: 100 / 100
[09/26 05:26:57 visual_prompt]: Loading validation data...
[09/26 05:26:57 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[45000:45200], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/26 05:26:57 visual_prompt]: Number of images: 200
[09/26 05:26:57 visual_prompt]: Number of classes: 90 / 100
[09/26 05:26:57 visual_prompt]: Constructing models...
[09/26 05:27:00 visual_prompt]: Total Parameters: 86336356	 Gradient Parameters: 537700
[09/26 05:27:00 visual_prompt]: tuned percent:0.623
[09/26 05:27:00 visual_prompt]: Device used for model: 0
[09/26 05:27:00 visual_prompt]: Setting up Evaluator...
[09/26 05:27:00 visual_prompt]: Setting up Trainer...
[09/26 05:27:00 visual_prompt]: 	Setting up the optimizer...
[09/26 05:27:00 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 05:27:07 visual_prompt]: Epoch 1 / 100: avg data time: 5.15e-02, avg batch time: 0.4939, average train loss: 4.6533
[09/26 05:27:08 visual_prompt]: Inference (val):avg data time: 3.65e-05, avg batch time: 0.1660, average loss: 4.6218
[09/26 05:27:08 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 7.00	
[09/26 05:27:08 visual_prompt]: Best epoch 1: best metric: 0.010
[09/26 05:27:08 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.010000000000000002
[09/26 05:27:15 visual_prompt]: Epoch 2 / 100: avg data time: 4.47e-02, avg batch time: 0.4873, average train loss: 4.6371
[09/26 05:27:16 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1661, average loss: 4.6106
[09/26 05:27:16 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 6.50	
[09/26 05:27:16 visual_prompt]: Best epoch 2: best metric: 0.015
[09/26 05:27:16 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.020000000000000004
[09/26 05:27:23 visual_prompt]: Epoch 3 / 100: avg data time: 5.93e-02, avg batch time: 0.5003, average train loss: 4.5988
[09/26 05:27:25 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1660, average loss: 4.6008
[09/26 05:27:25 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 6.50	
[09/26 05:27:25 visual_prompt]: Best epoch 3: best metric: 0.020
[09/26 05:27:25 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.03
[09/26 05:27:31 visual_prompt]: Epoch 4 / 100: avg data time: 5.37e-02, avg batch time: 0.4971, average train loss: 4.5527
[09/26 05:27:33 visual_prompt]: Inference (val):avg data time: 1.97e-05, avg batch time: 0.1662, average loss: 4.5938
[09/26 05:27:33 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 8.50	
[09/26 05:27:33 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.04000000000000001
[09/26 05:27:39 visual_prompt]: Epoch 5 / 100: avg data time: 5.16e-02, avg batch time: 0.4943, average train loss: 4.4977
[09/26 05:27:41 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1668, average loss: 4.5325
[09/26 05:27:41 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 11.50	
[09/26 05:27:41 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.05
[09/26 05:27:48 visual_prompt]: Epoch 6 / 100: avg data time: 5.58e-02, avg batch time: 0.4974, average train loss: 4.3351
[09/26 05:27:49 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1662, average loss: 4.3471
[09/26 05:27:49 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 5.00	top5: 16.00	
[09/26 05:27:49 visual_prompt]: Best epoch 6: best metric: 0.050
[09/26 05:27:49 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.06
[09/26 05:27:56 visual_prompt]: Epoch 7 / 100: avg data time: 5.64e-02, avg batch time: 0.4983, average train loss: 4.0233
[09/26 05:27:57 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1662, average loss: 4.0085
[09/26 05:27:57 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 7.50	top5: 22.00	
[09/26 05:27:57 visual_prompt]: Best epoch 7: best metric: 0.075
[09/26 05:27:57 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.06999999999999999
[09/26 05:28:04 visual_prompt]: Epoch 8 / 100: avg data time: 4.74e-02, avg batch time: 0.4908, average train loss: 3.4983
[09/26 05:28:06 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1662, average loss: 3.5644
[09/26 05:28:06 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 11.00	top5: 44.50	
[09/26 05:28:06 visual_prompt]: Best epoch 8: best metric: 0.110
[09/26 05:28:06 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.08000000000000002
[09/26 05:28:12 visual_prompt]: Epoch 9 / 100: avg data time: 5.42e-02, avg batch time: 0.4968, average train loss: 3.0081
[09/26 05:28:14 visual_prompt]: Inference (val):avg data time: 4.21e-05, avg batch time: 0.1664, average loss: 3.3312
[09/26 05:28:14 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 19.50	top5: 48.00	
[09/26 05:28:14 visual_prompt]: Best epoch 9: best metric: 0.195
[09/26 05:28:14 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.09000000000000001
[09/26 05:28:21 visual_prompt]: Epoch 10 / 100: avg data time: 4.98e-02, avg batch time: 0.4931, average train loss: 2.5071
[09/26 05:28:22 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1664, average loss: 2.9006
[09/26 05:28:22 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 24.50	top5: 59.00	
[09/26 05:28:22 visual_prompt]: Best epoch 10: best metric: 0.245
[09/26 05:28:22 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.1
[09/26 05:28:29 visual_prompt]: Epoch 11 / 100: avg data time: 6.08e-02, avg batch time: 0.5021, average train loss: 1.8926
[09/26 05:28:31 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1665, average loss: 2.4551
[09/26 05:28:31 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 33.50	top5: 70.50	
[09/26 05:28:31 visual_prompt]: Best epoch 11: best metric: 0.335
[09/26 05:28:31 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0999695413509548
[09/26 05:28:37 visual_prompt]: Epoch 12 / 100: avg data time: 4.50e-02, avg batch time: 0.4872, average train loss: 1.3902
[09/26 05:28:39 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1662, average loss: 2.2039
[09/26 05:28:39 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 39.50	top5: 74.00	
[09/26 05:28:39 visual_prompt]: Best epoch 12: best metric: 0.395
[09/26 05:28:39 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.09987820251299122
[09/26 05:28:46 visual_prompt]: Epoch 13 / 100: avg data time: 6.32e-02, avg batch time: 0.5048, average train loss: 0.9781
[09/26 05:28:47 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1663, average loss: 2.0980
[09/26 05:28:47 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 42.50	top5: 73.50	
[09/26 05:28:47 visual_prompt]: Best epoch 13: best metric: 0.425
[09/26 05:28:47 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.09972609476841367
[09/26 05:28:54 visual_prompt]: Epoch 14 / 100: avg data time: 6.09e-02, avg batch time: 0.5026, average train loss: 0.6843
[09/26 05:28:56 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1664, average loss: 1.8337
[09/26 05:28:56 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 46.00	top5: 81.00	
[09/26 05:28:56 visual_prompt]: Best epoch 14: best metric: 0.460
[09/26 05:28:56 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.09951340343707853
[09/26 05:29:02 visual_prompt]: Epoch 15 / 100: avg data time: 6.46e-02, avg batch time: 0.5060, average train loss: 0.4656
[09/26 05:29:04 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1663, average loss: 1.7300
[09/26 05:29:04 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 52.00	top5: 85.00	
[09/26 05:29:04 visual_prompt]: Best epoch 15: best metric: 0.520
[09/26 05:29:04 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.09924038765061041
[09/26 05:29:11 visual_prompt]: Epoch 16 / 100: avg data time: 5.81e-02, avg batch time: 0.5000, average train loss: 0.3148
[09/26 05:29:12 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1663, average loss: 1.7149
[09/26 05:29:12 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 53.50	top5: 86.50	
[09/26 05:29:12 visual_prompt]: Best epoch 16: best metric: 0.535
[09/26 05:29:12 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.09890738003669029
[09/26 05:29:19 visual_prompt]: Epoch 17 / 100: avg data time: 5.91e-02, avg batch time: 0.5014, average train loss: 0.2283
[09/26 05:29:20 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1665, average loss: 1.7183
[09/26 05:29:20 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.00	top5: 87.00	
[09/26 05:29:20 visual_prompt]: Best epoch 17: best metric: 0.540
[09/26 05:29:20 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.09851478631379983
[09/26 05:29:27 visual_prompt]: Epoch 18 / 100: avg data time: 6.44e-02, avg batch time: 0.5073, average train loss: 0.1664
[09/26 05:29:29 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1664, average loss: 1.6295
[09/26 05:29:29 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 56.00	top5: 84.50	
[09/26 05:29:29 visual_prompt]: Best epoch 18: best metric: 0.560
[09/26 05:29:29 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.09806308479691594
[09/26 05:29:36 visual_prompt]: Epoch 19 / 100: avg data time: 5.80e-02, avg batch time: 0.4993, average train loss: 0.1202
[09/26 05:29:37 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1667, average loss: 1.6323
[09/26 05:29:37 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 57.50	top5: 85.50	
[09/26 05:29:37 visual_prompt]: Best epoch 19: best metric: 0.575
[09/26 05:29:37 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.09755282581475769
[09/26 05:29:44 visual_prompt]: Epoch 20 / 100: avg data time: 5.92e-02, avg batch time: 0.5029, average train loss: 0.0871
[09/26 05:29:46 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1665, average loss: 1.6173
[09/26 05:29:46 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 57.50	top5: 87.00	
[09/26 05:29:46 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.09698463103929543
[09/26 05:29:52 visual_prompt]: Epoch 21 / 100: avg data time: 5.49e-02, avg batch time: 0.4963, average train loss: 0.0690
[09/26 05:29:54 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1664, average loss: 1.5992
[09/26 05:29:54 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 57.00	top5: 86.00	
[09/26 05:29:54 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.09635919272833937
[09/26 05:30:00 visual_prompt]: Epoch 22 / 100: avg data time: 5.66e-02, avg batch time: 0.4986, average train loss: 0.0592
[09/26 05:30:02 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1663, average loss: 1.5983
[09/26 05:30:02 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.50	top5: 85.50	
[09/26 05:30:02 visual_prompt]: Best epoch 22: best metric: 0.595
[09/26 05:30:02 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.09567727288213004
[09/26 05:30:09 visual_prompt]: Epoch 23 / 100: avg data time: 6.29e-02, avg batch time: 0.5043, average train loss: 0.0526
[09/26 05:30:10 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1662, average loss: 1.6233
[09/26 05:30:10 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.50	top5: 85.00	
[09/26 05:30:10 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.09493970231495835
[09/26 05:30:17 visual_prompt]: Epoch 24 / 100: avg data time: 5.95e-02, avg batch time: 0.5010, average train loss: 0.0459
[09/26 05:30:19 visual_prompt]: Inference (val):avg data time: 1.94e-05, avg batch time: 0.1664, average loss: 1.6156
[09/26 05:30:19 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 85.00	
[09/26 05:30:19 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.09414737964294635
[09/26 05:30:25 visual_prompt]: Epoch 25 / 100: avg data time: 4.85e-02, avg batch time: 0.4905, average train loss: 0.0409
[09/26 05:30:27 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1663, average loss: 1.6068
[09/26 05:30:27 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 57.00	top5: 86.00	
[09/26 05:30:27 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.09330127018922195
[09/26 05:30:34 visual_prompt]: Epoch 26 / 100: avg data time: 5.60e-02, avg batch time: 0.4976, average train loss: 0.0374
[09/26 05:30:35 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1664, average loss: 1.6288
[09/26 05:30:35 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.00	top5: 85.50	
[09/26 05:30:35 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.0924024048078213
[09/26 05:30:42 visual_prompt]: Epoch 27 / 100: avg data time: 4.38e-02, avg batch time: 0.4867, average train loss: 0.0343
[09/26 05:30:43 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1665, average loss: 1.6176
[09/26 05:30:43 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 86.00	
[09/26 05:30:43 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.09145187862775209
[09/26 05:30:50 visual_prompt]: Epoch 28 / 100: avg data time: 5.73e-02, avg batch time: 0.4999, average train loss: 0.0323
[09/26 05:30:51 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1663, average loss: 1.6376
[09/26 05:30:51 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 87.00	
[09/26 05:30:51 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.09045084971874738
[09/26 05:30:58 visual_prompt]: Epoch 29 / 100: avg data time: 5.08e-02, avg batch time: 0.4937, average train loss: 0.0304
[09/26 05:31:00 visual_prompt]: Inference (val):avg data time: 2.01e-05, avg batch time: 0.1664, average loss: 1.6114
[09/26 05:31:00 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 60.00	top5: 86.50	
[09/26 05:31:00 visual_prompt]: Best epoch 29: best metric: 0.600
[09/26 05:31:00 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.0894005376803361
[09/26 05:31:07 visual_prompt]: Epoch 30 / 100: avg data time: 5.95e-02, avg batch time: 0.5010, average train loss: 0.0275
[09/26 05:31:08 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1663, average loss: 1.6096
[09/26 05:31:08 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.50	top5: 85.50	
[09/26 05:31:08 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.0883022221559489
[09/26 05:31:15 visual_prompt]: Epoch 31 / 100: avg data time: 6.10e-02, avg batch time: 0.5044, average train loss: 0.0260
[09/26 05:31:16 visual_prompt]: Inference (val):avg data time: 2.01e-05, avg batch time: 0.1661, average loss: 1.6061
[09/26 05:31:16 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.50	top5: 86.50	
[09/26 05:31:16 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.08715724127386971
[09/26 05:31:23 visual_prompt]: Epoch 32 / 100: avg data time: 5.11e-02, avg batch time: 0.4929, average train loss: 0.0251
[09/26 05:31:25 visual_prompt]: Inference (val):avg data time: 1.97e-05, avg batch time: 0.1660, average loss: 1.6212
[09/26 05:31:25 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.50	top5: 85.00	
[09/26 05:31:25 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.08596699001693256
[09/26 05:31:31 visual_prompt]: Epoch 33 / 100: avg data time: 5.27e-02, avg batch time: 0.4954, average train loss: 0.0232
[09/26 05:31:33 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1661, average loss: 1.6093
[09/26 05:31:33 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 57.00	top5: 84.50	
[09/26 05:31:33 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.08473291852294987
[09/26 05:31:40 visual_prompt]: Epoch 34 / 100: avg data time: 4.66e-02, avg batch time: 0.4882, average train loss: 0.0230
[09/26 05:31:41 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1661, average loss: 1.6066
[09/26 05:31:41 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 86.00	
[09/26 05:31:41 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.08345653031794292
[09/26 05:31:48 visual_prompt]: Epoch 35 / 100: avg data time: 6.03e-02, avg batch time: 0.5022, average train loss: 0.0214
[09/26 05:31:50 visual_prompt]: Inference (val):avg data time: 1.97e-05, avg batch time: 0.1662, average loss: 1.6152
[09/26 05:31:50 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 57.00	top5: 85.50	
[09/26 05:31:50 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.08213938048432697
[09/26 05:31:56 visual_prompt]: Epoch 36 / 100: avg data time: 5.28e-02, avg batch time: 0.4960, average train loss: 0.0211
[09/26 05:31:58 visual_prompt]: Inference (val):avg data time: 1.96e-05, avg batch time: 0.1660, average loss: 1.6208
[09/26 05:31:58 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 86.00	
[09/26 05:31:58 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.08078307376628291
[09/26 05:32:05 visual_prompt]: Epoch 37 / 100: avg data time: 5.58e-02, avg batch time: 0.4975, average train loss: 0.0206
[09/26 05:32:06 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1662, average loss: 1.6382
[09/26 05:32:06 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 86.00	
[09/26 05:32:06 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.07938926261462366
[09/26 05:32:13 visual_prompt]: Epoch 38 / 100: avg data time: 6.18e-02, avg batch time: 0.5028, average train loss: 0.0194
[09/26 05:32:14 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1660, average loss: 1.6266
[09/26 05:32:14 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 86.00	
[09/26 05:32:14 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.07795964517353735
[09/26 05:32:21 visual_prompt]: Epoch 39 / 100: avg data time: 5.62e-02, avg batch time: 0.4971, average train loss: 0.0193
[09/26 05:32:23 visual_prompt]: Inference (val):avg data time: 2.11e-05, avg batch time: 0.1661, average loss: 1.6211
[09/26 05:32:23 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.50	top5: 86.00	
[09/26 05:32:23 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.07649596321166025
[09/26 05:32:29 visual_prompt]: Epoch 40 / 100: avg data time: 5.67e-02, avg batch time: 0.4977, average train loss: 0.0185
[09/26 05:32:31 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1662, average loss: 1.6177
[09/26 05:32:31 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.00	top5: 86.50	
[09/26 05:32:31 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.07500000000000001
[09/26 05:32:38 visual_prompt]: Epoch 41 / 100: avg data time: 6.18e-02, avg batch time: 0.5027, average train loss: 0.0182
[09/26 05:32:39 visual_prompt]: Inference (val):avg data time: 2.02e-05, avg batch time: 0.1660, average loss: 1.6386
[09/26 05:32:39 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 86.00	
[09/26 05:32:39 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.07347357813929455
[09/26 05:32:46 visual_prompt]: Epoch 42 / 100: avg data time: 5.79e-02, avg batch time: 0.5008, average train loss: 0.0174
[09/26 05:32:47 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1660, average loss: 1.6354
[09/26 05:32:47 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.50	top5: 86.00	
[09/26 05:32:47 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.07191855733945388
[09/26 05:32:54 visual_prompt]: Epoch 43 / 100: avg data time: 4.88e-02, avg batch time: 0.4918, average train loss: 0.0169
[09/26 05:32:56 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1662, average loss: 1.6354
[09/26 05:32:56 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 85.50	
[09/26 05:32:56 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.07033683215379002
[09/26 05:33:02 visual_prompt]: Epoch 44 / 100: avg data time: 5.81e-02, avg batch time: 0.5008, average train loss: 0.0167
[09/26 05:33:04 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1661, average loss: 1.6262
[09/26 05:33:04 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.50	top5: 86.00	
[09/26 05:33:04 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.0687303296707956
[09/26 05:33:11 visual_prompt]: Epoch 45 / 100: avg data time: 5.38e-02, avg batch time: 0.4965, average train loss: 0.0164
[09/26 05:33:12 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1661, average loss: 1.6441
[09/26 05:33:12 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.50	top5: 85.50	
[09/26 05:33:12 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.06710100716628345
[09/26 05:33:19 visual_prompt]: Epoch 46 / 100: avg data time: 6.49e-02, avg batch time: 0.5065, average train loss: 0.0157
[09/26 05:33:21 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1662, average loss: 1.6468
[09/26 05:33:21 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 86.00	
[09/26 05:33:21 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.06545084971874737
[09/26 05:33:27 visual_prompt]: Epoch 47 / 100: avg data time: 6.12e-02, avg batch time: 0.5024, average train loss: 0.0158
[09/26 05:33:29 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1661, average loss: 1.6245
[09/26 05:33:29 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.50	top5: 87.00	
[09/26 05:33:29 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.06378186779084996
[09/26 05:33:36 visual_prompt]: Epoch 48 / 100: avg data time: 6.12e-02, avg batch time: 0.5022, average train loss: 0.0150
[09/26 05:33:37 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1663, average loss: 1.6304
[09/26 05:33:37 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.50	top5: 86.00	
[09/26 05:33:37 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.06209609477998338
[09/26 05:33:44 visual_prompt]: Epoch 49 / 100: avg data time: 5.43e-02, avg batch time: 0.4957, average train loss: 0.0156
[09/26 05:33:45 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1662, average loss: 1.6187
[09/26 05:33:45 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.00	top5: 86.50	
[09/26 05:33:45 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.06039558454088796
[09/26 05:33:52 visual_prompt]: Epoch 50 / 100: avg data time: 5.87e-02, avg batch time: 0.5005, average train loss: 0.0148
[09/26 05:33:54 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1662, average loss: 1.6112
[09/26 05:33:54 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.00	top5: 87.50	
[09/26 05:33:54 visual_prompt]: Best epoch 50: best metric: 0.610
[09/26 05:33:54 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.058682408883346526
[09/26 05:34:01 visual_prompt]: Epoch 51 / 100: avg data time: 5.25e-02, avg batch time: 0.4950, average train loss: 0.0148
[09/26 05:34:02 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1662, average loss: 1.6308
[09/26 05:34:02 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.50	top5: 87.00	
[09/26 05:34:02 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.05695865504800327
[09/26 05:34:09 visual_prompt]: Epoch 52 / 100: avg data time: 4.34e-02, avg batch time: 0.4871, average train loss: 0.0144
[09/26 05:34:10 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1661, average loss: 1.6340
[09/26 05:34:10 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.00	top5: 86.50	
[09/26 05:34:10 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.05522642316338268
[09/26 05:34:17 visual_prompt]: Epoch 53 / 100: avg data time: 5.73e-02, avg batch time: 0.4982, average train loss: 0.0142
[09/26 05:34:18 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.1660, average loss: 1.6245
[09/26 05:34:19 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.50	top5: 88.00	
[09/26 05:34:19 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.05348782368720626
[09/26 05:34:25 visual_prompt]: Epoch 54 / 100: avg data time: 5.06e-02, avg batch time: 0.4915, average train loss: 0.0135
[09/26 05:34:27 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1662, average loss: 1.6182
[09/26 05:34:27 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.50	top5: 86.00	
[09/26 05:34:27 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.05174497483512506
[09/26 05:34:34 visual_prompt]: Epoch 55 / 100: avg data time: 5.91e-02, avg batch time: 0.5007, average train loss: 0.0134
[09/26 05:34:35 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1660, average loss: 1.6234
[09/26 05:34:35 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.00	top5: 84.50	
[09/26 05:34:35 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.05
[09/26 05:34:42 visual_prompt]: Epoch 56 / 100: avg data time: 4.94e-02, avg batch time: 0.4921, average train loss: 0.0133
[09/26 05:34:43 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1662, average loss: 1.6230
[09/26 05:34:43 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.00	top5: 84.50	
[09/26 05:34:43 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.04825502516487497
[09/26 05:34:50 visual_prompt]: Epoch 57 / 100: avg data time: 5.84e-02, avg batch time: 0.4997, average train loss: 0.0131
[09/26 05:34:52 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1662, average loss: 1.6245
[09/26 05:34:52 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.00	top5: 85.50	
[09/26 05:34:52 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.04651217631279374
[09/26 05:34:58 visual_prompt]: Epoch 58 / 100: avg data time: 6.41e-02, avg batch time: 0.5062, average train loss: 0.0128
[09/26 05:35:00 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1662, average loss: 1.6295
[09/26 05:35:00 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.00	top5: 85.50	
[09/26 05:35:00 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.04477357683661734
[09/26 05:35:07 visual_prompt]: Epoch 59 / 100: avg data time: 5.37e-02, avg batch time: 0.4954, average train loss: 0.0129
[09/26 05:35:08 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1663, average loss: 1.6338
[09/26 05:35:08 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 60.00	top5: 85.00	
[09/26 05:35:08 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.04304134495199674
[09/26 05:35:15 visual_prompt]: Epoch 60 / 100: avg data time: 5.58e-02, avg batch time: 0.4968, average train loss: 0.0129
[09/26 05:35:16 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1663, average loss: 1.6393
[09/26 05:35:16 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.50	top5: 86.00	
[09/26 05:35:16 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.041317591116653486
[09/26 05:35:23 visual_prompt]: Epoch 61 / 100: avg data time: 5.41e-02, avg batch time: 0.4970, average train loss: 0.0127
[09/26 05:35:25 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1663, average loss: 1.6394
[09/26 05:35:25 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.50	top5: 87.00	
[09/26 05:35:25 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.039604415459112044
[09/26 05:35:32 visual_prompt]: Epoch 62 / 100: avg data time: 5.47e-02, avg batch time: 0.4976, average train loss: 0.0122
[09/26 05:35:33 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1665, average loss: 1.6346
[09/26 05:35:33 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 60.00	top5: 86.50	
[09/26 05:35:33 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.037903905220016625
[09/26 05:35:40 visual_prompt]: Epoch 63 / 100: avg data time: 6.42e-02, avg batch time: 0.5053, average train loss: 0.0124
[09/26 05:35:42 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1663, average loss: 1.6310
[09/26 05:35:42 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 60.00	top5: 86.00	
[09/26 05:35:42 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.036218132209150045
[09/26 05:35:48 visual_prompt]: Epoch 64 / 100: avg data time: 6.07e-02, avg batch time: 0.5020, average train loss: 0.0123
[09/26 05:35:50 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1663, average loss: 1.6286
[09/26 05:35:50 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 60.00	top5: 86.00	
[09/26 05:35:50 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.03454915028125263
[09/26 05:35:57 visual_prompt]: Epoch 65 / 100: avg data time: 4.55e-02, avg batch time: 0.4898, average train loss: 0.0119
[09/26 05:35:58 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1664, average loss: 1.6349
[09/26 05:35:58 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.50	top5: 86.00	
[09/26 05:35:58 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.03289899283371657
[09/26 05:36:05 visual_prompt]: Epoch 66 / 100: avg data time: 4.54e-02, avg batch time: 0.4884, average train loss: 0.0119
[09/26 05:36:06 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1663, average loss: 1.6350
[09/26 05:36:06 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.50	top5: 85.50	
[09/26 05:36:06 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.0312696703292044
[09/26 05:36:13 visual_prompt]: Epoch 67 / 100: avg data time: 5.86e-02, avg batch time: 0.5002, average train loss: 0.0116
[09/26 05:36:15 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1662, average loss: 1.6328
[09/26 05:36:15 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 60.00	top5: 85.50	
[09/26 05:36:15 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.02966316784621
[09/26 05:36:21 visual_prompt]: Epoch 68 / 100: avg data time: 4.72e-02, avg batch time: 0.4906, average train loss: 0.0116
[09/26 05:36:23 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1664, average loss: 1.6331
[09/26 05:36:23 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 60.50	top5: 85.00	
[09/26 05:36:23 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.028081442660546126
[09/26 05:36:30 visual_prompt]: Epoch 69 / 100: avg data time: 4.53e-02, avg batch time: 0.4877, average train loss: 0.0116
[09/26 05:36:31 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1665, average loss: 1.6305
[09/26 05:36:31 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 60.50	top5: 86.00	
[09/26 05:36:31 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.026526421860705474
[09/26 05:36:38 visual_prompt]: Epoch 70 / 100: avg data time: 5.34e-02, avg batch time: 0.4953, average train loss: 0.0119
[09/26 05:36:39 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1664, average loss: 1.6285
[09/26 05:36:39 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 60.50	top5: 86.00	
[09/26 05:36:39 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.025000000000000012
[09/26 05:36:46 visual_prompt]: Epoch 71 / 100: avg data time: 5.47e-02, avg batch time: 0.4967, average train loss: 0.0112
[09/26 05:36:48 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1663, average loss: 1.6283
[09/26 05:36:48 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.00	top5: 86.50	
[09/26 05:36:48 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.02350403678833976
[09/26 05:36:54 visual_prompt]: Epoch 72 / 100: avg data time: 6.38e-02, avg batch time: 0.5056, average train loss: 0.0119
[09/26 05:36:56 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1663, average loss: 1.6263
[09/26 05:36:56 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 60.50	top5: 86.00	
[09/26 05:36:56 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.022040354826462667
[09/26 05:37:03 visual_prompt]: Epoch 73 / 100: avg data time: 5.30e-02, avg batch time: 0.4953, average train loss: 0.0115
[09/26 05:37:04 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1663, average loss: 1.6276
[09/26 05:37:04 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 60.50	top5: 85.50	
[09/26 05:37:04 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.02061073738537635
[09/26 05:37:11 visual_prompt]: Epoch 74 / 100: avg data time: 4.75e-02, avg batch time: 0.4905, average train loss: 0.0114
[09/26 05:37:12 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1664, average loss: 1.6288
[09/26 05:37:12 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 60.50	top5: 86.00	
[09/26 05:37:12 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.019216926233717086
[09/26 05:37:19 visual_prompt]: Epoch 75 / 100: avg data time: 5.70e-02, avg batch time: 0.4988, average train loss: 0.0113
[09/26 05:37:21 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1662, average loss: 1.6305
[09/26 05:37:21 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 60.50	top5: 86.00	
[09/26 05:37:21 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.017860619515673033
[09/26 05:37:27 visual_prompt]: Epoch 76 / 100: avg data time: 4.77e-02, avg batch time: 0.4914, average train loss: 0.0112
[09/26 05:37:29 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1663, average loss: 1.6305
[09/26 05:37:29 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 60.50	top5: 85.50	
[09/26 05:37:29 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.016543469682057107
[09/26 05:37:36 visual_prompt]: Epoch 77 / 100: avg data time: 4.64e-02, avg batch time: 0.4885, average train loss: 0.0113
[09/26 05:37:37 visual_prompt]: Inference (val):avg data time: 1.90e-05, avg batch time: 0.1665, average loss: 1.6297
[09/26 05:37:37 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 60.00	top5: 86.50	
[09/26 05:37:37 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.015267081477050132
[09/26 05:37:44 visual_prompt]: Epoch 78 / 100: avg data time: 6.05e-02, avg batch time: 0.5022, average train loss: 0.0108
[09/26 05:37:45 visual_prompt]: Inference (val):avg data time: 2.05e-05, avg batch time: 0.1662, average loss: 1.6272
[09/26 05:37:45 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 60.50	top5: 86.00	
[09/26 05:37:45 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.014033009983067453
[09/26 05:37:52 visual_prompt]: Epoch 79 / 100: avg data time: 4.59e-02, avg batch time: 0.4902, average train loss: 0.0112
[09/26 05:37:54 visual_prompt]: Inference (val):avg data time: 2.05e-05, avg batch time: 0.1663, average loss: 1.6248
[09/26 05:37:54 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 60.50	top5: 85.50	
[09/26 05:37:54 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.012842758726130284
[09/26 05:38:01 visual_prompt]: Epoch 80 / 100: avg data time: 6.21e-02, avg batch time: 0.5048, average train loss: 0.0112
[09/26 05:38:02 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1662, average loss: 1.6267
[09/26 05:38:02 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.00	top5: 86.00	
[09/26 05:38:02 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.011697777844051106
[09/26 05:38:09 visual_prompt]: Epoch 81 / 100: avg data time: 5.71e-02, avg batch time: 0.4999, average train loss: 0.0110
[09/26 05:38:10 visual_prompt]: Inference (val):avg data time: 1.92e-05, avg batch time: 0.1662, average loss: 1.6291
[09/26 05:38:10 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 60.00	top5: 86.00	
[09/26 05:38:10 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.010599462319663905
[09/26 05:38:17 visual_prompt]: Epoch 82 / 100: avg data time: 4.48e-02, avg batch time: 0.4878, average train loss: 0.0114
[09/26 05:38:18 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1661, average loss: 1.6298
[09/26 05:38:18 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 60.00	top5: 86.50	
[09/26 05:38:18 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.009549150281252633
[09/26 05:38:25 visual_prompt]: Epoch 83 / 100: avg data time: 5.94e-02, avg batch time: 0.5016, average train loss: 0.0110
[09/26 05:38:27 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.1662, average loss: 1.6292
[09/26 05:38:27 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 60.00	top5: 86.50	
[09/26 05:38:27 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.008548121372247919
[09/26 05:38:34 visual_prompt]: Epoch 84 / 100: avg data time: 6.24e-02, avg batch time: 0.5035, average train loss: 0.0114
[09/26 05:38:35 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1663, average loss: 1.6295
[09/26 05:38:35 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 60.00	top5: 87.00	
[09/26 05:38:35 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.007597595192178702
[09/26 05:38:42 visual_prompt]: Epoch 85 / 100: avg data time: 5.25e-02, avg batch time: 0.4943, average train loss: 0.0109
[09/26 05:38:43 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1661, average loss: 1.6310
[09/26 05:38:43 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 60.00	top5: 87.00	
[09/26 05:38:43 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.006698729810778065
[09/26 05:38:50 visual_prompt]: Epoch 86 / 100: avg data time: 5.42e-02, avg batch time: 0.4969, average train loss: 0.0113
[09/26 05:38:52 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1662, average loss: 1.6316
[09/26 05:38:52 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 60.00	top5: 87.00	
[09/26 05:38:52 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.005852620357053651
[09/26 05:38:58 visual_prompt]: Epoch 87 / 100: avg data time: 5.50e-02, avg batch time: 0.4968, average train loss: 0.0108
[09/26 05:39:00 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1663, average loss: 1.6321
[09/26 05:39:00 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 60.00	top5: 87.00	
[09/26 05:39:00 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.00506029768504166
[09/26 05:39:07 visual_prompt]: Epoch 88 / 100: avg data time: 5.46e-02, avg batch time: 0.4967, average train loss: 0.0108
[09/26 05:39:08 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1661, average loss: 1.6321
[09/26 05:39:08 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 60.00	top5: 87.00	
[09/26 05:39:08 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.004322727117869951
[09/26 05:39:15 visual_prompt]: Epoch 89 / 100: avg data time: 5.51e-02, avg batch time: 0.4978, average train loss: 0.0110
[09/26 05:39:16 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.1659, average loss: 1.6323
[09/26 05:39:16 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 60.00	top5: 87.00	
[09/26 05:39:16 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.0036408072716606343
[09/26 05:39:23 visual_prompt]: Epoch 90 / 100: avg data time: 4.54e-02, avg batch time: 0.4883, average train loss: 0.0110
[09/26 05:39:24 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1662, average loss: 1.6316
[09/26 05:39:24 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 60.00	top5: 87.00	
[09/26 05:39:24 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.0030153689607045845
[09/26 05:39:31 visual_prompt]: Epoch 91 / 100: avg data time: 4.69e-02, avg batch time: 0.4902, average train loss: 0.0110
[09/26 05:39:33 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1662, average loss: 1.6313
[09/26 05:39:33 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 60.50	top5: 87.00	
[09/26 05:39:33 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.0024471741852423235
[09/26 05:39:39 visual_prompt]: Epoch 92 / 100: avg data time: 5.66e-02, avg batch time: 0.4979, average train loss: 0.0107
[09/26 05:39:41 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1661, average loss: 1.6313
[09/26 05:39:41 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 60.50	top5: 87.00	
[09/26 05:39:41 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.0019369152030840554
[09/26 05:39:48 visual_prompt]: Epoch 93 / 100: avg data time: 5.34e-02, avg batch time: 0.4950, average train loss: 0.0109
[09/26 05:39:49 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1662, average loss: 1.6314
[09/26 05:39:49 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 60.50	top5: 87.00	
[09/26 05:39:49 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.0014852136862001765
[09/26 05:39:56 visual_prompt]: Epoch 94 / 100: avg data time: 5.68e-02, avg batch time: 0.4990, average train loss: 0.0110
[09/26 05:39:57 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1662, average loss: 1.6316
[09/26 05:39:57 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 60.50	top5: 87.00	
[09/26 05:39:57 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.0010926199633097156
[09/26 05:40:04 visual_prompt]: Epoch 95 / 100: avg data time: 6.45e-02, avg batch time: 0.5057, average train loss: 0.0112
[09/26 05:40:06 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1661, average loss: 1.6319
[09/26 05:40:06 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 60.50	top5: 87.00	
[09/26 05:40:06 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.0007596123493895991
[09/26 05:40:13 visual_prompt]: Epoch 96 / 100: avg data time: 5.99e-02, avg batch time: 0.5025, average train loss: 0.0108
[09/26 05:40:14 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1662, average loss: 1.6319
[09/26 05:40:14 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 60.50	top5: 87.00	
[09/26 05:40:14 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.00048659656292148194
[09/26 05:40:21 visual_prompt]: Epoch 97 / 100: avg data time: 5.72e-02, avg batch time: 0.4999, average train loss: 0.0107
[09/26 05:40:22 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1665, average loss: 1.6319
[09/26 05:40:22 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 60.50	top5: 87.00	
[09/26 05:40:22 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.0002739052315863355
[09/26 05:40:29 visual_prompt]: Epoch 98 / 100: avg data time: 4.27e-02, avg batch time: 0.4841, average train loss: 0.0107
[09/26 05:40:31 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1664, average loss: 1.6319
[09/26 05:40:31 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 60.50	top5: 87.00	
[09/26 05:40:31 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.00012179748700879012
[09/26 05:40:37 visual_prompt]: Epoch 99 / 100: avg data time: 6.02e-02, avg batch time: 0.5020, average train loss: 0.0108
[09/26 05:40:39 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1663, average loss: 1.6319
[09/26 05:40:39 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 60.50	top5: 87.00	
[09/26 05:40:39 visual_prompt]: Training 100 / 100 epoch, with learning rate 3.0458649045211895e-05
[09/26 05:40:46 visual_prompt]: Epoch 100 / 100: avg data time: 6.16e-02, avg batch time: 0.5028, average train loss: 0.0112
[09/26 05:40:47 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1662, average loss: 1.6319
[09/26 05:40:47 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 60.50	top5: 87.00	
[09/26 05:40:47 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 05:40:47 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 05:40:47 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-cifar(num_classes=100)', 'DATA.NUMBER_CLASSES', '100', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 05:40:47 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 05:40:47 visual_prompt]: Training with config:
[09/26 05:40:47 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-cifar(num_classes=100)/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.1_wd0.0/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 0.1, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-cifar(num_classes=100)', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 100, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 05:40:47 visual_prompt]: Loading training data...
[09/26 05:40:47 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[:800], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/26 05:40:48 visual_prompt]: Number of images: 800
[09/26 05:40:48 visual_prompt]: Number of classes: 100 / 100
[09/26 05:40:48 visual_prompt]: Loading validation data...
[09/26 05:40:48 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[45000:45200], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/26 05:40:49 visual_prompt]: Number of images: 200
[09/26 05:40:49 visual_prompt]: Number of classes: 90 / 100
[09/26 05:40:49 visual_prompt]: Constructing models...
[09/26 05:40:51 visual_prompt]: Total Parameters: 86336356	 Gradient Parameters: 537700
[09/26 05:40:51 visual_prompt]: tuned percent:0.623
[09/26 05:40:51 visual_prompt]: Device used for model: 0
[09/26 05:40:51 visual_prompt]: Setting up Evaluator...
[09/26 05:40:51 visual_prompt]: Setting up Trainer...
[09/26 05:40:51 visual_prompt]: 	Setting up the optimizer...
[09/26 05:40:51 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 05:40:58 visual_prompt]: Epoch 1 / 100: avg data time: 5.02e-02, avg batch time: 0.4952, average train loss: 4.6555
[09/26 05:40:59 visual_prompt]: Inference (val):avg data time: 1.98e-05, avg batch time: 0.1658, average loss: 4.6218
[09/26 05:40:59 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 7.00	
[09/26 05:40:59 visual_prompt]: Best epoch 1: best metric: 0.010
[09/26 05:40:59 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.010000000000000002
[09/26 05:41:06 visual_prompt]: Epoch 2 / 100: avg data time: 5.74e-02, avg batch time: 0.4986, average train loss: 4.6460
[09/26 05:41:07 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1659, average loss: 4.6086
[09/26 05:41:07 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 8.50	
[09/26 05:41:07 visual_prompt]: Best epoch 2: best metric: 0.020
[09/26 05:41:07 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.020000000000000004
[09/26 05:41:14 visual_prompt]: Epoch 3 / 100: avg data time: 4.61e-02, avg batch time: 0.4894, average train loss: 4.5894
[09/26 05:41:16 visual_prompt]: Inference (val):avg data time: 1.90e-05, avg batch time: 0.1661, average loss: 4.5915
[09/26 05:41:16 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 3.00	top5: 6.00	
[09/26 05:41:16 visual_prompt]: Best epoch 3: best metric: 0.030
[09/26 05:41:16 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.03
[09/26 05:41:22 visual_prompt]: Epoch 4 / 100: avg data time: 5.49e-02, avg batch time: 0.4969, average train loss: 4.5467
[09/26 05:41:24 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1661, average loss: 4.6115
[09/26 05:41:24 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.50	
[09/26 05:41:24 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.04000000000000001
[09/26 05:41:31 visual_prompt]: Epoch 5 / 100: avg data time: 5.43e-02, avg batch time: 0.4967, average train loss: 4.4820
[09/26 05:41:32 visual_prompt]: Inference (val):avg data time: 2.02e-05, avg batch time: 0.1662, average loss: 4.5293
[09/26 05:41:32 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.50	top5: 10.00	
[09/26 05:41:32 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.05
[09/26 05:41:39 visual_prompt]: Epoch 6 / 100: avg data time: 5.48e-02, avg batch time: 0.4958, average train loss: 4.3615
[09/26 05:41:40 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1660, average loss: 4.3929
[09/26 05:41:40 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 7.50	top5: 12.50	
[09/26 05:41:40 visual_prompt]: Best epoch 6: best metric: 0.075
[09/26 05:41:40 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.06
[09/26 05:41:47 visual_prompt]: Epoch 7 / 100: avg data time: 5.99e-02, avg batch time: 0.5031, average train loss: 4.0317
[09/26 05:41:49 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1661, average loss: 4.2653
[09/26 05:41:49 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 6.50	top5: 25.00	
[09/26 05:41:49 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.06999999999999999
[09/26 05:41:56 visual_prompt]: Epoch 8 / 100: avg data time: 5.52e-02, avg batch time: 0.4969, average train loss: 3.6146
[09/26 05:41:57 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1662, average loss: 3.6267
[09/26 05:41:57 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 14.00	top5: 37.00	
[09/26 05:41:57 visual_prompt]: Best epoch 8: best metric: 0.140
[09/26 05:41:57 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.08000000000000002
[09/26 05:42:04 visual_prompt]: Epoch 9 / 100: avg data time: 4.82e-02, avg batch time: 0.4923, average train loss: 3.0095
[09/26 05:42:05 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1661, average loss: 3.1927
[09/26 05:42:05 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 21.00	top5: 53.50	
[09/26 05:42:05 visual_prompt]: Best epoch 9: best metric: 0.210
[09/26 05:42:05 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.09000000000000001
[09/26 05:42:12 visual_prompt]: Epoch 10 / 100: avg data time: 5.88e-02, avg batch time: 0.5004, average train loss: 2.4512
[09/26 05:42:14 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1661, average loss: 2.7272
[09/26 05:42:14 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 26.50	top5: 63.50	
[09/26 05:42:14 visual_prompt]: Best epoch 10: best metric: 0.265
[09/26 05:42:14 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.1
[09/26 05:42:20 visual_prompt]: Epoch 11 / 100: avg data time: 4.77e-02, avg batch time: 0.4901, average train loss: 1.8539
[09/26 05:42:22 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1663, average loss: 2.3581
[09/26 05:42:22 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 35.00	top5: 73.50	
[09/26 05:42:22 visual_prompt]: Best epoch 11: best metric: 0.350
[09/26 05:42:22 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0999695413509548
[09/26 05:42:28 visual_prompt]: Epoch 12 / 100: avg data time: 5.58e-02, avg batch time: 0.4973, average train loss: 1.3846
[09/26 05:42:30 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1659, average loss: 2.2683
[09/26 05:42:30 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 36.00	top5: 72.50	
[09/26 05:42:30 visual_prompt]: Best epoch 12: best metric: 0.360
[09/26 05:42:30 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.09987820251299122
[09/26 05:42:37 visual_prompt]: Epoch 13 / 100: avg data time: 5.88e-02, avg batch time: 0.5007, average train loss: 1.0069
[09/26 05:42:38 visual_prompt]: Inference (val):avg data time: 2.08e-05, avg batch time: 0.1660, average loss: 2.0109
[09/26 05:42:38 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 43.50	top5: 79.50	
[09/26 05:42:38 visual_prompt]: Best epoch 13: best metric: 0.435
[09/26 05:42:38 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.09972609476841367
[09/26 05:42:45 visual_prompt]: Epoch 14 / 100: avg data time: 6.32e-02, avg batch time: 0.5042, average train loss: 0.6913
[09/26 05:42:47 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1661, average loss: 1.9359
[09/26 05:42:47 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 44.00	top5: 84.00	
[09/26 05:42:47 visual_prompt]: Best epoch 14: best metric: 0.440
[09/26 05:42:47 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.09951340343707853
[09/26 05:42:53 visual_prompt]: Epoch 15 / 100: avg data time: 5.91e-02, avg batch time: 0.5012, average train loss: 0.4480
[09/26 05:42:55 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1663, average loss: 1.8111
[09/26 05:42:55 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 48.00	top5: 83.50	
[09/26 05:42:55 visual_prompt]: Best epoch 15: best metric: 0.480
[09/26 05:42:55 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.09924038765061041
[09/26 05:43:02 visual_prompt]: Epoch 16 / 100: avg data time: 5.43e-02, avg batch time: 0.4970, average train loss: 0.2999
[09/26 05:43:03 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1662, average loss: 1.7651
[09/26 05:43:03 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 47.50	top5: 86.00	
[09/26 05:43:03 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.09890738003669029
[09/26 05:43:10 visual_prompt]: Epoch 17 / 100: avg data time: 6.04e-02, avg batch time: 0.5027, average train loss: 0.2024
[09/26 05:43:11 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1661, average loss: 1.7393
[09/26 05:43:11 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 51.00	top5: 87.00	
[09/26 05:43:11 visual_prompt]: Best epoch 17: best metric: 0.510
[09/26 05:43:11 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.09851478631379983
[09/26 05:43:18 visual_prompt]: Epoch 18 / 100: avg data time: 4.67e-02, avg batch time: 0.4883, average train loss: 0.1497
[09/26 05:43:20 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1661, average loss: 1.7134
[09/26 05:43:20 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 48.00	top5: 86.50	
[09/26 05:43:20 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.09806308479691594
[09/26 05:43:26 visual_prompt]: Epoch 19 / 100: avg data time: 5.75e-02, avg batch time: 0.4994, average train loss: 0.1143
[09/26 05:43:28 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1660, average loss: 1.7286
[09/26 05:43:28 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 50.50	top5: 86.50	
[09/26 05:43:28 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.09755282581475769
[09/26 05:43:35 visual_prompt]: Epoch 20 / 100: avg data time: 5.91e-02, avg batch time: 0.5003, average train loss: 0.0862
[09/26 05:43:36 visual_prompt]: Inference (val):avg data time: 2.08e-05, avg batch time: 0.1659, average loss: 1.7292
[09/26 05:43:36 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 49.50	top5: 87.00	
[09/26 05:43:36 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.09698463103929543
[09/26 05:43:43 visual_prompt]: Epoch 21 / 100: avg data time: 4.66e-02, avg batch time: 0.4888, average train loss: 0.0690
[09/26 05:43:44 visual_prompt]: Inference (val):avg data time: 1.92e-05, avg batch time: 0.1663, average loss: 1.7012
[09/26 05:43:44 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 50.50	top5: 87.50	
[09/26 05:43:44 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.09635919272833937
[09/26 05:43:51 visual_prompt]: Epoch 22 / 100: avg data time: 4.48e-02, avg batch time: 0.4874, average train loss: 0.0557
[09/26 05:43:52 visual_prompt]: Inference (val):avg data time: 1.98e-05, avg batch time: 0.1662, average loss: 1.6765
[09/26 05:43:52 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 52.00	top5: 87.50	
[09/26 05:43:52 visual_prompt]: Best epoch 22: best metric: 0.520
[09/26 05:43:52 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.09567727288213004
[09/26 05:43:59 visual_prompt]: Epoch 23 / 100: avg data time: 5.43e-02, avg batch time: 0.4961, average train loss: 0.0490
[09/26 05:44:01 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1662, average loss: 1.6945
[09/26 05:44:01 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 53.50	top5: 86.00	
[09/26 05:44:01 visual_prompt]: Best epoch 23: best metric: 0.535
[09/26 05:44:01 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.09493970231495835
[09/26 05:44:07 visual_prompt]: Epoch 24 / 100: avg data time: 4.33e-02, avg batch time: 0.4864, average train loss: 0.0436
[09/26 05:44:09 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1662, average loss: 1.6832
[09/26 05:44:09 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.00	top5: 88.50	
[09/26 05:44:09 visual_prompt]: Best epoch 24: best metric: 0.540
[09/26 05:44:09 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.09414737964294635
[09/26 05:44:16 visual_prompt]: Epoch 25 / 100: avg data time: 6.39e-02, avg batch time: 0.5055, average train loss: 0.0392
[09/26 05:44:17 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1661, average loss: 1.7041
[09/26 05:44:17 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 51.50	top5: 87.50	
[09/26 05:44:17 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.09330127018922195
[09/26 05:44:24 visual_prompt]: Epoch 26 / 100: avg data time: 5.89e-02, avg batch time: 0.5007, average train loss: 0.0343
[09/26 05:44:25 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1660, average loss: 1.6923
[09/26 05:44:25 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 52.00	top5: 87.00	
[09/26 05:44:25 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.0924024048078213
[09/26 05:44:32 visual_prompt]: Epoch 27 / 100: avg data time: 5.11e-02, avg batch time: 0.4933, average train loss: 0.0320
[09/26 05:44:34 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1661, average loss: 1.6853
[09/26 05:44:34 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 53.50	top5: 89.00	
[09/26 05:44:34 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.09145187862775209
[09/26 05:44:40 visual_prompt]: Epoch 28 / 100: avg data time: 5.93e-02, avg batch time: 0.5001, average train loss: 0.0305
[09/26 05:44:42 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1661, average loss: 1.6697
[09/26 05:44:42 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 52.50	top5: 88.50	
[09/26 05:44:42 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.09045084971874738
[09/26 05:44:49 visual_prompt]: Epoch 29 / 100: avg data time: 5.54e-02, avg batch time: 0.4970, average train loss: 0.0281
[09/26 05:44:50 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1662, average loss: 1.6716
[09/26 05:44:50 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 53.00	top5: 88.00	
[09/26 05:44:50 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.0894005376803361
[09/26 05:44:57 visual_prompt]: Epoch 30 / 100: avg data time: 6.00e-02, avg batch time: 0.5007, average train loss: 0.0265
[09/26 05:44:59 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1663, average loss: 1.6840
[09/26 05:44:59 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 53.50	top5: 87.50	
[09/26 05:44:59 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.0883022221559489
[09/26 05:45:05 visual_prompt]: Epoch 31 / 100: avg data time: 6.03e-02, avg batch time: 0.5012, average train loss: 0.0249
[09/26 05:45:07 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1659, average loss: 1.6722
[09/26 05:45:07 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.00	top5: 87.00	
[09/26 05:45:07 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.08715724127386971
[09/26 05:45:14 visual_prompt]: Epoch 32 / 100: avg data time: 5.64e-02, avg batch time: 0.4982, average train loss: 0.0232
[09/26 05:45:15 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1661, average loss: 1.6868
[09/26 05:45:15 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.50	top5: 87.00	
[09/26 05:45:15 visual_prompt]: Best epoch 32: best metric: 0.545
[09/26 05:45:15 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.08596699001693256
[09/26 05:45:22 visual_prompt]: Epoch 33 / 100: avg data time: 5.62e-02, avg batch time: 0.4969, average train loss: 0.0224
[09/26 05:45:23 visual_prompt]: Inference (val):avg data time: 4.26e-05, avg batch time: 0.1660, average loss: 1.6980
[09/26 05:45:23 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 53.50	top5: 87.50	
[09/26 05:45:23 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.08473291852294987
[09/26 05:45:30 visual_prompt]: Epoch 34 / 100: avg data time: 4.71e-02, avg batch time: 0.4905, average train loss: 0.0208
[09/26 05:45:32 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1662, average loss: 1.6849
[09/26 05:45:32 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 52.50	top5: 88.50	
[09/26 05:45:32 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.08345653031794292
[09/26 05:45:38 visual_prompt]: Epoch 35 / 100: avg data time: 5.76e-02, avg batch time: 0.4993, average train loss: 0.0201
[09/26 05:45:40 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1664, average loss: 1.6953
[09/26 05:45:40 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 52.50	top5: 87.50	
[09/26 05:45:40 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.08213938048432697
[09/26 05:45:47 visual_prompt]: Epoch 36 / 100: avg data time: 4.73e-02, avg batch time: 0.4898, average train loss: 0.0189
[09/26 05:45:48 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1662, average loss: 1.7102
[09/26 05:45:48 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 51.50	top5: 88.50	
[09/26 05:45:48 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.08078307376628291
[09/26 05:45:55 visual_prompt]: Epoch 37 / 100: avg data time: 4.67e-02, avg batch time: 0.4878, average train loss: 0.0188
[09/26 05:45:56 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1662, average loss: 1.7040
[09/26 05:45:56 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 52.50	top5: 89.00	
[09/26 05:45:56 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.07938926261462366
[09/26 05:46:03 visual_prompt]: Epoch 38 / 100: avg data time: 5.87e-02, avg batch time: 0.4996, average train loss: 0.0178
[09/26 05:46:05 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1664, average loss: 1.6970
[09/26 05:46:05 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 53.00	top5: 87.50	
[09/26 05:46:05 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.07795964517353735
[09/26 05:46:11 visual_prompt]: Epoch 39 / 100: avg data time: 5.43e-02, avg batch time: 0.4948, average train loss: 0.0165
[09/26 05:46:13 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1662, average loss: 1.6965
[09/26 05:46:13 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 53.00	top5: 88.00	
[09/26 05:46:13 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.07649596321166025
[09/26 05:46:20 visual_prompt]: Epoch 40 / 100: avg data time: 5.85e-02, avg batch time: 0.4988, average train loss: 0.0169
[09/26 05:46:21 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1661, average loss: 1.6921
[09/26 05:46:21 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 52.50	top5: 89.00	
[09/26 05:46:21 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.07500000000000001
[09/26 05:46:28 visual_prompt]: Epoch 41 / 100: avg data time: 5.78e-02, avg batch time: 0.4982, average train loss: 0.0162
[09/26 05:46:29 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1661, average loss: 1.6860
[09/26 05:46:29 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 53.00	top5: 88.50	
[09/26 05:46:29 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.07347357813929455
[09/26 05:46:36 visual_prompt]: Epoch 42 / 100: avg data time: 5.99e-02, avg batch time: 0.5010, average train loss: 0.0157
[09/26 05:46:38 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1662, average loss: 1.6953
[09/26 05:46:38 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 52.00	top5: 89.00	
[09/26 05:46:38 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.07191855733945388
[09/26 05:46:44 visual_prompt]: Epoch 43 / 100: avg data time: 5.63e-02, avg batch time: 0.4965, average train loss: 0.0149
[09/26 05:46:46 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1660, average loss: 1.7028
[09/26 05:46:46 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 51.50	top5: 88.50	
[09/26 05:46:46 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.07033683215379002
[09/26 05:46:53 visual_prompt]: Epoch 44 / 100: avg data time: 5.54e-02, avg batch time: 0.4983, average train loss: 0.0147
[09/26 05:46:54 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1659, average loss: 1.7077
[09/26 05:46:54 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 51.50	top5: 88.50	
[09/26 05:46:54 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.0687303296707956
[09/26 05:47:01 visual_prompt]: Epoch 45 / 100: avg data time: 5.09e-02, avg batch time: 0.4930, average train loss: 0.0140
[09/26 05:47:03 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1658, average loss: 1.7021
[09/26 05:47:03 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 51.00	top5: 88.50	
[09/26 05:47:03 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.06710100716628345
[09/26 05:47:09 visual_prompt]: Epoch 46 / 100: avg data time: 5.12e-02, avg batch time: 0.4928, average train loss: 0.0136
[09/26 05:47:11 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1661, average loss: 1.7060
[09/26 05:47:11 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 52.50	top5: 88.00	
[09/26 05:47:11 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.06545084971874737
[09/26 05:47:17 visual_prompt]: Epoch 47 / 100: avg data time: 5.50e-02, avg batch time: 0.4955, average train loss: 0.0131
[09/26 05:47:19 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1659, average loss: 1.7022
[09/26 05:47:19 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 52.50	top5: 88.50	
[09/26 05:47:19 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.06378186779084996
[09/26 05:47:26 visual_prompt]: Epoch 48 / 100: avg data time: 4.91e-02, avg batch time: 0.4896, average train loss: 0.0131
[09/26 05:47:27 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1661, average loss: 1.6968
[09/26 05:47:27 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 53.50	top5: 88.50	
[09/26 05:47:27 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.06209609477998338
[09/26 05:47:34 visual_prompt]: Epoch 49 / 100: avg data time: 5.08e-02, avg batch time: 0.4917, average train loss: 0.0130
[09/26 05:47:35 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1660, average loss: 1.6979
[09/26 05:47:35 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.00	top5: 88.50	
[09/26 05:47:35 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.06039558454088796
[09/26 05:47:42 visual_prompt]: Epoch 50 / 100: avg data time: 5.50e-02, avg batch time: 0.4953, average train loss: 0.0125
[09/26 05:47:44 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1662, average loss: 1.7027
[09/26 05:47:44 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 53.50	top5: 88.50	
[09/26 05:47:44 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.058682408883346526
[09/26 05:47:50 visual_prompt]: Epoch 51 / 100: avg data time: 5.39e-02, avg batch time: 0.4945, average train loss: 0.0122
[09/26 05:47:52 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1658, average loss: 1.7084
[09/26 05:47:52 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.50	top5: 88.00	
[09/26 05:47:52 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.05695865504800327
[09/26 05:47:59 visual_prompt]: Epoch 52 / 100: avg data time: 5.85e-02, avg batch time: 0.4995, average train loss: 0.0122
[09/26 05:48:00 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1659, average loss: 1.7082
[09/26 05:48:00 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 53.50	top5: 87.50	
[09/26 05:48:00 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.05522642316338268
[09/26 05:48:07 visual_prompt]: Epoch 53 / 100: avg data time: 4.49e-02, avg batch time: 0.4873, average train loss: 0.0125
[09/26 05:48:08 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1661, average loss: 1.7124
[09/26 05:48:08 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.00	top5: 87.50	
[09/26 05:48:08 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.05348782368720626
[09/26 05:48:15 visual_prompt]: Epoch 54 / 100: avg data time: 5.82e-02, avg batch time: 0.4990, average train loss: 0.0117
[09/26 05:48:17 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1661, average loss: 1.7080
[09/26 05:48:17 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.00	top5: 88.50	
[09/26 05:48:17 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.05174497483512506
[09/26 05:48:23 visual_prompt]: Epoch 55 / 100: avg data time: 5.71e-02, avg batch time: 0.4987, average train loss: 0.0114
[09/26 05:48:25 visual_prompt]: Inference (val):avg data time: 1.97e-05, avg batch time: 0.1661, average loss: 1.7025
[09/26 05:48:25 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.00	top5: 88.50	
[09/26 05:48:25 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.05
[09/26 05:48:31 visual_prompt]: Epoch 56 / 100: avg data time: 5.15e-02, avg batch time: 0.4931, average train loss: 0.0115
[09/26 05:48:33 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1661, average loss: 1.7064
[09/26 05:48:33 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.00	top5: 88.50	
[09/26 05:48:33 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.04825502516487497
[09/26 05:48:40 visual_prompt]: Epoch 57 / 100: avg data time: 6.12e-02, avg batch time: 0.5017, average train loss: 0.0115
[09/26 05:48:41 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1660, average loss: 1.7058
[09/26 05:48:41 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 53.50	top5: 88.00	
[09/26 05:48:41 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.04651217631279374
[09/26 05:48:48 visual_prompt]: Epoch 58 / 100: avg data time: 6.03e-02, avg batch time: 0.5027, average train loss: 0.0109
[09/26 05:48:50 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1661, average loss: 1.7041
[09/26 05:48:50 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 53.50	top5: 88.50	
[09/26 05:48:50 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.04477357683661734
[09/26 05:48:56 visual_prompt]: Epoch 59 / 100: avg data time: 4.92e-02, avg batch time: 0.4935, average train loss: 0.0108
[09/26 05:48:58 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1661, average loss: 1.7029
[09/26 05:48:58 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 53.50	top5: 88.00	
[09/26 05:48:58 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.04304134495199674
[09/26 05:49:05 visual_prompt]: Epoch 60 / 100: avg data time: 5.53e-02, avg batch time: 0.4967, average train loss: 0.0106
[09/26 05:49:06 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1661, average loss: 1.7039
[09/26 05:49:06 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 53.00	top5: 88.00	
[09/26 05:49:06 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.041317591116653486
[09/26 05:49:13 visual_prompt]: Epoch 61 / 100: avg data time: 5.63e-02, avg batch time: 0.4973, average train loss: 0.0105
[09/26 05:49:14 visual_prompt]: Inference (val):avg data time: 2.08e-05, avg batch time: 0.1662, average loss: 1.7051
[09/26 05:49:14 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 53.00	top5: 87.50	
[09/26 05:49:14 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.039604415459112044
[09/26 05:49:21 visual_prompt]: Epoch 62 / 100: avg data time: 4.97e-02, avg batch time: 0.4930, average train loss: 0.0108
[09/26 05:49:23 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1663, average loss: 1.7091
[09/26 05:49:23 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.50	top5: 88.00	
[09/26 05:49:23 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.037903905220016625
[09/26 05:49:29 visual_prompt]: Epoch 63 / 100: avg data time: 6.10e-02, avg batch time: 0.5030, average train loss: 0.0101
[09/26 05:49:31 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1661, average loss: 1.7134
[09/26 05:49:31 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.00	top5: 87.50	
[09/26 05:49:31 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.036218132209150045
[09/26 05:49:38 visual_prompt]: Epoch 64 / 100: avg data time: 6.10e-02, avg batch time: 0.5021, average train loss: 0.0103
[09/26 05:49:39 visual_prompt]: Inference (val):avg data time: 2.11e-05, avg batch time: 0.1662, average loss: 1.7134
[09/26 05:49:39 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.00	top5: 88.00	
[09/26 05:49:39 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.03454915028125263
[09/26 05:49:46 visual_prompt]: Epoch 65 / 100: avg data time: 5.62e-02, avg batch time: 0.4982, average train loss: 0.0099
[09/26 05:49:47 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1664, average loss: 1.7110
[09/26 05:49:47 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.00	top5: 88.00	
[09/26 05:49:47 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.03289899283371657
[09/26 05:49:54 visual_prompt]: Epoch 66 / 100: avg data time: 4.59e-02, avg batch time: 0.4883, average train loss: 0.0098
[09/26 05:49:56 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1662, average loss: 1.7085
[09/26 05:49:56 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.00	top5: 88.00	
[09/26 05:49:56 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.0312696703292044
[09/26 05:50:02 visual_prompt]: Epoch 67 / 100: avg data time: 5.60e-02, avg batch time: 0.4976, average train loss: 0.0099
[09/26 05:50:04 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1662, average loss: 1.7089
[09/26 05:50:04 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.00	top5: 88.00	
[09/26 05:50:04 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.02966316784621
[09/26 05:50:11 visual_prompt]: Epoch 68 / 100: avg data time: 5.93e-02, avg batch time: 0.5008, average train loss: 0.0099
[09/26 05:50:12 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1661, average loss: 1.7096
[09/26 05:50:12 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 53.50	top5: 88.00	
[09/26 05:50:12 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.028081442660546126
[09/26 05:50:19 visual_prompt]: Epoch 69 / 100: avg data time: 4.45e-02, avg batch time: 0.4866, average train loss: 0.0097
[09/26 05:50:20 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1661, average loss: 1.7078
[09/26 05:50:20 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 53.50	top5: 88.00	
[09/26 05:50:20 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.026526421860705474
[09/26 05:50:27 visual_prompt]: Epoch 70 / 100: avg data time: 5.56e-02, avg batch time: 0.4993, average train loss: 0.0095
[09/26 05:50:29 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1661, average loss: 1.7078
[09/26 05:50:29 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 53.50	top5: 88.00	
[09/26 05:50:29 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.025000000000000012
[09/26 05:50:35 visual_prompt]: Epoch 71 / 100: avg data time: 5.44e-02, avg batch time: 0.4964, average train loss: 0.0096
[09/26 05:50:37 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1663, average loss: 1.7053
[09/26 05:50:37 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 53.50	top5: 88.00	
[09/26 05:50:37 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.02350403678833976
[09/26 05:50:44 visual_prompt]: Epoch 72 / 100: avg data time: 5.34e-02, avg batch time: 0.4947, average train loss: 0.0095
[09/26 05:50:45 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1663, average loss: 1.7041
[09/26 05:50:45 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.00	top5: 88.00	
[09/26 05:50:45 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.022040354826462667
[09/26 05:50:52 visual_prompt]: Epoch 73 / 100: avg data time: 5.84e-02, avg batch time: 0.4999, average train loss: 0.0095
[09/26 05:50:53 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1661, average loss: 1.7035
[09/26 05:50:53 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.00	top5: 88.00	
[09/26 05:50:53 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.02061073738537635
[09/26 05:51:00 visual_prompt]: Epoch 74 / 100: avg data time: 4.80e-02, avg batch time: 0.4901, average train loss: 0.0094
[09/26 05:51:02 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1663, average loss: 1.7035
[09/26 05:51:02 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.00	top5: 87.50	
[09/26 05:51:02 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.019216926233717086
[09/26 05:51:08 visual_prompt]: Epoch 75 / 100: avg data time: 5.67e-02, avg batch time: 0.4977, average train loss: 0.0097
[09/26 05:51:10 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1662, average loss: 1.7029
[09/26 05:51:10 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.00	top5: 87.50	
[09/26 05:51:10 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.017860619515673033
[09/26 05:51:17 visual_prompt]: Epoch 76 / 100: avg data time: 5.20e-02, avg batch time: 0.4943, average train loss: 0.0092
[09/26 05:51:18 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1663, average loss: 1.7052
[09/26 05:51:18 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.00	top5: 87.50	
[09/26 05:51:18 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.016543469682057107
[09/26 05:51:25 visual_prompt]: Epoch 77 / 100: avg data time: 5.90e-02, avg batch time: 0.5001, average train loss: 0.0090
[09/26 05:51:27 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1662, average loss: 1.7053
[09/26 05:51:27 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.00	top5: 88.00	
[09/26 05:51:27 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.015267081477050132
[09/26 05:51:33 visual_prompt]: Epoch 78 / 100: avg data time: 5.64e-02, avg batch time: 0.4983, average train loss: 0.0094
[09/26 05:51:35 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1663, average loss: 1.7066
[09/26 05:51:35 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.00	top5: 88.00	
[09/26 05:51:35 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.014033009983067453
[09/26 05:51:42 visual_prompt]: Epoch 79 / 100: avg data time: 5.31e-02, avg batch time: 0.4951, average train loss: 0.0091
[09/26 05:51:43 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1664, average loss: 1.7062
[09/26 05:51:43 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.00	top5: 88.00	
[09/26 05:51:43 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.012842758726130284
[09/26 05:51:50 visual_prompt]: Epoch 80 / 100: avg data time: 4.55e-02, avg batch time: 0.4891, average train loss: 0.0092
[09/26 05:51:51 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1663, average loss: 1.7068
[09/26 05:51:51 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.00	top5: 88.00	
[09/26 05:51:51 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.011697777844051106
[09/26 05:51:58 visual_prompt]: Epoch 81 / 100: avg data time: 5.35e-02, avg batch time: 0.4950, average train loss: 0.0088
[09/26 05:52:00 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1663, average loss: 1.7067
[09/26 05:52:00 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.00	top5: 87.50	
[09/26 05:52:00 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.010599462319663905
[09/26 05:52:06 visual_prompt]: Epoch 82 / 100: avg data time: 5.10e-02, avg batch time: 0.4940, average train loss: 0.0091
[09/26 05:52:08 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1664, average loss: 1.7066
[09/26 05:52:08 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.00	top5: 88.00	
[09/26 05:52:08 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.009549150281252633
[09/26 05:52:15 visual_prompt]: Epoch 83 / 100: avg data time: 5.58e-02, avg batch time: 0.4968, average train loss: 0.0094
[09/26 05:52:16 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1663, average loss: 1.7063
[09/26 05:52:16 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.00	top5: 87.50	
[09/26 05:52:16 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.008548121372247919
[09/26 05:52:23 visual_prompt]: Epoch 84 / 100: avg data time: 5.14e-02, avg batch time: 0.4942, average train loss: 0.0090
[09/26 05:52:24 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1662, average loss: 1.7069
[09/26 05:52:24 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.00	top5: 87.50	
[09/26 05:52:24 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.007597595192178702
[09/26 05:52:31 visual_prompt]: Epoch 85 / 100: avg data time: 6.07e-02, avg batch time: 0.5025, average train loss: 0.0090
[09/26 05:52:33 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1662, average loss: 1.7083
[09/26 05:52:33 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.00	top5: 87.50	
[09/26 05:52:33 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.006698729810778065
[09/26 05:52:39 visual_prompt]: Epoch 86 / 100: avg data time: 5.80e-02, avg batch time: 0.4992, average train loss: 0.0091
[09/26 05:52:41 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1662, average loss: 1.7090
[09/26 05:52:41 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.00	top5: 87.50	
[09/26 05:52:41 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.005852620357053651
[09/26 05:52:48 visual_prompt]: Epoch 87 / 100: avg data time: 6.37e-02, avg batch time: 0.5055, average train loss: 0.0091
[09/26 05:52:49 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1661, average loss: 1.7097
[09/26 05:52:49 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.00	top5: 87.50	
[09/26 05:52:49 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.00506029768504166
[09/26 05:52:56 visual_prompt]: Epoch 88 / 100: avg data time: 5.22e-02, avg batch time: 0.4946, average train loss: 0.0087
[09/26 05:52:58 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1662, average loss: 1.7104
[09/26 05:52:58 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.00	top5: 87.50	
[09/26 05:52:58 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.004322727117869951
[09/26 05:53:04 visual_prompt]: Epoch 89 / 100: avg data time: 4.39e-02, avg batch time: 0.4874, average train loss: 0.0088
[09/26 05:53:06 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1663, average loss: 1.7105
[09/26 05:53:06 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.00	top5: 87.50	
[09/26 05:53:06 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.0036408072716606343
[09/26 05:53:13 visual_prompt]: Epoch 90 / 100: avg data time: 6.10e-02, avg batch time: 0.5018, average train loss: 0.0091
[09/26 05:53:14 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1662, average loss: 1.7101
[09/26 05:53:14 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.00	top5: 87.50	
[09/26 05:53:14 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.0030153689607045845
[09/26 05:53:21 visual_prompt]: Epoch 91 / 100: avg data time: 5.86e-02, avg batch time: 0.4994, average train loss: 0.0091
[09/26 05:53:22 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1662, average loss: 1.7101
[09/26 05:53:22 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.00	top5: 87.50	
[09/26 05:53:22 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.0024471741852423235
[09/26 05:53:29 visual_prompt]: Epoch 92 / 100: avg data time: 5.26e-02, avg batch time: 0.4947, average train loss: 0.0089
[09/26 05:53:31 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1663, average loss: 1.7103
[09/26 05:53:31 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.00	top5: 87.50	
[09/26 05:53:31 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.0019369152030840554
[09/26 05:53:37 visual_prompt]: Epoch 93 / 100: avg data time: 5.28e-02, avg batch time: 0.4952, average train loss: 0.0094
[09/26 05:53:39 visual_prompt]: Inference (val):avg data time: 1.92e-05, avg batch time: 0.1662, average loss: 1.7103
[09/26 05:53:39 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.00	top5: 87.50	
[09/26 05:53:39 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.0014852136862001765
[09/26 05:53:46 visual_prompt]: Epoch 94 / 100: avg data time: 5.55e-02, avg batch time: 0.4991, average train loss: 0.0090
[09/26 05:53:47 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1663, average loss: 1.7101
[09/26 05:53:47 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.00	top5: 88.00	
[09/26 05:53:47 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.0010926199633097156
[09/26 05:53:54 visual_prompt]: Epoch 95 / 100: avg data time: 5.81e-02, avg batch time: 0.5008, average train loss: 0.0091
[09/26 05:53:55 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1662, average loss: 1.7100
[09/26 05:53:55 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.00	top5: 88.00	
[09/26 05:53:55 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.0007596123493895991
[09/26 05:54:02 visual_prompt]: Epoch 96 / 100: avg data time: 5.60e-02, avg batch time: 0.4973, average train loss: 0.0090
[09/26 05:54:04 visual_prompt]: Inference (val):avg data time: 1.97e-05, avg batch time: 0.1660, average loss: 1.7100
[09/26 05:54:04 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.00	top5: 88.00	
[09/26 05:54:04 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.00048659656292148194
[09/26 05:54:10 visual_prompt]: Epoch 97 / 100: avg data time: 4.44e-02, avg batch time: 0.4876, average train loss: 0.0089
[09/26 05:54:12 visual_prompt]: Inference (val):avg data time: 1.94e-05, avg batch time: 0.1663, average loss: 1.7100
[09/26 05:54:12 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.00	top5: 88.00	
[09/26 05:54:12 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.0002739052315863355
[09/26 05:54:19 visual_prompt]: Epoch 98 / 100: avg data time: 5.57e-02, avg batch time: 0.4969, average train loss: 0.0090
[09/26 05:54:20 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1661, average loss: 1.7100
[09/26 05:54:20 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.00	top5: 88.00	
[09/26 05:54:20 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.00012179748700879012
[09/26 05:54:27 visual_prompt]: Epoch 99 / 100: avg data time: 6.08e-02, avg batch time: 0.5021, average train loss: 0.0089
[09/26 05:54:28 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1662, average loss: 1.7100
[09/26 05:54:28 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.00	top5: 88.00	
[09/26 05:54:28 visual_prompt]: Training 100 / 100 epoch, with learning rate 3.0458649045211895e-05
[09/26 05:54:35 visual_prompt]: Epoch 100 / 100: avg data time: 4.55e-02, avg batch time: 0.4899, average train loss: 0.0089
[09/26 05:54:37 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1661, average loss: 1.7100
[09/26 05:54:37 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.00	top5: 88.00	
[09/26 05:54:37 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 05:54:37 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 05:54:37 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-cifar(num_classes=100)', 'DATA.NUMBER_CLASSES', '100', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 05:54:37 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 05:54:37 visual_prompt]: Training with config:
[09/26 05:54:37 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-cifar(num_classes=100)/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.05_wd0.01/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 0.05, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-cifar(num_classes=100)', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 100, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 05:54:37 visual_prompt]: Loading training data...
[09/26 05:54:37 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[:800], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/26 05:54:38 visual_prompt]: Number of images: 800
[09/26 05:54:38 visual_prompt]: Number of classes: 100 / 100
[09/26 05:54:38 visual_prompt]: Loading validation data...
[09/26 05:54:38 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[45000:45200], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/26 05:54:38 visual_prompt]: Number of images: 200
[09/26 05:54:38 visual_prompt]: Number of classes: 90 / 100
[09/26 05:54:38 visual_prompt]: Constructing models...
[09/26 05:54:40 visual_prompt]: Total Parameters: 86336356	 Gradient Parameters: 537700
[09/26 05:54:40 visual_prompt]: tuned percent:0.623
[09/26 05:54:40 visual_prompt]: Device used for model: 0
[09/26 05:54:40 visual_prompt]: Setting up Evaluator...
[09/26 05:54:40 visual_prompt]: Setting up Trainer...
[09/26 05:54:40 visual_prompt]: 	Setting up the optimizer...
[09/26 05:54:40 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 05:54:47 visual_prompt]: Epoch 1 / 100: avg data time: 5.01e-02, avg batch time: 0.4944, average train loss: 4.6523
[09/26 05:54:49 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1658, average loss: 4.6218
[09/26 05:54:49 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 7.00	
[09/26 05:54:49 visual_prompt]: Best epoch 1: best metric: 0.010
[09/26 05:54:49 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.005000000000000001
[09/26 05:54:55 visual_prompt]: Epoch 2 / 100: avg data time: 5.67e-02, avg batch time: 0.4979, average train loss: 4.6470
[09/26 05:54:57 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1661, average loss: 4.6126
[09/26 05:54:57 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.50	top5: 7.50	
[09/26 05:54:57 visual_prompt]: Best epoch 2: best metric: 0.025
[09/26 05:54:57 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.010000000000000002
[09/26 05:55:04 visual_prompt]: Epoch 3 / 100: avg data time: 6.10e-02, avg batch time: 0.5013, average train loss: 4.6156
[09/26 05:55:05 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1659, average loss: 4.5922
[09/26 05:55:05 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 6.50	
[09/26 05:55:05 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.015
[09/26 05:55:12 visual_prompt]: Epoch 4 / 100: avg data time: 6.27e-02, avg batch time: 0.5038, average train loss: 4.5743
[09/26 05:55:14 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1660, average loss: 4.5821
[09/26 05:55:14 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 7.50	
[09/26 05:55:14 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.020000000000000004
[09/26 05:55:21 visual_prompt]: Epoch 5 / 100: avg data time: 6.05e-02, avg batch time: 0.5021, average train loss: 4.5233
[09/26 05:55:22 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1661, average loss: 4.5950
[09/26 05:55:22 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 7.00	
[09/26 05:55:22 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.025
[09/26 05:55:29 visual_prompt]: Epoch 6 / 100: avg data time: 5.49e-02, avg batch time: 0.4961, average train loss: 4.4613
[09/26 05:55:30 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1660, average loss: 4.5306
[09/26 05:55:30 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.50	top5: 11.50	
[09/26 05:55:30 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.03
[09/26 05:55:37 visual_prompt]: Epoch 7 / 100: avg data time: 5.44e-02, avg batch time: 0.4964, average train loss: 4.3205
[09/26 05:55:39 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1661, average loss: 4.3331
[09/26 05:55:39 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 10.00	top5: 18.50	
[09/26 05:55:39 visual_prompt]: Best epoch 7: best metric: 0.100
[09/26 05:55:39 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.034999999999999996
[09/26 05:55:45 visual_prompt]: Epoch 8 / 100: avg data time: 4.34e-02, avg batch time: 0.4865, average train loss: 4.0303
[09/26 05:55:47 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1661, average loss: 4.0476
[09/26 05:55:47 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 7.50	top5: 23.50	
[09/26 05:55:47 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.04000000000000001
[09/26 05:55:53 visual_prompt]: Epoch 9 / 100: avg data time: 4.55e-02, avg batch time: 0.4885, average train loss: 3.6761
[09/26 05:55:55 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1663, average loss: 3.8043
[09/26 05:55:55 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 10.50	top5: 32.00	
[09/26 05:55:55 visual_prompt]: Best epoch 9: best metric: 0.105
[09/26 05:55:55 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.045000000000000005
[09/26 05:56:02 visual_prompt]: Epoch 10 / 100: avg data time: 6.33e-02, avg batch time: 0.5054, average train loss: 3.3047
[09/26 05:56:03 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1662, average loss: 3.4703
[09/26 05:56:03 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 13.00	top5: 44.00	
[09/26 05:56:03 visual_prompt]: Best epoch 10: best metric: 0.130
[09/26 05:56:03 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.05
[09/26 05:56:10 visual_prompt]: Epoch 11 / 100: avg data time: 5.61e-02, avg batch time: 0.4984, average train loss: 2.8806
[09/26 05:56:12 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1662, average loss: 3.1905
[09/26 05:56:12 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 16.50	top5: 50.50	
[09/26 05:56:12 visual_prompt]: Best epoch 11: best metric: 0.165
[09/26 05:56:12 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0499847706754774
[09/26 05:56:19 visual_prompt]: Epoch 12 / 100: avg data time: 6.18e-02, avg batch time: 0.5028, average train loss: 2.4709
[09/26 05:56:20 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1662, average loss: 2.9153
[09/26 05:56:20 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 24.00	top5: 61.00	
[09/26 05:56:20 visual_prompt]: Best epoch 12: best metric: 0.240
[09/26 05:56:20 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.04993910125649561
[09/26 05:56:27 visual_prompt]: Epoch 13 / 100: avg data time: 5.96e-02, avg batch time: 0.5020, average train loss: 2.1592
[09/26 05:56:28 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1661, average loss: 2.7093
[09/26 05:56:28 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 32.00	top5: 66.00	
[09/26 05:56:28 visual_prompt]: Best epoch 13: best metric: 0.320
[09/26 05:56:28 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.049863047384206834
[09/26 05:56:35 visual_prompt]: Epoch 14 / 100: avg data time: 4.11e-02, avg batch time: 0.4859, average train loss: 1.8242
[09/26 05:56:37 visual_prompt]: Inference (val):avg data time: 4.77e-05, avg batch time: 0.1664, average loss: 2.4594
[09/26 05:56:37 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 38.00	top5: 74.00	
[09/26 05:56:37 visual_prompt]: Best epoch 14: best metric: 0.380
[09/26 05:56:37 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.04975670171853926
[09/26 05:56:43 visual_prompt]: Epoch 15 / 100: avg data time: 4.77e-02, avg batch time: 0.4909, average train loss: 1.5452
[09/26 05:56:45 visual_prompt]: Inference (val):avg data time: 4.49e-05, avg batch time: 0.1663, average loss: 2.3210
[09/26 05:56:45 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 43.50	top5: 76.50	
[09/26 05:56:45 visual_prompt]: Best epoch 15: best metric: 0.435
[09/26 05:56:45 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.049620193825305206
[09/26 05:56:52 visual_prompt]: Epoch 16 / 100: avg data time: 5.17e-02, avg batch time: 0.4945, average train loss: 1.3474
[09/26 05:56:53 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1662, average loss: 2.2722
[09/26 05:56:53 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 42.00	top5: 78.50	
[09/26 05:56:53 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.049453690018345146
[09/26 05:57:00 visual_prompt]: Epoch 17 / 100: avg data time: 4.76e-02, avg batch time: 0.4900, average train loss: 1.1721
[09/26 05:57:01 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1662, average loss: 2.1088
[09/26 05:57:01 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 45.50	top5: 81.00	
[09/26 05:57:01 visual_prompt]: Best epoch 17: best metric: 0.455
[09/26 05:57:01 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.04925739315689991
[09/26 05:57:08 visual_prompt]: Epoch 18 / 100: avg data time: 6.24e-02, avg batch time: 0.5038, average train loss: 0.9958
[09/26 05:57:10 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1664, average loss: 2.0420
[09/26 05:57:10 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 46.50	top5: 84.50	
[09/26 05:57:10 visual_prompt]: Best epoch 18: best metric: 0.465
[09/26 05:57:10 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.04903154239845797
[09/26 05:57:16 visual_prompt]: Epoch 19 / 100: avg data time: 5.37e-02, avg batch time: 0.4957, average train loss: 0.9067
[09/26 05:57:18 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1662, average loss: 2.0281
[09/26 05:57:18 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 50.00	top5: 82.00	
[09/26 05:57:18 visual_prompt]: Best epoch 19: best metric: 0.500
[09/26 05:57:18 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.048776412907378844
[09/26 05:57:25 visual_prompt]: Epoch 20 / 100: avg data time: 5.60e-02, avg batch time: 0.4981, average train loss: 0.8099
[09/26 05:57:26 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1661, average loss: 1.8742
[09/26 05:57:26 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 55.00	top5: 88.50	
[09/26 05:57:26 visual_prompt]: Best epoch 20: best metric: 0.550
[09/26 05:57:26 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.048492315519647715
[09/26 05:57:33 visual_prompt]: Epoch 21 / 100: avg data time: 5.45e-02, avg batch time: 0.4966, average train loss: 0.7111
[09/26 05:57:34 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1663, average loss: 1.8625
[09/26 05:57:34 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 55.00	top5: 86.00	
[09/26 05:57:34 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.048179596364169686
[09/26 05:57:41 visual_prompt]: Epoch 22 / 100: avg data time: 4.66e-02, avg batch time: 0.4900, average train loss: 0.6340
[09/26 05:57:43 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1663, average loss: 1.7841
[09/26 05:57:43 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.50	top5: 89.50	
[09/26 05:57:43 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.04783863644106502
[09/26 05:57:49 visual_prompt]: Epoch 23 / 100: avg data time: 4.98e-02, avg batch time: 0.4918, average train loss: 0.5817
[09/26 05:57:51 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1663, average loss: 1.7841
[09/26 05:57:51 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 56.00	top5: 85.50	
[09/26 05:57:51 visual_prompt]: Best epoch 23: best metric: 0.560
[09/26 05:57:51 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.047469851157479176
[09/26 05:57:58 visual_prompt]: Epoch 24 / 100: avg data time: 6.01e-02, avg batch time: 0.5024, average train loss: 0.5664
[09/26 05:57:59 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1661, average loss: 1.8473
[09/26 05:57:59 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 55.00	top5: 86.50	
[09/26 05:57:59 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.047073689821473176
[09/26 05:58:06 visual_prompt]: Epoch 25 / 100: avg data time: 5.81e-02, avg batch time: 0.4995, average train loss: 0.5591
[09/26 05:58:08 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1662, average loss: 1.8459
[09/26 05:58:08 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 55.50	top5: 86.00	
[09/26 05:58:08 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.046650635094610975
[09/26 05:58:14 visual_prompt]: Epoch 26 / 100: avg data time: 4.75e-02, avg batch time: 0.4902, average train loss: 0.5221
[09/26 05:58:16 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1663, average loss: 1.7512
[09/26 05:58:16 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 88.00	
[09/26 05:58:16 visual_prompt]: Best epoch 26: best metric: 0.580
[09/26 05:58:16 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.04620120240391065
[09/26 05:58:23 visual_prompt]: Epoch 27 / 100: avg data time: 5.79e-02, avg batch time: 0.4999, average train loss: 0.4873
[09/26 05:58:24 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1664, average loss: 1.7616
[09/26 05:58:24 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.00	top5: 89.00	
[09/26 05:58:24 visual_prompt]: Best epoch 27: best metric: 0.590
[09/26 05:58:24 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.04572593931387604
[09/26 05:58:31 visual_prompt]: Epoch 28 / 100: avg data time: 5.64e-02, avg batch time: 0.4977, average train loss: 0.4424
[09/26 05:58:32 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1663, average loss: 1.7016
[09/26 05:58:32 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 89.50	
[09/26 05:58:32 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.04522542485937369
[09/26 05:58:39 visual_prompt]: Epoch 29 / 100: avg data time: 5.37e-02, avg batch time: 0.4963, average train loss: 0.4113
[09/26 05:58:41 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1662, average loss: 1.6847
[09/26 05:58:41 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.50	top5: 88.00	
[09/26 05:58:41 visual_prompt]: Best epoch 29: best metric: 0.595
[09/26 05:58:41 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.04470026884016805
[09/26 05:58:47 visual_prompt]: Epoch 30 / 100: avg data time: 5.12e-02, avg batch time: 0.4942, average train loss: 0.3795
[09/26 05:58:49 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1663, average loss: 1.7036
[09/26 05:58:49 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 60.00	top5: 87.00	
[09/26 05:58:49 visual_prompt]: Best epoch 30: best metric: 0.600
[09/26 05:58:49 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.04415111107797445
[09/26 05:58:56 visual_prompt]: Epoch 31 / 100: avg data time: 5.44e-02, avg batch time: 0.4956, average train loss: 0.3683
[09/26 05:58:57 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.1663, average loss: 1.7405
[09/26 05:58:57 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.50	top5: 87.00	
[09/26 05:58:57 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.04357862063693486
[09/26 05:59:04 visual_prompt]: Epoch 32 / 100: avg data time: 5.83e-02, avg batch time: 0.5007, average train loss: 0.3605
[09/26 05:59:05 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1662, average loss: 1.6355
[09/26 05:59:05 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 89.50	
[09/26 05:59:05 visual_prompt]: Best epoch 32: best metric: 0.620
[09/26 05:59:05 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.04298349500846628
[09/26 05:59:12 visual_prompt]: Epoch 33 / 100: avg data time: 6.01e-02, avg batch time: 0.5026, average train loss: 0.3678
[09/26 05:59:14 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1662, average loss: 1.6620
[09/26 05:59:14 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.50	top5: 87.00	
[09/26 05:59:14 visual_prompt]: Best epoch 33: best metric: 0.635
[09/26 05:59:14 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.042366459261474934
[09/26 05:59:20 visual_prompt]: Epoch 34 / 100: avg data time: 5.12e-02, avg batch time: 0.4958, average train loss: 0.3845
[09/26 05:59:22 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1664, average loss: 1.6776
[09/26 05:59:22 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 90.00	
[09/26 05:59:22 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.04172826515897146
[09/26 05:59:29 visual_prompt]: Epoch 35 / 100: avg data time: 5.92e-02, avg batch time: 0.5010, average train loss: 0.3922
[09/26 05:59:30 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1665, average loss: 1.7375
[09/26 05:59:30 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 60.00	top5: 89.50	
[09/26 05:59:30 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.04106969024216348
[09/26 05:59:37 visual_prompt]: Epoch 36 / 100: avg data time: 5.64e-02, avg batch time: 0.4987, average train loss: 0.3900
[09/26 05:59:39 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1663, average loss: 1.7514
[09/26 05:59:39 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.50	top5: 88.00	
[09/26 05:59:39 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.040391536883141455
[09/26 05:59:45 visual_prompt]: Epoch 37 / 100: avg data time: 4.80e-02, avg batch time: 0.4907, average train loss: 0.4067
[09/26 05:59:47 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1664, average loss: 1.7880
[09/26 05:59:47 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 86.00	
[09/26 05:59:47 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.03969463130731183
[09/26 05:59:54 visual_prompt]: Epoch 38 / 100: avg data time: 5.92e-02, avg batch time: 0.5009, average train loss: 0.4144
[09/26 05:59:55 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1663, average loss: 1.8124
[09/26 05:59:55 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 57.00	top5: 85.50	
[09/26 05:59:55 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.03897982258676867
[09/26 06:00:02 visual_prompt]: Epoch 39 / 100: avg data time: 5.74e-02, avg batch time: 0.5000, average train loss: 0.4598
[09/26 06:00:03 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1664, average loss: 1.7760
[09/26 06:00:03 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.50	top5: 86.50	
[09/26 06:00:03 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.03824798160583012
[09/26 06:00:10 visual_prompt]: Epoch 40 / 100: avg data time: 6.05e-02, avg batch time: 0.5025, average train loss: 0.4857
[09/26 06:00:12 visual_prompt]: Inference (val):avg data time: 2.11e-05, avg batch time: 0.1665, average loss: 1.8615
[09/26 06:00:12 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 56.50	top5: 86.50	
[09/26 06:00:12 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.037500000000000006
[09/26 06:00:19 visual_prompt]: Epoch 41 / 100: avg data time: 5.93e-02, avg batch time: 0.5009, average train loss: 0.4928
[09/26 06:00:20 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1664, average loss: 1.7618
[09/26 06:00:20 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.50	top5: 88.00	
[09/26 06:00:20 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.03673678906964727
[09/26 06:00:27 visual_prompt]: Epoch 42 / 100: avg data time: 5.49e-02, avg batch time: 0.4974, average train loss: 0.4686
[09/26 06:00:28 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1664, average loss: 1.7275
[09/26 06:00:28 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.50	top5: 88.00	
[09/26 06:00:28 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.03595927866972694
[09/26 06:00:35 visual_prompt]: Epoch 43 / 100: avg data time: 5.55e-02, avg batch time: 0.4981, average train loss: 0.4001
[09/26 06:00:37 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1672, average loss: 1.5326
[09/26 06:00:37 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.50	top5: 90.00	
[09/26 06:00:37 visual_prompt]: Best epoch 43: best metric: 0.665
[09/26 06:00:37 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.03516841607689501
[09/26 06:00:44 visual_prompt]: Epoch 44 / 100: avg data time: 6.55e-02, avg batch time: 0.5073, average train loss: 0.3664
[09/26 06:00:45 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1663, average loss: 1.6299
[09/26 06:00:45 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.50	top5: 90.50	
[09/26 06:00:45 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.0343651648353978
[09/26 06:00:52 visual_prompt]: Epoch 45 / 100: avg data time: 5.62e-02, avg batch time: 0.4981, average train loss: 0.3327
[09/26 06:00:53 visual_prompt]: Inference (val):avg data time: 1.96e-05, avg batch time: 0.1663, average loss: 1.5631
[09/26 06:00:53 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 90.00	
[09/26 06:00:53 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.033550503583141725
[09/26 06:01:00 visual_prompt]: Epoch 46 / 100: avg data time: 5.00e-02, avg batch time: 0.4937, average train loss: 0.3210
[09/26 06:01:02 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1663, average loss: 1.4636
[09/26 06:01:02 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 68.50	top5: 90.00	
[09/26 06:01:02 visual_prompt]: Best epoch 46: best metric: 0.685
[09/26 06:01:02 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.032725424859373686
[09/26 06:01:08 visual_prompt]: Epoch 47 / 100: avg data time: 5.46e-02, avg batch time: 0.4975, average train loss: 0.2900
[09/26 06:01:10 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1661, average loss: 1.4964
[09/26 06:01:10 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.00	top5: 88.50	
[09/26 06:01:10 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.03189093389542498
[09/26 06:01:17 visual_prompt]: Epoch 48 / 100: avg data time: 5.39e-02, avg batch time: 0.4959, average train loss: 0.2717
[09/26 06:01:18 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1662, average loss: 1.4621
[09/26 06:01:18 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 68.00	top5: 91.50	
[09/26 06:01:18 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.03104804738999169
[09/26 06:01:25 visual_prompt]: Epoch 49 / 100: avg data time: 5.07e-02, avg batch time: 0.4951, average train loss: 0.2594
[09/26 06:01:26 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.1662, average loss: 1.4417
[09/26 06:01:26 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 68.00	top5: 89.50	
[09/26 06:01:26 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.03019779227044398
[09/26 06:01:33 visual_prompt]: Epoch 50 / 100: avg data time: 4.67e-02, avg batch time: 0.4885, average train loss: 0.2509
[09/26 06:01:35 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1665, average loss: 1.4802
[09/26 06:01:35 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.00	top5: 89.00	
[09/26 06:01:35 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.029341204441673263
[09/26 06:01:41 visual_prompt]: Epoch 51 / 100: avg data time: 5.07e-02, avg batch time: 0.4936, average train loss: 0.2487
[09/26 06:01:43 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1663, average loss: 1.4567
[09/26 06:01:43 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.50	top5: 90.50	
[09/26 06:01:43 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.028479327524001636
[09/26 06:01:50 visual_prompt]: Epoch 52 / 100: avg data time: 5.79e-02, avg batch time: 0.5020, average train loss: 0.2482
[09/26 06:01:51 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1664, average loss: 1.4846
[09/26 06:01:51 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.50	top5: 89.00	
[09/26 06:01:51 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.02761321158169134
[09/26 06:01:58 visual_prompt]: Epoch 53 / 100: avg data time: 6.27e-02, avg batch time: 0.5049, average train loss: 0.2489
[09/26 06:01:59 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1665, average loss: 1.4603
[09/26 06:01:59 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.00	top5: 89.00	
[09/26 06:01:59 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.02674391184360313
[09/26 06:02:06 visual_prompt]: Epoch 54 / 100: avg data time: 5.32e-02, avg batch time: 0.4947, average train loss: 0.2487
[09/26 06:02:08 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1662, average loss: 1.4568
[09/26 06:02:08 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.50	top5: 90.50	
[09/26 06:02:08 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.02587248741756253
[09/26 06:02:15 visual_prompt]: Epoch 55 / 100: avg data time: 6.04e-02, avg batch time: 0.5014, average train loss: 0.2497
[09/26 06:02:16 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1664, average loss: 1.4560
[09/26 06:02:16 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.50	top5: 89.50	
[09/26 06:02:16 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.025
[09/26 06:02:23 visual_prompt]: Epoch 56 / 100: avg data time: 5.58e-02, avg batch time: 0.4974, average train loss: 0.2506
[09/26 06:02:24 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1664, average loss: 1.4732
[09/26 06:02:24 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 67.00	top5: 90.50	
[09/26 06:02:24 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.024127512582437484
[09/26 06:02:31 visual_prompt]: Epoch 57 / 100: avg data time: 5.38e-02, avg batch time: 0.4956, average train loss: 0.2514
[09/26 06:02:33 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1665, average loss: 1.4867
[09/26 06:02:33 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.50	top5: 89.00	
[09/26 06:02:33 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.02325608815639687
[09/26 06:02:39 visual_prompt]: Epoch 58 / 100: avg data time: 5.48e-02, avg batch time: 0.4960, average train loss: 0.2498
[09/26 06:02:41 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1663, average loss: 1.4738
[09/26 06:02:41 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.50	top5: 91.50	
[09/26 06:02:41 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.02238678841830867
[09/26 06:02:48 visual_prompt]: Epoch 59 / 100: avg data time: 4.86e-02, avg batch time: 0.4923, average train loss: 0.2515
[09/26 06:02:49 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1664, average loss: 1.4958
[09/26 06:02:49 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.50	top5: 89.00	
[09/26 06:02:49 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.02152067247599837
[09/26 06:02:56 visual_prompt]: Epoch 60 / 100: avg data time: 5.38e-02, avg batch time: 0.4950, average train loss: 0.2509
[09/26 06:02:57 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1663, average loss: 1.5105
[09/26 06:02:57 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.50	top5: 90.00	
[09/26 06:02:57 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.020658795558326743
[09/26 06:03:04 visual_prompt]: Epoch 61 / 100: avg data time: 5.76e-02, avg batch time: 0.4992, average train loss: 0.2502
[09/26 06:03:06 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1663, average loss: 1.5358
[09/26 06:03:06 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 64.50	top5: 89.00	
[09/26 06:03:06 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.019802207729556022
[09/26 06:03:12 visual_prompt]: Epoch 62 / 100: avg data time: 6.12e-02, avg batch time: 0.5032, average train loss: 0.2476
[09/26 06:03:14 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1664, average loss: 1.5020
[09/26 06:03:14 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.50	top5: 91.50	
[09/26 06:03:14 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.018951952610008312
[09/26 06:03:21 visual_prompt]: Epoch 63 / 100: avg data time: 5.74e-02, avg batch time: 0.4999, average train loss: 0.2494
[09/26 06:03:22 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1662, average loss: 1.5682
[09/26 06:03:22 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.50	top5: 89.00	
[09/26 06:03:22 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.018109066104575022
[09/26 06:03:29 visual_prompt]: Epoch 64 / 100: avg data time: 5.14e-02, avg batch time: 0.4942, average train loss: 0.2499
[09/26 06:03:31 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1663, average loss: 1.5397
[09/26 06:03:31 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 64.00	top5: 90.00	
[09/26 06:03:31 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.017274575140626316
[09/26 06:03:37 visual_prompt]: Epoch 65 / 100: avg data time: 4.40e-02, avg batch time: 0.4875, average train loss: 0.2502
[09/26 06:03:39 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1662, average loss: 1.5529
[09/26 06:03:39 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.00	top5: 89.50	
[09/26 06:03:39 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.016449496416858285
[09/26 06:03:45 visual_prompt]: Epoch 66 / 100: avg data time: 4.61e-02, avg batch time: 0.4887, average train loss: 0.2476
[09/26 06:03:47 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1662, average loss: 1.4855
[09/26 06:03:47 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.00	top5: 90.50	
[09/26 06:03:47 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.0156348351646022
[09/26 06:03:54 visual_prompt]: Epoch 67 / 100: avg data time: 6.38e-02, avg batch time: 0.5057, average train loss: 0.2469
[09/26 06:03:55 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1663, average loss: 1.5219
[09/26 06:03:55 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 64.50	top5: 90.50	
[09/26 06:03:55 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.014831583923105
[09/26 06:04:02 visual_prompt]: Epoch 68 / 100: avg data time: 5.45e-02, avg batch time: 0.4957, average train loss: 0.2471
[09/26 06:04:04 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1660, average loss: 1.5269
[09/26 06:04:04 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.00	top5: 89.00	
[09/26 06:04:04 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.014040721330273063
[09/26 06:04:10 visual_prompt]: Epoch 69 / 100: avg data time: 5.91e-02, avg batch time: 0.5001, average train loss: 0.2462
[09/26 06:04:12 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1663, average loss: 1.5321
[09/26 06:04:12 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.00	top5: 89.50	
[09/26 06:04:12 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.013263210930352737
[09/26 06:04:19 visual_prompt]: Epoch 70 / 100: avg data time: 5.74e-02, avg batch time: 0.4995, average train loss: 0.2448
[09/26 06:04:20 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1665, average loss: 1.5245
[09/26 06:04:20 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 66.00	top5: 88.50	
[09/26 06:04:20 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.012500000000000006
[09/26 06:04:27 visual_prompt]: Epoch 71 / 100: avg data time: 5.99e-02, avg batch time: 0.5017, average train loss: 0.2446
[09/26 06:04:29 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1663, average loss: 1.5320
[09/26 06:04:29 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 64.50	top5: 90.50	
[09/26 06:04:29 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.01175201839416988
[09/26 06:04:35 visual_prompt]: Epoch 72 / 100: avg data time: 5.00e-02, avg batch time: 0.4923, average train loss: 0.2419
[09/26 06:04:37 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1662, average loss: 1.5745
[09/26 06:04:37 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 87.50	
[09/26 06:04:37 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.011020177413231334
[09/26 06:04:44 visual_prompt]: Epoch 73 / 100: avg data time: 5.15e-02, avg batch time: 0.4946, average train loss: 0.2420
[09/26 06:04:45 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1672, average loss: 1.5320
[09/26 06:04:45 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 90.50	
[09/26 06:04:45 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.010305368692688175
[09/26 06:04:52 visual_prompt]: Epoch 74 / 100: avg data time: 6.13e-02, avg batch time: 0.5032, average train loss: 0.2414
[09/26 06:04:53 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1663, average loss: 1.5399
[09/26 06:04:53 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.50	top5: 90.50	
[09/26 06:04:53 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.009608463116858543
[09/26 06:05:00 visual_prompt]: Epoch 75 / 100: avg data time: 5.19e-02, avg batch time: 0.4941, average train loss: 0.2406
[09/26 06:05:02 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1663, average loss: 1.5244
[09/26 06:05:02 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.00	top5: 89.50	
[09/26 06:05:02 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.008930309757836517
[09/26 06:05:08 visual_prompt]: Epoch 76 / 100: avg data time: 5.49e-02, avg batch time: 0.4970, average train loss: 0.2399
[09/26 06:05:10 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.1663, average loss: 1.5028
[09/26 06:05:10 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.50	top5: 89.00	
[09/26 06:05:10 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.008271734841028553
[09/26 06:05:17 visual_prompt]: Epoch 77 / 100: avg data time: 5.72e-02, avg batch time: 0.4993, average train loss: 0.2392
[09/26 06:05:18 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1663, average loss: 1.5320
[09/26 06:05:18 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 65.00	top5: 90.50	
[09/26 06:05:18 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.007633540738525066
[09/26 06:05:25 visual_prompt]: Epoch 78 / 100: avg data time: 5.62e-02, avg batch time: 0.4987, average train loss: 0.2391
[09/26 06:05:27 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1663, average loss: 1.5287
[09/26 06:05:27 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 64.00	top5: 89.50	
[09/26 06:05:27 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.0070165049915337264
[09/26 06:05:33 visual_prompt]: Epoch 79 / 100: avg data time: 5.47e-02, avg batch time: 0.4971, average train loss: 0.2376
[09/26 06:05:35 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1663, average loss: 1.5615
[09/26 06:05:35 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.00	top5: 90.50	
[09/26 06:05:35 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.006421379363065142
[09/26 06:05:42 visual_prompt]: Epoch 80 / 100: avg data time: 5.22e-02, avg batch time: 0.4940, average train loss: 0.2375
[09/26 06:05:43 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1663, average loss: 1.5502
[09/26 06:05:43 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 64.00	top5: 89.50	
[09/26 06:05:43 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.005848888922025553
[09/26 06:05:50 visual_prompt]: Epoch 81 / 100: avg data time: 5.13e-02, avg batch time: 0.4936, average train loss: 0.2368
[09/26 06:05:51 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1663, average loss: 1.5756
[09/26 06:05:51 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 88.50	
[09/26 06:05:51 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.005299731159831953
[09/26 06:05:58 visual_prompt]: Epoch 82 / 100: avg data time: 5.70e-02, avg batch time: 0.4990, average train loss: 0.2365
[09/26 06:06:00 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1663, average loss: 1.5922
[09/26 06:06:00 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.50	top5: 89.00	
[09/26 06:06:00 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.004774575140626317
[09/26 06:06:06 visual_prompt]: Epoch 83 / 100: avg data time: 4.96e-02, avg batch time: 0.4927, average train loss: 0.2362
[09/26 06:06:08 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1665, average loss: 1.5528
[09/26 06:06:08 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 64.00	top5: 89.50	
[09/26 06:06:08 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.004274060686123959
[09/26 06:06:15 visual_prompt]: Epoch 84 / 100: avg data time: 4.47e-02, avg batch time: 0.4897, average train loss: 0.2362
[09/26 06:06:16 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1662, average loss: 1.5695
[09/26 06:06:16 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.00	top5: 89.00	
[09/26 06:06:16 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.003798797596089351
[09/26 06:06:23 visual_prompt]: Epoch 85 / 100: avg data time: 5.02e-02, avg batch time: 0.4933, average train loss: 0.2352
[09/26 06:06:24 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1662, average loss: 1.5577
[09/26 06:06:24 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 64.00	top5: 89.50	
[09/26 06:06:24 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.0033493649053890325
[09/26 06:06:31 visual_prompt]: Epoch 86 / 100: avg data time: 5.53e-02, avg batch time: 0.4973, average train loss: 0.2354
[09/26 06:06:33 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1662, average loss: 1.5703
[09/26 06:06:33 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.00	top5: 90.00	
[09/26 06:06:33 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.0029263101785268254
[09/26 06:06:39 visual_prompt]: Epoch 87 / 100: avg data time: 5.58e-02, avg batch time: 0.4995, average train loss: 0.2356
[09/26 06:06:41 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1661, average loss: 1.5673
[09/26 06:06:41 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.50	top5: 91.00	
[09/26 06:06:41 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.00253014884252083
[09/26 06:06:48 visual_prompt]: Epoch 88 / 100: avg data time: 4.12e-02, avg batch time: 0.4856, average train loss: 0.2349
[09/26 06:06:49 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1666, average loss: 1.5535
[09/26 06:06:49 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 64.50	top5: 90.50	
[09/26 06:06:49 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.0021613635589349755
[09/26 06:06:56 visual_prompt]: Epoch 89 / 100: avg data time: 4.90e-02, avg batch time: 0.4919, average train loss: 0.2349
[09/26 06:06:57 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1664, average loss: 1.5629
[09/26 06:06:57 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 61.50	top5: 90.50	
[09/26 06:06:57 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.0018204036358303172
[09/26 06:07:04 visual_prompt]: Epoch 90 / 100: avg data time: 5.62e-02, avg batch time: 0.4977, average train loss: 0.2344
[09/26 06:07:05 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1664, average loss: 1.5610
[09/26 06:07:05 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.00	top5: 89.00	
[09/26 06:07:05 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.0015076844803522923
[09/26 06:07:12 visual_prompt]: Epoch 91 / 100: avg data time: 5.60e-02, avg batch time: 0.4977, average train loss: 0.2341
[09/26 06:07:14 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1664, average loss: 1.5666
[09/26 06:07:14 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 64.00	top5: 90.00	
[09/26 06:07:14 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.0012235870926211618
[09/26 06:07:20 visual_prompt]: Epoch 92 / 100: avg data time: 5.30e-02, avg batch time: 0.4943, average train loss: 0.2339
[09/26 06:07:22 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1661, average loss: 1.5572
[09/26 06:07:22 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.00	top5: 90.00	
[09/26 06:07:22 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.0009684576015420277
[09/26 06:07:29 visual_prompt]: Epoch 93 / 100: avg data time: 4.49e-02, avg batch time: 0.4885, average train loss: 0.2339
[09/26 06:07:30 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1663, average loss: 1.5504
[09/26 06:07:30 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 89.50	
[09/26 06:07:30 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.0007426068431000883
[09/26 06:07:37 visual_prompt]: Epoch 94 / 100: avg data time: 6.28e-02, avg batch time: 0.5056, average train loss: 0.2343
[09/26 06:07:39 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1663, average loss: 1.5561
[09/26 06:07:39 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 89.00	
[09/26 06:07:39 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.0005463099816548578
[09/26 06:07:45 visual_prompt]: Epoch 95 / 100: avg data time: 5.68e-02, avg batch time: 0.4994, average train loss: 0.2339
[09/26 06:07:47 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1663, average loss: 1.5596
[09/26 06:07:47 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 62.50	top5: 90.00	
[09/26 06:07:47 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.00037980617469479954
[09/26 06:07:54 visual_prompt]: Epoch 96 / 100: avg data time: 5.47e-02, avg batch time: 0.4961, average train loss: 0.2334
[09/26 06:07:55 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1664, average loss: 1.5589
[09/26 06:07:55 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.00	top5: 90.00	
[09/26 06:07:55 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.00024329828146074097
[09/26 06:08:02 visual_prompt]: Epoch 97 / 100: avg data time: 5.85e-02, avg batch time: 0.4997, average train loss: 0.2339
[09/26 06:08:04 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1662, average loss: 1.5575
[09/26 06:08:04 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.00	top5: 90.00	
[09/26 06:08:04 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.00013695261579316776
[09/26 06:08:10 visual_prompt]: Epoch 98 / 100: avg data time: 5.58e-02, avg batch time: 0.4974, average train loss: 0.2339
[09/26 06:08:12 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1666, average loss: 1.5571
[09/26 06:08:12 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.50	top5: 89.50	
[09/26 06:08:12 visual_prompt]: Training 99 / 100 epoch, with learning rate 6.089874350439506e-05
[09/26 06:08:19 visual_prompt]: Epoch 99 / 100: avg data time: 5.60e-02, avg batch time: 0.4977, average train loss: 0.2335
[09/26 06:08:20 visual_prompt]: Inference (val):avg data time: 4.14e-05, avg batch time: 0.1662, average loss: 1.5575
[09/26 06:08:20 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.50	top5: 89.50	
[09/26 06:08:20 visual_prompt]: Training 100 / 100 epoch, with learning rate 1.5229324522605948e-05
[09/26 06:08:27 visual_prompt]: Epoch 100 / 100: avg data time: 5.21e-02, avg batch time: 0.4937, average train loss: 0.2332
[09/26 06:08:28 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1662, average loss: 1.5576
[09/26 06:08:28 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 63.50	top5: 89.50	
[09/26 06:08:28 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 06:08:28 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 06:08:28 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-cifar(num_classes=100)', 'DATA.NUMBER_CLASSES', '100', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 06:08:28 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 06:08:28 visual_prompt]: Training with config:
[09/26 06:08:28 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-cifar(num_classes=100)/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.05_wd0.001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 0.05, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-cifar(num_classes=100)', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 100, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 06:08:28 visual_prompt]: Loading training data...
[09/26 06:08:28 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[:800], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/26 06:08:29 visual_prompt]: Number of images: 800
[09/26 06:08:29 visual_prompt]: Number of classes: 100 / 100
[09/26 06:08:29 visual_prompt]: Loading validation data...
[09/26 06:08:29 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[45000:45200], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/26 06:08:30 visual_prompt]: Number of images: 200
[09/26 06:08:30 visual_prompt]: Number of classes: 90 / 100
[09/26 06:08:30 visual_prompt]: Constructing models...
[09/26 06:08:32 visual_prompt]: Total Parameters: 86336356	 Gradient Parameters: 537700
[09/26 06:08:32 visual_prompt]: tuned percent:0.623
[09/26 06:08:32 visual_prompt]: Device used for model: 0
[09/26 06:08:32 visual_prompt]: Setting up Evaluator...
[09/26 06:08:32 visual_prompt]: Setting up Trainer...
[09/26 06:08:32 visual_prompt]: 	Setting up the optimizer...
[09/26 06:08:32 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 06:08:39 visual_prompt]: Epoch 1 / 100: avg data time: 5.68e-02, avg batch time: 0.5015, average train loss: 4.6568
[09/26 06:08:41 visual_prompt]: Inference (val):avg data time: 2.11e-05, avg batch time: 0.1658, average loss: 4.6218
[09/26 06:08:41 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 7.00	
[09/26 06:08:41 visual_prompt]: Best epoch 1: best metric: 0.010
[09/26 06:08:41 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.005000000000000001
[09/26 06:08:47 visual_prompt]: Epoch 2 / 100: avg data time: 4.87e-02, avg batch time: 0.4901, average train loss: 4.6444
[09/26 06:08:49 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1660, average loss: 4.6131
[09/26 06:08:49 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 8.00	
[09/26 06:08:49 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.010000000000000002
[09/26 06:08:56 visual_prompt]: Epoch 3 / 100: avg data time: 5.03e-02, avg batch time: 0.4907, average train loss: 4.6248
[09/26 06:08:57 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1661, average loss: 4.6110
[09/26 06:08:57 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 8.50	
[09/26 06:08:57 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.015
[09/26 06:09:04 visual_prompt]: Epoch 4 / 100: avg data time: 5.35e-02, avg batch time: 0.4940, average train loss: 4.5794
[09/26 06:09:05 visual_prompt]: Inference (val):avg data time: 1.98e-05, avg batch time: 0.1660, average loss: 4.5942
[09/26 06:09:05 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 8.00	
[09/26 06:09:05 visual_prompt]: Best epoch 4: best metric: 0.020
[09/26 06:09:05 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.020000000000000004
[09/26 06:09:12 visual_prompt]: Epoch 5 / 100: avg data time: 5.82e-02, avg batch time: 0.4989, average train loss: 4.5361
[09/26 06:09:13 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1658, average loss: 4.5803
[09/26 06:09:14 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 9.50	
[09/26 06:09:14 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.025
[09/26 06:09:20 visual_prompt]: Epoch 6 / 100: avg data time: 6.22e-02, avg batch time: 0.5034, average train loss: 4.4950
[09/26 06:09:22 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1660, average loss: 4.5370
[09/26 06:09:22 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 9.50	
[09/26 06:09:22 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.03
[09/26 06:09:29 visual_prompt]: Epoch 7 / 100: avg data time: 5.44e-02, avg batch time: 0.4963, average train loss: 4.3866
[09/26 06:09:30 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.1662, average loss: 4.4223
[09/26 06:09:30 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 4.50	top5: 18.50	
[09/26 06:09:30 visual_prompt]: Best epoch 7: best metric: 0.045
[09/26 06:09:30 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.034999999999999996
[09/26 06:09:37 visual_prompt]: Epoch 8 / 100: avg data time: 5.54e-02, avg batch time: 0.4963, average train loss: 4.1542
[09/26 06:09:38 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1662, average loss: 4.2059
[09/26 06:09:38 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 3.00	top5: 19.50	
[09/26 06:09:38 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.04000000000000001
[09/26 06:09:45 visual_prompt]: Epoch 9 / 100: avg data time: 5.39e-02, avg batch time: 0.4962, average train loss: 3.8660
[09/26 06:09:47 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1660, average loss: 3.9394
[09/26 06:09:47 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 9.00	top5: 25.00	
[09/26 06:09:47 visual_prompt]: Best epoch 9: best metric: 0.090
[09/26 06:09:47 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.045000000000000005
[09/26 06:09:53 visual_prompt]: Epoch 10 / 100: avg data time: 5.23e-02, avg batch time: 0.4952, average train loss: 3.4544
[09/26 06:09:55 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1664, average loss: 3.5785
[09/26 06:09:55 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 12.50	top5: 39.50	
[09/26 06:09:55 visual_prompt]: Best epoch 10: best metric: 0.125
[09/26 06:09:55 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.05
[09/26 06:10:02 visual_prompt]: Epoch 11 / 100: avg data time: 5.76e-02, avg batch time: 0.4989, average train loss: 3.0340
[09/26 06:10:03 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1662, average loss: 3.2878
[09/26 06:10:03 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 16.50	top5: 50.50	
[09/26 06:10:03 visual_prompt]: Best epoch 11: best metric: 0.165
[09/26 06:10:03 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0499847706754774
[09/26 06:10:10 visual_prompt]: Epoch 12 / 100: avg data time: 5.67e-02, avg batch time: 0.4980, average train loss: 2.5718
[09/26 06:10:12 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1671, average loss: 3.0687
[09/26 06:10:12 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 22.50	top5: 53.50	
[09/26 06:10:12 visual_prompt]: Best epoch 12: best metric: 0.225
[09/26 06:10:12 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.04993910125649561
[09/26 06:10:18 visual_prompt]: Epoch 13 / 100: avg data time: 5.85e-02, avg batch time: 0.5005, average train loss: 2.1541
[09/26 06:10:20 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1663, average loss: 2.7262
[09/26 06:10:20 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 27.00	top5: 66.00	
[09/26 06:10:20 visual_prompt]: Best epoch 13: best metric: 0.270
[09/26 06:10:20 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.049863047384206834
[09/26 06:10:27 visual_prompt]: Epoch 14 / 100: avg data time: 5.63e-02, avg batch time: 0.4986, average train loss: 1.7408
[09/26 06:10:28 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1662, average loss: 2.4351
[09/26 06:10:28 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 37.00	top5: 72.50	
[09/26 06:10:28 visual_prompt]: Best epoch 14: best metric: 0.370
[09/26 06:10:28 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.04975670171853926
[09/26 06:10:35 visual_prompt]: Epoch 15 / 100: avg data time: 5.52e-02, avg batch time: 0.4976, average train loss: 1.3897
[09/26 06:10:36 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1666, average loss: 2.2726
[09/26 06:10:36 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 40.50	top5: 77.00	
[09/26 06:10:36 visual_prompt]: Best epoch 15: best metric: 0.405
[09/26 06:10:36 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.049620193825305206
[09/26 06:10:43 visual_prompt]: Epoch 16 / 100: avg data time: 5.62e-02, avg batch time: 0.4982, average train loss: 1.0819
[09/26 06:10:45 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1663, average loss: 2.1337
[09/26 06:10:45 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 46.50	top5: 80.00	
[09/26 06:10:45 visual_prompt]: Best epoch 16: best metric: 0.465
[09/26 06:10:45 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.049453690018345146
[09/26 06:10:52 visual_prompt]: Epoch 17 / 100: avg data time: 5.37e-02, avg batch time: 0.4956, average train loss: 0.8526
[09/26 06:10:53 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1663, average loss: 1.9974
[09/26 06:10:53 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 46.50	top5: 82.00	
[09/26 06:10:53 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.04925739315689991
[09/26 06:11:00 visual_prompt]: Epoch 18 / 100: avg data time: 5.78e-02, avg batch time: 0.4998, average train loss: 0.6839
[09/26 06:11:01 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1665, average loss: 1.9761
[09/26 06:11:01 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 48.50	top5: 83.50	
[09/26 06:11:01 visual_prompt]: Best epoch 18: best metric: 0.485
[09/26 06:11:01 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.04903154239845797
[09/26 06:11:08 visual_prompt]: Epoch 19 / 100: avg data time: 5.56e-02, avg batch time: 0.4998, average train loss: 0.5252
[09/26 06:11:10 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.1662, average loss: 1.9395
[09/26 06:11:10 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 49.00	top5: 82.50	
[09/26 06:11:10 visual_prompt]: Best epoch 19: best metric: 0.490
[09/26 06:11:10 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.048776412907378844
[09/26 06:11:16 visual_prompt]: Epoch 20 / 100: avg data time: 5.63e-02, avg batch time: 0.4978, average train loss: 0.4274
[09/26 06:11:18 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1663, average loss: 1.9054
[09/26 06:11:18 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 50.50	top5: 83.50	
[09/26 06:11:18 visual_prompt]: Best epoch 20: best metric: 0.505
[09/26 06:11:18 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.048492315519647715
[09/26 06:11:25 visual_prompt]: Epoch 21 / 100: avg data time: 5.91e-02, avg batch time: 0.5027, average train loss: 0.3251
[09/26 06:11:26 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1664, average loss: 1.8524
[09/26 06:11:26 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 52.50	top5: 84.50	
[09/26 06:11:26 visual_prompt]: Best epoch 21: best metric: 0.525
[09/26 06:11:26 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.048179596364169686
[09/26 06:11:33 visual_prompt]: Epoch 22 / 100: avg data time: 4.66e-02, avg batch time: 0.4892, average train loss: 0.2630
[09/26 06:11:34 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1665, average loss: 1.7841
[09/26 06:11:34 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 52.50	top5: 86.50	
[09/26 06:11:34 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.04783863644106502
[09/26 06:11:41 visual_prompt]: Epoch 23 / 100: avg data time: 5.96e-02, avg batch time: 0.5022, average train loss: 0.2182
[09/26 06:11:43 visual_prompt]: Inference (val):avg data time: 1.96e-05, avg batch time: 0.1664, average loss: 1.7919
[09/26 06:11:43 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.00	top5: 86.00	
[09/26 06:11:43 visual_prompt]: Best epoch 23: best metric: 0.540
[09/26 06:11:43 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.047469851157479176
[09/26 06:11:50 visual_prompt]: Epoch 24 / 100: avg data time: 6.11e-02, avg batch time: 0.5029, average train loss: 0.1787
[09/26 06:11:51 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1662, average loss: 1.7867
[09/26 06:11:51 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 53.00	top5: 84.50	
[09/26 06:11:51 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.047073689821473176
[09/26 06:11:58 visual_prompt]: Epoch 25 / 100: avg data time: 5.12e-02, avg batch time: 0.4946, average train loss: 0.1530
[09/26 06:11:59 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1663, average loss: 1.7250
[09/26 06:11:59 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 55.50	top5: 83.00	
[09/26 06:11:59 visual_prompt]: Best epoch 25: best metric: 0.555
[09/26 06:11:59 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.046650635094610975
[09/26 06:12:06 visual_prompt]: Epoch 26 / 100: avg data time: 6.01e-02, avg batch time: 0.5016, average train loss: 0.1305
[09/26 06:12:08 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1661, average loss: 1.7146
[09/26 06:12:08 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 56.50	top5: 84.00	
[09/26 06:12:08 visual_prompt]: Best epoch 26: best metric: 0.565
[09/26 06:12:08 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.04620120240391065
[09/26 06:12:14 visual_prompt]: Epoch 27 / 100: avg data time: 5.19e-02, avg batch time: 0.4951, average train loss: 0.1170
[09/26 06:12:16 visual_prompt]: Inference (val):avg data time: 2.00e-05, avg batch time: 0.1664, average loss: 1.7256
[09/26 06:12:16 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 55.50	top5: 84.00	
[09/26 06:12:16 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.04572593931387604
[09/26 06:12:23 visual_prompt]: Epoch 28 / 100: avg data time: 5.90e-02, avg batch time: 0.5023, average train loss: 0.1003
[09/26 06:12:24 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1662, average loss: 1.7220
[09/26 06:12:24 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 55.00	top5: 83.50	
[09/26 06:12:24 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.04522542485937369
[09/26 06:12:31 visual_prompt]: Epoch 29 / 100: avg data time: 4.93e-02, avg batch time: 0.4926, average train loss: 0.0947
[09/26 06:12:32 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1664, average loss: 1.7671
[09/26 06:12:32 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 56.50	top5: 83.00	
[09/26 06:12:32 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.04470026884016805
[09/26 06:12:39 visual_prompt]: Epoch 30 / 100: avg data time: 5.22e-02, avg batch time: 0.4938, average train loss: 0.0882
[09/26 06:12:41 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1662, average loss: 1.7588
[09/26 06:12:41 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 53.00	top5: 84.50	
[09/26 06:12:41 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.04415111107797445
[09/26 06:12:47 visual_prompt]: Epoch 31 / 100: avg data time: 5.02e-02, avg batch time: 0.4934, average train loss: 0.0856
[09/26 06:12:49 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1662, average loss: 1.7228
[09/26 06:12:49 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.50	top5: 85.00	
[09/26 06:12:49 visual_prompt]: Best epoch 31: best metric: 0.595
[09/26 06:12:49 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.04357862063693486
[09/26 06:12:56 visual_prompt]: Epoch 32 / 100: avg data time: 6.17e-02, avg batch time: 0.5053, average train loss: 0.0808
[09/26 06:12:57 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1664, average loss: 1.7316
[09/26 06:12:57 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 57.50	top5: 85.00	
[09/26 06:12:57 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.04298349500846628
[09/26 06:13:04 visual_prompt]: Epoch 33 / 100: avg data time: 5.36e-02, avg batch time: 0.4958, average train loss: 0.0775
[09/26 06:13:05 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1662, average loss: 1.7521
[09/26 06:13:05 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 55.50	top5: 83.00	
[09/26 06:13:05 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.042366459261474934
[09/26 06:13:12 visual_prompt]: Epoch 34 / 100: avg data time: 5.24e-02, avg batch time: 0.4943, average train loss: 0.0707
[09/26 06:13:13 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1662, average loss: 1.7341
[09/26 06:13:13 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 56.00	top5: 83.50	
[09/26 06:13:13 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.04172826515897146
[09/26 06:13:20 visual_prompt]: Epoch 35 / 100: avg data time: 5.64e-02, avg batch time: 0.4989, average train loss: 0.0668
[09/26 06:13:22 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1662, average loss: 1.7196
[09/26 06:13:22 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 56.50	top5: 85.00	
[09/26 06:13:22 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.04106969024216348
[09/26 06:13:28 visual_prompt]: Epoch 36 / 100: avg data time: 4.32e-02, avg batch time: 0.4865, average train loss: 0.0638
[09/26 06:13:30 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1662, average loss: 1.6974
[09/26 06:13:30 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 56.00	top5: 86.00	
[09/26 06:13:30 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.040391536883141455
[09/26 06:13:37 visual_prompt]: Epoch 37 / 100: avg data time: 4.86e-02, avg batch time: 0.4910, average train loss: 0.0602
[09/26 06:13:38 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1662, average loss: 1.6943
[09/26 06:13:38 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 56.50	top5: 84.50	
[09/26 06:13:38 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.03969463130731183
[09/26 06:13:45 visual_prompt]: Epoch 38 / 100: avg data time: 5.95e-02, avg batch time: 0.5009, average train loss: 0.0581
[09/26 06:13:47 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1662, average loss: 1.6987
[09/26 06:13:47 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 56.50	top5: 85.00	
[09/26 06:13:47 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.03897982258676867
[09/26 06:13:53 visual_prompt]: Epoch 39 / 100: avg data time: 5.63e-02, avg batch time: 0.4975, average train loss: 0.0575
[09/26 06:13:55 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1662, average loss: 1.7188
[09/26 06:13:55 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 84.00	
[09/26 06:13:55 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.03824798160583012
[09/26 06:14:02 visual_prompt]: Epoch 40 / 100: avg data time: 5.60e-02, avg batch time: 0.4971, average train loss: 0.0567
[09/26 06:14:03 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.1664, average loss: 1.6941
[09/26 06:14:03 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.00	top5: 85.50	
[09/26 06:14:03 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.037500000000000006
[09/26 06:14:10 visual_prompt]: Epoch 41 / 100: avg data time: 6.18e-02, avg batch time: 0.5050, average train loss: 0.0538
[09/26 06:14:11 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1663, average loss: 1.6688
[09/26 06:14:11 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 85.50	
[09/26 06:14:11 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.03673678906964727
[09/26 06:14:18 visual_prompt]: Epoch 42 / 100: avg data time: 5.45e-02, avg batch time: 0.4960, average train loss: 0.0531
[09/26 06:14:20 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1663, average loss: 1.6773
[09/26 06:14:20 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 57.00	top5: 85.50	
[09/26 06:14:20 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.03595927866972694
[09/26 06:14:27 visual_prompt]: Epoch 43 / 100: avg data time: 5.35e-02, avg batch time: 0.4946, average train loss: 0.0502
[09/26 06:14:28 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1663, average loss: 1.6895
[09/26 06:14:28 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 57.50	top5: 85.00	
[09/26 06:14:28 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.03516841607689501
[09/26 06:14:35 visual_prompt]: Epoch 44 / 100: avg data time: 5.20e-02, avg batch time: 0.4944, average train loss: 0.0495
[09/26 06:14:36 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1661, average loss: 1.6989
[09/26 06:14:36 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 84.50	
[09/26 06:14:36 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.0343651648353978
[09/26 06:14:43 visual_prompt]: Epoch 45 / 100: avg data time: 5.20e-02, avg batch time: 0.4938, average train loss: 0.0505
[09/26 06:14:45 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1663, average loss: 1.6865
[09/26 06:14:45 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.00	top5: 83.50	
[09/26 06:14:45 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.033550503583141725
[09/26 06:14:51 visual_prompt]: Epoch 46 / 100: avg data time: 6.17e-02, avg batch time: 0.5032, average train loss: 0.0475
[09/26 06:14:53 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1663, average loss: 1.6925
[09/26 06:14:53 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 56.50	top5: 84.00	
[09/26 06:14:53 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.032725424859373686
[09/26 06:15:00 visual_prompt]: Epoch 47 / 100: avg data time: 5.12e-02, avg batch time: 0.4934, average train loss: 0.0473
[09/26 06:15:01 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1662, average loss: 1.6809
[09/26 06:15:01 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 84.50	
[09/26 06:15:01 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.03189093389542498
[09/26 06:15:08 visual_prompt]: Epoch 48 / 100: avg data time: 5.63e-02, avg batch time: 0.4988, average train loss: 0.0464
[09/26 06:15:09 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1668, average loss: 1.6890
[09/26 06:15:09 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 57.50	top5: 84.50	
[09/26 06:15:09 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.03104804738999169
[09/26 06:15:16 visual_prompt]: Epoch 49 / 100: avg data time: 5.75e-02, avg batch time: 0.4996, average train loss: 0.0460
[09/26 06:15:18 visual_prompt]: Inference (val):avg data time: 2.01e-05, avg batch time: 0.1662, average loss: 1.6765
[09/26 06:15:18 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.50	top5: 84.50	
[09/26 06:15:18 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.03019779227044398
[09/26 06:15:25 visual_prompt]: Epoch 50 / 100: avg data time: 5.72e-02, avg batch time: 0.4988, average train loss: 0.0454
[09/26 06:15:26 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1662, average loss: 1.6743
[09/26 06:15:26 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.50	top5: 86.50	
[09/26 06:15:26 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.029341204441673263
[09/26 06:15:33 visual_prompt]: Epoch 51 / 100: avg data time: 5.80e-02, avg batch time: 0.5009, average train loss: 0.0448
[09/26 06:15:34 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1662, average loss: 1.6627
[09/26 06:15:34 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.00	top5: 86.00	
[09/26 06:15:34 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.028479327524001636
[09/26 06:15:41 visual_prompt]: Epoch 52 / 100: avg data time: 5.38e-02, avg batch time: 0.4958, average train loss: 0.0440
[09/26 06:15:43 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1662, average loss: 1.6708
[09/26 06:15:43 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.00	top5: 85.50	
[09/26 06:15:43 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.02761321158169134
[09/26 06:15:50 visual_prompt]: Epoch 53 / 100: avg data time: 5.85e-02, avg batch time: 0.5004, average train loss: 0.0421
[09/26 06:15:51 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1663, average loss: 1.6821
[09/26 06:15:51 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.50	top5: 85.50	
[09/26 06:15:51 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.02674391184360313
[09/26 06:15:58 visual_prompt]: Epoch 54 / 100: avg data time: 5.22e-02, avg batch time: 0.4937, average train loss: 0.0425
[09/26 06:15:59 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1661, average loss: 1.6784
[09/26 06:15:59 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 86.00	
[09/26 06:15:59 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.02587248741756253
[09/26 06:16:06 visual_prompt]: Epoch 55 / 100: avg data time: 5.99e-02, avg batch time: 0.5039, average train loss: 0.0416
[09/26 06:16:08 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1663, average loss: 1.6749
[09/26 06:16:08 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 57.50	top5: 85.00	
[09/26 06:16:08 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.025
[09/26 06:16:15 visual_prompt]: Epoch 56 / 100: avg data time: 6.01e-02, avg batch time: 0.5029, average train loss: 0.0412
[09/26 06:16:16 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1663, average loss: 1.6874
[09/26 06:16:16 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.50	top5: 86.00	
[09/26 06:16:16 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.024127512582437484
[09/26 06:16:23 visual_prompt]: Epoch 57 / 100: avg data time: 6.15e-02, avg batch time: 0.5027, average train loss: 0.0423
[09/26 06:16:25 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1662, average loss: 1.6857
[09/26 06:16:25 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 84.50	
[09/26 06:16:25 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.02325608815639687
[09/26 06:16:31 visual_prompt]: Epoch 58 / 100: avg data time: 4.72e-02, avg batch time: 0.4905, average train loss: 0.0414
[09/26 06:16:33 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1661, average loss: 1.6846
[09/26 06:16:33 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 57.00	top5: 85.50	
[09/26 06:16:33 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.02238678841830867
[09/26 06:16:39 visual_prompt]: Epoch 59 / 100: avg data time: 6.13e-02, avg batch time: 0.5027, average train loss: 0.0412
[09/26 06:16:41 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1663, average loss: 1.6832
[09/26 06:16:41 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 86.00	
[09/26 06:16:41 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.02152067247599837
[09/26 06:16:48 visual_prompt]: Epoch 60 / 100: avg data time: 5.49e-02, avg batch time: 0.4978, average train loss: 0.0407
[09/26 06:16:49 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1663, average loss: 1.6755
[09/26 06:16:49 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.50	top5: 87.00	
[09/26 06:16:49 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.020658795558326743
[09/26 06:16:56 visual_prompt]: Epoch 61 / 100: avg data time: 5.88e-02, avg batch time: 0.5017, average train loss: 0.0402
[09/26 06:16:57 visual_prompt]: Inference (val):avg data time: 1.97e-05, avg batch time: 0.1662, average loss: 1.6782
[09/26 06:16:57 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 86.50	
[09/26 06:16:57 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.019802207729556022
[09/26 06:17:04 visual_prompt]: Epoch 62 / 100: avg data time: 5.38e-02, avg batch time: 0.4954, average train loss: 0.0386
[09/26 06:17:06 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1665, average loss: 1.6810
[09/26 06:17:06 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 57.00	top5: 84.50	
[09/26 06:17:06 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.018951952610008312
[09/26 06:17:12 visual_prompt]: Epoch 63 / 100: avg data time: 5.52e-02, avg batch time: 0.4976, average train loss: 0.0398
[09/26 06:17:14 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1663, average loss: 1.6907
[09/26 06:17:14 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 86.50	
[09/26 06:17:14 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.018109066104575022
[09/26 06:17:21 visual_prompt]: Epoch 64 / 100: avg data time: 4.50e-02, avg batch time: 0.4883, average train loss: 0.0386
[09/26 06:17:22 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1663, average loss: 1.6892
[09/26 06:17:22 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 57.00	top5: 86.50	
[09/26 06:17:22 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.017274575140626316
[09/26 06:17:29 visual_prompt]: Epoch 65 / 100: avg data time: 5.51e-02, avg batch time: 0.4968, average train loss: 0.0395
[09/26 06:17:30 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1662, average loss: 1.6846
[09/26 06:17:30 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 57.00	top5: 87.00	
[09/26 06:17:30 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.016449496416858285
[09/26 06:17:37 visual_prompt]: Epoch 66 / 100: avg data time: 5.47e-02, avg batch time: 0.4995, average train loss: 0.0385
[09/26 06:17:39 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1664, average loss: 1.6773
[09/26 06:17:39 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 56.50	top5: 87.50	
[09/26 06:17:39 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.0156348351646022
[09/26 06:17:46 visual_prompt]: Epoch 67 / 100: avg data time: 6.25e-02, avg batch time: 0.5039, average train loss: 0.0390
[09/26 06:17:47 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1663, average loss: 1.6721
[09/26 06:17:47 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.00	top5: 87.50	
[09/26 06:17:47 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.014831583923105
[09/26 06:17:54 visual_prompt]: Epoch 68 / 100: avg data time: 4.33e-02, avg batch time: 0.4873, average train loss: 0.0390
[09/26 06:17:55 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1661, average loss: 1.6774
[09/26 06:17:55 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.50	top5: 86.50	
[09/26 06:17:55 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.014040721330273063
[09/26 06:18:02 visual_prompt]: Epoch 69 / 100: avg data time: 5.49e-02, avg batch time: 0.4968, average train loss: 0.0384
[09/26 06:18:04 visual_prompt]: Inference (val):avg data time: 2.01e-05, avg batch time: 0.1660, average loss: 1.6772
[09/26 06:18:04 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 86.00	
[09/26 06:18:04 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.013263210930352737
[09/26 06:18:10 visual_prompt]: Epoch 70 / 100: avg data time: 4.60e-02, avg batch time: 0.4880, average train loss: 0.0389
[09/26 06:18:12 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1663, average loss: 1.6789
[09/26 06:18:12 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 57.50	top5: 85.00	
[09/26 06:18:12 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.012500000000000006
[09/26 06:18:18 visual_prompt]: Epoch 71 / 100: avg data time: 4.71e-02, avg batch time: 0.4889, average train loss: 0.0385
[09/26 06:18:20 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1661, average loss: 1.6721
[09/26 06:18:20 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 57.00	top5: 85.50	
[09/26 06:18:20 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.01175201839416988
[09/26 06:18:27 visual_prompt]: Epoch 72 / 100: avg data time: 5.82e-02, avg batch time: 0.5002, average train loss: 0.0382
[09/26 06:18:28 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1666, average loss: 1.6711
[09/26 06:18:28 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 57.00	top5: 86.50	
[09/26 06:18:28 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.011020177413231334
[09/26 06:18:35 visual_prompt]: Epoch 73 / 100: avg data time: 4.25e-02, avg batch time: 0.4860, average train loss: 0.0372
[09/26 06:18:36 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1665, average loss: 1.6712
[09/26 06:18:36 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 57.50	top5: 86.00	
[09/26 06:18:36 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.010305368692688175
[09/26 06:18:43 visual_prompt]: Epoch 74 / 100: avg data time: 5.66e-02, avg batch time: 0.4993, average train loss: 0.0366
[09/26 06:18:45 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1663, average loss: 1.6779
[09/26 06:18:45 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 85.00	
[09/26 06:18:45 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.009608463116858543
[09/26 06:18:51 visual_prompt]: Epoch 75 / 100: avg data time: 4.76e-02, avg batch time: 0.4891, average train loss: 0.0377
[09/26 06:18:53 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1661, average loss: 1.6796
[09/26 06:18:53 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 57.00	top5: 86.00	
[09/26 06:18:53 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.008930309757836517
[09/26 06:18:59 visual_prompt]: Epoch 76 / 100: avg data time: 5.43e-02, avg batch time: 0.4968, average train loss: 0.0381
[09/26 06:19:01 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1662, average loss: 1.6750
[09/26 06:19:01 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.00	top5: 85.50	
[09/26 06:19:01 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.008271734841028553
[09/26 06:19:08 visual_prompt]: Epoch 77 / 100: avg data time: 5.98e-02, avg batch time: 0.5008, average train loss: 0.0381
[09/26 06:19:09 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1662, average loss: 1.6678
[09/26 06:19:09 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.50	top5: 86.00	
[09/26 06:19:09 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.007633540738525066
[09/26 06:19:16 visual_prompt]: Epoch 78 / 100: avg data time: 5.81e-02, avg batch time: 0.4991, average train loss: 0.0369
[09/26 06:19:18 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1664, average loss: 1.6697
[09/26 06:19:18 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.50	top5: 86.00	
[09/26 06:19:18 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.0070165049915337264
[09/26 06:19:24 visual_prompt]: Epoch 79 / 100: avg data time: 4.43e-02, avg batch time: 0.4867, average train loss: 0.0376
[09/26 06:19:26 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1662, average loss: 1.6713
[09/26 06:19:26 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 60.00	top5: 86.50	
[09/26 06:19:26 visual_prompt]: Best epoch 79: best metric: 0.600
[09/26 06:19:26 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.006421379363065142
[09/26 06:19:33 visual_prompt]: Epoch 80 / 100: avg data time: 4.36e-02, avg batch time: 0.4871, average train loss: 0.0375
[09/26 06:19:34 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1664, average loss: 1.6776
[09/26 06:19:34 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.50	top5: 85.50	
[09/26 06:19:34 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.005848888922025553
[09/26 06:19:41 visual_prompt]: Epoch 81 / 100: avg data time: 5.74e-02, avg batch time: 0.4997, average train loss: 0.0367
[09/26 06:19:42 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1661, average loss: 1.6843
[09/26 06:19:42 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.50	top5: 86.00	
[09/26 06:19:42 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.005299731159831953
[09/26 06:19:49 visual_prompt]: Epoch 82 / 100: avg data time: 5.84e-02, avg batch time: 0.5003, average train loss: 0.0382
[09/26 06:19:51 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1665, average loss: 1.6859
[09/26 06:19:51 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.50	top5: 85.50	
[09/26 06:19:51 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.004774575140626317
[09/26 06:19:57 visual_prompt]: Epoch 83 / 100: avg data time: 5.45e-02, avg batch time: 0.4971, average train loss: 0.0380
[09/26 06:19:59 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1663, average loss: 1.6864
[09/26 06:19:59 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.50	top5: 85.50	
[09/26 06:19:59 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.004274060686123959
[09/26 06:20:06 visual_prompt]: Epoch 84 / 100: avg data time: 5.98e-02, avg batch time: 0.5007, average train loss: 0.0371
[09/26 06:20:07 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1663, average loss: 1.6861
[09/26 06:20:07 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.50	top5: 86.00	
[09/26 06:20:07 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.003798797596089351
[09/26 06:20:14 visual_prompt]: Epoch 85 / 100: avg data time: 5.13e-02, avg batch time: 0.4952, average train loss: 0.0372
[09/26 06:20:16 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1662, average loss: 1.6832
[09/26 06:20:16 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.00	top5: 86.00	
[09/26 06:20:16 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.0033493649053890325
[09/26 06:20:22 visual_prompt]: Epoch 86 / 100: avg data time: 4.63e-02, avg batch time: 0.4884, average train loss: 0.0369
[09/26 06:20:24 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1662, average loss: 1.6842
[09/26 06:20:24 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 59.00	top5: 86.00	
[09/26 06:20:24 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.0029263101785268254
[09/26 06:20:31 visual_prompt]: Epoch 87 / 100: avg data time: 6.11e-02, avg batch time: 0.5036, average train loss: 0.0366
[09/26 06:20:32 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1663, average loss: 1.6842
[09/26 06:20:32 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.50	top5: 86.00	
[09/26 06:20:32 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.00253014884252083
[09/26 06:20:39 visual_prompt]: Epoch 88 / 100: avg data time: 5.63e-02, avg batch time: 0.4980, average train loss: 0.0365
[09/26 06:20:41 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1662, average loss: 1.6828
[09/26 06:20:41 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.50	top5: 86.00	
[09/26 06:20:41 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.0021613635589349755
[09/26 06:20:47 visual_prompt]: Epoch 89 / 100: avg data time: 4.81e-02, avg batch time: 0.4907, average train loss: 0.0363
[09/26 06:20:49 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1662, average loss: 1.6805
[09/26 06:20:49 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.50	top5: 86.00	
[09/26 06:20:49 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.0018204036358303172
[09/26 06:20:56 visual_prompt]: Epoch 90 / 100: avg data time: 6.07e-02, avg batch time: 0.5022, average train loss: 0.0366
[09/26 06:20:57 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1662, average loss: 1.6806
[09/26 06:20:57 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.50	top5: 86.00	
[09/26 06:20:57 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.0015076844803522923
[09/26 06:21:04 visual_prompt]: Epoch 91 / 100: avg data time: 5.45e-02, avg batch time: 0.4964, average train loss: 0.0360
[09/26 06:21:05 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1666, average loss: 1.6803
[09/26 06:21:06 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.50	top5: 86.00	
[09/26 06:21:06 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.0012235870926211618
[09/26 06:21:12 visual_prompt]: Epoch 92 / 100: avg data time: 5.97e-02, avg batch time: 0.5026, average train loss: 0.0369
[09/26 06:21:14 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1665, average loss: 1.6801
[09/26 06:21:14 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.50	top5: 86.00	
[09/26 06:21:14 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.0009684576015420277
[09/26 06:21:21 visual_prompt]: Epoch 93 / 100: avg data time: 6.07e-02, avg batch time: 0.5028, average train loss: 0.0368
[09/26 06:21:22 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1663, average loss: 1.6806
[09/26 06:21:22 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.50	top5: 86.00	
[09/26 06:21:22 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.0007426068431000883
[09/26 06:21:29 visual_prompt]: Epoch 94 / 100: avg data time: 4.80e-02, avg batch time: 0.4906, average train loss: 0.0360
[09/26 06:21:30 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1663, average loss: 1.6803
[09/26 06:21:30 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.50	top5: 86.50	
[09/26 06:21:30 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.0005463099816548578
[09/26 06:21:37 visual_prompt]: Epoch 95 / 100: avg data time: 5.03e-02, avg batch time: 0.4918, average train loss: 0.0362
[09/26 06:21:39 visual_prompt]: Inference (val):avg data time: 2.11e-05, avg batch time: 0.1663, average loss: 1.6805
[09/26 06:21:39 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.50	top5: 86.50	
[09/26 06:21:39 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.00037980617469479954
[09/26 06:21:45 visual_prompt]: Epoch 96 / 100: avg data time: 4.50e-02, avg batch time: 0.4892, average train loss: 0.0360
[09/26 06:21:47 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1665, average loss: 1.6805
[09/26 06:21:47 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.50	top5: 86.50	
[09/26 06:21:47 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.00024329828146074097
[09/26 06:21:54 visual_prompt]: Epoch 97 / 100: avg data time: 5.91e-02, avg batch time: 0.5018, average train loss: 0.0360
[09/26 06:21:55 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1663, average loss: 1.6805
[09/26 06:21:55 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.50	top5: 86.50	
[09/26 06:21:55 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.00013695261579316776
[09/26 06:22:02 visual_prompt]: Epoch 98 / 100: avg data time: 4.76e-02, avg batch time: 0.4915, average train loss: 0.0365
[09/26 06:22:03 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1662, average loss: 1.6806
[09/26 06:22:03 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.50	top5: 86.50	
[09/26 06:22:03 visual_prompt]: Training 99 / 100 epoch, with learning rate 6.089874350439506e-05
[09/26 06:22:10 visual_prompt]: Epoch 99 / 100: avg data time: 4.82e-02, avg batch time: 0.4910, average train loss: 0.0368
[09/26 06:22:12 visual_prompt]: Inference (val):avg data time: 3.57e-05, avg batch time: 0.1664, average loss: 1.6806
[09/26 06:22:12 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.50	top5: 86.50	
[09/26 06:22:12 visual_prompt]: Training 100 / 100 epoch, with learning rate 1.5229324522605948e-05
[09/26 06:22:18 visual_prompt]: Epoch 100 / 100: avg data time: 4.81e-02, avg batch time: 0.4904, average train loss: 0.0365
[09/26 06:22:20 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1663, average loss: 1.6806
[09/26 06:22:20 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 58.50	top5: 86.50	
[09/26 06:22:20 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 06:22:20 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 06:22:20 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-cifar(num_classes=100)', 'DATA.NUMBER_CLASSES', '100', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 06:22:20 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 06:22:20 visual_prompt]: Training with config:
[09/26 06:22:20 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-cifar(num_classes=100)/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.05_wd0.0001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 0.05, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-cifar(num_classes=100)', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 100, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 06:22:20 visual_prompt]: Loading training data...
[09/26 06:22:20 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[:800], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/26 06:22:21 visual_prompt]: Number of images: 800
[09/26 06:22:21 visual_prompt]: Number of classes: 100 / 100
[09/26 06:22:21 visual_prompt]: Loading validation data...
[09/26 06:22:21 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[45000:45200], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/26 06:22:21 visual_prompt]: Number of images: 200
[09/26 06:22:21 visual_prompt]: Number of classes: 90 / 100
[09/26 06:22:21 visual_prompt]: Constructing models...
[09/26 06:22:23 visual_prompt]: Total Parameters: 86336356	 Gradient Parameters: 537700
[09/26 06:22:23 visual_prompt]: tuned percent:0.623
[09/26 06:22:24 visual_prompt]: Device used for model: 0
[09/26 06:22:24 visual_prompt]: Setting up Evaluator...
[09/26 06:22:24 visual_prompt]: Setting up Trainer...
[09/26 06:22:24 visual_prompt]: 	Setting up the optimizer...
[09/26 06:22:24 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 06:22:30 visual_prompt]: Epoch 1 / 100: avg data time: 4.55e-02, avg batch time: 0.4914, average train loss: 4.6561
[09/26 06:22:32 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1660, average loss: 4.6218
[09/26 06:22:32 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 7.00	
[09/26 06:22:32 visual_prompt]: Best epoch 1: best metric: 0.010
[09/26 06:22:32 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.005000000000000001
[09/26 06:22:39 visual_prompt]: Epoch 2 / 100: avg data time: 5.54e-02, avg batch time: 0.4965, average train loss: 4.6468
[09/26 06:22:40 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1661, average loss: 4.6137
[09/26 06:22:40 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 7.50	
[09/26 06:22:40 visual_prompt]: Best epoch 2: best metric: 0.020
[09/26 06:22:40 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.010000000000000002
[09/26 06:22:47 visual_prompt]: Epoch 3 / 100: avg data time: 5.86e-02, avg batch time: 0.4995, average train loss: 4.6161
[09/26 06:22:48 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1660, average loss: 4.5984
[09/26 06:22:48 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.50	top5: 5.50	
[09/26 06:22:48 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.015
[09/26 06:22:55 visual_prompt]: Epoch 4 / 100: avg data time: 4.79e-02, avg batch time: 0.4891, average train loss: 4.5755
[09/26 06:22:57 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1659, average loss: 4.5964
[09/26 06:22:57 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 8.00	
[09/26 06:22:57 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.020000000000000004
[09/26 06:23:03 visual_prompt]: Epoch 5 / 100: avg data time: 5.55e-02, avg batch time: 0.4964, average train loss: 4.5515
[09/26 06:23:05 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1660, average loss: 4.5824
[09/26 06:23:05 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 5.50	
[09/26 06:23:05 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.025
[09/26 06:23:12 visual_prompt]: Epoch 6 / 100: avg data time: 5.50e-02, avg batch time: 0.4969, average train loss: 4.4879
[09/26 06:23:13 visual_prompt]: Inference (val):avg data time: 3.57e-05, avg batch time: 0.1662, average loss: 4.5513
[09/26 06:23:13 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.50	top5: 11.50	
[09/26 06:23:13 visual_prompt]: Best epoch 6: best metric: 0.025
[09/26 06:23:13 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.03
[09/26 06:23:20 visual_prompt]: Epoch 7 / 100: avg data time: 5.63e-02, avg batch time: 0.4980, average train loss: 4.3920
[09/26 06:23:21 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1663, average loss: 4.4226
[09/26 06:23:21 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 4.00	top5: 16.50	
[09/26 06:23:21 visual_prompt]: Best epoch 7: best metric: 0.040
[09/26 06:23:21 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.034999999999999996
[09/26 06:23:28 visual_prompt]: Epoch 8 / 100: avg data time: 5.74e-02, avg batch time: 0.4983, average train loss: 4.0990
[09/26 06:23:30 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1663, average loss: 4.1533
[09/26 06:23:30 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 11.00	top5: 24.00	
[09/26 06:23:30 visual_prompt]: Best epoch 8: best metric: 0.110
[09/26 06:23:30 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.04000000000000001
[09/26 06:23:37 visual_prompt]: Epoch 9 / 100: avg data time: 6.34e-02, avg batch time: 0.5047, average train loss: 3.7796
[09/26 06:23:38 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1664, average loss: 3.8557
[09/26 06:23:38 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 8.00	top5: 32.00	
[09/26 06:23:38 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.045000000000000005
[09/26 06:23:45 visual_prompt]: Epoch 10 / 100: avg data time: 6.19e-02, avg batch time: 0.5027, average train loss: 3.3633
[09/26 06:23:46 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1664, average loss: 3.4437
[09/26 06:23:46 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 17.00	top5: 42.50	
[09/26 06:23:46 visual_prompt]: Best epoch 10: best metric: 0.170
[09/26 06:23:46 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.05
[09/26 06:23:53 visual_prompt]: Epoch 11 / 100: avg data time: 5.68e-02, avg batch time: 0.4987, average train loss: 2.9270
[09/26 06:23:55 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1663, average loss: 3.1683
[09/26 06:23:55 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 19.50	top5: 51.50	
[09/26 06:23:55 visual_prompt]: Best epoch 11: best metric: 0.195
[09/26 06:23:55 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0499847706754774
[09/26 06:24:01 visual_prompt]: Epoch 12 / 100: avg data time: 5.37e-02, avg batch time: 0.4950, average train loss: 2.5531
[09/26 06:24:03 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1665, average loss: 3.0034
[09/26 06:24:03 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 21.50	top5: 55.00	
[09/26 06:24:03 visual_prompt]: Best epoch 12: best metric: 0.215
[09/26 06:24:03 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.04993910125649561
[09/26 06:24:10 visual_prompt]: Epoch 13 / 100: avg data time: 5.28e-02, avg batch time: 0.4951, average train loss: 2.1279
[09/26 06:24:11 visual_prompt]: Inference (val):avg data time: 1.94e-05, avg batch time: 0.1665, average loss: 2.7623
[09/26 06:24:11 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 30.00	top5: 63.00	
[09/26 06:24:11 visual_prompt]: Best epoch 13: best metric: 0.300
[09/26 06:24:11 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.049863047384206834
[09/26 06:24:18 visual_prompt]: Epoch 14 / 100: avg data time: 5.13e-02, avg batch time: 0.4933, average train loss: 1.7398
[09/26 06:24:20 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1660, average loss: 2.6005
[09/26 06:24:20 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 29.50	top5: 67.50	
[09/26 06:24:20 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.04975670171853926
[09/26 06:24:26 visual_prompt]: Epoch 15 / 100: avg data time: 6.53e-02, avg batch time: 0.5077, average train loss: 1.4340
[09/26 06:24:28 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1662, average loss: 2.3719
[09/26 06:24:28 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 35.00	top5: 70.50	
[09/26 06:24:28 visual_prompt]: Best epoch 15: best metric: 0.350
[09/26 06:24:28 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.049620193825305206
[09/26 06:24:35 visual_prompt]: Epoch 16 / 100: avg data time: 5.30e-02, avg batch time: 0.4952, average train loss: 1.1170
[09/26 06:24:36 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1661, average loss: 2.2943
[09/26 06:24:36 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 38.50	top5: 73.50	
[09/26 06:24:36 visual_prompt]: Best epoch 16: best metric: 0.385
[09/26 06:24:36 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.049453690018345146
[09/26 06:24:43 visual_prompt]: Epoch 17 / 100: avg data time: 4.27e-02, avg batch time: 0.4855, average train loss: 0.8866
[09/26 06:24:44 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1662, average loss: 2.1471
[09/26 06:24:44 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 43.00	top5: 75.50	
[09/26 06:24:44 visual_prompt]: Best epoch 17: best metric: 0.430
[09/26 06:24:44 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.04925739315689991
[09/26 06:24:51 visual_prompt]: Epoch 18 / 100: avg data time: 4.54e-02, avg batch time: 0.4877, average train loss: 0.7118
[09/26 06:24:53 visual_prompt]: Inference (val):avg data time: 3.62e-05, avg batch time: 0.1664, average loss: 2.0115
[09/26 06:24:53 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 42.00	top5: 78.50	
[09/26 06:24:53 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.04903154239845797
[09/26 06:24:59 visual_prompt]: Epoch 19 / 100: avg data time: 5.78e-02, avg batch time: 0.5002, average train loss: 0.5387
[09/26 06:25:01 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1664, average loss: 1.9411
[09/26 06:25:01 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 48.50	top5: 78.50	
[09/26 06:25:01 visual_prompt]: Best epoch 19: best metric: 0.485
[09/26 06:25:01 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.048776412907378844
[09/26 06:25:08 visual_prompt]: Epoch 20 / 100: avg data time: 5.63e-02, avg batch time: 0.4975, average train loss: 0.4330
[09/26 06:25:09 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1665, average loss: 1.8993
[09/26 06:25:09 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 49.00	top5: 80.00	
[09/26 06:25:09 visual_prompt]: Best epoch 20: best metric: 0.490
[09/26 06:25:09 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.048492315519647715
[09/26 06:25:16 visual_prompt]: Epoch 21 / 100: avg data time: 5.64e-02, avg batch time: 0.4981, average train loss: 0.3408
[09/26 06:25:17 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1664, average loss: 1.8555
[09/26 06:25:17 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 50.50	top5: 82.00	
[09/26 06:25:17 visual_prompt]: Best epoch 21: best metric: 0.505
[09/26 06:25:17 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.048179596364169686
[09/26 06:25:24 visual_prompt]: Epoch 22 / 100: avg data time: 6.11e-02, avg batch time: 0.5030, average train loss: 0.2600
[09/26 06:25:26 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.1663, average loss: 1.8131
[09/26 06:25:26 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 50.00	top5: 81.50	
[09/26 06:25:26 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.04783863644106502
[09/26 06:25:32 visual_prompt]: Epoch 23 / 100: avg data time: 5.09e-02, avg batch time: 0.4924, average train loss: 0.2082
[09/26 06:25:34 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1665, average loss: 1.8708
[09/26 06:25:34 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 51.50	top5: 79.50	
[09/26 06:25:34 visual_prompt]: Best epoch 23: best metric: 0.515
[09/26 06:25:34 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.047469851157479176
[09/26 06:25:41 visual_prompt]: Epoch 24 / 100: avg data time: 4.88e-02, avg batch time: 0.4912, average train loss: 0.1704
[09/26 06:25:42 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1664, average loss: 1.8120
[09/26 06:25:42 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 51.50	top5: 80.50	
[09/26 06:25:42 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.047073689821473176
[09/26 06:25:49 visual_prompt]: Epoch 25 / 100: avg data time: 5.13e-02, avg batch time: 0.4942, average train loss: 0.1412
[09/26 06:25:51 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1663, average loss: 1.7581
[09/26 06:25:51 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 52.00	top5: 79.00	
[09/26 06:25:51 visual_prompt]: Best epoch 25: best metric: 0.520
[09/26 06:25:51 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.046650635094610975
[09/26 06:25:57 visual_prompt]: Epoch 26 / 100: avg data time: 5.34e-02, avg batch time: 0.4954, average train loss: 0.1271
[09/26 06:25:59 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1664, average loss: 1.7696
[09/26 06:25:59 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 52.00	top5: 80.00	
[09/26 06:25:59 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.04620120240391065
[09/26 06:26:06 visual_prompt]: Epoch 27 / 100: avg data time: 5.63e-02, avg batch time: 0.4988, average train loss: 0.1114
[09/26 06:26:07 visual_prompt]: Inference (val):avg data time: 3.50e-05, avg batch time: 0.1664, average loss: 1.7668
[09/26 06:26:07 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 50.50	top5: 80.00	
[09/26 06:26:07 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.04572593931387604
[09/26 06:26:14 visual_prompt]: Epoch 28 / 100: avg data time: 4.77e-02, avg batch time: 0.4921, average train loss: 0.0960
[09/26 06:26:15 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1666, average loss: 1.6948
[09/26 06:26:15 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 51.00	top5: 82.50	
[09/26 06:26:15 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.04522542485937369
[09/26 06:26:22 visual_prompt]: Epoch 29 / 100: avg data time: 5.89e-02, avg batch time: 0.5018, average train loss: 0.0831
[09/26 06:26:24 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1664, average loss: 1.6753
[09/26 06:26:24 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 53.00	top5: 82.50	
[09/26 06:26:24 visual_prompt]: Best epoch 29: best metric: 0.530
[09/26 06:26:24 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.04470026884016805
[09/26 06:26:30 visual_prompt]: Epoch 30 / 100: avg data time: 4.68e-02, avg batch time: 0.4888, average train loss: 0.0755
[09/26 06:26:32 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1662, average loss: 1.7160
[09/26 06:26:32 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 51.50	top5: 80.00	
[09/26 06:26:32 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.04415111107797445
[09/26 06:26:39 visual_prompt]: Epoch 31 / 100: avg data time: 5.00e-02, avg batch time: 0.4927, average train loss: 0.0701
[09/26 06:26:40 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1663, average loss: 1.6895
[09/26 06:26:40 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 53.50	top5: 82.00	
[09/26 06:26:40 visual_prompt]: Best epoch 31: best metric: 0.535
[09/26 06:26:40 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.04357862063693486
[09/26 06:26:47 visual_prompt]: Epoch 32 / 100: avg data time: 4.83e-02, avg batch time: 0.4915, average train loss: 0.0645
[09/26 06:26:48 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1662, average loss: 1.6935
[09/26 06:26:48 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 53.00	top5: 81.50	
[09/26 06:26:48 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.04298349500846628
[09/26 06:26:55 visual_prompt]: Epoch 33 / 100: avg data time: 4.04e-02, avg batch time: 0.4836, average train loss: 0.0588
[09/26 06:26:56 visual_prompt]: Inference (val):avg data time: 2.08e-05, avg batch time: 0.1664, average loss: 1.6668
[09/26 06:26:56 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 53.50	top5: 83.50	
[09/26 06:26:56 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.042366459261474934
[09/26 06:27:03 visual_prompt]: Epoch 34 / 100: avg data time: 5.48e-02, avg batch time: 0.4968, average train loss: 0.0561
[09/26 06:27:04 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1662, average loss: 1.6758
[09/26 06:27:04 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 51.50	top5: 82.00	
[09/26 06:27:04 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.04172826515897146
[09/26 06:27:11 visual_prompt]: Epoch 35 / 100: avg data time: 5.91e-02, avg batch time: 0.5014, average train loss: 0.0506
[09/26 06:27:13 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1661, average loss: 1.6591
[09/26 06:27:13 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 53.00	top5: 82.50	
[09/26 06:27:13 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.04106969024216348
[09/26 06:27:20 visual_prompt]: Epoch 36 / 100: avg data time: 5.53e-02, avg batch time: 0.4977, average train loss: 0.0509
[09/26 06:27:21 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1663, average loss: 1.6395
[09/26 06:27:21 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 53.50	top5: 82.50	
[09/26 06:27:21 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.040391536883141455
[09/26 06:27:28 visual_prompt]: Epoch 37 / 100: avg data time: 6.14e-02, avg batch time: 0.5031, average train loss: 0.0468
[09/26 06:27:29 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1664, average loss: 1.6770
[09/26 06:27:29 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 52.50	top5: 83.00	
[09/26 06:27:29 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.03969463130731183
[09/26 06:27:36 visual_prompt]: Epoch 38 / 100: avg data time: 4.84e-02, avg batch time: 0.4917, average train loss: 0.0441
[09/26 06:27:38 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1662, average loss: 1.6878
[09/26 06:27:38 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 53.50	top5: 83.00	
[09/26 06:27:38 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.03897982258676867
[09/26 06:27:44 visual_prompt]: Epoch 39 / 100: avg data time: 6.11e-02, avg batch time: 0.5040, average train loss: 0.0435
[09/26 06:27:46 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1663, average loss: 1.6662
[09/26 06:27:46 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 53.00	top5: 83.00	
[09/26 06:27:46 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.03824798160583012
[09/26 06:27:53 visual_prompt]: Epoch 40 / 100: avg data time: 5.26e-02, avg batch time: 0.4941, average train loss: 0.0412
[09/26 06:27:54 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1661, average loss: 1.6727
[09/26 06:27:54 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 53.50	top5: 84.00	
[09/26 06:27:54 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.037500000000000006
[09/26 06:28:01 visual_prompt]: Epoch 41 / 100: avg data time: 5.81e-02, avg batch time: 0.5002, average train loss: 0.0388
[09/26 06:28:02 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1661, average loss: 1.6769
[09/26 06:28:02 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 51.50	top5: 83.50	
[09/26 06:28:02 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.03673678906964727
[09/26 06:28:09 visual_prompt]: Epoch 42 / 100: avg data time: 5.23e-02, avg batch time: 0.4939, average train loss: 0.0387
[09/26 06:28:11 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1661, average loss: 1.6864
[09/26 06:28:11 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 53.00	top5: 81.00	
[09/26 06:28:11 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.03595927866972694
[09/26 06:28:17 visual_prompt]: Epoch 43 / 100: avg data time: 5.49e-02, avg batch time: 0.4967, average train loss: 0.0370
[09/26 06:28:19 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1663, average loss: 1.6717
[09/26 06:28:19 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.50	top5: 80.50	
[09/26 06:28:19 visual_prompt]: Best epoch 43: best metric: 0.545
[09/26 06:28:19 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.03516841607689501
[09/26 06:28:26 visual_prompt]: Epoch 44 / 100: avg data time: 5.64e-02, avg batch time: 0.4986, average train loss: 0.0349
[09/26 06:28:27 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1665, average loss: 1.6814
[09/26 06:28:27 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 53.00	top5: 82.50	
[09/26 06:28:27 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.0343651648353978
[09/26 06:28:34 visual_prompt]: Epoch 45 / 100: avg data time: 5.55e-02, avg batch time: 0.4983, average train loss: 0.0346
[09/26 06:28:35 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1661, average loss: 1.6818
[09/26 06:28:35 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 53.00	top5: 82.00	
[09/26 06:28:35 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.033550503583141725
[09/26 06:28:42 visual_prompt]: Epoch 46 / 100: avg data time: 4.90e-02, avg batch time: 0.4922, average train loss: 0.0333
[09/26 06:28:44 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1665, average loss: 1.6373
[09/26 06:28:44 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 55.50	top5: 82.00	
[09/26 06:28:44 visual_prompt]: Best epoch 46: best metric: 0.555
[09/26 06:28:44 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.032725424859373686
[09/26 06:28:50 visual_prompt]: Epoch 47 / 100: avg data time: 5.34e-02, avg batch time: 0.4956, average train loss: 0.0326
[09/26 06:28:52 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1663, average loss: 1.6406
[09/26 06:28:52 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.50	top5: 82.00	
[09/26 06:28:52 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.03189093389542498
[09/26 06:28:59 visual_prompt]: Epoch 48 / 100: avg data time: 5.09e-02, avg batch time: 0.4936, average train loss: 0.0320
[09/26 06:29:00 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1663, average loss: 1.6417
[09/26 06:29:00 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.00	top5: 82.00	
[09/26 06:29:00 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.03104804738999169
[09/26 06:29:07 visual_prompt]: Epoch 49 / 100: avg data time: 4.44e-02, avg batch time: 0.4875, average train loss: 0.0307
[09/26 06:29:08 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1664, average loss: 1.6435
[09/26 06:29:08 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.50	top5: 83.00	
[09/26 06:29:08 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.03019779227044398
[09/26 06:29:15 visual_prompt]: Epoch 50 / 100: avg data time: 5.66e-02, avg batch time: 0.4992, average train loss: 0.0307
[09/26 06:29:17 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1664, average loss: 1.6469
[09/26 06:29:17 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 53.00	top5: 82.50	
[09/26 06:29:17 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.029341204441673263
[09/26 06:29:23 visual_prompt]: Epoch 51 / 100: avg data time: 4.68e-02, avg batch time: 0.4887, average train loss: 0.0290
[09/26 06:29:25 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1663, average loss: 1.6359
[09/26 06:29:25 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.00	top5: 82.50	
[09/26 06:29:25 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.028479327524001636
[09/26 06:29:32 visual_prompt]: Epoch 52 / 100: avg data time: 5.61e-02, avg batch time: 0.4984, average train loss: 0.0286
[09/26 06:29:33 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1665, average loss: 1.6310
[09/26 06:29:33 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 55.50	top5: 82.50	
[09/26 06:29:33 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.02761321158169134
[09/26 06:29:40 visual_prompt]: Epoch 53 / 100: avg data time: 5.53e-02, avg batch time: 0.4983, average train loss: 0.0271
[09/26 06:29:41 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1664, average loss: 1.6365
[09/26 06:29:41 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.00	top5: 83.50	
[09/26 06:29:41 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.02674391184360313
[09/26 06:29:48 visual_prompt]: Epoch 54 / 100: avg data time: 5.47e-02, avg batch time: 0.4977, average train loss: 0.0270
[09/26 06:29:50 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1665, average loss: 1.6418
[09/26 06:29:50 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 55.50	top5: 83.00	
[09/26 06:29:50 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.02587248741756253
[09/26 06:29:57 visual_prompt]: Epoch 55 / 100: avg data time: 6.17e-02, avg batch time: 0.5032, average train loss: 0.0266
[09/26 06:29:58 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1662, average loss: 1.6396
[09/26 06:29:58 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 56.50	top5: 82.00	
[09/26 06:29:58 visual_prompt]: Best epoch 55: best metric: 0.565
[09/26 06:29:58 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.025
[09/26 06:30:05 visual_prompt]: Epoch 56 / 100: avg data time: 4.51e-02, avg batch time: 0.4895, average train loss: 0.0261
[09/26 06:30:06 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1664, average loss: 1.6516
[09/26 06:30:06 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 56.00	top5: 82.00	
[09/26 06:30:06 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.024127512582437484
[09/26 06:30:13 visual_prompt]: Epoch 57 / 100: avg data time: 5.85e-02, avg batch time: 0.5003, average train loss: 0.0264
[09/26 06:30:15 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1666, average loss: 1.6516
[09/26 06:30:15 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 55.00	top5: 83.00	
[09/26 06:30:15 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.02325608815639687
[09/26 06:30:21 visual_prompt]: Epoch 58 / 100: avg data time: 5.12e-02, avg batch time: 0.4934, average train loss: 0.0258
[09/26 06:30:23 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1666, average loss: 1.6395
[09/26 06:30:23 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 55.50	top5: 83.00	
[09/26 06:30:23 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.02238678841830867
[09/26 06:30:30 visual_prompt]: Epoch 59 / 100: avg data time: 6.06e-02, avg batch time: 0.5031, average train loss: 0.0253
[09/26 06:30:31 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1664, average loss: 1.6287
[09/26 06:30:31 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 55.50	top5: 82.50	
[09/26 06:30:31 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.02152067247599837
[09/26 06:30:38 visual_prompt]: Epoch 60 / 100: avg data time: 4.68e-02, avg batch time: 0.4912, average train loss: 0.0252
[09/26 06:30:40 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1666, average loss: 1.6304
[09/26 06:30:40 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 55.50	top5: 82.50	
[09/26 06:30:40 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.020658795558326743
[09/26 06:30:46 visual_prompt]: Epoch 61 / 100: avg data time: 5.21e-02, avg batch time: 0.4946, average train loss: 0.0255
[09/26 06:30:48 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1664, average loss: 1.6459
[09/26 06:30:48 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 55.50	top5: 83.00	
[09/26 06:30:48 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.019802207729556022
[09/26 06:30:55 visual_prompt]: Epoch 62 / 100: avg data time: 5.42e-02, avg batch time: 0.4975, average train loss: 0.0233
[09/26 06:30:56 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1664, average loss: 1.6487
[09/26 06:30:56 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 55.00	top5: 83.00	
[09/26 06:30:56 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.018951952610008312
[09/26 06:31:03 visual_prompt]: Epoch 63 / 100: avg data time: 5.09e-02, avg batch time: 0.4951, average train loss: 0.0234
[09/26 06:31:04 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1664, average loss: 1.6380
[09/26 06:31:04 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 56.00	top5: 82.50	
[09/26 06:31:04 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.018109066104575022
[09/26 06:31:11 visual_prompt]: Epoch 64 / 100: avg data time: 5.11e-02, avg batch time: 0.4951, average train loss: 0.0234
[09/26 06:31:13 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.1664, average loss: 1.6407
[09/26 06:31:13 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 56.50	top5: 82.00	
[09/26 06:31:13 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.017274575140626316
[09/26 06:31:19 visual_prompt]: Epoch 65 / 100: avg data time: 5.63e-02, avg batch time: 0.4996, average train loss: 0.0230
[09/26 06:31:21 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1666, average loss: 1.6390
[09/26 06:31:21 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 56.00	top5: 82.00	
[09/26 06:31:21 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.016449496416858285
[09/26 06:31:27 visual_prompt]: Epoch 66 / 100: avg data time: 5.13e-02, avg batch time: 0.4941, average train loss: 0.0230
[09/26 06:31:29 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1666, average loss: 1.6331
[09/26 06:31:29 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 56.00	top5: 82.50	
[09/26 06:31:29 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.0156348351646022
[09/26 06:31:36 visual_prompt]: Epoch 67 / 100: avg data time: 5.83e-02, avg batch time: 0.5010, average train loss: 0.0223
[09/26 06:31:37 visual_prompt]: Inference (val):avg data time: 2.01e-05, avg batch time: 0.1665, average loss: 1.6331
[09/26 06:31:37 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 56.00	top5: 83.00	
[09/26 06:31:37 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.014831583923105
[09/26 06:31:44 visual_prompt]: Epoch 68 / 100: avg data time: 4.98e-02, avg batch time: 0.4916, average train loss: 0.0221
[09/26 06:31:46 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1663, average loss: 1.6417
[09/26 06:31:46 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 55.50	top5: 82.50	
[09/26 06:31:46 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.014040721330273063
[09/26 06:31:52 visual_prompt]: Epoch 69 / 100: avg data time: 5.93e-02, avg batch time: 0.5022, average train loss: 0.0223
[09/26 06:31:54 visual_prompt]: Inference (val):avg data time: 1.94e-05, avg batch time: 0.1664, average loss: 1.6407
[09/26 06:31:54 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 55.50	top5: 83.50	
[09/26 06:31:54 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.013263210930352737
[09/26 06:32:01 visual_prompt]: Epoch 70 / 100: avg data time: 5.14e-02, avg batch time: 0.4940, average train loss: 0.0215
[09/26 06:32:02 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1665, average loss: 1.6395
[09/26 06:32:02 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 55.50	top5: 83.00	
[09/26 06:32:02 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.012500000000000006
[09/26 06:32:09 visual_prompt]: Epoch 71 / 100: avg data time: 5.98e-02, avg batch time: 0.5024, average train loss: 0.0218
[09/26 06:32:10 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1664, average loss: 1.6346
[09/26 06:32:10 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 55.50	top5: 83.00	
[09/26 06:32:10 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.01175201839416988
[09/26 06:32:17 visual_prompt]: Epoch 72 / 100: avg data time: 4.89e-02, avg batch time: 0.4941, average train loss: 0.0224
[09/26 06:32:19 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.1664, average loss: 1.6295
[09/26 06:32:19 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 56.50	top5: 83.00	
[09/26 06:32:19 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.011020177413231334
[09/26 06:32:25 visual_prompt]: Epoch 73 / 100: avg data time: 5.85e-02, avg batch time: 0.5004, average train loss: 0.0211
[09/26 06:32:27 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1666, average loss: 1.6303
[09/26 06:32:27 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 55.50	top5: 83.00	
[09/26 06:32:27 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.010305368692688175
[09/26 06:32:34 visual_prompt]: Epoch 74 / 100: avg data time: 5.01e-02, avg batch time: 0.4933, average train loss: 0.0220
[09/26 06:32:35 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1666, average loss: 1.6371
[09/26 06:32:35 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 56.50	top5: 83.00	
[09/26 06:32:35 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.009608463116858543
[09/26 06:32:42 visual_prompt]: Epoch 75 / 100: avg data time: 4.90e-02, avg batch time: 0.4917, average train loss: 0.0211
[09/26 06:32:43 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1665, average loss: 1.6337
[09/26 06:32:43 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 57.00	top5: 83.00	
[09/26 06:32:43 visual_prompt]: Best epoch 75: best metric: 0.570
[09/26 06:32:43 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.008930309757836517
[09/26 06:32:50 visual_prompt]: Epoch 76 / 100: avg data time: 5.83e-02, avg batch time: 0.5016, average train loss: 0.0209
[09/26 06:32:52 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1666, average loss: 1.6300
[09/26 06:32:52 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 56.00	top5: 82.50	
[09/26 06:32:52 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.008271734841028553
[09/26 06:32:58 visual_prompt]: Epoch 77 / 100: avg data time: 4.85e-02, avg batch time: 0.4903, average train loss: 0.0206
[09/26 06:33:00 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1665, average loss: 1.6291
[09/26 06:33:00 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 57.00	top5: 82.50	
[09/26 06:33:00 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.007633540738525066
[09/26 06:33:07 visual_prompt]: Epoch 78 / 100: avg data time: 5.65e-02, avg batch time: 0.5004, average train loss: 0.0206
[09/26 06:33:08 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1667, average loss: 1.6279
[09/26 06:33:08 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 57.50	top5: 82.50	
[09/26 06:33:08 visual_prompt]: Best epoch 78: best metric: 0.575
[09/26 06:33:08 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.0070165049915337264
[09/26 06:33:15 visual_prompt]: Epoch 79 / 100: avg data time: 5.40e-02, avg batch time: 0.4961, average train loss: 0.0210
[09/26 06:33:16 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1665, average loss: 1.6267
[09/26 06:33:16 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 57.00	top5: 82.50	
[09/26 06:33:16 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.006421379363065142
[09/26 06:33:23 visual_prompt]: Epoch 80 / 100: avg data time: 5.40e-02, avg batch time: 0.4961, average train loss: 0.0207
[09/26 06:33:25 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1666, average loss: 1.6279
[09/26 06:33:25 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 57.00	top5: 82.50	
[09/26 06:33:25 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.005848888922025553
[09/26 06:33:31 visual_prompt]: Epoch 81 / 100: avg data time: 6.05e-02, avg batch time: 0.5022, average train loss: 0.0213
[09/26 06:33:33 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1664, average loss: 1.6295
[09/26 06:33:33 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 56.50	top5: 83.00	
[09/26 06:33:33 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.005299731159831953
[09/26 06:33:40 visual_prompt]: Epoch 82 / 100: avg data time: 4.60e-02, avg batch time: 0.4895, average train loss: 0.0208
[09/26 06:33:41 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1662, average loss: 1.6307
[09/26 06:33:41 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 56.50	top5: 83.00	
[09/26 06:33:41 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.004774575140626317
[09/26 06:33:48 visual_prompt]: Epoch 83 / 100: avg data time: 5.22e-02, avg batch time: 0.4950, average train loss: 0.0195
[09/26 06:33:49 visual_prompt]: Inference (val):avg data time: 4.09e-05, avg batch time: 0.1664, average loss: 1.6310
[09/26 06:33:49 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 56.50	top5: 83.00	
[09/26 06:33:49 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.004274060686123959
[09/26 06:33:56 visual_prompt]: Epoch 84 / 100: avg data time: 5.82e-02, avg batch time: 0.5014, average train loss: 0.0206
[09/26 06:33:58 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1665, average loss: 1.6290
[09/26 06:33:58 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 57.00	top5: 83.00	
[09/26 06:33:58 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.003798797596089351
[09/26 06:34:05 visual_prompt]: Epoch 85 / 100: avg data time: 5.49e-02, avg batch time: 0.4985, average train loss: 0.0207
[09/26 06:34:06 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1666, average loss: 1.6284
[09/26 06:34:06 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 56.50	top5: 83.00	
[09/26 06:34:06 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.0033493649053890325
[09/26 06:34:13 visual_prompt]: Epoch 86 / 100: avg data time: 4.89e-02, avg batch time: 0.4908, average train loss: 0.0208
[09/26 06:34:14 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1667, average loss: 1.6285
[09/26 06:34:14 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 57.00	top5: 83.50	
[09/26 06:34:14 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.0029263101785268254
[09/26 06:34:21 visual_prompt]: Epoch 87 / 100: avg data time: 5.71e-02, avg batch time: 0.4997, average train loss: 0.0200
[09/26 06:34:23 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1663, average loss: 1.6288
[09/26 06:34:23 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 57.00	top5: 83.50	
[09/26 06:34:23 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.00253014884252083
[09/26 06:34:29 visual_prompt]: Epoch 88 / 100: avg data time: 5.24e-02, avg batch time: 0.4943, average train loss: 0.0207
[09/26 06:34:31 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.1666, average loss: 1.6306
[09/26 06:34:31 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 57.00	top5: 83.50	
[09/26 06:34:31 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.0021613635589349755
[09/26 06:34:38 visual_prompt]: Epoch 89 / 100: avg data time: 4.77e-02, avg batch time: 0.4911, average train loss: 0.0202
[09/26 06:34:39 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1664, average loss: 1.6301
[09/26 06:34:39 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 57.00	top5: 83.50	
[09/26 06:34:39 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.0018204036358303172
[09/26 06:34:46 visual_prompt]: Epoch 90 / 100: avg data time: 5.26e-02, avg batch time: 0.4956, average train loss: 0.0197
[09/26 06:34:47 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1665, average loss: 1.6299
[09/26 06:34:47 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 57.00	top5: 83.50	
[09/26 06:34:47 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.0015076844803522923
[09/26 06:34:54 visual_prompt]: Epoch 91 / 100: avg data time: 5.72e-02, avg batch time: 0.4992, average train loss: 0.0206
[09/26 06:34:56 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1665, average loss: 1.6295
[09/26 06:34:56 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 57.00	top5: 83.00	
[09/26 06:34:56 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.0012235870926211618
[09/26 06:35:03 visual_prompt]: Epoch 92 / 100: avg data time: 4.71e-02, avg batch time: 0.4926, average train loss: 0.0207
[09/26 06:35:04 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1665, average loss: 1.6289
[09/26 06:35:04 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 57.00	top5: 83.00	
[09/26 06:35:04 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.0009684576015420277
[09/26 06:35:11 visual_prompt]: Epoch 93 / 100: avg data time: 6.66e-02, avg batch time: 0.5086, average train loss: 0.0204
[09/26 06:35:12 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1663, average loss: 1.6282
[09/26 06:35:12 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 57.00	top5: 82.50	
[09/26 06:35:12 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.0007426068431000883
[09/26 06:35:19 visual_prompt]: Epoch 94 / 100: avg data time: 5.40e-02, avg batch time: 0.4956, average train loss: 0.0201
[09/26 06:35:21 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1664, average loss: 1.6280
[09/26 06:35:21 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 57.00	top5: 83.00	
[09/26 06:35:21 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.0005463099816548578
[09/26 06:35:27 visual_prompt]: Epoch 95 / 100: avg data time: 5.68e-02, avg batch time: 0.4984, average train loss: 0.0204
[09/26 06:35:29 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1663, average loss: 1.6278
[09/26 06:35:29 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 57.00	top5: 83.00	
[09/26 06:35:29 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.00037980617469479954
[09/26 06:35:36 visual_prompt]: Epoch 96 / 100: avg data time: 5.20e-02, avg batch time: 0.4960, average train loss: 0.0203
[09/26 06:35:37 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1665, average loss: 1.6279
[09/26 06:35:37 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 57.00	top5: 83.00	
[09/26 06:35:37 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.00024329828146074097
[09/26 06:35:44 visual_prompt]: Epoch 97 / 100: avg data time: 4.72e-02, avg batch time: 0.4899, average train loss: 0.0205
[09/26 06:35:46 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1664, average loss: 1.6276
[09/26 06:35:46 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 57.00	top5: 83.00	
[09/26 06:35:46 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.00013695261579316776
[09/26 06:35:52 visual_prompt]: Epoch 98 / 100: avg data time: 5.85e-02, avg batch time: 0.5001, average train loss: 0.0199
[09/26 06:35:54 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1667, average loss: 1.6276
[09/26 06:35:54 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 57.00	top5: 83.00	
[09/26 06:35:54 visual_prompt]: Training 99 / 100 epoch, with learning rate 6.089874350439506e-05
[09/26 06:36:01 visual_prompt]: Epoch 99 / 100: avg data time: 5.09e-02, avg batch time: 0.4937, average train loss: 0.0203
[09/26 06:36:02 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1666, average loss: 1.6275
[09/26 06:36:02 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 57.00	top5: 83.00	
[09/26 06:36:02 visual_prompt]: Training 100 / 100 epoch, with learning rate 1.5229324522605948e-05
[09/26 06:36:09 visual_prompt]: Epoch 100 / 100: avg data time: 6.20e-02, avg batch time: 0.5033, average train loss: 0.0198
[09/26 06:36:10 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1665, average loss: 1.6275
[09/26 06:36:10 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 57.00	top5: 83.00	
[09/26 06:36:10 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 06:36:10 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 06:36:10 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-cifar(num_classes=100)', 'DATA.NUMBER_CLASSES', '100', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 06:36:10 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 06:36:10 visual_prompt]: Training with config:
[09/26 06:36:10 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-cifar(num_classes=100)/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.05_wd0.0/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 0.05, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-cifar(num_classes=100)', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 100, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 06:36:10 visual_prompt]: Loading training data...
[09/26 06:36:10 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[:800], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/26 06:36:11 visual_prompt]: Number of images: 800
[09/26 06:36:11 visual_prompt]: Number of classes: 100 / 100
[09/26 06:36:11 visual_prompt]: Loading validation data...
[09/26 06:36:11 visual_prompt]: Constructing vtab-cifar(num_classes=100) dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/cifar100/3.0.2
[INFO: dataset_builder.py:  573]: Reusing dataset cifar100 (visual_prompt_tuning/data_path/cifar100/3.0.2)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset cifar100 for split train[45000:45200], from visual_prompt_tuning/data_path/cifar100/3.0.2
[09/26 06:36:12 visual_prompt]: Number of images: 200
[09/26 06:36:12 visual_prompt]: Number of classes: 90 / 100
[09/26 06:36:12 visual_prompt]: Constructing models...
[09/26 06:36:14 visual_prompt]: Total Parameters: 86336356	 Gradient Parameters: 537700
[09/26 06:36:14 visual_prompt]: tuned percent:0.623
[09/26 06:36:14 visual_prompt]: Device used for model: 0
[09/26 06:36:14 visual_prompt]: Setting up Evaluator...
[09/26 06:36:14 visual_prompt]: Setting up Trainer...
[09/26 06:36:14 visual_prompt]: 	Setting up the optimizer...
[09/26 06:36:14 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 06:36:21 visual_prompt]: Epoch 1 / 100: avg data time: 6.11e-02, avg batch time: 0.5040, average train loss: 4.6539
[09/26 06:36:23 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1659, average loss: 4.6218
[09/26 06:36:23 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 7.00	
[09/26 06:36:23 visual_prompt]: Best epoch 1: best metric: 0.010
[09/26 06:36:23 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.005000000000000001
[09/26 06:36:29 visual_prompt]: Epoch 2 / 100: avg data time: 5.78e-02, avg batch time: 0.4987, average train loss: 4.6456
[09/26 06:36:31 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1661, average loss: 4.6114
[09/26 06:36:31 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.00	top5: 8.00	
[09/26 06:36:31 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.010000000000000002
[09/26 06:36:38 visual_prompt]: Epoch 3 / 100: avg data time: 5.67e-02, avg batch time: 0.4981, average train loss: 4.6111
[09/26 06:36:39 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1662, average loss: 4.5999
[09/26 06:36:39 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 1.00	top5: 6.00	
[09/26 06:36:39 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.015
[09/26 06:36:46 visual_prompt]: Epoch 4 / 100: avg data time: 5.69e-02, avg batch time: 0.4988, average train loss: 4.5757
[09/26 06:36:48 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1662, average loss: 4.5856
[09/26 06:36:48 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.00	top5: 8.00	
[09/26 06:36:48 visual_prompt]: Best epoch 4: best metric: 0.020
[09/26 06:36:48 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.020000000000000004
[09/26 06:36:54 visual_prompt]: Epoch 5 / 100: avg data time: 5.45e-02, avg batch time: 0.4967, average train loss: 4.5364
[09/26 06:36:56 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1663, average loss: 4.5950
[09/26 06:36:56 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 0.50	top5: 7.00	
[09/26 06:36:56 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.025
[09/26 06:37:03 visual_prompt]: Epoch 6 / 100: avg data time: 5.50e-02, avg batch time: 0.4964, average train loss: 4.4866
[09/26 06:37:04 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1664, average loss: 4.5281
[09/26 06:37:04 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 2.50	top5: 10.00	
[09/26 06:37:04 visual_prompt]: Best epoch 6: best metric: 0.025
[09/26 06:37:04 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.03
[09/26 06:37:11 visual_prompt]: Epoch 7 / 100: avg data time: 6.09e-02, avg batch time: 0.5026, average train loss: 4.3573
[09/26 06:37:13 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1665, average loss: 4.4213
[09/26 06:37:13 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 3.50	top5: 14.50	
[09/26 06:37:13 visual_prompt]: Best epoch 7: best metric: 0.035
[09/26 06:37:13 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.034999999999999996
[09/26 06:37:19 visual_prompt]: Epoch 8 / 100: avg data time: 5.89e-02, avg batch time: 0.5013, average train loss: 4.0952
[09/26 06:37:21 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1664, average loss: 4.1148
[09/26 06:37:21 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 8.50	top5: 20.50	
[09/26 06:37:21 visual_prompt]: Best epoch 8: best metric: 0.085
[09/26 06:37:21 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.04000000000000001
[09/26 06:37:28 visual_prompt]: Epoch 9 / 100: avg data time: 5.15e-02, avg batch time: 0.4935, average train loss: 3.7163
[09/26 06:37:29 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1667, average loss: 3.8949
[09/26 06:37:29 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 7.50	top5: 28.00	
[09/26 06:37:29 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.045000000000000005
[09/26 06:37:36 visual_prompt]: Epoch 10 / 100: avg data time: 5.92e-02, avg batch time: 0.5017, average train loss: 3.3728
[09/26 06:37:38 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1664, average loss: 3.5297
[09/26 06:37:38 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 13.50	top5: 42.50	
[09/26 06:37:38 visual_prompt]: Best epoch 10: best metric: 0.135
[09/26 06:37:38 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.05
[09/26 06:37:44 visual_prompt]: Epoch 11 / 100: avg data time: 5.44e-02, avg batch time: 0.4970, average train loss: 2.9597
[09/26 06:37:46 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1665, average loss: 3.2043
[09/26 06:37:46 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 20.50	top5: 51.50	
[09/26 06:37:46 visual_prompt]: Best epoch 11: best metric: 0.205
[09/26 06:37:46 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0499847706754774
[09/26 06:37:53 visual_prompt]: Epoch 12 / 100: avg data time: 5.67e-02, avg batch time: 0.4995, average train loss: 2.4964
[09/26 06:37:54 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1665, average loss: 2.9987
[09/26 06:37:54 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 20.00	top5: 58.00	
[09/26 06:37:54 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.04993910125649561
[09/26 06:38:01 visual_prompt]: Epoch 13 / 100: avg data time: 5.95e-02, avg batch time: 0.5020, average train loss: 2.0747
[09/26 06:38:03 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1664, average loss: 2.7841
[09/26 06:38:03 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 23.00	top5: 62.50	
[09/26 06:38:03 visual_prompt]: Best epoch 13: best metric: 0.230
[09/26 06:38:03 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.049863047384206834
[09/26 06:38:09 visual_prompt]: Epoch 14 / 100: avg data time: 5.41e-02, avg batch time: 0.4954, average train loss: 1.6992
[09/26 06:38:11 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1667, average loss: 2.5961
[09/26 06:38:11 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 33.00	top5: 63.50	
[09/26 06:38:11 visual_prompt]: Best epoch 14: best metric: 0.330
[09/26 06:38:11 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.04975670171853926
[09/26 06:38:18 visual_prompt]: Epoch 15 / 100: avg data time: 4.48e-02, avg batch time: 0.4871, average train loss: 1.3838
[09/26 06:38:19 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1664, average loss: 2.4155
[09/26 06:38:19 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 33.00	top5: 68.50	
[09/26 06:38:19 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.049620193825305206
[09/26 06:38:26 visual_prompt]: Epoch 16 / 100: avg data time: 5.74e-02, avg batch time: 0.4991, average train loss: 1.0869
[09/26 06:38:27 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1665, average loss: 2.3160
[09/26 06:38:27 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 39.50	top5: 73.50	
[09/26 06:38:27 visual_prompt]: Best epoch 16: best metric: 0.395
[09/26 06:38:27 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.049453690018345146
[09/26 06:38:34 visual_prompt]: Epoch 17 / 100: avg data time: 6.09e-02, avg batch time: 0.5037, average train loss: 0.8636
[09/26 06:38:36 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1666, average loss: 2.1480
[09/26 06:38:36 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 44.00	top5: 77.00	
[09/26 06:38:36 visual_prompt]: Best epoch 17: best metric: 0.440
[09/26 06:38:36 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.04925739315689991
[09/26 06:38:43 visual_prompt]: Epoch 18 / 100: avg data time: 6.08e-02, avg batch time: 0.5030, average train loss: 0.6647
[09/26 06:38:44 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1662, average loss: 2.1341
[09/26 06:38:44 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 45.00	top5: 75.00	
[09/26 06:38:44 visual_prompt]: Best epoch 18: best metric: 0.450
[09/26 06:38:44 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.04903154239845797
[09/26 06:38:51 visual_prompt]: Epoch 19 / 100: avg data time: 4.89e-02, avg batch time: 0.4901, average train loss: 0.4990
[09/26 06:38:53 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1664, average loss: 2.0004
[09/26 06:38:53 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 46.50	top5: 81.00	
[09/26 06:38:53 visual_prompt]: Best epoch 19: best metric: 0.465
[09/26 06:38:53 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.048776412907378844
[09/26 06:38:59 visual_prompt]: Epoch 20 / 100: avg data time: 5.57e-02, avg batch time: 0.4980, average train loss: 0.3883
[09/26 06:39:01 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.1664, average loss: 1.9397
[09/26 06:39:01 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 45.50	top5: 85.00	
[09/26 06:39:01 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.048492315519647715
[09/26 06:39:08 visual_prompt]: Epoch 21 / 100: avg data time: 5.55e-02, avg batch time: 0.4977, average train loss: 0.2960
[09/26 06:39:09 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1663, average loss: 1.9412
[09/26 06:39:09 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 50.00	top5: 82.00	
[09/26 06:39:09 visual_prompt]: Best epoch 21: best metric: 0.500
[09/26 06:39:09 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.048179596364169686
[09/26 06:39:16 visual_prompt]: Epoch 22 / 100: avg data time: 5.31e-02, avg batch time: 0.4956, average train loss: 0.2515
[09/26 06:39:17 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1662, average loss: 1.9148
[09/26 06:39:17 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 49.00	top5: 82.50	
[09/26 06:39:17 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.04783863644106502
[09/26 06:39:24 visual_prompt]: Epoch 23 / 100: avg data time: 5.84e-02, avg batch time: 0.4998, average train loss: 0.1978
[09/26 06:39:26 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1662, average loss: 1.9060
[09/26 06:39:26 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 50.00	top5: 83.50	
[09/26 06:39:26 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.047469851157479176
[09/26 06:39:32 visual_prompt]: Epoch 24 / 100: avg data time: 5.43e-02, avg batch time: 0.4957, average train loss: 0.1667
[09/26 06:39:34 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1663, average loss: 1.8623
[09/26 06:39:34 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 48.00	top5: 82.50	
[09/26 06:39:34 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.047073689821473176
[09/26 06:39:41 visual_prompt]: Epoch 25 / 100: avg data time: 5.78e-02, avg batch time: 0.4995, average train loss: 0.1424
[09/26 06:39:42 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1664, average loss: 1.8195
[09/26 06:39:42 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 50.50	top5: 84.00	
[09/26 06:39:42 visual_prompt]: Best epoch 25: best metric: 0.505
[09/26 06:39:42 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.046650635094610975
[09/26 06:39:49 visual_prompt]: Epoch 26 / 100: avg data time: 4.77e-02, avg batch time: 0.4917, average train loss: 0.1153
[09/26 06:39:50 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1664, average loss: 1.8089
[09/26 06:39:50 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 51.00	top5: 85.00	
[09/26 06:39:50 visual_prompt]: Best epoch 26: best metric: 0.510
[09/26 06:39:50 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.04620120240391065
[09/26 06:39:57 visual_prompt]: Epoch 27 / 100: avg data time: 5.69e-02, avg batch time: 0.4988, average train loss: 0.1008
[09/26 06:39:59 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1664, average loss: 1.8477
[09/26 06:39:59 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 50.00	top5: 82.00	
[09/26 06:39:59 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.04572593931387604
[09/26 06:40:06 visual_prompt]: Epoch 28 / 100: avg data time: 6.20e-02, avg batch time: 0.5040, average train loss: 0.0886
[09/26 06:40:07 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1664, average loss: 1.8070
[09/26 06:40:07 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 52.00	top5: 85.00	
[09/26 06:40:07 visual_prompt]: Best epoch 28: best metric: 0.520
[09/26 06:40:07 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.04522542485937369
[09/26 06:40:14 visual_prompt]: Epoch 29 / 100: avg data time: 5.37e-02, avg batch time: 0.4959, average train loss: 0.0790
[09/26 06:40:15 visual_prompt]: Inference (val):avg data time: 3.63e-05, avg batch time: 0.1665, average loss: 1.8234
[09/26 06:40:15 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 50.00	top5: 85.00	
[09/26 06:40:15 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.04470026884016805
[09/26 06:40:22 visual_prompt]: Epoch 30 / 100: avg data time: 5.67e-02, avg batch time: 0.4984, average train loss: 0.0722
[09/26 06:40:24 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1662, average loss: 1.7933
[09/26 06:40:24 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 53.00	top5: 84.00	
[09/26 06:40:24 visual_prompt]: Best epoch 30: best metric: 0.530
[09/26 06:40:24 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.04415111107797445
[09/26 06:40:31 visual_prompt]: Epoch 31 / 100: avg data time: 5.88e-02, avg batch time: 0.5027, average train loss: 0.0625
[09/26 06:40:32 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1664, average loss: 1.7716
[09/26 06:40:32 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 52.50	top5: 84.50	
[09/26 06:40:32 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.04357862063693486
[09/26 06:40:39 visual_prompt]: Epoch 32 / 100: avg data time: 5.18e-02, avg batch time: 0.4949, average train loss: 0.0608
[09/26 06:40:40 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1663, average loss: 1.7696
[09/26 06:40:40 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.00	top5: 84.00	
[09/26 06:40:40 visual_prompt]: Best epoch 32: best metric: 0.540
[09/26 06:40:40 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.04298349500846628
[09/26 06:40:47 visual_prompt]: Epoch 33 / 100: avg data time: 4.42e-02, avg batch time: 0.4886, average train loss: 0.0572
[09/26 06:40:49 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1663, average loss: 1.7819
[09/26 06:40:49 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 52.50	top5: 84.00	
[09/26 06:40:49 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.042366459261474934
[09/26 06:40:55 visual_prompt]: Epoch 34 / 100: avg data time: 4.97e-02, avg batch time: 0.4935, average train loss: 0.0540
[09/26 06:40:57 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1663, average loss: 1.7748
[09/26 06:40:57 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 53.00	top5: 83.50	
[09/26 06:40:57 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.04172826515897146
[09/26 06:41:04 visual_prompt]: Epoch 35 / 100: avg data time: 5.16e-02, avg batch time: 0.4940, average train loss: 0.0493
[09/26 06:41:05 visual_prompt]: Inference (val):avg data time: 2.11e-05, avg batch time: 0.1663, average loss: 1.7723
[09/26 06:41:05 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.00	top5: 84.00	
[09/26 06:41:05 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.04106969024216348
[09/26 06:41:12 visual_prompt]: Epoch 36 / 100: avg data time: 4.69e-02, avg batch time: 0.4897, average train loss: 0.0455
[09/26 06:41:13 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1663, average loss: 1.7825
[09/26 06:41:13 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 53.00	top5: 83.50	
[09/26 06:41:13 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.040391536883141455
[09/26 06:41:20 visual_prompt]: Epoch 37 / 100: avg data time: 4.25e-02, avg batch time: 0.4855, average train loss: 0.0443
[09/26 06:41:22 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1665, average loss: 1.7695
[09/26 06:41:22 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 52.50	top5: 83.50	
[09/26 06:41:22 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.03969463130731183
[09/26 06:41:28 visual_prompt]: Epoch 38 / 100: avg data time: 6.16e-02, avg batch time: 0.5027, average train loss: 0.0414
[09/26 06:41:30 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1664, average loss: 1.7388
[09/26 06:41:30 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 53.00	top5: 84.50	
[09/26 06:41:30 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.03897982258676867
[09/26 06:41:37 visual_prompt]: Epoch 39 / 100: avg data time: 4.31e-02, avg batch time: 0.4864, average train loss: 0.0389
[09/26 06:41:38 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1664, average loss: 1.7399
[09/26 06:41:38 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 53.50	top5: 84.50	
[09/26 06:41:38 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.03824798160583012
[09/26 06:41:45 visual_prompt]: Epoch 40 / 100: avg data time: 6.10e-02, avg batch time: 0.5021, average train loss: 0.0389
[09/26 06:41:46 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1662, average loss: 1.7653
[09/26 06:41:46 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 55.00	top5: 83.50	
[09/26 06:41:46 visual_prompt]: Best epoch 40: best metric: 0.550
[09/26 06:41:46 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.037500000000000006
[09/26 06:41:53 visual_prompt]: Epoch 41 / 100: avg data time: 5.54e-02, avg batch time: 0.4987, average train loss: 0.0348
[09/26 06:41:55 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1662, average loss: 1.7522
[09/26 06:41:55 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 53.50	top5: 83.00	
[09/26 06:41:55 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.03673678906964727
[09/26 06:42:02 visual_prompt]: Epoch 42 / 100: avg data time: 5.68e-02, avg batch time: 0.4992, average train loss: 0.0335
[09/26 06:42:03 visual_prompt]: Inference (val):avg data time: 2.00e-05, avg batch time: 0.1663, average loss: 1.7518
[09/26 06:42:03 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.00	top5: 83.50	
[09/26 06:42:03 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.03595927866972694
[09/26 06:42:10 visual_prompt]: Epoch 43 / 100: avg data time: 5.99e-02, avg batch time: 0.5023, average train loss: 0.0333
[09/26 06:42:11 visual_prompt]: Inference (val):avg data time: 1.97e-05, avg batch time: 0.1662, average loss: 1.7481
[09/26 06:42:11 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 55.00	top5: 82.50	
[09/26 06:42:11 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.03516841607689501
[09/26 06:42:18 visual_prompt]: Epoch 44 / 100: avg data time: 4.72e-02, avg batch time: 0.4906, average train loss: 0.0322
[09/26 06:42:20 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1663, average loss: 1.7613
[09/26 06:42:20 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.50	top5: 82.50	
[09/26 06:42:20 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.0343651648353978
[09/26 06:42:26 visual_prompt]: Epoch 45 / 100: avg data time: 5.80e-02, avg batch time: 0.5002, average train loss: 0.0323
[09/26 06:42:28 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1662, average loss: 1.7588
[09/26 06:42:28 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 53.50	top5: 83.00	
[09/26 06:42:28 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.033550503583141725
[09/26 06:42:35 visual_prompt]: Epoch 46 / 100: avg data time: 4.45e-02, avg batch time: 0.4860, average train loss: 0.0300
[09/26 06:42:36 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1665, average loss: 1.7427
[09/26 06:42:36 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.50	top5: 83.50	
[09/26 06:42:36 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.032725424859373686
[09/26 06:42:43 visual_prompt]: Epoch 47 / 100: avg data time: 6.28e-02, avg batch time: 0.5041, average train loss: 0.0294
[09/26 06:42:44 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1661, average loss: 1.7514
[09/26 06:42:44 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.50	top5: 82.50	
[09/26 06:42:44 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.03189093389542498
[09/26 06:42:51 visual_prompt]: Epoch 48 / 100: avg data time: 4.41e-02, avg batch time: 0.4870, average train loss: 0.0287
[09/26 06:42:52 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1662, average loss: 1.7699
[09/26 06:42:52 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.00	top5: 83.00	
[09/26 06:42:52 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.03104804738999169
[09/26 06:42:59 visual_prompt]: Epoch 49 / 100: avg data time: 5.63e-02, avg batch time: 0.4985, average train loss: 0.0276
[09/26 06:43:01 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.1664, average loss: 1.7482
[09/26 06:43:01 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 55.50	top5: 84.00	
[09/26 06:43:01 visual_prompt]: Best epoch 49: best metric: 0.555
[09/26 06:43:01 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.03019779227044398
[09/26 06:43:08 visual_prompt]: Epoch 50 / 100: avg data time: 5.68e-02, avg batch time: 0.4994, average train loss: 0.0270
[09/26 06:43:09 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1662, average loss: 1.7587
[09/26 06:43:09 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.00	top5: 84.00	
[09/26 06:43:09 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.029341204441673263
[09/26 06:43:16 visual_prompt]: Epoch 51 / 100: avg data time: 5.73e-02, avg batch time: 0.4998, average train loss: 0.0272
[09/26 06:43:17 visual_prompt]: Inference (val):avg data time: 1.99e-05, avg batch time: 0.1661, average loss: 1.7563
[09/26 06:43:17 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.00	top5: 84.50	
[09/26 06:43:17 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.028479327524001636
[09/26 06:43:24 visual_prompt]: Epoch 52 / 100: avg data time: 4.53e-02, avg batch time: 0.4877, average train loss: 0.0262
[09/26 06:43:26 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1661, average loss: 1.7555
[09/26 06:43:26 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.00	top5: 84.00	
[09/26 06:43:26 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.02761321158169134
[09/26 06:43:32 visual_prompt]: Epoch 53 / 100: avg data time: 5.72e-02, avg batch time: 0.4986, average train loss: 0.0257
[09/26 06:43:34 visual_prompt]: Inference (val):avg data time: 2.00e-05, avg batch time: 0.1662, average loss: 1.7576
[09/26 06:43:34 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 53.50	top5: 83.50	
[09/26 06:43:34 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.02674391184360313
[09/26 06:43:41 visual_prompt]: Epoch 54 / 100: avg data time: 4.90e-02, avg batch time: 0.4917, average train loss: 0.0262
[09/26 06:43:42 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1662, average loss: 1.7702
[09/26 06:43:42 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 53.50	top5: 83.50	
[09/26 06:43:42 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.02587248741756253
[09/26 06:43:49 visual_prompt]: Epoch 55 / 100: avg data time: 6.04e-02, avg batch time: 0.5032, average train loss: 0.0242
[09/26 06:43:50 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1665, average loss: 1.7629
[09/26 06:43:50 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.50	top5: 84.00	
[09/26 06:43:50 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.025
[09/26 06:43:57 visual_prompt]: Epoch 56 / 100: avg data time: 5.58e-02, avg batch time: 0.4992, average train loss: 0.0241
[09/26 06:43:59 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1665, average loss: 1.7586
[09/26 06:43:59 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.50	top5: 83.00	
[09/26 06:43:59 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.024127512582437484
[09/26 06:44:06 visual_prompt]: Epoch 57 / 100: avg data time: 6.23e-02, avg batch time: 0.5034, average train loss: 0.0230
[09/26 06:44:07 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1661, average loss: 1.7607
[09/26 06:44:07 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.50	top5: 85.00	
[09/26 06:44:07 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.02325608815639687
[09/26 06:44:14 visual_prompt]: Epoch 58 / 100: avg data time: 5.37e-02, avg batch time: 0.4960, average train loss: 0.0235
[09/26 06:44:15 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1664, average loss: 1.7583
[09/26 06:44:15 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.50	top5: 84.50	
[09/26 06:44:15 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.02238678841830867
[09/26 06:44:22 visual_prompt]: Epoch 59 / 100: avg data time: 5.26e-02, avg batch time: 0.4986, average train loss: 0.0230
[09/26 06:44:24 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1663, average loss: 1.7653
[09/26 06:44:24 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 55.50	top5: 84.50	
[09/26 06:44:24 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.02152067247599837
[09/26 06:44:30 visual_prompt]: Epoch 60 / 100: avg data time: 6.40e-02, avg batch time: 0.5054, average train loss: 0.0226
[09/26 06:44:32 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1663, average loss: 1.7615
[09/26 06:44:32 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 56.00	top5: 85.00	
[09/26 06:44:32 visual_prompt]: Best epoch 60: best metric: 0.560
[09/26 06:44:32 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.020658795558326743
[09/26 06:44:39 visual_prompt]: Epoch 61 / 100: avg data time: 6.08e-02, avg batch time: 0.5026, average train loss: 0.0233
[09/26 06:44:40 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1662, average loss: 1.7666
[09/26 06:44:40 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.50	top5: 84.00	
[09/26 06:44:40 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.019802207729556022
[09/26 06:44:47 visual_prompt]: Epoch 62 / 100: avg data time: 5.75e-02, avg batch time: 0.4990, average train loss: 0.0205
[09/26 06:44:49 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1662, average loss: 1.7703
[09/26 06:44:49 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 55.00	top5: 84.00	
[09/26 06:44:49 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.018951952610008312
[09/26 06:44:55 visual_prompt]: Epoch 63 / 100: avg data time: 5.84e-02, avg batch time: 0.4996, average train loss: 0.0214
[09/26 06:44:57 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1664, average loss: 1.7669
[09/26 06:44:57 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 56.00	top5: 84.50	
[09/26 06:44:57 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.018109066104575022
[09/26 06:45:04 visual_prompt]: Epoch 64 / 100: avg data time: 5.69e-02, avg batch time: 0.5004, average train loss: 0.0222
[09/26 06:45:05 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1663, average loss: 1.7627
[09/26 06:45:05 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 55.00	top5: 85.00	
[09/26 06:45:05 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.017274575140626316
[09/26 06:45:12 visual_prompt]: Epoch 65 / 100: avg data time: 5.53e-02, avg batch time: 0.4978, average train loss: 0.0219
[09/26 06:45:14 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1664, average loss: 1.7773
[09/26 06:45:14 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 55.00	top5: 85.00	
[09/26 06:45:14 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.016449496416858285
[09/26 06:45:20 visual_prompt]: Epoch 66 / 100: avg data time: 6.20e-02, avg batch time: 0.5037, average train loss: 0.0206
[09/26 06:45:22 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1664, average loss: 1.7682
[09/26 06:45:22 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.50	top5: 85.00	
[09/26 06:45:22 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.0156348351646022
[09/26 06:45:29 visual_prompt]: Epoch 67 / 100: avg data time: 5.51e-02, avg batch time: 0.4982, average train loss: 0.0209
[09/26 06:45:30 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1663, average loss: 1.7592
[09/26 06:45:30 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 55.00	top5: 84.50	
[09/26 06:45:30 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.014831583923105
[09/26 06:45:37 visual_prompt]: Epoch 68 / 100: avg data time: 5.48e-02, avg batch time: 0.4968, average train loss: 0.0200
[09/26 06:45:39 visual_prompt]: Inference (val):avg data time: 4.84e-05, avg batch time: 0.1663, average loss: 1.7620
[09/26 06:45:39 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.50	top5: 85.00	
[09/26 06:45:39 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.014040721330273063
[09/26 06:45:45 visual_prompt]: Epoch 69 / 100: avg data time: 5.73e-02, avg batch time: 0.5003, average train loss: 0.0203
[09/26 06:45:47 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1663, average loss: 1.7669
[09/26 06:45:47 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.50	top5: 84.50	
[09/26 06:45:47 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.013263210930352737
[09/26 06:45:54 visual_prompt]: Epoch 70 / 100: avg data time: 5.84e-02, avg batch time: 0.4999, average train loss: 0.0198
[09/26 06:45:55 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1665, average loss: 1.7659
[09/26 06:45:55 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 53.50	top5: 84.50	
[09/26 06:45:55 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.012500000000000006
[09/26 06:46:02 visual_prompt]: Epoch 71 / 100: avg data time: 5.46e-02, avg batch time: 0.4956, average train loss: 0.0197
[09/26 06:46:04 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1663, average loss: 1.7727
[09/26 06:46:04 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 53.50	top5: 84.50	
[09/26 06:46:04 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.01175201839416988
[09/26 06:46:10 visual_prompt]: Epoch 72 / 100: avg data time: 5.89e-02, avg batch time: 0.4999, average train loss: 0.0199
[09/26 06:46:12 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1663, average loss: 1.7695
[09/26 06:46:12 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 53.50	top5: 84.00	
[09/26 06:46:12 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.011020177413231334
[09/26 06:46:19 visual_prompt]: Epoch 73 / 100: avg data time: 5.95e-02, avg batch time: 0.5028, average train loss: 0.0193
[09/26 06:46:20 visual_prompt]: Inference (val):avg data time: 4.54e-05, avg batch time: 0.1661, average loss: 1.7716
[09/26 06:46:20 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 53.50	top5: 84.00	
[09/26 06:46:20 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.010305368692688175
[09/26 06:46:27 visual_prompt]: Epoch 74 / 100: avg data time: 4.91e-02, avg batch time: 0.4938, average train loss: 0.0196
[09/26 06:46:29 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1664, average loss: 1.7733
[09/26 06:46:29 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.00	top5: 83.50	
[09/26 06:46:29 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.009608463116858543
[09/26 06:46:35 visual_prompt]: Epoch 75 / 100: avg data time: 6.25e-02, avg batch time: 0.5036, average train loss: 0.0195
[09/26 06:46:37 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1664, average loss: 1.7723
[09/26 06:46:37 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.00	top5: 83.50	
[09/26 06:46:37 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.008930309757836517
[09/26 06:46:44 visual_prompt]: Epoch 76 / 100: avg data time: 4.07e-02, avg batch time: 0.4856, average train loss: 0.0191
[09/26 06:46:45 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1664, average loss: 1.7707
[09/26 06:46:45 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.00	top5: 84.00	
[09/26 06:46:45 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.008271734841028553
[09/26 06:46:52 visual_prompt]: Epoch 77 / 100: avg data time: 5.34e-02, avg batch time: 0.4950, average train loss: 0.0191
[09/26 06:46:53 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1662, average loss: 1.7701
[09/26 06:46:53 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 54.00	top5: 84.50	
[09/26 06:46:53 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.007633540738525066
[09/26 06:47:00 visual_prompt]: Epoch 78 / 100: avg data time: 5.73e-02, avg batch time: 0.4984, average train loss: 0.0183
[09/26 06:47:02 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1663, average loss: 1.7706
[09/26 06:47:02 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 55.00	top5: 84.00	
[09/26 06:47:02 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.0070165049915337264
[09/26 06:47:08 visual_prompt]: Epoch 79 / 100: avg data time: 5.80e-02, avg batch time: 0.4990, average train loss: 0.0188
[09/26 06:47:10 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1664, average loss: 1.7688
[09/26 06:47:10 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 55.00	top5: 84.00	
[09/26 06:47:10 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.006421379363065142
[09/26 06:47:17 visual_prompt]: Epoch 80 / 100: avg data time: 5.52e-02, avg batch time: 0.4978, average train loss: 0.0193
[09/26 06:47:18 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1661, average loss: 1.7669
[09/26 06:47:18 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 55.00	top5: 84.00	
[09/26 06:47:18 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.005848888922025553
[09/26 06:47:25 visual_prompt]: Epoch 81 / 100: avg data time: 6.03e-02, avg batch time: 0.5024, average train loss: 0.0186
[09/26 06:47:26 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1661, average loss: 1.7635
[09/26 06:47:26 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 55.00	top5: 84.50	
[09/26 06:47:26 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.005299731159831953
[09/26 06:47:33 visual_prompt]: Epoch 82 / 100: avg data time: 5.27e-02, avg batch time: 0.4950, average train loss: 0.0187
[09/26 06:47:35 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1662, average loss: 1.7615
[09/26 06:47:35 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 55.00	top5: 84.50	
[09/26 06:47:35 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.004774575140626317
[09/26 06:47:41 visual_prompt]: Epoch 83 / 100: avg data time: 5.53e-02, avg batch time: 0.4974, average train loss: 0.0186
[09/26 06:47:43 visual_prompt]: Inference (val):avg data time: 2.11e-05, avg batch time: 0.1662, average loss: 1.7623
[09/26 06:47:43 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 55.00	top5: 84.50	
[09/26 06:47:43 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.004274060686123959
[09/26 06:47:50 visual_prompt]: Epoch 84 / 100: avg data time: 5.31e-02, avg batch time: 0.4959, average train loss: 0.0181
[09/26 06:47:51 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1662, average loss: 1.7610
[09/26 06:47:51 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 55.00	top5: 84.50	
[09/26 06:47:51 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.003798797596089351
[09/26 06:47:58 visual_prompt]: Epoch 85 / 100: avg data time: 5.93e-02, avg batch time: 0.5012, average train loss: 0.0183
[09/26 06:47:59 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1661, average loss: 1.7602
[09/26 06:47:59 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 55.00	top5: 84.50	
[09/26 06:47:59 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.0033493649053890325
[09/26 06:48:06 visual_prompt]: Epoch 86 / 100: avg data time: 5.40e-02, avg batch time: 0.4978, average train loss: 0.0177
[09/26 06:48:08 visual_prompt]: Inference (val):avg data time: 1.92e-05, avg batch time: 0.1662, average loss: 1.7599
[09/26 06:48:08 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 55.00	top5: 84.50	
[09/26 06:48:08 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.0029263101785268254
[09/26 06:48:15 visual_prompt]: Epoch 87 / 100: avg data time: 5.48e-02, avg batch time: 0.4968, average train loss: 0.0182
[09/26 06:48:16 visual_prompt]: Inference (val):avg data time: 1.78e-05, avg batch time: 0.1661, average loss: 1.7596
[09/26 06:48:16 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 55.00	top5: 84.50	
[09/26 06:48:16 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.00253014884252083
[09/26 06:48:23 visual_prompt]: Epoch 88 / 100: avg data time: 5.49e-02, avg batch time: 0.4975, average train loss: 0.0188
[09/26 06:48:24 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1663, average loss: 1.7591
[09/26 06:48:24 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 55.00	top5: 84.50	
[09/26 06:48:24 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.0021613635589349755
[09/26 06:48:31 visual_prompt]: Epoch 89 / 100: avg data time: 5.66e-02, avg batch time: 0.4980, average train loss: 0.0186
[09/26 06:48:33 visual_prompt]: Inference (val):avg data time: 1.99e-05, avg batch time: 0.1662, average loss: 1.7592
[09/26 06:48:33 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 55.00	top5: 84.50	
[09/26 06:48:33 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.0018204036358303172
[09/26 06:48:39 visual_prompt]: Epoch 90 / 100: avg data time: 4.29e-02, avg batch time: 0.4865, average train loss: 0.0192
[09/26 06:48:41 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1663, average loss: 1.7598
[09/26 06:48:41 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 55.00	top5: 84.50	
[09/26 06:48:41 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.0015076844803522923
[09/26 06:48:47 visual_prompt]: Epoch 91 / 100: avg data time: 5.09e-02, avg batch time: 0.4943, average train loss: 0.0183
[09/26 06:48:49 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1665, average loss: 1.7608
[09/26 06:48:49 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 55.50	top5: 84.50	
[09/26 06:48:49 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.0012235870926211618
[09/26 06:48:56 visual_prompt]: Epoch 92 / 100: avg data time: 4.90e-02, avg batch time: 0.4922, average train loss: 0.0180
[09/26 06:48:57 visual_prompt]: Inference (val):avg data time: 1.95e-05, avg batch time: 0.1662, average loss: 1.7614
[09/26 06:48:57 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 55.00	top5: 84.50	
[09/26 06:48:57 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.0009684576015420277
[09/26 06:49:04 visual_prompt]: Epoch 93 / 100: avg data time: 5.88e-02, avg batch time: 0.5017, average train loss: 0.0186
[09/26 06:49:05 visual_prompt]: Inference (val):avg data time: 1.98e-05, avg batch time: 0.1666, average loss: 1.7612
[09/26 06:49:05 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 55.00	top5: 84.50	
[09/26 06:49:05 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.0007426068431000883
[09/26 06:49:12 visual_prompt]: Epoch 94 / 100: avg data time: 4.80e-02, avg batch time: 0.4916, average train loss: 0.0185
[09/26 06:49:14 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1663, average loss: 1.7614
[09/26 06:49:14 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 55.00	top5: 84.50	
[09/26 06:49:14 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.0005463099816548578
[09/26 06:49:20 visual_prompt]: Epoch 95 / 100: avg data time: 5.16e-02, avg batch time: 0.4952, average train loss: 0.0186
[09/26 06:49:22 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1664, average loss: 1.7616
[09/26 06:49:22 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 55.00	top5: 84.50	
[09/26 06:49:22 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.00037980617469479954
[09/26 06:49:29 visual_prompt]: Epoch 96 / 100: avg data time: 5.05e-02, avg batch time: 0.4953, average train loss: 0.0187
[09/26 06:49:30 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1663, average loss: 1.7617
[09/26 06:49:30 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 55.00	top5: 84.50	
[09/26 06:49:30 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.00024329828146074097
[09/26 06:49:37 visual_prompt]: Epoch 97 / 100: avg data time: 5.91e-02, avg batch time: 0.5012, average train loss: 0.0177
[09/26 06:49:38 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1662, average loss: 1.7618
[09/26 06:49:38 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 55.50	top5: 84.50	
[09/26 06:49:38 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.00013695261579316776
[09/26 06:49:45 visual_prompt]: Epoch 98 / 100: avg data time: 5.57e-02, avg batch time: 0.4971, average train loss: 0.0182
[09/26 06:49:47 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1662, average loss: 1.7618
[09/26 06:49:47 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 55.50	top5: 84.50	
[09/26 06:49:47 visual_prompt]: Training 99 / 100 epoch, with learning rate 6.089874350439506e-05
[09/26 06:49:54 visual_prompt]: Epoch 99 / 100: avg data time: 5.71e-02, avg batch time: 0.4993, average train loss: 0.0180
[09/26 06:49:55 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1662, average loss: 1.7618
[09/26 06:49:55 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 55.50	top5: 84.50	
[09/26 06:49:55 visual_prompt]: Training 100 / 100 epoch, with learning rate 1.5229324522605948e-05
[09/26 06:50:02 visual_prompt]: Epoch 100 / 100: avg data time: 6.41e-02, avg batch time: 0.5056, average train loss: 0.0188
[09/26 06:50:03 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1664, average loss: 1.7618
[09/26 06:50:03 visual_prompt]: Classification results with val_vtab-cifar(num_classes=100): top1: 55.50	top5: 84.50	
Traceback (most recent call last):
  File "/home/s1952889/final-project/implementation/visual_prompt_tuning/tune_vtab.py", line 289, in <module>
    main(args)
  File "/home/s1952889/final-project/implementation/visual_prompt_tuning/tune_vtab.py", line 284, in main
    train(cfg, args)
  File "/home/s1952889/final-project/implementation/visual_prompt_tuning/tune_vtab.py", line 113, in train
    seed(cfg)
  File "/home/s1952889/final-project/implementation/visual_prompt_tuning/tune_vtab.py", line 136, in seed
    torch.manual_seed(SEED)
  File "/home/s1952889/miniconda3/envs/prompt/lib/python3.11/site-packages/torch/random.py", line 36, in manual_seed
    seed = int(seed)
           ^^^^^^^^^
TypeError: int() argument must be a string, a bytes-like object or a real number, not 'tuple'
