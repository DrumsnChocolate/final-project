/bin/bash: /home/s1952889/miniconda3/envs/prompt/lib/libtinfo.so.6: no version information available (required by /bin/bash)
An exception occurred in telemetry logging.Disabling telemetry to prevent further exceptions.
Traceback (most recent call last):
  File "/home/s1952889/miniconda3/envs/prompt/lib/python3.11/site-packages/iopath/common/file_io.py", line 946, in __log_tmetry_keys
    handler.log_event()
  File "/home/s1952889/miniconda3/envs/prompt/lib/python3.11/site-packages/iopath/common/event_logger.py", line 97, in log_event
    del self._evt
        ^^^^^^^^^
AttributeError: 'NativePathHandler' object has no attribute '_evt'
Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/22 11:07:44 visual_prompt]: Rank of current process: 0. World size: 1
[11/22 11:07:45 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/22 11:07:45 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/22 11:07:45 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/22 11:07:45 visual_prompt]: Training with config:
[11/22 11:07:45 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr50.0_wd0.01/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 50.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/22 11:07:45 visual_prompt]: Loading training data...
[11/22 11:07:45 visual_prompt]: Constructing mammo-cbis dataset train...
[11/22 11:07:46 visual_prompt]: Loading validation data...
[11/22 11:07:46 visual_prompt]: Constructing mammo-cbis dataset val...
[11/22 11:07:46 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/22 11:07:59 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/22 11:07:59 visual_prompt]: tuned percent:0.532
[11/22 11:07:59 visual_prompt]: Device used for model: 0
[11/22 11:07:59 visual_prompt]: Setting up Evaluator...
[11/22 11:07:59 visual_prompt]: Setting up Trainer...
[11/22 11:07:59 visual_prompt]: 	Setting up the optimizer...
[11/22 11:07:59 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/22 11:15:34 visual_prompt]: Epoch 1 / 100: avg data time: 5.03e+00, avg batch time: 6.4938, average train loss: 1.4863
[11/22 11:16:26 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.5879, average loss: 1.4553
[11/22 11:16:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/22 11:16:26 visual_prompt]: Training 2 / 100 epoch, with learning rate 5.0
[11/22 11:23:57 visual_prompt]: Epoch 2 / 100: avg data time: 4.99e+00, avg batch time: 6.4434, average train loss: 23.4194
[11/22 11:24:48 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.5880, average loss: 5.9050
[11/22 11:24:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.15	
[11/22 11:24:48 visual_prompt]: Training 3 / 100 epoch, with learning rate 10.0
[11/22 11:32:19 visual_prompt]: Epoch 3 / 100: avg data time: 4.99e+00, avg batch time: 6.4412, average train loss: 22.7559
[11/22 11:33:10 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.5870, average loss: 78.4539
[11/22 11:33:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 47.15	rocauc: 47.22	
[11/22 11:33:10 visual_prompt]: Training 4 / 100 epoch, with learning rate 15.0
[11/22 11:40:40 visual_prompt]: Epoch 4 / 100: avg data time: 4.97e+00, avg batch time: 6.4187, average train loss: 31.9098
[11/22 11:41:31 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.5885, average loss: 36.0121
[11/22 11:41:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.13	
[11/22 11:41:31 visual_prompt]: Training 5 / 100 epoch, with learning rate 20.0
[11/22 11:49:01 visual_prompt]: Epoch 5 / 100: avg data time: 4.98e+00, avg batch time: 6.4287, average train loss: 37.4111
[11/22 11:49:53 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.5856, average loss: 33.6763
[11/22 11:49:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.87	
[11/22 11:49:53 visual_prompt]: Training 6 / 100 epoch, with learning rate 25.0
[11/22 11:57:24 visual_prompt]: Epoch 6 / 100: avg data time: 5.00e+00, avg batch time: 6.4429, average train loss: 80.9835
[11/22 11:58:15 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.5897, average loss: 70.5767
[11/22 11:58:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.50	
[11/22 11:58:15 visual_prompt]: Training 7 / 100 epoch, with learning rate 30.0
[11/22 12:05:39 visual_prompt]: Epoch 7 / 100: avg data time: 4.90e+00, avg batch time: 6.3408, average train loss: 62.2236
[11/22 12:06:30 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.5913, average loss: 54.4756
[11/22 12:06:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.78	
[11/22 12:06:30 visual_prompt]: Training 8 / 100 epoch, with learning rate 35.0
[11/22 12:13:54 visual_prompt]: Epoch 8 / 100: avg data time: 4.90e+00, avg batch time: 6.3410, average train loss: 130.3972
[11/22 12:14:44 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.5854, average loss: 173.7895
[11/22 12:14:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.03	
[11/22 12:14:44 visual_prompt]: Training 9 / 100 epoch, with learning rate 40.0
[11/22 12:22:08 visual_prompt]: Epoch 9 / 100: avg data time: 4.90e+00, avg batch time: 6.3349, average train loss: 111.8224
[11/22 12:22:58 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.5860, average loss: 51.1531
[11/22 12:22:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 41.05	
[11/22 12:22:58 visual_prompt]: Training 10 / 100 epoch, with learning rate 45.0
[11/22 12:30:19 visual_prompt]: Epoch 10 / 100: avg data time: 4.86e+00, avg batch time: 6.2990, average train loss: 105.2176
[11/22 12:31:09 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.5911, average loss: 31.9708
[11/22 12:31:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.58	
[11/22 12:31:09 visual_prompt]: Training 11 / 100 epoch, with learning rate 50.0
[11/22 12:38:31 visual_prompt]: Epoch 11 / 100: avg data time: 4.87e+00, avg batch time: 6.3123, average train loss: 129.0567
[11/22 12:39:22 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.5854, average loss: 13.2878
[11/22 12:39:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.27	
[11/22 12:39:22 visual_prompt]: Training 12 / 100 epoch, with learning rate 49.9847706754774
[11/22 12:46:46 visual_prompt]: Epoch 12 / 100: avg data time: 4.90e+00, avg batch time: 6.3415, average train loss: 208.1526
[11/22 12:47:36 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.5895, average loss: 183.8571
[11/22 12:47:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.65	
[11/22 12:47:36 visual_prompt]: Training 13 / 100 epoch, with learning rate 49.939101256495604
[11/22 12:54:57 visual_prompt]: Epoch 13 / 100: avg data time: 4.86e+00, avg batch time: 6.3018, average train loss: 148.6304
[11/22 12:55:48 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.5868, average loss: 167.0876
[11/22 12:55:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 44.63	
[11/22 12:55:48 visual_prompt]: Training 14 / 100 epoch, with learning rate 49.86304738420683
[11/22 13:03:10 visual_prompt]: Epoch 14 / 100: avg data time: 4.87e+00, avg batch time: 6.3179, average train loss: 112.9457
[11/22 13:04:01 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.5858, average loss: 180.0684
[11/22 13:04:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.04	
[11/22 13:04:01 visual_prompt]: Training 15 / 100 epoch, with learning rate 49.75670171853926
[11/22 13:11:21 visual_prompt]: Epoch 15 / 100: avg data time: 4.86e+00, avg batch time: 6.2957, average train loss: 107.0701
[11/22 13:12:12 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.5883, average loss: 218.0983
[11/22 13:12:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.53	rocauc: 50.02	
[11/22 13:12:12 visual_prompt]: Training 16 / 100 epoch, with learning rate 49.6201938253052
[11/22 13:19:34 visual_prompt]: Epoch 16 / 100: avg data time: 4.87e+00, avg batch time: 6.3114, average train loss: 157.8699
[11/22 13:20:24 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.5846, average loss: 6.8180
[11/22 13:20:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.42	
[11/22 13:20:24 visual_prompt]: Best epoch 16: best metric: -6.818
[11/22 13:20:24 visual_prompt]: Training 17 / 100 epoch, with learning rate 49.45369001834514
[11/22 13:27:43 visual_prompt]: Epoch 17 / 100: avg data time: 4.84e+00, avg batch time: 6.2745, average train loss: 172.9522
[11/22 13:28:34 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.5919, average loss: 46.7653
[11/22 13:28:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.43	
[11/22 13:28:34 visual_prompt]: Training 18 / 100 epoch, with learning rate 49.25739315689991
[11/22 13:35:56 visual_prompt]: Epoch 18 / 100: avg data time: 4.87e+00, avg batch time: 6.3097, average train loss: 134.8895
[11/22 13:36:46 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.5879, average loss: 44.4161
[11/22 13:36:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.95	
[11/22 13:36:46 visual_prompt]: Training 19 / 100 epoch, with learning rate 49.03154239845797
[11/22 13:44:07 visual_prompt]: Epoch 19 / 100: avg data time: 4.86e+00, avg batch time: 6.2952, average train loss: 108.6106
[11/22 13:44:57 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.5899, average loss: 330.5166
[11/22 13:44:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.82	
[11/22 13:44:57 visual_prompt]: Training 20 / 100 epoch, with learning rate 48.77641290737884
[11/22 13:52:20 visual_prompt]: Epoch 20 / 100: avg data time: 4.88e+00, avg batch time: 6.3190, average train loss: 141.1177
[11/22 13:53:10 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.5906, average loss: 192.2731
[11/22 13:53:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.96	
[11/22 13:53:10 visual_prompt]: Training 21 / 100 epoch, with learning rate 48.49231551964771
[11/22 14:00:37 visual_prompt]: Epoch 21 / 100: avg data time: 4.93e+00, avg batch time: 6.3759, average train loss: 133.8192
[11/22 14:01:27 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.5835, average loss: 236.0819
[11/22 14:01:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.05	
[11/22 14:01:27 visual_prompt]: Training 22 / 100 epoch, with learning rate 48.17959636416968
[11/22 14:08:49 visual_prompt]: Epoch 22 / 100: avg data time: 4.88e+00, avg batch time: 6.3183, average train loss: 166.6178
[11/22 14:09:41 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.5874, average loss: 36.2407
[11/22 14:09:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 42.01	
[11/22 14:09:41 visual_prompt]: Training 23 / 100 epoch, with learning rate 47.83863644106502
[11/22 14:17:05 visual_prompt]: Epoch 23 / 100: avg data time: 4.91e+00, avg batch time: 6.3472, average train loss: 107.7752
[11/22 14:17:55 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.5856, average loss: 94.2358
[11/22 14:17:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.47	rocauc: 48.56	
[11/22 14:17:55 visual_prompt]: Training 24 / 100 epoch, with learning rate 47.46985115747918
[11/22 14:25:18 visual_prompt]: Epoch 24 / 100: avg data time: 4.88e+00, avg batch time: 6.3195, average train loss: 116.4842
[11/22 14:26:08 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.5931, average loss: 106.7851
[11/22 14:26:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 45.64	
[11/22 14:26:08 visual_prompt]: Training 25 / 100 epoch, with learning rate 47.073689821473174
[11/22 14:33:32 visual_prompt]: Epoch 25 / 100: avg data time: 4.89e+00, avg batch time: 6.3334, average train loss: 113.7748
[11/22 14:34:22 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.5886, average loss: 109.0722
[11/22 14:34:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.17	
[11/22 14:34:22 visual_prompt]: Training 26 / 100 epoch, with learning rate 46.65063509461097
[11/22 14:41:44 visual_prompt]: Epoch 26 / 100: avg data time: 4.87e+00, avg batch time: 6.3114, average train loss: 146.5544
[11/22 14:42:35 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.5895, average loss: 21.7410
[11/22 14:42:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 41.72	
[11/22 14:42:35 visual_prompt]: Training 27 / 100 epoch, with learning rate 46.20120240391065
[11/22 14:49:58 visual_prompt]: Epoch 27 / 100: avg data time: 4.88e+00, avg batch time: 6.3208, average train loss: 103.7777
[11/22 14:50:49 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.5889, average loss: 98.3964
[11/22 14:50:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.96	
[11/22 14:50:49 visual_prompt]: Training 28 / 100 epoch, with learning rate 45.72593931387604
[11/22 14:58:13 visual_prompt]: Epoch 28 / 100: avg data time: 4.91e+00, avg batch time: 6.3509, average train loss: 91.9104
[11/22 14:59:04 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.5859, average loss: 96.4467
[11/22 14:59:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.64	
[11/22 14:59:04 visual_prompt]: Training 29 / 100 epoch, with learning rate 45.22542485937369
[11/22 15:06:29 visual_prompt]: Epoch 29 / 100: avg data time: 4.92e+00, avg batch time: 6.3610, average train loss: 128.0840
[11/22 15:07:20 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.5907, average loss: 263.1504
[11/22 15:07:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.34	
[11/22 15:07:20 visual_prompt]: Training 30 / 100 epoch, with learning rate 44.70026884016804
[11/22 15:14:44 visual_prompt]: Epoch 30 / 100: avg data time: 4.90e+00, avg batch time: 6.3425, average train loss: 124.3856
[11/22 15:15:34 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.5882, average loss: 35.3219
[11/22 15:15:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.47	rocauc: 45.57	
[11/22 15:15:34 visual_prompt]: Training 31 / 100 epoch, with learning rate 44.15111107797445
[11/22 15:22:57 visual_prompt]: Epoch 31 / 100: avg data time: 4.89e+00, avg batch time: 6.3288, average train loss: 90.1168
[11/22 15:23:48 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.5899, average loss: 62.5616
[11/22 15:23:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.61	
[11/22 15:23:48 visual_prompt]: Training 32 / 100 epoch, with learning rate 43.57862063693486
[11/22 15:31:12 visual_prompt]: Epoch 32 / 100: avg data time: 4.91e+00, avg batch time: 6.3491, average train loss: 141.1328
[11/22 15:32:04 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.5864, average loss: 49.1966
[11/22 15:32:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 37.79	
[11/22 15:32:04 visual_prompt]: Training 33 / 100 epoch, with learning rate 42.98349500846628
[11/22 15:39:28 visual_prompt]: Epoch 33 / 100: avg data time: 4.90e+00, avg batch time: 6.3391, average train loss: 171.0309
[11/22 15:40:18 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.5848, average loss: 93.6822
[11/22 15:40:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.67	
[11/22 15:40:18 visual_prompt]: Training 34 / 100 epoch, with learning rate 42.36645926147493
[11/22 15:47:43 visual_prompt]: Epoch 34 / 100: avg data time: 4.91e+00, avg batch time: 6.3471, average train loss: 149.7995
[11/22 15:48:33 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.5879, average loss: 80.9170
[11/22 15:48:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 44.14	
[11/22 15:48:33 visual_prompt]: Training 35 / 100 epoch, with learning rate 41.72826515897145
[11/22 15:55:55 visual_prompt]: Epoch 35 / 100: avg data time: 4.87e+00, avg batch time: 6.3136, average train loss: 122.3858
[11/22 15:56:45 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.5841, average loss: 111.7660
[11/22 15:56:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.22	
[11/22 15:56:45 visual_prompt]: Training 36 / 100 epoch, with learning rate 41.06969024216348
[11/22 16:04:10 visual_prompt]: Epoch 36 / 100: avg data time: 4.90e+00, avg batch time: 6.3434, average train loss: 93.8266
[11/22 16:05:00 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.5901, average loss: 70.4725
[11/22 16:05:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.88	
[11/22 16:05:00 visual_prompt]: Training 37 / 100 epoch, with learning rate 40.391536883141455
[11/22 16:12:23 visual_prompt]: Epoch 37 / 100: avg data time: 4.89e+00, avg batch time: 6.3273, average train loss: 96.4561
[11/22 16:13:14 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.5907, average loss: 88.9703
[11/22 16:13:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 45.71	
[11/22 16:13:14 visual_prompt]: Stopping early.
[11/22 16:13:14 visual_prompt]: Rank of current process: 0. World size: 1
[11/22 16:13:14 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/22 16:13:14 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/22 16:13:14 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/22 16:13:14 visual_prompt]: Training with config:
[11/22 16:13:14 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr50.0_wd0.001/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 50.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/22 16:13:14 visual_prompt]: Loading training data...
[11/22 16:13:14 visual_prompt]: Constructing mammo-cbis dataset train...
[11/22 16:13:14 visual_prompt]: Loading validation data...
[11/22 16:13:14 visual_prompt]: Constructing mammo-cbis dataset val...
[11/22 16:13:14 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/22 16:13:17 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/22 16:13:17 visual_prompt]: tuned percent:0.532
[11/22 16:13:17 visual_prompt]: Device used for model: 0
[11/22 16:13:17 visual_prompt]: Setting up Evaluator...
[11/22 16:13:17 visual_prompt]: Setting up Trainer...
[11/22 16:13:17 visual_prompt]: 	Setting up the optimizer...
[11/22 16:13:17 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/22 16:20:41 visual_prompt]: Epoch 1 / 100: avg data time: 4.89e+00, avg batch time: 6.3436, average train loss: 1.4863
[11/22 16:21:31 visual_prompt]: Inference (val):avg data time: 2.05e-05, avg batch time: 0.5937, average loss: 1.4553
[11/22 16:21:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/22 16:21:31 visual_prompt]: Training 2 / 100 epoch, with learning rate 5.0
[11/22 16:28:54 visual_prompt]: Epoch 2 / 100: avg data time: 4.87e+00, avg batch time: 6.3197, average train loss: 29.6890
[11/22 16:29:44 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.5867, average loss: 4.8085
[11/22 16:29:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.82	
[11/22 16:29:44 visual_prompt]: Training 3 / 100 epoch, with learning rate 10.0
[11/22 16:37:07 visual_prompt]: Epoch 3 / 100: avg data time: 4.88e+00, avg batch time: 6.3283, average train loss: 28.3773
[11/22 16:37:57 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.5862, average loss: 36.1099
[11/22 16:37:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.14	
[11/22 16:37:58 visual_prompt]: Training 4 / 100 epoch, with learning rate 15.0
[11/22 16:45:18 visual_prompt]: Epoch 4 / 100: avg data time: 4.85e+00, avg batch time: 6.2964, average train loss: 28.7815
[11/22 16:46:09 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.5868, average loss: 28.0690
[11/22 16:46:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.59	
[11/22 16:46:09 visual_prompt]: Training 5 / 100 epoch, with learning rate 20.0
[11/22 16:53:30 visual_prompt]: Epoch 5 / 100: avg data time: 4.86e+00, avg batch time: 6.2990, average train loss: 37.3561
[11/22 16:54:20 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.5842, average loss: 105.6275
[11/22 16:54:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.50	
[11/22 16:54:20 visual_prompt]: Training 6 / 100 epoch, with learning rate 25.0
[11/22 17:02:03 visual_prompt]: Epoch 6 / 100: avg data time: 5.17e+00, avg batch time: 6.6119, average train loss: 49.8338
[11/22 17:02:55 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.5845, average loss: 79.5973
[11/22 17:02:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 41.72	
[11/22 17:02:55 visual_prompt]: Training 7 / 100 epoch, with learning rate 30.0
[11/22 17:10:23 visual_prompt]: Epoch 7 / 100: avg data time: 4.96e+00, avg batch time: 6.4044, average train loss: 76.3471
[11/22 17:11:14 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.5871, average loss: 59.3471
[11/22 17:11:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.57	
[11/22 17:11:14 visual_prompt]: Training 8 / 100 epoch, with learning rate 35.0
[11/22 17:18:37 visual_prompt]: Epoch 8 / 100: avg data time: 4.89e+00, avg batch time: 6.3270, average train loss: 121.1505
[11/22 17:19:27 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.5865, average loss: 242.3564
[11/22 17:19:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.41	
[11/22 17:19:27 visual_prompt]: Training 9 / 100 epoch, with learning rate 40.0
[11/22 17:26:51 visual_prompt]: Epoch 9 / 100: avg data time: 4.89e+00, avg batch time: 6.3329, average train loss: 98.8507
[11/22 17:27:41 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.5866, average loss: 265.9323
[11/22 17:27:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.62	
[11/22 17:27:41 visual_prompt]: Training 10 / 100 epoch, with learning rate 45.0
[11/22 17:35:07 visual_prompt]: Epoch 10 / 100: avg data time: 4.92e+00, avg batch time: 6.3629, average train loss: 108.4417
[11/22 17:35:57 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.5864, average loss: 25.7128
[11/22 17:35:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.06	
[11/22 17:35:57 visual_prompt]: Training 11 / 100 epoch, with learning rate 50.0
[11/22 17:43:20 visual_prompt]: Epoch 11 / 100: avg data time: 4.89e+00, avg batch time: 6.3339, average train loss: 86.0772
[11/22 17:44:11 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.5849, average loss: 233.3680
[11/22 17:44:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 45.84	
[11/22 17:44:11 visual_prompt]: Training 12 / 100 epoch, with learning rate 49.9847706754774
[11/22 17:51:33 visual_prompt]: Epoch 12 / 100: avg data time: 4.87e+00, avg batch time: 6.3158, average train loss: 125.8367
[11/22 17:52:24 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.5897, average loss: 3.7898
[11/22 17:52:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.28	
[11/22 17:52:24 visual_prompt]: Best epoch 12: best metric: -3.790
[11/22 17:52:24 visual_prompt]: Training 13 / 100 epoch, with learning rate 49.939101256495604
[11/22 17:59:48 visual_prompt]: Epoch 13 / 100: avg data time: 4.90e+00, avg batch time: 6.3408, average train loss: 145.2245
[11/22 18:00:39 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.5900, average loss: 16.6351
[11/22 18:00:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.75	
[11/22 18:00:39 visual_prompt]: Training 14 / 100 epoch, with learning rate 49.86304738420683
[11/22 18:08:00 visual_prompt]: Epoch 14 / 100: avg data time: 4.87e+00, avg batch time: 6.3084, average train loss: 130.2937
[11/22 18:08:52 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.5858, average loss: 52.4746
[11/22 18:08:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.90	
[11/22 18:08:52 visual_prompt]: Training 15 / 100 epoch, with learning rate 49.75670171853926
[11/22 18:16:13 visual_prompt]: Epoch 15 / 100: avg data time: 4.86e+00, avg batch time: 6.3025, average train loss: 80.5654
[11/22 18:17:03 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.5920, average loss: 43.1324
[11/22 18:17:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.08	
[11/22 18:17:03 visual_prompt]: Training 16 / 100 epoch, with learning rate 49.6201938253052
[11/22 18:24:25 visual_prompt]: Epoch 16 / 100: avg data time: 4.87e+00, avg batch time: 6.3140, average train loss: 106.6968
[11/22 18:25:17 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.5848, average loss: 337.7281
[11/22 18:25:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.76	
[11/22 18:25:17 visual_prompt]: Training 17 / 100 epoch, with learning rate 49.45369001834514
[11/22 18:32:41 visual_prompt]: Epoch 17 / 100: avg data time: 4.91e+00, avg batch time: 6.3511, average train loss: 128.5729
[11/22 18:33:32 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.5885, average loss: 380.2673
[11/22 18:33:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.12	
[11/22 18:33:32 visual_prompt]: Training 18 / 100 epoch, with learning rate 49.25739315689991
[11/22 18:40:56 visual_prompt]: Epoch 18 / 100: avg data time: 4.90e+00, avg batch time: 6.3345, average train loss: 109.7811
[11/22 18:41:47 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.5858, average loss: 17.9192
[11/22 18:41:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.66	
[11/22 18:41:47 visual_prompt]: Training 19 / 100 epoch, with learning rate 49.03154239845797
[11/22 18:49:08 visual_prompt]: Epoch 19 / 100: avg data time: 4.86e+00, avg batch time: 6.3066, average train loss: 130.5409
[11/22 18:50:00 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.5878, average loss: 84.5841
[11/22 18:50:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.71	
[11/22 18:50:00 visual_prompt]: Training 20 / 100 epoch, with learning rate 48.77641290737884
[11/22 18:57:24 visual_prompt]: Epoch 20 / 100: avg data time: 4.90e+00, avg batch time: 6.3406, average train loss: 92.9746
[11/22 18:58:15 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.5853, average loss: 141.7912
[11/22 18:58:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.49	
[11/22 18:58:15 visual_prompt]: Training 21 / 100 epoch, with learning rate 48.49231551964771
[11/22 19:05:38 visual_prompt]: Epoch 21 / 100: avg data time: 4.89e+00, avg batch time: 6.3353, average train loss: 93.9640
[11/22 19:06:29 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.5893, average loss: 143.8580
[11/22 19:06:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.35	
[11/22 19:06:29 visual_prompt]: Training 22 / 100 epoch, with learning rate 48.17959636416968
[11/22 19:13:54 visual_prompt]: Epoch 22 / 100: avg data time: 4.91e+00, avg batch time: 6.3460, average train loss: 108.6632
[11/22 19:14:44 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.5896, average loss: 164.8212
[11/22 19:14:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.19	
[11/22 19:14:44 visual_prompt]: Training 23 / 100 epoch, with learning rate 47.83863644106502
[11/22 19:22:12 visual_prompt]: Epoch 23 / 100: avg data time: 4.96e+00, avg batch time: 6.3955, average train loss: 147.8838
[11/22 19:23:03 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.5883, average loss: 4.1596
[11/22 19:23:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 35.92	
[11/22 19:23:03 visual_prompt]: Training 24 / 100 epoch, with learning rate 47.46985115747918
[11/22 19:30:28 visual_prompt]: Epoch 24 / 100: avg data time: 4.91e+00, avg batch time: 6.3544, average train loss: 131.2509
[11/22 19:31:18 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.5914, average loss: 268.7511
[11/22 19:31:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.99	
[11/22 19:31:18 visual_prompt]: Training 25 / 100 epoch, with learning rate 47.073689821473174
[11/22 19:38:42 visual_prompt]: Epoch 25 / 100: avg data time: 4.90e+00, avg batch time: 6.3404, average train loss: 89.2651
[11/22 19:39:33 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.5852, average loss: 16.8490
[11/22 19:39:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 44.50	
[11/22 19:39:33 visual_prompt]: Training 26 / 100 epoch, with learning rate 46.65063509461097
[11/22 19:46:57 visual_prompt]: Epoch 26 / 100: avg data time: 4.89e+00, avg batch time: 6.3347, average train loss: 109.7163
[11/22 19:47:47 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.5849, average loss: 135.4173
[11/22 19:47:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.60	
[11/22 19:47:47 visual_prompt]: Training 27 / 100 epoch, with learning rate 46.20120240391065
[11/22 19:55:09 visual_prompt]: Epoch 27 / 100: avg data time: 4.87e+00, avg batch time: 6.3075, average train loss: 133.6033
[11/22 19:55:59 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.5846, average loss: 17.3202
[11/22 19:55:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 48.78	rocauc: 47.23	
[11/22 19:55:59 visual_prompt]: Training 28 / 100 epoch, with learning rate 45.72593931387604
[11/22 20:03:22 visual_prompt]: Epoch 28 / 100: avg data time: 4.89e+00, avg batch time: 6.3266, average train loss: 133.9062
[11/22 20:04:13 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.5833, average loss: 169.7275
[11/22 20:04:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.08	
[11/22 20:04:13 visual_prompt]: Training 29 / 100 epoch, with learning rate 45.22542485937369
[11/22 20:11:35 visual_prompt]: Epoch 29 / 100: avg data time: 4.88e+00, avg batch time: 6.3237, average train loss: 107.2097
[11/22 20:12:26 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.5909, average loss: 277.7167
[11/22 20:12:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.66	
[11/22 20:12:26 visual_prompt]: Training 30 / 100 epoch, with learning rate 44.70026884016804
[11/22 20:19:50 visual_prompt]: Epoch 30 / 100: avg data time: 4.90e+00, avg batch time: 6.3428, average train loss: 101.4560
[11/22 20:20:40 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.5886, average loss: 74.6420
[11/22 20:20:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.95	
[11/22 20:20:40 visual_prompt]: Training 31 / 100 epoch, with learning rate 44.15111107797445
[11/22 20:28:02 visual_prompt]: Epoch 31 / 100: avg data time: 4.86e+00, avg batch time: 6.3019, average train loss: 124.6804
[11/22 20:28:52 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.5856, average loss: 6.7570
[11/22 20:28:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.40	
[11/22 20:28:52 visual_prompt]: Training 32 / 100 epoch, with learning rate 43.57862063693486
[11/22 20:36:15 visual_prompt]: Epoch 32 / 100: avg data time: 4.88e+00, avg batch time: 6.3219, average train loss: 107.6275
[11/22 20:37:05 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.5890, average loss: 32.8927
[11/22 20:37:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 44.52	
[11/22 20:37:05 visual_prompt]: Training 33 / 100 epoch, with learning rate 42.98349500846628
[11/22 20:44:27 visual_prompt]: Epoch 33 / 100: avg data time: 4.87e+00, avg batch time: 6.3155, average train loss: 136.6128
[11/22 20:45:19 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.5891, average loss: 96.4105
[11/22 20:45:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.28	
[11/22 20:45:19 visual_prompt]: Stopping early.
[11/22 20:45:19 visual_prompt]: Rank of current process: 0. World size: 1
[11/22 20:45:19 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/22 20:45:19 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/22 20:45:19 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/22 20:45:19 visual_prompt]: Training with config:
[11/22 20:45:19 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr50.0_wd0.0001/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 50.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/22 20:45:19 visual_prompt]: Loading training data...
[11/22 20:45:19 visual_prompt]: Constructing mammo-cbis dataset train...
[11/22 20:45:19 visual_prompt]: Loading validation data...
[11/22 20:45:19 visual_prompt]: Constructing mammo-cbis dataset val...
[11/22 20:45:19 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/22 20:45:21 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/22 20:45:21 visual_prompt]: tuned percent:0.532
[11/22 20:45:21 visual_prompt]: Device used for model: 0
[11/22 20:45:21 visual_prompt]: Setting up Evaluator...
[11/22 20:45:21 visual_prompt]: Setting up Trainer...
[11/22 20:45:21 visual_prompt]: 	Setting up the optimizer...
[11/22 20:45:21 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/22 20:52:44 visual_prompt]: Epoch 1 / 100: avg data time: 4.87e+00, avg batch time: 6.3259, average train loss: 1.4863
[11/22 20:53:35 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.5901, average loss: 1.4553
[11/22 20:53:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/22 20:53:35 visual_prompt]: Training 2 / 100 epoch, with learning rate 5.0
[11/22 21:00:57 visual_prompt]: Epoch 2 / 100: avg data time: 4.87e+00, avg batch time: 6.3170, average train loss: 20.3780
[11/22 21:01:48 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.5841, average loss: 5.1255
[11/22 21:01:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.29	
[11/22 21:01:48 visual_prompt]: Training 3 / 100 epoch, with learning rate 10.0
[11/22 21:09:09 visual_prompt]: Epoch 3 / 100: avg data time: 4.85e+00, avg batch time: 6.2983, average train loss: 22.9462
[11/22 21:10:00 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.5895, average loss: 23.8554
[11/22 21:10:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.59	
[11/22 21:10:00 visual_prompt]: Training 4 / 100 epoch, with learning rate 15.0
[11/22 21:17:23 visual_prompt]: Epoch 4 / 100: avg data time: 4.88e+00, avg batch time: 6.3241, average train loss: 30.8549
[11/22 21:18:13 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.5832, average loss: 40.9484
[11/22 21:18:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.05	
[11/22 21:18:13 visual_prompt]: Training 5 / 100 epoch, with learning rate 20.0
[11/22 21:25:35 visual_prompt]: Epoch 5 / 100: avg data time: 4.86e+00, avg batch time: 6.3101, average train loss: 39.4185
[11/22 21:26:26 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.5842, average loss: 25.5446
[11/22 21:26:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.95	
[11/22 21:26:26 visual_prompt]: Training 6 / 100 epoch, with learning rate 25.0
[11/22 21:33:49 visual_prompt]: Epoch 6 / 100: avg data time: 4.90e+00, avg batch time: 6.3390, average train loss: 55.9571
[11/22 21:34:40 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.5856, average loss: 104.3030
[11/22 21:34:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.10	
[11/22 21:34:40 visual_prompt]: Training 7 / 100 epoch, with learning rate 30.0
[11/22 21:42:02 visual_prompt]: Epoch 7 / 100: avg data time: 4.87e+00, avg batch time: 6.3107, average train loss: 45.2455
[11/22 21:42:53 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.5850, average loss: 79.2160
[11/22 21:42:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.91	
[11/22 21:42:53 visual_prompt]: Training 8 / 100 epoch, with learning rate 35.0
[11/22 21:50:17 visual_prompt]: Epoch 8 / 100: avg data time: 4.90e+00, avg batch time: 6.3428, average train loss: 65.1711
[11/22 21:51:07 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.5873, average loss: 14.0736
[11/22 21:51:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 45.57	
[11/22 21:51:07 visual_prompt]: Training 9 / 100 epoch, with learning rate 40.0
[11/22 21:58:30 visual_prompt]: Epoch 9 / 100: avg data time: 4.88e+00, avg batch time: 6.3197, average train loss: 54.6180
[11/22 21:59:20 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.5854, average loss: 82.0216
[11/22 21:59:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.68	
[11/22 21:59:20 visual_prompt]: Training 10 / 100 epoch, with learning rate 45.0
[11/22 22:06:44 visual_prompt]: Epoch 10 / 100: avg data time: 4.90e+00, avg batch time: 6.3451, average train loss: 86.8197
[11/22 22:07:36 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.5857, average loss: 59.5717
[11/22 22:07:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 44.88	
[11/22 22:07:36 visual_prompt]: Training 11 / 100 epoch, with learning rate 50.0
[11/22 22:15:01 visual_prompt]: Epoch 11 / 100: avg data time: 4.92e+00, avg batch time: 6.3608, average train loss: 96.6974
[11/22 22:15:52 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.5907, average loss: 84.8839
[11/22 22:15:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.14	
[11/22 22:15:52 visual_prompt]: Training 12 / 100 epoch, with learning rate 49.9847706754774
[11/22 22:23:16 visual_prompt]: Epoch 12 / 100: avg data time: 4.90e+00, avg batch time: 6.3427, average train loss: 110.2374
[11/22 22:24:06 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.5857, average loss: 40.7016
[11/22 22:24:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 45.03	
[11/22 22:24:06 visual_prompt]: Best epoch 12: best metric: -40.702
[11/22 22:24:06 visual_prompt]: Training 13 / 100 epoch, with learning rate 49.939101256495604
[11/22 22:31:28 visual_prompt]: Epoch 13 / 100: avg data time: 4.87e+00, avg batch time: 6.3148, average train loss: 82.8512
[11/22 22:32:19 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.5892, average loss: 42.2964
[11/22 22:32:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.54	
[11/22 22:32:19 visual_prompt]: Training 14 / 100 epoch, with learning rate 49.86304738420683
[11/22 22:39:42 visual_prompt]: Epoch 14 / 100: avg data time: 4.88e+00, avg batch time: 6.3200, average train loss: 186.6293
[11/22 22:40:32 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.5836, average loss: 151.4444
[11/22 22:40:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.88	
[11/22 22:40:32 visual_prompt]: Training 15 / 100 epoch, with learning rate 49.75670171853926
[11/22 22:47:57 visual_prompt]: Epoch 15 / 100: avg data time: 4.91e+00, avg batch time: 6.3486, average train loss: 126.1228
[11/22 22:48:48 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.5854, average loss: 54.1846
[11/22 22:48:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.20	
[11/22 22:48:48 visual_prompt]: Training 16 / 100 epoch, with learning rate 49.6201938253052
[11/22 22:56:12 visual_prompt]: Epoch 16 / 100: avg data time: 4.90e+00, avg batch time: 6.3404, average train loss: 77.2475
[11/22 22:57:02 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.5902, average loss: 147.1842
[11/22 22:57:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.70	
[11/22 22:57:02 visual_prompt]: Training 17 / 100 epoch, with learning rate 49.45369001834514
[11/22 23:04:24 visual_prompt]: Epoch 17 / 100: avg data time: 4.87e+00, avg batch time: 6.3086, average train loss: 69.4608
[11/22 23:05:14 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.5872, average loss: 224.6104
[11/22 23:05:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.21	
[11/22 23:05:14 visual_prompt]: Training 18 / 100 epoch, with learning rate 49.25739315689991
[11/22 23:12:37 visual_prompt]: Epoch 18 / 100: avg data time: 4.88e+00, avg batch time: 6.3253, average train loss: 107.6016
[11/22 23:13:28 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.5878, average loss: 28.3802
[11/22 23:13:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.00	
[11/22 23:13:28 visual_prompt]: Best epoch 18: best metric: -28.380
[11/22 23:13:28 visual_prompt]: Training 19 / 100 epoch, with learning rate 49.03154239845797
[11/22 23:20:48 visual_prompt]: Epoch 19 / 100: avg data time: 4.85e+00, avg batch time: 6.2919, average train loss: 73.0924
[11/22 23:21:39 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.5878, average loss: 5.8467
[11/22 23:21:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.44	
[11/22 23:21:39 visual_prompt]: Best epoch 19: best metric: -5.847
[11/22 23:21:39 visual_prompt]: Training 20 / 100 epoch, with learning rate 48.77641290737884
[11/22 23:29:02 visual_prompt]: Epoch 20 / 100: avg data time: 4.89e+00, avg batch time: 6.3282, average train loss: 92.2818
[11/22 23:29:54 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.5846, average loss: 147.1998
[11/22 23:29:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.43	
[11/22 23:29:54 visual_prompt]: Training 21 / 100 epoch, with learning rate 48.49231551964771
[11/22 23:37:24 visual_prompt]: Epoch 21 / 100: avg data time: 5.00e+00, avg batch time: 6.4320, average train loss: 113.5255
[11/22 23:38:15 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.5873, average loss: 59.1547
[11/22 23:38:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.86	
[11/22 23:38:15 visual_prompt]: Training 22 / 100 epoch, with learning rate 48.17959636416968
[11/22 23:45:46 visual_prompt]: Epoch 22 / 100: avg data time: 4.99e+00, avg batch time: 6.4366, average train loss: 91.3612
[11/22 23:46:37 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.5869, average loss: 10.5461
[11/22 23:46:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.10	
[11/22 23:46:37 visual_prompt]: Training 23 / 100 epoch, with learning rate 47.83863644106502
[11/22 23:54:07 visual_prompt]: Epoch 23 / 100: avg data time: 4.99e+00, avg batch time: 6.4254, average train loss: 133.1470
[11/22 23:54:59 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.5890, average loss: 85.4615
[11/22 23:54:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.47	
[11/22 23:54:59 visual_prompt]: Training 24 / 100 epoch, with learning rate 47.46985115747918
[11/23 00:02:29 visual_prompt]: Epoch 24 / 100: avg data time: 4.99e+00, avg batch time: 6.4279, average train loss: 80.1999
[11/23 00:03:20 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.5857, average loss: 3.8078
[11/23 00:03:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.12	
[11/23 00:03:20 visual_prompt]: Best epoch 24: best metric: -3.808
[11/23 00:03:20 visual_prompt]: Training 25 / 100 epoch, with learning rate 47.073689821473174
[11/23 00:10:51 visual_prompt]: Epoch 25 / 100: avg data time: 5.00e+00, avg batch time: 6.4354, average train loss: 122.6318
[11/23 00:11:42 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.5901, average loss: 156.8054
[11/23 00:11:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.67	
[11/23 00:11:42 visual_prompt]: Training 26 / 100 epoch, with learning rate 46.65063509461097
[11/23 00:19:11 visual_prompt]: Epoch 26 / 100: avg data time: 4.97e+00, avg batch time: 6.4080, average train loss: 93.7701
[11/23 00:20:02 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.5837, average loss: 10.4415
[11/23 00:20:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.47	
[11/23 00:20:02 visual_prompt]: Training 27 / 100 epoch, with learning rate 46.20120240391065
[11/23 00:27:31 visual_prompt]: Epoch 27 / 100: avg data time: 4.96e+00, avg batch time: 6.4043, average train loss: 93.0354
[11/23 00:28:22 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.5901, average loss: 173.7292
[11/23 00:28:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.06	
[11/23 00:28:22 visual_prompt]: Training 28 / 100 epoch, with learning rate 45.72593931387604
[11/23 00:35:52 visual_prompt]: Epoch 28 / 100: avg data time: 4.99e+00, avg batch time: 6.4308, average train loss: 98.3128
[11/23 00:36:44 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.5884, average loss: 115.2049
[11/23 00:36:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.74	
[11/23 00:36:44 visual_prompt]: Training 29 / 100 epoch, with learning rate 45.22542485937369
[11/23 00:44:14 visual_prompt]: Epoch 29 / 100: avg data time: 4.99e+00, avg batch time: 6.4292, average train loss: 92.3197
[11/23 00:45:05 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.5929, average loss: 208.0735
[11/23 00:45:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.10	
[11/23 00:45:05 visual_prompt]: Training 30 / 100 epoch, with learning rate 44.70026884016804
[11/23 00:52:35 visual_prompt]: Epoch 30 / 100: avg data time: 4.98e+00, avg batch time: 6.4225, average train loss: 117.8638
[11/23 00:53:26 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.5867, average loss: 151.8972
[11/23 00:53:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.73	
[11/23 00:53:26 visual_prompt]: Training 31 / 100 epoch, with learning rate 44.15111107797445
[11/23 01:00:55 visual_prompt]: Epoch 31 / 100: avg data time: 4.97e+00, avg batch time: 6.4098, average train loss: 136.5047
[11/23 01:01:47 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.5859, average loss: 18.3430
[11/23 01:01:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.27	
[11/23 01:01:47 visual_prompt]: Training 32 / 100 epoch, with learning rate 43.57862063693486
[11/23 01:09:16 visual_prompt]: Epoch 32 / 100: avg data time: 4.98e+00, avg batch time: 6.4213, average train loss: 64.2359
[11/23 01:10:08 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.5843, average loss: 106.8584
[11/23 01:10:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.53	
[11/23 01:10:08 visual_prompt]: Training 33 / 100 epoch, with learning rate 42.98349500846628
[11/23 01:17:31 visual_prompt]: Epoch 33 / 100: avg data time: 4.89e+00, avg batch time: 6.3362, average train loss: 94.7470
[11/23 01:18:22 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.5883, average loss: 178.2198
[11/23 01:18:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.42	
[11/23 01:18:22 visual_prompt]: Training 34 / 100 epoch, with learning rate 42.36645926147493
[11/23 01:25:43 visual_prompt]: Epoch 34 / 100: avg data time: 4.86e+00, avg batch time: 6.3019, average train loss: 105.6765
[11/23 01:26:33 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.5861, average loss: 11.9395
[11/23 01:26:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.11	
[11/23 01:26:33 visual_prompt]: Training 35 / 100 epoch, with learning rate 41.72826515897145
[11/23 01:33:57 visual_prompt]: Epoch 35 / 100: avg data time: 4.90e+00, avg batch time: 6.3358, average train loss: 119.8641
[11/23 01:34:48 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.5880, average loss: 197.5336
[11/23 01:34:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.46	
[11/23 01:34:48 visual_prompt]: Training 36 / 100 epoch, with learning rate 41.06969024216348
[11/23 01:42:12 visual_prompt]: Epoch 36 / 100: avg data time: 4.91e+00, avg batch time: 6.3471, average train loss: 78.3067
[11/23 01:43:03 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.5886, average loss: 3.5021
[11/23 01:43:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 44.31	rocauc: 46.27	
[11/23 01:43:03 visual_prompt]: Best epoch 36: best metric: -3.502
[11/23 01:43:03 visual_prompt]: Training 37 / 100 epoch, with learning rate 40.391536883141455
[11/23 01:50:27 visual_prompt]: Epoch 37 / 100: avg data time: 4.89e+00, avg batch time: 6.3394, average train loss: 75.9535
[11/23 01:51:18 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.5877, average loss: 67.3251
[11/23 01:51:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.24	
[11/23 01:51:18 visual_prompt]: Training 38 / 100 epoch, with learning rate 39.69463130731183
[11/23 01:58:40 visual_prompt]: Epoch 38 / 100: avg data time: 4.88e+00, avg batch time: 6.3216, average train loss: 48.9238
[11/23 01:59:31 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.5896, average loss: 80.9727
[11/23 01:59:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.82	
[11/23 01:59:31 visual_prompt]: Training 39 / 100 epoch, with learning rate 38.97982258676867
[11/23 02:06:55 visual_prompt]: Epoch 39 / 100: avg data time: 4.90e+00, avg batch time: 6.3453, average train loss: 88.0498
[11/23 02:07:46 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.5864, average loss: 72.4487
[11/23 02:07:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 44.85	
[11/23 02:07:46 visual_prompt]: Training 40 / 100 epoch, with learning rate 38.24798160583012
[11/23 02:15:09 visual_prompt]: Epoch 40 / 100: avg data time: 4.89e+00, avg batch time: 6.3319, average train loss: 58.7556
[11/23 02:16:00 visual_prompt]: Inference (val):avg data time: 2.03e-03, avg batch time: 0.5863, average loss: 11.0629
[11/23 02:16:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.60	
[11/23 02:16:00 visual_prompt]: Training 41 / 100 epoch, with learning rate 37.5
[11/23 02:23:23 visual_prompt]: Epoch 41 / 100: avg data time: 4.89e+00, avg batch time: 6.3301, average train loss: 50.7774
[11/23 02:24:14 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.5859, average loss: 67.7956
[11/23 02:24:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.24	
[11/23 02:24:14 visual_prompt]: Training 42 / 100 epoch, with learning rate 36.736789069647266
[11/23 02:31:37 visual_prompt]: Epoch 42 / 100: avg data time: 4.89e+00, avg batch time: 6.3279, average train loss: 83.1322
[11/23 02:32:27 visual_prompt]: Inference (val):avg data time: 1.24e-04, avg batch time: 0.5887, average loss: 175.8947
[11/23 02:32:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 44.14	
[11/23 02:32:27 visual_prompt]: Training 43 / 100 epoch, with learning rate 35.959278669726935
[11/23 02:39:53 visual_prompt]: Epoch 43 / 100: avg data time: 4.93e+00, avg batch time: 6.3691, average train loss: 83.4012
[11/23 02:40:44 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.5880, average loss: 187.2698
[11/23 02:40:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.43	
[11/23 02:40:44 visual_prompt]: Training 44 / 100 epoch, with learning rate 35.16841607689501
[11/23 02:48:08 visual_prompt]: Epoch 44 / 100: avg data time: 4.90e+00, avg batch time: 6.3365, average train loss: 70.3138
[11/23 02:48:58 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.5922, average loss: 100.1013
[11/23 02:48:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 45.89	
[11/23 02:48:58 visual_prompt]: Training 45 / 100 epoch, with learning rate 34.365164835397806
[11/23 02:56:22 visual_prompt]: Epoch 45 / 100: avg data time: 4.90e+00, avg batch time: 6.3391, average train loss: 63.3193
[11/23 02:57:13 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.5886, average loss: 5.9979
[11/23 02:57:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.27	
[11/23 02:57:13 visual_prompt]: Training 46 / 100 epoch, with learning rate 33.55050358314172
[11/23 03:04:35 visual_prompt]: Epoch 46 / 100: avg data time: 4.87e+00, avg batch time: 6.3152, average train loss: 57.3201
[11/23 03:05:25 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.5847, average loss: 44.7624
[11/23 03:05:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 42.64	
[11/23 03:05:25 visual_prompt]: Training 47 / 100 epoch, with learning rate 32.72542485937369
[11/23 03:12:48 visual_prompt]: Epoch 47 / 100: avg data time: 4.89e+00, avg batch time: 6.3289, average train loss: 57.2510
[11/23 03:13:39 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.5914, average loss: 8.4430
[11/23 03:13:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.11	
[11/23 03:13:39 visual_prompt]: Training 48 / 100 epoch, with learning rate 31.89093389542498
[11/23 03:20:59 visual_prompt]: Epoch 48 / 100: avg data time: 4.85e+00, avg batch time: 6.2934, average train loss: 52.1243
[11/23 03:21:50 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.5896, average loss: 52.3113
[11/23 03:21:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.63	
[11/23 03:21:50 visual_prompt]: Training 49 / 100 epoch, with learning rate 31.04804738999169
[11/23 03:29:12 visual_prompt]: Epoch 49 / 100: avg data time: 4.87e+00, avg batch time: 6.3215, average train loss: 42.0767
[11/23 03:30:03 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.5886, average loss: 38.1934
[11/23 03:30:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.29	
[11/23 03:30:03 visual_prompt]: Training 50 / 100 epoch, with learning rate 30.19779227044398
[11/23 03:37:26 visual_prompt]: Epoch 50 / 100: avg data time: 4.89e+00, avg batch time: 6.3234, average train loss: 97.6234
[11/23 03:38:17 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.5863, average loss: 148.9838
[11/23 03:38:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.77	
[11/23 03:38:17 visual_prompt]: Training 51 / 100 epoch, with learning rate 29.341204441673263
[11/23 03:45:38 visual_prompt]: Epoch 51 / 100: avg data time: 4.87e+00, avg batch time: 6.3091, average train loss: 46.9198
[11/23 03:46:29 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.5869, average loss: 95.2465
[11/23 03:46:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 61.53	
[11/23 03:46:29 visual_prompt]: Training 52 / 100 epoch, with learning rate 28.479327524001636
[11/23 03:53:54 visual_prompt]: Epoch 52 / 100: avg data time: 4.91e+00, avg batch time: 6.3505, average train loss: 53.4680
[11/23 03:54:44 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.5858, average loss: 74.4442
[11/23 03:54:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.80	
[11/23 03:54:44 visual_prompt]: Training 53 / 100 epoch, with learning rate 27.61321158169134
[11/23 04:02:08 visual_prompt]: Epoch 53 / 100: avg data time: 4.89e+00, avg batch time: 6.3406, average train loss: 36.1559
[11/23 04:02:58 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.5916, average loss: 29.0806
[11/23 04:02:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.60	
[11/23 04:02:58 visual_prompt]: Training 54 / 100 epoch, with learning rate 26.74391184360313
[11/23 04:10:20 visual_prompt]: Epoch 54 / 100: avg data time: 4.86e+00, avg batch time: 6.3062, average train loss: 58.0513
[11/23 04:11:11 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.5864, average loss: 73.3476
[11/23 04:11:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.51	
[11/23 04:11:11 visual_prompt]: Training 55 / 100 epoch, with learning rate 25.872487417562528
[11/23 04:18:33 visual_prompt]: Epoch 55 / 100: avg data time: 4.88e+00, avg batch time: 6.3195, average train loss: 57.5813
[11/23 04:19:24 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.5825, average loss: 33.6108
[11/23 04:19:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.95	
[11/23 04:19:24 visual_prompt]: Training 56 / 100 epoch, with learning rate 25.0
[11/23 04:26:44 visual_prompt]: Epoch 56 / 100: avg data time: 4.85e+00, avg batch time: 6.2935, average train loss: 44.6864
[11/23 04:27:35 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.5877, average loss: 52.2001
[11/23 04:27:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.65	
[11/23 04:27:35 visual_prompt]: Training 57 / 100 epoch, with learning rate 24.127512582437483
[11/23 04:35:01 visual_prompt]: Epoch 57 / 100: avg data time: 4.93e+00, avg batch time: 6.3709, average train loss: 53.5879
[11/23 04:35:52 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.5872, average loss: 6.1235
[11/23 04:35:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.01	
[11/23 04:35:52 visual_prompt]: Stopping early.
[11/23 04:35:52 visual_prompt]: Rank of current process: 0. World size: 1
[11/23 04:35:52 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/23 04:35:52 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/23 04:35:52 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/23 04:35:52 visual_prompt]: Training with config:
[11/23 04:35:52 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr50.0_wd0.0/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 50.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/23 04:35:52 visual_prompt]: Loading training data...
[11/23 04:35:52 visual_prompt]: Constructing mammo-cbis dataset train...
[11/23 04:35:52 visual_prompt]: Loading validation data...
[11/23 04:35:52 visual_prompt]: Constructing mammo-cbis dataset val...
[11/23 04:35:52 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/23 04:35:55 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/23 04:35:55 visual_prompt]: tuned percent:0.532
[11/23 04:35:55 visual_prompt]: Device used for model: 0
[11/23 04:35:55 visual_prompt]: Setting up Evaluator...
[11/23 04:35:55 visual_prompt]: Setting up Trainer...
[11/23 04:35:55 visual_prompt]: 	Setting up the optimizer...
[11/23 04:35:55 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/23 04:43:20 visual_prompt]: Epoch 1 / 100: avg data time: 4.90e+00, avg batch time: 6.3493, average train loss: 1.4863
[11/23 04:44:10 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.5881, average loss: 1.4553
[11/23 04:44:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/23 04:44:10 visual_prompt]: Training 2 / 100 epoch, with learning rate 5.0
[11/23 04:51:34 visual_prompt]: Epoch 2 / 100: avg data time: 4.88e+00, avg batch time: 6.3287, average train loss: 18.7267
[11/23 04:52:24 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.5855, average loss: 23.8607
[11/23 04:52:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.63	
[11/23 04:52:24 visual_prompt]: Training 3 / 100 epoch, with learning rate 10.0
[11/23 04:59:45 visual_prompt]: Epoch 3 / 100: avg data time: 4.85e+00, avg batch time: 6.3005, average train loss: 27.0763
[11/23 05:00:36 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.5895, average loss: 39.5016
[11/23 05:00:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.12	
[11/23 05:00:36 visual_prompt]: Training 4 / 100 epoch, with learning rate 15.0
[11/23 05:07:59 visual_prompt]: Epoch 4 / 100: avg data time: 4.88e+00, avg batch time: 6.3227, average train loss: 57.2564
[11/23 05:08:49 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.5890, average loss: 68.3047
[11/23 05:08:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.11	
[11/23 05:08:49 visual_prompt]: Training 5 / 100 epoch, with learning rate 20.0
[11/23 05:16:12 visual_prompt]: Epoch 5 / 100: avg data time: 4.88e+00, avg batch time: 6.3233, average train loss: 41.7823
[11/23 05:17:03 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.5889, average loss: 11.4361
[11/23 05:17:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.89	
[11/23 05:17:03 visual_prompt]: Training 6 / 100 epoch, with learning rate 25.0
[11/23 05:24:26 visual_prompt]: Epoch 6 / 100: avg data time: 4.90e+00, avg batch time: 6.3390, average train loss: 46.3878
[11/23 05:25:17 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.5858, average loss: 47.0229
[11/23 05:25:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.44	
[11/23 05:25:17 visual_prompt]: Training 7 / 100 epoch, with learning rate 30.0
[11/23 05:32:38 visual_prompt]: Epoch 7 / 100: avg data time: 4.86e+00, avg batch time: 6.2988, average train loss: 49.5998
[11/23 05:33:28 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.5855, average loss: 149.5717
[11/23 05:33:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.98	
[11/23 05:33:28 visual_prompt]: Training 8 / 100 epoch, with learning rate 35.0
[11/23 05:40:51 visual_prompt]: Epoch 8 / 100: avg data time: 4.88e+00, avg batch time: 6.3212, average train loss: 78.7175
[11/23 05:41:42 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.5863, average loss: 57.6138
[11/23 05:41:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.23	
[11/23 05:41:42 visual_prompt]: Training 9 / 100 epoch, with learning rate 40.0
[11/23 05:49:06 visual_prompt]: Epoch 9 / 100: avg data time: 4.90e+00, avg batch time: 6.3403, average train loss: 46.2650
[11/23 05:49:56 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.5863, average loss: 84.5307
[11/23 05:49:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.37	
[11/23 05:49:56 visual_prompt]: Training 10 / 100 epoch, with learning rate 45.0
[11/23 05:57:21 visual_prompt]: Epoch 10 / 100: avg data time: 4.90e+00, avg batch time: 6.3546, average train loss: 92.3278
[11/23 05:58:12 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.5863, average loss: 27.6195
[11/23 05:58:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.81	
[11/23 05:58:12 visual_prompt]: Training 11 / 100 epoch, with learning rate 50.0
[11/23 06:05:36 visual_prompt]: Epoch 11 / 100: avg data time: 4.90e+00, avg batch time: 6.3397, average train loss: 122.7208
[11/23 06:06:27 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.5852, average loss: 6.6309
[11/23 06:06:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.26	
[11/23 06:06:27 visual_prompt]: Training 12 / 100 epoch, with learning rate 49.9847706754774
[11/23 06:13:47 visual_prompt]: Epoch 12 / 100: avg data time: 4.84e+00, avg batch time: 6.2844, average train loss: 94.4580
[11/23 06:14:38 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.5854, average loss: 44.9683
[11/23 06:14:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.02	
[11/23 06:14:38 visual_prompt]: Training 13 / 100 epoch, with learning rate 49.939101256495604
[11/23 06:22:01 visual_prompt]: Epoch 13 / 100: avg data time: 4.90e+00, avg batch time: 6.3324, average train loss: 119.3497
[11/23 06:22:51 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.5867, average loss: 8.7367
[11/23 06:22:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.11	
[11/23 06:22:51 visual_prompt]: Training 14 / 100 epoch, with learning rate 49.86304738420683
[11/23 06:30:13 visual_prompt]: Epoch 14 / 100: avg data time: 4.86e+00, avg batch time: 6.3018, average train loss: 87.4063
[11/23 06:31:04 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.5861, average loss: 76.1077
[11/23 06:31:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.35	
[11/23 06:31:04 visual_prompt]: Training 15 / 100 epoch, with learning rate 49.75670171853926
[11/23 06:38:26 visual_prompt]: Epoch 15 / 100: avg data time: 4.87e+00, avg batch time: 6.3200, average train loss: 51.3531
[11/23 06:39:16 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.5845, average loss: 67.2423
[11/23 06:39:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.65	
[11/23 06:39:16 visual_prompt]: Training 16 / 100 epoch, with learning rate 49.6201938253052
[11/23 06:46:38 visual_prompt]: Epoch 16 / 100: avg data time: 4.86e+00, avg batch time: 6.3050, average train loss: 78.9950
[11/23 06:47:28 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.5886, average loss: 27.0773
[11/23 06:47:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.69	
[11/23 06:47:28 visual_prompt]: Training 17 / 100 epoch, with learning rate 49.45369001834514
[11/23 06:54:50 visual_prompt]: Epoch 17 / 100: avg data time: 4.86e+00, avg batch time: 6.3046, average train loss: 26.5004
[11/23 06:55:40 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.5877, average loss: 108.9821
[11/23 06:55:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.59	
[11/23 06:55:40 visual_prompt]: Training 18 / 100 epoch, with learning rate 49.25739315689991
[11/23 07:03:01 visual_prompt]: Epoch 18 / 100: avg data time: 4.85e+00, avg batch time: 6.2908, average train loss: 62.2150
[11/23 07:03:51 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.5868, average loss: 8.0574
[11/23 07:03:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.43	
[11/23 07:03:51 visual_prompt]: Training 19 / 100 epoch, with learning rate 49.03154239845797
[11/23 07:11:13 visual_prompt]: Epoch 19 / 100: avg data time: 4.87e+00, avg batch time: 6.3103, average train loss: 66.2149
[11/23 07:12:04 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.5853, average loss: 3.2948
[11/23 07:12:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.62	
[11/23 07:12:04 visual_prompt]: Best epoch 19: best metric: -3.295
[11/23 07:12:04 visual_prompt]: Training 20 / 100 epoch, with learning rate 48.77641290737884
[11/23 07:19:28 visual_prompt]: Epoch 20 / 100: avg data time: 4.90e+00, avg batch time: 6.3408, average train loss: 44.9275
[11/23 07:20:18 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.5896, average loss: 16.6158
[11/23 07:20:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.74	
[11/23 07:20:18 visual_prompt]: Training 21 / 100 epoch, with learning rate 48.49231551964771
[11/23 07:27:40 visual_prompt]: Epoch 21 / 100: avg data time: 4.87e+00, avg batch time: 6.3091, average train loss: 64.0591
[11/23 07:28:31 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.5878, average loss: 24.9053
[11/23 07:28:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.12	
[11/23 07:28:31 visual_prompt]: Training 22 / 100 epoch, with learning rate 48.17959636416968
[11/23 07:35:52 visual_prompt]: Epoch 22 / 100: avg data time: 4.87e+00, avg batch time: 6.3052, average train loss: 47.1782
[11/23 07:36:43 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.5855, average loss: 70.3440
[11/23 07:36:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.75	
[11/23 07:36:43 visual_prompt]: Training 23 / 100 epoch, with learning rate 47.83863644106502
[11/23 07:44:06 visual_prompt]: Epoch 23 / 100: avg data time: 4.88e+00, avg batch time: 6.3253, average train loss: 37.2159
[11/23 07:44:56 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.5863, average loss: 12.5568
[11/23 07:44:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.42	
[11/23 07:44:56 visual_prompt]: Training 24 / 100 epoch, with learning rate 47.46985115747918
[11/23 07:52:18 visual_prompt]: Epoch 24 / 100: avg data time: 4.86e+00, avg batch time: 6.3077, average train loss: 41.6032
[11/23 07:53:08 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.5862, average loss: 8.8968
[11/23 07:53:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.66	
[11/23 07:53:08 visual_prompt]: Training 25 / 100 epoch, with learning rate 47.073689821473174
[11/23 08:00:30 visual_prompt]: Epoch 25 / 100: avg data time: 4.87e+00, avg batch time: 6.3134, average train loss: 51.7500
[11/23 08:01:21 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.5934, average loss: 13.4114
[11/23 08:01:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.85	
[11/23 08:01:21 visual_prompt]: Training 26 / 100 epoch, with learning rate 46.65063509461097
[11/23 08:08:43 visual_prompt]: Epoch 26 / 100: avg data time: 4.86e+00, avg batch time: 6.3186, average train loss: 25.6396
[11/23 08:09:34 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.5897, average loss: 36.6733
[11/23 08:09:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 61.39	
[11/23 08:09:34 visual_prompt]: Training 27 / 100 epoch, with learning rate 46.20120240391065
[11/23 08:16:55 visual_prompt]: Epoch 27 / 100: avg data time: 4.85e+00, avg batch time: 6.2960, average train loss: 38.7008
[11/23 08:17:45 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.5849, average loss: 56.9118
[11/23 08:17:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.70	
[11/23 08:17:45 visual_prompt]: Training 28 / 100 epoch, with learning rate 45.72593931387604
[11/23 08:25:07 visual_prompt]: Epoch 28 / 100: avg data time: 4.87e+00, avg batch time: 6.3142, average train loss: 57.5679
[11/23 08:25:58 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.5842, average loss: 22.7835
[11/23 08:25:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.64	
[11/23 08:25:58 visual_prompt]: Training 29 / 100 epoch, with learning rate 45.22542485937369
[11/23 08:33:19 visual_prompt]: Epoch 29 / 100: avg data time: 4.86e+00, avg batch time: 6.2981, average train loss: 59.0418
[11/23 08:34:10 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.5865, average loss: 72.1700
[11/23 08:34:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.84	
[11/23 08:34:10 visual_prompt]: Training 30 / 100 epoch, with learning rate 44.70026884016804
[11/23 08:41:33 visual_prompt]: Epoch 30 / 100: avg data time: 4.89e+00, avg batch time: 6.3375, average train loss: 39.6449
[11/23 08:42:24 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.5877, average loss: 62.3798
[11/23 08:42:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.16	
[11/23 08:42:24 visual_prompt]: Training 31 / 100 epoch, with learning rate 44.15111107797445
[11/23 08:49:46 visual_prompt]: Epoch 31 / 100: avg data time: 4.86e+00, avg batch time: 6.3088, average train loss: 42.6935
[11/23 08:50:36 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.5871, average loss: 4.9063
[11/23 08:50:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.53	rocauc: 62.99	
[11/23 08:50:36 visual_prompt]: Training 32 / 100 epoch, with learning rate 43.57862063693486
[11/23 08:58:00 visual_prompt]: Epoch 32 / 100: avg data time: 4.90e+00, avg batch time: 6.3392, average train loss: 45.2211
[11/23 08:58:51 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.5874, average loss: 5.5182
[11/23 08:58:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.52	
[11/23 08:58:51 visual_prompt]: Training 33 / 100 epoch, with learning rate 42.98349500846628
[11/23 09:06:14 visual_prompt]: Epoch 33 / 100: avg data time: 4.88e+00, avg batch time: 6.3240, average train loss: 38.1421
[11/23 09:07:04 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.5857, average loss: 12.0966
[11/23 09:07:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 62.22	
[11/23 09:07:04 visual_prompt]: Training 34 / 100 epoch, with learning rate 42.36645926147493
[11/23 09:14:27 visual_prompt]: Epoch 34 / 100: avg data time: 4.88e+00, avg batch time: 6.3215, average train loss: 30.9063
[11/23 09:15:18 visual_prompt]: Inference (val):avg data time: 3.41e-05, avg batch time: 0.5904, average loss: 78.9922
[11/23 09:15:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.14	
[11/23 09:15:18 visual_prompt]: Training 35 / 100 epoch, with learning rate 41.72826515897145
[11/23 09:22:40 visual_prompt]: Epoch 35 / 100: avg data time: 4.88e+00, avg batch time: 6.3180, average train loss: 60.9830
[11/23 09:23:31 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.5867, average loss: 58.7923
[11/23 09:23:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 61.56	
[11/23 09:23:31 visual_prompt]: Training 36 / 100 epoch, with learning rate 41.06969024216348
[11/23 09:30:57 visual_prompt]: Epoch 36 / 100: avg data time: 4.92e+00, avg batch time: 6.3694, average train loss: 29.7691
[11/23 09:31:48 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.5858, average loss: 104.6510
[11/23 09:31:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 63.43	
[11/23 09:31:48 visual_prompt]: Training 37 / 100 epoch, with learning rate 40.391536883141455
[11/23 09:39:12 visual_prompt]: Epoch 37 / 100: avg data time: 4.90e+00, avg batch time: 6.3454, average train loss: 37.3983
[11/23 09:40:03 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.5859, average loss: 4.5521
[11/23 09:40:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 64.06	
[11/23 09:40:03 visual_prompt]: Training 38 / 100 epoch, with learning rate 39.69463130731183
[11/23 09:47:25 visual_prompt]: Epoch 38 / 100: avg data time: 4.87e+00, avg batch time: 6.3105, average train loss: 34.9036
[11/23 09:48:15 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.5849, average loss: 17.1098
[11/23 09:48:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 65.11	
[11/23 09:48:15 visual_prompt]: Training 39 / 100 epoch, with learning rate 38.97982258676867
[11/23 09:55:35 visual_prompt]: Epoch 39 / 100: avg data time: 4.85e+00, avg batch time: 6.2871, average train loss: 34.7068
[11/23 09:56:26 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.5847, average loss: 40.0117
[11/23 09:56:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 62.64	
[11/23 09:56:26 visual_prompt]: Training 40 / 100 epoch, with learning rate 38.24798160583012
[11/23 10:03:48 visual_prompt]: Epoch 40 / 100: avg data time: 4.86e+00, avg batch time: 6.3053, average train loss: 34.7645
[11/23 10:04:38 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.5895, average loss: 82.7537
[11/23 10:04:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 63.60	
[11/23 10:04:38 visual_prompt]: Stopping early.
[11/23 10:04:38 visual_prompt]: Rank of current process: 0. World size: 1
[11/23 10:04:38 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/23 10:04:38 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/23 10:04:38 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/23 10:04:38 visual_prompt]: Training with config:
[11/23 10:04:38 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr25.0_wd0.01/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 25.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/23 10:04:38 visual_prompt]: Loading training data...
[11/23 10:04:38 visual_prompt]: Constructing mammo-cbis dataset train...
[11/23 10:04:38 visual_prompt]: Loading validation data...
[11/23 10:04:38 visual_prompt]: Constructing mammo-cbis dataset val...
[11/23 10:04:38 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/23 10:04:41 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/23 10:04:41 visual_prompt]: tuned percent:0.532
[11/23 10:04:41 visual_prompt]: Device used for model: 0
[11/23 10:04:41 visual_prompt]: Setting up Evaluator...
[11/23 10:04:41 visual_prompt]: Setting up Trainer...
[11/23 10:04:41 visual_prompt]: 	Setting up the optimizer...
[11/23 10:04:41 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/23 10:12:04 visual_prompt]: Epoch 1 / 100: avg data time: 4.88e+00, avg batch time: 6.3336, average train loss: 1.4863
[11/23 10:12:55 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.5855, average loss: 1.4553
[11/23 10:12:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/23 10:12:55 visual_prompt]: Training 2 / 100 epoch, with learning rate 2.5
[11/23 10:20:18 visual_prompt]: Epoch 2 / 100: avg data time: 4.86e+00, avg batch time: 6.3193, average train loss: 9.2644
[11/23 10:21:08 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.5859, average loss: 7.2979
[11/23 10:21:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 42.57	
[11/23 10:21:08 visual_prompt]: Training 3 / 100 epoch, with learning rate 5.0
[11/23 10:28:33 visual_prompt]: Epoch 3 / 100: avg data time: 4.90e+00, avg batch time: 6.3532, average train loss: 11.8082
[11/23 10:29:24 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.5892, average loss: 17.2598
[11/23 10:29:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.68	
[11/23 10:29:24 visual_prompt]: Training 4 / 100 epoch, with learning rate 7.5
[11/23 10:36:46 visual_prompt]: Epoch 4 / 100: avg data time: 4.86e+00, avg batch time: 6.3140, average train loss: 15.7340
[11/23 10:37:36 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.5923, average loss: 6.6949
[11/23 10:37:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.09	
[11/23 10:37:36 visual_prompt]: Training 5 / 100 epoch, with learning rate 10.0
[11/23 10:44:57 visual_prompt]: Epoch 5 / 100: avg data time: 4.84e+00, avg batch time: 6.2905, average train loss: 21.7801
[11/23 10:45:47 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.5873, average loss: 60.4453
[11/23 10:45:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.72	
[11/23 10:45:47 visual_prompt]: Training 6 / 100 epoch, with learning rate 12.5
[11/23 10:53:12 visual_prompt]: Epoch 6 / 100: avg data time: 4.90e+00, avg batch time: 6.3488, average train loss: 39.3944
[11/23 10:54:03 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.5904, average loss: 56.8249
[11/23 10:54:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 39.45	
[11/23 10:54:03 visual_prompt]: Training 7 / 100 epoch, with learning rate 15.0
[11/23 11:01:23 visual_prompt]: Epoch 7 / 100: avg data time: 4.85e+00, avg batch time: 6.2959, average train loss: 41.5170
[11/23 11:02:15 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.5890, average loss: 13.9227
[11/23 11:02:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.53	
[11/23 11:02:15 visual_prompt]: Training 8 / 100 epoch, with learning rate 17.5
[11/23 11:09:37 visual_prompt]: Epoch 8 / 100: avg data time: 4.87e+00, avg batch time: 6.3176, average train loss: 50.4916
[11/23 11:10:28 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.5900, average loss: 110.5232
[11/23 11:10:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.89	
[11/23 11:10:28 visual_prompt]: Training 9 / 100 epoch, with learning rate 20.0
[11/23 11:17:51 visual_prompt]: Epoch 9 / 100: avg data time: 4.89e+00, avg batch time: 6.3323, average train loss: 91.9525
[11/23 11:18:42 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.5864, average loss: 244.2756
[11/23 11:18:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.05	
[11/23 11:18:42 visual_prompt]: Training 10 / 100 epoch, with learning rate 22.5
[11/23 11:26:04 visual_prompt]: Epoch 10 / 100: avg data time: 4.86e+00, avg batch time: 6.3073, average train loss: 66.3340
[11/23 11:26:55 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.5831, average loss: 11.5450
[11/23 11:26:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.45	
[11/23 11:26:55 visual_prompt]: Training 11 / 100 epoch, with learning rate 25.0
[11/23 11:34:20 visual_prompt]: Epoch 11 / 100: avg data time: 4.91e+00, avg batch time: 6.3598, average train loss: 61.0317
[11/23 11:35:11 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.5898, average loss: 7.7466
[11/23 11:35:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.03	
[11/23 11:35:11 visual_prompt]: Training 12 / 100 epoch, with learning rate 24.9923853377387
[11/23 11:42:33 visual_prompt]: Epoch 12 / 100: avg data time: 4.86e+00, avg batch time: 6.3098, average train loss: 77.4658
[11/23 11:43:23 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.5889, average loss: 20.5838
[11/23 11:43:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.51	
[11/23 11:43:23 visual_prompt]: Training 13 / 100 epoch, with learning rate 24.969550628247802
[11/23 11:50:47 visual_prompt]: Epoch 13 / 100: avg data time: 4.89e+00, avg batch time: 6.3346, average train loss: 50.8149
[11/23 11:51:38 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.5881, average loss: 98.8989
[11/23 11:51:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.48	
[11/23 11:51:38 visual_prompt]: Training 14 / 100 epoch, with learning rate 24.931523692103415
[11/23 11:59:01 visual_prompt]: Epoch 14 / 100: avg data time: 4.88e+00, avg batch time: 6.3292, average train loss: 51.6674
[11/23 11:59:51 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.5871, average loss: 40.5529
[11/23 11:59:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 41.67	
[11/23 11:59:51 visual_prompt]: Training 15 / 100 epoch, with learning rate 24.87835085926963
[11/23 12:07:13 visual_prompt]: Epoch 15 / 100: avg data time: 4.86e+00, avg batch time: 6.3055, average train loss: 61.2310
[11/23 12:08:04 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.5890, average loss: 74.9735
[11/23 12:08:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.50	
[11/23 12:08:04 visual_prompt]: Training 16 / 100 epoch, with learning rate 24.8100969126526
[11/23 12:15:27 visual_prompt]: Epoch 16 / 100: avg data time: 4.89e+00, avg batch time: 6.3319, average train loss: 60.7043
[11/23 12:16:18 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.5850, average loss: 313.0779
[11/23 12:16:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.15	
[11/23 12:16:18 visual_prompt]: Training 17 / 100 epoch, with learning rate 24.72684500917257
[11/23 12:23:43 visual_prompt]: Epoch 17 / 100: avg data time: 4.91e+00, avg batch time: 6.3511, average train loss: 84.5412
[11/23 12:24:34 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.5883, average loss: 128.9083
[11/23 12:24:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 44.84	
[11/23 12:24:34 visual_prompt]: Training 18 / 100 epoch, with learning rate 24.628696578449954
[11/23 12:31:52 visual_prompt]: Epoch 18 / 100: avg data time: 4.82e+00, avg batch time: 6.2647, average train loss: 93.7010
[11/23 12:32:40 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.5881, average loss: 6.8398
[11/23 12:32:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.52	
[11/23 12:32:40 visual_prompt]: Best epoch 18: best metric: -6.840
[11/23 12:32:40 visual_prompt]: Training 19 / 100 epoch, with learning rate 24.515771199228986
[11/23 12:39:40 visual_prompt]: Epoch 19 / 100: avg data time: 4.56e+00, avg batch time: 5.9991, average train loss: 89.5964
[11/23 12:40:28 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.5881, average loss: 131.6036
[11/23 12:40:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.03	
[11/23 12:40:28 visual_prompt]: Training 20 / 100 epoch, with learning rate 24.38820645368942
[11/23 12:47:32 visual_prompt]: Epoch 20 / 100: avg data time: 4.62e+00, avg batch time: 6.0594, average train loss: 82.3185
[11/23 12:48:21 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.5861, average loss: 84.5250
[11/23 12:48:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 44.58	
[11/23 12:48:21 visual_prompt]: Training 21 / 100 epoch, with learning rate 24.246157759823856
[11/23 12:55:25 visual_prompt]: Epoch 21 / 100: avg data time: 4.62e+00, avg batch time: 6.0577, average train loss: 56.3152
[11/23 12:56:14 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.5850, average loss: 123.3887
[11/23 12:56:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.70	
[11/23 12:56:14 visual_prompt]: Training 22 / 100 epoch, with learning rate 24.08979818208484
[11/23 13:03:17 visual_prompt]: Epoch 22 / 100: avg data time: 4.60e+00, avg batch time: 6.0477, average train loss: 68.6338
[11/23 13:04:05 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.5905, average loss: 12.9044
[11/23 13:04:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 45.65	
[11/23 13:04:05 visual_prompt]: Training 23 / 100 epoch, with learning rate 23.91931822053251
[11/23 13:11:10 visual_prompt]: Epoch 23 / 100: avg data time: 4.62e+00, avg batch time: 6.0643, average train loss: 76.1778
[11/23 13:11:59 visual_prompt]: Inference (val):avg data time: 1.89e-05, avg batch time: 0.5864, average loss: 38.9189
[11/23 13:11:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 39.68	
[11/23 13:11:59 visual_prompt]: Training 24 / 100 epoch, with learning rate 23.73492557873959
[11/23 13:19:00 visual_prompt]: Epoch 24 / 100: avg data time: 4.57e+00, avg batch time: 6.0171, average train loss: 59.8707
[11/23 13:19:48 visual_prompt]: Inference (val):avg data time: 1.97e-05, avg batch time: 0.5875, average loss: 110.5927
[11/23 13:19:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.18	
[11/23 13:19:48 visual_prompt]: Training 25 / 100 epoch, with learning rate 23.536844910736587
[11/23 13:26:48 visual_prompt]: Epoch 25 / 100: avg data time: 4.56e+00, avg batch time: 5.9991, average train loss: 60.0324
[11/23 13:27:36 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.5871, average loss: 97.2395
[11/23 13:27:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.80	
[11/23 13:27:36 visual_prompt]: Training 26 / 100 epoch, with learning rate 23.325317547305485
[11/23 13:34:35 visual_prompt]: Epoch 26 / 100: avg data time: 4.54e+00, avg batch time: 5.9847, average train loss: 68.9984
[11/23 13:35:23 visual_prompt]: Inference (val):avg data time: 1.96e-05, avg batch time: 0.5907, average loss: 58.5007
[11/23 13:35:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.79	
[11/23 13:35:23 visual_prompt]: Training 27 / 100 epoch, with learning rate 23.100601201955325
[11/23 13:42:21 visual_prompt]: Epoch 27 / 100: avg data time: 4.53e+00, avg batch time: 5.9786, average train loss: 50.0887
[11/23 13:43:09 visual_prompt]: Inference (val):avg data time: 2.02e-05, avg batch time: 0.5860, average loss: 45.2765
[11/23 13:43:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.22	
[11/23 13:43:09 visual_prompt]: Training 28 / 100 epoch, with learning rate 22.86296965693802
[11/23 13:50:10 visual_prompt]: Epoch 28 / 100: avg data time: 4.56e+00, avg batch time: 6.0033, average train loss: 58.0203
[11/23 13:50:58 visual_prompt]: Inference (val):avg data time: 1.96e-05, avg batch time: 0.5854, average loss: 31.2717
[11/23 13:50:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.51	
[11/23 13:50:58 visual_prompt]: Training 29 / 100 epoch, with learning rate 22.612712429686844
[11/23 13:57:58 visual_prompt]: Epoch 29 / 100: avg data time: 4.56e+00, avg batch time: 6.0003, average train loss: 54.2602
[11/23 13:58:46 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.5856, average loss: 80.8989
[11/23 13:58:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.75	
[11/23 13:58:46 visual_prompt]: Training 30 / 100 epoch, with learning rate 22.35013442008402
[11/23 14:05:46 visual_prompt]: Epoch 30 / 100: avg data time: 4.56e+00, avg batch time: 5.9979, average train loss: 69.7901
[11/23 14:06:34 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.5892, average loss: 20.1720
[11/23 14:06:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.60	
[11/23 14:06:34 visual_prompt]: Training 31 / 100 epoch, with learning rate 22.075555538987224
[11/23 14:13:32 visual_prompt]: Epoch 31 / 100: avg data time: 4.52e+00, avg batch time: 5.9667, average train loss: 74.0750
[11/23 14:14:20 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.5872, average loss: 49.9190
[11/23 14:14:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.88	
[11/23 14:14:20 visual_prompt]: Training 32 / 100 epoch, with learning rate 21.78931031846743
[11/23 14:21:22 visual_prompt]: Epoch 32 / 100: avg data time: 4.59e+00, avg batch time: 6.0368, average train loss: 58.6641
[11/23 14:22:12 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.5887, average loss: 106.6819
[11/23 14:22:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.30	
[11/23 14:22:12 visual_prompt]: Training 33 / 100 epoch, with learning rate 21.49174750423314
[11/23 14:29:15 visual_prompt]: Epoch 33 / 100: avg data time: 4.61e+00, avg batch time: 6.0509, average train loss: 65.8152
[11/23 14:30:04 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.5921, average loss: 101.9799
[11/23 14:30:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.07	
[11/23 14:30:04 visual_prompt]: Training 34 / 100 epoch, with learning rate 21.183229630737465
[11/23 14:37:06 visual_prompt]: Epoch 34 / 100: avg data time: 4.59e+00, avg batch time: 6.0364, average train loss: 56.5285
[11/23 14:37:55 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.5866, average loss: 107.5842
[11/23 14:37:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.50	
[11/23 14:37:55 visual_prompt]: Training 35 / 100 epoch, with learning rate 20.864132579485727
[11/23 14:44:57 visual_prompt]: Epoch 35 / 100: avg data time: 4.59e+00, avg batch time: 6.0353, average train loss: 62.9725
[11/23 14:45:46 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.5905, average loss: 114.0355
[11/23 14:45:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.38	
[11/23 14:45:46 visual_prompt]: Training 36 / 100 epoch, with learning rate 20.53484512108174
[11/23 14:52:54 visual_prompt]: Epoch 36 / 100: avg data time: 4.67e+00, avg batch time: 6.1086, average train loss: 55.8987
[11/23 14:53:42 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.5857, average loss: 15.4660
[11/23 14:53:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.09	
[11/23 14:53:42 visual_prompt]: Training 37 / 100 epoch, with learning rate 20.195768441570728
[11/23 15:00:48 visual_prompt]: Epoch 37 / 100: avg data time: 4.64e+00, avg batch time: 6.0786, average train loss: 60.1558
[11/23 15:01:36 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.5904, average loss: 31.3375
[11/23 15:01:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.44	
[11/23 15:01:36 visual_prompt]: Training 38 / 100 epoch, with learning rate 19.847315653655915
[11/23 15:08:40 visual_prompt]: Epoch 38 / 100: avg data time: 4.61e+00, avg batch time: 6.0511, average train loss: 57.1590
[11/23 15:09:28 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.5898, average loss: 7.1590
[11/23 15:09:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.42	
[11/23 15:09:28 visual_prompt]: Training 39 / 100 epoch, with learning rate 19.489911293384335
[11/23 15:16:32 visual_prompt]: Epoch 39 / 100: avg data time: 4.60e+00, avg batch time: 6.0440, average train loss: 56.6910
[11/23 15:17:20 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.5906, average loss: 77.3994
[11/23 15:17:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.80	
[11/23 15:17:20 visual_prompt]: Stopping early.
[11/23 15:17:20 visual_prompt]: Rank of current process: 0. World size: 1
[11/23 15:17:20 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/23 15:17:20 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/23 15:17:20 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/23 15:17:20 visual_prompt]: Training with config:
[11/23 15:17:20 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr25.0_wd0.001/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 25.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/23 15:17:20 visual_prompt]: Loading training data...
[11/23 15:17:20 visual_prompt]: Constructing mammo-cbis dataset train...
[11/23 15:17:20 visual_prompt]: Loading validation data...
[11/23 15:17:20 visual_prompt]: Constructing mammo-cbis dataset val...
[11/23 15:17:20 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/23 15:17:23 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/23 15:17:23 visual_prompt]: tuned percent:0.532
[11/23 15:17:23 visual_prompt]: Device used for model: 0
[11/23 15:17:23 visual_prompt]: Setting up Evaluator...
[11/23 15:17:23 visual_prompt]: Setting up Trainer...
[11/23 15:17:23 visual_prompt]: 	Setting up the optimizer...
[11/23 15:17:23 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/23 15:24:27 visual_prompt]: Epoch 1 / 100: avg data time: 4.60e+00, avg batch time: 6.0506, average train loss: 1.4863
[11/23 15:25:15 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.5852, average loss: 1.4553
[11/23 15:25:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/23 15:25:15 visual_prompt]: Training 2 / 100 epoch, with learning rate 2.5
[11/23 15:32:18 visual_prompt]: Epoch 2 / 100: avg data time: 4.60e+00, avg batch time: 6.0482, average train loss: 8.2590
[11/23 15:33:07 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.5848, average loss: 6.5246
[11/23 15:33:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.04	
[11/23 15:33:07 visual_prompt]: Training 3 / 100 epoch, with learning rate 5.0
[11/23 15:40:10 visual_prompt]: Epoch 3 / 100: avg data time: 4.59e+00, avg batch time: 6.0405, average train loss: 12.8542
[11/23 15:40:58 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.5863, average loss: 43.0126
[11/23 15:40:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.14	
[11/23 15:40:58 visual_prompt]: Training 4 / 100 epoch, with learning rate 7.5
[11/23 15:48:00 visual_prompt]: Epoch 4 / 100: avg data time: 4.58e+00, avg batch time: 6.0314, average train loss: 24.3482
[11/23 15:48:49 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.5870, average loss: 38.9421
[11/23 15:48:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.34	
[11/23 15:48:49 visual_prompt]: Training 5 / 100 epoch, with learning rate 10.0
[11/23 15:55:51 visual_prompt]: Epoch 5 / 100: avg data time: 4.58e+00, avg batch time: 6.0329, average train loss: 16.7612
[11/23 15:56:39 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.5847, average loss: 34.1162
[11/23 15:56:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.36	
[11/23 15:56:39 visual_prompt]: Training 6 / 100 epoch, with learning rate 12.5
[11/23 16:03:43 visual_prompt]: Epoch 6 / 100: avg data time: 4.61e+00, avg batch time: 6.0570, average train loss: 32.9153
[11/23 16:04:32 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.5896, average loss: 33.9918
[11/23 16:04:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.23	
[11/23 16:04:32 visual_prompt]: Training 7 / 100 epoch, with learning rate 15.0
[11/23 16:11:30 visual_prompt]: Epoch 7 / 100: avg data time: 4.53e+00, avg batch time: 5.9807, average train loss: 42.2689
[11/23 16:12:19 visual_prompt]: Inference (val):avg data time: 2.08e-05, avg batch time: 0.5853, average loss: 10.0477
[11/23 16:12:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.37	
[11/23 16:12:19 visual_prompt]: Training 8 / 100 epoch, with learning rate 17.5
[11/23 16:19:21 visual_prompt]: Epoch 8 / 100: avg data time: 4.58e+00, avg batch time: 6.0242, average train loss: 44.8138
[11/23 16:20:08 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.5905, average loss: 11.9901
[11/23 16:20:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.26	
[11/23 16:20:08 visual_prompt]: Training 9 / 100 epoch, with learning rate 20.0
[11/23 16:27:07 visual_prompt]: Epoch 9 / 100: avg data time: 4.53e+00, avg batch time: 5.9814, average train loss: 47.6991
[11/23 16:27:55 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.5848, average loss: 26.2309
[11/23 16:27:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.40	
[11/23 16:27:55 visual_prompt]: Training 10 / 100 epoch, with learning rate 22.5
[11/23 16:34:53 visual_prompt]: Epoch 10 / 100: avg data time: 4.53e+00, avg batch time: 5.9731, average train loss: 45.2072
[11/23 16:35:41 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.5913, average loss: 32.8155
[11/23 16:35:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 45.87	
[11/23 16:35:41 visual_prompt]: Training 11 / 100 epoch, with learning rate 25.0
[11/23 16:42:40 visual_prompt]: Epoch 11 / 100: avg data time: 4.54e+00, avg batch time: 5.9857, average train loss: 55.8975
[11/23 16:43:28 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.5906, average loss: 97.0035
[11/23 16:43:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.36	
[11/23 16:43:28 visual_prompt]: Training 12 / 100 epoch, with learning rate 24.9923853377387
[11/23 16:50:26 visual_prompt]: Epoch 12 / 100: avg data time: 4.53e+00, avg batch time: 5.9727, average train loss: 73.6140
[11/23 16:51:14 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.5879, average loss: 46.6619
[11/23 16:51:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.40	
[11/23 16:51:14 visual_prompt]: Best epoch 12: best metric: -46.662
[11/23 16:51:14 visual_prompt]: Training 13 / 100 epoch, with learning rate 24.969550628247802
[11/23 16:58:13 visual_prompt]: Epoch 13 / 100: avg data time: 4.54e+00, avg batch time: 5.9783, average train loss: 73.8447
[11/23 16:59:01 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.5902, average loss: 36.8033
[11/23 16:59:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.25	
[11/23 16:59:01 visual_prompt]: Best epoch 13: best metric: -36.803
[11/23 16:59:01 visual_prompt]: Training 14 / 100 epoch, with learning rate 24.931523692103415
[11/23 17:06:33 visual_prompt]: Epoch 14 / 100: avg data time: 5.01e+00, avg batch time: 6.4498, average train loss: 66.3276
[11/23 17:07:24 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.5883, average loss: 40.3746
[11/23 17:07:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.99	
[11/23 17:07:24 visual_prompt]: Training 15 / 100 epoch, with learning rate 24.87835085926963
[11/23 17:14:56 visual_prompt]: Epoch 15 / 100: avg data time: 5.00e+00, avg batch time: 6.4452, average train loss: 44.0138
[11/23 17:15:47 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.5862, average loss: 62.5143
[11/23 17:15:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.06	
[11/23 17:15:47 visual_prompt]: Training 16 / 100 epoch, with learning rate 24.8100969126526
[11/23 17:23:20 visual_prompt]: Epoch 16 / 100: avg data time: 5.02e+00, avg batch time: 6.4639, average train loss: 60.8178
[11/23 17:24:12 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.5910, average loss: 78.9373
[11/23 17:24:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.80	
[11/23 17:24:12 visual_prompt]: Training 17 / 100 epoch, with learning rate 24.72684500917257
[11/23 17:31:45 visual_prompt]: Epoch 17 / 100: avg data time: 5.03e+00, avg batch time: 6.4753, average train loss: 70.1742
[11/23 17:32:37 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.5905, average loss: 47.0000
[11/23 17:32:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.10	
[11/23 17:32:37 visual_prompt]: Training 18 / 100 epoch, with learning rate 24.628696578449954
[11/23 17:40:10 visual_prompt]: Epoch 18 / 100: avg data time: 5.03e+00, avg batch time: 6.4778, average train loss: 72.0207
[11/23 17:41:02 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.5862, average loss: 180.6186
[11/23 17:41:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.03	
[11/23 17:41:02 visual_prompt]: Training 19 / 100 epoch, with learning rate 24.515771199228986
[11/23 17:48:39 visual_prompt]: Epoch 19 / 100: avg data time: 5.07e+00, avg batch time: 6.5194, average train loss: 52.7497
[11/23 17:49:31 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.5875, average loss: 10.9395
[11/23 17:49:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.11	
[11/23 17:49:31 visual_prompt]: Best epoch 19: best metric: -10.940
[11/23 17:49:31 visual_prompt]: Training 20 / 100 epoch, with learning rate 24.38820645368942
[11/23 17:57:04 visual_prompt]: Epoch 20 / 100: avg data time: 5.03e+00, avg batch time: 6.4759, average train loss: 66.2339
[11/23 17:57:56 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.5890, average loss: 68.7037
[11/23 17:57:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.45	
[11/23 17:57:56 visual_prompt]: Training 21 / 100 epoch, with learning rate 24.246157759823856
[11/23 18:05:31 visual_prompt]: Epoch 21 / 100: avg data time: 5.06e+00, avg batch time: 6.5022, average train loss: 41.2648
[11/23 18:06:23 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.5888, average loss: 22.5610
[11/23 18:06:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.42	
[11/23 18:06:23 visual_prompt]: Training 22 / 100 epoch, with learning rate 24.08979818208484
[11/23 18:13:56 visual_prompt]: Epoch 22 / 100: avg data time: 5.03e+00, avg batch time: 6.4749, average train loss: 62.9471
[11/23 18:14:48 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.5863, average loss: 22.4820
[11/23 18:14:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.27	
[11/23 18:14:48 visual_prompt]: Training 23 / 100 epoch, with learning rate 23.91931822053251
[11/23 18:22:24 visual_prompt]: Epoch 23 / 100: avg data time: 5.07e+00, avg batch time: 6.5118, average train loss: 43.8226
[11/23 18:23:16 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.5887, average loss: 2.9938
[11/23 18:23:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 52.44	rocauc: 50.62	
[11/23 18:23:16 visual_prompt]: Best epoch 23: best metric: -2.994
[11/23 18:23:16 visual_prompt]: Training 24 / 100 epoch, with learning rate 23.73492557873959
[11/23 18:30:49 visual_prompt]: Epoch 24 / 100: avg data time: 5.03e+00, avg batch time: 6.4778, average train loss: 53.3922
[11/23 18:31:41 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.5870, average loss: 58.7837
[11/23 18:31:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 44.56	
[11/23 18:31:41 visual_prompt]: Training 25 / 100 epoch, with learning rate 23.536844910736587
[11/23 18:39:16 visual_prompt]: Epoch 25 / 100: avg data time: 5.06e+00, avg batch time: 6.4998, average train loss: 55.7526
[11/23 18:40:08 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.5878, average loss: 81.7253
[11/23 18:40:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.51	
[11/23 18:40:08 visual_prompt]: Training 26 / 100 epoch, with learning rate 23.325317547305485
[11/23 18:47:40 visual_prompt]: Epoch 26 / 100: avg data time: 5.02e+00, avg batch time: 6.4666, average train loss: 55.7976
[11/23 18:48:32 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.5847, average loss: 21.4056
[11/23 18:48:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 42.68	
[11/23 18:48:32 visual_prompt]: Training 27 / 100 epoch, with learning rate 23.100601201955325
[11/23 18:56:04 visual_prompt]: Epoch 27 / 100: avg data time: 5.01e+00, avg batch time: 6.4542, average train loss: 34.8045
[11/23 18:56:56 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.5879, average loss: 27.6092
[11/23 18:56:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.66	
[11/23 18:56:56 visual_prompt]: Training 28 / 100 epoch, with learning rate 22.86296965693802
[11/23 19:04:30 visual_prompt]: Epoch 28 / 100: avg data time: 5.04e+00, avg batch time: 6.4825, average train loss: 44.9755
[11/23 19:05:22 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.5902, average loss: 1.4754
[11/23 19:05:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.14	
[11/23 19:05:22 visual_prompt]: Best epoch 28: best metric: -1.475
[11/23 19:05:22 visual_prompt]: Training 29 / 100 epoch, with learning rate 22.612712429686844
[11/23 19:12:55 visual_prompt]: Epoch 29 / 100: avg data time: 5.03e+00, avg batch time: 6.4787, average train loss: 44.0545
[11/23 19:13:47 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.5887, average loss: 260.0705
[11/23 19:13:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.09	
[11/23 19:13:47 visual_prompt]: Training 30 / 100 epoch, with learning rate 22.35013442008402
[11/23 19:21:21 visual_prompt]: Epoch 30 / 100: avg data time: 5.04e+00, avg batch time: 6.4826, average train loss: 63.1470
[11/23 19:22:13 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.5856, average loss: 24.1087
[11/23 19:22:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.04	
[11/23 19:22:13 visual_prompt]: Training 31 / 100 epoch, with learning rate 22.075555538987224
[11/23 19:29:44 visual_prompt]: Epoch 31 / 100: avg data time: 4.99e+00, avg batch time: 6.4396, average train loss: 37.0340
[11/23 19:30:35 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.5875, average loss: 11.5403
[11/23 19:30:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.37	
[11/23 19:30:35 visual_prompt]: Training 32 / 100 epoch, with learning rate 21.78931031846743
[11/23 19:38:07 visual_prompt]: Epoch 32 / 100: avg data time: 5.01e+00, avg batch time: 6.4496, average train loss: 44.4204
[11/23 19:38:58 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.5920, average loss: 109.9710
[11/23 19:38:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.73	
[11/23 19:38:58 visual_prompt]: Training 33 / 100 epoch, with learning rate 21.49174750423314
[11/23 19:46:29 visual_prompt]: Epoch 33 / 100: avg data time: 4.99e+00, avg batch time: 6.4344, average train loss: 53.9043
[11/23 19:47:21 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.5935, average loss: 58.6641
[11/23 19:47:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.13	
[11/23 19:47:21 visual_prompt]: Training 34 / 100 epoch, with learning rate 21.183229630737465
[11/23 19:54:49 visual_prompt]: Epoch 34 / 100: avg data time: 4.96e+00, avg batch time: 6.4046, average train loss: 46.9848
[11/23 19:55:40 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.5879, average loss: 76.9097
[11/23 19:55:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 45.49	
[11/23 19:55:40 visual_prompt]: Training 35 / 100 epoch, with learning rate 20.864132579485727
[11/23 20:03:08 visual_prompt]: Epoch 35 / 100: avg data time: 4.95e+00, avg batch time: 6.3936, average train loss: 44.3540
[11/23 20:03:59 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.5918, average loss: 27.6591
[11/23 20:03:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.30	
[11/23 20:03:59 visual_prompt]: Training 36 / 100 epoch, with learning rate 20.53484512108174
[11/23 20:11:28 visual_prompt]: Epoch 36 / 100: avg data time: 4.96e+00, avg batch time: 6.4055, average train loss: 48.0853
[11/23 20:12:19 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.5884, average loss: 40.0645
[11/23 20:12:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.56	
[11/23 20:12:19 visual_prompt]: Training 37 / 100 epoch, with learning rate 20.195768441570728
[11/23 20:19:46 visual_prompt]: Epoch 37 / 100: avg data time: 4.94e+00, avg batch time: 6.3875, average train loss: 41.3010
[11/23 20:20:37 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.5885, average loss: 6.3328
[11/23 20:20:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.50	
[11/23 20:20:37 visual_prompt]: Training 38 / 100 epoch, with learning rate 19.847315653655915
[11/23 20:28:05 visual_prompt]: Epoch 38 / 100: avg data time: 4.96e+00, avg batch time: 6.3977, average train loss: 41.6885
[11/23 20:28:56 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.5905, average loss: 65.0417
[11/23 20:28:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 43.63	
[11/23 20:28:56 visual_prompt]: Training 39 / 100 epoch, with learning rate 19.489911293384335
[11/23 20:36:23 visual_prompt]: Epoch 39 / 100: avg data time: 4.94e+00, avg batch time: 6.3854, average train loss: 44.3886
[11/23 20:37:15 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.5915, average loss: 6.3829
[11/23 20:37:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 47.97	rocauc: 47.31	
[11/23 20:37:15 visual_prompt]: Training 40 / 100 epoch, with learning rate 19.12399080291506
[11/23 20:44:43 visual_prompt]: Epoch 40 / 100: avg data time: 4.95e+00, avg batch time: 6.3994, average train loss: 35.7436
[11/23 20:45:34 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.5855, average loss: 45.0229
[11/23 20:45:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.61	
[11/23 20:45:34 visual_prompt]: Training 41 / 100 epoch, with learning rate 18.75
[11/23 20:53:03 visual_prompt]: Epoch 41 / 100: avg data time: 4.96e+00, avg batch time: 6.4074, average train loss: 63.7943
[11/23 20:53:54 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.5869, average loss: 27.7560
[11/23 20:53:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.47	rocauc: 51.02	
[11/23 20:53:54 visual_prompt]: Training 42 / 100 epoch, with learning rate 18.368394534823633
[11/23 21:01:24 visual_prompt]: Epoch 42 / 100: avg data time: 4.99e+00, avg batch time: 6.4307, average train loss: 37.8346
[11/23 21:02:16 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.5893, average loss: 28.7439
[11/23 21:02:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.39	
[11/23 21:02:16 visual_prompt]: Training 43 / 100 epoch, with learning rate 17.979639334863467
[11/23 21:09:49 visual_prompt]: Epoch 43 / 100: avg data time: 5.03e+00, avg batch time: 6.4734, average train loss: 45.0149
[11/23 21:10:41 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.5889, average loss: 31.4061
[11/23 21:10:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 43.62	
[11/23 21:10:41 visual_prompt]: Training 44 / 100 epoch, with learning rate 17.584208038447503
[11/23 21:18:15 visual_prompt]: Epoch 44 / 100: avg data time: 5.03e+00, avg batch time: 6.4789, average train loss: 28.8709
[11/23 21:19:06 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.5860, average loss: 74.4183
[11/23 21:19:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.87	
[11/23 21:19:06 visual_prompt]: Training 45 / 100 epoch, with learning rate 17.182582417698903
[11/23 21:26:36 visual_prompt]: Epoch 45 / 100: avg data time: 4.98e+00, avg batch time: 6.4245, average train loss: 56.1718
[11/23 21:27:27 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.5911, average loss: 69.7327
[11/23 21:27:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 38.18	
[11/23 21:27:27 visual_prompt]: Training 46 / 100 epoch, with learning rate 16.77525179157086
[11/23 21:34:55 visual_prompt]: Epoch 46 / 100: avg data time: 4.94e+00, avg batch time: 6.3896, average train loss: 44.8990
[11/23 21:35:45 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.5871, average loss: 12.5469
[11/23 21:35:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.28	
[11/23 21:35:45 visual_prompt]: Training 47 / 100 epoch, with learning rate 16.362712429686844
[11/23 21:43:17 visual_prompt]: Epoch 47 / 100: avg data time: 5.00e+00, avg batch time: 6.4545, average train loss: 25.0009
[11/23 21:44:09 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.5859, average loss: 20.3711
[11/23 21:44:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 45.31	
[11/23 21:44:09 visual_prompt]: Training 48 / 100 epoch, with learning rate 15.94546694771249
[11/23 21:51:41 visual_prompt]: Epoch 48 / 100: avg data time: 5.01e+00, avg batch time: 6.4535, average train loss: 40.9969
[11/23 21:52:33 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.5882, average loss: 8.9304
[11/23 21:52:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.33	
[11/23 21:52:33 visual_prompt]: Training 49 / 100 epoch, with learning rate 15.524023694995845
[11/23 22:00:07 visual_prompt]: Epoch 49 / 100: avg data time: 5.04e+00, avg batch time: 6.4897, average train loss: 36.0324
[11/23 22:00:59 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.5885, average loss: 43.2546
[11/23 22:00:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.20	
[11/23 22:00:59 visual_prompt]: Stopping early.
[11/23 22:00:59 visual_prompt]: Rank of current process: 0. World size: 1
[11/23 22:00:59 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/23 22:00:59 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/23 22:00:59 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/23 22:00:59 visual_prompt]: Training with config:
[11/23 22:00:59 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr25.0_wd0.0001/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 25.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/23 22:00:59 visual_prompt]: Loading training data...
[11/23 22:00:59 visual_prompt]: Constructing mammo-cbis dataset train...
[11/23 22:00:59 visual_prompt]: Loading validation data...
[11/23 22:00:59 visual_prompt]: Constructing mammo-cbis dataset val...
[11/23 22:00:59 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/23 22:01:02 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/23 22:01:02 visual_prompt]: tuned percent:0.532
[11/23 22:01:02 visual_prompt]: Device used for model: 0
[11/23 22:01:02 visual_prompt]: Setting up Evaluator...
[11/23 22:01:02 visual_prompt]: Setting up Trainer...
[11/23 22:01:02 visual_prompt]: 	Setting up the optimizer...
[11/23 22:01:02 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/23 22:08:37 visual_prompt]: Epoch 1 / 100: avg data time: 5.05e+00, avg batch time: 6.5017, average train loss: 1.4863
[11/23 22:09:29 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.5885, average loss: 1.4553
[11/23 22:09:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/23 22:09:29 visual_prompt]: Training 2 / 100 epoch, with learning rate 2.5
[11/23 22:17:04 visual_prompt]: Epoch 2 / 100: avg data time: 5.05e+00, avg batch time: 6.5013, average train loss: 14.1045
[11/23 22:17:56 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.5840, average loss: 9.4368
[11/23 22:17:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.83	
[11/23 22:17:56 visual_prompt]: Training 3 / 100 epoch, with learning rate 5.0
[11/23 22:25:31 visual_prompt]: Epoch 3 / 100: avg data time: 5.04e+00, avg batch time: 6.4939, average train loss: 12.1708
[11/23 22:26:23 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.5852, average loss: 17.5772
[11/23 22:26:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.57	
[11/23 22:26:23 visual_prompt]: Training 4 / 100 epoch, with learning rate 7.5
[11/23 22:33:57 visual_prompt]: Epoch 4 / 100: avg data time: 5.03e+00, avg batch time: 6.4730, average train loss: 28.3325
[11/23 22:34:49 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.5876, average loss: 30.1488
[11/23 22:34:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.28	
[11/23 22:34:49 visual_prompt]: Training 5 / 100 epoch, with learning rate 10.0
[11/23 22:42:23 visual_prompt]: Epoch 5 / 100: avg data time: 5.04e+00, avg batch time: 6.4962, average train loss: 20.1486
[11/23 22:43:15 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.5917, average loss: 34.7076
[11/23 22:43:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.32	
[11/23 22:43:15 visual_prompt]: Training 6 / 100 epoch, with learning rate 12.5
[11/23 22:50:51 visual_prompt]: Epoch 6 / 100: avg data time: 5.05e+00, avg batch time: 6.5033, average train loss: 13.5248
[11/23 22:51:43 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.5890, average loss: 7.0067
[11/23 22:51:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 40.84	
[11/23 22:51:43 visual_prompt]: Training 7 / 100 epoch, with learning rate 15.0
[11/23 22:59:11 visual_prompt]: Epoch 7 / 100: avg data time: 4.95e+00, avg batch time: 6.3963, average train loss: 13.7616
[11/23 23:00:01 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.5882, average loss: 48.1128
[11/23 23:00:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 41.41	
[11/23 23:00:01 visual_prompt]: Training 8 / 100 epoch, with learning rate 17.5
[11/23 23:07:31 visual_prompt]: Epoch 8 / 100: avg data time: 4.98e+00, avg batch time: 6.4296, average train loss: 52.1651
[11/23 23:08:23 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.5919, average loss: 11.1195
[11/23 23:08:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 45.54	
[11/23 23:08:23 visual_prompt]: Training 9 / 100 epoch, with learning rate 20.0
[11/23 23:15:49 visual_prompt]: Epoch 9 / 100: avg data time: 4.93e+00, avg batch time: 6.3784, average train loss: 41.3893
[11/23 23:16:40 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.5847, average loss: 26.3347
[11/23 23:16:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.17	
[11/23 23:16:40 visual_prompt]: Training 10 / 100 epoch, with learning rate 22.5
[11/23 23:24:08 visual_prompt]: Epoch 10 / 100: avg data time: 4.95e+00, avg batch time: 6.3945, average train loss: 44.9572
[11/23 23:24:59 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.5924, average loss: 42.2427
[11/23 23:24:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.87	
[11/23 23:24:59 visual_prompt]: Training 11 / 100 epoch, with learning rate 25.0
[11/23 23:32:28 visual_prompt]: Epoch 11 / 100: avg data time: 4.96e+00, avg batch time: 6.4061, average train loss: 42.2056
[11/23 23:33:19 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.5934, average loss: 51.3139
[11/23 23:33:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.48	
[11/23 23:33:19 visual_prompt]: Training 12 / 100 epoch, with learning rate 24.9923853377387
[11/23 23:40:43 visual_prompt]: Epoch 12 / 100: avg data time: 4.90e+00, avg batch time: 6.3495, average train loss: 43.9473
[11/23 23:41:34 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.5894, average loss: 31.6831
[11/23 23:41:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 45.15	
[11/23 23:41:34 visual_prompt]: Best epoch 12: best metric: -31.683
[11/23 23:41:34 visual_prompt]: Training 13 / 100 epoch, with learning rate 24.969550628247802
[11/23 23:49:00 visual_prompt]: Epoch 13 / 100: avg data time: 4.92e+00, avg batch time: 6.3670, average train loss: 32.5941
[11/23 23:49:51 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.5897, average loss: 33.9490
[11/23 23:49:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.62	
[11/23 23:49:51 visual_prompt]: Training 14 / 100 epoch, with learning rate 24.931523692103415
[11/23 23:57:17 visual_prompt]: Epoch 14 / 100: avg data time: 4.92e+00, avg batch time: 6.3613, average train loss: 48.6793
[11/23 23:58:07 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.5882, average loss: 57.6376
[11/23 23:58:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.49	
[11/23 23:58:07 visual_prompt]: Training 15 / 100 epoch, with learning rate 24.87835085926963
[11/24 00:05:32 visual_prompt]: Epoch 15 / 100: avg data time: 4.91e+00, avg batch time: 6.3544, average train loss: 43.8270
[11/24 00:06:24 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.5932, average loss: 61.6118
[11/24 00:06:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.04	
[11/24 00:06:24 visual_prompt]: Training 16 / 100 epoch, with learning rate 24.8100969126526
[11/24 00:13:52 visual_prompt]: Epoch 16 / 100: avg data time: 4.95e+00, avg batch time: 6.4033, average train loss: 22.3551
[11/24 00:14:43 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.5878, average loss: 47.9962
[11/24 00:14:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.83	
[11/24 00:14:43 visual_prompt]: Training 17 / 100 epoch, with learning rate 24.72684500917257
[11/24 00:22:12 visual_prompt]: Epoch 17 / 100: avg data time: 4.96e+00, avg batch time: 6.4050, average train loss: 49.6621
[11/24 00:23:03 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.5853, average loss: 10.1766
[11/24 00:23:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.02	
[11/24 00:23:03 visual_prompt]: Best epoch 17: best metric: -10.177
[11/24 00:23:03 visual_prompt]: Training 18 / 100 epoch, with learning rate 24.628696578449954
[11/24 00:30:32 visual_prompt]: Epoch 18 / 100: avg data time: 4.97e+00, avg batch time: 6.4105, average train loss: 40.4469
[11/24 00:31:24 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.5889, average loss: 40.1932
[11/24 00:31:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.31	
[11/24 00:31:24 visual_prompt]: Training 19 / 100 epoch, with learning rate 24.515771199228986
[11/24 00:38:51 visual_prompt]: Epoch 19 / 100: avg data time: 4.95e+00, avg batch time: 6.3959, average train loss: 35.7924
[11/24 00:39:43 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.5861, average loss: 12.3812
[11/24 00:39:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.54	
[11/24 00:39:43 visual_prompt]: Training 20 / 100 epoch, with learning rate 24.38820645368942
[11/24 00:47:11 visual_prompt]: Epoch 20 / 100: avg data time: 4.96e+00, avg batch time: 6.4055, average train loss: 40.1632
[11/24 00:48:03 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.5887, average loss: 36.6647
[11/24 00:48:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.07	
[11/24 00:48:03 visual_prompt]: Training 21 / 100 epoch, with learning rate 24.246157759823856
[11/24 00:55:34 visual_prompt]: Epoch 21 / 100: avg data time: 5.00e+00, avg batch time: 6.4482, average train loss: 36.4532
[11/24 00:56:26 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.5887, average loss: 25.0213
[11/24 00:56:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.33	
[11/24 00:56:26 visual_prompt]: Training 22 / 100 epoch, with learning rate 24.08979818208484
[11/24 01:03:59 visual_prompt]: Epoch 22 / 100: avg data time: 5.02e+00, avg batch time: 6.4686, average train loss: 46.5363
[11/24 01:04:51 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.5860, average loss: 54.7477
[11/24 01:04:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.19	
[11/24 01:04:51 visual_prompt]: Training 23 / 100 epoch, with learning rate 23.91931822053251
[11/24 01:12:23 visual_prompt]: Epoch 23 / 100: avg data time: 5.03e+00, avg batch time: 6.4676, average train loss: 41.4210
[11/24 01:13:15 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.5853, average loss: 70.8233
[11/24 01:13:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.70	
[11/24 01:13:15 visual_prompt]: Training 24 / 100 epoch, with learning rate 23.73492557873959
[11/24 01:20:49 visual_prompt]: Epoch 24 / 100: avg data time: 5.03e+00, avg batch time: 6.4798, average train loss: 25.7247
[11/24 01:21:41 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.5891, average loss: 20.1975
[11/24 01:21:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.90	
[11/24 01:21:41 visual_prompt]: Training 25 / 100 epoch, with learning rate 23.536844910736587
[11/24 01:29:13 visual_prompt]: Epoch 25 / 100: avg data time: 5.02e+00, avg batch time: 6.4612, average train loss: 49.7056
[11/24 01:30:04 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.5856, average loss: 292.2785
[11/24 01:30:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.15	
[11/24 01:30:04 visual_prompt]: Training 26 / 100 epoch, with learning rate 23.325317547305485
[11/24 01:37:30 visual_prompt]: Epoch 26 / 100: avg data time: 4.93e+00, avg batch time: 6.3691, average train loss: 80.1109
[11/24 01:38:22 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.5849, average loss: 61.1482
[11/24 01:38:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.78	
[11/24 01:38:22 visual_prompt]: Training 27 / 100 epoch, with learning rate 23.100601201955325
[11/24 01:45:49 visual_prompt]: Epoch 27 / 100: avg data time: 4.93e+00, avg batch time: 6.3821, average train loss: 32.7905
[11/24 01:46:40 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.5880, average loss: 54.5140
[11/24 01:46:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.16	
[11/24 01:46:40 visual_prompt]: Training 28 / 100 epoch, with learning rate 22.86296965693802
[11/24 01:54:10 visual_prompt]: Epoch 28 / 100: avg data time: 4.97e+00, avg batch time: 6.4178, average train loss: 38.8043
[11/24 01:55:01 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.5857, average loss: 39.8181
[11/24 01:55:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.88	
[11/24 01:55:01 visual_prompt]: Training 29 / 100 epoch, with learning rate 22.612712429686844
[11/24 02:02:29 visual_prompt]: Epoch 29 / 100: avg data time: 4.94e+00, avg batch time: 6.3919, average train loss: 28.7661
[11/24 02:03:20 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.5907, average loss: 11.3278
[11/24 02:03:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.36	
[11/24 02:03:20 visual_prompt]: Training 30 / 100 epoch, with learning rate 22.35013442008402
[11/24 02:10:48 visual_prompt]: Epoch 30 / 100: avg data time: 4.96e+00, avg batch time: 6.4029, average train loss: 42.6049
[11/24 02:11:39 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.5857, average loss: 2.1007
[11/24 02:11:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.02	
[11/24 02:11:39 visual_prompt]: Best epoch 30: best metric: -2.101
[11/24 02:11:39 visual_prompt]: Training 31 / 100 epoch, with learning rate 22.075555538987224
[11/24 02:19:06 visual_prompt]: Epoch 31 / 100: avg data time: 4.94e+00, avg batch time: 6.3860, average train loss: 22.0164
[11/24 02:19:57 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.5844, average loss: 68.9451
[11/24 02:19:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.39	
[11/24 02:19:57 visual_prompt]: Training 32 / 100 epoch, with learning rate 21.78931031846743
[11/24 02:27:25 visual_prompt]: Epoch 32 / 100: avg data time: 4.95e+00, avg batch time: 6.4001, average train loss: 40.7430
[11/24 02:28:17 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.5899, average loss: 15.0380
[11/24 02:28:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.16	
[11/24 02:28:17 visual_prompt]: Training 33 / 100 epoch, with learning rate 21.49174750423314
[11/24 02:35:45 visual_prompt]: Epoch 33 / 100: avg data time: 4.96e+00, avg batch time: 6.4049, average train loss: 22.2787
[11/24 02:36:36 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.5892, average loss: 13.6798
[11/24 02:36:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 42.80	
[11/24 02:36:36 visual_prompt]: Training 34 / 100 epoch, with learning rate 21.183229630737465
[11/24 02:44:06 visual_prompt]: Epoch 34 / 100: avg data time: 4.97e+00, avg batch time: 6.4215, average train loss: 36.2158
[11/24 02:44:57 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.5858, average loss: 22.6130
[11/24 02:44:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 44.23	
[11/24 02:44:57 visual_prompt]: Training 35 / 100 epoch, with learning rate 20.864132579485727
[11/24 02:52:24 visual_prompt]: Epoch 35 / 100: avg data time: 4.94e+00, avg batch time: 6.3853, average train loss: 56.1053
[11/24 02:53:15 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.5880, average loss: 5.3855
[11/24 02:53:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.30	
[11/24 02:53:15 visual_prompt]: Training 36 / 100 epoch, with learning rate 20.53484512108174
[11/24 03:00:47 visual_prompt]: Epoch 36 / 100: avg data time: 5.00e+00, avg batch time: 6.4446, average train loss: 59.4651
[11/24 03:01:38 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.5865, average loss: 48.3050
[11/24 03:01:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.81	
[11/24 03:01:38 visual_prompt]: Training 37 / 100 epoch, with learning rate 20.195768441570728
[11/24 03:09:08 visual_prompt]: Epoch 37 / 100: avg data time: 4.98e+00, avg batch time: 6.4287, average train loss: 32.2662
[11/24 03:10:00 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.5880, average loss: 72.6989
[11/24 03:10:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.26	
[11/24 03:10:00 visual_prompt]: Training 38 / 100 epoch, with learning rate 19.847315653655915
[11/24 03:17:30 visual_prompt]: Epoch 38 / 100: avg data time: 4.98e+00, avg batch time: 6.4212, average train loss: 42.5562
[11/24 03:18:21 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.5940, average loss: 4.2675
[11/24 03:18:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.39	
[11/24 03:18:21 visual_prompt]: Training 39 / 100 epoch, with learning rate 19.489911293384335
[11/24 03:25:49 visual_prompt]: Epoch 39 / 100: avg data time: 4.95e+00, avg batch time: 6.4019, average train loss: 36.5143
[11/24 03:26:40 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.5859, average loss: 4.1555
[11/24 03:26:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.22	
[11/24 03:26:40 visual_prompt]: Training 40 / 100 epoch, with learning rate 19.12399080291506
[11/24 03:34:07 visual_prompt]: Epoch 40 / 100: avg data time: 4.94e+00, avg batch time: 6.3834, average train loss: 39.6153
[11/24 03:34:58 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.5857, average loss: 7.0833
[11/24 03:34:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.75	
[11/24 03:34:58 visual_prompt]: Training 41 / 100 epoch, with learning rate 18.75
[11/24 03:42:27 visual_prompt]: Epoch 41 / 100: avg data time: 4.95e+00, avg batch time: 6.4028, average train loss: 19.3398
[11/24 03:43:18 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.5867, average loss: 206.9054
[11/24 03:43:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 42.06	
[11/24 03:43:18 visual_prompt]: Training 42 / 100 epoch, with learning rate 18.368394534823633
[11/24 03:50:43 visual_prompt]: Epoch 42 / 100: avg data time: 4.92e+00, avg batch time: 6.3655, average train loss: 50.4669
[11/24 03:51:34 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.5908, average loss: 4.0986
[11/24 03:51:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.62	
[11/24 03:51:34 visual_prompt]: Training 43 / 100 epoch, with learning rate 17.979639334863467
[11/24 03:59:01 visual_prompt]: Epoch 43 / 100: avg data time: 4.94e+00, avg batch time: 6.3797, average train loss: 43.5799
[11/24 03:59:52 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.5871, average loss: 134.5260
[11/24 03:59:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.64	
[11/24 03:59:52 visual_prompt]: Training 44 / 100 epoch, with learning rate 17.584208038447503
[11/24 04:07:18 visual_prompt]: Epoch 44 / 100: avg data time: 4.93e+00, avg batch time: 6.3825, average train loss: 45.4177
[11/24 04:08:09 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.5899, average loss: 15.0290
[11/24 04:08:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.72	
[11/24 04:08:09 visual_prompt]: Training 45 / 100 epoch, with learning rate 17.182582417698903
[11/24 04:15:37 visual_prompt]: Epoch 45 / 100: avg data time: 4.94e+00, avg batch time: 6.3927, average train loss: 28.1657
[11/24 04:16:28 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.5868, average loss: 9.0208
[11/24 04:16:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.76	
[11/24 04:16:28 visual_prompt]: Training 46 / 100 epoch, with learning rate 16.77525179157086
[11/24 04:23:56 visual_prompt]: Epoch 46 / 100: avg data time: 4.95e+00, avg batch time: 6.3979, average train loss: 44.4996
[11/24 04:24:48 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.5887, average loss: 50.9570
[11/24 04:24:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.11	
[11/24 04:24:48 visual_prompt]: Training 47 / 100 epoch, with learning rate 16.362712429686844
[11/24 04:32:17 visual_prompt]: Epoch 47 / 100: avg data time: 4.97e+00, avg batch time: 6.4200, average train loss: 24.0153
[11/24 04:33:09 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.5922, average loss: 4.7144
[11/24 04:33:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.99	
[11/24 04:33:09 visual_prompt]: Training 48 / 100 epoch, with learning rate 15.94546694771249
[11/24 04:40:38 visual_prompt]: Epoch 48 / 100: avg data time: 4.97e+00, avg batch time: 6.4194, average train loss: 24.9171
[11/24 04:41:30 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.5853, average loss: 7.9281
[11/24 04:41:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.84	
[11/24 04:41:30 visual_prompt]: Training 49 / 100 epoch, with learning rate 15.524023694995845
[11/24 04:48:51 visual_prompt]: Epoch 49 / 100: avg data time: 4.86e+00, avg batch time: 6.3022, average train loss: 31.3803
[11/24 04:49:41 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.5873, average loss: 111.4237
[11/24 04:49:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.74	
[11/24 04:49:41 visual_prompt]: Training 50 / 100 epoch, with learning rate 15.09889613522199
[11/24 04:57:03 visual_prompt]: Epoch 50 / 100: avg data time: 4.86e+00, avg batch time: 6.3045, average train loss: 33.0342
[11/24 04:57:53 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.5864, average loss: 26.8380
[11/24 04:57:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.96	
[11/24 04:57:53 visual_prompt]: Training 51 / 100 epoch, with learning rate 14.670602220836631
[11/24 05:05:17 visual_prompt]: Epoch 51 / 100: avg data time: 4.89e+00, avg batch time: 6.3409, average train loss: 30.8800
[11/24 05:06:08 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.5837, average loss: 4.9138
[11/24 05:06:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 38.36	
[11/24 05:06:08 visual_prompt]: Stopping early.
[11/24 05:06:08 visual_prompt]: Rank of current process: 0. World size: 1
[11/24 05:06:08 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/24 05:06:08 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/24 05:06:08 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/24 05:06:08 visual_prompt]: Training with config:
[11/24 05:06:08 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr25.0_wd0.0/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 25.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/24 05:06:08 visual_prompt]: Loading training data...
[11/24 05:06:08 visual_prompt]: Constructing mammo-cbis dataset train...
[11/24 05:06:08 visual_prompt]: Loading validation data...
[11/24 05:06:08 visual_prompt]: Constructing mammo-cbis dataset val...
[11/24 05:06:08 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/24 05:06:11 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/24 05:06:11 visual_prompt]: tuned percent:0.532
[11/24 05:06:11 visual_prompt]: Device used for model: 0
[11/24 05:06:11 visual_prompt]: Setting up Evaluator...
[11/24 05:06:11 visual_prompt]: Setting up Trainer...
[11/24 05:06:11 visual_prompt]: 	Setting up the optimizer...
[11/24 05:06:11 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/24 05:13:36 visual_prompt]: Epoch 1 / 100: avg data time: 4.92e+00, avg batch time: 6.3643, average train loss: 1.4863
[11/24 05:14:28 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.5845, average loss: 1.4553
[11/24 05:14:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/24 05:14:28 visual_prompt]: Training 2 / 100 epoch, with learning rate 2.5
[11/24 05:21:56 visual_prompt]: Epoch 2 / 100: avg data time: 4.95e+00, avg batch time: 6.4050, average train loss: 12.0091
[11/24 05:22:47 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.5861, average loss: 5.3519
[11/24 05:22:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.88	
[11/24 05:22:47 visual_prompt]: Training 3 / 100 epoch, with learning rate 5.0
[11/24 05:30:16 visual_prompt]: Epoch 3 / 100: avg data time: 4.96e+00, avg batch time: 6.4109, average train loss: 12.7435
[11/24 05:31:07 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.5881, average loss: 21.8348
[11/24 05:31:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.51	
[11/24 05:31:07 visual_prompt]: Training 4 / 100 epoch, with learning rate 7.5
[11/24 05:38:36 visual_prompt]: Epoch 4 / 100: avg data time: 4.96e+00, avg batch time: 6.4085, average train loss: 28.3749
[11/24 05:39:27 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.5862, average loss: 21.9880
[11/24 05:39:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.76	
[11/24 05:39:27 visual_prompt]: Training 5 / 100 epoch, with learning rate 10.0
[11/24 05:46:54 visual_prompt]: Epoch 5 / 100: avg data time: 4.94e+00, avg batch time: 6.3892, average train loss: 30.4389
[11/24 05:47:46 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.5867, average loss: 17.9642
[11/24 05:47:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.47	
[11/24 05:47:46 visual_prompt]: Training 6 / 100 epoch, with learning rate 12.5
[11/24 05:55:16 visual_prompt]: Epoch 6 / 100: avg data time: 4.98e+00, avg batch time: 6.4260, average train loss: 38.2745
[11/24 05:56:07 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.5855, average loss: 24.7019
[11/24 05:56:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.51	
[11/24 05:56:07 visual_prompt]: Training 7 / 100 epoch, with learning rate 15.0
[11/24 06:03:34 visual_prompt]: Epoch 7 / 100: avg data time: 4.94e+00, avg batch time: 6.3889, average train loss: 17.9071
[11/24 06:04:25 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.5885, average loss: 54.3213
[11/24 06:04:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.54	
[11/24 06:04:25 visual_prompt]: Training 8 / 100 epoch, with learning rate 17.5
[11/24 06:11:54 visual_prompt]: Epoch 8 / 100: avg data time: 4.96e+00, avg batch time: 6.4111, average train loss: 37.1880
[11/24 06:12:44 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.5856, average loss: 25.2939
[11/24 06:12:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.58	
[11/24 06:12:44 visual_prompt]: Training 9 / 100 epoch, with learning rate 20.0
[11/24 06:20:13 visual_prompt]: Epoch 9 / 100: avg data time: 4.96e+00, avg batch time: 6.4032, average train loss: 32.9157
[11/24 06:21:04 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.5851, average loss: 7.0755
[11/24 06:21:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.00	
[11/24 06:21:04 visual_prompt]: Training 10 / 100 epoch, with learning rate 22.5
[11/24 06:28:32 visual_prompt]: Epoch 10 / 100: avg data time: 4.96e+00, avg batch time: 6.4036, average train loss: 29.5431
[11/24 06:29:24 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.5870, average loss: 16.9934
[11/24 06:29:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.65	
[11/24 06:29:24 visual_prompt]: Training 11 / 100 epoch, with learning rate 25.0
[11/24 06:36:53 visual_prompt]: Epoch 11 / 100: avg data time: 4.96e+00, avg batch time: 6.4117, average train loss: 24.2630
[11/24 06:37:45 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.5900, average loss: 22.6335
[11/24 06:37:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.87	
[11/24 06:37:45 visual_prompt]: Training 12 / 100 epoch, with learning rate 24.9923853377387
[11/24 06:45:14 visual_prompt]: Epoch 12 / 100: avg data time: 4.97e+00, avg batch time: 6.4221, average train loss: 35.4042
[11/24 06:46:06 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.5857, average loss: 49.3523
[11/24 06:46:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 45.53	
[11/24 06:46:06 visual_prompt]: Training 13 / 100 epoch, with learning rate 24.969550628247802
[11/24 06:53:41 visual_prompt]: Epoch 13 / 100: avg data time: 5.04e+00, avg batch time: 6.4906, average train loss: 24.6365
[11/24 06:54:32 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.5837, average loss: 52.9193
[11/24 06:54:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.96	
[11/24 06:54:32 visual_prompt]: Training 14 / 100 epoch, with learning rate 24.931523692103415
[11/24 07:02:07 visual_prompt]: Epoch 14 / 100: avg data time: 5.04e+00, avg batch time: 6.4868, average train loss: 31.0816
[11/24 07:02:58 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.5851, average loss: 8.3084
[11/24 07:02:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.55	
[11/24 07:02:58 visual_prompt]: Best epoch 14: best metric: -8.308
[11/24 07:02:58 visual_prompt]: Training 15 / 100 epoch, with learning rate 24.87835085926963
[11/24 07:10:31 visual_prompt]: Epoch 15 / 100: avg data time: 5.01e+00, avg batch time: 6.4565, average train loss: 34.8043
[11/24 07:11:22 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.5868, average loss: 9.7471
[11/24 07:11:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.99	
[11/24 07:11:22 visual_prompt]: Training 16 / 100 epoch, with learning rate 24.8100969126526
[11/24 07:18:56 visual_prompt]: Epoch 16 / 100: avg data time: 5.04e+00, avg batch time: 6.4815, average train loss: 66.6468
[11/24 07:19:48 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.5865, average loss: 36.3207
[11/24 07:19:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.19	
[11/24 07:19:48 visual_prompt]: Training 17 / 100 epoch, with learning rate 24.72684500917257
[11/24 07:27:22 visual_prompt]: Epoch 17 / 100: avg data time: 5.03e+00, avg batch time: 6.4785, average train loss: 17.2166
[11/24 07:28:14 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.5890, average loss: 35.5849
[11/24 07:28:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.25	
[11/24 07:28:14 visual_prompt]: Training 18 / 100 epoch, with learning rate 24.628696578449954
[11/24 07:35:47 visual_prompt]: Epoch 18 / 100: avg data time: 5.02e+00, avg batch time: 6.4647, average train loss: 21.8187
[11/24 07:36:38 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.5876, average loss: 6.5733
[11/24 07:36:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.44	
[11/24 07:36:38 visual_prompt]: Best epoch 18: best metric: -6.573
[11/24 07:36:38 visual_prompt]: Training 19 / 100 epoch, with learning rate 24.515771199228986
[11/24 07:44:11 visual_prompt]: Epoch 19 / 100: avg data time: 5.02e+00, avg batch time: 6.4620, average train loss: 21.6233
[11/24 07:45:03 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.5862, average loss: 58.2876
[11/24 07:45:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.15	
[11/24 07:45:03 visual_prompt]: Training 20 / 100 epoch, with learning rate 24.38820645368942
[11/24 07:52:35 visual_prompt]: Epoch 20 / 100: avg data time: 5.02e+00, avg batch time: 6.4671, average train loss: 26.4669
[11/24 07:53:26 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.5867, average loss: 35.9255
[11/24 07:53:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.98	
[11/24 07:53:26 visual_prompt]: Training 21 / 100 epoch, with learning rate 24.246157759823856
[11/24 08:00:58 visual_prompt]: Epoch 21 / 100: avg data time: 5.00e+00, avg batch time: 6.4511, average train loss: 22.5894
[11/24 08:01:50 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.5850, average loss: 4.4938
[11/24 08:01:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.39	
[11/24 08:01:50 visual_prompt]: Best epoch 21: best metric: -4.494
[11/24 08:01:50 visual_prompt]: Training 22 / 100 epoch, with learning rate 24.08979818208484
[11/24 08:09:18 visual_prompt]: Epoch 22 / 100: avg data time: 4.96e+00, avg batch time: 6.4000, average train loss: 36.8448
[11/24 08:10:09 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.5864, average loss: 31.1177
[11/24 08:10:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.58	
[11/24 08:10:09 visual_prompt]: Training 23 / 100 epoch, with learning rate 23.91931822053251
[11/24 08:17:38 visual_prompt]: Epoch 23 / 100: avg data time: 4.97e+00, avg batch time: 6.4107, average train loss: 25.7429
[11/24 08:18:29 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.5852, average loss: 27.3958
[11/24 08:18:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.39	
[11/24 08:18:29 visual_prompt]: Training 24 / 100 epoch, with learning rate 23.73492557873959
[11/24 08:25:57 visual_prompt]: Epoch 24 / 100: avg data time: 4.95e+00, avg batch time: 6.4024, average train loss: 22.0812
[11/24 08:26:49 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.5870, average loss: 16.3876
[11/24 08:26:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.90	
[11/24 08:26:49 visual_prompt]: Training 25 / 100 epoch, with learning rate 23.536844910736587
[11/24 08:34:19 visual_prompt]: Epoch 25 / 100: avg data time: 4.98e+00, avg batch time: 6.4272, average train loss: 27.0851
[11/24 08:35:10 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.5873, average loss: 19.4446
[11/24 08:35:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.63	
[11/24 08:35:10 visual_prompt]: Training 26 / 100 epoch, with learning rate 23.325317547305485
[11/24 08:42:39 visual_prompt]: Epoch 26 / 100: avg data time: 4.96e+00, avg batch time: 6.4145, average train loss: 16.4704
[11/24 08:43:31 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.5912, average loss: 2.5804
[11/24 08:43:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 44.72	rocauc: 58.80	
[11/24 08:43:31 visual_prompt]: Best epoch 26: best metric: -2.580
[11/24 08:43:31 visual_prompt]: Training 27 / 100 epoch, with learning rate 23.100601201955325
[11/24 08:50:57 visual_prompt]: Epoch 27 / 100: avg data time: 4.93e+00, avg batch time: 6.3767, average train loss: 36.2296
[11/24 08:51:47 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.5887, average loss: 63.0418
[11/24 08:51:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.72	
[11/24 08:51:48 visual_prompt]: Training 28 / 100 epoch, with learning rate 22.86296965693802
[11/24 08:59:16 visual_prompt]: Epoch 28 / 100: avg data time: 4.97e+00, avg batch time: 6.4080, average train loss: 45.4160
[11/24 09:00:07 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.5860, average loss: 5.5664
[11/24 09:00:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.39	
[11/24 09:00:07 visual_prompt]: Training 29 / 100 epoch, with learning rate 22.612712429686844
[11/24 09:07:37 visual_prompt]: Epoch 29 / 100: avg data time: 4.97e+00, avg batch time: 6.4217, average train loss: 19.8106
[11/24 09:08:29 visual_prompt]: Inference (val):avg data time: 2.03e-03, avg batch time: 0.5914, average loss: 4.8114
[11/24 09:08:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.27	
[11/24 09:08:29 visual_prompt]: Training 30 / 100 epoch, with learning rate 22.35013442008402
[11/24 09:16:02 visual_prompt]: Epoch 30 / 100: avg data time: 5.02e+00, avg batch time: 6.4747, average train loss: 12.8429
[11/24 09:16:54 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.5892, average loss: 24.3753
[11/24 09:16:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.03	
[11/24 09:16:54 visual_prompt]: Training 31 / 100 epoch, with learning rate 22.075555538987224
[11/24 09:24:24 visual_prompt]: Epoch 31 / 100: avg data time: 4.99e+00, avg batch time: 6.4341, average train loss: 31.7836
[11/24 09:25:16 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.5841, average loss: 2.1278
[11/24 09:25:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 47.56	rocauc: 60.76	
[11/24 09:25:16 visual_prompt]: Best epoch 31: best metric: -2.128
[11/24 09:25:16 visual_prompt]: Training 32 / 100 epoch, with learning rate 21.78931031846743
[11/24 09:32:48 visual_prompt]: Epoch 32 / 100: avg data time: 5.01e+00, avg batch time: 6.4580, average train loss: 10.5953
[11/24 09:33:39 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.5859, average loss: 12.6125
[11/24 09:33:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.98	
[11/24 09:33:39 visual_prompt]: Training 33 / 100 epoch, with learning rate 21.49174750423314
[11/24 09:41:07 visual_prompt]: Epoch 33 / 100: avg data time: 4.95e+00, avg batch time: 6.3971, average train loss: 24.0571
[11/24 09:41:58 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.5889, average loss: 3.9808
[11/24 09:41:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 62.03	
[11/24 09:41:58 visual_prompt]: Training 34 / 100 epoch, with learning rate 21.183229630737465
[11/24 09:49:25 visual_prompt]: Epoch 34 / 100: avg data time: 4.93e+00, avg batch time: 6.3799, average train loss: 14.0902
[11/24 09:50:16 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.5850, average loss: 5.2535
[11/24 09:50:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.20	
[11/24 09:50:16 visual_prompt]: Training 35 / 100 epoch, with learning rate 20.864132579485727
[11/24 09:57:43 visual_prompt]: Epoch 35 / 100: avg data time: 4.94e+00, avg batch time: 6.3872, average train loss: 18.7800
[11/24 09:58:34 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.5849, average loss: 19.7491
[11/24 09:58:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.23	
[11/24 09:58:34 visual_prompt]: Training 36 / 100 epoch, with learning rate 20.53484512108174
[11/24 10:06:04 visual_prompt]: Epoch 36 / 100: avg data time: 4.98e+00, avg batch time: 6.4237, average train loss: 16.4630
[11/24 10:06:55 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.5893, average loss: 28.7687
[11/24 10:06:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 63.87	
[11/24 10:06:55 visual_prompt]: Training 37 / 100 epoch, with learning rate 20.195768441570728
[11/24 10:14:23 visual_prompt]: Epoch 37 / 100: avg data time: 4.94e+00, avg batch time: 6.3883, average train loss: 20.7447
[11/24 10:15:14 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.5898, average loss: 34.2183
[11/24 10:15:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.61	
[11/24 10:15:14 visual_prompt]: Training 38 / 100 epoch, with learning rate 19.847315653655915
[11/24 10:22:43 visual_prompt]: Epoch 38 / 100: avg data time: 4.95e+00, avg batch time: 6.4044, average train loss: 15.3798
[11/24 10:23:34 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.5889, average loss: 50.9128
[11/24 10:23:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.47	
[11/24 10:23:34 visual_prompt]: Training 39 / 100 epoch, with learning rate 19.489911293384335
[11/24 10:31:04 visual_prompt]: Epoch 39 / 100: avg data time: 4.97e+00, avg batch time: 6.4236, average train loss: 27.5735
[11/24 10:31:55 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.5862, average loss: 19.0553
[11/24 10:31:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 62.25	
[11/24 10:31:55 visual_prompt]: Training 40 / 100 epoch, with learning rate 19.12399080291506
[11/24 10:39:22 visual_prompt]: Epoch 40 / 100: avg data time: 4.93e+00, avg batch time: 6.3901, average train loss: 11.9866
[11/24 10:40:13 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.5882, average loss: 4.5235
[11/24 10:40:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 47.97	rocauc: 63.94	
[11/24 10:40:13 visual_prompt]: Training 41 / 100 epoch, with learning rate 18.75
[11/24 10:47:41 visual_prompt]: Epoch 41 / 100: avg data time: 4.94e+00, avg batch time: 6.3980, average train loss: 9.0450
[11/24 10:48:33 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.5861, average loss: 20.2232
[11/24 10:48:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.34	
[11/24 10:48:33 visual_prompt]: Training 42 / 100 epoch, with learning rate 18.368394534823633
[11/24 10:56:00 visual_prompt]: Epoch 42 / 100: avg data time: 4.94e+00, avg batch time: 6.3912, average train loss: 7.0879
[11/24 10:56:51 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.5867, average loss: 1.3983
[11/24 10:56:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 64.39	
[11/24 10:56:51 visual_prompt]: Best epoch 42: best metric: -1.398
[11/24 10:56:51 visual_prompt]: Training 43 / 100 epoch, with learning rate 17.979639334863467
[11/24 11:04:19 visual_prompt]: Epoch 43 / 100: avg data time: 4.95e+00, avg batch time: 6.4018, average train loss: 14.8000
[11/24 11:05:11 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.5857, average loss: 18.5769
[11/24 11:05:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 67.19	
[11/24 11:05:11 visual_prompt]: Training 44 / 100 epoch, with learning rate 17.584208038447503
[11/24 11:12:42 visual_prompt]: Epoch 44 / 100: avg data time: 4.99e+00, avg batch time: 6.4408, average train loss: 14.2442
[11/24 11:13:33 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.5866, average loss: 16.6304
[11/24 11:13:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 64.74	
[11/24 11:13:33 visual_prompt]: Training 45 / 100 epoch, with learning rate 17.182582417698903
[11/24 11:21:03 visual_prompt]: Epoch 45 / 100: avg data time: 4.97e+00, avg batch time: 6.4248, average train loss: 9.1219
[11/24 11:21:54 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.5876, average loss: 9.5314
[11/24 11:21:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 63.70	
[11/24 11:21:54 visual_prompt]: Training 46 / 100 epoch, with learning rate 16.77525179157086
[11/24 11:29:28 visual_prompt]: Epoch 46 / 100: avg data time: 5.03e+00, avg batch time: 6.4786, average train loss: 6.9335
[11/24 11:30:20 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.5859, average loss: 6.1607
[11/24 11:30:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 65.45	
[11/24 11:30:20 visual_prompt]: Training 47 / 100 epoch, with learning rate 16.362712429686844
[11/24 11:37:53 visual_prompt]: Epoch 47 / 100: avg data time: 5.02e+00, avg batch time: 6.4697, average train loss: 6.3023
[11/24 11:38:45 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.5884, average loss: 5.9604
[11/24 11:38:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 63.55	
[11/24 11:38:45 visual_prompt]: Training 48 / 100 epoch, with learning rate 15.94546694771249
[11/24 11:46:17 visual_prompt]: Epoch 48 / 100: avg data time: 5.01e+00, avg batch time: 6.4642, average train loss: 10.8818
[11/24 11:47:09 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.5868, average loss: 4.0505
[11/24 11:47:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 67.84	
[11/24 11:47:09 visual_prompt]: Training 49 / 100 epoch, with learning rate 15.524023694995845
[11/24 11:54:40 visual_prompt]: Epoch 49 / 100: avg data time: 5.00e+00, avg batch time: 6.4503, average train loss: 5.2683
[11/24 11:55:32 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.5848, average loss: 12.3859
[11/24 11:55:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 64.71	
[11/24 11:55:32 visual_prompt]: Training 50 / 100 epoch, with learning rate 15.09889613522199
[11/24 12:03:04 visual_prompt]: Epoch 50 / 100: avg data time: 5.01e+00, avg batch time: 6.4564, average train loss: 10.7237
[11/24 12:03:56 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.5864, average loss: 22.7845
[11/24 12:03:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.22	
[11/24 12:03:56 visual_prompt]: Training 51 / 100 epoch, with learning rate 14.670602220836631
[11/24 12:11:26 visual_prompt]: Epoch 51 / 100: avg data time: 4.97e+00, avg batch time: 6.4264, average train loss: 6.8120
[11/24 12:12:16 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.5857, average loss: 14.6110
[11/24 12:12:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 64.73	
[11/24 12:12:16 visual_prompt]: Training 52 / 100 epoch, with learning rate 14.239663762000818
[11/24 12:19:37 visual_prompt]: Epoch 52 / 100: avg data time: 4.85e+00, avg batch time: 6.3026, average train loss: 8.3853
[11/24 12:20:27 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.5856, average loss: 10.9722
[11/24 12:20:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.84	
[11/24 12:20:27 visual_prompt]: Training 53 / 100 epoch, with learning rate 13.80660579084567
[11/24 12:27:51 visual_prompt]: Epoch 53 / 100: avg data time: 4.88e+00, avg batch time: 6.3282, average train loss: 6.7071
[11/24 12:28:41 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.5877, average loss: 13.6650
[11/24 12:28:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 64.58	
[11/24 12:28:41 visual_prompt]: Training 54 / 100 epoch, with learning rate 13.371955921801565
[11/24 12:36:03 visual_prompt]: Epoch 54 / 100: avg data time: 4.86e+00, avg batch time: 6.3170, average train loss: 5.6029
[11/24 12:36:54 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.5897, average loss: 26.8152
[11/24 12:36:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 67.03	
[11/24 12:36:54 visual_prompt]: Training 55 / 100 epoch, with learning rate 12.936243708781264
[11/24 12:44:13 visual_prompt]: Epoch 55 / 100: avg data time: 4.83e+00, avg batch time: 6.2832, average train loss: 11.5853
[11/24 12:45:03 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.5846, average loss: 1.6903
[11/24 12:45:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.47	rocauc: 64.94	
[11/24 12:45:03 visual_prompt]: Training 56 / 100 epoch, with learning rate 12.5
[11/24 12:52:25 visual_prompt]: Epoch 56 / 100: avg data time: 4.85e+00, avg batch time: 6.3005, average train loss: 3.3948
[11/24 12:53:14 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.5831, average loss: 3.6458
[11/24 12:53:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.44	
[11/24 12:53:14 visual_prompt]: Training 57 / 100 epoch, with learning rate 12.063756291218741
[11/24 13:00:34 visual_prompt]: Epoch 57 / 100: avg data time: 4.83e+00, avg batch time: 6.2789, average train loss: 7.9843
[11/24 13:01:25 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.5862, average loss: 20.9372
[11/24 13:01:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 63.85	
[11/24 13:01:25 visual_prompt]: Training 58 / 100 epoch, with learning rate 11.628044078198434
[11/24 13:08:46 visual_prompt]: Epoch 58 / 100: avg data time: 4.85e+00, avg batch time: 6.2974, average train loss: 7.7748
[11/24 13:09:36 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.5836, average loss: 18.4434
[11/24 13:09:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 64.90	
[11/24 13:09:36 visual_prompt]: Training 59 / 100 epoch, with learning rate 11.193394209154334
[11/24 13:16:57 visual_prompt]: Epoch 59 / 100: avg data time: 4.85e+00, avg batch time: 6.3000, average train loss: 9.6328
[11/24 13:17:48 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.5855, average loss: 1.6665
[11/24 13:17:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 50.81	rocauc: 66.93	
[11/24 13:17:48 visual_prompt]: Training 60 / 100 epoch, with learning rate 10.760336237999185
[11/24 13:25:15 visual_prompt]: Epoch 60 / 100: avg data time: 4.92e+00, avg batch time: 6.3742, average train loss: 6.4325
[11/24 13:26:06 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.5863, average loss: 2.5907
[11/24 13:26:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 65.58	
[11/24 13:26:06 visual_prompt]: Training 61 / 100 epoch, with learning rate 10.32939777916337
[11/24 13:33:33 visual_prompt]: Epoch 61 / 100: avg data time: 4.94e+00, avg batch time: 6.3879, average train loss: 6.2665
[11/24 13:34:24 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.5891, average loss: 12.3742
[11/24 13:34:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 66.05	
[11/24 13:34:24 visual_prompt]: Training 62 / 100 epoch, with learning rate 9.90110386477801
[11/24 13:41:51 visual_prompt]: Epoch 62 / 100: avg data time: 4.93e+00, avg batch time: 6.3819, average train loss: 4.7121
[11/24 13:42:42 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.5865, average loss: 1.1892
[11/24 13:42:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 50.81	rocauc: 68.58	
[11/24 13:42:42 visual_prompt]: Best epoch 62: best metric: -1.189
[11/24 13:42:42 visual_prompt]: Training 63 / 100 epoch, with learning rate 9.475976305004155
[11/24 13:50:10 visual_prompt]: Epoch 63 / 100: avg data time: 4.94e+00, avg batch time: 6.3944, average train loss: 5.7413
[11/24 13:51:00 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.5864, average loss: 3.0515
[11/24 13:51:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 66.62	
[11/24 13:51:00 visual_prompt]: Training 64 / 100 epoch, with learning rate 9.05453305228751
[11/24 13:58:28 visual_prompt]: Epoch 64 / 100: avg data time: 4.95e+00, avg batch time: 6.3943, average train loss: 3.8286
[11/24 13:59:19 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.5863, average loss: 1.9961
[11/24 13:59:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 52.44	rocauc: 66.94	
[11/24 13:59:19 visual_prompt]: Training 65 / 100 epoch, with learning rate 8.637287570313159
[11/24 14:06:48 visual_prompt]: Epoch 65 / 100: avg data time: 4.95e+00, avg batch time: 6.4041, average train loss: 3.0184
[11/24 14:07:39 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.5868, average loss: 10.6221
[11/24 14:07:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 69.21	
[11/24 14:07:39 visual_prompt]: Training 66 / 100 epoch, with learning rate 8.224748208429142
[11/24 14:15:08 visual_prompt]: Epoch 66 / 100: avg data time: 4.95e+00, avg batch time: 6.4071, average train loss: 4.6698
[11/24 14:15:59 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.5831, average loss: 0.6584
[11/24 14:15:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 68.57	
[11/24 14:15:59 visual_prompt]: Best epoch 66: best metric: -0.658
[11/24 14:15:59 visual_prompt]: Training 67 / 100 epoch, with learning rate 7.817417582301099
[11/24 14:23:25 visual_prompt]: Epoch 67 / 100: avg data time: 4.93e+00, avg batch time: 6.3789, average train loss: 4.8385
[11/24 14:24:17 visual_prompt]: Inference (val):avg data time: 3.03e-03, avg batch time: 0.5903, average loss: 5.2117
[11/24 14:24:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.47	rocauc: 66.61	
[11/24 14:24:17 visual_prompt]: Training 68 / 100 epoch, with learning rate 7.415791961552499
[11/24 14:31:43 visual_prompt]: Epoch 68 / 100: avg data time: 4.93e+00, avg batch time: 6.3810, average train loss: 3.4332
[11/24 14:32:35 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.5906, average loss: 3.7470
[11/24 14:32:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 68.33	
[11/24 14:32:35 visual_prompt]: Training 69 / 100 epoch, with learning rate 7.020360665136531
[11/24 14:40:04 visual_prompt]: Epoch 69 / 100: avg data time: 4.95e+00, avg batch time: 6.4068, average train loss: 2.8739
[11/24 14:40:55 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.5877, average loss: 2.3747
[11/24 14:40:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.07	rocauc: 67.67	
[11/24 14:40:55 visual_prompt]: Training 70 / 100 epoch, with learning rate 6.631605465176368
[11/24 14:48:24 visual_prompt]: Epoch 70 / 100: avg data time: 4.96e+00, avg batch time: 6.4105, average train loss: 2.2298
[11/24 14:49:16 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.5849, average loss: 8.7844
[11/24 14:49:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 68.37	
[11/24 14:49:16 visual_prompt]: Training 71 / 100 epoch, with learning rate 6.250000000000003
[11/24 14:56:43 visual_prompt]: Epoch 71 / 100: avg data time: 4.94e+00, avg batch time: 6.3890, average train loss: 3.1477
[11/24 14:57:35 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.5847, average loss: 2.2009
[11/24 14:57:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 70.43	
[11/24 14:57:35 visual_prompt]: Training 72 / 100 epoch, with learning rate 5.87600919708494
[11/24 15:05:08 visual_prompt]: Epoch 72 / 100: avg data time: 5.01e+00, avg batch time: 6.4670, average train loss: 1.8570
[11/24 15:06:00 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.5877, average loss: 1.9290
[11/24 15:06:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 67.37	
[11/24 15:06:00 visual_prompt]: Training 73 / 100 epoch, with learning rate 5.510088706615666
[11/24 15:13:34 visual_prompt]: Epoch 73 / 100: avg data time: 5.04e+00, avg batch time: 6.4912, average train loss: 1.5541
[11/24 15:14:26 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.5853, average loss: 1.7137
[11/24 15:14:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 68.58	
[11/24 15:14:26 visual_prompt]: Training 74 / 100 epoch, with learning rate 5.1526843463440875
[11/24 15:22:00 visual_prompt]: Epoch 74 / 100: avg data time: 5.03e+00, avg batch time: 6.4831, average train loss: 1.4742
[11/24 15:22:52 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.5853, average loss: 0.9253
[11/24 15:22:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 52.85	rocauc: 70.53	
[11/24 15:22:52 visual_prompt]: Training 75 / 100 epoch, with learning rate 4.804231558429271
[11/24 15:30:26 visual_prompt]: Epoch 75 / 100: avg data time: 5.04e+00, avg batch time: 6.4892, average train loss: 1.3149
[11/24 15:31:18 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.5954, average loss: 2.1668
[11/24 15:31:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 70.65	
[11/24 15:31:18 visual_prompt]: Training 76 / 100 epoch, with learning rate 4.465154878918258
[11/24 15:38:52 visual_prompt]: Epoch 76 / 100: avg data time: 5.02e+00, avg batch time: 6.4761, average train loss: 1.7072
[11/24 15:39:44 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.5868, average loss: 0.8982
[11/24 15:39:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 69.01	
[11/24 15:39:44 visual_prompt]: Training 77 / 100 epoch, with learning rate 4.135867420514276
[11/24 15:47:19 visual_prompt]: Epoch 77 / 100: avg data time: 5.05e+00, avg batch time: 6.4964, average train loss: 1.8437
[11/24 15:48:11 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.5870, average loss: 1.1184
[11/24 15:48:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 70.16	
[11/24 15:48:11 visual_prompt]: Training 78 / 100 epoch, with learning rate 3.816770369262533
[11/24 15:55:44 visual_prompt]: Epoch 78 / 100: avg data time: 5.01e+00, avg batch time: 6.4652, average train loss: 1.3423
[11/24 15:56:36 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.5847, average loss: 2.6291
[11/24 15:56:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 71.57	
[11/24 15:56:36 visual_prompt]: Training 79 / 100 epoch, with learning rate 3.508252495766863
[11/24 16:04:08 visual_prompt]: Epoch 79 / 100: avg data time: 5.01e+00, avg batch time: 6.4647, average train loss: 1.3560
[11/24 16:05:00 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.5914, average loss: 2.1621
[11/24 16:05:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 70.01	
[11/24 16:05:00 visual_prompt]: Training 80 / 100 epoch, with learning rate 3.2106896815325707
[11/24 16:12:32 visual_prompt]: Epoch 80 / 100: avg data time: 5.01e+00, avg batch time: 6.4614, average train loss: 0.9738
[11/24 16:13:24 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.5897, average loss: 0.8357
[11/24 16:13:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 52.03	rocauc: 70.41	
[11/24 16:13:24 visual_prompt]: Training 81 / 100 epoch, with learning rate 2.924444461012776
[11/24 16:20:53 visual_prompt]: Epoch 81 / 100: avg data time: 4.96e+00, avg batch time: 6.4088, average train loss: 1.0392
[11/24 16:21:44 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.5859, average loss: 1.4842
[11/24 16:21:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 70.96	
[11/24 16:21:44 visual_prompt]: Training 82 / 100 epoch, with learning rate 2.6498655799159763
[11/24 16:29:13 visual_prompt]: Epoch 82 / 100: avg data time: 4.96e+00, avg batch time: 6.4151, average train loss: 1.0679
[11/24 16:30:04 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.5862, average loss: 2.1903
[11/24 16:30:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 70.13	
[11/24 16:30:04 visual_prompt]: Training 83 / 100 epoch, with learning rate 2.387287570313158
[11/24 16:37:32 visual_prompt]: Epoch 83 / 100: avg data time: 4.94e+00, avg batch time: 6.3886, average train loss: 1.1526
[11/24 16:38:23 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.5836, average loss: 1.3204
[11/24 16:38:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 70.18	
[11/24 16:38:23 visual_prompt]: Training 84 / 100 epoch, with learning rate 2.13703034306198
[11/24 16:45:52 visual_prompt]: Epoch 84 / 100: avg data time: 4.97e+00, avg batch time: 6.4186, average train loss: 0.8281
[11/24 16:46:44 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.5860, average loss: 1.5813
[11/24 16:46:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 70.35	
[11/24 16:46:44 visual_prompt]: Training 85 / 100 epoch, with learning rate 1.8993987980446756
[11/24 16:54:13 visual_prompt]: Epoch 85 / 100: avg data time: 4.97e+00, avg batch time: 6.4215, average train loss: 0.8609
[11/24 16:55:04 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.5903, average loss: 0.6442
[11/24 16:55:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 70.26	
[11/24 16:55:04 visual_prompt]: Best epoch 85: best metric: -0.644
[11/24 16:55:04 visual_prompt]: Training 86 / 100 epoch, with learning rate 1.674682452694516
[11/24 17:02:33 visual_prompt]: Epoch 86 / 100: avg data time: 4.96e+00, avg batch time: 6.4064, average train loss: 0.8373
[11/24 17:03:24 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.5903, average loss: 0.6706
[11/24 17:03:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 69.09	
[11/24 17:03:24 visual_prompt]: Training 87 / 100 epoch, with learning rate 1.4631550892634126
[11/24 17:10:54 visual_prompt]: Epoch 87 / 100: avg data time: 4.96e+00, avg batch time: 6.4203, average train loss: 0.9047
[11/24 17:11:45 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.5882, average loss: 0.7158
[11/24 17:11:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 69.23	
[11/24 17:11:45 visual_prompt]: Training 88 / 100 epoch, with learning rate 1.2650744212604148
[11/24 17:19:14 visual_prompt]: Epoch 88 / 100: avg data time: 4.97e+00, avg batch time: 6.4189, average train loss: 0.8010
[11/24 17:20:06 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.5879, average loss: 0.7413
[11/24 17:20:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 69.24	
[11/24 17:20:06 visual_prompt]: Training 89 / 100 epoch, with learning rate 1.0806817794674877
[11/24 17:27:36 visual_prompt]: Epoch 89 / 100: avg data time: 4.97e+00, avg batch time: 6.4235, average train loss: 0.7841
[11/24 17:28:28 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.5860, average loss: 0.7806
[11/24 17:28:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 69.15	
[11/24 17:28:28 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.9102018179151585
[11/24 17:36:02 visual_prompt]: Epoch 90 / 100: avg data time: 5.03e+00, avg batch time: 6.4815, average train loss: 0.7971
[11/24 17:36:53 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.5866, average loss: 1.0313
[11/24 17:36:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.07	rocauc: 69.61	
[11/24 17:36:53 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.753842240176146
[11/24 17:44:26 visual_prompt]: Epoch 91 / 100: avg data time: 5.01e+00, avg batch time: 6.4723, average train loss: 0.7609
[11/24 17:45:18 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.5851, average loss: 0.6365
[11/24 17:45:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 69.70	
[11/24 17:45:18 visual_prompt]: Best epoch 91: best metric: -0.636
[11/24 17:45:18 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.6117935463105808
[11/24 17:52:52 visual_prompt]: Epoch 92 / 100: avg data time: 5.03e+00, avg batch time: 6.4842, average train loss: 0.7925
[11/24 17:53:44 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.5853, average loss: 0.8278
[11/24 17:53:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 69.53	
[11/24 17:53:44 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.4842288007710138
[11/24 18:01:17 visual_prompt]: Epoch 93 / 100: avg data time: 5.01e+00, avg batch time: 6.4628, average train loss: 0.6733
[11/24 18:02:08 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.5866, average loss: 0.6507
[11/24 18:02:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 69.48	
[11/24 18:02:08 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.3713034215500441
[11/24 18:09:41 visual_prompt]: Epoch 94 / 100: avg data time: 5.02e+00, avg batch time: 6.4686, average train loss: 0.6611
[11/24 18:10:32 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.5872, average loss: 0.6398
[11/24 18:10:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 69.52	
[11/24 18:10:32 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.2731549908274289
[11/24 18:18:02 visual_prompt]: Epoch 95 / 100: avg data time: 4.97e+00, avg batch time: 6.4198, average train loss: 0.6649
[11/24 18:18:53 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.5857, average loss: 0.6390
[11/24 18:18:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 69.44	
[11/24 18:18:53 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.18990308734739975
[11/24 18:26:21 visual_prompt]: Epoch 96 / 100: avg data time: 4.95e+00, avg batch time: 6.4016, average train loss: 0.6656
[11/24 18:27:13 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.5858, average loss: 0.6433
[11/24 18:27:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 69.50	
[11/24 18:27:13 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.12164914073037048
[11/24 18:34:41 visual_prompt]: Epoch 97 / 100: avg data time: 4.95e+00, avg batch time: 6.3966, average train loss: 0.6581
[11/24 18:35:32 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.5845, average loss: 0.6675
[11/24 18:35:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 69.46	
[11/24 18:35:32 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.06847630789658388
[11/24 18:43:01 visual_prompt]: Epoch 98 / 100: avg data time: 4.97e+00, avg batch time: 6.4206, average train loss: 0.6670
[11/24 18:43:52 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.5843, average loss: 0.6761
[11/24 18:43:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 69.48	
[11/24 18:43:52 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.03044937175219753
[11/24 18:51:20 visual_prompt]: Epoch 99 / 100: avg data time: 4.94e+00, avg batch time: 6.3953, average train loss: 0.6588
[11/24 18:52:11 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.5860, average loss: 0.6486
[11/24 18:52:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 69.49	
[11/24 18:52:11 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0076146622613029735
[11/24 18:59:40 visual_prompt]: Epoch 100 / 100: avg data time: 4.96e+00, avg batch time: 6.4141, average train loss: 0.6558
[11/24 19:00:32 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.5895, average loss: 0.6499
[11/24 19:00:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 69.48	
[11/24 19:00:32 visual_prompt]: Rank of current process: 0. World size: 1
[11/24 19:00:32 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/24 19:00:32 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/24 19:00:32 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/24 19:00:32 visual_prompt]: Training with config:
[11/24 19:00:32 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr10.0_wd0.01/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 10.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/24 19:00:32 visual_prompt]: Loading training data...
[11/24 19:00:32 visual_prompt]: Constructing mammo-cbis dataset train...
[11/24 19:00:32 visual_prompt]: Loading validation data...
[11/24 19:00:32 visual_prompt]: Constructing mammo-cbis dataset val...
[11/24 19:00:32 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/24 19:00:34 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/24 19:00:34 visual_prompt]: tuned percent:0.532
[11/24 19:00:34 visual_prompt]: Device used for model: 0
[11/24 19:00:34 visual_prompt]: Setting up Evaluator...
[11/24 19:00:34 visual_prompt]: Setting up Trainer...
[11/24 19:00:34 visual_prompt]: 	Setting up the optimizer...
[11/24 19:00:34 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/24 19:08:04 visual_prompt]: Epoch 1 / 100: avg data time: 4.97e+00, avg batch time: 6.4265, average train loss: 1.4863
[11/24 19:08:56 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.5877, average loss: 1.4553
[11/24 19:08:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/24 19:08:56 visual_prompt]: Training 2 / 100 epoch, with learning rate 1.0
[11/24 19:16:25 visual_prompt]: Epoch 2 / 100: avg data time: 4.96e+00, avg batch time: 6.4170, average train loss: 4.2628
[11/24 19:17:17 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.5887, average loss: 3.0798
[11/24 19:17:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.96	
[11/24 19:17:17 visual_prompt]: Training 3 / 100 epoch, with learning rate 2.0
[11/24 19:24:46 visual_prompt]: Epoch 3 / 100: avg data time: 4.96e+00, avg batch time: 6.4179, average train loss: 2.8057
[11/24 19:25:37 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.5849, average loss: 5.1767
[11/24 19:25:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.32	
[11/24 19:25:37 visual_prompt]: Training 4 / 100 epoch, with learning rate 3.0
[11/24 19:33:04 visual_prompt]: Epoch 4 / 100: avg data time: 4.93e+00, avg batch time: 6.3854, average train loss: 6.0841
[11/24 19:33:56 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.5877, average loss: 1.0925
[11/24 19:33:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.41	
[11/24 19:33:56 visual_prompt]: Training 5 / 100 epoch, with learning rate 4.0
[11/24 19:41:23 visual_prompt]: Epoch 5 / 100: avg data time: 4.94e+00, avg batch time: 6.3909, average train loss: 9.0258
[11/24 19:42:14 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.5892, average loss: 4.7054
[11/24 19:42:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.99	
[11/24 19:42:14 visual_prompt]: Training 6 / 100 epoch, with learning rate 5.0
[11/24 19:49:43 visual_prompt]: Epoch 6 / 100: avg data time: 4.96e+00, avg batch time: 6.4155, average train loss: 7.8715
[11/24 19:50:35 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.5852, average loss: 7.6205
[11/24 19:50:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.77	
[11/24 19:50:35 visual_prompt]: Training 7 / 100 epoch, with learning rate 6.0
[11/24 19:58:01 visual_prompt]: Epoch 7 / 100: avg data time: 4.91e+00, avg batch time: 6.3667, average train loss: 11.8376
[11/24 19:58:52 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.5862, average loss: 8.5169
[11/24 19:58:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.50	
[11/24 19:58:52 visual_prompt]: Training 8 / 100 epoch, with learning rate 7.0
[11/24 20:06:15 visual_prompt]: Epoch 8 / 100: avg data time: 4.88e+00, avg batch time: 6.3255, average train loss: 16.9194
[11/24 20:07:06 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.5855, average loss: 24.7710
[11/24 20:07:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 42.84	
[11/24 20:07:06 visual_prompt]: Training 9 / 100 epoch, with learning rate 8.0
[11/24 20:14:30 visual_prompt]: Epoch 9 / 100: avg data time: 4.89e+00, avg batch time: 6.3435, average train loss: 19.4422
[11/24 20:15:21 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.5904, average loss: 30.7351
[11/24 20:15:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.60	
[11/24 20:15:21 visual_prompt]: Training 10 / 100 epoch, with learning rate 9.0
[11/24 20:22:46 visual_prompt]: Epoch 10 / 100: avg data time: 4.90e+00, avg batch time: 6.3536, average train loss: 20.7824
[11/24 20:23:36 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.5877, average loss: 33.1404
[11/24 20:23:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.34	
[11/24 20:23:36 visual_prompt]: Training 11 / 100 epoch, with learning rate 10.0
[11/24 20:31:04 visual_prompt]: Epoch 11 / 100: avg data time: 4.94e+00, avg batch time: 6.3859, average train loss: 21.0017
[11/24 20:31:55 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.5891, average loss: 24.1618
[11/24 20:31:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.44	
[11/24 20:31:55 visual_prompt]: Training 12 / 100 epoch, with learning rate 9.996954135095478
[11/24 20:39:21 visual_prompt]: Epoch 12 / 100: avg data time: 4.93e+00, avg batch time: 6.3797, average train loss: 25.9167
[11/24 20:40:12 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.5887, average loss: 19.8308
[11/24 20:40:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.68	
[11/24 20:40:12 visual_prompt]: Best epoch 12: best metric: -19.831
[11/24 20:40:12 visual_prompt]: Training 13 / 100 epoch, with learning rate 9.987820251299121
[11/24 20:47:40 visual_prompt]: Epoch 13 / 100: avg data time: 4.95e+00, avg batch time: 6.3961, average train loss: 28.3131
[11/24 20:48:31 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.5868, average loss: 11.1644
[11/24 20:48:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 55.78	
[11/24 20:48:31 visual_prompt]: Best epoch 13: best metric: -11.164
[11/24 20:48:31 visual_prompt]: Training 14 / 100 epoch, with learning rate 9.972609476841367
[11/24 20:55:58 visual_prompt]: Epoch 14 / 100: avg data time: 4.94e+00, avg batch time: 6.3844, average train loss: 19.9398
[11/24 20:56:49 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.5872, average loss: 3.8987
[11/24 20:56:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.57	
[11/24 20:56:49 visual_prompt]: Best epoch 14: best metric: -3.899
[11/24 20:56:49 visual_prompt]: Training 15 / 100 epoch, with learning rate 9.951340343707852
[11/24 21:04:16 visual_prompt]: Epoch 15 / 100: avg data time: 4.93e+00, avg batch time: 6.3883, average train loss: 17.1764
[11/24 21:05:08 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.5856, average loss: 26.4822
[11/24 21:05:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 41.06	rocauc: 40.92	
[11/24 21:05:08 visual_prompt]: Training 16 / 100 epoch, with learning rate 9.924038765061042
[11/24 21:12:36 visual_prompt]: Epoch 16 / 100: avg data time: 4.95e+00, avg batch time: 6.4020, average train loss: 22.4121
[11/24 21:13:27 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.5892, average loss: 9.6794
[11/24 21:13:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 43.11	
[11/24 21:13:27 visual_prompt]: Training 17 / 100 epoch, with learning rate 9.890738003669028
[11/24 21:20:54 visual_prompt]: Epoch 17 / 100: avg data time: 4.93e+00, avg batch time: 6.3842, average train loss: 17.7470
[11/24 21:21:45 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.5872, average loss: 25.9551
[11/24 21:21:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.43	
[11/24 21:21:45 visual_prompt]: Training 18 / 100 epoch, with learning rate 9.851478631379981
[11/24 21:29:13 visual_prompt]: Epoch 18 / 100: avg data time: 4.95e+00, avg batch time: 6.4043, average train loss: 20.3399
[11/24 21:30:05 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.5870, average loss: 71.2985
[11/24 21:30:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.03	
[11/24 21:30:05 visual_prompt]: Training 19 / 100 epoch, with learning rate 9.806308479691594
[11/24 21:37:32 visual_prompt]: Epoch 19 / 100: avg data time: 4.93e+00, avg batch time: 6.3849, average train loss: 18.2647
[11/24 21:38:22 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.5860, average loss: 9.5806
[11/24 21:38:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.06	
[11/24 21:38:22 visual_prompt]: Training 20 / 100 epoch, with learning rate 9.755282581475768
[11/24 21:45:50 visual_prompt]: Epoch 20 / 100: avg data time: 4.94e+00, avg batch time: 6.3912, average train loss: 25.2810
[11/24 21:46:41 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.5875, average loss: 22.5832
[11/24 21:46:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 41.03	
[11/24 21:46:41 visual_prompt]: Training 21 / 100 epoch, with learning rate 9.698463103929543
[11/24 21:54:09 visual_prompt]: Epoch 21 / 100: avg data time: 4.95e+00, avg batch time: 6.4044, average train loss: 21.7394
[11/24 21:55:00 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.5907, average loss: 24.3224
[11/24 21:55:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 44.05	
[11/24 21:55:00 visual_prompt]: Training 22 / 100 epoch, with learning rate 9.635919272833938
[11/24 22:02:30 visual_prompt]: Epoch 22 / 100: avg data time: 4.98e+00, avg batch time: 6.4273, average train loss: 35.5453
[11/24 22:03:21 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.5877, average loss: 6.4928
[11/24 22:03:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.24	
[11/24 22:03:21 visual_prompt]: Training 23 / 100 epoch, with learning rate 9.567727288213003
[11/24 22:10:49 visual_prompt]: Epoch 23 / 100: avg data time: 4.95e+00, avg batch time: 6.4014, average train loss: 21.4196
[11/24 22:11:40 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.5893, average loss: 17.7449
[11/24 22:11:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 39.61	
[11/24 22:11:40 visual_prompt]: Training 24 / 100 epoch, with learning rate 9.493970231495835
[11/24 22:19:08 visual_prompt]: Epoch 24 / 100: avg data time: 4.94e+00, avg batch time: 6.3859, average train loss: 23.0666
[11/24 22:19:59 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.5857, average loss: 69.2306
[11/24 22:19:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.45	
[11/24 22:19:59 visual_prompt]: Training 25 / 100 epoch, with learning rate 9.414737964294634
[11/24 22:27:27 visual_prompt]: Epoch 25 / 100: avg data time: 4.95e+00, avg batch time: 6.3987, average train loss: 27.6949
[11/24 22:28:18 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.5892, average loss: 70.0105
[11/24 22:28:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.41	
[11/24 22:28:18 visual_prompt]: Training 26 / 100 epoch, with learning rate 9.330127018922195
[11/24 22:35:44 visual_prompt]: Epoch 26 / 100: avg data time: 4.92e+00, avg batch time: 6.3697, average train loss: 21.9503
[11/24 22:36:35 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.5920, average loss: 28.9259
[11/24 22:36:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.27	
[11/24 22:36:35 visual_prompt]: Training 27 / 100 epoch, with learning rate 9.240240480782129
[11/24 22:43:59 visual_prompt]: Epoch 27 / 100: avg data time: 4.89e+00, avg batch time: 6.3396, average train loss: 23.8609
[11/24 22:44:50 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.5890, average loss: 15.4007
[11/24 22:44:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.99	
[11/24 22:44:50 visual_prompt]: Training 28 / 100 epoch, with learning rate 9.145187862775208
[11/24 22:52:16 visual_prompt]: Epoch 28 / 100: avg data time: 4.92e+00, avg batch time: 6.3711, average train loss: 23.3968
[11/24 22:53:07 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.5887, average loss: 18.5482
[11/24 22:53:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.14	
[11/24 22:53:07 visual_prompt]: Training 29 / 100 epoch, with learning rate 9.045084971874736
[11/24 23:00:31 visual_prompt]: Epoch 29 / 100: avg data time: 4.88e+00, avg batch time: 6.3308, average train loss: 21.5869
[11/24 23:01:21 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.5883, average loss: 35.3483
[11/24 23:01:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.90	
[11/24 23:01:21 visual_prompt]: Training 30 / 100 epoch, with learning rate 8.940053768033609
[11/24 23:08:42 visual_prompt]: Epoch 30 / 100: avg data time: 4.85e+00, avg batch time: 6.3027, average train loss: 24.2019
[11/24 23:09:33 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.5904, average loss: 29.9047
[11/24 23:09:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 44.08	
[11/24 23:09:33 visual_prompt]: Training 31 / 100 epoch, with learning rate 8.83022221559489
[11/24 23:16:52 visual_prompt]: Epoch 31 / 100: avg data time: 4.82e+00, avg batch time: 6.2667, average train loss: 29.6167
[11/24 23:17:42 visual_prompt]: Inference (val):avg data time: 3.77e-05, avg batch time: 0.5873, average loss: 27.7486
[11/24 23:17:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 44.74	
[11/24 23:17:42 visual_prompt]: Training 32 / 100 epoch, with learning rate 8.715724127386972
[11/24 23:25:04 visual_prompt]: Epoch 32 / 100: avg data time: 4.85e+00, avg batch time: 6.3071, average train loss: 20.4995
[11/24 23:25:55 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.5885, average loss: 4.1891
[11/24 23:25:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.97	
[11/24 23:25:55 visual_prompt]: Training 33 / 100 epoch, with learning rate 8.596699001693256
[11/24 23:33:14 visual_prompt]: Epoch 33 / 100: avg data time: 4.82e+00, avg batch time: 6.2692, average train loss: 23.4257
[11/24 23:34:04 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.5855, average loss: 14.4127
[11/24 23:34:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 42.88	
[11/24 23:34:04 visual_prompt]: Training 34 / 100 epoch, with learning rate 8.473291852294986
[11/24 23:41:23 visual_prompt]: Epoch 34 / 100: avg data time: 4.82e+00, avg batch time: 6.2720, average train loss: 19.1444
[11/24 23:42:14 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.5884, average loss: 4.6434
[11/24 23:42:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.08	
[11/24 23:42:14 visual_prompt]: Training 35 / 100 epoch, with learning rate 8.345653031794292
[11/24 23:49:34 visual_prompt]: Epoch 35 / 100: avg data time: 4.83e+00, avg batch time: 6.2820, average train loss: 16.8090
[11/24 23:50:24 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.5905, average loss: 23.9573
[11/24 23:50:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.90	
[11/24 23:50:24 visual_prompt]: Stopping early.
[11/24 23:50:24 visual_prompt]: Rank of current process: 0. World size: 1
[11/24 23:50:24 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/24 23:50:24 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/24 23:50:24 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/24 23:50:24 visual_prompt]: Training with config:
[11/24 23:50:24 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr10.0_wd0.001/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 10.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/24 23:50:24 visual_prompt]: Loading training data...
[11/24 23:50:24 visual_prompt]: Constructing mammo-cbis dataset train...
[11/24 23:50:24 visual_prompt]: Loading validation data...
[11/24 23:50:24 visual_prompt]: Constructing mammo-cbis dataset val...
[11/24 23:50:24 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/24 23:50:27 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/24 23:50:27 visual_prompt]: tuned percent:0.532
[11/24 23:50:27 visual_prompt]: Device used for model: 0
[11/24 23:50:27 visual_prompt]: Setting up Evaluator...
[11/24 23:50:27 visual_prompt]: Setting up Trainer...
[11/24 23:50:27 visual_prompt]: 	Setting up the optimizer...
[11/24 23:50:27 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/24 23:57:51 visual_prompt]: Epoch 1 / 100: avg data time: 4.88e+00, avg batch time: 6.3336, average train loss: 1.4863
[11/24 23:58:42 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.5872, average loss: 1.4553
[11/24 23:58:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/24 23:58:42 visual_prompt]: Training 2 / 100 epoch, with learning rate 1.0
[11/25 00:06:04 visual_prompt]: Epoch 2 / 100: avg data time: 4.87e+00, avg batch time: 6.3242, average train loss: 3.6290
[11/25 00:06:55 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.5849, average loss: 0.7015
[11/25 00:06:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.64	
[11/25 00:06:56 visual_prompt]: Training 3 / 100 epoch, with learning rate 2.0
[11/25 00:14:19 visual_prompt]: Epoch 3 / 100: avg data time: 4.88e+00, avg batch time: 6.3362, average train loss: 3.3315
[11/25 00:15:10 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.5851, average loss: 6.6219
[11/25 00:15:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.92	
[11/25 00:15:10 visual_prompt]: Training 4 / 100 epoch, with learning rate 3.0
[11/25 00:22:36 visual_prompt]: Epoch 4 / 100: avg data time: 4.92e+00, avg batch time: 6.3700, average train loss: 4.5911
[11/25 00:23:27 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.5849, average loss: 18.1257
[11/25 00:23:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.95	
[11/25 00:23:27 visual_prompt]: Training 5 / 100 epoch, with learning rate 4.0
[11/25 00:30:51 visual_prompt]: Epoch 5 / 100: avg data time: 4.90e+00, avg batch time: 6.3491, average train loss: 9.1223
[11/25 00:31:42 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.5864, average loss: 9.0045
[11/25 00:31:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.47	
[11/25 00:31:42 visual_prompt]: Training 6 / 100 epoch, with learning rate 5.0
[11/25 00:39:10 visual_prompt]: Epoch 6 / 100: avg data time: 4.95e+00, avg batch time: 6.4003, average train loss: 4.2861
[11/25 00:40:01 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.5885, average loss: 12.1229
[11/25 00:40:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.81	
[11/25 00:40:01 visual_prompt]: Training 7 / 100 epoch, with learning rate 6.0
[11/25 00:47:29 visual_prompt]: Epoch 7 / 100: avg data time: 4.94e+00, avg batch time: 6.3950, average train loss: 8.5586
[11/25 00:48:20 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.5905, average loss: 1.7698
[11/25 00:48:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 41.86	
[11/25 00:48:20 visual_prompt]: Training 8 / 100 epoch, with learning rate 7.0
[11/25 00:55:48 visual_prompt]: Epoch 8 / 100: avg data time: 4.95e+00, avg batch time: 6.3991, average train loss: 11.6387
[11/25 00:56:39 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.5901, average loss: 23.7068
[11/25 00:56:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.93	
[11/25 00:56:39 visual_prompt]: Training 9 / 100 epoch, with learning rate 8.0
[11/25 01:04:07 visual_prompt]: Epoch 9 / 100: avg data time: 4.94e+00, avg batch time: 6.3906, average train loss: 19.9712
[11/25 01:04:58 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.5891, average loss: 10.6126
[11/25 01:04:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.46	
[11/25 01:04:58 visual_prompt]: Training 10 / 100 epoch, with learning rate 9.0
[11/25 01:12:24 visual_prompt]: Epoch 10 / 100: avg data time: 4.91e+00, avg batch time: 6.3683, average train loss: 11.6369
[11/25 01:13:15 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.5896, average loss: 25.8073
[11/25 01:13:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.33	
[11/25 01:13:15 visual_prompt]: Training 11 / 100 epoch, with learning rate 10.0
[11/25 01:20:42 visual_prompt]: Epoch 11 / 100: avg data time: 4.95e+00, avg batch time: 6.3934, average train loss: 17.4059
[11/25 01:21:33 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.5868, average loss: 9.1535
[11/25 01:21:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.11	
[11/25 01:21:33 visual_prompt]: Training 12 / 100 epoch, with learning rate 9.996954135095478
[11/25 01:29:01 visual_prompt]: Epoch 12 / 100: avg data time: 4.95e+00, avg batch time: 6.3969, average train loss: 20.5649
[11/25 01:29:52 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.5859, average loss: 16.1951
[11/25 01:29:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 42.04	
[11/25 01:29:52 visual_prompt]: Training 13 / 100 epoch, with learning rate 9.987820251299121
[11/25 01:37:20 visual_prompt]: Epoch 13 / 100: avg data time: 4.95e+00, avg batch time: 6.3976, average train loss: 20.7172
[11/25 01:38:12 visual_prompt]: Inference (val):avg data time: 7.79e-05, avg batch time: 0.5895, average loss: 20.2129
[11/25 01:38:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.94	
[11/25 01:38:12 visual_prompt]: Training 14 / 100 epoch, with learning rate 9.972609476841367
[11/25 01:45:38 visual_prompt]: Epoch 14 / 100: avg data time: 4.92e+00, avg batch time: 6.3694, average train loss: 29.2269
[11/25 01:46:28 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.5892, average loss: 12.0221
[11/25 01:46:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.45	
[11/25 01:46:28 visual_prompt]: Training 15 / 100 epoch, with learning rate 9.951340343707852
[11/25 01:53:56 visual_prompt]: Epoch 15 / 100: avg data time: 4.94e+00, avg batch time: 6.3988, average train loss: 16.4286
[11/25 01:54:48 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.5862, average loss: 41.7761
[11/25 01:54:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.62	
[11/25 01:54:48 visual_prompt]: Training 16 / 100 epoch, with learning rate 9.924038765061042
[11/25 02:02:16 visual_prompt]: Epoch 16 / 100: avg data time: 4.95e+00, avg batch time: 6.3989, average train loss: 26.0824
[11/25 02:03:07 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.5891, average loss: 10.6975
[11/25 02:03:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.44	
[11/25 02:03:07 visual_prompt]: Training 17 / 100 epoch, with learning rate 9.890738003669028
[11/25 02:10:35 visual_prompt]: Epoch 17 / 100: avg data time: 4.94e+00, avg batch time: 6.3925, average train loss: 30.1166
[11/25 02:11:26 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.5932, average loss: 2.9526
[11/25 02:11:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.60	
[11/25 02:11:26 visual_prompt]: Best epoch 17: best metric: -2.953
[11/25 02:11:26 visual_prompt]: Training 18 / 100 epoch, with learning rate 9.851478631379981
[11/25 02:18:54 visual_prompt]: Epoch 18 / 100: avg data time: 4.95e+00, avg batch time: 6.3975, average train loss: 19.3340
[11/25 02:19:45 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.5851, average loss: 6.7008
[11/25 02:19:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.61	
[11/25 02:19:45 visual_prompt]: Training 19 / 100 epoch, with learning rate 9.806308479691594
[11/25 02:27:10 visual_prompt]: Epoch 19 / 100: avg data time: 4.90e+00, avg batch time: 6.3546, average train loss: 15.5036
[11/25 02:28:01 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.5897, average loss: 5.0658
[11/25 02:28:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.26	
[11/25 02:28:01 visual_prompt]: Training 20 / 100 epoch, with learning rate 9.755282581475768
[11/25 02:35:28 visual_prompt]: Epoch 20 / 100: avg data time: 4.94e+00, avg batch time: 6.3888, average train loss: 20.9254
[11/25 02:36:20 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.5870, average loss: 8.0544
[11/25 02:36:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.95	
[11/25 02:36:20 visual_prompt]: Training 21 / 100 epoch, with learning rate 9.698463103929543
[11/25 02:43:46 visual_prompt]: Epoch 21 / 100: avg data time: 4.93e+00, avg batch time: 6.3803, average train loss: 11.6590
[11/25 02:44:38 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.5844, average loss: 31.2982
[11/25 02:44:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.47	
[11/25 02:44:38 visual_prompt]: Training 22 / 100 epoch, with learning rate 9.635919272833938
[11/25 02:52:05 visual_prompt]: Epoch 22 / 100: avg data time: 4.93e+00, avg batch time: 6.3763, average train loss: 20.6247
[11/25 02:52:56 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.5933, average loss: 25.8599
[11/25 02:52:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.85	
[11/25 02:52:56 visual_prompt]: Training 23 / 100 epoch, with learning rate 9.567727288213003
[11/25 03:00:23 visual_prompt]: Epoch 23 / 100: avg data time: 4.93e+00, avg batch time: 6.3781, average train loss: 26.0219
[11/25 03:01:14 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.5868, average loss: 23.6759
[11/25 03:01:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.59	
[11/25 03:01:14 visual_prompt]: Training 24 / 100 epoch, with learning rate 9.493970231495835
[11/25 03:08:36 visual_prompt]: Epoch 24 / 100: avg data time: 4.86e+00, avg batch time: 6.3166, average train loss: 13.6635
[11/25 03:09:27 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.5859, average loss: 10.0365
[11/25 03:09:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.47	
[11/25 03:09:27 visual_prompt]: Training 25 / 100 epoch, with learning rate 9.414737964294634
[11/25 03:16:48 visual_prompt]: Epoch 25 / 100: avg data time: 4.85e+00, avg batch time: 6.2987, average train loss: 17.6200
[11/25 03:17:38 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.5862, average loss: 0.6902
[11/25 03:17:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 57.28	
[11/25 03:17:38 visual_prompt]: Best epoch 25: best metric: -0.690
[11/25 03:17:38 visual_prompt]: Training 26 / 100 epoch, with learning rate 9.330127018922195
[11/25 03:25:00 visual_prompt]: Epoch 26 / 100: avg data time: 4.86e+00, avg batch time: 6.3122, average train loss: 22.7075
[11/25 03:25:51 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.5908, average loss: 6.7935
[11/25 03:25:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.86	
[11/25 03:25:51 visual_prompt]: Training 27 / 100 epoch, with learning rate 9.240240480782129
[11/25 03:33:12 visual_prompt]: Epoch 27 / 100: avg data time: 4.86e+00, avg batch time: 6.3074, average train loss: 26.4200
[11/25 03:34:02 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.5886, average loss: 19.3973
[11/25 03:34:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.33	
[11/25 03:34:02 visual_prompt]: Training 28 / 100 epoch, with learning rate 9.145187862775208
[11/25 03:41:25 visual_prompt]: Epoch 28 / 100: avg data time: 4.86e+00, avg batch time: 6.3143, average train loss: 19.0276
[11/25 03:42:15 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.5868, average loss: 18.1109
[11/25 03:42:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.91	
[11/25 03:42:15 visual_prompt]: Training 29 / 100 epoch, with learning rate 9.045084971874736
[11/25 03:49:36 visual_prompt]: Epoch 29 / 100: avg data time: 4.84e+00, avg batch time: 6.2919, average train loss: 16.6779
[11/25 03:50:26 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.5881, average loss: 59.9815
[11/25 03:50:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.77	
[11/25 03:50:26 visual_prompt]: Training 30 / 100 epoch, with learning rate 8.940053768033609
[11/25 03:57:50 visual_prompt]: Epoch 30 / 100: avg data time: 4.88e+00, avg batch time: 6.3374, average train loss: 21.1487
[11/25 03:58:41 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.5881, average loss: 5.0961
[11/25 03:58:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.28	
[11/25 03:58:41 visual_prompt]: Training 31 / 100 epoch, with learning rate 8.83022221559489
[11/25 04:06:03 visual_prompt]: Epoch 31 / 100: avg data time: 4.86e+00, avg batch time: 6.3120, average train loss: 17.6643
[11/25 04:06:53 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.5893, average loss: 22.5894
[11/25 04:06:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.89	
[11/25 04:06:53 visual_prompt]: Training 32 / 100 epoch, with learning rate 8.715724127386972
[11/25 04:14:18 visual_prompt]: Epoch 32 / 100: avg data time: 4.91e+00, avg batch time: 6.3608, average train loss: 17.2669
[11/25 04:15:09 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.5896, average loss: 79.8224
[11/25 04:15:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.85	
[11/25 04:15:09 visual_prompt]: Training 33 / 100 epoch, with learning rate 8.596699001693256
[11/25 04:22:36 visual_prompt]: Epoch 33 / 100: avg data time: 4.93e+00, avg batch time: 6.3784, average train loss: 17.8570
[11/25 04:23:27 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.5874, average loss: 5.8537
[11/25 04:23:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.80	
[11/25 04:23:27 visual_prompt]: Training 34 / 100 epoch, with learning rate 8.473291852294986
[11/25 04:30:51 visual_prompt]: Epoch 34 / 100: avg data time: 4.89e+00, avg batch time: 6.3474, average train loss: 12.7621
[11/25 04:31:43 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.5856, average loss: 35.0363
[11/25 04:31:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 45.25	
[11/25 04:31:43 visual_prompt]: Training 35 / 100 epoch, with learning rate 8.345653031794292
[11/25 04:39:10 visual_prompt]: Epoch 35 / 100: avg data time: 4.93e+00, avg batch time: 6.3794, average train loss: 11.9029
[11/25 04:40:00 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.5877, average loss: 26.8221
[11/25 04:40:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.32	
[11/25 04:40:00 visual_prompt]: Training 36 / 100 epoch, with learning rate 8.213938048432697
[11/25 04:47:29 visual_prompt]: Epoch 36 / 100: avg data time: 4.95e+00, avg batch time: 6.4016, average train loss: 17.2054
[11/25 04:48:20 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.5872, average loss: 41.0775
[11/25 04:48:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.96	
[11/25 04:48:20 visual_prompt]: Training 37 / 100 epoch, with learning rate 8.078307376628292
[11/25 04:55:47 visual_prompt]: Epoch 37 / 100: avg data time: 4.93e+00, avg batch time: 6.3837, average train loss: 15.1260
[11/25 04:56:38 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.5851, average loss: 4.0567
[11/25 04:56:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.03	
[11/25 04:56:38 visual_prompt]: Training 38 / 100 epoch, with learning rate 7.938926261462366
[11/25 05:04:06 visual_prompt]: Epoch 38 / 100: avg data time: 4.95e+00, avg batch time: 6.3950, average train loss: 12.4601
[11/25 05:04:58 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.5908, average loss: 16.4591
[11/25 05:04:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.95	
[11/25 05:04:58 visual_prompt]: Training 39 / 100 epoch, with learning rate 7.795964517353734
[11/25 05:12:29 visual_prompt]: Epoch 39 / 100: avg data time: 4.99e+00, avg batch time: 6.4432, average train loss: 14.7313
[11/25 05:13:21 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.5879, average loss: 2.9662
[11/25 05:13:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.03	
[11/25 05:13:21 visual_prompt]: Training 40 / 100 epoch, with learning rate 7.649596321166024
[11/25 05:20:52 visual_prompt]: Epoch 40 / 100: avg data time: 5.00e+00, avg batch time: 6.4507, average train loss: 10.9341
[11/25 05:21:44 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.5877, average loss: 12.5913
[11/25 05:21:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.65	
[11/25 05:21:44 visual_prompt]: Training 41 / 100 epoch, with learning rate 7.5
[11/25 05:29:17 visual_prompt]: Epoch 41 / 100: avg data time: 5.01e+00, avg batch time: 6.4652, average train loss: 10.5450
[11/25 05:30:09 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.5875, average loss: 5.2581
[11/25 05:30:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.86	
[11/25 05:30:09 visual_prompt]: Training 42 / 100 epoch, with learning rate 7.347357813929454
[11/25 05:37:42 visual_prompt]: Epoch 42 / 100: avg data time: 5.02e+00, avg batch time: 6.4768, average train loss: 10.4594
[11/25 05:38:34 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.5852, average loss: 13.0582
[11/25 05:38:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.07	
[11/25 05:38:34 visual_prompt]: Training 43 / 100 epoch, with learning rate 7.191855733945387
[11/25 05:46:07 visual_prompt]: Epoch 43 / 100: avg data time: 5.02e+00, avg batch time: 6.4765, average train loss: 10.1250
[11/25 05:46:59 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.5874, average loss: 35.0607
[11/25 05:46:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.58	
[11/25 05:46:59 visual_prompt]: Training 44 / 100 epoch, with learning rate 7.033683215379002
[11/25 05:54:34 visual_prompt]: Epoch 44 / 100: avg data time: 5.05e+00, avg batch time: 6.4995, average train loss: 9.4960
[11/25 05:55:26 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.5872, average loss: 13.6460
[11/25 05:55:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 41.82	
[11/25 05:55:26 visual_prompt]: Training 45 / 100 epoch, with learning rate 6.873032967079561
[11/25 06:03:00 visual_prompt]: Epoch 45 / 100: avg data time: 5.03e+00, avg batch time: 6.4857, average train loss: 9.2092
[11/25 06:03:52 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.5862, average loss: 1.5679
[11/25 06:03:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.53	
[11/25 06:03:52 visual_prompt]: Training 46 / 100 epoch, with learning rate 6.710100716628345
[11/25 06:11:24 visual_prompt]: Epoch 46 / 100: avg data time: 5.01e+00, avg batch time: 6.4586, average train loss: 14.4562
[11/25 06:12:16 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.5863, average loss: 9.7857
[11/25 06:12:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.05	
[11/25 06:12:16 visual_prompt]: Stopping early.
[11/25 06:12:16 visual_prompt]: Rank of current process: 0. World size: 1
[11/25 06:12:16 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/25 06:12:16 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/25 06:12:16 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/25 06:12:16 visual_prompt]: Training with config:
[11/25 06:12:16 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr10.0_wd0.0001/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 10.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/25 06:12:16 visual_prompt]: Loading training data...
[11/25 06:12:16 visual_prompt]: Constructing mammo-cbis dataset train...
[11/25 06:12:16 visual_prompt]: Loading validation data...
[11/25 06:12:16 visual_prompt]: Constructing mammo-cbis dataset val...
[11/25 06:12:16 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/25 06:12:19 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/25 06:12:19 visual_prompt]: tuned percent:0.532
[11/25 06:12:19 visual_prompt]: Device used for model: 0
[11/25 06:12:19 visual_prompt]: Setting up Evaluator...
[11/25 06:12:19 visual_prompt]: Setting up Trainer...
[11/25 06:12:19 visual_prompt]: 	Setting up the optimizer...
[11/25 06:12:19 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/25 06:19:53 visual_prompt]: Epoch 1 / 100: avg data time: 5.03e+00, avg batch time: 6.4881, average train loss: 1.4863
[11/25 06:20:45 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.5886, average loss: 1.4553
[11/25 06:20:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/25 06:20:45 visual_prompt]: Training 2 / 100 epoch, with learning rate 1.0
[11/25 06:28:18 visual_prompt]: Epoch 2 / 100: avg data time: 5.01e+00, avg batch time: 6.4691, average train loss: 3.8484
[11/25 06:29:10 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.5849, average loss: 4.6136
[11/25 06:29:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.53	
[11/25 06:29:10 visual_prompt]: Training 3 / 100 epoch, with learning rate 2.0
[11/25 06:36:42 visual_prompt]: Epoch 3 / 100: avg data time: 5.01e+00, avg batch time: 6.4643, average train loss: 4.0152
[11/25 06:37:34 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.5924, average loss: 3.4962
[11/25 06:37:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.14	
[11/25 06:37:34 visual_prompt]: Training 4 / 100 epoch, with learning rate 3.0
[11/25 06:45:05 visual_prompt]: Epoch 4 / 100: avg data time: 4.99e+00, avg batch time: 6.4416, average train loss: 9.5956
[11/25 06:45:57 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.5854, average loss: 17.7444
[11/25 06:45:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.27	
[11/25 06:45:57 visual_prompt]: Training 5 / 100 epoch, with learning rate 4.0
[11/25 06:53:27 visual_prompt]: Epoch 5 / 100: avg data time: 4.97e+00, avg batch time: 6.4247, average train loss: 11.9517
[11/25 06:54:18 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.5867, average loss: 6.3556
[11/25 06:54:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.19	
[11/25 06:54:18 visual_prompt]: Training 6 / 100 epoch, with learning rate 5.0
[11/25 07:01:50 visual_prompt]: Epoch 6 / 100: avg data time: 5.00e+00, avg batch time: 6.4495, average train loss: 5.5102
[11/25 07:02:41 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.5887, average loss: 12.4938
[11/25 07:02:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.18	
[11/25 07:02:41 visual_prompt]: Training 7 / 100 epoch, with learning rate 6.0
[11/25 07:10:10 visual_prompt]: Epoch 7 / 100: avg data time: 4.96e+00, avg batch time: 6.4136, average train loss: 10.8707
[11/25 07:11:02 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.5854, average loss: 15.6162
[11/25 07:11:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.02	
[11/25 07:11:02 visual_prompt]: Training 8 / 100 epoch, with learning rate 7.0
[11/25 07:18:29 visual_prompt]: Epoch 8 / 100: avg data time: 4.93e+00, avg batch time: 6.3828, average train loss: 16.1962
[11/25 07:19:20 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.5875, average loss: 20.9911
[11/25 07:19:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.46	
[11/25 07:19:20 visual_prompt]: Training 9 / 100 epoch, with learning rate 8.0
[11/25 07:26:47 visual_prompt]: Epoch 9 / 100: avg data time: 4.93e+00, avg batch time: 6.3853, average train loss: 10.8896
[11/25 07:27:38 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.5863, average loss: 9.4035
[11/25 07:27:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.40	
[11/25 07:27:38 visual_prompt]: Training 10 / 100 epoch, with learning rate 9.0
[11/25 07:35:05 visual_prompt]: Epoch 10 / 100: avg data time: 4.93e+00, avg batch time: 6.3830, average train loss: 8.6100
[11/25 07:35:56 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.5876, average loss: 13.1743
[11/25 07:35:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.28	
[11/25 07:35:56 visual_prompt]: Training 11 / 100 epoch, with learning rate 10.0
[11/25 07:43:25 visual_prompt]: Epoch 11 / 100: avg data time: 4.96e+00, avg batch time: 6.4056, average train loss: 18.8795
[11/25 07:44:16 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.5868, average loss: 8.2741
[11/25 07:44:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.07	
[11/25 07:44:16 visual_prompt]: Training 12 / 100 epoch, with learning rate 9.996954135095478
[11/25 07:51:44 visual_prompt]: Epoch 12 / 100: avg data time: 4.95e+00, avg batch time: 6.3978, average train loss: 6.8283
[11/25 07:52:35 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.5845, average loss: 5.3706
[11/25 07:52:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.73	
[11/25 07:52:35 visual_prompt]: Best epoch 12: best metric: -5.371
[11/25 07:52:35 visual_prompt]: Training 13 / 100 epoch, with learning rate 9.987820251299121
[11/25 08:00:03 visual_prompt]: Epoch 13 / 100: avg data time: 4.95e+00, avg batch time: 6.4032, average train loss: 23.1503
[11/25 08:00:54 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.5878, average loss: 18.8135
[11/25 08:00:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.66	
[11/25 08:00:54 visual_prompt]: Training 14 / 100 epoch, with learning rate 9.972609476841367
[11/25 08:08:24 visual_prompt]: Epoch 14 / 100: avg data time: 4.97e+00, avg batch time: 6.4200, average train loss: 17.3023
[11/25 08:09:15 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.5853, average loss: 9.3853
[11/25 08:09:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.40	
[11/25 08:09:15 visual_prompt]: Training 15 / 100 epoch, with learning rate 9.951340343707852
[11/25 08:16:45 visual_prompt]: Epoch 15 / 100: avg data time: 4.97e+00, avg batch time: 6.4219, average train loss: 15.3914
[11/25 08:17:37 visual_prompt]: Inference (val):avg data time: 3.55e-05, avg batch time: 0.5870, average loss: 16.7519
[11/25 08:17:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.92	
[11/25 08:17:37 visual_prompt]: Training 16 / 100 epoch, with learning rate 9.924038765061042
[11/25 08:25:08 visual_prompt]: Epoch 16 / 100: avg data time: 5.00e+00, avg batch time: 6.4493, average train loss: 8.8022
[11/25 08:26:00 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.5912, average loss: 17.3945
[11/25 08:26:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 44.41	
[11/25 08:26:00 visual_prompt]: Training 17 / 100 epoch, with learning rate 9.890738003669028
[11/25 08:33:33 visual_prompt]: Epoch 17 / 100: avg data time: 5.02e+00, avg batch time: 6.4691, average train loss: 11.0128
[11/25 08:34:25 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.5880, average loss: 4.9359
[11/25 08:34:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 44.66	
[11/25 08:34:25 visual_prompt]: Best epoch 17: best metric: -4.936
[11/25 08:34:25 visual_prompt]: Training 18 / 100 epoch, with learning rate 9.851478631379981
[11/25 08:42:05 visual_prompt]: Epoch 18 / 100: avg data time: 5.12e+00, avg batch time: 6.5736, average train loss: 20.5911
[11/25 08:42:57 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.5861, average loss: 2.0057
[11/25 08:42:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.90	
[11/25 08:42:57 visual_prompt]: Best epoch 18: best metric: -2.006
[11/25 08:42:57 visual_prompt]: Training 19 / 100 epoch, with learning rate 9.806308479691594
[11/25 08:50:30 visual_prompt]: Epoch 19 / 100: avg data time: 5.01e+00, avg batch time: 6.4629, average train loss: 11.3233
[11/25 08:51:21 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.5936, average loss: 34.0491
[11/25 08:51:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.41	
[11/25 08:51:21 visual_prompt]: Training 20 / 100 epoch, with learning rate 9.755282581475768
[11/25 08:58:53 visual_prompt]: Epoch 20 / 100: avg data time: 5.00e+00, avg batch time: 6.4471, average train loss: 11.8072
[11/25 08:59:44 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.5878, average loss: 7.3134
[11/25 08:59:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.06	
[11/25 08:59:44 visual_prompt]: Training 21 / 100 epoch, with learning rate 9.698463103929543
[11/25 09:07:13 visual_prompt]: Epoch 21 / 100: avg data time: 4.96e+00, avg batch time: 6.4126, average train loss: 6.6352
[11/25 09:08:04 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.5875, average loss: 2.0948
[11/25 09:08:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.44	
[11/25 09:08:04 visual_prompt]: Training 22 / 100 epoch, with learning rate 9.635919272833938
[11/25 09:15:30 visual_prompt]: Epoch 22 / 100: avg data time: 4.92e+00, avg batch time: 6.3657, average train loss: 11.7063
[11/25 09:16:21 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.5917, average loss: 22.8586
[11/25 09:16:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.40	
[11/25 09:16:21 visual_prompt]: Training 23 / 100 epoch, with learning rate 9.567727288213003
[11/25 09:23:48 visual_prompt]: Epoch 23 / 100: avg data time: 4.94e+00, avg batch time: 6.3914, average train loss: 17.6822
[11/25 09:24:39 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.5908, average loss: 12.0150
[11/25 09:24:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.92	
[11/25 09:24:39 visual_prompt]: Training 24 / 100 epoch, with learning rate 9.493970231495835
[11/25 09:32:06 visual_prompt]: Epoch 24 / 100: avg data time: 4.92e+00, avg batch time: 6.3831, average train loss: 16.8503
[11/25 09:32:57 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.5875, average loss: 5.5806
[11/25 09:32:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.11	
[11/25 09:32:57 visual_prompt]: Training 25 / 100 epoch, with learning rate 9.414737964294634
[11/25 09:40:25 visual_prompt]: Epoch 25 / 100: avg data time: 4.94e+00, avg batch time: 6.3958, average train loss: 13.8365
[11/25 09:41:16 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.5861, average loss: 1.9885
[11/25 09:41:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.12	
[11/25 09:41:16 visual_prompt]: Best epoch 25: best metric: -1.989
[11/25 09:41:16 visual_prompt]: Training 26 / 100 epoch, with learning rate 9.330127018922195
[11/25 09:48:45 visual_prompt]: Epoch 26 / 100: avg data time: 4.96e+00, avg batch time: 6.4091, average train loss: 14.8586
[11/25 09:49:36 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.5875, average loss: 12.7063
[11/25 09:49:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.66	
[11/25 09:49:36 visual_prompt]: Training 27 / 100 epoch, with learning rate 9.240240480782129
[11/25 09:57:04 visual_prompt]: Epoch 27 / 100: avg data time: 4.94e+00, avg batch time: 6.3926, average train loss: 21.0689
[11/25 09:57:55 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.5890, average loss: 23.5132
[11/25 09:57:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.67	
[11/25 09:57:55 visual_prompt]: Training 28 / 100 epoch, with learning rate 9.145187862775208
[11/25 10:05:21 visual_prompt]: Epoch 28 / 100: avg data time: 4.93e+00, avg batch time: 6.3743, average train loss: 28.3326
[11/25 10:06:12 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.5887, average loss: 12.2928
[11/25 10:06:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.39	
[11/25 10:06:12 visual_prompt]: Training 29 / 100 epoch, with learning rate 9.045084971874736
[11/25 10:13:39 visual_prompt]: Epoch 29 / 100: avg data time: 4.92e+00, avg batch time: 6.3718, average train loss: 10.9070
[11/25 10:14:30 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.5871, average loss: 17.8515
[11/25 10:14:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.68	
[11/25 10:14:30 visual_prompt]: Training 30 / 100 epoch, with learning rate 8.940053768033609
[11/25 10:21:58 visual_prompt]: Epoch 30 / 100: avg data time: 4.95e+00, avg batch time: 6.4016, average train loss: 11.5604
[11/25 10:22:49 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.5875, average loss: 21.8766
[11/25 10:22:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.59	
[11/25 10:22:49 visual_prompt]: Training 31 / 100 epoch, with learning rate 8.83022221559489
[11/25 10:30:14 visual_prompt]: Epoch 31 / 100: avg data time: 4.91e+00, avg batch time: 6.3565, average train loss: 8.7012
[11/25 10:31:05 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.5912, average loss: 0.6995
[11/25 10:31:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.47	
[11/25 10:31:05 visual_prompt]: Best epoch 31: best metric: -0.700
[11/25 10:31:05 visual_prompt]: Training 32 / 100 epoch, with learning rate 8.715724127386972
[11/25 10:38:31 visual_prompt]: Epoch 32 / 100: avg data time: 4.92e+00, avg batch time: 6.3700, average train loss: 5.9034
[11/25 10:39:22 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.5899, average loss: 0.8802
[11/25 10:39:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 44.57	
[11/25 10:39:22 visual_prompt]: Training 33 / 100 epoch, with learning rate 8.596699001693256
[11/25 10:46:50 visual_prompt]: Epoch 33 / 100: avg data time: 4.94e+00, avg batch time: 6.3954, average train loss: 6.1837
[11/25 10:47:41 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.5860, average loss: 9.3105
[11/25 10:47:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.39	
[11/25 10:47:41 visual_prompt]: Training 34 / 100 epoch, with learning rate 8.473291852294986
[11/25 10:55:05 visual_prompt]: Epoch 34 / 100: avg data time: 4.89e+00, avg batch time: 6.3387, average train loss: 7.6691
[11/25 10:55:56 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.5858, average loss: 1.2568
[11/25 10:55:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.96	
[11/25 10:55:56 visual_prompt]: Training 35 / 100 epoch, with learning rate 8.345653031794292
[11/25 11:03:20 visual_prompt]: Epoch 35 / 100: avg data time: 4.89e+00, avg batch time: 6.3447, average train loss: 16.6743
[11/25 11:04:11 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.5890, average loss: 24.7372
[11/25 11:04:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.41	
[11/25 11:04:11 visual_prompt]: Training 36 / 100 epoch, with learning rate 8.213938048432697
[11/25 11:11:33 visual_prompt]: Epoch 36 / 100: avg data time: 4.87e+00, avg batch time: 6.3186, average train loss: 15.7066
[11/25 11:12:23 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.5858, average loss: 8.1762
[11/25 11:12:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.91	
[11/25 11:12:23 visual_prompt]: Training 37 / 100 epoch, with learning rate 8.078307376628292
[11/25 11:19:45 visual_prompt]: Epoch 37 / 100: avg data time: 4.86e+00, avg batch time: 6.3105, average train loss: 20.3900
[11/25 11:20:35 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.5886, average loss: 28.9904
[11/25 11:20:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.22	
[11/25 11:20:35 visual_prompt]: Training 38 / 100 epoch, with learning rate 7.938926261462366
[11/25 11:27:56 visual_prompt]: Epoch 38 / 100: avg data time: 4.85e+00, avg batch time: 6.3000, average train loss: 18.5016
[11/25 11:28:46 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.5842, average loss: 9.8416
[11/25 11:28:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.39	
[11/25 11:28:46 visual_prompt]: Training 39 / 100 epoch, with learning rate 7.795964517353734
[11/25 11:36:05 visual_prompt]: Epoch 39 / 100: avg data time: 4.82e+00, avg batch time: 6.2711, average train loss: 15.5384
[11/25 11:36:57 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.5852, average loss: 28.7403
[11/25 11:36:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 44.33	
[11/25 11:36:57 visual_prompt]: Training 40 / 100 epoch, with learning rate 7.649596321166024
[11/25 11:44:17 visual_prompt]: Epoch 40 / 100: avg data time: 4.84e+00, avg batch time: 6.2909, average train loss: 21.1376
[11/25 11:45:07 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.5851, average loss: 19.2719
[11/25 11:45:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.65	
[11/25 11:45:07 visual_prompt]: Training 41 / 100 epoch, with learning rate 7.5
[11/25 11:52:28 visual_prompt]: Epoch 41 / 100: avg data time: 4.85e+00, avg batch time: 6.2992, average train loss: 16.0181
[11/25 11:53:18 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.5866, average loss: 15.8603
[11/25 11:53:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.94	
[11/25 11:53:18 visual_prompt]: Training 42 / 100 epoch, with learning rate 7.347357813929454
[11/25 12:00:39 visual_prompt]: Epoch 42 / 100: avg data time: 4.85e+00, avg batch time: 6.3002, average train loss: 11.2651
[11/25 12:01:30 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.5887, average loss: 2.4032
[11/25 12:01:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.85	
[11/25 12:01:30 visual_prompt]: Training 43 / 100 epoch, with learning rate 7.191855733945387
[11/25 12:08:53 visual_prompt]: Epoch 43 / 100: avg data time: 4.89e+00, avg batch time: 6.3362, average train loss: 8.5799
[11/25 12:09:44 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.5885, average loss: 14.3877
[11/25 12:09:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.71	
[11/25 12:09:44 visual_prompt]: Training 44 / 100 epoch, with learning rate 7.033683215379002
[11/25 12:17:11 visual_prompt]: Epoch 44 / 100: avg data time: 4.94e+00, avg batch time: 6.3878, average train loss: 11.4445
[11/25 12:18:02 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.5878, average loss: 21.7082
[11/25 12:18:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.43	
[11/25 12:18:02 visual_prompt]: Training 45 / 100 epoch, with learning rate 6.873032967079561
[11/25 12:25:29 visual_prompt]: Epoch 45 / 100: avg data time: 4.93e+00, avg batch time: 6.3791, average train loss: 24.4704
[11/25 12:26:20 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.5858, average loss: 5.0379
[11/25 12:26:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.51	
[11/25 12:26:20 visual_prompt]: Training 46 / 100 epoch, with learning rate 6.710100716628345
[11/25 12:33:44 visual_prompt]: Epoch 46 / 100: avg data time: 4.89e+00, avg batch time: 6.3435, average train loss: 13.2770
[11/25 12:34:34 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.5874, average loss: 26.0465
[11/25 12:34:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 61.76	
[11/25 12:34:34 visual_prompt]: Training 47 / 100 epoch, with learning rate 6.545084971874737
[11/25 12:41:59 visual_prompt]: Epoch 47 / 100: avg data time: 4.90e+00, avg batch time: 6.3494, average train loss: 17.2606
[11/25 12:42:50 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.5880, average loss: 17.7124
[11/25 12:42:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.01	
[11/25 12:42:50 visual_prompt]: Training 48 / 100 epoch, with learning rate 6.378186779084995
[11/25 12:50:25 visual_prompt]: Epoch 48 / 100: avg data time: 5.04e+00, avg batch time: 6.4910, average train loss: 12.9159
[11/25 12:51:16 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.5913, average loss: 1.4578
[11/25 12:51:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 44.74	
[11/25 12:51:16 visual_prompt]: Training 49 / 100 epoch, with learning rate 6.209609477998338
