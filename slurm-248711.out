/bin/bash: /home/s1952889/miniconda3/envs/prompt/lib/libtinfo.so.6: no version information available (required by /bin/bash)
An exception occurred in telemetry logging.Disabling telemetry to prevent further exceptions.
Traceback (most recent call last):
  File "/home/s1952889/miniconda3/envs/prompt/lib/python3.11/site-packages/iopath/common/file_io.py", line 946, in __log_tmetry_keys
    handler.log_event()
  File "/home/s1952889/miniconda3/envs/prompt/lib/python3.11/site-packages/iopath/common/event_logger.py", line 97, in log_event
    del self._evt
        ^^^^^^^^^
AttributeError: 'NativePathHandler' object has no attribute '_evt'
Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/22 11:07:44 visual_prompt]: Rank of current process: 0. World size: 1
[11/22 11:07:45 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/22 11:07:45 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/22 11:07:45 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/22 11:07:45 visual_prompt]: Training with config:
[11/22 11:07:45 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr50.0_wd0.01/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 50.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/22 11:07:45 visual_prompt]: Loading training data...
[11/22 11:07:45 visual_prompt]: Constructing mammo-cbis dataset train...
[11/22 11:07:46 visual_prompt]: Loading validation data...
[11/22 11:07:46 visual_prompt]: Constructing mammo-cbis dataset val...
[11/22 11:07:46 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/22 11:07:59 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/22 11:07:59 visual_prompt]: tuned percent:0.532
[11/22 11:07:59 visual_prompt]: Device used for model: 0
[11/22 11:07:59 visual_prompt]: Setting up Evaluator...
[11/22 11:07:59 visual_prompt]: Setting up Trainer...
[11/22 11:07:59 visual_prompt]: 	Setting up the optimizer...
[11/22 11:07:59 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/22 11:15:34 visual_prompt]: Epoch 1 / 100: avg data time: 5.03e+00, avg batch time: 6.4938, average train loss: 1.4863
[11/22 11:16:26 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.5879, average loss: 1.4553
[11/22 11:16:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/22 11:16:26 visual_prompt]: Training 2 / 100 epoch, with learning rate 5.0
[11/22 11:23:57 visual_prompt]: Epoch 2 / 100: avg data time: 4.99e+00, avg batch time: 6.4434, average train loss: 23.4194
[11/22 11:24:48 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.5880, average loss: 5.9050
[11/22 11:24:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.15	
[11/22 11:24:48 visual_prompt]: Training 3 / 100 epoch, with learning rate 10.0
[11/22 11:32:19 visual_prompt]: Epoch 3 / 100: avg data time: 4.99e+00, avg batch time: 6.4412, average train loss: 22.7559
[11/22 11:33:10 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.5870, average loss: 78.4539
[11/22 11:33:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 47.15	rocauc: 47.22	
[11/22 11:33:10 visual_prompt]: Training 4 / 100 epoch, with learning rate 15.0
[11/22 11:40:40 visual_prompt]: Epoch 4 / 100: avg data time: 4.97e+00, avg batch time: 6.4187, average train loss: 31.9098
[11/22 11:41:31 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.5885, average loss: 36.0121
[11/22 11:41:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.13	
[11/22 11:41:31 visual_prompt]: Training 5 / 100 epoch, with learning rate 20.0
[11/22 11:49:01 visual_prompt]: Epoch 5 / 100: avg data time: 4.98e+00, avg batch time: 6.4287, average train loss: 37.4111
[11/22 11:49:53 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.5856, average loss: 33.6763
[11/22 11:49:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.87	
[11/22 11:49:53 visual_prompt]: Training 6 / 100 epoch, with learning rate 25.0
[11/22 11:57:24 visual_prompt]: Epoch 6 / 100: avg data time: 5.00e+00, avg batch time: 6.4429, average train loss: 80.9835
[11/22 11:58:15 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.5897, average loss: 70.5767
[11/22 11:58:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.50	
[11/22 11:58:15 visual_prompt]: Training 7 / 100 epoch, with learning rate 30.0
[11/22 12:05:39 visual_prompt]: Epoch 7 / 100: avg data time: 4.90e+00, avg batch time: 6.3408, average train loss: 62.2236
[11/22 12:06:30 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.5913, average loss: 54.4756
[11/22 12:06:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.78	
[11/22 12:06:30 visual_prompt]: Training 8 / 100 epoch, with learning rate 35.0
[11/22 12:13:54 visual_prompt]: Epoch 8 / 100: avg data time: 4.90e+00, avg batch time: 6.3410, average train loss: 130.3972
[11/22 12:14:44 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.5854, average loss: 173.7895
[11/22 12:14:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.03	
[11/22 12:14:44 visual_prompt]: Training 9 / 100 epoch, with learning rate 40.0
[11/22 12:22:08 visual_prompt]: Epoch 9 / 100: avg data time: 4.90e+00, avg batch time: 6.3349, average train loss: 111.8224
[11/22 12:22:58 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.5860, average loss: 51.1531
[11/22 12:22:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 41.05	
[11/22 12:22:58 visual_prompt]: Training 10 / 100 epoch, with learning rate 45.0
[11/22 12:30:19 visual_prompt]: Epoch 10 / 100: avg data time: 4.86e+00, avg batch time: 6.2990, average train loss: 105.2176
[11/22 12:31:09 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.5911, average loss: 31.9708
[11/22 12:31:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.58	
[11/22 12:31:09 visual_prompt]: Training 11 / 100 epoch, with learning rate 50.0
[11/22 12:38:31 visual_prompt]: Epoch 11 / 100: avg data time: 4.87e+00, avg batch time: 6.3123, average train loss: 129.0567
[11/22 12:39:22 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.5854, average loss: 13.2878
[11/22 12:39:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.27	
[11/22 12:39:22 visual_prompt]: Training 12 / 100 epoch, with learning rate 49.9847706754774
[11/22 12:46:46 visual_prompt]: Epoch 12 / 100: avg data time: 4.90e+00, avg batch time: 6.3415, average train loss: 208.1526
[11/22 12:47:36 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.5895, average loss: 183.8571
[11/22 12:47:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.65	
[11/22 12:47:36 visual_prompt]: Training 13 / 100 epoch, with learning rate 49.939101256495604
[11/22 12:54:57 visual_prompt]: Epoch 13 / 100: avg data time: 4.86e+00, avg batch time: 6.3018, average train loss: 148.6304
[11/22 12:55:48 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.5868, average loss: 167.0876
[11/22 12:55:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 44.63	
[11/22 12:55:48 visual_prompt]: Training 14 / 100 epoch, with learning rate 49.86304738420683
[11/22 13:03:10 visual_prompt]: Epoch 14 / 100: avg data time: 4.87e+00, avg batch time: 6.3179, average train loss: 112.9457
[11/22 13:04:01 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.5858, average loss: 180.0684
[11/22 13:04:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.04	
[11/22 13:04:01 visual_prompt]: Training 15 / 100 epoch, with learning rate 49.75670171853926
[11/22 13:11:21 visual_prompt]: Epoch 15 / 100: avg data time: 4.86e+00, avg batch time: 6.2957, average train loss: 107.0701
[11/22 13:12:12 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.5883, average loss: 218.0983
[11/22 13:12:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.53	rocauc: 50.02	
[11/22 13:12:12 visual_prompt]: Training 16 / 100 epoch, with learning rate 49.6201938253052
[11/22 13:19:34 visual_prompt]: Epoch 16 / 100: avg data time: 4.87e+00, avg batch time: 6.3114, average train loss: 157.8699
[11/22 13:20:24 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.5846, average loss: 6.8180
[11/22 13:20:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.42	
[11/22 13:20:24 visual_prompt]: Best epoch 16: best metric: -6.818
[11/22 13:20:24 visual_prompt]: Training 17 / 100 epoch, with learning rate 49.45369001834514
[11/22 13:27:43 visual_prompt]: Epoch 17 / 100: avg data time: 4.84e+00, avg batch time: 6.2745, average train loss: 172.9522
[11/22 13:28:34 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.5919, average loss: 46.7653
[11/22 13:28:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.43	
[11/22 13:28:34 visual_prompt]: Training 18 / 100 epoch, with learning rate 49.25739315689991
[11/22 13:35:56 visual_prompt]: Epoch 18 / 100: avg data time: 4.87e+00, avg batch time: 6.3097, average train loss: 134.8895
[11/22 13:36:46 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.5879, average loss: 44.4161
[11/22 13:36:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.95	
[11/22 13:36:46 visual_prompt]: Training 19 / 100 epoch, with learning rate 49.03154239845797
[11/22 13:44:07 visual_prompt]: Epoch 19 / 100: avg data time: 4.86e+00, avg batch time: 6.2952, average train loss: 108.6106
[11/22 13:44:57 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.5899, average loss: 330.5166
[11/22 13:44:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.82	
[11/22 13:44:57 visual_prompt]: Training 20 / 100 epoch, with learning rate 48.77641290737884
[11/22 13:52:20 visual_prompt]: Epoch 20 / 100: avg data time: 4.88e+00, avg batch time: 6.3190, average train loss: 141.1177
[11/22 13:53:10 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.5906, average loss: 192.2731
[11/22 13:53:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.96	
[11/22 13:53:10 visual_prompt]: Training 21 / 100 epoch, with learning rate 48.49231551964771
[11/22 14:00:37 visual_prompt]: Epoch 21 / 100: avg data time: 4.93e+00, avg batch time: 6.3759, average train loss: 133.8192
[11/22 14:01:27 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.5835, average loss: 236.0819
[11/22 14:01:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.05	
[11/22 14:01:27 visual_prompt]: Training 22 / 100 epoch, with learning rate 48.17959636416968
[11/22 14:08:49 visual_prompt]: Epoch 22 / 100: avg data time: 4.88e+00, avg batch time: 6.3183, average train loss: 166.6178
[11/22 14:09:41 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.5874, average loss: 36.2407
[11/22 14:09:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 42.01	
[11/22 14:09:41 visual_prompt]: Training 23 / 100 epoch, with learning rate 47.83863644106502
[11/22 14:17:05 visual_prompt]: Epoch 23 / 100: avg data time: 4.91e+00, avg batch time: 6.3472, average train loss: 107.7752
[11/22 14:17:55 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.5856, average loss: 94.2358
[11/22 14:17:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.47	rocauc: 48.56	
[11/22 14:17:55 visual_prompt]: Training 24 / 100 epoch, with learning rate 47.46985115747918
[11/22 14:25:18 visual_prompt]: Epoch 24 / 100: avg data time: 4.88e+00, avg batch time: 6.3195, average train loss: 116.4842
[11/22 14:26:08 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.5931, average loss: 106.7851
[11/22 14:26:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 45.64	
[11/22 14:26:08 visual_prompt]: Training 25 / 100 epoch, with learning rate 47.073689821473174
[11/22 14:33:32 visual_prompt]: Epoch 25 / 100: avg data time: 4.89e+00, avg batch time: 6.3334, average train loss: 113.7748
[11/22 14:34:22 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.5886, average loss: 109.0722
[11/22 14:34:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.17	
[11/22 14:34:22 visual_prompt]: Training 26 / 100 epoch, with learning rate 46.65063509461097
[11/22 14:41:44 visual_prompt]: Epoch 26 / 100: avg data time: 4.87e+00, avg batch time: 6.3114, average train loss: 146.5544
[11/22 14:42:35 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.5895, average loss: 21.7410
[11/22 14:42:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 41.72	
[11/22 14:42:35 visual_prompt]: Training 27 / 100 epoch, with learning rate 46.20120240391065
[11/22 14:49:58 visual_prompt]: Epoch 27 / 100: avg data time: 4.88e+00, avg batch time: 6.3208, average train loss: 103.7777
[11/22 14:50:49 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.5889, average loss: 98.3964
[11/22 14:50:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.96	
[11/22 14:50:49 visual_prompt]: Training 28 / 100 epoch, with learning rate 45.72593931387604
[11/22 14:58:13 visual_prompt]: Epoch 28 / 100: avg data time: 4.91e+00, avg batch time: 6.3509, average train loss: 91.9104
[11/22 14:59:04 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.5859, average loss: 96.4467
[11/22 14:59:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.64	
[11/22 14:59:04 visual_prompt]: Training 29 / 100 epoch, with learning rate 45.22542485937369
[11/22 15:06:29 visual_prompt]: Epoch 29 / 100: avg data time: 4.92e+00, avg batch time: 6.3610, average train loss: 128.0840
[11/22 15:07:20 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.5907, average loss: 263.1504
[11/22 15:07:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.34	
[11/22 15:07:20 visual_prompt]: Training 30 / 100 epoch, with learning rate 44.70026884016804
[11/22 15:14:44 visual_prompt]: Epoch 30 / 100: avg data time: 4.90e+00, avg batch time: 6.3425, average train loss: 124.3856
[11/22 15:15:34 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.5882, average loss: 35.3219
[11/22 15:15:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.47	rocauc: 45.57	
[11/22 15:15:34 visual_prompt]: Training 31 / 100 epoch, with learning rate 44.15111107797445
[11/22 15:22:57 visual_prompt]: Epoch 31 / 100: avg data time: 4.89e+00, avg batch time: 6.3288, average train loss: 90.1168
[11/22 15:23:48 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.5899, average loss: 62.5616
[11/22 15:23:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.61	
[11/22 15:23:48 visual_prompt]: Training 32 / 100 epoch, with learning rate 43.57862063693486
[11/22 15:31:12 visual_prompt]: Epoch 32 / 100: avg data time: 4.91e+00, avg batch time: 6.3491, average train loss: 141.1328
[11/22 15:32:04 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.5864, average loss: 49.1966
[11/22 15:32:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 37.79	
[11/22 15:32:04 visual_prompt]: Training 33 / 100 epoch, with learning rate 42.98349500846628
[11/22 15:39:28 visual_prompt]: Epoch 33 / 100: avg data time: 4.90e+00, avg batch time: 6.3391, average train loss: 171.0309
[11/22 15:40:18 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.5848, average loss: 93.6822
[11/22 15:40:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.67	
[11/22 15:40:18 visual_prompt]: Training 34 / 100 epoch, with learning rate 42.36645926147493
[11/22 15:47:43 visual_prompt]: Epoch 34 / 100: avg data time: 4.91e+00, avg batch time: 6.3471, average train loss: 149.7995
[11/22 15:48:33 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.5879, average loss: 80.9170
[11/22 15:48:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 44.14	
[11/22 15:48:33 visual_prompt]: Training 35 / 100 epoch, with learning rate 41.72826515897145
[11/22 15:55:55 visual_prompt]: Epoch 35 / 100: avg data time: 4.87e+00, avg batch time: 6.3136, average train loss: 122.3858
[11/22 15:56:45 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.5841, average loss: 111.7660
[11/22 15:56:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.22	
[11/22 15:56:45 visual_prompt]: Training 36 / 100 epoch, with learning rate 41.06969024216348
[11/22 16:04:10 visual_prompt]: Epoch 36 / 100: avg data time: 4.90e+00, avg batch time: 6.3434, average train loss: 93.8266
[11/22 16:05:00 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.5901, average loss: 70.4725
[11/22 16:05:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.88	
[11/22 16:05:00 visual_prompt]: Training 37 / 100 epoch, with learning rate 40.391536883141455
[11/22 16:12:23 visual_prompt]: Epoch 37 / 100: avg data time: 4.89e+00, avg batch time: 6.3273, average train loss: 96.4561
[11/22 16:13:14 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.5907, average loss: 88.9703
[11/22 16:13:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 45.71	
[11/22 16:13:14 visual_prompt]: Stopping early.
[11/22 16:13:14 visual_prompt]: Rank of current process: 0. World size: 1
[11/22 16:13:14 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/22 16:13:14 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/22 16:13:14 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/22 16:13:14 visual_prompt]: Training with config:
[11/22 16:13:14 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr50.0_wd0.001/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 50.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/22 16:13:14 visual_prompt]: Loading training data...
[11/22 16:13:14 visual_prompt]: Constructing mammo-cbis dataset train...
[11/22 16:13:14 visual_prompt]: Loading validation data...
[11/22 16:13:14 visual_prompt]: Constructing mammo-cbis dataset val...
[11/22 16:13:14 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/22 16:13:17 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/22 16:13:17 visual_prompt]: tuned percent:0.532
[11/22 16:13:17 visual_prompt]: Device used for model: 0
[11/22 16:13:17 visual_prompt]: Setting up Evaluator...
[11/22 16:13:17 visual_prompt]: Setting up Trainer...
[11/22 16:13:17 visual_prompt]: 	Setting up the optimizer...
[11/22 16:13:17 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/22 16:20:41 visual_prompt]: Epoch 1 / 100: avg data time: 4.89e+00, avg batch time: 6.3436, average train loss: 1.4863
[11/22 16:21:31 visual_prompt]: Inference (val):avg data time: 2.05e-05, avg batch time: 0.5937, average loss: 1.4553
[11/22 16:21:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/22 16:21:31 visual_prompt]: Training 2 / 100 epoch, with learning rate 5.0
[11/22 16:28:54 visual_prompt]: Epoch 2 / 100: avg data time: 4.87e+00, avg batch time: 6.3197, average train loss: 29.6890
[11/22 16:29:44 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.5867, average loss: 4.8085
[11/22 16:29:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.82	
[11/22 16:29:44 visual_prompt]: Training 3 / 100 epoch, with learning rate 10.0
[11/22 16:37:07 visual_prompt]: Epoch 3 / 100: avg data time: 4.88e+00, avg batch time: 6.3283, average train loss: 28.3773
[11/22 16:37:57 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.5862, average loss: 36.1099
[11/22 16:37:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.14	
[11/22 16:37:58 visual_prompt]: Training 4 / 100 epoch, with learning rate 15.0
[11/22 16:45:18 visual_prompt]: Epoch 4 / 100: avg data time: 4.85e+00, avg batch time: 6.2964, average train loss: 28.7815
[11/22 16:46:09 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.5868, average loss: 28.0690
[11/22 16:46:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.59	
[11/22 16:46:09 visual_prompt]: Training 5 / 100 epoch, with learning rate 20.0
[11/22 16:53:30 visual_prompt]: Epoch 5 / 100: avg data time: 4.86e+00, avg batch time: 6.2990, average train loss: 37.3561
[11/22 16:54:20 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.5842, average loss: 105.6275
[11/22 16:54:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.50	
[11/22 16:54:20 visual_prompt]: Training 6 / 100 epoch, with learning rate 25.0
[11/22 17:02:03 visual_prompt]: Epoch 6 / 100: avg data time: 5.17e+00, avg batch time: 6.6119, average train loss: 49.8338
[11/22 17:02:55 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.5845, average loss: 79.5973
[11/22 17:02:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 41.72	
[11/22 17:02:55 visual_prompt]: Training 7 / 100 epoch, with learning rate 30.0
[11/22 17:10:23 visual_prompt]: Epoch 7 / 100: avg data time: 4.96e+00, avg batch time: 6.4044, average train loss: 76.3471
[11/22 17:11:14 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.5871, average loss: 59.3471
[11/22 17:11:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.57	
[11/22 17:11:14 visual_prompt]: Training 8 / 100 epoch, with learning rate 35.0
[11/22 17:18:37 visual_prompt]: Epoch 8 / 100: avg data time: 4.89e+00, avg batch time: 6.3270, average train loss: 121.1505
[11/22 17:19:27 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.5865, average loss: 242.3564
[11/22 17:19:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.41	
[11/22 17:19:27 visual_prompt]: Training 9 / 100 epoch, with learning rate 40.0
[11/22 17:26:51 visual_prompt]: Epoch 9 / 100: avg data time: 4.89e+00, avg batch time: 6.3329, average train loss: 98.8507
[11/22 17:27:41 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.5866, average loss: 265.9323
[11/22 17:27:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.62	
[11/22 17:27:41 visual_prompt]: Training 10 / 100 epoch, with learning rate 45.0
[11/22 17:35:07 visual_prompt]: Epoch 10 / 100: avg data time: 4.92e+00, avg batch time: 6.3629, average train loss: 108.4417
[11/22 17:35:57 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.5864, average loss: 25.7128
[11/22 17:35:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.06	
[11/22 17:35:57 visual_prompt]: Training 11 / 100 epoch, with learning rate 50.0
[11/22 17:43:20 visual_prompt]: Epoch 11 / 100: avg data time: 4.89e+00, avg batch time: 6.3339, average train loss: 86.0772
[11/22 17:44:11 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.5849, average loss: 233.3680
[11/22 17:44:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 45.84	
[11/22 17:44:11 visual_prompt]: Training 12 / 100 epoch, with learning rate 49.9847706754774
[11/22 17:51:33 visual_prompt]: Epoch 12 / 100: avg data time: 4.87e+00, avg batch time: 6.3158, average train loss: 125.8367
[11/22 17:52:24 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.5897, average loss: 3.7898
[11/22 17:52:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.28	
[11/22 17:52:24 visual_prompt]: Best epoch 12: best metric: -3.790
[11/22 17:52:24 visual_prompt]: Training 13 / 100 epoch, with learning rate 49.939101256495604
[11/22 17:59:48 visual_prompt]: Epoch 13 / 100: avg data time: 4.90e+00, avg batch time: 6.3408, average train loss: 145.2245
[11/22 18:00:39 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.5900, average loss: 16.6351
[11/22 18:00:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.75	
[11/22 18:00:39 visual_prompt]: Training 14 / 100 epoch, with learning rate 49.86304738420683
[11/22 18:08:00 visual_prompt]: Epoch 14 / 100: avg data time: 4.87e+00, avg batch time: 6.3084, average train loss: 130.2937
[11/22 18:08:52 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.5858, average loss: 52.4746
[11/22 18:08:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.90	
[11/22 18:08:52 visual_prompt]: Training 15 / 100 epoch, with learning rate 49.75670171853926
[11/22 18:16:13 visual_prompt]: Epoch 15 / 100: avg data time: 4.86e+00, avg batch time: 6.3025, average train loss: 80.5654
[11/22 18:17:03 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.5920, average loss: 43.1324
[11/22 18:17:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.08	
[11/22 18:17:03 visual_prompt]: Training 16 / 100 epoch, with learning rate 49.6201938253052
[11/22 18:24:25 visual_prompt]: Epoch 16 / 100: avg data time: 4.87e+00, avg batch time: 6.3140, average train loss: 106.6968
[11/22 18:25:17 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.5848, average loss: 337.7281
[11/22 18:25:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.76	
[11/22 18:25:17 visual_prompt]: Training 17 / 100 epoch, with learning rate 49.45369001834514
[11/22 18:32:41 visual_prompt]: Epoch 17 / 100: avg data time: 4.91e+00, avg batch time: 6.3511, average train loss: 128.5729
[11/22 18:33:32 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.5885, average loss: 380.2673
[11/22 18:33:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.12	
[11/22 18:33:32 visual_prompt]: Training 18 / 100 epoch, with learning rate 49.25739315689991
[11/22 18:40:56 visual_prompt]: Epoch 18 / 100: avg data time: 4.90e+00, avg batch time: 6.3345, average train loss: 109.7811
[11/22 18:41:47 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.5858, average loss: 17.9192
[11/22 18:41:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.66	
[11/22 18:41:47 visual_prompt]: Training 19 / 100 epoch, with learning rate 49.03154239845797
[11/22 18:49:08 visual_prompt]: Epoch 19 / 100: avg data time: 4.86e+00, avg batch time: 6.3066, average train loss: 130.5409
[11/22 18:50:00 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.5878, average loss: 84.5841
[11/22 18:50:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.71	
[11/22 18:50:00 visual_prompt]: Training 20 / 100 epoch, with learning rate 48.77641290737884
[11/22 18:57:24 visual_prompt]: Epoch 20 / 100: avg data time: 4.90e+00, avg batch time: 6.3406, average train loss: 92.9746
[11/22 18:58:15 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.5853, average loss: 141.7912
[11/22 18:58:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.49	
[11/22 18:58:15 visual_prompt]: Training 21 / 100 epoch, with learning rate 48.49231551964771
[11/22 19:05:38 visual_prompt]: Epoch 21 / 100: avg data time: 4.89e+00, avg batch time: 6.3353, average train loss: 93.9640
[11/22 19:06:29 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.5893, average loss: 143.8580
[11/22 19:06:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.35	
[11/22 19:06:29 visual_prompt]: Training 22 / 100 epoch, with learning rate 48.17959636416968
[11/22 19:13:54 visual_prompt]: Epoch 22 / 100: avg data time: 4.91e+00, avg batch time: 6.3460, average train loss: 108.6632
[11/22 19:14:44 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.5896, average loss: 164.8212
[11/22 19:14:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.19	
[11/22 19:14:44 visual_prompt]: Training 23 / 100 epoch, with learning rate 47.83863644106502
[11/22 19:22:12 visual_prompt]: Epoch 23 / 100: avg data time: 4.96e+00, avg batch time: 6.3955, average train loss: 147.8838
[11/22 19:23:03 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.5883, average loss: 4.1596
[11/22 19:23:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 35.92	
[11/22 19:23:03 visual_prompt]: Training 24 / 100 epoch, with learning rate 47.46985115747918
[11/22 19:30:28 visual_prompt]: Epoch 24 / 100: avg data time: 4.91e+00, avg batch time: 6.3544, average train loss: 131.2509
[11/22 19:31:18 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.5914, average loss: 268.7511
[11/22 19:31:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.99	
[11/22 19:31:18 visual_prompt]: Training 25 / 100 epoch, with learning rate 47.073689821473174
[11/22 19:38:42 visual_prompt]: Epoch 25 / 100: avg data time: 4.90e+00, avg batch time: 6.3404, average train loss: 89.2651
[11/22 19:39:33 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.5852, average loss: 16.8490
[11/22 19:39:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 44.50	
[11/22 19:39:33 visual_prompt]: Training 26 / 100 epoch, with learning rate 46.65063509461097
[11/22 19:46:57 visual_prompt]: Epoch 26 / 100: avg data time: 4.89e+00, avg batch time: 6.3347, average train loss: 109.7163
[11/22 19:47:47 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.5849, average loss: 135.4173
[11/22 19:47:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.60	
[11/22 19:47:47 visual_prompt]: Training 27 / 100 epoch, with learning rate 46.20120240391065
[11/22 19:55:09 visual_prompt]: Epoch 27 / 100: avg data time: 4.87e+00, avg batch time: 6.3075, average train loss: 133.6033
[11/22 19:55:59 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.5846, average loss: 17.3202
[11/22 19:55:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 48.78	rocauc: 47.23	
[11/22 19:55:59 visual_prompt]: Training 28 / 100 epoch, with learning rate 45.72593931387604
[11/22 20:03:22 visual_prompt]: Epoch 28 / 100: avg data time: 4.89e+00, avg batch time: 6.3266, average train loss: 133.9062
[11/22 20:04:13 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.5833, average loss: 169.7275
[11/22 20:04:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.08	
[11/22 20:04:13 visual_prompt]: Training 29 / 100 epoch, with learning rate 45.22542485937369
[11/22 20:11:35 visual_prompt]: Epoch 29 / 100: avg data time: 4.88e+00, avg batch time: 6.3237, average train loss: 107.2097
[11/22 20:12:26 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.5909, average loss: 277.7167
[11/22 20:12:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.66	
[11/22 20:12:26 visual_prompt]: Training 30 / 100 epoch, with learning rate 44.70026884016804
[11/22 20:19:50 visual_prompt]: Epoch 30 / 100: avg data time: 4.90e+00, avg batch time: 6.3428, average train loss: 101.4560
[11/22 20:20:40 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.5886, average loss: 74.6420
[11/22 20:20:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.95	
[11/22 20:20:40 visual_prompt]: Training 31 / 100 epoch, with learning rate 44.15111107797445
[11/22 20:28:02 visual_prompt]: Epoch 31 / 100: avg data time: 4.86e+00, avg batch time: 6.3019, average train loss: 124.6804
[11/22 20:28:52 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.5856, average loss: 6.7570
[11/22 20:28:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.40	
[11/22 20:28:52 visual_prompt]: Training 32 / 100 epoch, with learning rate 43.57862063693486
[11/22 20:36:15 visual_prompt]: Epoch 32 / 100: avg data time: 4.88e+00, avg batch time: 6.3219, average train loss: 107.6275
[11/22 20:37:05 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.5890, average loss: 32.8927
[11/22 20:37:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 44.52	
[11/22 20:37:05 visual_prompt]: Training 33 / 100 epoch, with learning rate 42.98349500846628
[11/22 20:44:27 visual_prompt]: Epoch 33 / 100: avg data time: 4.87e+00, avg batch time: 6.3155, average train loss: 136.6128
[11/22 20:45:19 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.5891, average loss: 96.4105
[11/22 20:45:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.28	
[11/22 20:45:19 visual_prompt]: Stopping early.
[11/22 20:45:19 visual_prompt]: Rank of current process: 0. World size: 1
[11/22 20:45:19 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/22 20:45:19 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/22 20:45:19 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/22 20:45:19 visual_prompt]: Training with config:
[11/22 20:45:19 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr50.0_wd0.0001/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 50.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/22 20:45:19 visual_prompt]: Loading training data...
[11/22 20:45:19 visual_prompt]: Constructing mammo-cbis dataset train...
[11/22 20:45:19 visual_prompt]: Loading validation data...
[11/22 20:45:19 visual_prompt]: Constructing mammo-cbis dataset val...
[11/22 20:45:19 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/22 20:45:21 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/22 20:45:21 visual_prompt]: tuned percent:0.532
[11/22 20:45:21 visual_prompt]: Device used for model: 0
[11/22 20:45:21 visual_prompt]: Setting up Evaluator...
[11/22 20:45:21 visual_prompt]: Setting up Trainer...
[11/22 20:45:21 visual_prompt]: 	Setting up the optimizer...
[11/22 20:45:21 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/22 20:52:44 visual_prompt]: Epoch 1 / 100: avg data time: 4.87e+00, avg batch time: 6.3259, average train loss: 1.4863
[11/22 20:53:35 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.5901, average loss: 1.4553
[11/22 20:53:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/22 20:53:35 visual_prompt]: Training 2 / 100 epoch, with learning rate 5.0
[11/22 21:00:57 visual_prompt]: Epoch 2 / 100: avg data time: 4.87e+00, avg batch time: 6.3170, average train loss: 20.3780
[11/22 21:01:48 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.5841, average loss: 5.1255
[11/22 21:01:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.29	
[11/22 21:01:48 visual_prompt]: Training 3 / 100 epoch, with learning rate 10.0
[11/22 21:09:09 visual_prompt]: Epoch 3 / 100: avg data time: 4.85e+00, avg batch time: 6.2983, average train loss: 22.9462
[11/22 21:10:00 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.5895, average loss: 23.8554
[11/22 21:10:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.59	
[11/22 21:10:00 visual_prompt]: Training 4 / 100 epoch, with learning rate 15.0
[11/22 21:17:23 visual_prompt]: Epoch 4 / 100: avg data time: 4.88e+00, avg batch time: 6.3241, average train loss: 30.8549
[11/22 21:18:13 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.5832, average loss: 40.9484
[11/22 21:18:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.05	
[11/22 21:18:13 visual_prompt]: Training 5 / 100 epoch, with learning rate 20.0
[11/22 21:25:35 visual_prompt]: Epoch 5 / 100: avg data time: 4.86e+00, avg batch time: 6.3101, average train loss: 39.4185
[11/22 21:26:26 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.5842, average loss: 25.5446
[11/22 21:26:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.95	
[11/22 21:26:26 visual_prompt]: Training 6 / 100 epoch, with learning rate 25.0
[11/22 21:33:49 visual_prompt]: Epoch 6 / 100: avg data time: 4.90e+00, avg batch time: 6.3390, average train loss: 55.9571
[11/22 21:34:40 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.5856, average loss: 104.3030
[11/22 21:34:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.10	
[11/22 21:34:40 visual_prompt]: Training 7 / 100 epoch, with learning rate 30.0
[11/22 21:42:02 visual_prompt]: Epoch 7 / 100: avg data time: 4.87e+00, avg batch time: 6.3107, average train loss: 45.2455
[11/22 21:42:53 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.5850, average loss: 79.2160
[11/22 21:42:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.91	
[11/22 21:42:53 visual_prompt]: Training 8 / 100 epoch, with learning rate 35.0
[11/22 21:50:17 visual_prompt]: Epoch 8 / 100: avg data time: 4.90e+00, avg batch time: 6.3428, average train loss: 65.1711
[11/22 21:51:07 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.5873, average loss: 14.0736
[11/22 21:51:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 45.57	
[11/22 21:51:07 visual_prompt]: Training 9 / 100 epoch, with learning rate 40.0
[11/22 21:58:30 visual_prompt]: Epoch 9 / 100: avg data time: 4.88e+00, avg batch time: 6.3197, average train loss: 54.6180
[11/22 21:59:20 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.5854, average loss: 82.0216
[11/22 21:59:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.68	
[11/22 21:59:20 visual_prompt]: Training 10 / 100 epoch, with learning rate 45.0
[11/22 22:06:44 visual_prompt]: Epoch 10 / 100: avg data time: 4.90e+00, avg batch time: 6.3451, average train loss: 86.8197
[11/22 22:07:36 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.5857, average loss: 59.5717
[11/22 22:07:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 44.88	
[11/22 22:07:36 visual_prompt]: Training 11 / 100 epoch, with learning rate 50.0
[11/22 22:15:01 visual_prompt]: Epoch 11 / 100: avg data time: 4.92e+00, avg batch time: 6.3608, average train loss: 96.6974
[11/22 22:15:52 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.5907, average loss: 84.8839
[11/22 22:15:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.14	
[11/22 22:15:52 visual_prompt]: Training 12 / 100 epoch, with learning rate 49.9847706754774
[11/22 22:23:16 visual_prompt]: Epoch 12 / 100: avg data time: 4.90e+00, avg batch time: 6.3427, average train loss: 110.2374
[11/22 22:24:06 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.5857, average loss: 40.7016
[11/22 22:24:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 45.03	
[11/22 22:24:06 visual_prompt]: Best epoch 12: best metric: -40.702
[11/22 22:24:06 visual_prompt]: Training 13 / 100 epoch, with learning rate 49.939101256495604
[11/22 22:31:28 visual_prompt]: Epoch 13 / 100: avg data time: 4.87e+00, avg batch time: 6.3148, average train loss: 82.8512
[11/22 22:32:19 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.5892, average loss: 42.2964
[11/22 22:32:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.54	
[11/22 22:32:19 visual_prompt]: Training 14 / 100 epoch, with learning rate 49.86304738420683
[11/22 22:39:42 visual_prompt]: Epoch 14 / 100: avg data time: 4.88e+00, avg batch time: 6.3200, average train loss: 186.6293
[11/22 22:40:32 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.5836, average loss: 151.4444
[11/22 22:40:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.88	
[11/22 22:40:32 visual_prompt]: Training 15 / 100 epoch, with learning rate 49.75670171853926
[11/22 22:47:57 visual_prompt]: Epoch 15 / 100: avg data time: 4.91e+00, avg batch time: 6.3486, average train loss: 126.1228
[11/22 22:48:48 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.5854, average loss: 54.1846
[11/22 22:48:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.20	
[11/22 22:48:48 visual_prompt]: Training 16 / 100 epoch, with learning rate 49.6201938253052
[11/22 22:56:12 visual_prompt]: Epoch 16 / 100: avg data time: 4.90e+00, avg batch time: 6.3404, average train loss: 77.2475
[11/22 22:57:02 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.5902, average loss: 147.1842
[11/22 22:57:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.70	
[11/22 22:57:02 visual_prompt]: Training 17 / 100 epoch, with learning rate 49.45369001834514
[11/22 23:04:24 visual_prompt]: Epoch 17 / 100: avg data time: 4.87e+00, avg batch time: 6.3086, average train loss: 69.4608
[11/22 23:05:14 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.5872, average loss: 224.6104
[11/22 23:05:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.21	
[11/22 23:05:14 visual_prompt]: Training 18 / 100 epoch, with learning rate 49.25739315689991
[11/22 23:12:37 visual_prompt]: Epoch 18 / 100: avg data time: 4.88e+00, avg batch time: 6.3253, average train loss: 107.6016
[11/22 23:13:28 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.5878, average loss: 28.3802
[11/22 23:13:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.00	
[11/22 23:13:28 visual_prompt]: Best epoch 18: best metric: -28.380
[11/22 23:13:28 visual_prompt]: Training 19 / 100 epoch, with learning rate 49.03154239845797
[11/22 23:20:48 visual_prompt]: Epoch 19 / 100: avg data time: 4.85e+00, avg batch time: 6.2919, average train loss: 73.0924
[11/22 23:21:39 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.5878, average loss: 5.8467
[11/22 23:21:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.44	
[11/22 23:21:39 visual_prompt]: Best epoch 19: best metric: -5.847
[11/22 23:21:39 visual_prompt]: Training 20 / 100 epoch, with learning rate 48.77641290737884
[11/22 23:29:02 visual_prompt]: Epoch 20 / 100: avg data time: 4.89e+00, avg batch time: 6.3282, average train loss: 92.2818
[11/22 23:29:54 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.5846, average loss: 147.1998
[11/22 23:29:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.43	
[11/22 23:29:54 visual_prompt]: Training 21 / 100 epoch, with learning rate 48.49231551964771
[11/22 23:37:24 visual_prompt]: Epoch 21 / 100: avg data time: 5.00e+00, avg batch time: 6.4320, average train loss: 113.5255
[11/22 23:38:15 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.5873, average loss: 59.1547
[11/22 23:38:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.86	
[11/22 23:38:15 visual_prompt]: Training 22 / 100 epoch, with learning rate 48.17959636416968
[11/22 23:45:46 visual_prompt]: Epoch 22 / 100: avg data time: 4.99e+00, avg batch time: 6.4366, average train loss: 91.3612
[11/22 23:46:37 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.5869, average loss: 10.5461
[11/22 23:46:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.10	
[11/22 23:46:37 visual_prompt]: Training 23 / 100 epoch, with learning rate 47.83863644106502
[11/22 23:54:07 visual_prompt]: Epoch 23 / 100: avg data time: 4.99e+00, avg batch time: 6.4254, average train loss: 133.1470
[11/22 23:54:59 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.5890, average loss: 85.4615
[11/22 23:54:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.47	
[11/22 23:54:59 visual_prompt]: Training 24 / 100 epoch, with learning rate 47.46985115747918
[11/23 00:02:29 visual_prompt]: Epoch 24 / 100: avg data time: 4.99e+00, avg batch time: 6.4279, average train loss: 80.1999
[11/23 00:03:20 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.5857, average loss: 3.8078
[11/23 00:03:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.12	
[11/23 00:03:20 visual_prompt]: Best epoch 24: best metric: -3.808
[11/23 00:03:20 visual_prompt]: Training 25 / 100 epoch, with learning rate 47.073689821473174
[11/23 00:10:51 visual_prompt]: Epoch 25 / 100: avg data time: 5.00e+00, avg batch time: 6.4354, average train loss: 122.6318
[11/23 00:11:42 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.5901, average loss: 156.8054
[11/23 00:11:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.67	
[11/23 00:11:42 visual_prompt]: Training 26 / 100 epoch, with learning rate 46.65063509461097
[11/23 00:19:11 visual_prompt]: Epoch 26 / 100: avg data time: 4.97e+00, avg batch time: 6.4080, average train loss: 93.7701
[11/23 00:20:02 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.5837, average loss: 10.4415
[11/23 00:20:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.47	
[11/23 00:20:02 visual_prompt]: Training 27 / 100 epoch, with learning rate 46.20120240391065
[11/23 00:27:31 visual_prompt]: Epoch 27 / 100: avg data time: 4.96e+00, avg batch time: 6.4043, average train loss: 93.0354
[11/23 00:28:22 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.5901, average loss: 173.7292
[11/23 00:28:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.06	
[11/23 00:28:22 visual_prompt]: Training 28 / 100 epoch, with learning rate 45.72593931387604
[11/23 00:35:52 visual_prompt]: Epoch 28 / 100: avg data time: 4.99e+00, avg batch time: 6.4308, average train loss: 98.3128
[11/23 00:36:44 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.5884, average loss: 115.2049
[11/23 00:36:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.74	
[11/23 00:36:44 visual_prompt]: Training 29 / 100 epoch, with learning rate 45.22542485937369
[11/23 00:44:14 visual_prompt]: Epoch 29 / 100: avg data time: 4.99e+00, avg batch time: 6.4292, average train loss: 92.3197
[11/23 00:45:05 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.5929, average loss: 208.0735
[11/23 00:45:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.10	
[11/23 00:45:05 visual_prompt]: Training 30 / 100 epoch, with learning rate 44.70026884016804
[11/23 00:52:35 visual_prompt]: Epoch 30 / 100: avg data time: 4.98e+00, avg batch time: 6.4225, average train loss: 117.8638
[11/23 00:53:26 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.5867, average loss: 151.8972
[11/23 00:53:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.73	
[11/23 00:53:26 visual_prompt]: Training 31 / 100 epoch, with learning rate 44.15111107797445
[11/23 01:00:55 visual_prompt]: Epoch 31 / 100: avg data time: 4.97e+00, avg batch time: 6.4098, average train loss: 136.5047
[11/23 01:01:47 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.5859, average loss: 18.3430
[11/23 01:01:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.27	
[11/23 01:01:47 visual_prompt]: Training 32 / 100 epoch, with learning rate 43.57862063693486
[11/23 01:09:16 visual_prompt]: Epoch 32 / 100: avg data time: 4.98e+00, avg batch time: 6.4213, average train loss: 64.2359
[11/23 01:10:08 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.5843, average loss: 106.8584
[11/23 01:10:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.53	
[11/23 01:10:08 visual_prompt]: Training 33 / 100 epoch, with learning rate 42.98349500846628
[11/23 01:17:31 visual_prompt]: Epoch 33 / 100: avg data time: 4.89e+00, avg batch time: 6.3362, average train loss: 94.7470
[11/23 01:18:22 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.5883, average loss: 178.2198
[11/23 01:18:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.42	
[11/23 01:18:22 visual_prompt]: Training 34 / 100 epoch, with learning rate 42.36645926147493
[11/23 01:25:43 visual_prompt]: Epoch 34 / 100: avg data time: 4.86e+00, avg batch time: 6.3019, average train loss: 105.6765
[11/23 01:26:33 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.5861, average loss: 11.9395
[11/23 01:26:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.11	
[11/23 01:26:33 visual_prompt]: Training 35 / 100 epoch, with learning rate 41.72826515897145
[11/23 01:33:57 visual_prompt]: Epoch 35 / 100: avg data time: 4.90e+00, avg batch time: 6.3358, average train loss: 119.8641
[11/23 01:34:48 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.5880, average loss: 197.5336
[11/23 01:34:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.46	
[11/23 01:34:48 visual_prompt]: Training 36 / 100 epoch, with learning rate 41.06969024216348
[11/23 01:42:12 visual_prompt]: Epoch 36 / 100: avg data time: 4.91e+00, avg batch time: 6.3471, average train loss: 78.3067
[11/23 01:43:03 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.5886, average loss: 3.5021
[11/23 01:43:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 44.31	rocauc: 46.27	
[11/23 01:43:03 visual_prompt]: Best epoch 36: best metric: -3.502
[11/23 01:43:03 visual_prompt]: Training 37 / 100 epoch, with learning rate 40.391536883141455
[11/23 01:50:27 visual_prompt]: Epoch 37 / 100: avg data time: 4.89e+00, avg batch time: 6.3394, average train loss: 75.9535
[11/23 01:51:18 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.5877, average loss: 67.3251
[11/23 01:51:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.24	
[11/23 01:51:18 visual_prompt]: Training 38 / 100 epoch, with learning rate 39.69463130731183
[11/23 01:58:40 visual_prompt]: Epoch 38 / 100: avg data time: 4.88e+00, avg batch time: 6.3216, average train loss: 48.9238
[11/23 01:59:31 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.5896, average loss: 80.9727
[11/23 01:59:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.82	
[11/23 01:59:31 visual_prompt]: Training 39 / 100 epoch, with learning rate 38.97982258676867
[11/23 02:06:55 visual_prompt]: Epoch 39 / 100: avg data time: 4.90e+00, avg batch time: 6.3453, average train loss: 88.0498
[11/23 02:07:46 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.5864, average loss: 72.4487
[11/23 02:07:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 44.85	
[11/23 02:07:46 visual_prompt]: Training 40 / 100 epoch, with learning rate 38.24798160583012
[11/23 02:15:09 visual_prompt]: Epoch 40 / 100: avg data time: 4.89e+00, avg batch time: 6.3319, average train loss: 58.7556
[11/23 02:16:00 visual_prompt]: Inference (val):avg data time: 2.03e-03, avg batch time: 0.5863, average loss: 11.0629
[11/23 02:16:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.60	
[11/23 02:16:00 visual_prompt]: Training 41 / 100 epoch, with learning rate 37.5
[11/23 02:23:23 visual_prompt]: Epoch 41 / 100: avg data time: 4.89e+00, avg batch time: 6.3301, average train loss: 50.7774
[11/23 02:24:14 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.5859, average loss: 67.7956
[11/23 02:24:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.24	
[11/23 02:24:14 visual_prompt]: Training 42 / 100 epoch, with learning rate 36.736789069647266
[11/23 02:31:37 visual_prompt]: Epoch 42 / 100: avg data time: 4.89e+00, avg batch time: 6.3279, average train loss: 83.1322
[11/23 02:32:27 visual_prompt]: Inference (val):avg data time: 1.24e-04, avg batch time: 0.5887, average loss: 175.8947
[11/23 02:32:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 44.14	
[11/23 02:32:27 visual_prompt]: Training 43 / 100 epoch, with learning rate 35.959278669726935
[11/23 02:39:53 visual_prompt]: Epoch 43 / 100: avg data time: 4.93e+00, avg batch time: 6.3691, average train loss: 83.4012
[11/23 02:40:44 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.5880, average loss: 187.2698
[11/23 02:40:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.43	
[11/23 02:40:44 visual_prompt]: Training 44 / 100 epoch, with learning rate 35.16841607689501
[11/23 02:48:08 visual_prompt]: Epoch 44 / 100: avg data time: 4.90e+00, avg batch time: 6.3365, average train loss: 70.3138
[11/23 02:48:58 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.5922, average loss: 100.1013
[11/23 02:48:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 45.89	
[11/23 02:48:58 visual_prompt]: Training 45 / 100 epoch, with learning rate 34.365164835397806
[11/23 02:56:22 visual_prompt]: Epoch 45 / 100: avg data time: 4.90e+00, avg batch time: 6.3391, average train loss: 63.3193
[11/23 02:57:13 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.5886, average loss: 5.9979
[11/23 02:57:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.27	
[11/23 02:57:13 visual_prompt]: Training 46 / 100 epoch, with learning rate 33.55050358314172
[11/23 03:04:35 visual_prompt]: Epoch 46 / 100: avg data time: 4.87e+00, avg batch time: 6.3152, average train loss: 57.3201
[11/23 03:05:25 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.5847, average loss: 44.7624
[11/23 03:05:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 42.64	
[11/23 03:05:25 visual_prompt]: Training 47 / 100 epoch, with learning rate 32.72542485937369
[11/23 03:12:48 visual_prompt]: Epoch 47 / 100: avg data time: 4.89e+00, avg batch time: 6.3289, average train loss: 57.2510
[11/23 03:13:39 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.5914, average loss: 8.4430
[11/23 03:13:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.11	
[11/23 03:13:39 visual_prompt]: Training 48 / 100 epoch, with learning rate 31.89093389542498
[11/23 03:20:59 visual_prompt]: Epoch 48 / 100: avg data time: 4.85e+00, avg batch time: 6.2934, average train loss: 52.1243
[11/23 03:21:50 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.5896, average loss: 52.3113
[11/23 03:21:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.63	
[11/23 03:21:50 visual_prompt]: Training 49 / 100 epoch, with learning rate 31.04804738999169
[11/23 03:29:12 visual_prompt]: Epoch 49 / 100: avg data time: 4.87e+00, avg batch time: 6.3215, average train loss: 42.0767
[11/23 03:30:03 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.5886, average loss: 38.1934
[11/23 03:30:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.29	
[11/23 03:30:03 visual_prompt]: Training 50 / 100 epoch, with learning rate 30.19779227044398
[11/23 03:37:26 visual_prompt]: Epoch 50 / 100: avg data time: 4.89e+00, avg batch time: 6.3234, average train loss: 97.6234
[11/23 03:38:17 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.5863, average loss: 148.9838
[11/23 03:38:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.77	
[11/23 03:38:17 visual_prompt]: Training 51 / 100 epoch, with learning rate 29.341204441673263
[11/23 03:45:38 visual_prompt]: Epoch 51 / 100: avg data time: 4.87e+00, avg batch time: 6.3091, average train loss: 46.9198
[11/23 03:46:29 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.5869, average loss: 95.2465
[11/23 03:46:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 61.53	
[11/23 03:46:29 visual_prompt]: Training 52 / 100 epoch, with learning rate 28.479327524001636
[11/23 03:53:54 visual_prompt]: Epoch 52 / 100: avg data time: 4.91e+00, avg batch time: 6.3505, average train loss: 53.4680
[11/23 03:54:44 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.5858, average loss: 74.4442
[11/23 03:54:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.80	
[11/23 03:54:44 visual_prompt]: Training 53 / 100 epoch, with learning rate 27.61321158169134
[11/23 04:02:08 visual_prompt]: Epoch 53 / 100: avg data time: 4.89e+00, avg batch time: 6.3406, average train loss: 36.1559
[11/23 04:02:58 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.5916, average loss: 29.0806
[11/23 04:02:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.60	
[11/23 04:02:58 visual_prompt]: Training 54 / 100 epoch, with learning rate 26.74391184360313
[11/23 04:10:20 visual_prompt]: Epoch 54 / 100: avg data time: 4.86e+00, avg batch time: 6.3062, average train loss: 58.0513
[11/23 04:11:11 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.5864, average loss: 73.3476
[11/23 04:11:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.51	
[11/23 04:11:11 visual_prompt]: Training 55 / 100 epoch, with learning rate 25.872487417562528
[11/23 04:18:33 visual_prompt]: Epoch 55 / 100: avg data time: 4.88e+00, avg batch time: 6.3195, average train loss: 57.5813
[11/23 04:19:24 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.5825, average loss: 33.6108
[11/23 04:19:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.95	
[11/23 04:19:24 visual_prompt]: Training 56 / 100 epoch, with learning rate 25.0
[11/23 04:26:44 visual_prompt]: Epoch 56 / 100: avg data time: 4.85e+00, avg batch time: 6.2935, average train loss: 44.6864
[11/23 04:27:35 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.5877, average loss: 52.2001
[11/23 04:27:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.65	
[11/23 04:27:35 visual_prompt]: Training 57 / 100 epoch, with learning rate 24.127512582437483
[11/23 04:35:01 visual_prompt]: Epoch 57 / 100: avg data time: 4.93e+00, avg batch time: 6.3709, average train loss: 53.5879
[11/23 04:35:52 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.5872, average loss: 6.1235
[11/23 04:35:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.01	
[11/23 04:35:52 visual_prompt]: Stopping early.
[11/23 04:35:52 visual_prompt]: Rank of current process: 0. World size: 1
[11/23 04:35:52 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/23 04:35:52 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/23 04:35:52 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/23 04:35:52 visual_prompt]: Training with config:
[11/23 04:35:52 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr50.0_wd0.0/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 50.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/23 04:35:52 visual_prompt]: Loading training data...
[11/23 04:35:52 visual_prompt]: Constructing mammo-cbis dataset train...
[11/23 04:35:52 visual_prompt]: Loading validation data...
[11/23 04:35:52 visual_prompt]: Constructing mammo-cbis dataset val...
[11/23 04:35:52 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/23 04:35:55 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/23 04:35:55 visual_prompt]: tuned percent:0.532
[11/23 04:35:55 visual_prompt]: Device used for model: 0
[11/23 04:35:55 visual_prompt]: Setting up Evaluator...
[11/23 04:35:55 visual_prompt]: Setting up Trainer...
[11/23 04:35:55 visual_prompt]: 	Setting up the optimizer...
[11/23 04:35:55 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/23 04:43:20 visual_prompt]: Epoch 1 / 100: avg data time: 4.90e+00, avg batch time: 6.3493, average train loss: 1.4863
[11/23 04:44:10 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.5881, average loss: 1.4553
[11/23 04:44:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/23 04:44:10 visual_prompt]: Training 2 / 100 epoch, with learning rate 5.0
[11/23 04:51:34 visual_prompt]: Epoch 2 / 100: avg data time: 4.88e+00, avg batch time: 6.3287, average train loss: 18.7267
[11/23 04:52:24 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.5855, average loss: 23.8607
[11/23 04:52:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.63	
[11/23 04:52:24 visual_prompt]: Training 3 / 100 epoch, with learning rate 10.0
[11/23 04:59:45 visual_prompt]: Epoch 3 / 100: avg data time: 4.85e+00, avg batch time: 6.3005, average train loss: 27.0763
[11/23 05:00:36 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.5895, average loss: 39.5016
[11/23 05:00:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.12	
[11/23 05:00:36 visual_prompt]: Training 4 / 100 epoch, with learning rate 15.0
[11/23 05:07:59 visual_prompt]: Epoch 4 / 100: avg data time: 4.88e+00, avg batch time: 6.3227, average train loss: 57.2564
[11/23 05:08:49 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.5890, average loss: 68.3047
[11/23 05:08:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.11	
[11/23 05:08:49 visual_prompt]: Training 5 / 100 epoch, with learning rate 20.0
[11/23 05:16:12 visual_prompt]: Epoch 5 / 100: avg data time: 4.88e+00, avg batch time: 6.3233, average train loss: 41.7823
[11/23 05:17:03 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.5889, average loss: 11.4361
[11/23 05:17:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.89	
[11/23 05:17:03 visual_prompt]: Training 6 / 100 epoch, with learning rate 25.0
[11/23 05:24:26 visual_prompt]: Epoch 6 / 100: avg data time: 4.90e+00, avg batch time: 6.3390, average train loss: 46.3878
[11/23 05:25:17 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.5858, average loss: 47.0229
[11/23 05:25:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.44	
[11/23 05:25:17 visual_prompt]: Training 7 / 100 epoch, with learning rate 30.0
[11/23 05:32:38 visual_prompt]: Epoch 7 / 100: avg data time: 4.86e+00, avg batch time: 6.2988, average train loss: 49.5998
[11/23 05:33:28 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.5855, average loss: 149.5717
[11/23 05:33:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.98	
[11/23 05:33:28 visual_prompt]: Training 8 / 100 epoch, with learning rate 35.0
[11/23 05:40:51 visual_prompt]: Epoch 8 / 100: avg data time: 4.88e+00, avg batch time: 6.3212, average train loss: 78.7175
[11/23 05:41:42 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.5863, average loss: 57.6138
[11/23 05:41:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.23	
[11/23 05:41:42 visual_prompt]: Training 9 / 100 epoch, with learning rate 40.0
[11/23 05:49:06 visual_prompt]: Epoch 9 / 100: avg data time: 4.90e+00, avg batch time: 6.3403, average train loss: 46.2650
[11/23 05:49:56 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.5863, average loss: 84.5307
[11/23 05:49:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.37	
[11/23 05:49:56 visual_prompt]: Training 10 / 100 epoch, with learning rate 45.0
[11/23 05:57:21 visual_prompt]: Epoch 10 / 100: avg data time: 4.90e+00, avg batch time: 6.3546, average train loss: 92.3278
[11/23 05:58:12 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.5863, average loss: 27.6195
[11/23 05:58:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.81	
[11/23 05:58:12 visual_prompt]: Training 11 / 100 epoch, with learning rate 50.0
[11/23 06:05:36 visual_prompt]: Epoch 11 / 100: avg data time: 4.90e+00, avg batch time: 6.3397, average train loss: 122.7208
[11/23 06:06:27 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.5852, average loss: 6.6309
[11/23 06:06:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.26	
[11/23 06:06:27 visual_prompt]: Training 12 / 100 epoch, with learning rate 49.9847706754774
[11/23 06:13:47 visual_prompt]: Epoch 12 / 100: avg data time: 4.84e+00, avg batch time: 6.2844, average train loss: 94.4580
[11/23 06:14:38 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.5854, average loss: 44.9683
[11/23 06:14:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.02	
[11/23 06:14:38 visual_prompt]: Training 13 / 100 epoch, with learning rate 49.939101256495604
[11/23 06:22:01 visual_prompt]: Epoch 13 / 100: avg data time: 4.90e+00, avg batch time: 6.3324, average train loss: 119.3497
[11/23 06:22:51 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.5867, average loss: 8.7367
[11/23 06:22:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.11	
[11/23 06:22:51 visual_prompt]: Training 14 / 100 epoch, with learning rate 49.86304738420683
[11/23 06:30:13 visual_prompt]: Epoch 14 / 100: avg data time: 4.86e+00, avg batch time: 6.3018, average train loss: 87.4063
[11/23 06:31:04 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.5861, average loss: 76.1077
[11/23 06:31:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.35	
[11/23 06:31:04 visual_prompt]: Training 15 / 100 epoch, with learning rate 49.75670171853926
[11/23 06:38:26 visual_prompt]: Epoch 15 / 100: avg data time: 4.87e+00, avg batch time: 6.3200, average train loss: 51.3531
[11/23 06:39:16 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.5845, average loss: 67.2423
[11/23 06:39:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.65	
[11/23 06:39:16 visual_prompt]: Training 16 / 100 epoch, with learning rate 49.6201938253052
[11/23 06:46:38 visual_prompt]: Epoch 16 / 100: avg data time: 4.86e+00, avg batch time: 6.3050, average train loss: 78.9950
[11/23 06:47:28 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.5886, average loss: 27.0773
[11/23 06:47:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.69	
[11/23 06:47:28 visual_prompt]: Training 17 / 100 epoch, with learning rate 49.45369001834514
[11/23 06:54:50 visual_prompt]: Epoch 17 / 100: avg data time: 4.86e+00, avg batch time: 6.3046, average train loss: 26.5004
[11/23 06:55:40 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.5877, average loss: 108.9821
[11/23 06:55:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.59	
[11/23 06:55:40 visual_prompt]: Training 18 / 100 epoch, with learning rate 49.25739315689991
[11/23 07:03:01 visual_prompt]: Epoch 18 / 100: avg data time: 4.85e+00, avg batch time: 6.2908, average train loss: 62.2150
[11/23 07:03:51 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.5868, average loss: 8.0574
[11/23 07:03:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.43	
[11/23 07:03:51 visual_prompt]: Training 19 / 100 epoch, with learning rate 49.03154239845797
[11/23 07:11:13 visual_prompt]: Epoch 19 / 100: avg data time: 4.87e+00, avg batch time: 6.3103, average train loss: 66.2149
[11/23 07:12:04 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.5853, average loss: 3.2948
[11/23 07:12:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.62	
[11/23 07:12:04 visual_prompt]: Best epoch 19: best metric: -3.295
[11/23 07:12:04 visual_prompt]: Training 20 / 100 epoch, with learning rate 48.77641290737884
[11/23 07:19:28 visual_prompt]: Epoch 20 / 100: avg data time: 4.90e+00, avg batch time: 6.3408, average train loss: 44.9275
[11/23 07:20:18 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.5896, average loss: 16.6158
[11/23 07:20:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.74	
[11/23 07:20:18 visual_prompt]: Training 21 / 100 epoch, with learning rate 48.49231551964771
[11/23 07:27:40 visual_prompt]: Epoch 21 / 100: avg data time: 4.87e+00, avg batch time: 6.3091, average train loss: 64.0591
[11/23 07:28:31 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.5878, average loss: 24.9053
[11/23 07:28:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.12	
[11/23 07:28:31 visual_prompt]: Training 22 / 100 epoch, with learning rate 48.17959636416968
[11/23 07:35:52 visual_prompt]: Epoch 22 / 100: avg data time: 4.87e+00, avg batch time: 6.3052, average train loss: 47.1782
[11/23 07:36:43 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.5855, average loss: 70.3440
[11/23 07:36:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.75	
[11/23 07:36:43 visual_prompt]: Training 23 / 100 epoch, with learning rate 47.83863644106502
[11/23 07:44:06 visual_prompt]: Epoch 23 / 100: avg data time: 4.88e+00, avg batch time: 6.3253, average train loss: 37.2159
[11/23 07:44:56 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.5863, average loss: 12.5568
[11/23 07:44:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.42	
[11/23 07:44:56 visual_prompt]: Training 24 / 100 epoch, with learning rate 47.46985115747918
[11/23 07:52:18 visual_prompt]: Epoch 24 / 100: avg data time: 4.86e+00, avg batch time: 6.3077, average train loss: 41.6032
[11/23 07:53:08 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.5862, average loss: 8.8968
[11/23 07:53:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.66	
[11/23 07:53:08 visual_prompt]: Training 25 / 100 epoch, with learning rate 47.073689821473174
[11/23 08:00:30 visual_prompt]: Epoch 25 / 100: avg data time: 4.87e+00, avg batch time: 6.3134, average train loss: 51.7500
[11/23 08:01:21 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.5934, average loss: 13.4114
[11/23 08:01:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.85	
[11/23 08:01:21 visual_prompt]: Training 26 / 100 epoch, with learning rate 46.65063509461097
[11/23 08:08:43 visual_prompt]: Epoch 26 / 100: avg data time: 4.86e+00, avg batch time: 6.3186, average train loss: 25.6396
[11/23 08:09:34 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.5897, average loss: 36.6733
[11/23 08:09:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 61.39	
[11/23 08:09:34 visual_prompt]: Training 27 / 100 epoch, with learning rate 46.20120240391065
[11/23 08:16:55 visual_prompt]: Epoch 27 / 100: avg data time: 4.85e+00, avg batch time: 6.2960, average train loss: 38.7008
[11/23 08:17:45 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.5849, average loss: 56.9118
[11/23 08:17:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.70	
[11/23 08:17:45 visual_prompt]: Training 28 / 100 epoch, with learning rate 45.72593931387604
[11/23 08:25:07 visual_prompt]: Epoch 28 / 100: avg data time: 4.87e+00, avg batch time: 6.3142, average train loss: 57.5679
[11/23 08:25:58 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.5842, average loss: 22.7835
[11/23 08:25:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.64	
[11/23 08:25:58 visual_prompt]: Training 29 / 100 epoch, with learning rate 45.22542485937369
[11/23 08:33:19 visual_prompt]: Epoch 29 / 100: avg data time: 4.86e+00, avg batch time: 6.2981, average train loss: 59.0418
[11/23 08:34:10 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.5865, average loss: 72.1700
[11/23 08:34:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.84	
[11/23 08:34:10 visual_prompt]: Training 30 / 100 epoch, with learning rate 44.70026884016804
[11/23 08:41:33 visual_prompt]: Epoch 30 / 100: avg data time: 4.89e+00, avg batch time: 6.3375, average train loss: 39.6449
[11/23 08:42:24 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.5877, average loss: 62.3798
[11/23 08:42:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.16	
[11/23 08:42:24 visual_prompt]: Training 31 / 100 epoch, with learning rate 44.15111107797445
[11/23 08:49:46 visual_prompt]: Epoch 31 / 100: avg data time: 4.86e+00, avg batch time: 6.3088, average train loss: 42.6935
[11/23 08:50:36 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.5871, average loss: 4.9063
[11/23 08:50:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.53	rocauc: 62.99	
[11/23 08:50:36 visual_prompt]: Training 32 / 100 epoch, with learning rate 43.57862063693486
[11/23 08:58:00 visual_prompt]: Epoch 32 / 100: avg data time: 4.90e+00, avg batch time: 6.3392, average train loss: 45.2211
[11/23 08:58:51 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.5874, average loss: 5.5182
[11/23 08:58:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.52	
[11/23 08:58:51 visual_prompt]: Training 33 / 100 epoch, with learning rate 42.98349500846628
[11/23 09:06:14 visual_prompt]: Epoch 33 / 100: avg data time: 4.88e+00, avg batch time: 6.3240, average train loss: 38.1421
[11/23 09:07:04 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.5857, average loss: 12.0966
[11/23 09:07:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 62.22	
[11/23 09:07:04 visual_prompt]: Training 34 / 100 epoch, with learning rate 42.36645926147493
[11/23 09:14:27 visual_prompt]: Epoch 34 / 100: avg data time: 4.88e+00, avg batch time: 6.3215, average train loss: 30.9063
[11/23 09:15:18 visual_prompt]: Inference (val):avg data time: 3.41e-05, avg batch time: 0.5904, average loss: 78.9922
[11/23 09:15:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.14	
[11/23 09:15:18 visual_prompt]: Training 35 / 100 epoch, with learning rate 41.72826515897145
[11/23 09:22:40 visual_prompt]: Epoch 35 / 100: avg data time: 4.88e+00, avg batch time: 6.3180, average train loss: 60.9830
[11/23 09:23:31 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.5867, average loss: 58.7923
[11/23 09:23:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 61.56	
[11/23 09:23:31 visual_prompt]: Training 36 / 100 epoch, with learning rate 41.06969024216348
[11/23 09:30:57 visual_prompt]: Epoch 36 / 100: avg data time: 4.92e+00, avg batch time: 6.3694, average train loss: 29.7691
[11/23 09:31:48 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.5858, average loss: 104.6510
[11/23 09:31:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 63.43	
[11/23 09:31:48 visual_prompt]: Training 37 / 100 epoch, with learning rate 40.391536883141455
[11/23 09:39:12 visual_prompt]: Epoch 37 / 100: avg data time: 4.90e+00, avg batch time: 6.3454, average train loss: 37.3983
[11/23 09:40:03 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.5859, average loss: 4.5521
[11/23 09:40:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 64.06	
[11/23 09:40:03 visual_prompt]: Training 38 / 100 epoch, with learning rate 39.69463130731183
[11/23 09:47:25 visual_prompt]: Epoch 38 / 100: avg data time: 4.87e+00, avg batch time: 6.3105, average train loss: 34.9036
[11/23 09:48:15 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.5849, average loss: 17.1098
[11/23 09:48:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 65.11	
[11/23 09:48:15 visual_prompt]: Training 39 / 100 epoch, with learning rate 38.97982258676867
[11/23 09:55:35 visual_prompt]: Epoch 39 / 100: avg data time: 4.85e+00, avg batch time: 6.2871, average train loss: 34.7068
[11/23 09:56:26 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.5847, average loss: 40.0117
[11/23 09:56:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 62.64	
[11/23 09:56:26 visual_prompt]: Training 40 / 100 epoch, with learning rate 38.24798160583012
[11/23 10:03:48 visual_prompt]: Epoch 40 / 100: avg data time: 4.86e+00, avg batch time: 6.3053, average train loss: 34.7645
[11/23 10:04:38 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.5895, average loss: 82.7537
[11/23 10:04:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 63.60	
[11/23 10:04:38 visual_prompt]: Stopping early.
[11/23 10:04:38 visual_prompt]: Rank of current process: 0. World size: 1
[11/23 10:04:38 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/23 10:04:38 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/23 10:04:38 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/23 10:04:38 visual_prompt]: Training with config:
[11/23 10:04:38 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr25.0_wd0.01/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 25.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/23 10:04:38 visual_prompt]: Loading training data...
[11/23 10:04:38 visual_prompt]: Constructing mammo-cbis dataset train...
[11/23 10:04:38 visual_prompt]: Loading validation data...
[11/23 10:04:38 visual_prompt]: Constructing mammo-cbis dataset val...
[11/23 10:04:38 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/23 10:04:41 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/23 10:04:41 visual_prompt]: tuned percent:0.532
[11/23 10:04:41 visual_prompt]: Device used for model: 0
[11/23 10:04:41 visual_prompt]: Setting up Evaluator...
[11/23 10:04:41 visual_prompt]: Setting up Trainer...
[11/23 10:04:41 visual_prompt]: 	Setting up the optimizer...
[11/23 10:04:41 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/23 10:12:04 visual_prompt]: Epoch 1 / 100: avg data time: 4.88e+00, avg batch time: 6.3336, average train loss: 1.4863
[11/23 10:12:55 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.5855, average loss: 1.4553
[11/23 10:12:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/23 10:12:55 visual_prompt]: Training 2 / 100 epoch, with learning rate 2.5
[11/23 10:20:18 visual_prompt]: Epoch 2 / 100: avg data time: 4.86e+00, avg batch time: 6.3193, average train loss: 9.2644
[11/23 10:21:08 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.5859, average loss: 7.2979
[11/23 10:21:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 42.57	
[11/23 10:21:08 visual_prompt]: Training 3 / 100 epoch, with learning rate 5.0
[11/23 10:28:33 visual_prompt]: Epoch 3 / 100: avg data time: 4.90e+00, avg batch time: 6.3532, average train loss: 11.8082
[11/23 10:29:24 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.5892, average loss: 17.2598
[11/23 10:29:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.68	
[11/23 10:29:24 visual_prompt]: Training 4 / 100 epoch, with learning rate 7.5
[11/23 10:36:46 visual_prompt]: Epoch 4 / 100: avg data time: 4.86e+00, avg batch time: 6.3140, average train loss: 15.7340
[11/23 10:37:36 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.5923, average loss: 6.6949
[11/23 10:37:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.09	
[11/23 10:37:36 visual_prompt]: Training 5 / 100 epoch, with learning rate 10.0
[11/23 10:44:57 visual_prompt]: Epoch 5 / 100: avg data time: 4.84e+00, avg batch time: 6.2905, average train loss: 21.7801
[11/23 10:45:47 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.5873, average loss: 60.4453
[11/23 10:45:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.72	
[11/23 10:45:47 visual_prompt]: Training 6 / 100 epoch, with learning rate 12.5
[11/23 10:53:12 visual_prompt]: Epoch 6 / 100: avg data time: 4.90e+00, avg batch time: 6.3488, average train loss: 39.3944
[11/23 10:54:03 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.5904, average loss: 56.8249
[11/23 10:54:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 39.45	
[11/23 10:54:03 visual_prompt]: Training 7 / 100 epoch, with learning rate 15.0
[11/23 11:01:23 visual_prompt]: Epoch 7 / 100: avg data time: 4.85e+00, avg batch time: 6.2959, average train loss: 41.5170
[11/23 11:02:15 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.5890, average loss: 13.9227
[11/23 11:02:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.53	
[11/23 11:02:15 visual_prompt]: Training 8 / 100 epoch, with learning rate 17.5
[11/23 11:09:37 visual_prompt]: Epoch 8 / 100: avg data time: 4.87e+00, avg batch time: 6.3176, average train loss: 50.4916
[11/23 11:10:28 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.5900, average loss: 110.5232
[11/23 11:10:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.89	
[11/23 11:10:28 visual_prompt]: Training 9 / 100 epoch, with learning rate 20.0
[11/23 11:17:51 visual_prompt]: Epoch 9 / 100: avg data time: 4.89e+00, avg batch time: 6.3323, average train loss: 91.9525
[11/23 11:18:42 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.5864, average loss: 244.2756
[11/23 11:18:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.05	
[11/23 11:18:42 visual_prompt]: Training 10 / 100 epoch, with learning rate 22.5
[11/23 11:26:04 visual_prompt]: Epoch 10 / 100: avg data time: 4.86e+00, avg batch time: 6.3073, average train loss: 66.3340
[11/23 11:26:55 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.5831, average loss: 11.5450
[11/23 11:26:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.45	
[11/23 11:26:55 visual_prompt]: Training 11 / 100 epoch, with learning rate 25.0
[11/23 11:34:20 visual_prompt]: Epoch 11 / 100: avg data time: 4.91e+00, avg batch time: 6.3598, average train loss: 61.0317
[11/23 11:35:11 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.5898, average loss: 7.7466
[11/23 11:35:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.03	
[11/23 11:35:11 visual_prompt]: Training 12 / 100 epoch, with learning rate 24.9923853377387
[11/23 11:42:33 visual_prompt]: Epoch 12 / 100: avg data time: 4.86e+00, avg batch time: 6.3098, average train loss: 77.4658
[11/23 11:43:23 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.5889, average loss: 20.5838
[11/23 11:43:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.51	
[11/23 11:43:23 visual_prompt]: Training 13 / 100 epoch, with learning rate 24.969550628247802
[11/23 11:50:47 visual_prompt]: Epoch 13 / 100: avg data time: 4.89e+00, avg batch time: 6.3346, average train loss: 50.8149
[11/23 11:51:38 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.5881, average loss: 98.8989
[11/23 11:51:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.48	
[11/23 11:51:38 visual_prompt]: Training 14 / 100 epoch, with learning rate 24.931523692103415
[11/23 11:59:01 visual_prompt]: Epoch 14 / 100: avg data time: 4.88e+00, avg batch time: 6.3292, average train loss: 51.6674
[11/23 11:59:51 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.5871, average loss: 40.5529
[11/23 11:59:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 41.67	
[11/23 11:59:51 visual_prompt]: Training 15 / 100 epoch, with learning rate 24.87835085926963
[11/23 12:07:13 visual_prompt]: Epoch 15 / 100: avg data time: 4.86e+00, avg batch time: 6.3055, average train loss: 61.2310
[11/23 12:08:04 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.5890, average loss: 74.9735
[11/23 12:08:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.50	
[11/23 12:08:04 visual_prompt]: Training 16 / 100 epoch, with learning rate 24.8100969126526
[11/23 12:15:27 visual_prompt]: Epoch 16 / 100: avg data time: 4.89e+00, avg batch time: 6.3319, average train loss: 60.7043
[11/23 12:16:18 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.5850, average loss: 313.0779
[11/23 12:16:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.15	
[11/23 12:16:18 visual_prompt]: Training 17 / 100 epoch, with learning rate 24.72684500917257
[11/23 12:23:43 visual_prompt]: Epoch 17 / 100: avg data time: 4.91e+00, avg batch time: 6.3511, average train loss: 84.5412
[11/23 12:24:34 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.5883, average loss: 128.9083
[11/23 12:24:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 44.84	
[11/23 12:24:34 visual_prompt]: Training 18 / 100 epoch, with learning rate 24.628696578449954
[11/23 12:31:52 visual_prompt]: Epoch 18 / 100: avg data time: 4.82e+00, avg batch time: 6.2647, average train loss: 93.7010
[11/23 12:32:40 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.5881, average loss: 6.8398
[11/23 12:32:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.52	
[11/23 12:32:40 visual_prompt]: Best epoch 18: best metric: -6.840
[11/23 12:32:40 visual_prompt]: Training 19 / 100 epoch, with learning rate 24.515771199228986
[11/23 12:39:40 visual_prompt]: Epoch 19 / 100: avg data time: 4.56e+00, avg batch time: 5.9991, average train loss: 89.5964
[11/23 12:40:28 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.5881, average loss: 131.6036
[11/23 12:40:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.03	
[11/23 12:40:28 visual_prompt]: Training 20 / 100 epoch, with learning rate 24.38820645368942
[11/23 12:47:32 visual_prompt]: Epoch 20 / 100: avg data time: 4.62e+00, avg batch time: 6.0594, average train loss: 82.3185
[11/23 12:48:21 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.5861, average loss: 84.5250
[11/23 12:48:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 44.58	
[11/23 12:48:21 visual_prompt]: Training 21 / 100 epoch, with learning rate 24.246157759823856
[11/23 12:55:25 visual_prompt]: Epoch 21 / 100: avg data time: 4.62e+00, avg batch time: 6.0577, average train loss: 56.3152
[11/23 12:56:14 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.5850, average loss: 123.3887
[11/23 12:56:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.70	
[11/23 12:56:14 visual_prompt]: Training 22 / 100 epoch, with learning rate 24.08979818208484
[11/23 13:03:17 visual_prompt]: Epoch 22 / 100: avg data time: 4.60e+00, avg batch time: 6.0477, average train loss: 68.6338
[11/23 13:04:05 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.5905, average loss: 12.9044
[11/23 13:04:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 45.65	
[11/23 13:04:05 visual_prompt]: Training 23 / 100 epoch, with learning rate 23.91931822053251
[11/23 13:11:10 visual_prompt]: Epoch 23 / 100: avg data time: 4.62e+00, avg batch time: 6.0643, average train loss: 76.1778
[11/23 13:11:59 visual_prompt]: Inference (val):avg data time: 1.89e-05, avg batch time: 0.5864, average loss: 38.9189
[11/23 13:11:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 39.68	
[11/23 13:11:59 visual_prompt]: Training 24 / 100 epoch, with learning rate 23.73492557873959
[11/23 13:19:00 visual_prompt]: Epoch 24 / 100: avg data time: 4.57e+00, avg batch time: 6.0171, average train loss: 59.8707
[11/23 13:19:48 visual_prompt]: Inference (val):avg data time: 1.97e-05, avg batch time: 0.5875, average loss: 110.5927
[11/23 13:19:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.18	
[11/23 13:19:48 visual_prompt]: Training 25 / 100 epoch, with learning rate 23.536844910736587
[11/23 13:26:48 visual_prompt]: Epoch 25 / 100: avg data time: 4.56e+00, avg batch time: 5.9991, average train loss: 60.0324
[11/23 13:27:36 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.5871, average loss: 97.2395
[11/23 13:27:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.80	
[11/23 13:27:36 visual_prompt]: Training 26 / 100 epoch, with learning rate 23.325317547305485
[11/23 13:34:35 visual_prompt]: Epoch 26 / 100: avg data time: 4.54e+00, avg batch time: 5.9847, average train loss: 68.9984
[11/23 13:35:23 visual_prompt]: Inference (val):avg data time: 1.96e-05, avg batch time: 0.5907, average loss: 58.5007
[11/23 13:35:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.79	
[11/23 13:35:23 visual_prompt]: Training 27 / 100 epoch, with learning rate 23.100601201955325
[11/23 13:42:21 visual_prompt]: Epoch 27 / 100: avg data time: 4.53e+00, avg batch time: 5.9786, average train loss: 50.0887
[11/23 13:43:09 visual_prompt]: Inference (val):avg data time: 2.02e-05, avg batch time: 0.5860, average loss: 45.2765
[11/23 13:43:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.22	
[11/23 13:43:09 visual_prompt]: Training 28 / 100 epoch, with learning rate 22.86296965693802
[11/23 13:50:10 visual_prompt]: Epoch 28 / 100: avg data time: 4.56e+00, avg batch time: 6.0033, average train loss: 58.0203
[11/23 13:50:58 visual_prompt]: Inference (val):avg data time: 1.96e-05, avg batch time: 0.5854, average loss: 31.2717
[11/23 13:50:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.51	
[11/23 13:50:58 visual_prompt]: Training 29 / 100 epoch, with learning rate 22.612712429686844
[11/23 13:57:58 visual_prompt]: Epoch 29 / 100: avg data time: 4.56e+00, avg batch time: 6.0003, average train loss: 54.2602
[11/23 13:58:46 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.5856, average loss: 80.8989
[11/23 13:58:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.75	
[11/23 13:58:46 visual_prompt]: Training 30 / 100 epoch, with learning rate 22.35013442008402
[11/23 14:05:46 visual_prompt]: Epoch 30 / 100: avg data time: 4.56e+00, avg batch time: 5.9979, average train loss: 69.7901
[11/23 14:06:34 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.5892, average loss: 20.1720
[11/23 14:06:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.60	
[11/23 14:06:34 visual_prompt]: Training 31 / 100 epoch, with learning rate 22.075555538987224
[11/23 14:13:32 visual_prompt]: Epoch 31 / 100: avg data time: 4.52e+00, avg batch time: 5.9667, average train loss: 74.0750
[11/23 14:14:20 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.5872, average loss: 49.9190
[11/23 14:14:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.88	
[11/23 14:14:20 visual_prompt]: Training 32 / 100 epoch, with learning rate 21.78931031846743
[11/23 14:21:22 visual_prompt]: Epoch 32 / 100: avg data time: 4.59e+00, avg batch time: 6.0368, average train loss: 58.6641
[11/23 14:22:12 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.5887, average loss: 106.6819
[11/23 14:22:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.30	
[11/23 14:22:12 visual_prompt]: Training 33 / 100 epoch, with learning rate 21.49174750423314
[11/23 14:29:15 visual_prompt]: Epoch 33 / 100: avg data time: 4.61e+00, avg batch time: 6.0509, average train loss: 65.8152
[11/23 14:30:04 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.5921, average loss: 101.9799
[11/23 14:30:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.07	
[11/23 14:30:04 visual_prompt]: Training 34 / 100 epoch, with learning rate 21.183229630737465
[11/23 14:37:06 visual_prompt]: Epoch 34 / 100: avg data time: 4.59e+00, avg batch time: 6.0364, average train loss: 56.5285
[11/23 14:37:55 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.5866, average loss: 107.5842
[11/23 14:37:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.50	
[11/23 14:37:55 visual_prompt]: Training 35 / 100 epoch, with learning rate 20.864132579485727
[11/23 14:44:57 visual_prompt]: Epoch 35 / 100: avg data time: 4.59e+00, avg batch time: 6.0353, average train loss: 62.9725
[11/23 14:45:46 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.5905, average loss: 114.0355
[11/23 14:45:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.38	
[11/23 14:45:46 visual_prompt]: Training 36 / 100 epoch, with learning rate 20.53484512108174
[11/23 14:52:54 visual_prompt]: Epoch 36 / 100: avg data time: 4.67e+00, avg batch time: 6.1086, average train loss: 55.8987
[11/23 14:53:42 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.5857, average loss: 15.4660
[11/23 14:53:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.09	
[11/23 14:53:42 visual_prompt]: Training 37 / 100 epoch, with learning rate 20.195768441570728
[11/23 15:00:48 visual_prompt]: Epoch 37 / 100: avg data time: 4.64e+00, avg batch time: 6.0786, average train loss: 60.1558
[11/23 15:01:36 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.5904, average loss: 31.3375
[11/23 15:01:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.44	
[11/23 15:01:36 visual_prompt]: Training 38 / 100 epoch, with learning rate 19.847315653655915
[11/23 15:08:40 visual_prompt]: Epoch 38 / 100: avg data time: 4.61e+00, avg batch time: 6.0511, average train loss: 57.1590
[11/23 15:09:28 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.5898, average loss: 7.1590
[11/23 15:09:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.42	
[11/23 15:09:28 visual_prompt]: Training 39 / 100 epoch, with learning rate 19.489911293384335
[11/23 15:16:32 visual_prompt]: Epoch 39 / 100: avg data time: 4.60e+00, avg batch time: 6.0440, average train loss: 56.6910
[11/23 15:17:20 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.5906, average loss: 77.3994
[11/23 15:17:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.80	
[11/23 15:17:20 visual_prompt]: Stopping early.
[11/23 15:17:20 visual_prompt]: Rank of current process: 0. World size: 1
[11/23 15:17:20 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/23 15:17:20 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/23 15:17:20 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/23 15:17:20 visual_prompt]: Training with config:
[11/23 15:17:20 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr25.0_wd0.001/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 25.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/23 15:17:20 visual_prompt]: Loading training data...
[11/23 15:17:20 visual_prompt]: Constructing mammo-cbis dataset train...
[11/23 15:17:20 visual_prompt]: Loading validation data...
[11/23 15:17:20 visual_prompt]: Constructing mammo-cbis dataset val...
[11/23 15:17:20 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/23 15:17:23 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/23 15:17:23 visual_prompt]: tuned percent:0.532
[11/23 15:17:23 visual_prompt]: Device used for model: 0
[11/23 15:17:23 visual_prompt]: Setting up Evaluator...
[11/23 15:17:23 visual_prompt]: Setting up Trainer...
[11/23 15:17:23 visual_prompt]: 	Setting up the optimizer...
[11/23 15:17:23 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/23 15:24:27 visual_prompt]: Epoch 1 / 100: avg data time: 4.60e+00, avg batch time: 6.0506, average train loss: 1.4863
[11/23 15:25:15 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.5852, average loss: 1.4553
[11/23 15:25:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/23 15:25:15 visual_prompt]: Training 2 / 100 epoch, with learning rate 2.5
[11/23 15:32:18 visual_prompt]: Epoch 2 / 100: avg data time: 4.60e+00, avg batch time: 6.0482, average train loss: 8.2590
[11/23 15:33:07 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.5848, average loss: 6.5246
[11/23 15:33:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.04	
[11/23 15:33:07 visual_prompt]: Training 3 / 100 epoch, with learning rate 5.0
[11/23 15:40:10 visual_prompt]: Epoch 3 / 100: avg data time: 4.59e+00, avg batch time: 6.0405, average train loss: 12.8542
[11/23 15:40:58 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.5863, average loss: 43.0126
[11/23 15:40:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.14	
[11/23 15:40:58 visual_prompt]: Training 4 / 100 epoch, with learning rate 7.5
[11/23 15:48:00 visual_prompt]: Epoch 4 / 100: avg data time: 4.58e+00, avg batch time: 6.0314, average train loss: 24.3482
[11/23 15:48:49 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.5870, average loss: 38.9421
[11/23 15:48:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.34	
[11/23 15:48:49 visual_prompt]: Training 5 / 100 epoch, with learning rate 10.0
[11/23 15:55:51 visual_prompt]: Epoch 5 / 100: avg data time: 4.58e+00, avg batch time: 6.0329, average train loss: 16.7612
[11/23 15:56:39 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.5847, average loss: 34.1162
[11/23 15:56:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.36	
[11/23 15:56:39 visual_prompt]: Training 6 / 100 epoch, with learning rate 12.5
[11/23 16:03:43 visual_prompt]: Epoch 6 / 100: avg data time: 4.61e+00, avg batch time: 6.0570, average train loss: 32.9153
[11/23 16:04:32 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.5896, average loss: 33.9918
[11/23 16:04:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.23	
[11/23 16:04:32 visual_prompt]: Training 7 / 100 epoch, with learning rate 15.0
[11/23 16:11:30 visual_prompt]: Epoch 7 / 100: avg data time: 4.53e+00, avg batch time: 5.9807, average train loss: 42.2689
[11/23 16:12:19 visual_prompt]: Inference (val):avg data time: 2.08e-05, avg batch time: 0.5853, average loss: 10.0477
[11/23 16:12:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.37	
[11/23 16:12:19 visual_prompt]: Training 8 / 100 epoch, with learning rate 17.5
[11/23 16:19:21 visual_prompt]: Epoch 8 / 100: avg data time: 4.58e+00, avg batch time: 6.0242, average train loss: 44.8138
[11/23 16:20:08 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.5905, average loss: 11.9901
[11/23 16:20:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.26	
[11/23 16:20:08 visual_prompt]: Training 9 / 100 epoch, with learning rate 20.0
[11/23 16:27:07 visual_prompt]: Epoch 9 / 100: avg data time: 4.53e+00, avg batch time: 5.9814, average train loss: 47.6991
[11/23 16:27:55 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.5848, average loss: 26.2309
[11/23 16:27:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.40	
[11/23 16:27:55 visual_prompt]: Training 10 / 100 epoch, with learning rate 22.5
[11/23 16:34:53 visual_prompt]: Epoch 10 / 100: avg data time: 4.53e+00, avg batch time: 5.9731, average train loss: 45.2072
[11/23 16:35:41 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.5913, average loss: 32.8155
[11/23 16:35:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 45.87	
[11/23 16:35:41 visual_prompt]: Training 11 / 100 epoch, with learning rate 25.0
[11/23 16:42:40 visual_prompt]: Epoch 11 / 100: avg data time: 4.54e+00, avg batch time: 5.9857, average train loss: 55.8975
[11/23 16:43:28 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.5906, average loss: 97.0035
[11/23 16:43:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.36	
[11/23 16:43:28 visual_prompt]: Training 12 / 100 epoch, with learning rate 24.9923853377387
[11/23 16:50:26 visual_prompt]: Epoch 12 / 100: avg data time: 4.53e+00, avg batch time: 5.9727, average train loss: 73.6140
[11/23 16:51:14 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.5879, average loss: 46.6619
[11/23 16:51:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.40	
[11/23 16:51:14 visual_prompt]: Best epoch 12: best metric: -46.662
[11/23 16:51:14 visual_prompt]: Training 13 / 100 epoch, with learning rate 24.969550628247802
[11/23 16:58:13 visual_prompt]: Epoch 13 / 100: avg data time: 4.54e+00, avg batch time: 5.9783, average train loss: 73.8447
[11/23 16:59:01 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.5902, average loss: 36.8033
[11/23 16:59:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.25	
[11/23 16:59:01 visual_prompt]: Best epoch 13: best metric: -36.803
[11/23 16:59:01 visual_prompt]: Training 14 / 100 epoch, with learning rate 24.931523692103415
[11/23 17:06:33 visual_prompt]: Epoch 14 / 100: avg data time: 5.01e+00, avg batch time: 6.4498, average train loss: 66.3276
[11/23 17:07:24 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.5883, average loss: 40.3746
[11/23 17:07:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.99	
[11/23 17:07:24 visual_prompt]: Training 15 / 100 epoch, with learning rate 24.87835085926963
[11/23 17:14:56 visual_prompt]: Epoch 15 / 100: avg data time: 5.00e+00, avg batch time: 6.4452, average train loss: 44.0138
[11/23 17:15:47 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.5862, average loss: 62.5143
[11/23 17:15:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.06	
[11/23 17:15:47 visual_prompt]: Training 16 / 100 epoch, with learning rate 24.8100969126526
[11/23 17:23:20 visual_prompt]: Epoch 16 / 100: avg data time: 5.02e+00, avg batch time: 6.4639, average train loss: 60.8178
[11/23 17:24:12 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.5910, average loss: 78.9373
[11/23 17:24:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.80	
[11/23 17:24:12 visual_prompt]: Training 17 / 100 epoch, with learning rate 24.72684500917257
[11/23 17:31:45 visual_prompt]: Epoch 17 / 100: avg data time: 5.03e+00, avg batch time: 6.4753, average train loss: 70.1742
[11/23 17:32:37 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.5905, average loss: 47.0000
[11/23 17:32:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.10	
[11/23 17:32:37 visual_prompt]: Training 18 / 100 epoch, with learning rate 24.628696578449954
[11/23 17:40:10 visual_prompt]: Epoch 18 / 100: avg data time: 5.03e+00, avg batch time: 6.4778, average train loss: 72.0207
[11/23 17:41:02 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.5862, average loss: 180.6186
[11/23 17:41:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.03	
[11/23 17:41:02 visual_prompt]: Training 19 / 100 epoch, with learning rate 24.515771199228986
[11/23 17:48:39 visual_prompt]: Epoch 19 / 100: avg data time: 5.07e+00, avg batch time: 6.5194, average train loss: 52.7497
[11/23 17:49:31 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.5875, average loss: 10.9395
[11/23 17:49:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.11	
[11/23 17:49:31 visual_prompt]: Best epoch 19: best metric: -10.940
[11/23 17:49:31 visual_prompt]: Training 20 / 100 epoch, with learning rate 24.38820645368942
[11/23 17:57:04 visual_prompt]: Epoch 20 / 100: avg data time: 5.03e+00, avg batch time: 6.4759, average train loss: 66.2339
[11/23 17:57:56 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.5890, average loss: 68.7037
[11/23 17:57:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.45	
[11/23 17:57:56 visual_prompt]: Training 21 / 100 epoch, with learning rate 24.246157759823856
[11/23 18:05:31 visual_prompt]: Epoch 21 / 100: avg data time: 5.06e+00, avg batch time: 6.5022, average train loss: 41.2648
[11/23 18:06:23 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.5888, average loss: 22.5610
[11/23 18:06:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.42	
[11/23 18:06:23 visual_prompt]: Training 22 / 100 epoch, with learning rate 24.08979818208484
[11/23 18:13:56 visual_prompt]: Epoch 22 / 100: avg data time: 5.03e+00, avg batch time: 6.4749, average train loss: 62.9471
[11/23 18:14:48 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.5863, average loss: 22.4820
[11/23 18:14:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.27	
[11/23 18:14:48 visual_prompt]: Training 23 / 100 epoch, with learning rate 23.91931822053251
[11/23 18:22:24 visual_prompt]: Epoch 23 / 100: avg data time: 5.07e+00, avg batch time: 6.5118, average train loss: 43.8226
[11/23 18:23:16 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.5887, average loss: 2.9938
[11/23 18:23:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 52.44	rocauc: 50.62	
[11/23 18:23:16 visual_prompt]: Best epoch 23: best metric: -2.994
[11/23 18:23:16 visual_prompt]: Training 24 / 100 epoch, with learning rate 23.73492557873959
[11/23 18:30:49 visual_prompt]: Epoch 24 / 100: avg data time: 5.03e+00, avg batch time: 6.4778, average train loss: 53.3922
[11/23 18:31:41 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.5870, average loss: 58.7837
[11/23 18:31:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 44.56	
[11/23 18:31:41 visual_prompt]: Training 25 / 100 epoch, with learning rate 23.536844910736587
[11/23 18:39:16 visual_prompt]: Epoch 25 / 100: avg data time: 5.06e+00, avg batch time: 6.4998, average train loss: 55.7526
[11/23 18:40:08 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.5878, average loss: 81.7253
[11/23 18:40:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.51	
[11/23 18:40:08 visual_prompt]: Training 26 / 100 epoch, with learning rate 23.325317547305485
[11/23 18:47:40 visual_prompt]: Epoch 26 / 100: avg data time: 5.02e+00, avg batch time: 6.4666, average train loss: 55.7976
[11/23 18:48:32 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.5847, average loss: 21.4056
[11/23 18:48:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 42.68	
[11/23 18:48:32 visual_prompt]: Training 27 / 100 epoch, with learning rate 23.100601201955325
[11/23 18:56:04 visual_prompt]: Epoch 27 / 100: avg data time: 5.01e+00, avg batch time: 6.4542, average train loss: 34.8045
[11/23 18:56:56 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.5879, average loss: 27.6092
[11/23 18:56:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.66	
[11/23 18:56:56 visual_prompt]: Training 28 / 100 epoch, with learning rate 22.86296965693802
[11/23 19:04:30 visual_prompt]: Epoch 28 / 100: avg data time: 5.04e+00, avg batch time: 6.4825, average train loss: 44.9755
[11/23 19:05:22 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.5902, average loss: 1.4754
[11/23 19:05:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.14	
[11/23 19:05:22 visual_prompt]: Best epoch 28: best metric: -1.475
[11/23 19:05:22 visual_prompt]: Training 29 / 100 epoch, with learning rate 22.612712429686844
[11/23 19:12:55 visual_prompt]: Epoch 29 / 100: avg data time: 5.03e+00, avg batch time: 6.4787, average train loss: 44.0545
[11/23 19:13:47 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.5887, average loss: 260.0705
[11/23 19:13:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.09	
[11/23 19:13:47 visual_prompt]: Training 30 / 100 epoch, with learning rate 22.35013442008402
[11/23 19:21:21 visual_prompt]: Epoch 30 / 100: avg data time: 5.04e+00, avg batch time: 6.4826, average train loss: 63.1470
[11/23 19:22:13 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.5856, average loss: 24.1087
[11/23 19:22:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.04	
[11/23 19:22:13 visual_prompt]: Training 31 / 100 epoch, with learning rate 22.075555538987224
[11/23 19:29:44 visual_prompt]: Epoch 31 / 100: avg data time: 4.99e+00, avg batch time: 6.4396, average train loss: 37.0340
[11/23 19:30:35 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.5875, average loss: 11.5403
[11/23 19:30:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.37	
[11/23 19:30:35 visual_prompt]: Training 32 / 100 epoch, with learning rate 21.78931031846743
[11/23 19:38:07 visual_prompt]: Epoch 32 / 100: avg data time: 5.01e+00, avg batch time: 6.4496, average train loss: 44.4204
[11/23 19:38:58 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.5920, average loss: 109.9710
[11/23 19:38:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.73	
[11/23 19:38:58 visual_prompt]: Training 33 / 100 epoch, with learning rate 21.49174750423314
[11/23 19:46:29 visual_prompt]: Epoch 33 / 100: avg data time: 4.99e+00, avg batch time: 6.4344, average train loss: 53.9043
[11/23 19:47:21 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.5935, average loss: 58.6641
[11/23 19:47:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.13	
[11/23 19:47:21 visual_prompt]: Training 34 / 100 epoch, with learning rate 21.183229630737465
[11/23 19:54:49 visual_prompt]: Epoch 34 / 100: avg data time: 4.96e+00, avg batch time: 6.4046, average train loss: 46.9848
[11/23 19:55:40 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.5879, average loss: 76.9097
[11/23 19:55:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 45.49	
[11/23 19:55:40 visual_prompt]: Training 35 / 100 epoch, with learning rate 20.864132579485727
[11/23 20:03:08 visual_prompt]: Epoch 35 / 100: avg data time: 4.95e+00, avg batch time: 6.3936, average train loss: 44.3540
[11/23 20:03:59 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.5918, average loss: 27.6591
[11/23 20:03:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.30	
[11/23 20:03:59 visual_prompt]: Training 36 / 100 epoch, with learning rate 20.53484512108174
[11/23 20:11:28 visual_prompt]: Epoch 36 / 100: avg data time: 4.96e+00, avg batch time: 6.4055, average train loss: 48.0853
[11/23 20:12:19 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.5884, average loss: 40.0645
[11/23 20:12:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.56	
[11/23 20:12:19 visual_prompt]: Training 37 / 100 epoch, with learning rate 20.195768441570728
[11/23 20:19:46 visual_prompt]: Epoch 37 / 100: avg data time: 4.94e+00, avg batch time: 6.3875, average train loss: 41.3010
[11/23 20:20:37 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.5885, average loss: 6.3328
[11/23 20:20:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.50	
[11/23 20:20:37 visual_prompt]: Training 38 / 100 epoch, with learning rate 19.847315653655915
[11/23 20:28:05 visual_prompt]: Epoch 38 / 100: avg data time: 4.96e+00, avg batch time: 6.3977, average train loss: 41.6885
[11/23 20:28:56 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.5905, average loss: 65.0417
[11/23 20:28:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 43.63	
[11/23 20:28:56 visual_prompt]: Training 39 / 100 epoch, with learning rate 19.489911293384335
[11/23 20:36:23 visual_prompt]: Epoch 39 / 100: avg data time: 4.94e+00, avg batch time: 6.3854, average train loss: 44.3886
[11/23 20:37:15 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.5915, average loss: 6.3829
[11/23 20:37:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 47.97	rocauc: 47.31	
[11/23 20:37:15 visual_prompt]: Training 40 / 100 epoch, with learning rate 19.12399080291506
[11/23 20:44:43 visual_prompt]: Epoch 40 / 100: avg data time: 4.95e+00, avg batch time: 6.3994, average train loss: 35.7436
[11/23 20:45:34 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.5855, average loss: 45.0229
[11/23 20:45:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.61	
[11/23 20:45:34 visual_prompt]: Training 41 / 100 epoch, with learning rate 18.75
[11/23 20:53:03 visual_prompt]: Epoch 41 / 100: avg data time: 4.96e+00, avg batch time: 6.4074, average train loss: 63.7943
[11/23 20:53:54 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.5869, average loss: 27.7560
[11/23 20:53:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.47	rocauc: 51.02	
[11/23 20:53:54 visual_prompt]: Training 42 / 100 epoch, with learning rate 18.368394534823633
[11/23 21:01:24 visual_prompt]: Epoch 42 / 100: avg data time: 4.99e+00, avg batch time: 6.4307, average train loss: 37.8346
[11/23 21:02:16 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.5893, average loss: 28.7439
[11/23 21:02:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.39	
[11/23 21:02:16 visual_prompt]: Training 43 / 100 epoch, with learning rate 17.979639334863467
[11/23 21:09:49 visual_prompt]: Epoch 43 / 100: avg data time: 5.03e+00, avg batch time: 6.4734, average train loss: 45.0149
[11/23 21:10:41 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.5889, average loss: 31.4061
[11/23 21:10:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 43.62	
[11/23 21:10:41 visual_prompt]: Training 44 / 100 epoch, with learning rate 17.584208038447503
[11/23 21:18:15 visual_prompt]: Epoch 44 / 100: avg data time: 5.03e+00, avg batch time: 6.4789, average train loss: 28.8709
[11/23 21:19:06 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.5860, average loss: 74.4183
[11/23 21:19:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.87	
[11/23 21:19:06 visual_prompt]: Training 45 / 100 epoch, with learning rate 17.182582417698903
[11/23 21:26:36 visual_prompt]: Epoch 45 / 100: avg data time: 4.98e+00, avg batch time: 6.4245, average train loss: 56.1718
[11/23 21:27:27 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.5911, average loss: 69.7327
[11/23 21:27:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 38.18	
[11/23 21:27:27 visual_prompt]: Training 46 / 100 epoch, with learning rate 16.77525179157086
[11/23 21:34:55 visual_prompt]: Epoch 46 / 100: avg data time: 4.94e+00, avg batch time: 6.3896, average train loss: 44.8990
[11/23 21:35:45 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.5871, average loss: 12.5469
[11/23 21:35:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.28	
[11/23 21:35:45 visual_prompt]: Training 47 / 100 epoch, with learning rate 16.362712429686844
[11/23 21:43:17 visual_prompt]: Epoch 47 / 100: avg data time: 5.00e+00, avg batch time: 6.4545, average train loss: 25.0009
[11/23 21:44:09 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.5859, average loss: 20.3711
[11/23 21:44:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 45.31	
[11/23 21:44:09 visual_prompt]: Training 48 / 100 epoch, with learning rate 15.94546694771249
[11/23 21:51:41 visual_prompt]: Epoch 48 / 100: avg data time: 5.01e+00, avg batch time: 6.4535, average train loss: 40.9969
[11/23 21:52:33 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.5882, average loss: 8.9304
[11/23 21:52:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.33	
[11/23 21:52:33 visual_prompt]: Training 49 / 100 epoch, with learning rate 15.524023694995845
[11/23 22:00:07 visual_prompt]: Epoch 49 / 100: avg data time: 5.04e+00, avg batch time: 6.4897, average train loss: 36.0324
[11/23 22:00:59 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.5885, average loss: 43.2546
[11/23 22:00:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.20	
[11/23 22:00:59 visual_prompt]: Stopping early.
[11/23 22:00:59 visual_prompt]: Rank of current process: 0. World size: 1
[11/23 22:00:59 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/23 22:00:59 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/23 22:00:59 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/23 22:00:59 visual_prompt]: Training with config:
[11/23 22:00:59 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr25.0_wd0.0001/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 25.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/23 22:00:59 visual_prompt]: Loading training data...
[11/23 22:00:59 visual_prompt]: Constructing mammo-cbis dataset train...
[11/23 22:00:59 visual_prompt]: Loading validation data...
[11/23 22:00:59 visual_prompt]: Constructing mammo-cbis dataset val...
[11/23 22:00:59 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/23 22:01:02 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/23 22:01:02 visual_prompt]: tuned percent:0.532
[11/23 22:01:02 visual_prompt]: Device used for model: 0
[11/23 22:01:02 visual_prompt]: Setting up Evaluator...
[11/23 22:01:02 visual_prompt]: Setting up Trainer...
[11/23 22:01:02 visual_prompt]: 	Setting up the optimizer...
[11/23 22:01:02 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/23 22:08:37 visual_prompt]: Epoch 1 / 100: avg data time: 5.05e+00, avg batch time: 6.5017, average train loss: 1.4863
[11/23 22:09:29 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.5885, average loss: 1.4553
[11/23 22:09:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/23 22:09:29 visual_prompt]: Training 2 / 100 epoch, with learning rate 2.5
[11/23 22:17:04 visual_prompt]: Epoch 2 / 100: avg data time: 5.05e+00, avg batch time: 6.5013, average train loss: 14.1045
[11/23 22:17:56 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.5840, average loss: 9.4368
[11/23 22:17:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.83	
[11/23 22:17:56 visual_prompt]: Training 3 / 100 epoch, with learning rate 5.0
[11/23 22:25:31 visual_prompt]: Epoch 3 / 100: avg data time: 5.04e+00, avg batch time: 6.4939, average train loss: 12.1708
[11/23 22:26:23 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.5852, average loss: 17.5772
[11/23 22:26:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.57	
[11/23 22:26:23 visual_prompt]: Training 4 / 100 epoch, with learning rate 7.5
[11/23 22:33:57 visual_prompt]: Epoch 4 / 100: avg data time: 5.03e+00, avg batch time: 6.4730, average train loss: 28.3325
[11/23 22:34:49 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.5876, average loss: 30.1488
[11/23 22:34:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.28	
[11/23 22:34:49 visual_prompt]: Training 5 / 100 epoch, with learning rate 10.0
[11/23 22:42:23 visual_prompt]: Epoch 5 / 100: avg data time: 5.04e+00, avg batch time: 6.4962, average train loss: 20.1486
[11/23 22:43:15 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.5917, average loss: 34.7076
[11/23 22:43:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.32	
[11/23 22:43:15 visual_prompt]: Training 6 / 100 epoch, with learning rate 12.5
[11/23 22:50:51 visual_prompt]: Epoch 6 / 100: avg data time: 5.05e+00, avg batch time: 6.5033, average train loss: 13.5248
[11/23 22:51:43 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.5890, average loss: 7.0067
[11/23 22:51:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 40.84	
[11/23 22:51:43 visual_prompt]: Training 7 / 100 epoch, with learning rate 15.0
[11/23 22:59:11 visual_prompt]: Epoch 7 / 100: avg data time: 4.95e+00, avg batch time: 6.3963, average train loss: 13.7616
[11/23 23:00:01 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.5882, average loss: 48.1128
[11/23 23:00:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 41.41	
[11/23 23:00:01 visual_prompt]: Training 8 / 100 epoch, with learning rate 17.5
[11/23 23:07:31 visual_prompt]: Epoch 8 / 100: avg data time: 4.98e+00, avg batch time: 6.4296, average train loss: 52.1651
[11/23 23:08:23 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.5919, average loss: 11.1195
[11/23 23:08:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 45.54	
[11/23 23:08:23 visual_prompt]: Training 9 / 100 epoch, with learning rate 20.0
[11/23 23:15:49 visual_prompt]: Epoch 9 / 100: avg data time: 4.93e+00, avg batch time: 6.3784, average train loss: 41.3893
[11/23 23:16:40 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.5847, average loss: 26.3347
[11/23 23:16:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.17	
[11/23 23:16:40 visual_prompt]: Training 10 / 100 epoch, with learning rate 22.5
[11/23 23:24:08 visual_prompt]: Epoch 10 / 100: avg data time: 4.95e+00, avg batch time: 6.3945, average train loss: 44.9572
[11/23 23:24:59 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.5924, average loss: 42.2427
[11/23 23:24:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.87	
[11/23 23:24:59 visual_prompt]: Training 11 / 100 epoch, with learning rate 25.0
[11/23 23:32:28 visual_prompt]: Epoch 11 / 100: avg data time: 4.96e+00, avg batch time: 6.4061, average train loss: 42.2056
[11/23 23:33:19 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.5934, average loss: 51.3139
[11/23 23:33:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.48	
[11/23 23:33:19 visual_prompt]: Training 12 / 100 epoch, with learning rate 24.9923853377387
[11/23 23:40:43 visual_prompt]: Epoch 12 / 100: avg data time: 4.90e+00, avg batch time: 6.3495, average train loss: 43.9473
[11/23 23:41:34 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.5894, average loss: 31.6831
[11/23 23:41:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 45.15	
[11/23 23:41:34 visual_prompt]: Best epoch 12: best metric: -31.683
[11/23 23:41:34 visual_prompt]: Training 13 / 100 epoch, with learning rate 24.969550628247802
[11/23 23:49:00 visual_prompt]: Epoch 13 / 100: avg data time: 4.92e+00, avg batch time: 6.3670, average train loss: 32.5941
[11/23 23:49:51 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.5897, average loss: 33.9490
[11/23 23:49:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.62	
[11/23 23:49:51 visual_prompt]: Training 14 / 100 epoch, with learning rate 24.931523692103415
[11/23 23:57:17 visual_prompt]: Epoch 14 / 100: avg data time: 4.92e+00, avg batch time: 6.3613, average train loss: 48.6793
[11/23 23:58:07 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.5882, average loss: 57.6376
[11/23 23:58:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.49	
[11/23 23:58:07 visual_prompt]: Training 15 / 100 epoch, with learning rate 24.87835085926963
[11/24 00:05:32 visual_prompt]: Epoch 15 / 100: avg data time: 4.91e+00, avg batch time: 6.3544, average train loss: 43.8270
[11/24 00:06:24 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.5932, average loss: 61.6118
[11/24 00:06:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.04	
[11/24 00:06:24 visual_prompt]: Training 16 / 100 epoch, with learning rate 24.8100969126526
[11/24 00:13:52 visual_prompt]: Epoch 16 / 100: avg data time: 4.95e+00, avg batch time: 6.4033, average train loss: 22.3551
[11/24 00:14:43 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.5878, average loss: 47.9962
[11/24 00:14:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.83	
[11/24 00:14:43 visual_prompt]: Training 17 / 100 epoch, with learning rate 24.72684500917257
[11/24 00:22:12 visual_prompt]: Epoch 17 / 100: avg data time: 4.96e+00, avg batch time: 6.4050, average train loss: 49.6621
[11/24 00:23:03 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.5853, average loss: 10.1766
[11/24 00:23:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.02	
[11/24 00:23:03 visual_prompt]: Best epoch 17: best metric: -10.177
[11/24 00:23:03 visual_prompt]: Training 18 / 100 epoch, with learning rate 24.628696578449954
[11/24 00:30:32 visual_prompt]: Epoch 18 / 100: avg data time: 4.97e+00, avg batch time: 6.4105, average train loss: 40.4469
[11/24 00:31:24 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.5889, average loss: 40.1932
[11/24 00:31:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.31	
[11/24 00:31:24 visual_prompt]: Training 19 / 100 epoch, with learning rate 24.515771199228986
[11/24 00:38:51 visual_prompt]: Epoch 19 / 100: avg data time: 4.95e+00, avg batch time: 6.3959, average train loss: 35.7924
[11/24 00:39:43 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.5861, average loss: 12.3812
[11/24 00:39:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.54	
[11/24 00:39:43 visual_prompt]: Training 20 / 100 epoch, with learning rate 24.38820645368942
[11/24 00:47:11 visual_prompt]: Epoch 20 / 100: avg data time: 4.96e+00, avg batch time: 6.4055, average train loss: 40.1632
[11/24 00:48:03 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.5887, average loss: 36.6647
[11/24 00:48:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.07	
[11/24 00:48:03 visual_prompt]: Training 21 / 100 epoch, with learning rate 24.246157759823856
[11/24 00:55:34 visual_prompt]: Epoch 21 / 100: avg data time: 5.00e+00, avg batch time: 6.4482, average train loss: 36.4532
[11/24 00:56:26 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.5887, average loss: 25.0213
[11/24 00:56:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.33	
[11/24 00:56:26 visual_prompt]: Training 22 / 100 epoch, with learning rate 24.08979818208484
[11/24 01:03:59 visual_prompt]: Epoch 22 / 100: avg data time: 5.02e+00, avg batch time: 6.4686, average train loss: 46.5363
[11/24 01:04:51 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.5860, average loss: 54.7477
[11/24 01:04:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.19	
[11/24 01:04:51 visual_prompt]: Training 23 / 100 epoch, with learning rate 23.91931822053251
[11/24 01:12:23 visual_prompt]: Epoch 23 / 100: avg data time: 5.03e+00, avg batch time: 6.4676, average train loss: 41.4210
[11/24 01:13:15 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.5853, average loss: 70.8233
[11/24 01:13:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.70	
[11/24 01:13:15 visual_prompt]: Training 24 / 100 epoch, with learning rate 23.73492557873959
[11/24 01:20:49 visual_prompt]: Epoch 24 / 100: avg data time: 5.03e+00, avg batch time: 6.4798, average train loss: 25.7247
[11/24 01:21:41 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.5891, average loss: 20.1975
[11/24 01:21:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.90	
[11/24 01:21:41 visual_prompt]: Training 25 / 100 epoch, with learning rate 23.536844910736587
[11/24 01:29:13 visual_prompt]: Epoch 25 / 100: avg data time: 5.02e+00, avg batch time: 6.4612, average train loss: 49.7056
[11/24 01:30:04 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.5856, average loss: 292.2785
[11/24 01:30:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.15	
[11/24 01:30:04 visual_prompt]: Training 26 / 100 epoch, with learning rate 23.325317547305485
[11/24 01:37:30 visual_prompt]: Epoch 26 / 100: avg data time: 4.93e+00, avg batch time: 6.3691, average train loss: 80.1109
[11/24 01:38:22 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.5849, average loss: 61.1482
[11/24 01:38:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.78	
[11/24 01:38:22 visual_prompt]: Training 27 / 100 epoch, with learning rate 23.100601201955325
[11/24 01:45:49 visual_prompt]: Epoch 27 / 100: avg data time: 4.93e+00, avg batch time: 6.3821, average train loss: 32.7905
[11/24 01:46:40 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.5880, average loss: 54.5140
[11/24 01:46:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.16	
[11/24 01:46:40 visual_prompt]: Training 28 / 100 epoch, with learning rate 22.86296965693802
[11/24 01:54:10 visual_prompt]: Epoch 28 / 100: avg data time: 4.97e+00, avg batch time: 6.4178, average train loss: 38.8043
[11/24 01:55:01 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.5857, average loss: 39.8181
[11/24 01:55:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.88	
[11/24 01:55:01 visual_prompt]: Training 29 / 100 epoch, with learning rate 22.612712429686844
[11/24 02:02:29 visual_prompt]: Epoch 29 / 100: avg data time: 4.94e+00, avg batch time: 6.3919, average train loss: 28.7661
[11/24 02:03:20 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.5907, average loss: 11.3278
[11/24 02:03:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.36	
[11/24 02:03:20 visual_prompt]: Training 30 / 100 epoch, with learning rate 22.35013442008402
[11/24 02:10:48 visual_prompt]: Epoch 30 / 100: avg data time: 4.96e+00, avg batch time: 6.4029, average train loss: 42.6049
[11/24 02:11:39 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.5857, average loss: 2.1007
[11/24 02:11:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.02	
[11/24 02:11:39 visual_prompt]: Best epoch 30: best metric: -2.101
[11/24 02:11:39 visual_prompt]: Training 31 / 100 epoch, with learning rate 22.075555538987224
[11/24 02:19:06 visual_prompt]: Epoch 31 / 100: avg data time: 4.94e+00, avg batch time: 6.3860, average train loss: 22.0164
[11/24 02:19:57 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.5844, average loss: 68.9451
[11/24 02:19:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.39	
[11/24 02:19:57 visual_prompt]: Training 32 / 100 epoch, with learning rate 21.78931031846743
[11/24 02:27:25 visual_prompt]: Epoch 32 / 100: avg data time: 4.95e+00, avg batch time: 6.4001, average train loss: 40.7430
[11/24 02:28:17 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.5899, average loss: 15.0380
[11/24 02:28:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.16	
[11/24 02:28:17 visual_prompt]: Training 33 / 100 epoch, with learning rate 21.49174750423314
[11/24 02:35:45 visual_prompt]: Epoch 33 / 100: avg data time: 4.96e+00, avg batch time: 6.4049, average train loss: 22.2787
[11/24 02:36:36 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.5892, average loss: 13.6798
[11/24 02:36:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 42.80	
[11/24 02:36:36 visual_prompt]: Training 34 / 100 epoch, with learning rate 21.183229630737465
[11/24 02:44:06 visual_prompt]: Epoch 34 / 100: avg data time: 4.97e+00, avg batch time: 6.4215, average train loss: 36.2158
[11/24 02:44:57 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.5858, average loss: 22.6130
[11/24 02:44:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 44.23	
[11/24 02:44:57 visual_prompt]: Training 35 / 100 epoch, with learning rate 20.864132579485727
[11/24 02:52:24 visual_prompt]: Epoch 35 / 100: avg data time: 4.94e+00, avg batch time: 6.3853, average train loss: 56.1053
[11/24 02:53:15 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.5880, average loss: 5.3855
[11/24 02:53:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.30	
[11/24 02:53:15 visual_prompt]: Training 36 / 100 epoch, with learning rate 20.53484512108174
[11/24 03:00:47 visual_prompt]: Epoch 36 / 100: avg data time: 5.00e+00, avg batch time: 6.4446, average train loss: 59.4651
[11/24 03:01:38 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.5865, average loss: 48.3050
[11/24 03:01:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.81	
[11/24 03:01:38 visual_prompt]: Training 37 / 100 epoch, with learning rate 20.195768441570728
[11/24 03:09:08 visual_prompt]: Epoch 37 / 100: avg data time: 4.98e+00, avg batch time: 6.4287, average train loss: 32.2662
[11/24 03:10:00 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.5880, average loss: 72.6989
[11/24 03:10:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.26	
[11/24 03:10:00 visual_prompt]: Training 38 / 100 epoch, with learning rate 19.847315653655915
[11/24 03:17:30 visual_prompt]: Epoch 38 / 100: avg data time: 4.98e+00, avg batch time: 6.4212, average train loss: 42.5562
[11/24 03:18:21 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.5940, average loss: 4.2675
[11/24 03:18:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.39	
[11/24 03:18:21 visual_prompt]: Training 39 / 100 epoch, with learning rate 19.489911293384335
[11/24 03:25:49 visual_prompt]: Epoch 39 / 100: avg data time: 4.95e+00, avg batch time: 6.4019, average train loss: 36.5143
[11/24 03:26:40 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.5859, average loss: 4.1555
[11/24 03:26:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.22	
[11/24 03:26:40 visual_prompt]: Training 40 / 100 epoch, with learning rate 19.12399080291506
[11/24 03:34:07 visual_prompt]: Epoch 40 / 100: avg data time: 4.94e+00, avg batch time: 6.3834, average train loss: 39.6153
[11/24 03:34:58 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.5857, average loss: 7.0833
[11/24 03:34:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.75	
[11/24 03:34:58 visual_prompt]: Training 41 / 100 epoch, with learning rate 18.75
[11/24 03:42:27 visual_prompt]: Epoch 41 / 100: avg data time: 4.95e+00, avg batch time: 6.4028, average train loss: 19.3398
[11/24 03:43:18 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.5867, average loss: 206.9054
[11/24 03:43:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 42.06	
[11/24 03:43:18 visual_prompt]: Training 42 / 100 epoch, with learning rate 18.368394534823633
[11/24 03:50:43 visual_prompt]: Epoch 42 / 100: avg data time: 4.92e+00, avg batch time: 6.3655, average train loss: 50.4669
[11/24 03:51:34 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.5908, average loss: 4.0986
[11/24 03:51:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.62	
[11/24 03:51:34 visual_prompt]: Training 43 / 100 epoch, with learning rate 17.979639334863467
[11/24 03:59:01 visual_prompt]: Epoch 43 / 100: avg data time: 4.94e+00, avg batch time: 6.3797, average train loss: 43.5799
[11/24 03:59:52 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.5871, average loss: 134.5260
[11/24 03:59:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.64	
[11/24 03:59:52 visual_prompt]: Training 44 / 100 epoch, with learning rate 17.584208038447503
[11/24 04:07:18 visual_prompt]: Epoch 44 / 100: avg data time: 4.93e+00, avg batch time: 6.3825, average train loss: 45.4177
[11/24 04:08:09 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.5899, average loss: 15.0290
[11/24 04:08:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.72	
[11/24 04:08:09 visual_prompt]: Training 45 / 100 epoch, with learning rate 17.182582417698903
[11/24 04:15:37 visual_prompt]: Epoch 45 / 100: avg data time: 4.94e+00, avg batch time: 6.3927, average train loss: 28.1657
[11/24 04:16:28 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.5868, average loss: 9.0208
[11/24 04:16:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.76	
[11/24 04:16:28 visual_prompt]: Training 46 / 100 epoch, with learning rate 16.77525179157086
[11/24 04:23:56 visual_prompt]: Epoch 46 / 100: avg data time: 4.95e+00, avg batch time: 6.3979, average train loss: 44.4996
[11/24 04:24:48 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.5887, average loss: 50.9570
[11/24 04:24:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.11	
[11/24 04:24:48 visual_prompt]: Training 47 / 100 epoch, with learning rate 16.362712429686844
[11/24 04:32:17 visual_prompt]: Epoch 47 / 100: avg data time: 4.97e+00, avg batch time: 6.4200, average train loss: 24.0153
[11/24 04:33:09 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.5922, average loss: 4.7144
[11/24 04:33:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.99	
[11/24 04:33:09 visual_prompt]: Training 48 / 100 epoch, with learning rate 15.94546694771249
[11/24 04:40:38 visual_prompt]: Epoch 48 / 100: avg data time: 4.97e+00, avg batch time: 6.4194, average train loss: 24.9171
[11/24 04:41:30 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.5853, average loss: 7.9281
[11/24 04:41:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.84	
[11/24 04:41:30 visual_prompt]: Training 49 / 100 epoch, with learning rate 15.524023694995845
[11/24 04:48:51 visual_prompt]: Epoch 49 / 100: avg data time: 4.86e+00, avg batch time: 6.3022, average train loss: 31.3803
[11/24 04:49:41 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.5873, average loss: 111.4237
[11/24 04:49:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.74	
[11/24 04:49:41 visual_prompt]: Training 50 / 100 epoch, with learning rate 15.09889613522199
[11/24 04:57:03 visual_prompt]: Epoch 50 / 100: avg data time: 4.86e+00, avg batch time: 6.3045, average train loss: 33.0342
[11/24 04:57:53 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.5864, average loss: 26.8380
[11/24 04:57:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.96	
[11/24 04:57:53 visual_prompt]: Training 51 / 100 epoch, with learning rate 14.670602220836631
[11/24 05:05:17 visual_prompt]: Epoch 51 / 100: avg data time: 4.89e+00, avg batch time: 6.3409, average train loss: 30.8800
[11/24 05:06:08 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.5837, average loss: 4.9138
[11/24 05:06:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 38.36	
[11/24 05:06:08 visual_prompt]: Stopping early.
[11/24 05:06:08 visual_prompt]: Rank of current process: 0. World size: 1
[11/24 05:06:08 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/24 05:06:08 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/24 05:06:08 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/24 05:06:08 visual_prompt]: Training with config:
[11/24 05:06:08 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr25.0_wd0.0/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 25.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/24 05:06:08 visual_prompt]: Loading training data...
[11/24 05:06:08 visual_prompt]: Constructing mammo-cbis dataset train...
[11/24 05:06:08 visual_prompt]: Loading validation data...
[11/24 05:06:08 visual_prompt]: Constructing mammo-cbis dataset val...
[11/24 05:06:08 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/24 05:06:11 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/24 05:06:11 visual_prompt]: tuned percent:0.532
[11/24 05:06:11 visual_prompt]: Device used for model: 0
[11/24 05:06:11 visual_prompt]: Setting up Evaluator...
[11/24 05:06:11 visual_prompt]: Setting up Trainer...
[11/24 05:06:11 visual_prompt]: 	Setting up the optimizer...
[11/24 05:06:11 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/24 05:13:36 visual_prompt]: Epoch 1 / 100: avg data time: 4.92e+00, avg batch time: 6.3643, average train loss: 1.4863
[11/24 05:14:28 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.5845, average loss: 1.4553
[11/24 05:14:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/24 05:14:28 visual_prompt]: Training 2 / 100 epoch, with learning rate 2.5
[11/24 05:21:56 visual_prompt]: Epoch 2 / 100: avg data time: 4.95e+00, avg batch time: 6.4050, average train loss: 12.0091
[11/24 05:22:47 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.5861, average loss: 5.3519
[11/24 05:22:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.88	
[11/24 05:22:47 visual_prompt]: Training 3 / 100 epoch, with learning rate 5.0
[11/24 05:30:16 visual_prompt]: Epoch 3 / 100: avg data time: 4.96e+00, avg batch time: 6.4109, average train loss: 12.7435
[11/24 05:31:07 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.5881, average loss: 21.8348
[11/24 05:31:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.51	
[11/24 05:31:07 visual_prompt]: Training 4 / 100 epoch, with learning rate 7.5
[11/24 05:38:36 visual_prompt]: Epoch 4 / 100: avg data time: 4.96e+00, avg batch time: 6.4085, average train loss: 28.3749
[11/24 05:39:27 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.5862, average loss: 21.9880
[11/24 05:39:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.76	
[11/24 05:39:27 visual_prompt]: Training 5 / 100 epoch, with learning rate 10.0
[11/24 05:46:54 visual_prompt]: Epoch 5 / 100: avg data time: 4.94e+00, avg batch time: 6.3892, average train loss: 30.4389
[11/24 05:47:46 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.5867, average loss: 17.9642
[11/24 05:47:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.47	
[11/24 05:47:46 visual_prompt]: Training 6 / 100 epoch, with learning rate 12.5
[11/24 05:55:16 visual_prompt]: Epoch 6 / 100: avg data time: 4.98e+00, avg batch time: 6.4260, average train loss: 38.2745
[11/24 05:56:07 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.5855, average loss: 24.7019
[11/24 05:56:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.51	
[11/24 05:56:07 visual_prompt]: Training 7 / 100 epoch, with learning rate 15.0
[11/24 06:03:34 visual_prompt]: Epoch 7 / 100: avg data time: 4.94e+00, avg batch time: 6.3889, average train loss: 17.9071
[11/24 06:04:25 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.5885, average loss: 54.3213
[11/24 06:04:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.54	
[11/24 06:04:25 visual_prompt]: Training 8 / 100 epoch, with learning rate 17.5
[11/24 06:11:54 visual_prompt]: Epoch 8 / 100: avg data time: 4.96e+00, avg batch time: 6.4111, average train loss: 37.1880
[11/24 06:12:44 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.5856, average loss: 25.2939
[11/24 06:12:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.58	
[11/24 06:12:44 visual_prompt]: Training 9 / 100 epoch, with learning rate 20.0
[11/24 06:20:13 visual_prompt]: Epoch 9 / 100: avg data time: 4.96e+00, avg batch time: 6.4032, average train loss: 32.9157
[11/24 06:21:04 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.5851, average loss: 7.0755
[11/24 06:21:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.00	
[11/24 06:21:04 visual_prompt]: Training 10 / 100 epoch, with learning rate 22.5
[11/24 06:28:32 visual_prompt]: Epoch 10 / 100: avg data time: 4.96e+00, avg batch time: 6.4036, average train loss: 29.5431
[11/24 06:29:24 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.5870, average loss: 16.9934
[11/24 06:29:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.65	
[11/24 06:29:24 visual_prompt]: Training 11 / 100 epoch, with learning rate 25.0
[11/24 06:36:53 visual_prompt]: Epoch 11 / 100: avg data time: 4.96e+00, avg batch time: 6.4117, average train loss: 24.2630
[11/24 06:37:45 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.5900, average loss: 22.6335
[11/24 06:37:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.87	
[11/24 06:37:45 visual_prompt]: Training 12 / 100 epoch, with learning rate 24.9923853377387
[11/24 06:45:14 visual_prompt]: Epoch 12 / 100: avg data time: 4.97e+00, avg batch time: 6.4221, average train loss: 35.4042
[11/24 06:46:06 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.5857, average loss: 49.3523
[11/24 06:46:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 45.53	
[11/24 06:46:06 visual_prompt]: Training 13 / 100 epoch, with learning rate 24.969550628247802
[11/24 06:53:41 visual_prompt]: Epoch 13 / 100: avg data time: 5.04e+00, avg batch time: 6.4906, average train loss: 24.6365
[11/24 06:54:32 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.5837, average loss: 52.9193
[11/24 06:54:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.96	
[11/24 06:54:32 visual_prompt]: Training 14 / 100 epoch, with learning rate 24.931523692103415
[11/24 07:02:07 visual_prompt]: Epoch 14 / 100: avg data time: 5.04e+00, avg batch time: 6.4868, average train loss: 31.0816
[11/24 07:02:58 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.5851, average loss: 8.3084
[11/24 07:02:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.55	
[11/24 07:02:58 visual_prompt]: Best epoch 14: best metric: -8.308
[11/24 07:02:58 visual_prompt]: Training 15 / 100 epoch, with learning rate 24.87835085926963
[11/24 07:10:31 visual_prompt]: Epoch 15 / 100: avg data time: 5.01e+00, avg batch time: 6.4565, average train loss: 34.8043
[11/24 07:11:22 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.5868, average loss: 9.7471
[11/24 07:11:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.99	
[11/24 07:11:22 visual_prompt]: Training 16 / 100 epoch, with learning rate 24.8100969126526
[11/24 07:18:56 visual_prompt]: Epoch 16 / 100: avg data time: 5.04e+00, avg batch time: 6.4815, average train loss: 66.6468
[11/24 07:19:48 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.5865, average loss: 36.3207
[11/24 07:19:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.19	
[11/24 07:19:48 visual_prompt]: Training 17 / 100 epoch, with learning rate 24.72684500917257
[11/24 07:27:22 visual_prompt]: Epoch 17 / 100: avg data time: 5.03e+00, avg batch time: 6.4785, average train loss: 17.2166
[11/24 07:28:14 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.5890, average loss: 35.5849
[11/24 07:28:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.25	
[11/24 07:28:14 visual_prompt]: Training 18 / 100 epoch, with learning rate 24.628696578449954
[11/24 07:35:47 visual_prompt]: Epoch 18 / 100: avg data time: 5.02e+00, avg batch time: 6.4647, average train loss: 21.8187
[11/24 07:36:38 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.5876, average loss: 6.5733
[11/24 07:36:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.44	
[11/24 07:36:38 visual_prompt]: Best epoch 18: best metric: -6.573
[11/24 07:36:38 visual_prompt]: Training 19 / 100 epoch, with learning rate 24.515771199228986
[11/24 07:44:11 visual_prompt]: Epoch 19 / 100: avg data time: 5.02e+00, avg batch time: 6.4620, average train loss: 21.6233
[11/24 07:45:03 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.5862, average loss: 58.2876
[11/24 07:45:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.15	
[11/24 07:45:03 visual_prompt]: Training 20 / 100 epoch, with learning rate 24.38820645368942
[11/24 07:52:35 visual_prompt]: Epoch 20 / 100: avg data time: 5.02e+00, avg batch time: 6.4671, average train loss: 26.4669
[11/24 07:53:26 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.5867, average loss: 35.9255
[11/24 07:53:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.98	
[11/24 07:53:26 visual_prompt]: Training 21 / 100 epoch, with learning rate 24.246157759823856
[11/24 08:00:58 visual_prompt]: Epoch 21 / 100: avg data time: 5.00e+00, avg batch time: 6.4511, average train loss: 22.5894
[11/24 08:01:50 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.5850, average loss: 4.4938
[11/24 08:01:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.39	
[11/24 08:01:50 visual_prompt]: Best epoch 21: best metric: -4.494
[11/24 08:01:50 visual_prompt]: Training 22 / 100 epoch, with learning rate 24.08979818208484
[11/24 08:09:18 visual_prompt]: Epoch 22 / 100: avg data time: 4.96e+00, avg batch time: 6.4000, average train loss: 36.8448
[11/24 08:10:09 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.5864, average loss: 31.1177
[11/24 08:10:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.58	
[11/24 08:10:09 visual_prompt]: Training 23 / 100 epoch, with learning rate 23.91931822053251
[11/24 08:17:38 visual_prompt]: Epoch 23 / 100: avg data time: 4.97e+00, avg batch time: 6.4107, average train loss: 25.7429
[11/24 08:18:29 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.5852, average loss: 27.3958
[11/24 08:18:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.39	
[11/24 08:18:29 visual_prompt]: Training 24 / 100 epoch, with learning rate 23.73492557873959
[11/24 08:25:57 visual_prompt]: Epoch 24 / 100: avg data time: 4.95e+00, avg batch time: 6.4024, average train loss: 22.0812
[11/24 08:26:49 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.5870, average loss: 16.3876
[11/24 08:26:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.90	
[11/24 08:26:49 visual_prompt]: Training 25 / 100 epoch, with learning rate 23.536844910736587
[11/24 08:34:19 visual_prompt]: Epoch 25 / 100: avg data time: 4.98e+00, avg batch time: 6.4272, average train loss: 27.0851
[11/24 08:35:10 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.5873, average loss: 19.4446
[11/24 08:35:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.63	
[11/24 08:35:10 visual_prompt]: Training 26 / 100 epoch, with learning rate 23.325317547305485
[11/24 08:42:39 visual_prompt]: Epoch 26 / 100: avg data time: 4.96e+00, avg batch time: 6.4145, average train loss: 16.4704
[11/24 08:43:31 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.5912, average loss: 2.5804
[11/24 08:43:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 44.72	rocauc: 58.80	
[11/24 08:43:31 visual_prompt]: Best epoch 26: best metric: -2.580
[11/24 08:43:31 visual_prompt]: Training 27 / 100 epoch, with learning rate 23.100601201955325
[11/24 08:50:57 visual_prompt]: Epoch 27 / 100: avg data time: 4.93e+00, avg batch time: 6.3767, average train loss: 36.2296
[11/24 08:51:47 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.5887, average loss: 63.0418
[11/24 08:51:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.72	
[11/24 08:51:48 visual_prompt]: Training 28 / 100 epoch, with learning rate 22.86296965693802
[11/24 08:59:16 visual_prompt]: Epoch 28 / 100: avg data time: 4.97e+00, avg batch time: 6.4080, average train loss: 45.4160
[11/24 09:00:07 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.5860, average loss: 5.5664
[11/24 09:00:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.39	
[11/24 09:00:07 visual_prompt]: Training 29 / 100 epoch, with learning rate 22.612712429686844
[11/24 09:07:37 visual_prompt]: Epoch 29 / 100: avg data time: 4.97e+00, avg batch time: 6.4217, average train loss: 19.8106
[11/24 09:08:29 visual_prompt]: Inference (val):avg data time: 2.03e-03, avg batch time: 0.5914, average loss: 4.8114
[11/24 09:08:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.27	
[11/24 09:08:29 visual_prompt]: Training 30 / 100 epoch, with learning rate 22.35013442008402
[11/24 09:16:02 visual_prompt]: Epoch 30 / 100: avg data time: 5.02e+00, avg batch time: 6.4747, average train loss: 12.8429
[11/24 09:16:54 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.5892, average loss: 24.3753
[11/24 09:16:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.03	
[11/24 09:16:54 visual_prompt]: Training 31 / 100 epoch, with learning rate 22.075555538987224
[11/24 09:24:24 visual_prompt]: Epoch 31 / 100: avg data time: 4.99e+00, avg batch time: 6.4341, average train loss: 31.7836
[11/24 09:25:16 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.5841, average loss: 2.1278
[11/24 09:25:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 47.56	rocauc: 60.76	
[11/24 09:25:16 visual_prompt]: Best epoch 31: best metric: -2.128
[11/24 09:25:16 visual_prompt]: Training 32 / 100 epoch, with learning rate 21.78931031846743
[11/24 09:32:48 visual_prompt]: Epoch 32 / 100: avg data time: 5.01e+00, avg batch time: 6.4580, average train loss: 10.5953
[11/24 09:33:39 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.5859, average loss: 12.6125
[11/24 09:33:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.98	
[11/24 09:33:39 visual_prompt]: Training 33 / 100 epoch, with learning rate 21.49174750423314
[11/24 09:41:07 visual_prompt]: Epoch 33 / 100: avg data time: 4.95e+00, avg batch time: 6.3971, average train loss: 24.0571
[11/24 09:41:58 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.5889, average loss: 3.9808
[11/24 09:41:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 62.03	
[11/24 09:41:58 visual_prompt]: Training 34 / 100 epoch, with learning rate 21.183229630737465
[11/24 09:49:25 visual_prompt]: Epoch 34 / 100: avg data time: 4.93e+00, avg batch time: 6.3799, average train loss: 14.0902
[11/24 09:50:16 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.5850, average loss: 5.2535
[11/24 09:50:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.20	
[11/24 09:50:16 visual_prompt]: Training 35 / 100 epoch, with learning rate 20.864132579485727
[11/24 09:57:43 visual_prompt]: Epoch 35 / 100: avg data time: 4.94e+00, avg batch time: 6.3872, average train loss: 18.7800
[11/24 09:58:34 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.5849, average loss: 19.7491
[11/24 09:58:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.23	
[11/24 09:58:34 visual_prompt]: Training 36 / 100 epoch, with learning rate 20.53484512108174
[11/24 10:06:04 visual_prompt]: Epoch 36 / 100: avg data time: 4.98e+00, avg batch time: 6.4237, average train loss: 16.4630
[11/24 10:06:55 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.5893, average loss: 28.7687
[11/24 10:06:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 63.87	
[11/24 10:06:55 visual_prompt]: Training 37 / 100 epoch, with learning rate 20.195768441570728
[11/24 10:14:23 visual_prompt]: Epoch 37 / 100: avg data time: 4.94e+00, avg batch time: 6.3883, average train loss: 20.7447
[11/24 10:15:14 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.5898, average loss: 34.2183
[11/24 10:15:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.61	
[11/24 10:15:14 visual_prompt]: Training 38 / 100 epoch, with learning rate 19.847315653655915
[11/24 10:22:43 visual_prompt]: Epoch 38 / 100: avg data time: 4.95e+00, avg batch time: 6.4044, average train loss: 15.3798
[11/24 10:23:34 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.5889, average loss: 50.9128
[11/24 10:23:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.47	
[11/24 10:23:34 visual_prompt]: Training 39 / 100 epoch, with learning rate 19.489911293384335
[11/24 10:31:04 visual_prompt]: Epoch 39 / 100: avg data time: 4.97e+00, avg batch time: 6.4236, average train loss: 27.5735
[11/24 10:31:55 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.5862, average loss: 19.0553
[11/24 10:31:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 62.25	
[11/24 10:31:55 visual_prompt]: Training 40 / 100 epoch, with learning rate 19.12399080291506
[11/24 10:39:22 visual_prompt]: Epoch 40 / 100: avg data time: 4.93e+00, avg batch time: 6.3901, average train loss: 11.9866
[11/24 10:40:13 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.5882, average loss: 4.5235
[11/24 10:40:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 47.97	rocauc: 63.94	
[11/24 10:40:13 visual_prompt]: Training 41 / 100 epoch, with learning rate 18.75
[11/24 10:47:41 visual_prompt]: Epoch 41 / 100: avg data time: 4.94e+00, avg batch time: 6.3980, average train loss: 9.0450
[11/24 10:48:33 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.5861, average loss: 20.2232
[11/24 10:48:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.34	
[11/24 10:48:33 visual_prompt]: Training 42 / 100 epoch, with learning rate 18.368394534823633
[11/24 10:56:00 visual_prompt]: Epoch 42 / 100: avg data time: 4.94e+00, avg batch time: 6.3912, average train loss: 7.0879
[11/24 10:56:51 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.5867, average loss: 1.3983
[11/24 10:56:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 64.39	
[11/24 10:56:51 visual_prompt]: Best epoch 42: best metric: -1.398
[11/24 10:56:51 visual_prompt]: Training 43 / 100 epoch, with learning rate 17.979639334863467
[11/24 11:04:19 visual_prompt]: Epoch 43 / 100: avg data time: 4.95e+00, avg batch time: 6.4018, average train loss: 14.8000
[11/24 11:05:11 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.5857, average loss: 18.5769
[11/24 11:05:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 67.19	
[11/24 11:05:11 visual_prompt]: Training 44 / 100 epoch, with learning rate 17.584208038447503
[11/24 11:12:42 visual_prompt]: Epoch 44 / 100: avg data time: 4.99e+00, avg batch time: 6.4408, average train loss: 14.2442
[11/24 11:13:33 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.5866, average loss: 16.6304
[11/24 11:13:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 64.74	
[11/24 11:13:33 visual_prompt]: Training 45 / 100 epoch, with learning rate 17.182582417698903
[11/24 11:21:03 visual_prompt]: Epoch 45 / 100: avg data time: 4.97e+00, avg batch time: 6.4248, average train loss: 9.1219
[11/24 11:21:54 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.5876, average loss: 9.5314
[11/24 11:21:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 63.70	
[11/24 11:21:54 visual_prompt]: Training 46 / 100 epoch, with learning rate 16.77525179157086
[11/24 11:29:28 visual_prompt]: Epoch 46 / 100: avg data time: 5.03e+00, avg batch time: 6.4786, average train loss: 6.9335
[11/24 11:30:20 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.5859, average loss: 6.1607
[11/24 11:30:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 65.45	
[11/24 11:30:20 visual_prompt]: Training 47 / 100 epoch, with learning rate 16.362712429686844
[11/24 11:37:53 visual_prompt]: Epoch 47 / 100: avg data time: 5.02e+00, avg batch time: 6.4697, average train loss: 6.3023
[11/24 11:38:45 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.5884, average loss: 5.9604
[11/24 11:38:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 63.55	
[11/24 11:38:45 visual_prompt]: Training 48 / 100 epoch, with learning rate 15.94546694771249
[11/24 11:46:17 visual_prompt]: Epoch 48 / 100: avg data time: 5.01e+00, avg batch time: 6.4642, average train loss: 10.8818
[11/24 11:47:09 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.5868, average loss: 4.0505
[11/24 11:47:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 67.84	
[11/24 11:47:09 visual_prompt]: Training 49 / 100 epoch, with learning rate 15.524023694995845
[11/24 11:54:40 visual_prompt]: Epoch 49 / 100: avg data time: 5.00e+00, avg batch time: 6.4503, average train loss: 5.2683
[11/24 11:55:32 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.5848, average loss: 12.3859
[11/24 11:55:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 64.71	
[11/24 11:55:32 visual_prompt]: Training 50 / 100 epoch, with learning rate 15.09889613522199
[11/24 12:03:04 visual_prompt]: Epoch 50 / 100: avg data time: 5.01e+00, avg batch time: 6.4564, average train loss: 10.7237
[11/24 12:03:56 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.5864, average loss: 22.7845
[11/24 12:03:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.22	
[11/24 12:03:56 visual_prompt]: Training 51 / 100 epoch, with learning rate 14.670602220836631
[11/24 12:11:26 visual_prompt]: Epoch 51 / 100: avg data time: 4.97e+00, avg batch time: 6.4264, average train loss: 6.8120
[11/24 12:12:16 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.5857, average loss: 14.6110
[11/24 12:12:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 64.73	
[11/24 12:12:16 visual_prompt]: Training 52 / 100 epoch, with learning rate 14.239663762000818
[11/24 12:19:37 visual_prompt]: Epoch 52 / 100: avg data time: 4.85e+00, avg batch time: 6.3026, average train loss: 8.3853
[11/24 12:20:27 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.5856, average loss: 10.9722
[11/24 12:20:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.84	
[11/24 12:20:27 visual_prompt]: Training 53 / 100 epoch, with learning rate 13.80660579084567
[11/24 12:27:51 visual_prompt]: Epoch 53 / 100: avg data time: 4.88e+00, avg batch time: 6.3282, average train loss: 6.7071
[11/24 12:28:41 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.5877, average loss: 13.6650
[11/24 12:28:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 64.58	
[11/24 12:28:41 visual_prompt]: Training 54 / 100 epoch, with learning rate 13.371955921801565
[11/24 12:36:03 visual_prompt]: Epoch 54 / 100: avg data time: 4.86e+00, avg batch time: 6.3170, average train loss: 5.6029
[11/24 12:36:54 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.5897, average loss: 26.8152
[11/24 12:36:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 67.03	
[11/24 12:36:54 visual_prompt]: Training 55 / 100 epoch, with learning rate 12.936243708781264
[11/24 12:44:13 visual_prompt]: Epoch 55 / 100: avg data time: 4.83e+00, avg batch time: 6.2832, average train loss: 11.5853
[11/24 12:45:03 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.5846, average loss: 1.6903
[11/24 12:45:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.47	rocauc: 64.94	
[11/24 12:45:03 visual_prompt]: Training 56 / 100 epoch, with learning rate 12.5
[11/24 12:52:25 visual_prompt]: Epoch 56 / 100: avg data time: 4.85e+00, avg batch time: 6.3005, average train loss: 3.3948
[11/24 12:53:14 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.5831, average loss: 3.6458
[11/24 12:53:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.44	
[11/24 12:53:14 visual_prompt]: Training 57 / 100 epoch, with learning rate 12.063756291218741
[11/24 13:00:34 visual_prompt]: Epoch 57 / 100: avg data time: 4.83e+00, avg batch time: 6.2789, average train loss: 7.9843
[11/24 13:01:25 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.5862, average loss: 20.9372
[11/24 13:01:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 63.85	
[11/24 13:01:25 visual_prompt]: Training 58 / 100 epoch, with learning rate 11.628044078198434
[11/24 13:08:46 visual_prompt]: Epoch 58 / 100: avg data time: 4.85e+00, avg batch time: 6.2974, average train loss: 7.7748
[11/24 13:09:36 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.5836, average loss: 18.4434
[11/24 13:09:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 64.90	
[11/24 13:09:36 visual_prompt]: Training 59 / 100 epoch, with learning rate 11.193394209154334
[11/24 13:16:57 visual_prompt]: Epoch 59 / 100: avg data time: 4.85e+00, avg batch time: 6.3000, average train loss: 9.6328
[11/24 13:17:48 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.5855, average loss: 1.6665
[11/24 13:17:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 50.81	rocauc: 66.93	
[11/24 13:17:48 visual_prompt]: Training 60 / 100 epoch, with learning rate 10.760336237999185
[11/24 13:25:15 visual_prompt]: Epoch 60 / 100: avg data time: 4.92e+00, avg batch time: 6.3742, average train loss: 6.4325
[11/24 13:26:06 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.5863, average loss: 2.5907
[11/24 13:26:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 65.58	
[11/24 13:26:06 visual_prompt]: Training 61 / 100 epoch, with learning rate 10.32939777916337
[11/24 13:33:33 visual_prompt]: Epoch 61 / 100: avg data time: 4.94e+00, avg batch time: 6.3879, average train loss: 6.2665
[11/24 13:34:24 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.5891, average loss: 12.3742
[11/24 13:34:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 66.05	
[11/24 13:34:24 visual_prompt]: Training 62 / 100 epoch, with learning rate 9.90110386477801
[11/24 13:41:51 visual_prompt]: Epoch 62 / 100: avg data time: 4.93e+00, avg batch time: 6.3819, average train loss: 4.7121
[11/24 13:42:42 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.5865, average loss: 1.1892
[11/24 13:42:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 50.81	rocauc: 68.58	
[11/24 13:42:42 visual_prompt]: Best epoch 62: best metric: -1.189
[11/24 13:42:42 visual_prompt]: Training 63 / 100 epoch, with learning rate 9.475976305004155
[11/24 13:50:10 visual_prompt]: Epoch 63 / 100: avg data time: 4.94e+00, avg batch time: 6.3944, average train loss: 5.7413
[11/24 13:51:00 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.5864, average loss: 3.0515
[11/24 13:51:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 66.62	
[11/24 13:51:00 visual_prompt]: Training 64 / 100 epoch, with learning rate 9.05453305228751
[11/24 13:58:28 visual_prompt]: Epoch 64 / 100: avg data time: 4.95e+00, avg batch time: 6.3943, average train loss: 3.8286
[11/24 13:59:19 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.5863, average loss: 1.9961
[11/24 13:59:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 52.44	rocauc: 66.94	
[11/24 13:59:19 visual_prompt]: Training 65 / 100 epoch, with learning rate 8.637287570313159
[11/24 14:06:48 visual_prompt]: Epoch 65 / 100: avg data time: 4.95e+00, avg batch time: 6.4041, average train loss: 3.0184
[11/24 14:07:39 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.5868, average loss: 10.6221
[11/24 14:07:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 69.21	
[11/24 14:07:39 visual_prompt]: Training 66 / 100 epoch, with learning rate 8.224748208429142
[11/24 14:15:08 visual_prompt]: Epoch 66 / 100: avg data time: 4.95e+00, avg batch time: 6.4071, average train loss: 4.6698
[11/24 14:15:59 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.5831, average loss: 0.6584
[11/24 14:15:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 68.57	
[11/24 14:15:59 visual_prompt]: Best epoch 66: best metric: -0.658
[11/24 14:15:59 visual_prompt]: Training 67 / 100 epoch, with learning rate 7.817417582301099
[11/24 14:23:25 visual_prompt]: Epoch 67 / 100: avg data time: 4.93e+00, avg batch time: 6.3789, average train loss: 4.8385
[11/24 14:24:17 visual_prompt]: Inference (val):avg data time: 3.03e-03, avg batch time: 0.5903, average loss: 5.2117
[11/24 14:24:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.47	rocauc: 66.61	
[11/24 14:24:17 visual_prompt]: Training 68 / 100 epoch, with learning rate 7.415791961552499
[11/24 14:31:43 visual_prompt]: Epoch 68 / 100: avg data time: 4.93e+00, avg batch time: 6.3810, average train loss: 3.4332
[11/24 14:32:35 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.5906, average loss: 3.7470
[11/24 14:32:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 68.33	
[11/24 14:32:35 visual_prompt]: Training 69 / 100 epoch, with learning rate 7.020360665136531
[11/24 14:40:04 visual_prompt]: Epoch 69 / 100: avg data time: 4.95e+00, avg batch time: 6.4068, average train loss: 2.8739
[11/24 14:40:55 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.5877, average loss: 2.3747
[11/24 14:40:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.07	rocauc: 67.67	
[11/24 14:40:55 visual_prompt]: Training 70 / 100 epoch, with learning rate 6.631605465176368
[11/24 14:48:24 visual_prompt]: Epoch 70 / 100: avg data time: 4.96e+00, avg batch time: 6.4105, average train loss: 2.2298
[11/24 14:49:16 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.5849, average loss: 8.7844
[11/24 14:49:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 68.37	
[11/24 14:49:16 visual_prompt]: Training 71 / 100 epoch, with learning rate 6.250000000000003
[11/24 14:56:43 visual_prompt]: Epoch 71 / 100: avg data time: 4.94e+00, avg batch time: 6.3890, average train loss: 3.1477
[11/24 14:57:35 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.5847, average loss: 2.2009
[11/24 14:57:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 70.43	
[11/24 14:57:35 visual_prompt]: Training 72 / 100 epoch, with learning rate 5.87600919708494
[11/24 15:05:08 visual_prompt]: Epoch 72 / 100: avg data time: 5.01e+00, avg batch time: 6.4670, average train loss: 1.8570
[11/24 15:06:00 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.5877, average loss: 1.9290
[11/24 15:06:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 67.37	
[11/24 15:06:00 visual_prompt]: Training 73 / 100 epoch, with learning rate 5.510088706615666
[11/24 15:13:34 visual_prompt]: Epoch 73 / 100: avg data time: 5.04e+00, avg batch time: 6.4912, average train loss: 1.5541
[11/24 15:14:26 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.5853, average loss: 1.7137
[11/24 15:14:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 68.58	
[11/24 15:14:26 visual_prompt]: Training 74 / 100 epoch, with learning rate 5.1526843463440875
[11/24 15:22:00 visual_prompt]: Epoch 74 / 100: avg data time: 5.03e+00, avg batch time: 6.4831, average train loss: 1.4742
[11/24 15:22:52 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.5853, average loss: 0.9253
[11/24 15:22:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 52.85	rocauc: 70.53	
[11/24 15:22:52 visual_prompt]: Training 75 / 100 epoch, with learning rate 4.804231558429271
[11/24 15:30:26 visual_prompt]: Epoch 75 / 100: avg data time: 5.04e+00, avg batch time: 6.4892, average train loss: 1.3149
[11/24 15:31:18 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.5954, average loss: 2.1668
[11/24 15:31:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 70.65	
[11/24 15:31:18 visual_prompt]: Training 76 / 100 epoch, with learning rate 4.465154878918258
[11/24 15:38:52 visual_prompt]: Epoch 76 / 100: avg data time: 5.02e+00, avg batch time: 6.4761, average train loss: 1.7072
[11/24 15:39:44 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.5868, average loss: 0.8982
[11/24 15:39:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 69.01	
[11/24 15:39:44 visual_prompt]: Training 77 / 100 epoch, with learning rate 4.135867420514276
[11/24 15:47:19 visual_prompt]: Epoch 77 / 100: avg data time: 5.05e+00, avg batch time: 6.4964, average train loss: 1.8437
[11/24 15:48:11 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.5870, average loss: 1.1184
[11/24 15:48:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 70.16	
[11/24 15:48:11 visual_prompt]: Training 78 / 100 epoch, with learning rate 3.816770369262533
[11/24 15:55:44 visual_prompt]: Epoch 78 / 100: avg data time: 5.01e+00, avg batch time: 6.4652, average train loss: 1.3423
[11/24 15:56:36 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.5847, average loss: 2.6291
[11/24 15:56:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 71.57	
[11/24 15:56:36 visual_prompt]: Training 79 / 100 epoch, with learning rate 3.508252495766863
[11/24 16:04:08 visual_prompt]: Epoch 79 / 100: avg data time: 5.01e+00, avg batch time: 6.4647, average train loss: 1.3560
[11/24 16:05:00 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.5914, average loss: 2.1621
[11/24 16:05:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 70.01	
[11/24 16:05:00 visual_prompt]: Training 80 / 100 epoch, with learning rate 3.2106896815325707
[11/24 16:12:32 visual_prompt]: Epoch 80 / 100: avg data time: 5.01e+00, avg batch time: 6.4614, average train loss: 0.9738
[11/24 16:13:24 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.5897, average loss: 0.8357
[11/24 16:13:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 52.03	rocauc: 70.41	
[11/24 16:13:24 visual_prompt]: Training 81 / 100 epoch, with learning rate 2.924444461012776
[11/24 16:20:53 visual_prompt]: Epoch 81 / 100: avg data time: 4.96e+00, avg batch time: 6.4088, average train loss: 1.0392
[11/24 16:21:44 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.5859, average loss: 1.4842
[11/24 16:21:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 70.96	
[11/24 16:21:44 visual_prompt]: Training 82 / 100 epoch, with learning rate 2.6498655799159763
[11/24 16:29:13 visual_prompt]: Epoch 82 / 100: avg data time: 4.96e+00, avg batch time: 6.4151, average train loss: 1.0679
[11/24 16:30:04 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.5862, average loss: 2.1903
[11/24 16:30:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 70.13	
[11/24 16:30:04 visual_prompt]: Training 83 / 100 epoch, with learning rate 2.387287570313158
[11/24 16:37:32 visual_prompt]: Epoch 83 / 100: avg data time: 4.94e+00, avg batch time: 6.3886, average train loss: 1.1526
[11/24 16:38:23 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.5836, average loss: 1.3204
[11/24 16:38:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 70.18	
[11/24 16:38:23 visual_prompt]: Training 84 / 100 epoch, with learning rate 2.13703034306198
[11/24 16:45:52 visual_prompt]: Epoch 84 / 100: avg data time: 4.97e+00, avg batch time: 6.4186, average train loss: 0.8281
[11/24 16:46:44 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.5860, average loss: 1.5813
[11/24 16:46:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 70.35	
[11/24 16:46:44 visual_prompt]: Training 85 / 100 epoch, with learning rate 1.8993987980446756
[11/24 16:54:13 visual_prompt]: Epoch 85 / 100: avg data time: 4.97e+00, avg batch time: 6.4215, average train loss: 0.8609
[11/24 16:55:04 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.5903, average loss: 0.6442
[11/24 16:55:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 70.26	
[11/24 16:55:04 visual_prompt]: Best epoch 85: best metric: -0.644
[11/24 16:55:04 visual_prompt]: Training 86 / 100 epoch, with learning rate 1.674682452694516
[11/24 17:02:33 visual_prompt]: Epoch 86 / 100: avg data time: 4.96e+00, avg batch time: 6.4064, average train loss: 0.8373
[11/24 17:03:24 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.5903, average loss: 0.6706
[11/24 17:03:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 69.09	
[11/24 17:03:24 visual_prompt]: Training 87 / 100 epoch, with learning rate 1.4631550892634126
[11/24 17:10:54 visual_prompt]: Epoch 87 / 100: avg data time: 4.96e+00, avg batch time: 6.4203, average train loss: 0.9047
[11/24 17:11:45 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.5882, average loss: 0.7158
[11/24 17:11:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 69.23	
[11/24 17:11:45 visual_prompt]: Training 88 / 100 epoch, with learning rate 1.2650744212604148
[11/24 17:19:14 visual_prompt]: Epoch 88 / 100: avg data time: 4.97e+00, avg batch time: 6.4189, average train loss: 0.8010
[11/24 17:20:06 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.5879, average loss: 0.7413
[11/24 17:20:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 69.24	
[11/24 17:20:06 visual_prompt]: Training 89 / 100 epoch, with learning rate 1.0806817794674877
[11/24 17:27:36 visual_prompt]: Epoch 89 / 100: avg data time: 4.97e+00, avg batch time: 6.4235, average train loss: 0.7841
[11/24 17:28:28 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.5860, average loss: 0.7806
[11/24 17:28:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 69.15	
[11/24 17:28:28 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.9102018179151585
[11/24 17:36:02 visual_prompt]: Epoch 90 / 100: avg data time: 5.03e+00, avg batch time: 6.4815, average train loss: 0.7971
[11/24 17:36:53 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.5866, average loss: 1.0313
[11/24 17:36:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.07	rocauc: 69.61	
[11/24 17:36:53 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.753842240176146
[11/24 17:44:26 visual_prompt]: Epoch 91 / 100: avg data time: 5.01e+00, avg batch time: 6.4723, average train loss: 0.7609
[11/24 17:45:18 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.5851, average loss: 0.6365
[11/24 17:45:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 69.70	
[11/24 17:45:18 visual_prompt]: Best epoch 91: best metric: -0.636
[11/24 17:45:18 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.6117935463105808
[11/24 17:52:52 visual_prompt]: Epoch 92 / 100: avg data time: 5.03e+00, avg batch time: 6.4842, average train loss: 0.7925
[11/24 17:53:44 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.5853, average loss: 0.8278
[11/24 17:53:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 69.53	
[11/24 17:53:44 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.4842288007710138
[11/24 18:01:17 visual_prompt]: Epoch 93 / 100: avg data time: 5.01e+00, avg batch time: 6.4628, average train loss: 0.6733
[11/24 18:02:08 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.5866, average loss: 0.6507
[11/24 18:02:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 69.48	
[11/24 18:02:08 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.3713034215500441
[11/24 18:09:41 visual_prompt]: Epoch 94 / 100: avg data time: 5.02e+00, avg batch time: 6.4686, average train loss: 0.6611
[11/24 18:10:32 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.5872, average loss: 0.6398
[11/24 18:10:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 69.52	
[11/24 18:10:32 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.2731549908274289
[11/24 18:18:02 visual_prompt]: Epoch 95 / 100: avg data time: 4.97e+00, avg batch time: 6.4198, average train loss: 0.6649
[11/24 18:18:53 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.5857, average loss: 0.6390
[11/24 18:18:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 69.44	
[11/24 18:18:53 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.18990308734739975
[11/24 18:26:21 visual_prompt]: Epoch 96 / 100: avg data time: 4.95e+00, avg batch time: 6.4016, average train loss: 0.6656
[11/24 18:27:13 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.5858, average loss: 0.6433
[11/24 18:27:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 69.50	
[11/24 18:27:13 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.12164914073037048
[11/24 18:34:41 visual_prompt]: Epoch 97 / 100: avg data time: 4.95e+00, avg batch time: 6.3966, average train loss: 0.6581
[11/24 18:35:32 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.5845, average loss: 0.6675
[11/24 18:35:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 69.46	
[11/24 18:35:32 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.06847630789658388
[11/24 18:43:01 visual_prompt]: Epoch 98 / 100: avg data time: 4.97e+00, avg batch time: 6.4206, average train loss: 0.6670
[11/24 18:43:52 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.5843, average loss: 0.6761
[11/24 18:43:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 69.48	
[11/24 18:43:52 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.03044937175219753
[11/24 18:51:20 visual_prompt]: Epoch 99 / 100: avg data time: 4.94e+00, avg batch time: 6.3953, average train loss: 0.6588
[11/24 18:52:11 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.5860, average loss: 0.6486
[11/24 18:52:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 69.49	
[11/24 18:52:11 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0076146622613029735
[11/24 18:59:40 visual_prompt]: Epoch 100 / 100: avg data time: 4.96e+00, avg batch time: 6.4141, average train loss: 0.6558
[11/24 19:00:32 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.5895, average loss: 0.6499
[11/24 19:00:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 69.48	
[11/24 19:00:32 visual_prompt]: Rank of current process: 0. World size: 1
[11/24 19:00:32 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/24 19:00:32 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/24 19:00:32 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/24 19:00:32 visual_prompt]: Training with config:
[11/24 19:00:32 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr10.0_wd0.01/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 10.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/24 19:00:32 visual_prompt]: Loading training data...
[11/24 19:00:32 visual_prompt]: Constructing mammo-cbis dataset train...
[11/24 19:00:32 visual_prompt]: Loading validation data...
[11/24 19:00:32 visual_prompt]: Constructing mammo-cbis dataset val...
[11/24 19:00:32 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/24 19:00:34 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/24 19:00:34 visual_prompt]: tuned percent:0.532
[11/24 19:00:34 visual_prompt]: Device used for model: 0
[11/24 19:00:34 visual_prompt]: Setting up Evaluator...
[11/24 19:00:34 visual_prompt]: Setting up Trainer...
[11/24 19:00:34 visual_prompt]: 	Setting up the optimizer...
[11/24 19:00:34 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/24 19:08:04 visual_prompt]: Epoch 1 / 100: avg data time: 4.97e+00, avg batch time: 6.4265, average train loss: 1.4863
[11/24 19:08:56 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.5877, average loss: 1.4553
[11/24 19:08:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/24 19:08:56 visual_prompt]: Training 2 / 100 epoch, with learning rate 1.0
[11/24 19:16:25 visual_prompt]: Epoch 2 / 100: avg data time: 4.96e+00, avg batch time: 6.4170, average train loss: 4.2628
[11/24 19:17:17 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.5887, average loss: 3.0798
[11/24 19:17:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.96	
[11/24 19:17:17 visual_prompt]: Training 3 / 100 epoch, with learning rate 2.0
[11/24 19:24:46 visual_prompt]: Epoch 3 / 100: avg data time: 4.96e+00, avg batch time: 6.4179, average train loss: 2.8057
[11/24 19:25:37 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.5849, average loss: 5.1767
[11/24 19:25:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.32	
[11/24 19:25:37 visual_prompt]: Training 4 / 100 epoch, with learning rate 3.0
[11/24 19:33:04 visual_prompt]: Epoch 4 / 100: avg data time: 4.93e+00, avg batch time: 6.3854, average train loss: 6.0841
[11/24 19:33:56 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.5877, average loss: 1.0925
[11/24 19:33:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.41	
[11/24 19:33:56 visual_prompt]: Training 5 / 100 epoch, with learning rate 4.0
[11/24 19:41:23 visual_prompt]: Epoch 5 / 100: avg data time: 4.94e+00, avg batch time: 6.3909, average train loss: 9.0258
[11/24 19:42:14 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.5892, average loss: 4.7054
[11/24 19:42:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.99	
[11/24 19:42:14 visual_prompt]: Training 6 / 100 epoch, with learning rate 5.0
[11/24 19:49:43 visual_prompt]: Epoch 6 / 100: avg data time: 4.96e+00, avg batch time: 6.4155, average train loss: 7.8715
[11/24 19:50:35 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.5852, average loss: 7.6205
[11/24 19:50:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.77	
[11/24 19:50:35 visual_prompt]: Training 7 / 100 epoch, with learning rate 6.0
[11/24 19:58:01 visual_prompt]: Epoch 7 / 100: avg data time: 4.91e+00, avg batch time: 6.3667, average train loss: 11.8376
[11/24 19:58:52 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.5862, average loss: 8.5169
[11/24 19:58:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.50	
[11/24 19:58:52 visual_prompt]: Training 8 / 100 epoch, with learning rate 7.0
[11/24 20:06:15 visual_prompt]: Epoch 8 / 100: avg data time: 4.88e+00, avg batch time: 6.3255, average train loss: 16.9194
[11/24 20:07:06 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.5855, average loss: 24.7710
[11/24 20:07:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 42.84	
[11/24 20:07:06 visual_prompt]: Training 9 / 100 epoch, with learning rate 8.0
[11/24 20:14:30 visual_prompt]: Epoch 9 / 100: avg data time: 4.89e+00, avg batch time: 6.3435, average train loss: 19.4422
[11/24 20:15:21 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.5904, average loss: 30.7351
[11/24 20:15:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.60	
[11/24 20:15:21 visual_prompt]: Training 10 / 100 epoch, with learning rate 9.0
[11/24 20:22:46 visual_prompt]: Epoch 10 / 100: avg data time: 4.90e+00, avg batch time: 6.3536, average train loss: 20.7824
[11/24 20:23:36 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.5877, average loss: 33.1404
[11/24 20:23:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.34	
[11/24 20:23:36 visual_prompt]: Training 11 / 100 epoch, with learning rate 10.0
[11/24 20:31:04 visual_prompt]: Epoch 11 / 100: avg data time: 4.94e+00, avg batch time: 6.3859, average train loss: 21.0017
[11/24 20:31:55 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.5891, average loss: 24.1618
[11/24 20:31:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.44	
[11/24 20:31:55 visual_prompt]: Training 12 / 100 epoch, with learning rate 9.996954135095478
[11/24 20:39:21 visual_prompt]: Epoch 12 / 100: avg data time: 4.93e+00, avg batch time: 6.3797, average train loss: 25.9167
[11/24 20:40:12 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.5887, average loss: 19.8308
[11/24 20:40:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.68	
[11/24 20:40:12 visual_prompt]: Best epoch 12: best metric: -19.831
[11/24 20:40:12 visual_prompt]: Training 13 / 100 epoch, with learning rate 9.987820251299121
[11/24 20:47:40 visual_prompt]: Epoch 13 / 100: avg data time: 4.95e+00, avg batch time: 6.3961, average train loss: 28.3131
[11/24 20:48:31 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.5868, average loss: 11.1644
[11/24 20:48:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 55.78	
[11/24 20:48:31 visual_prompt]: Best epoch 13: best metric: -11.164
[11/24 20:48:31 visual_prompt]: Training 14 / 100 epoch, with learning rate 9.972609476841367
[11/24 20:55:58 visual_prompt]: Epoch 14 / 100: avg data time: 4.94e+00, avg batch time: 6.3844, average train loss: 19.9398
[11/24 20:56:49 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.5872, average loss: 3.8987
[11/24 20:56:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.57	
[11/24 20:56:49 visual_prompt]: Best epoch 14: best metric: -3.899
[11/24 20:56:49 visual_prompt]: Training 15 / 100 epoch, with learning rate 9.951340343707852
[11/24 21:04:16 visual_prompt]: Epoch 15 / 100: avg data time: 4.93e+00, avg batch time: 6.3883, average train loss: 17.1764
[11/24 21:05:08 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.5856, average loss: 26.4822
[11/24 21:05:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 41.06	rocauc: 40.92	
[11/24 21:05:08 visual_prompt]: Training 16 / 100 epoch, with learning rate 9.924038765061042
[11/24 21:12:36 visual_prompt]: Epoch 16 / 100: avg data time: 4.95e+00, avg batch time: 6.4020, average train loss: 22.4121
[11/24 21:13:27 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.5892, average loss: 9.6794
[11/24 21:13:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 43.11	
[11/24 21:13:27 visual_prompt]: Training 17 / 100 epoch, with learning rate 9.890738003669028
[11/24 21:20:54 visual_prompt]: Epoch 17 / 100: avg data time: 4.93e+00, avg batch time: 6.3842, average train loss: 17.7470
[11/24 21:21:45 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.5872, average loss: 25.9551
[11/24 21:21:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.43	
[11/24 21:21:45 visual_prompt]: Training 18 / 100 epoch, with learning rate 9.851478631379981
[11/24 21:29:13 visual_prompt]: Epoch 18 / 100: avg data time: 4.95e+00, avg batch time: 6.4043, average train loss: 20.3399
[11/24 21:30:05 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.5870, average loss: 71.2985
[11/24 21:30:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.03	
[11/24 21:30:05 visual_prompt]: Training 19 / 100 epoch, with learning rate 9.806308479691594
[11/24 21:37:32 visual_prompt]: Epoch 19 / 100: avg data time: 4.93e+00, avg batch time: 6.3849, average train loss: 18.2647
[11/24 21:38:22 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.5860, average loss: 9.5806
[11/24 21:38:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.06	
[11/24 21:38:22 visual_prompt]: Training 20 / 100 epoch, with learning rate 9.755282581475768
[11/24 21:45:50 visual_prompt]: Epoch 20 / 100: avg data time: 4.94e+00, avg batch time: 6.3912, average train loss: 25.2810
[11/24 21:46:41 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.5875, average loss: 22.5832
[11/24 21:46:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 41.03	
[11/24 21:46:41 visual_prompt]: Training 21 / 100 epoch, with learning rate 9.698463103929543
[11/24 21:54:09 visual_prompt]: Epoch 21 / 100: avg data time: 4.95e+00, avg batch time: 6.4044, average train loss: 21.7394
[11/24 21:55:00 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.5907, average loss: 24.3224
[11/24 21:55:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 44.05	
[11/24 21:55:00 visual_prompt]: Training 22 / 100 epoch, with learning rate 9.635919272833938
[11/24 22:02:30 visual_prompt]: Epoch 22 / 100: avg data time: 4.98e+00, avg batch time: 6.4273, average train loss: 35.5453
[11/24 22:03:21 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.5877, average loss: 6.4928
[11/24 22:03:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.24	
[11/24 22:03:21 visual_prompt]: Training 23 / 100 epoch, with learning rate 9.567727288213003
[11/24 22:10:49 visual_prompt]: Epoch 23 / 100: avg data time: 4.95e+00, avg batch time: 6.4014, average train loss: 21.4196
[11/24 22:11:40 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.5893, average loss: 17.7449
[11/24 22:11:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 39.61	
[11/24 22:11:40 visual_prompt]: Training 24 / 100 epoch, with learning rate 9.493970231495835
[11/24 22:19:08 visual_prompt]: Epoch 24 / 100: avg data time: 4.94e+00, avg batch time: 6.3859, average train loss: 23.0666
[11/24 22:19:59 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.5857, average loss: 69.2306
[11/24 22:19:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.45	
[11/24 22:19:59 visual_prompt]: Training 25 / 100 epoch, with learning rate 9.414737964294634
[11/24 22:27:27 visual_prompt]: Epoch 25 / 100: avg data time: 4.95e+00, avg batch time: 6.3987, average train loss: 27.6949
[11/24 22:28:18 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.5892, average loss: 70.0105
[11/24 22:28:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.41	
[11/24 22:28:18 visual_prompt]: Training 26 / 100 epoch, with learning rate 9.330127018922195
[11/24 22:35:44 visual_prompt]: Epoch 26 / 100: avg data time: 4.92e+00, avg batch time: 6.3697, average train loss: 21.9503
[11/24 22:36:35 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.5920, average loss: 28.9259
[11/24 22:36:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.27	
[11/24 22:36:35 visual_prompt]: Training 27 / 100 epoch, with learning rate 9.240240480782129
[11/24 22:43:59 visual_prompt]: Epoch 27 / 100: avg data time: 4.89e+00, avg batch time: 6.3396, average train loss: 23.8609
[11/24 22:44:50 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.5890, average loss: 15.4007
[11/24 22:44:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.99	
[11/24 22:44:50 visual_prompt]: Training 28 / 100 epoch, with learning rate 9.145187862775208
[11/24 22:52:16 visual_prompt]: Epoch 28 / 100: avg data time: 4.92e+00, avg batch time: 6.3711, average train loss: 23.3968
[11/24 22:53:07 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.5887, average loss: 18.5482
[11/24 22:53:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.14	
[11/24 22:53:07 visual_prompt]: Training 29 / 100 epoch, with learning rate 9.045084971874736
[11/24 23:00:31 visual_prompt]: Epoch 29 / 100: avg data time: 4.88e+00, avg batch time: 6.3308, average train loss: 21.5869
[11/24 23:01:21 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.5883, average loss: 35.3483
[11/24 23:01:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.90	
[11/24 23:01:21 visual_prompt]: Training 30 / 100 epoch, with learning rate 8.940053768033609
[11/24 23:08:42 visual_prompt]: Epoch 30 / 100: avg data time: 4.85e+00, avg batch time: 6.3027, average train loss: 24.2019
[11/24 23:09:33 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.5904, average loss: 29.9047
[11/24 23:09:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 44.08	
[11/24 23:09:33 visual_prompt]: Training 31 / 100 epoch, with learning rate 8.83022221559489
[11/24 23:16:52 visual_prompt]: Epoch 31 / 100: avg data time: 4.82e+00, avg batch time: 6.2667, average train loss: 29.6167
[11/24 23:17:42 visual_prompt]: Inference (val):avg data time: 3.77e-05, avg batch time: 0.5873, average loss: 27.7486
[11/24 23:17:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 44.74	
[11/24 23:17:42 visual_prompt]: Training 32 / 100 epoch, with learning rate 8.715724127386972
[11/24 23:25:04 visual_prompt]: Epoch 32 / 100: avg data time: 4.85e+00, avg batch time: 6.3071, average train loss: 20.4995
[11/24 23:25:55 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.5885, average loss: 4.1891
[11/24 23:25:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.97	
[11/24 23:25:55 visual_prompt]: Training 33 / 100 epoch, with learning rate 8.596699001693256
[11/24 23:33:14 visual_prompt]: Epoch 33 / 100: avg data time: 4.82e+00, avg batch time: 6.2692, average train loss: 23.4257
[11/24 23:34:04 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.5855, average loss: 14.4127
[11/24 23:34:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 42.88	
[11/24 23:34:04 visual_prompt]: Training 34 / 100 epoch, with learning rate 8.473291852294986
[11/24 23:41:23 visual_prompt]: Epoch 34 / 100: avg data time: 4.82e+00, avg batch time: 6.2720, average train loss: 19.1444
[11/24 23:42:14 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.5884, average loss: 4.6434
[11/24 23:42:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.08	
[11/24 23:42:14 visual_prompt]: Training 35 / 100 epoch, with learning rate 8.345653031794292
[11/24 23:49:34 visual_prompt]: Epoch 35 / 100: avg data time: 4.83e+00, avg batch time: 6.2820, average train loss: 16.8090
[11/24 23:50:24 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.5905, average loss: 23.9573
[11/24 23:50:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.90	
[11/24 23:50:24 visual_prompt]: Stopping early.
[11/24 23:50:24 visual_prompt]: Rank of current process: 0. World size: 1
[11/24 23:50:24 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/24 23:50:24 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/24 23:50:24 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/24 23:50:24 visual_prompt]: Training with config:
[11/24 23:50:24 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr10.0_wd0.001/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 10.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/24 23:50:24 visual_prompt]: Loading training data...
[11/24 23:50:24 visual_prompt]: Constructing mammo-cbis dataset train...
[11/24 23:50:24 visual_prompt]: Loading validation data...
[11/24 23:50:24 visual_prompt]: Constructing mammo-cbis dataset val...
[11/24 23:50:24 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/24 23:50:27 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/24 23:50:27 visual_prompt]: tuned percent:0.532
[11/24 23:50:27 visual_prompt]: Device used for model: 0
[11/24 23:50:27 visual_prompt]: Setting up Evaluator...
[11/24 23:50:27 visual_prompt]: Setting up Trainer...
[11/24 23:50:27 visual_prompt]: 	Setting up the optimizer...
[11/24 23:50:27 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/24 23:57:51 visual_prompt]: Epoch 1 / 100: avg data time: 4.88e+00, avg batch time: 6.3336, average train loss: 1.4863
[11/24 23:58:42 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.5872, average loss: 1.4553
[11/24 23:58:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/24 23:58:42 visual_prompt]: Training 2 / 100 epoch, with learning rate 1.0
[11/25 00:06:04 visual_prompt]: Epoch 2 / 100: avg data time: 4.87e+00, avg batch time: 6.3242, average train loss: 3.6290
[11/25 00:06:55 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.5849, average loss: 0.7015
[11/25 00:06:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.64	
[11/25 00:06:56 visual_prompt]: Training 3 / 100 epoch, with learning rate 2.0
[11/25 00:14:19 visual_prompt]: Epoch 3 / 100: avg data time: 4.88e+00, avg batch time: 6.3362, average train loss: 3.3315
[11/25 00:15:10 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.5851, average loss: 6.6219
[11/25 00:15:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.92	
[11/25 00:15:10 visual_prompt]: Training 4 / 100 epoch, with learning rate 3.0
[11/25 00:22:36 visual_prompt]: Epoch 4 / 100: avg data time: 4.92e+00, avg batch time: 6.3700, average train loss: 4.5911
[11/25 00:23:27 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.5849, average loss: 18.1257
[11/25 00:23:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.95	
[11/25 00:23:27 visual_prompt]: Training 5 / 100 epoch, with learning rate 4.0
[11/25 00:30:51 visual_prompt]: Epoch 5 / 100: avg data time: 4.90e+00, avg batch time: 6.3491, average train loss: 9.1223
[11/25 00:31:42 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.5864, average loss: 9.0045
[11/25 00:31:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.47	
[11/25 00:31:42 visual_prompt]: Training 6 / 100 epoch, with learning rate 5.0
[11/25 00:39:10 visual_prompt]: Epoch 6 / 100: avg data time: 4.95e+00, avg batch time: 6.4003, average train loss: 4.2861
[11/25 00:40:01 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.5885, average loss: 12.1229
[11/25 00:40:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.81	
[11/25 00:40:01 visual_prompt]: Training 7 / 100 epoch, with learning rate 6.0
[11/25 00:47:29 visual_prompt]: Epoch 7 / 100: avg data time: 4.94e+00, avg batch time: 6.3950, average train loss: 8.5586
[11/25 00:48:20 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.5905, average loss: 1.7698
[11/25 00:48:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 41.86	
[11/25 00:48:20 visual_prompt]: Training 8 / 100 epoch, with learning rate 7.0
[11/25 00:55:48 visual_prompt]: Epoch 8 / 100: avg data time: 4.95e+00, avg batch time: 6.3991, average train loss: 11.6387
[11/25 00:56:39 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.5901, average loss: 23.7068
[11/25 00:56:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.93	
[11/25 00:56:39 visual_prompt]: Training 9 / 100 epoch, with learning rate 8.0
[11/25 01:04:07 visual_prompt]: Epoch 9 / 100: avg data time: 4.94e+00, avg batch time: 6.3906, average train loss: 19.9712
[11/25 01:04:58 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.5891, average loss: 10.6126
[11/25 01:04:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.46	
[11/25 01:04:58 visual_prompt]: Training 10 / 100 epoch, with learning rate 9.0
[11/25 01:12:24 visual_prompt]: Epoch 10 / 100: avg data time: 4.91e+00, avg batch time: 6.3683, average train loss: 11.6369
[11/25 01:13:15 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.5896, average loss: 25.8073
[11/25 01:13:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.33	
[11/25 01:13:15 visual_prompt]: Training 11 / 100 epoch, with learning rate 10.0
[11/25 01:20:42 visual_prompt]: Epoch 11 / 100: avg data time: 4.95e+00, avg batch time: 6.3934, average train loss: 17.4059
[11/25 01:21:33 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.5868, average loss: 9.1535
[11/25 01:21:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.11	
[11/25 01:21:33 visual_prompt]: Training 12 / 100 epoch, with learning rate 9.996954135095478
[11/25 01:29:01 visual_prompt]: Epoch 12 / 100: avg data time: 4.95e+00, avg batch time: 6.3969, average train loss: 20.5649
[11/25 01:29:52 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.5859, average loss: 16.1951
[11/25 01:29:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 42.04	
[11/25 01:29:52 visual_prompt]: Training 13 / 100 epoch, with learning rate 9.987820251299121
[11/25 01:37:20 visual_prompt]: Epoch 13 / 100: avg data time: 4.95e+00, avg batch time: 6.3976, average train loss: 20.7172
[11/25 01:38:12 visual_prompt]: Inference (val):avg data time: 7.79e-05, avg batch time: 0.5895, average loss: 20.2129
[11/25 01:38:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.94	
[11/25 01:38:12 visual_prompt]: Training 14 / 100 epoch, with learning rate 9.972609476841367
[11/25 01:45:38 visual_prompt]: Epoch 14 / 100: avg data time: 4.92e+00, avg batch time: 6.3694, average train loss: 29.2269
[11/25 01:46:28 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.5892, average loss: 12.0221
[11/25 01:46:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.45	
[11/25 01:46:28 visual_prompt]: Training 15 / 100 epoch, with learning rate 9.951340343707852
[11/25 01:53:56 visual_prompt]: Epoch 15 / 100: avg data time: 4.94e+00, avg batch time: 6.3988, average train loss: 16.4286
[11/25 01:54:48 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.5862, average loss: 41.7761
[11/25 01:54:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.62	
[11/25 01:54:48 visual_prompt]: Training 16 / 100 epoch, with learning rate 9.924038765061042
[11/25 02:02:16 visual_prompt]: Epoch 16 / 100: avg data time: 4.95e+00, avg batch time: 6.3989, average train loss: 26.0824
[11/25 02:03:07 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.5891, average loss: 10.6975
[11/25 02:03:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.44	
[11/25 02:03:07 visual_prompt]: Training 17 / 100 epoch, with learning rate 9.890738003669028
[11/25 02:10:35 visual_prompt]: Epoch 17 / 100: avg data time: 4.94e+00, avg batch time: 6.3925, average train loss: 30.1166
[11/25 02:11:26 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.5932, average loss: 2.9526
[11/25 02:11:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.60	
[11/25 02:11:26 visual_prompt]: Best epoch 17: best metric: -2.953
[11/25 02:11:26 visual_prompt]: Training 18 / 100 epoch, with learning rate 9.851478631379981
[11/25 02:18:54 visual_prompt]: Epoch 18 / 100: avg data time: 4.95e+00, avg batch time: 6.3975, average train loss: 19.3340
[11/25 02:19:45 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.5851, average loss: 6.7008
[11/25 02:19:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.61	
[11/25 02:19:45 visual_prompt]: Training 19 / 100 epoch, with learning rate 9.806308479691594
[11/25 02:27:10 visual_prompt]: Epoch 19 / 100: avg data time: 4.90e+00, avg batch time: 6.3546, average train loss: 15.5036
[11/25 02:28:01 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.5897, average loss: 5.0658
[11/25 02:28:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.26	
[11/25 02:28:01 visual_prompt]: Training 20 / 100 epoch, with learning rate 9.755282581475768
[11/25 02:35:28 visual_prompt]: Epoch 20 / 100: avg data time: 4.94e+00, avg batch time: 6.3888, average train loss: 20.9254
[11/25 02:36:20 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.5870, average loss: 8.0544
[11/25 02:36:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.95	
[11/25 02:36:20 visual_prompt]: Training 21 / 100 epoch, with learning rate 9.698463103929543
[11/25 02:43:46 visual_prompt]: Epoch 21 / 100: avg data time: 4.93e+00, avg batch time: 6.3803, average train loss: 11.6590
[11/25 02:44:38 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.5844, average loss: 31.2982
[11/25 02:44:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.47	
[11/25 02:44:38 visual_prompt]: Training 22 / 100 epoch, with learning rate 9.635919272833938
[11/25 02:52:05 visual_prompt]: Epoch 22 / 100: avg data time: 4.93e+00, avg batch time: 6.3763, average train loss: 20.6247
[11/25 02:52:56 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.5933, average loss: 25.8599
[11/25 02:52:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.85	
[11/25 02:52:56 visual_prompt]: Training 23 / 100 epoch, with learning rate 9.567727288213003
[11/25 03:00:23 visual_prompt]: Epoch 23 / 100: avg data time: 4.93e+00, avg batch time: 6.3781, average train loss: 26.0219
[11/25 03:01:14 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.5868, average loss: 23.6759
[11/25 03:01:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.59	
[11/25 03:01:14 visual_prompt]: Training 24 / 100 epoch, with learning rate 9.493970231495835
[11/25 03:08:36 visual_prompt]: Epoch 24 / 100: avg data time: 4.86e+00, avg batch time: 6.3166, average train loss: 13.6635
[11/25 03:09:27 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.5859, average loss: 10.0365
[11/25 03:09:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.47	
[11/25 03:09:27 visual_prompt]: Training 25 / 100 epoch, with learning rate 9.414737964294634
[11/25 03:16:48 visual_prompt]: Epoch 25 / 100: avg data time: 4.85e+00, avg batch time: 6.2987, average train loss: 17.6200
[11/25 03:17:38 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.5862, average loss: 0.6902
[11/25 03:17:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 57.28	
[11/25 03:17:38 visual_prompt]: Best epoch 25: best metric: -0.690
[11/25 03:17:38 visual_prompt]: Training 26 / 100 epoch, with learning rate 9.330127018922195
[11/25 03:25:00 visual_prompt]: Epoch 26 / 100: avg data time: 4.86e+00, avg batch time: 6.3122, average train loss: 22.7075
[11/25 03:25:51 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.5908, average loss: 6.7935
[11/25 03:25:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.86	
[11/25 03:25:51 visual_prompt]: Training 27 / 100 epoch, with learning rate 9.240240480782129
[11/25 03:33:12 visual_prompt]: Epoch 27 / 100: avg data time: 4.86e+00, avg batch time: 6.3074, average train loss: 26.4200
[11/25 03:34:02 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.5886, average loss: 19.3973
[11/25 03:34:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.33	
[11/25 03:34:02 visual_prompt]: Training 28 / 100 epoch, with learning rate 9.145187862775208
[11/25 03:41:25 visual_prompt]: Epoch 28 / 100: avg data time: 4.86e+00, avg batch time: 6.3143, average train loss: 19.0276
[11/25 03:42:15 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.5868, average loss: 18.1109
[11/25 03:42:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.91	
[11/25 03:42:15 visual_prompt]: Training 29 / 100 epoch, with learning rate 9.045084971874736
[11/25 03:49:36 visual_prompt]: Epoch 29 / 100: avg data time: 4.84e+00, avg batch time: 6.2919, average train loss: 16.6779
[11/25 03:50:26 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.5881, average loss: 59.9815
[11/25 03:50:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.77	
[11/25 03:50:26 visual_prompt]: Training 30 / 100 epoch, with learning rate 8.940053768033609
[11/25 03:57:50 visual_prompt]: Epoch 30 / 100: avg data time: 4.88e+00, avg batch time: 6.3374, average train loss: 21.1487
[11/25 03:58:41 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.5881, average loss: 5.0961
[11/25 03:58:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.28	
[11/25 03:58:41 visual_prompt]: Training 31 / 100 epoch, with learning rate 8.83022221559489
[11/25 04:06:03 visual_prompt]: Epoch 31 / 100: avg data time: 4.86e+00, avg batch time: 6.3120, average train loss: 17.6643
[11/25 04:06:53 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.5893, average loss: 22.5894
[11/25 04:06:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.89	
[11/25 04:06:53 visual_prompt]: Training 32 / 100 epoch, with learning rate 8.715724127386972
[11/25 04:14:18 visual_prompt]: Epoch 32 / 100: avg data time: 4.91e+00, avg batch time: 6.3608, average train loss: 17.2669
[11/25 04:15:09 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.5896, average loss: 79.8224
[11/25 04:15:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.85	
[11/25 04:15:09 visual_prompt]: Training 33 / 100 epoch, with learning rate 8.596699001693256
[11/25 04:22:36 visual_prompt]: Epoch 33 / 100: avg data time: 4.93e+00, avg batch time: 6.3784, average train loss: 17.8570
[11/25 04:23:27 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.5874, average loss: 5.8537
[11/25 04:23:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.80	
[11/25 04:23:27 visual_prompt]: Training 34 / 100 epoch, with learning rate 8.473291852294986
[11/25 04:30:51 visual_prompt]: Epoch 34 / 100: avg data time: 4.89e+00, avg batch time: 6.3474, average train loss: 12.7621
[11/25 04:31:43 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.5856, average loss: 35.0363
[11/25 04:31:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 45.25	
[11/25 04:31:43 visual_prompt]: Training 35 / 100 epoch, with learning rate 8.345653031794292
[11/25 04:39:10 visual_prompt]: Epoch 35 / 100: avg data time: 4.93e+00, avg batch time: 6.3794, average train loss: 11.9029
[11/25 04:40:00 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.5877, average loss: 26.8221
[11/25 04:40:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.32	
[11/25 04:40:00 visual_prompt]: Training 36 / 100 epoch, with learning rate 8.213938048432697
[11/25 04:47:29 visual_prompt]: Epoch 36 / 100: avg data time: 4.95e+00, avg batch time: 6.4016, average train loss: 17.2054
[11/25 04:48:20 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.5872, average loss: 41.0775
[11/25 04:48:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.96	
[11/25 04:48:20 visual_prompt]: Training 37 / 100 epoch, with learning rate 8.078307376628292
[11/25 04:55:47 visual_prompt]: Epoch 37 / 100: avg data time: 4.93e+00, avg batch time: 6.3837, average train loss: 15.1260
[11/25 04:56:38 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.5851, average loss: 4.0567
[11/25 04:56:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.03	
[11/25 04:56:38 visual_prompt]: Training 38 / 100 epoch, with learning rate 7.938926261462366
[11/25 05:04:06 visual_prompt]: Epoch 38 / 100: avg data time: 4.95e+00, avg batch time: 6.3950, average train loss: 12.4601
[11/25 05:04:58 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.5908, average loss: 16.4591
[11/25 05:04:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.95	
[11/25 05:04:58 visual_prompt]: Training 39 / 100 epoch, with learning rate 7.795964517353734
[11/25 05:12:29 visual_prompt]: Epoch 39 / 100: avg data time: 4.99e+00, avg batch time: 6.4432, average train loss: 14.7313
[11/25 05:13:21 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.5879, average loss: 2.9662
[11/25 05:13:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.03	
[11/25 05:13:21 visual_prompt]: Training 40 / 100 epoch, with learning rate 7.649596321166024
[11/25 05:20:52 visual_prompt]: Epoch 40 / 100: avg data time: 5.00e+00, avg batch time: 6.4507, average train loss: 10.9341
[11/25 05:21:44 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.5877, average loss: 12.5913
[11/25 05:21:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.65	
[11/25 05:21:44 visual_prompt]: Training 41 / 100 epoch, with learning rate 7.5
[11/25 05:29:17 visual_prompt]: Epoch 41 / 100: avg data time: 5.01e+00, avg batch time: 6.4652, average train loss: 10.5450
[11/25 05:30:09 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.5875, average loss: 5.2581
[11/25 05:30:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.86	
[11/25 05:30:09 visual_prompt]: Training 42 / 100 epoch, with learning rate 7.347357813929454
[11/25 05:37:42 visual_prompt]: Epoch 42 / 100: avg data time: 5.02e+00, avg batch time: 6.4768, average train loss: 10.4594
[11/25 05:38:34 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.5852, average loss: 13.0582
[11/25 05:38:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.07	
[11/25 05:38:34 visual_prompt]: Training 43 / 100 epoch, with learning rate 7.191855733945387
[11/25 05:46:07 visual_prompt]: Epoch 43 / 100: avg data time: 5.02e+00, avg batch time: 6.4765, average train loss: 10.1250
[11/25 05:46:59 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.5874, average loss: 35.0607
[11/25 05:46:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.58	
[11/25 05:46:59 visual_prompt]: Training 44 / 100 epoch, with learning rate 7.033683215379002
[11/25 05:54:34 visual_prompt]: Epoch 44 / 100: avg data time: 5.05e+00, avg batch time: 6.4995, average train loss: 9.4960
[11/25 05:55:26 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.5872, average loss: 13.6460
[11/25 05:55:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 41.82	
[11/25 05:55:26 visual_prompt]: Training 45 / 100 epoch, with learning rate 6.873032967079561
[11/25 06:03:00 visual_prompt]: Epoch 45 / 100: avg data time: 5.03e+00, avg batch time: 6.4857, average train loss: 9.2092
[11/25 06:03:52 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.5862, average loss: 1.5679
[11/25 06:03:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.53	
[11/25 06:03:52 visual_prompt]: Training 46 / 100 epoch, with learning rate 6.710100716628345
[11/25 06:11:24 visual_prompt]: Epoch 46 / 100: avg data time: 5.01e+00, avg batch time: 6.4586, average train loss: 14.4562
[11/25 06:12:16 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.5863, average loss: 9.7857
[11/25 06:12:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.05	
[11/25 06:12:16 visual_prompt]: Stopping early.
[11/25 06:12:16 visual_prompt]: Rank of current process: 0. World size: 1
[11/25 06:12:16 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/25 06:12:16 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/25 06:12:16 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/25 06:12:16 visual_prompt]: Training with config:
[11/25 06:12:16 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr10.0_wd0.0001/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 10.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/25 06:12:16 visual_prompt]: Loading training data...
[11/25 06:12:16 visual_prompt]: Constructing mammo-cbis dataset train...
[11/25 06:12:16 visual_prompt]: Loading validation data...
[11/25 06:12:16 visual_prompt]: Constructing mammo-cbis dataset val...
[11/25 06:12:16 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/25 06:12:19 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/25 06:12:19 visual_prompt]: tuned percent:0.532
[11/25 06:12:19 visual_prompt]: Device used for model: 0
[11/25 06:12:19 visual_prompt]: Setting up Evaluator...
[11/25 06:12:19 visual_prompt]: Setting up Trainer...
[11/25 06:12:19 visual_prompt]: 	Setting up the optimizer...
[11/25 06:12:19 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/25 06:19:53 visual_prompt]: Epoch 1 / 100: avg data time: 5.03e+00, avg batch time: 6.4881, average train loss: 1.4863
[11/25 06:20:45 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.5886, average loss: 1.4553
[11/25 06:20:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/25 06:20:45 visual_prompt]: Training 2 / 100 epoch, with learning rate 1.0
[11/25 06:28:18 visual_prompt]: Epoch 2 / 100: avg data time: 5.01e+00, avg batch time: 6.4691, average train loss: 3.8484
[11/25 06:29:10 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.5849, average loss: 4.6136
[11/25 06:29:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.53	
[11/25 06:29:10 visual_prompt]: Training 3 / 100 epoch, with learning rate 2.0
[11/25 06:36:42 visual_prompt]: Epoch 3 / 100: avg data time: 5.01e+00, avg batch time: 6.4643, average train loss: 4.0152
[11/25 06:37:34 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.5924, average loss: 3.4962
[11/25 06:37:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.14	
[11/25 06:37:34 visual_prompt]: Training 4 / 100 epoch, with learning rate 3.0
[11/25 06:45:05 visual_prompt]: Epoch 4 / 100: avg data time: 4.99e+00, avg batch time: 6.4416, average train loss: 9.5956
[11/25 06:45:57 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.5854, average loss: 17.7444
[11/25 06:45:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.27	
[11/25 06:45:57 visual_prompt]: Training 5 / 100 epoch, with learning rate 4.0
[11/25 06:53:27 visual_prompt]: Epoch 5 / 100: avg data time: 4.97e+00, avg batch time: 6.4247, average train loss: 11.9517
[11/25 06:54:18 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.5867, average loss: 6.3556
[11/25 06:54:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.19	
[11/25 06:54:18 visual_prompt]: Training 6 / 100 epoch, with learning rate 5.0
[11/25 07:01:50 visual_prompt]: Epoch 6 / 100: avg data time: 5.00e+00, avg batch time: 6.4495, average train loss: 5.5102
[11/25 07:02:41 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.5887, average loss: 12.4938
[11/25 07:02:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.18	
[11/25 07:02:41 visual_prompt]: Training 7 / 100 epoch, with learning rate 6.0
[11/25 07:10:10 visual_prompt]: Epoch 7 / 100: avg data time: 4.96e+00, avg batch time: 6.4136, average train loss: 10.8707
[11/25 07:11:02 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.5854, average loss: 15.6162
[11/25 07:11:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.02	
[11/25 07:11:02 visual_prompt]: Training 8 / 100 epoch, with learning rate 7.0
[11/25 07:18:29 visual_prompt]: Epoch 8 / 100: avg data time: 4.93e+00, avg batch time: 6.3828, average train loss: 16.1962
[11/25 07:19:20 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.5875, average loss: 20.9911
[11/25 07:19:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.46	
[11/25 07:19:20 visual_prompt]: Training 9 / 100 epoch, with learning rate 8.0
[11/25 07:26:47 visual_prompt]: Epoch 9 / 100: avg data time: 4.93e+00, avg batch time: 6.3853, average train loss: 10.8896
[11/25 07:27:38 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.5863, average loss: 9.4035
[11/25 07:27:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.40	
[11/25 07:27:38 visual_prompt]: Training 10 / 100 epoch, with learning rate 9.0
[11/25 07:35:05 visual_prompt]: Epoch 10 / 100: avg data time: 4.93e+00, avg batch time: 6.3830, average train loss: 8.6100
[11/25 07:35:56 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.5876, average loss: 13.1743
[11/25 07:35:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.28	
[11/25 07:35:56 visual_prompt]: Training 11 / 100 epoch, with learning rate 10.0
[11/25 07:43:25 visual_prompt]: Epoch 11 / 100: avg data time: 4.96e+00, avg batch time: 6.4056, average train loss: 18.8795
[11/25 07:44:16 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.5868, average loss: 8.2741
[11/25 07:44:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.07	
[11/25 07:44:16 visual_prompt]: Training 12 / 100 epoch, with learning rate 9.996954135095478
[11/25 07:51:44 visual_prompt]: Epoch 12 / 100: avg data time: 4.95e+00, avg batch time: 6.3978, average train loss: 6.8283
[11/25 07:52:35 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.5845, average loss: 5.3706
[11/25 07:52:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.73	
[11/25 07:52:35 visual_prompt]: Best epoch 12: best metric: -5.371
[11/25 07:52:35 visual_prompt]: Training 13 / 100 epoch, with learning rate 9.987820251299121
[11/25 08:00:03 visual_prompt]: Epoch 13 / 100: avg data time: 4.95e+00, avg batch time: 6.4032, average train loss: 23.1503
[11/25 08:00:54 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.5878, average loss: 18.8135
[11/25 08:00:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.66	
[11/25 08:00:54 visual_prompt]: Training 14 / 100 epoch, with learning rate 9.972609476841367
[11/25 08:08:24 visual_prompt]: Epoch 14 / 100: avg data time: 4.97e+00, avg batch time: 6.4200, average train loss: 17.3023
[11/25 08:09:15 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.5853, average loss: 9.3853
[11/25 08:09:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.40	
[11/25 08:09:15 visual_prompt]: Training 15 / 100 epoch, with learning rate 9.951340343707852
[11/25 08:16:45 visual_prompt]: Epoch 15 / 100: avg data time: 4.97e+00, avg batch time: 6.4219, average train loss: 15.3914
[11/25 08:17:37 visual_prompt]: Inference (val):avg data time: 3.55e-05, avg batch time: 0.5870, average loss: 16.7519
[11/25 08:17:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.92	
[11/25 08:17:37 visual_prompt]: Training 16 / 100 epoch, with learning rate 9.924038765061042
[11/25 08:25:08 visual_prompt]: Epoch 16 / 100: avg data time: 5.00e+00, avg batch time: 6.4493, average train loss: 8.8022
[11/25 08:26:00 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.5912, average loss: 17.3945
[11/25 08:26:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 44.41	
[11/25 08:26:00 visual_prompt]: Training 17 / 100 epoch, with learning rate 9.890738003669028
[11/25 08:33:33 visual_prompt]: Epoch 17 / 100: avg data time: 5.02e+00, avg batch time: 6.4691, average train loss: 11.0128
[11/25 08:34:25 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.5880, average loss: 4.9359
[11/25 08:34:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 44.66	
[11/25 08:34:25 visual_prompt]: Best epoch 17: best metric: -4.936
[11/25 08:34:25 visual_prompt]: Training 18 / 100 epoch, with learning rate 9.851478631379981
[11/25 08:42:05 visual_prompt]: Epoch 18 / 100: avg data time: 5.12e+00, avg batch time: 6.5736, average train loss: 20.5911
[11/25 08:42:57 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.5861, average loss: 2.0057
[11/25 08:42:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.90	
[11/25 08:42:57 visual_prompt]: Best epoch 18: best metric: -2.006
[11/25 08:42:57 visual_prompt]: Training 19 / 100 epoch, with learning rate 9.806308479691594
[11/25 08:50:30 visual_prompt]: Epoch 19 / 100: avg data time: 5.01e+00, avg batch time: 6.4629, average train loss: 11.3233
[11/25 08:51:21 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.5936, average loss: 34.0491
[11/25 08:51:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.41	
[11/25 08:51:21 visual_prompt]: Training 20 / 100 epoch, with learning rate 9.755282581475768
[11/25 08:58:53 visual_prompt]: Epoch 20 / 100: avg data time: 5.00e+00, avg batch time: 6.4471, average train loss: 11.8072
[11/25 08:59:44 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.5878, average loss: 7.3134
[11/25 08:59:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.06	
[11/25 08:59:44 visual_prompt]: Training 21 / 100 epoch, with learning rate 9.698463103929543
[11/25 09:07:13 visual_prompt]: Epoch 21 / 100: avg data time: 4.96e+00, avg batch time: 6.4126, average train loss: 6.6352
[11/25 09:08:04 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.5875, average loss: 2.0948
[11/25 09:08:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.44	
[11/25 09:08:04 visual_prompt]: Training 22 / 100 epoch, with learning rate 9.635919272833938
[11/25 09:15:30 visual_prompt]: Epoch 22 / 100: avg data time: 4.92e+00, avg batch time: 6.3657, average train loss: 11.7063
[11/25 09:16:21 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.5917, average loss: 22.8586
[11/25 09:16:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.40	
[11/25 09:16:21 visual_prompt]: Training 23 / 100 epoch, with learning rate 9.567727288213003
[11/25 09:23:48 visual_prompt]: Epoch 23 / 100: avg data time: 4.94e+00, avg batch time: 6.3914, average train loss: 17.6822
[11/25 09:24:39 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.5908, average loss: 12.0150
[11/25 09:24:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.92	
[11/25 09:24:39 visual_prompt]: Training 24 / 100 epoch, with learning rate 9.493970231495835
[11/25 09:32:06 visual_prompt]: Epoch 24 / 100: avg data time: 4.92e+00, avg batch time: 6.3831, average train loss: 16.8503
[11/25 09:32:57 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.5875, average loss: 5.5806
[11/25 09:32:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.11	
[11/25 09:32:57 visual_prompt]: Training 25 / 100 epoch, with learning rate 9.414737964294634
[11/25 09:40:25 visual_prompt]: Epoch 25 / 100: avg data time: 4.94e+00, avg batch time: 6.3958, average train loss: 13.8365
[11/25 09:41:16 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.5861, average loss: 1.9885
[11/25 09:41:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.12	
[11/25 09:41:16 visual_prompt]: Best epoch 25: best metric: -1.989
[11/25 09:41:16 visual_prompt]: Training 26 / 100 epoch, with learning rate 9.330127018922195
[11/25 09:48:45 visual_prompt]: Epoch 26 / 100: avg data time: 4.96e+00, avg batch time: 6.4091, average train loss: 14.8586
[11/25 09:49:36 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.5875, average loss: 12.7063
[11/25 09:49:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.66	
[11/25 09:49:36 visual_prompt]: Training 27 / 100 epoch, with learning rate 9.240240480782129
[11/25 09:57:04 visual_prompt]: Epoch 27 / 100: avg data time: 4.94e+00, avg batch time: 6.3926, average train loss: 21.0689
[11/25 09:57:55 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.5890, average loss: 23.5132
[11/25 09:57:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.67	
[11/25 09:57:55 visual_prompt]: Training 28 / 100 epoch, with learning rate 9.145187862775208
[11/25 10:05:21 visual_prompt]: Epoch 28 / 100: avg data time: 4.93e+00, avg batch time: 6.3743, average train loss: 28.3326
[11/25 10:06:12 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.5887, average loss: 12.2928
[11/25 10:06:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.39	
[11/25 10:06:12 visual_prompt]: Training 29 / 100 epoch, with learning rate 9.045084971874736
[11/25 10:13:39 visual_prompt]: Epoch 29 / 100: avg data time: 4.92e+00, avg batch time: 6.3718, average train loss: 10.9070
[11/25 10:14:30 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.5871, average loss: 17.8515
[11/25 10:14:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.68	
[11/25 10:14:30 visual_prompt]: Training 30 / 100 epoch, with learning rate 8.940053768033609
[11/25 10:21:58 visual_prompt]: Epoch 30 / 100: avg data time: 4.95e+00, avg batch time: 6.4016, average train loss: 11.5604
[11/25 10:22:49 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.5875, average loss: 21.8766
[11/25 10:22:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.59	
[11/25 10:22:49 visual_prompt]: Training 31 / 100 epoch, with learning rate 8.83022221559489
[11/25 10:30:14 visual_prompt]: Epoch 31 / 100: avg data time: 4.91e+00, avg batch time: 6.3565, average train loss: 8.7012
[11/25 10:31:05 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.5912, average loss: 0.6995
[11/25 10:31:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.47	
[11/25 10:31:05 visual_prompt]: Best epoch 31: best metric: -0.700
[11/25 10:31:05 visual_prompt]: Training 32 / 100 epoch, with learning rate 8.715724127386972
[11/25 10:38:31 visual_prompt]: Epoch 32 / 100: avg data time: 4.92e+00, avg batch time: 6.3700, average train loss: 5.9034
[11/25 10:39:22 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.5899, average loss: 0.8802
[11/25 10:39:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 44.57	
[11/25 10:39:22 visual_prompt]: Training 33 / 100 epoch, with learning rate 8.596699001693256
[11/25 10:46:50 visual_prompt]: Epoch 33 / 100: avg data time: 4.94e+00, avg batch time: 6.3954, average train loss: 6.1837
[11/25 10:47:41 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.5860, average loss: 9.3105
[11/25 10:47:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.39	
[11/25 10:47:41 visual_prompt]: Training 34 / 100 epoch, with learning rate 8.473291852294986
[11/25 10:55:05 visual_prompt]: Epoch 34 / 100: avg data time: 4.89e+00, avg batch time: 6.3387, average train loss: 7.6691
[11/25 10:55:56 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.5858, average loss: 1.2568
[11/25 10:55:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.96	
[11/25 10:55:56 visual_prompt]: Training 35 / 100 epoch, with learning rate 8.345653031794292
[11/25 11:03:20 visual_prompt]: Epoch 35 / 100: avg data time: 4.89e+00, avg batch time: 6.3447, average train loss: 16.6743
[11/25 11:04:11 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.5890, average loss: 24.7372
[11/25 11:04:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.41	
[11/25 11:04:11 visual_prompt]: Training 36 / 100 epoch, with learning rate 8.213938048432697
[11/25 11:11:33 visual_prompt]: Epoch 36 / 100: avg data time: 4.87e+00, avg batch time: 6.3186, average train loss: 15.7066
[11/25 11:12:23 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.5858, average loss: 8.1762
[11/25 11:12:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.91	
[11/25 11:12:23 visual_prompt]: Training 37 / 100 epoch, with learning rate 8.078307376628292
[11/25 11:19:45 visual_prompt]: Epoch 37 / 100: avg data time: 4.86e+00, avg batch time: 6.3105, average train loss: 20.3900
[11/25 11:20:35 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.5886, average loss: 28.9904
[11/25 11:20:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.22	
[11/25 11:20:35 visual_prompt]: Training 38 / 100 epoch, with learning rate 7.938926261462366
[11/25 11:27:56 visual_prompt]: Epoch 38 / 100: avg data time: 4.85e+00, avg batch time: 6.3000, average train loss: 18.5016
[11/25 11:28:46 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.5842, average loss: 9.8416
[11/25 11:28:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.39	
[11/25 11:28:46 visual_prompt]: Training 39 / 100 epoch, with learning rate 7.795964517353734
[11/25 11:36:05 visual_prompt]: Epoch 39 / 100: avg data time: 4.82e+00, avg batch time: 6.2711, average train loss: 15.5384
[11/25 11:36:57 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.5852, average loss: 28.7403
[11/25 11:36:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 44.33	
[11/25 11:36:57 visual_prompt]: Training 40 / 100 epoch, with learning rate 7.649596321166024
[11/25 11:44:17 visual_prompt]: Epoch 40 / 100: avg data time: 4.84e+00, avg batch time: 6.2909, average train loss: 21.1376
[11/25 11:45:07 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.5851, average loss: 19.2719
[11/25 11:45:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.65	
[11/25 11:45:07 visual_prompt]: Training 41 / 100 epoch, with learning rate 7.5
[11/25 11:52:28 visual_prompt]: Epoch 41 / 100: avg data time: 4.85e+00, avg batch time: 6.2992, average train loss: 16.0181
[11/25 11:53:18 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.5866, average loss: 15.8603
[11/25 11:53:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.94	
[11/25 11:53:18 visual_prompt]: Training 42 / 100 epoch, with learning rate 7.347357813929454
[11/25 12:00:39 visual_prompt]: Epoch 42 / 100: avg data time: 4.85e+00, avg batch time: 6.3002, average train loss: 11.2651
[11/25 12:01:30 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.5887, average loss: 2.4032
[11/25 12:01:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.85	
[11/25 12:01:30 visual_prompt]: Training 43 / 100 epoch, with learning rate 7.191855733945387
[11/25 12:08:53 visual_prompt]: Epoch 43 / 100: avg data time: 4.89e+00, avg batch time: 6.3362, average train loss: 8.5799
[11/25 12:09:44 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.5885, average loss: 14.3877
[11/25 12:09:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.71	
[11/25 12:09:44 visual_prompt]: Training 44 / 100 epoch, with learning rate 7.033683215379002
[11/25 12:17:11 visual_prompt]: Epoch 44 / 100: avg data time: 4.94e+00, avg batch time: 6.3878, average train loss: 11.4445
[11/25 12:18:02 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.5878, average loss: 21.7082
[11/25 12:18:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.43	
[11/25 12:18:02 visual_prompt]: Training 45 / 100 epoch, with learning rate 6.873032967079561
[11/25 12:25:29 visual_prompt]: Epoch 45 / 100: avg data time: 4.93e+00, avg batch time: 6.3791, average train loss: 24.4704
[11/25 12:26:20 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.5858, average loss: 5.0379
[11/25 12:26:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.51	
[11/25 12:26:20 visual_prompt]: Training 46 / 100 epoch, with learning rate 6.710100716628345
[11/25 12:33:44 visual_prompt]: Epoch 46 / 100: avg data time: 4.89e+00, avg batch time: 6.3435, average train loss: 13.2770
[11/25 12:34:34 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.5874, average loss: 26.0465
[11/25 12:34:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 61.76	
[11/25 12:34:34 visual_prompt]: Training 47 / 100 epoch, with learning rate 6.545084971874737
[11/25 12:41:59 visual_prompt]: Epoch 47 / 100: avg data time: 4.90e+00, avg batch time: 6.3494, average train loss: 17.2606
[11/25 12:42:50 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.5880, average loss: 17.7124
[11/25 12:42:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.01	
[11/25 12:42:50 visual_prompt]: Training 48 / 100 epoch, with learning rate 6.378186779084995
[11/25 12:50:25 visual_prompt]: Epoch 48 / 100: avg data time: 5.04e+00, avg batch time: 6.4910, average train loss: 12.9159
[11/25 12:51:16 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.5913, average loss: 1.4578
[11/25 12:51:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 44.74	
[11/25 12:51:16 visual_prompt]: Training 49 / 100 epoch, with learning rate 6.209609477998338
[11/25 12:58:42 visual_prompt]: Epoch 49 / 100: avg data time: 4.92e+00, avg batch time: 6.3759, average train loss: 12.6071
[11/25 12:59:33 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.5891, average loss: 2.2930
[11/25 12:59:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.91	
[11/25 12:59:33 visual_prompt]: Training 50 / 100 epoch, with learning rate 6.039558454088796
[11/25 13:07:02 visual_prompt]: Epoch 50 / 100: avg data time: 4.96e+00, avg batch time: 6.4134, average train loss: 12.4457
[11/25 13:07:53 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.5869, average loss: 33.4986
[11/25 13:07:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.96	
[11/25 13:07:53 visual_prompt]: Training 51 / 100 epoch, with learning rate 5.868240888334652
[11/25 13:15:21 visual_prompt]: Epoch 51 / 100: avg data time: 4.94e+00, avg batch time: 6.3957, average train loss: 15.4547
[11/25 13:16:12 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.5835, average loss: 36.5597
[11/25 13:16:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.02	
[11/25 13:16:12 visual_prompt]: Training 52 / 100 epoch, with learning rate 5.695865504800327
[11/25 13:23:40 visual_prompt]: Epoch 52 / 100: avg data time: 4.95e+00, avg batch time: 6.3995, average train loss: 12.4741
[11/25 13:24:32 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.5867, average loss: 1.5257
[11/25 13:24:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.95	
[11/25 13:24:32 visual_prompt]: Stopping early.
[11/25 13:24:32 visual_prompt]: Rank of current process: 0. World size: 1
[11/25 13:24:32 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/25 13:24:32 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/25 13:24:32 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/25 13:24:32 visual_prompt]: Training with config:
[11/25 13:24:32 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr10.0_wd0.0/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 10.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/25 13:24:32 visual_prompt]: Loading training data...
[11/25 13:24:32 visual_prompt]: Constructing mammo-cbis dataset train...
[11/25 13:24:32 visual_prompt]: Loading validation data...
[11/25 13:24:32 visual_prompt]: Constructing mammo-cbis dataset val...
[11/25 13:24:32 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/25 13:24:34 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/25 13:24:34 visual_prompt]: tuned percent:0.532
[11/25 13:24:34 visual_prompt]: Device used for model: 0
[11/25 13:24:34 visual_prompt]: Setting up Evaluator...
[11/25 13:24:34 visual_prompt]: Setting up Trainer...
[11/25 13:24:34 visual_prompt]: 	Setting up the optimizer...
[11/25 13:24:34 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/25 13:32:04 visual_prompt]: Epoch 1 / 100: avg data time: 4.95e+00, avg batch time: 6.4179, average train loss: 1.4863
[11/25 13:32:55 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.5919, average loss: 1.4553
[11/25 13:32:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/25 13:32:55 visual_prompt]: Training 2 / 100 epoch, with learning rate 1.0
[11/25 13:40:22 visual_prompt]: Epoch 2 / 100: avg data time: 4.94e+00, avg batch time: 6.3937, average train loss: 4.2951
[11/25 13:41:14 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.5876, average loss: 1.8348
[11/25 13:41:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.72	
[11/25 13:41:14 visual_prompt]: Training 3 / 100 epoch, with learning rate 2.0
[11/25 13:48:43 visual_prompt]: Epoch 3 / 100: avg data time: 4.96e+00, avg batch time: 6.4181, average train loss: 5.0061
[11/25 13:49:34 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.5842, average loss: 5.8642
[11/25 13:49:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.60	
[11/25 13:49:34 visual_prompt]: Training 4 / 100 epoch, with learning rate 3.0
[11/25 13:57:01 visual_prompt]: Epoch 4 / 100: avg data time: 4.93e+00, avg batch time: 6.3825, average train loss: 11.8872
[11/25 13:57:51 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.5862, average loss: 6.2582
[11/25 13:57:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.22	
[11/25 13:57:51 visual_prompt]: Training 5 / 100 epoch, with learning rate 4.0
[11/25 14:05:19 visual_prompt]: Epoch 5 / 100: avg data time: 4.93e+00, avg batch time: 6.3870, average train loss: 8.2661
[11/25 14:06:10 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.5885, average loss: 11.0977
[11/25 14:06:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.55	
[11/25 14:06:10 visual_prompt]: Training 6 / 100 epoch, with learning rate 5.0
[11/25 14:13:39 visual_prompt]: Epoch 6 / 100: avg data time: 4.96e+00, avg batch time: 6.4102, average train loss: 5.4826
[11/25 14:14:29 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.5854, average loss: 14.5264
[11/25 14:14:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.61	
[11/25 14:14:29 visual_prompt]: Training 7 / 100 epoch, with learning rate 6.0
[11/25 14:21:58 visual_prompt]: Epoch 7 / 100: avg data time: 4.96e+00, avg batch time: 6.4129, average train loss: 14.0829
[11/25 14:22:49 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.5852, average loss: 17.7971
[11/25 14:22:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.40	
[11/25 14:22:49 visual_prompt]: Training 8 / 100 epoch, with learning rate 7.0
[11/25 14:30:16 visual_prompt]: Epoch 8 / 100: avg data time: 4.93e+00, avg batch time: 6.3759, average train loss: 13.7356
[11/25 14:31:07 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.5840, average loss: 27.1819
[11/25 14:31:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.88	
[11/25 14:31:07 visual_prompt]: Training 9 / 100 epoch, with learning rate 8.0
[11/25 14:38:32 visual_prompt]: Epoch 9 / 100: avg data time: 4.91e+00, avg batch time: 6.3621, average train loss: 15.8670
[11/25 14:39:24 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.5931, average loss: 40.9099
[11/25 14:39:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.88	
[11/25 14:39:24 visual_prompt]: Training 10 / 100 epoch, with learning rate 9.0
[11/25 14:46:50 visual_prompt]: Epoch 10 / 100: avg data time: 4.93e+00, avg batch time: 6.3804, average train loss: 11.0402
[11/25 14:47:41 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.5877, average loss: 5.8996
[11/25 14:47:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.87	
[11/25 14:47:41 visual_prompt]: Training 11 / 100 epoch, with learning rate 10.0
[11/25 14:55:10 visual_prompt]: Epoch 11 / 100: avg data time: 4.95e+00, avg batch time: 6.4100, average train loss: 14.0393
[11/25 14:56:01 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.5898, average loss: 20.6367
[11/25 14:56:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.55	
[11/25 14:56:01 visual_prompt]: Training 12 / 100 epoch, with learning rate 9.996954135095478
[11/25 15:03:28 visual_prompt]: Epoch 12 / 100: avg data time: 4.92e+00, avg batch time: 6.3808, average train loss: 13.4744
[11/25 15:04:18 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.5909, average loss: 6.5964
[11/25 15:04:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 62.92	
[11/25 15:04:18 visual_prompt]: Best epoch 12: best metric: -6.596
[11/25 15:04:18 visual_prompt]: Training 13 / 100 epoch, with learning rate 9.987820251299121
[11/25 15:11:42 visual_prompt]: Epoch 13 / 100: avg data time: 4.89e+00, avg batch time: 6.3422, average train loss: 8.6314
[11/25 15:12:33 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.5847, average loss: 21.5790
[11/25 15:12:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.97	
[11/25 15:12:33 visual_prompt]: Training 14 / 100 epoch, with learning rate 9.972609476841367
[11/25 15:19:54 visual_prompt]: Epoch 14 / 100: avg data time: 4.85e+00, avg batch time: 6.2999, average train loss: 13.9254
[11/25 15:20:44 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.5855, average loss: 4.2329
[11/25 15:20:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 63.71	
[11/25 15:20:44 visual_prompt]: Best epoch 14: best metric: -4.233
[11/25 15:20:44 visual_prompt]: Training 15 / 100 epoch, with learning rate 9.951340343707852
[11/25 15:28:04 visual_prompt]: Epoch 15 / 100: avg data time: 4.84e+00, avg batch time: 6.2855, average train loss: 11.5434
[11/25 15:28:55 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.5884, average loss: 22.3574
[11/25 15:28:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 62.71	
[11/25 15:28:55 visual_prompt]: Training 16 / 100 epoch, with learning rate 9.924038765061042
[11/25 15:36:16 visual_prompt]: Epoch 16 / 100: avg data time: 4.85e+00, avg batch time: 6.3024, average train loss: 9.9482
[11/25 15:37:06 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.5861, average loss: 2.2060
[11/25 15:37:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 62.05	
[11/25 15:37:06 visual_prompt]: Best epoch 16: best metric: -2.206
[11/25 15:37:06 visual_prompt]: Training 17 / 100 epoch, with learning rate 9.890738003669028
[11/25 15:44:26 visual_prompt]: Epoch 17 / 100: avg data time: 4.83e+00, avg batch time: 6.2817, average train loss: 11.8424
[11/25 15:45:16 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.5848, average loss: 7.5604
[11/25 15:45:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 65.27	
[11/25 15:45:16 visual_prompt]: Training 18 / 100 epoch, with learning rate 9.851478631379981
[11/25 15:52:37 visual_prompt]: Epoch 18 / 100: avg data time: 4.84e+00, avg batch time: 6.2906, average train loss: 10.1184
[11/25 15:53:27 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.5847, average loss: 7.6597
[11/25 15:53:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 65.09	
[11/25 15:53:27 visual_prompt]: Training 19 / 100 epoch, with learning rate 9.806308479691594
[11/25 16:00:47 visual_prompt]: Epoch 19 / 100: avg data time: 4.83e+00, avg batch time: 6.2832, average train loss: 12.8917
[11/25 16:01:37 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.5866, average loss: 34.6207
[11/25 16:01:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 66.08	
[11/25 16:01:37 visual_prompt]: Training 20 / 100 epoch, with learning rate 9.755282581475768
[11/25 16:09:01 visual_prompt]: Epoch 20 / 100: avg data time: 4.89e+00, avg batch time: 6.3408, average train loss: 12.5878
[11/25 16:09:52 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.5889, average loss: 9.1452
[11/25 16:09:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 68.52	
[11/25 16:09:52 visual_prompt]: Training 21 / 100 epoch, with learning rate 9.698463103929543
[11/25 16:17:16 visual_prompt]: Epoch 21 / 100: avg data time: 4.89e+00, avg batch time: 6.3438, average train loss: 13.7105
[11/25 16:18:07 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.5878, average loss: 3.6799
[11/25 16:18:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 64.74	
[11/25 16:18:07 visual_prompt]: Training 22 / 100 epoch, with learning rate 9.635919272833938
[11/25 16:25:33 visual_prompt]: Epoch 22 / 100: avg data time: 4.92e+00, avg batch time: 6.3699, average train loss: 13.6711
[11/25 16:26:25 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.5886, average loss: 10.6699
[11/25 16:26:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 66.64	
[11/25 16:26:25 visual_prompt]: Training 23 / 100 epoch, with learning rate 9.567727288213003
[11/25 16:33:52 visual_prompt]: Epoch 23 / 100: avg data time: 4.94e+00, avg batch time: 6.3885, average train loss: 8.5223
[11/25 16:34:43 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.5861, average loss: 4.3967
[11/25 16:34:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 67.44	
[11/25 16:34:43 visual_prompt]: Training 24 / 100 epoch, with learning rate 9.493970231495835
[11/25 16:42:10 visual_prompt]: Epoch 24 / 100: avg data time: 4.93e+00, avg batch time: 6.3815, average train loss: 5.2597
[11/25 16:43:01 visual_prompt]: Inference (val):avg data time: 1.33e-04, avg batch time: 0.5948, average loss: 3.5950
[11/25 16:43:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 67.57	
[11/25 16:43:01 visual_prompt]: Training 25 / 100 epoch, with learning rate 9.414737964294634
[11/25 16:50:28 visual_prompt]: Epoch 25 / 100: avg data time: 4.92e+00, avg batch time: 6.3772, average train loss: 5.8605
[11/25 16:51:18 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.5904, average loss: 0.6970
[11/25 16:51:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 64.75	
[11/25 16:51:18 visual_prompt]: Best epoch 25: best metric: -0.697
[11/25 16:51:18 visual_prompt]: Training 26 / 100 epoch, with learning rate 9.330127018922195
[11/25 16:58:47 visual_prompt]: Epoch 26 / 100: avg data time: 4.97e+00, avg batch time: 6.4172, average train loss: 8.1918
[11/25 16:59:38 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.5859, average loss: 5.4254
[11/25 16:59:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 69.80	
[11/25 16:59:38 visual_prompt]: Training 27 / 100 epoch, with learning rate 9.240240480782129
[11/25 17:07:04 visual_prompt]: Epoch 27 / 100: avg data time: 4.92e+00, avg batch time: 6.3699, average train loss: 10.7751
[11/25 17:07:55 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.5849, average loss: 1.5116
[11/25 17:07:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 67.32	
[11/25 17:07:55 visual_prompt]: Training 28 / 100 epoch, with learning rate 9.145187862775208
[11/25 17:15:23 visual_prompt]: Epoch 28 / 100: avg data time: 4.94e+00, avg batch time: 6.3902, average train loss: 4.8519
[11/25 17:16:14 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.5865, average loss: 1.0155
[11/25 17:16:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 69.01	
[11/25 17:16:14 visual_prompt]: Training 29 / 100 epoch, with learning rate 9.045084971874736
[11/25 17:23:40 visual_prompt]: Epoch 29 / 100: avg data time: 4.92e+00, avg batch time: 6.3767, average train loss: 9.7333
[11/25 17:24:31 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.5865, average loss: 2.0517
[11/25 17:24:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 68.65	
[11/25 17:24:31 visual_prompt]: Training 30 / 100 epoch, with learning rate 8.940053768033609
[11/25 17:32:00 visual_prompt]: Epoch 30 / 100: avg data time: 4.95e+00, avg batch time: 6.4044, average train loss: 3.5240
[11/25 17:32:50 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.5884, average loss: 8.9571
[11/25 17:32:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.93	
[11/25 17:32:50 visual_prompt]: Training 31 / 100 epoch, with learning rate 8.83022221559489
[11/25 17:40:17 visual_prompt]: Epoch 31 / 100: avg data time: 4.92e+00, avg batch time: 6.3761, average train loss: 6.7305
[11/25 17:41:09 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.5856, average loss: 1.6209
[11/25 17:41:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 67.13	
[11/25 17:41:09 visual_prompt]: Training 32 / 100 epoch, with learning rate 8.715724127386972
[11/25 17:48:35 visual_prompt]: Epoch 32 / 100: avg data time: 4.93e+00, avg batch time: 6.3817, average train loss: 3.9989
[11/25 17:49:26 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.5866, average loss: 5.8083
[11/25 17:49:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 68.15	
[11/25 17:49:26 visual_prompt]: Training 33 / 100 epoch, with learning rate 8.596699001693256
[11/25 17:56:53 visual_prompt]: Epoch 33 / 100: avg data time: 4.93e+00, avg batch time: 6.3808, average train loss: 6.7435
[11/25 17:57:44 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.5876, average loss: 0.7349
[11/25 17:57:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 68.80	
[11/25 17:57:44 visual_prompt]: Training 34 / 100 epoch, with learning rate 8.473291852294986
[11/25 18:05:10 visual_prompt]: Epoch 34 / 100: avg data time: 4.92e+00, avg batch time: 6.3744, average train loss: 4.5611
[11/25 18:06:01 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.5848, average loss: 8.3701
[11/25 18:06:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 67.71	
[11/25 18:06:01 visual_prompt]: Training 35 / 100 epoch, with learning rate 8.345653031794292
[11/25 18:13:28 visual_prompt]: Epoch 35 / 100: avg data time: 4.92e+00, avg batch time: 6.3813, average train loss: 6.1257
[11/25 18:14:19 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.5897, average loss: 1.4494
[11/25 18:14:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 68.74	
[11/25 18:14:19 visual_prompt]: Training 36 / 100 epoch, with learning rate 8.213938048432697
[11/25 18:21:49 visual_prompt]: Epoch 36 / 100: avg data time: 4.97e+00, avg batch time: 6.4212, average train loss: 5.1354
[11/25 18:22:40 visual_prompt]: Inference (val):avg data time: 1.35e-04, avg batch time: 0.5940, average loss: 1.3743
[11/25 18:22:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 68.72	
[11/25 18:22:40 visual_prompt]: Training 37 / 100 epoch, with learning rate 8.078307376628292
[11/25 18:30:07 visual_prompt]: Epoch 37 / 100: avg data time: 4.93e+00, avg batch time: 6.3843, average train loss: 4.5551
[11/25 18:30:57 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.5861, average loss: 1.0983
[11/25 18:30:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 69.33	
[11/25 18:30:57 visual_prompt]: Training 38 / 100 epoch, with learning rate 7.938926261462366
[11/25 18:38:25 visual_prompt]: Epoch 38 / 100: avg data time: 4.94e+00, avg batch time: 6.3943, average train loss: 3.0907
[11/25 18:39:16 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.5863, average loss: 1.0862
[11/25 18:39:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 70.41	
[11/25 18:39:16 visual_prompt]: Training 39 / 100 epoch, with learning rate 7.795964517353734
[11/25 18:46:42 visual_prompt]: Epoch 39 / 100: avg data time: 4.91e+00, avg batch time: 6.3699, average train loss: 5.6515
[11/25 18:47:34 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.5883, average loss: 2.5797
[11/25 18:47:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 67.86	
[11/25 18:47:34 visual_prompt]: Training 40 / 100 epoch, with learning rate 7.649596321166024
[11/25 18:55:00 visual_prompt]: Epoch 40 / 100: avg data time: 4.91e+00, avg batch time: 6.3634, average train loss: 8.4372
[11/25 18:55:51 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.5857, average loss: 5.5797
[11/25 18:55:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 69.18	
[11/25 18:55:51 visual_prompt]: Training 41 / 100 epoch, with learning rate 7.5
[11/25 19:03:16 visual_prompt]: Epoch 41 / 100: avg data time: 4.90e+00, avg batch time: 6.3560, average train loss: 4.1854
[11/25 19:04:07 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.5901, average loss: 5.3578
[11/25 19:04:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 70.46	
[11/25 19:04:07 visual_prompt]: Training 42 / 100 epoch, with learning rate 7.347357813929454
[11/25 19:11:32 visual_prompt]: Epoch 42 / 100: avg data time: 4.90e+00, avg batch time: 6.3472, average train loss: 3.8816
[11/25 19:12:22 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.5842, average loss: 0.9513
[11/25 19:12:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 68.93	
[11/25 19:12:22 visual_prompt]: Training 43 / 100 epoch, with learning rate 7.191855733945387
[11/25 19:19:41 visual_prompt]: Epoch 43 / 100: avg data time: 4.82e+00, avg batch time: 6.2685, average train loss: 3.4665
[11/25 19:20:32 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.5854, average loss: 5.1473
[11/25 19:20:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 68.86	
[11/25 19:20:32 visual_prompt]: Training 44 / 100 epoch, with learning rate 7.033683215379002
[11/25 19:27:53 visual_prompt]: Epoch 44 / 100: avg data time: 4.85e+00, avg batch time: 6.2962, average train loss: 2.9244
[11/25 19:28:43 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.5861, average loss: 1.2201
[11/25 19:28:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 69.29	
[11/25 19:28:43 visual_prompt]: Training 45 / 100 epoch, with learning rate 6.873032967079561
[11/25 19:36:04 visual_prompt]: Epoch 45 / 100: avg data time: 4.85e+00, avg batch time: 6.2963, average train loss: 4.4957
[11/25 19:36:55 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.5909, average loss: 6.5994
[11/25 19:36:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 69.74	
[11/25 19:36:55 visual_prompt]: Training 46 / 100 epoch, with learning rate 6.710100716628345
[11/25 19:44:17 visual_prompt]: Epoch 46 / 100: avg data time: 4.86e+00, avg batch time: 6.3179, average train loss: 4.1730
[11/25 19:45:07 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.5881, average loss: 4.6635
[11/25 19:45:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 70.50	
[11/25 19:45:07 visual_prompt]: Stopping early.
[11/25 19:45:07 visual_prompt]: Rank of current process: 0. World size: 1
[11/25 19:45:07 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/25 19:45:07 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/25 19:45:07 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/25 19:45:07 visual_prompt]: Training with config:
[11/25 19:45:07 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr5.0_wd0.01/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 5.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/25 19:45:07 visual_prompt]: Loading training data...
[11/25 19:45:07 visual_prompt]: Constructing mammo-cbis dataset train...
[11/25 19:45:07 visual_prompt]: Loading validation data...
[11/25 19:45:07 visual_prompt]: Constructing mammo-cbis dataset val...
[11/25 19:45:07 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/25 19:45:10 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/25 19:45:10 visual_prompt]: tuned percent:0.532
[11/25 19:45:10 visual_prompt]: Device used for model: 0
[11/25 19:45:10 visual_prompt]: Setting up Evaluator...
[11/25 19:45:10 visual_prompt]: Setting up Trainer...
[11/25 19:45:10 visual_prompt]: 	Setting up the optimizer...
[11/25 19:45:11 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/25 19:52:34 visual_prompt]: Epoch 1 / 100: avg data time: 4.88e+00, avg batch time: 6.3309, average train loss: 1.4863
[11/25 19:53:24 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.5871, average loss: 1.4553
[11/25 19:53:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/25 19:53:24 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.5
[11/25 20:00:45 visual_prompt]: Epoch 2 / 100: avg data time: 4.84e+00, avg batch time: 6.2902, average train loss: 2.7848
[11/25 20:01:35 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.5866, average loss: 0.9262
[11/25 20:01:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.59	
[11/25 20:01:35 visual_prompt]: Training 3 / 100 epoch, with learning rate 1.0
[11/25 20:08:57 visual_prompt]: Epoch 3 / 100: avg data time: 4.87e+00, avg batch time: 6.3211, average train loss: 1.2319
[11/25 20:09:48 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.5883, average loss: 3.8233
[11/25 20:09:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 43.98	
[11/25 20:09:48 visual_prompt]: Training 4 / 100 epoch, with learning rate 1.5
[11/25 20:17:07 visual_prompt]: Epoch 4 / 100: avg data time: 4.83e+00, avg batch time: 6.2798, average train loss: 1.6728
[11/25 20:17:58 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.5897, average loss: 2.7204
[11/25 20:17:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.22	
[11/25 20:17:58 visual_prompt]: Training 5 / 100 epoch, with learning rate 2.0
[11/25 20:25:25 visual_prompt]: Epoch 5 / 100: avg data time: 4.93e+00, avg batch time: 6.3820, average train loss: 2.3166
[11/25 20:26:16 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.5849, average loss: 4.3611
[11/25 20:26:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.06	
[11/25 20:26:16 visual_prompt]: Training 6 / 100 epoch, with learning rate 2.5
[11/25 20:33:41 visual_prompt]: Epoch 6 / 100: avg data time: 4.91e+00, avg batch time: 6.3618, average train loss: 3.7838
[11/25 20:34:32 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.5879, average loss: 10.6632
[11/25 20:34:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.33	
[11/25 20:34:32 visual_prompt]: Training 7 / 100 epoch, with learning rate 3.0
[11/25 20:41:59 visual_prompt]: Epoch 7 / 100: avg data time: 4.93e+00, avg batch time: 6.3791, average train loss: 4.9261
[11/25 20:42:49 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.5855, average loss: 4.4988
[11/25 20:42:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.71	
[11/25 20:42:49 visual_prompt]: Training 8 / 100 epoch, with learning rate 3.5
[11/25 20:50:20 visual_prompt]: Epoch 8 / 100: avg data time: 4.98e+00, avg batch time: 6.4318, average train loss: 8.2477
[11/25 20:51:11 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.5887, average loss: 8.5580
[11/25 20:51:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.83	
[11/25 20:51:11 visual_prompt]: Training 9 / 100 epoch, with learning rate 4.0
[11/25 20:58:40 visual_prompt]: Epoch 9 / 100: avg data time: 4.96e+00, avg batch time: 6.4128, average train loss: 9.1507
[11/25 20:59:31 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.5860, average loss: 12.4504
[11/25 20:59:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.75	
[11/25 20:59:31 visual_prompt]: Training 10 / 100 epoch, with learning rate 4.5
[11/25 21:06:58 visual_prompt]: Epoch 10 / 100: avg data time: 4.92e+00, avg batch time: 6.3739, average train loss: 7.3559
[11/25 21:07:49 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.5883, average loss: 7.3023
[11/25 21:07:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.39	
[11/25 21:07:49 visual_prompt]: Training 11 / 100 epoch, with learning rate 5.0
[11/25 21:15:17 visual_prompt]: Epoch 11 / 100: avg data time: 4.96e+00, avg batch time: 6.4094, average train loss: 7.3332
[11/25 21:16:08 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.5866, average loss: 6.1562
[11/25 21:16:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 45.15	
[11/25 21:16:08 visual_prompt]: Training 12 / 100 epoch, with learning rate 4.998477067547739
[11/25 21:23:35 visual_prompt]: Epoch 12 / 100: avg data time: 4.92e+00, avg batch time: 6.3728, average train loss: 10.6316
[11/25 21:24:26 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.5844, average loss: 35.5423
[11/25 21:24:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.48	
[11/25 21:24:26 visual_prompt]: Training 13 / 100 epoch, with learning rate 4.993910125649561
[11/25 21:31:54 visual_prompt]: Epoch 13 / 100: avg data time: 4.95e+00, avg batch time: 6.3977, average train loss: 15.0183
[11/25 21:32:44 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.5913, average loss: 11.8189
[11/25 21:32:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 44.09	
[11/25 21:32:44 visual_prompt]: Training 14 / 100 epoch, with learning rate 4.986304738420683
[11/25 21:40:10 visual_prompt]: Epoch 14 / 100: avg data time: 4.92e+00, avg batch time: 6.3677, average train loss: 13.3394
[11/25 21:41:01 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.5922, average loss: 16.1210
[11/25 21:41:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.29	
[11/25 21:41:01 visual_prompt]: Training 15 / 100 epoch, with learning rate 4.975670171853926
[11/25 21:48:27 visual_prompt]: Epoch 15 / 100: avg data time: 4.92e+00, avg batch time: 6.3680, average train loss: 8.0343
[11/25 21:49:19 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.5881, average loss: 19.8728
[11/25 21:49:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.65	
[11/25 21:49:19 visual_prompt]: Training 16 / 100 epoch, with learning rate 4.962019382530521
[11/25 21:56:45 visual_prompt]: Epoch 16 / 100: avg data time: 4.92e+00, avg batch time: 6.3715, average train loss: 15.3063
[11/25 21:57:36 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.5964, average loss: 8.9128
[11/25 21:57:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.36	
[11/25 21:57:36 visual_prompt]: Training 17 / 100 epoch, with learning rate 4.945369001834514
[11/25 22:05:03 visual_prompt]: Epoch 17 / 100: avg data time: 4.93e+00, avg batch time: 6.3844, average train loss: 11.2095
[11/25 22:05:54 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.5840, average loss: 6.7191
[11/25 22:05:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 38.71	
[11/25 22:05:54 visual_prompt]: Training 18 / 100 epoch, with learning rate 4.925739315689991
[11/25 22:13:17 visual_prompt]: Epoch 18 / 100: avg data time: 4.88e+00, avg batch time: 6.3309, average train loss: 12.4548
[11/25 22:14:08 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.5875, average loss: 7.6133
[11/25 22:14:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.66	
[11/25 22:14:08 visual_prompt]: Training 19 / 100 epoch, with learning rate 4.903154239845797
[11/25 22:21:32 visual_prompt]: Epoch 19 / 100: avg data time: 4.88e+00, avg batch time: 6.3363, average train loss: 9.2137
[11/25 22:22:23 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.5877, average loss: 5.8031
[11/25 22:22:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.36	
[11/25 22:22:23 visual_prompt]: Best epoch 19: best metric: -5.803
[11/25 22:22:23 visual_prompt]: Training 20 / 100 epoch, with learning rate 4.877641290737884
[11/25 22:29:51 visual_prompt]: Epoch 20 / 100: avg data time: 4.95e+00, avg batch time: 6.4037, average train loss: 10.6842
[11/25 22:30:42 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.5883, average loss: 20.7116
[11/25 22:30:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.68	
[11/25 22:30:42 visual_prompt]: Training 21 / 100 epoch, with learning rate 4.849231551964771
[11/25 22:38:10 visual_prompt]: Epoch 21 / 100: avg data time: 4.95e+00, avg batch time: 6.3999, average train loss: 9.4496
[11/25 22:39:02 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.5884, average loss: 11.1390
[11/25 22:39:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.00	
[11/25 22:39:02 visual_prompt]: Training 22 / 100 epoch, with learning rate 4.817959636416969
[11/25 22:46:27 visual_prompt]: Epoch 22 / 100: avg data time: 4.91e+00, avg batch time: 6.3605, average train loss: 9.6387
[11/25 22:47:18 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.5869, average loss: 16.5941
[11/25 22:47:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.69	
[11/25 22:47:18 visual_prompt]: Training 23 / 100 epoch, with learning rate 4.783863644106502
[11/25 22:54:45 visual_prompt]: Epoch 23 / 100: avg data time: 4.93e+00, avg batch time: 6.3825, average train loss: 12.5725
[11/25 22:55:33 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.5849, average loss: 7.6509
[11/25 22:55:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.67	
[11/25 22:55:33 visual_prompt]: Training 24 / 100 epoch, with learning rate 4.7469851157479175
[11/25 23:02:32 visual_prompt]: Epoch 24 / 100: avg data time: 4.54e+00, avg batch time: 5.9897, average train loss: 13.1446
[11/25 23:03:21 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.5890, average loss: 13.6834
[11/25 23:03:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 44.08	
[11/25 23:03:21 visual_prompt]: Training 25 / 100 epoch, with learning rate 4.707368982147317
[11/25 23:10:26 visual_prompt]: Epoch 25 / 100: avg data time: 4.62e+00, avg batch time: 6.0696, average train loss: 7.5349
[11/25 23:11:14 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.5868, average loss: 12.0203
[11/25 23:11:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.20	
[11/25 23:11:14 visual_prompt]: Training 26 / 100 epoch, with learning rate 4.665063509461097
[11/25 23:18:17 visual_prompt]: Epoch 26 / 100: avg data time: 4.59e+00, avg batch time: 6.0443, average train loss: 11.5619
[11/25 23:19:06 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.5879, average loss: 9.9770
[11/25 23:19:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 45.05	
[11/25 23:19:06 visual_prompt]: Training 27 / 100 epoch, with learning rate 4.620120240391064
[11/25 23:26:08 visual_prompt]: Epoch 27 / 100: avg data time: 4.58e+00, avg batch time: 6.0360, average train loss: 13.0516
[11/25 23:26:57 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.5866, average loss: 4.0530
[11/25 23:26:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 38.58	
[11/25 23:26:57 visual_prompt]: Best epoch 27: best metric: -4.053
[11/25 23:26:57 visual_prompt]: Training 28 / 100 epoch, with learning rate 4.572593931387604
[11/25 23:34:01 visual_prompt]: Epoch 28 / 100: avg data time: 4.60e+00, avg batch time: 6.0542, average train loss: 8.3452
[11/25 23:34:49 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.5874, average loss: 13.7381
[11/25 23:34:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.46	
[11/25 23:34:49 visual_prompt]: Training 29 / 100 epoch, with learning rate 4.522542485937368
[11/25 23:41:52 visual_prompt]: Epoch 29 / 100: avg data time: 4.59e+00, avg batch time: 6.0450, average train loss: 11.3038
[11/25 23:42:41 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.5870, average loss: 3.0765
[11/25 23:42:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 44.86	
[11/25 23:42:41 visual_prompt]: Best epoch 29: best metric: -3.076
[11/25 23:42:41 visual_prompt]: Training 30 / 100 epoch, with learning rate 4.4700268840168045
[11/25 23:49:46 visual_prompt]: Epoch 30 / 100: avg data time: 4.61e+00, avg batch time: 6.0633, average train loss: 12.1638
[11/25 23:50:34 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.5866, average loss: 8.7520
[11/25 23:50:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.82	
[11/25 23:50:34 visual_prompt]: Training 31 / 100 epoch, with learning rate 4.415111107797445
[11/25 23:57:37 visual_prompt]: Epoch 31 / 100: avg data time: 4.58e+00, avg batch time: 6.0366, average train loss: 7.9387
[11/25 23:58:25 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.5843, average loss: 31.3213
[11/25 23:58:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.55	
[11/25 23:58:25 visual_prompt]: Training 32 / 100 epoch, with learning rate 4.357862063693486
[11/26 00:05:28 visual_prompt]: Epoch 32 / 100: avg data time: 4.60e+00, avg batch time: 6.0479, average train loss: 8.3573
[11/26 00:06:17 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.5848, average loss: 15.2481
[11/26 00:06:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.90	
[11/26 00:06:17 visual_prompt]: Training 33 / 100 epoch, with learning rate 4.298349500846628
[11/26 00:13:21 visual_prompt]: Epoch 33 / 100: avg data time: 4.60e+00, avg batch time: 6.0650, average train loss: 11.0858
[11/26 00:14:09 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.5863, average loss: 7.8440
[11/26 00:14:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.80	
[11/26 00:14:09 visual_prompt]: Training 34 / 100 epoch, with learning rate 4.236645926147493
[11/26 00:21:08 visual_prompt]: Epoch 34 / 100: avg data time: 4.53e+00, avg batch time: 5.9845, average train loss: 8.0202
[11/26 00:21:56 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.5873, average loss: 11.2091
[11/26 00:21:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.95	
[11/26 00:21:56 visual_prompt]: Training 35 / 100 epoch, with learning rate 4.172826515897146
[11/26 00:28:57 visual_prompt]: Epoch 35 / 100: avg data time: 4.55e+00, avg batch time: 6.0058, average train loss: 7.0952
[11/26 00:29:46 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.5895, average loss: 18.0191
[11/26 00:29:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.48	
[11/26 00:29:46 visual_prompt]: Training 36 / 100 epoch, with learning rate 4.106969024216348
[11/26 00:36:51 visual_prompt]: Epoch 36 / 100: avg data time: 4.62e+00, avg batch time: 6.0733, average train loss: 13.6207
[11/26 00:37:39 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.5866, average loss: 1.8677
[11/26 00:37:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.25	
[11/26 00:37:39 visual_prompt]: Best epoch 36: best metric: -1.868
[11/26 00:37:39 visual_prompt]: Training 37 / 100 epoch, with learning rate 4.039153688314146
[11/26 00:44:43 visual_prompt]: Epoch 37 / 100: avg data time: 4.60e+00, avg batch time: 6.0512, average train loss: 7.1356
[11/26 00:45:32 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.5908, average loss: 2.8733
[11/26 00:45:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 41.03	
[11/26 00:45:32 visual_prompt]: Training 38 / 100 epoch, with learning rate 3.969463130731183
[11/26 00:52:37 visual_prompt]: Epoch 38 / 100: avg data time: 4.61e+00, avg batch time: 6.0693, average train loss: 7.6268
[11/26 00:53:25 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.5867, average loss: 3.0940
[11/26 00:53:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.72	
[11/26 00:53:25 visual_prompt]: Training 39 / 100 epoch, with learning rate 3.897982258676867
[11/26 01:00:29 visual_prompt]: Epoch 39 / 100: avg data time: 4.60e+00, avg batch time: 6.0492, average train loss: 11.2297
[11/26 01:01:17 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.5854, average loss: 1.2887
[11/26 01:01:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.76	
[11/26 01:01:17 visual_prompt]: Best epoch 39: best metric: -1.289
[11/26 01:01:17 visual_prompt]: Training 40 / 100 epoch, with learning rate 3.824798160583012
[11/26 01:08:25 visual_prompt]: Epoch 40 / 100: avg data time: 4.66e+00, avg batch time: 6.1132, average train loss: 10.2636
[11/26 01:09:14 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.5866, average loss: 11.4468
[11/26 01:09:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 45.05	
[11/26 01:09:14 visual_prompt]: Training 41 / 100 epoch, with learning rate 3.75
[11/26 01:16:18 visual_prompt]: Epoch 41 / 100: avg data time: 4.60e+00, avg batch time: 6.0535, average train loss: 8.0118
[11/26 01:17:06 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.5881, average loss: 2.2145
[11/26 01:17:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 39.31	
[11/26 01:17:06 visual_prompt]: Training 42 / 100 epoch, with learning rate 3.673678906964727
[11/26 01:24:09 visual_prompt]: Epoch 42 / 100: avg data time: 4.59e+00, avg batch time: 6.0382, average train loss: 10.1627
[11/26 01:24:57 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.5851, average loss: 8.4205
[11/26 01:24:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.99	
[11/26 01:24:57 visual_prompt]: Training 43 / 100 epoch, with learning rate 3.5959278669726933
[11/26 01:32:02 visual_prompt]: Epoch 43 / 100: avg data time: 4.61e+00, avg batch time: 6.0618, average train loss: 7.2841
[11/26 01:32:50 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.5904, average loss: 19.0636
[11/26 01:32:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.07	
[11/26 01:32:51 visual_prompt]: Training 44 / 100 epoch, with learning rate 3.516841607689501
[11/26 01:39:56 visual_prompt]: Epoch 44 / 100: avg data time: 4.62e+00, avg batch time: 6.0713, average train loss: 6.0035
[11/26 01:40:44 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.5883, average loss: 12.1730
[11/26 01:40:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.16	
[11/26 01:40:44 visual_prompt]: Training 45 / 100 epoch, with learning rate 3.4365164835397803
[11/26 01:47:50 visual_prompt]: Epoch 45 / 100: avg data time: 4.63e+00, avg batch time: 6.0786, average train loss: 5.0494
[11/26 01:48:38 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.5950, average loss: 2.5811
[11/26 01:48:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.07	
[11/26 01:48:38 visual_prompt]: Training 46 / 100 epoch, with learning rate 3.3550503583141724
[11/26 01:55:41 visual_prompt]: Epoch 46 / 100: avg data time: 4.59e+00, avg batch time: 6.0443, average train loss: 6.4797
[11/26 01:56:30 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.5881, average loss: 1.0688
[11/26 01:56:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 37.60	
[11/26 01:56:30 visual_prompt]: Best epoch 46: best metric: -1.069
[11/26 01:56:30 visual_prompt]: Training 47 / 100 epoch, with learning rate 3.2725424859373686
[11/26 02:03:36 visual_prompt]: Epoch 47 / 100: avg data time: 4.64e+00, avg batch time: 6.0927, average train loss: 8.5035
[11/26 02:04:28 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.5867, average loss: 1.4006
[11/26 02:04:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.76	
[11/26 02:04:28 visual_prompt]: Training 48 / 100 epoch, with learning rate 3.1890933895424975
[11/26 02:11:32 visual_prompt]: Epoch 48 / 100: avg data time: 4.61e+00, avg batch time: 6.0598, average train loss: 5.4785
[11/26 02:12:20 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.5851, average loss: 9.2214
[11/26 02:12:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.14	
[11/26 02:12:20 visual_prompt]: Training 49 / 100 epoch, with learning rate 3.104804738999169
[11/26 02:19:20 visual_prompt]: Epoch 49 / 100: avg data time: 4.54e+00, avg batch time: 5.9939, average train loss: 6.0560
[11/26 02:20:08 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.5951, average loss: 22.8427
[11/26 02:20:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.96	
[11/26 02:20:08 visual_prompt]: Training 50 / 100 epoch, with learning rate 3.019779227044398
[11/26 02:27:08 visual_prompt]: Epoch 50 / 100: avg data time: 4.54e+00, avg batch time: 5.9876, average train loss: 6.4326
[11/26 02:27:56 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.5883, average loss: 6.2267
[11/26 02:27:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.12	
[11/26 02:27:56 visual_prompt]: Training 51 / 100 epoch, with learning rate 2.934120444167326
[11/26 02:34:55 visual_prompt]: Epoch 51 / 100: avg data time: 4.54e+00, avg batch time: 5.9912, average train loss: 7.8440
[11/26 02:35:43 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.5847, average loss: 0.7176
[11/26 02:35:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 46.75	rocauc: 52.60	
[11/26 02:35:43 visual_prompt]: Best epoch 51: best metric: -0.718
[11/26 02:35:43 visual_prompt]: Training 52 / 100 epoch, with learning rate 2.8479327524001636
[11/26 02:42:43 visual_prompt]: Epoch 52 / 100: avg data time: 4.55e+00, avg batch time: 5.9991, average train loss: 5.8174
[11/26 02:43:31 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.5879, average loss: 0.7059
[11/26 02:43:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 44.63	
[11/26 02:43:31 visual_prompt]: Best epoch 52: best metric: -0.706
[11/26 02:43:31 visual_prompt]: Training 53 / 100 epoch, with learning rate 2.761321158169134
[11/26 02:50:32 visual_prompt]: Epoch 53 / 100: avg data time: 4.55e+00, avg batch time: 6.0048, average train loss: 5.2114
[11/26 02:51:20 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.5869, average loss: 6.7011
[11/26 02:51:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.00	
[11/26 02:51:20 visual_prompt]: Training 54 / 100 epoch, with learning rate 2.6743911843603128
[11/26 02:58:22 visual_prompt]: Epoch 54 / 100: avg data time: 4.58e+00, avg batch time: 6.0317, average train loss: 7.7452
[11/26 02:59:11 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.5892, average loss: 25.7155
[11/26 02:59:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.73	
[11/26 02:59:11 visual_prompt]: Training 55 / 100 epoch, with learning rate 2.5872487417562526
[11/26 03:06:14 visual_prompt]: Epoch 55 / 100: avg data time: 4.60e+00, avg batch time: 6.0539, average train loss: 4.6377
[11/26 03:07:03 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.5879, average loss: 5.6612
[11/26 03:07:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 41.38	
[11/26 03:07:03 visual_prompt]: Training 56 / 100 epoch, with learning rate 2.5
[11/26 03:14:07 visual_prompt]: Epoch 56 / 100: avg data time: 4.60e+00, avg batch time: 6.0540, average train loss: 3.1049
[11/26 03:14:55 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.5894, average loss: 1.9974
[11/26 03:14:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.42	
[11/26 03:14:55 visual_prompt]: Training 57 / 100 epoch, with learning rate 2.4127512582437483
[11/26 03:22:00 visual_prompt]: Epoch 57 / 100: avg data time: 4.62e+00, avg batch time: 6.0701, average train loss: 7.2028
[11/26 03:22:49 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.5874, average loss: 12.0926
[11/26 03:22:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.37	
[11/26 03:22:49 visual_prompt]: Training 58 / 100 epoch, with learning rate 2.325608815639687
[11/26 03:29:52 visual_prompt]: Epoch 58 / 100: avg data time: 4.59e+00, avg batch time: 6.0420, average train loss: 6.2803
[11/26 03:30:40 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.5917, average loss: 4.2504
[11/26 03:30:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.98	
[11/26 03:30:41 visual_prompt]: Training 59 / 100 epoch, with learning rate 2.2386788418308665
[11/26 03:37:46 visual_prompt]: Epoch 59 / 100: avg data time: 4.61e+00, avg batch time: 6.0695, average train loss: 5.1015
[11/26 03:38:34 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.5912, average loss: 2.8702
[11/26 03:38:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.66	
[11/26 03:38:34 visual_prompt]: Training 60 / 100 epoch, with learning rate 2.1520672475998373
[11/26 03:45:38 visual_prompt]: Epoch 60 / 100: avg data time: 4.60e+00, avg batch time: 6.0495, average train loss: 5.0333
[11/26 03:46:26 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.5863, average loss: 0.8204
[11/26 03:46:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.76	
[11/26 03:46:26 visual_prompt]: Training 61 / 100 epoch, with learning rate 2.0658795558326744
[11/26 03:53:31 visual_prompt]: Epoch 61 / 100: avg data time: 4.61e+00, avg batch time: 6.0730, average train loss: 2.9351
[11/26 03:54:20 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.5914, average loss: 2.7852
[11/26 03:54:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 43.39	
[11/26 03:54:20 visual_prompt]: Training 62 / 100 epoch, with learning rate 1.980220772955602
[11/26 04:01:25 visual_prompt]: Epoch 62 / 100: avg data time: 4.61e+00, avg batch time: 6.0667, average train loss: 4.6942
[11/26 04:02:13 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.5876, average loss: 4.1326
[11/26 04:02:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.83	
[11/26 04:02:13 visual_prompt]: Training 63 / 100 epoch, with learning rate 1.895195261000831
[11/26 04:09:18 visual_prompt]: Epoch 63 / 100: avg data time: 4.61e+00, avg batch time: 6.0615, average train loss: 2.7773
[11/26 04:10:06 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.5898, average loss: 7.2329
[11/26 04:10:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.46	
[11/26 04:10:06 visual_prompt]: Training 64 / 100 epoch, with learning rate 1.8109066104575022
[11/26 04:17:08 visual_prompt]: Epoch 64 / 100: avg data time: 4.58e+00, avg batch time: 6.0340, average train loss: 2.9002
[11/26 04:17:57 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.5859, average loss: 1.0962
[11/26 04:17:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.44	
[11/26 04:17:57 visual_prompt]: Training 65 / 100 epoch, with learning rate 1.7274575140626316
[11/26 04:25:00 visual_prompt]: Epoch 65 / 100: avg data time: 4.58e+00, avg batch time: 6.0342, average train loss: 2.2727
[11/26 04:25:48 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.5882, average loss: 0.6925
[11/26 04:25:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.92	
[11/26 04:25:48 visual_prompt]: Best epoch 65: best metric: -0.693
[11/26 04:25:48 visual_prompt]: Training 66 / 100 epoch, with learning rate 1.6449496416858285
[11/26 04:32:47 visual_prompt]: Epoch 66 / 100: avg data time: 4.53e+00, avg batch time: 5.9876, average train loss: 1.4498
[11/26 04:33:35 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.5861, average loss: 0.9905
[11/26 04:33:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.02	
[11/26 04:33:35 visual_prompt]: Training 67 / 100 epoch, with learning rate 1.5634835164602199
[11/26 04:40:34 visual_prompt]: Epoch 67 / 100: avg data time: 4.53e+00, avg batch time: 5.9879, average train loss: 1.9112
[11/26 04:41:22 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.5868, average loss: 1.9140
[11/26 04:41:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.73	
[11/26 04:41:22 visual_prompt]: Training 68 / 100 epoch, with learning rate 1.4831583923104998
[11/26 04:48:22 visual_prompt]: Epoch 68 / 100: avg data time: 4.54e+00, avg batch time: 5.9919, average train loss: 1.7048
[11/26 04:49:10 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.5888, average loss: 0.9801
[11/26 04:49:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.73	
[11/26 04:49:10 visual_prompt]: Training 69 / 100 epoch, with learning rate 1.4040721330273063
[11/26 04:56:10 visual_prompt]: Epoch 69 / 100: avg data time: 4.54e+00, avg batch time: 5.9956, average train loss: 1.7174
[11/26 04:56:58 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.5845, average loss: 1.5635
[11/26 04:56:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.93	
[11/26 04:56:58 visual_prompt]: Training 70 / 100 epoch, with learning rate 1.3263210930352738
[11/26 05:04:00 visual_prompt]: Epoch 70 / 100: avg data time: 4.57e+00, avg batch time: 6.0265, average train loss: 1.1911
[11/26 05:04:48 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.5887, average loss: 0.7427
[11/26 05:04:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 41.53	
[11/26 05:04:48 visual_prompt]: Training 71 / 100 epoch, with learning rate 1.2500000000000004
[11/26 05:11:49 visual_prompt]: Epoch 71 / 100: avg data time: 4.56e+00, avg batch time: 6.0112, average train loss: 2.0104
[11/26 05:12:37 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.5901, average loss: 2.5056
[11/26 05:12:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.35	
[11/26 05:12:37 visual_prompt]: Training 72 / 100 epoch, with learning rate 1.175201839416988
[11/26 05:19:36 visual_prompt]: Epoch 72 / 100: avg data time: 4.53e+00, avg batch time: 5.9848, average train loss: 3.0487
[11/26 05:20:24 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.5893, average loss: 4.9806
[11/26 05:20:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.67	
[11/26 05:20:24 visual_prompt]: Training 73 / 100 epoch, with learning rate 1.1020177413231333
[11/26 05:27:25 visual_prompt]: Epoch 73 / 100: avg data time: 4.56e+00, avg batch time: 6.0083, average train loss: 1.3755
[11/26 05:28:13 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.5867, average loss: 0.8977
[11/26 05:28:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.26	
[11/26 05:28:13 visual_prompt]: Training 74 / 100 epoch, with learning rate 1.0305368692688175
[11/26 05:35:17 visual_prompt]: Epoch 74 / 100: avg data time: 4.60e+00, avg batch time: 6.0528, average train loss: 1.2382
[11/26 05:36:06 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.5920, average loss: 2.1079
[11/26 05:36:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.18	
[11/26 05:36:06 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.9608463116858543
[11/26 05:43:10 visual_prompt]: Epoch 75 / 100: avg data time: 4.61e+00, avg batch time: 6.0585, average train loss: 0.9729
[11/26 05:43:59 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.5876, average loss: 2.1979
[11/26 05:43:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.84	
[11/26 05:43:59 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.8930309757836516
[11/26 05:51:02 visual_prompt]: Epoch 76 / 100: avg data time: 4.59e+00, avg batch time: 6.0483, average train loss: 0.9251
[11/26 05:51:51 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.5845, average loss: 0.7825
[11/26 05:51:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.85	
[11/26 05:51:51 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.8271734841028553
[11/26 05:58:54 visual_prompt]: Epoch 77 / 100: avg data time: 4.60e+00, avg batch time: 6.0526, average train loss: 1.0279
[11/26 05:59:43 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.5875, average loss: 0.7550
[11/26 05:59:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 44.77	
[11/26 05:59:43 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.7633540738525066
[11/26 06:06:46 visual_prompt]: Epoch 78 / 100: avg data time: 4.59e+00, avg batch time: 6.0449, average train loss: 0.7910
[11/26 06:07:35 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.5908, average loss: 1.0162
[11/26 06:07:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.34	
[11/26 06:07:35 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.7016504991533725
[11/26 06:14:38 visual_prompt]: Epoch 79 / 100: avg data time: 4.60e+00, avg batch time: 6.0501, average train loss: 0.7969
[11/26 06:15:27 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.5884, average loss: 0.7253
[11/26 06:15:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.19	
[11/26 06:15:27 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.6421379363065141
[11/26 06:22:32 visual_prompt]: Epoch 80 / 100: avg data time: 4.62e+00, avg batch time: 6.0765, average train loss: 0.7884
[11/26 06:23:21 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.5867, average loss: 0.6886
[11/26 06:23:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.02	
[11/26 06:23:21 visual_prompt]: Best epoch 80: best metric: -0.689
[11/26 06:23:21 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.5848888922025552
[11/26 06:30:24 visual_prompt]: Epoch 81 / 100: avg data time: 4.60e+00, avg batch time: 6.0474, average train loss: 0.8506
[11/26 06:31:13 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.5924, average loss: 1.2597
[11/26 06:31:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 42.17	
[11/26 06:31:13 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.5299731159831953
[11/26 06:38:17 visual_prompt]: Epoch 82 / 100: avg data time: 4.60e+00, avg batch time: 6.0553, average train loss: 0.8426
[11/26 06:39:06 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.5885, average loss: 3.8597
[11/26 06:39:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.66	
[11/26 06:39:06 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.47745751406263165
[11/26 06:46:08 visual_prompt]: Epoch 83 / 100: avg data time: 4.58e+00, avg batch time: 6.0312, average train loss: 0.9086
[11/26 06:46:56 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.5870, average loss: 0.8274
[11/26 06:46:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.17	
[11/26 06:46:56 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.42740606861239594
[11/26 06:54:02 visual_prompt]: Epoch 84 / 100: avg data time: 4.62e+00, avg batch time: 6.0747, average train loss: 0.8051
[11/26 06:54:50 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.5871, average loss: 1.8962
[11/26 06:54:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.81	
[11/26 06:54:50 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.3798797596089351
[11/26 07:01:55 visual_prompt]: Epoch 85 / 100: avg data time: 4.61e+00, avg batch time: 6.0686, average train loss: 0.7563
[11/26 07:02:44 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.5897, average loss: 0.7077
[11/26 07:02:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.85	
[11/26 07:02:44 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.33493649053890323
[11/26 07:09:48 visual_prompt]: Epoch 86 / 100: avg data time: 4.60e+00, avg batch time: 6.0559, average train loss: 0.7527
[11/26 07:10:36 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.5840, average loss: 0.7161
[11/26 07:10:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 43.32	
[11/26 07:10:36 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.29263101785268253
[11/26 07:17:40 visual_prompt]: Epoch 87 / 100: avg data time: 4.60e+00, avg batch time: 6.0511, average train loss: 0.7372
[11/26 07:18:29 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.5859, average loss: 0.7572
[11/26 07:18:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.58	
[11/26 07:18:29 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.25301488425208296
[11/26 07:25:33 visual_prompt]: Epoch 88 / 100: avg data time: 4.60e+00, avg batch time: 6.0590, average train loss: 0.7249
[11/26 07:26:21 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.5891, average loss: 0.7026
[11/26 07:26:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.82	
[11/26 07:26:21 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.21613635589349756
[11/26 07:33:25 visual_prompt]: Epoch 89 / 100: avg data time: 4.59e+00, avg batch time: 6.0436, average train loss: 0.7001
[11/26 07:34:13 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.5865, average loss: 0.8604
[11/26 07:34:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.27	
[11/26 07:34:13 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.18204036358303172
[11/26 07:41:18 visual_prompt]: Epoch 90 / 100: avg data time: 4.61e+00, avg batch time: 6.0638, average train loss: 0.7093
[11/26 07:42:06 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.5892, average loss: 0.7423
[11/26 07:42:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.92	
[11/26 07:42:06 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.1507684480352292
[11/26 07:49:10 visual_prompt]: Epoch 91 / 100: avg data time: 4.59e+00, avg batch time: 6.0491, average train loss: 0.7153
[11/26 07:49:58 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.5872, average loss: 0.7559
[11/26 07:49:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.55	
[11/26 07:49:58 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.12235870926211617
[11/26 07:57:02 visual_prompt]: Epoch 92 / 100: avg data time: 4.60e+00, avg batch time: 6.0571, average train loss: 0.7118
[11/26 07:57:51 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.5902, average loss: 0.7379
[11/26 07:57:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.94	
[11/26 07:57:51 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.09684576015420276
[11/26 08:04:56 visual_prompt]: Epoch 93 / 100: avg data time: 4.61e+00, avg batch time: 6.0655, average train loss: 0.7016
[11/26 08:05:44 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.5876, average loss: 0.7159
[11/26 08:05:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.56	
[11/26 08:05:44 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.07426068431000882
[11/26 08:12:50 visual_prompt]: Epoch 94 / 100: avg data time: 4.62e+00, avg batch time: 6.0714, average train loss: 0.6966
[11/26 08:13:38 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.5848, average loss: 0.6910
[11/26 08:13:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.27	
[11/26 08:13:38 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.05463099816548578
[11/26 08:20:42 visual_prompt]: Epoch 95 / 100: avg data time: 4.60e+00, avg batch time: 6.0536, average train loss: 0.6925
[11/26 08:21:30 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.5868, average loss: 0.6898
[11/26 08:21:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.54	
[11/26 08:21:30 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.03798061746947995
[11/26 08:28:36 visual_prompt]: Epoch 96 / 100: avg data time: 4.62e+00, avg batch time: 6.0753, average train loss: 0.6901
[11/26 08:29:24 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.5864, average loss: 0.6882
[11/26 08:29:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.81	
[11/26 08:29:24 visual_prompt]: Best epoch 96: best metric: -0.688
[11/26 08:29:24 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.024329828146074095
[11/26 08:36:28 visual_prompt]: Epoch 97 / 100: avg data time: 4.59e+00, avg batch time: 6.0463, average train loss: 0.6910
[11/26 08:37:17 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.5893, average loss: 0.6882
[11/26 08:37:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.19	
[11/26 08:37:17 visual_prompt]: Best epoch 97: best metric: -0.688
[11/26 08:37:17 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.013695261579316775
[11/26 08:44:22 visual_prompt]: Epoch 98 / 100: avg data time: 4.61e+00, avg batch time: 6.0659, average train loss: 0.6924
[11/26 08:45:10 visual_prompt]: Inference (val):avg data time: 1.66e-04, avg batch time: 0.5900, average loss: 0.6884
[11/26 08:45:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.05	
[11/26 08:45:10 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.006089874350439506
[11/26 08:52:14 visual_prompt]: Epoch 99 / 100: avg data time: 4.61e+00, avg batch time: 6.0576, average train loss: 0.6895
[11/26 08:53:03 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.5861, average loss: 0.6880
[11/26 08:53:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.08	
[11/26 08:53:03 visual_prompt]: Best epoch 99: best metric: -0.688
[11/26 08:53:03 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0015229324522605947
[11/26 09:00:08 visual_prompt]: Epoch 100 / 100: avg data time: 4.61e+00, avg batch time: 6.0625, average train loss: 0.6883
[11/26 09:00:56 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.5897, average loss: 0.6880
[11/26 09:00:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.80	
[11/26 09:00:56 visual_prompt]: Best epoch 100: best metric: -0.688
[11/26 09:00:56 visual_prompt]: Rank of current process: 0. World size: 1
[11/26 09:00:56 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/26 09:00:56 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/26 09:00:56 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/26 09:00:56 visual_prompt]: Training with config:
[11/26 09:00:56 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr5.0_wd0.001/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 5.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/26 09:00:56 visual_prompt]: Loading training data...
[11/26 09:00:56 visual_prompt]: Constructing mammo-cbis dataset train...
[11/26 09:00:56 visual_prompt]: Loading validation data...
[11/26 09:00:56 visual_prompt]: Constructing mammo-cbis dataset val...
[11/26 09:00:56 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/26 09:00:59 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/26 09:00:59 visual_prompt]: tuned percent:0.532
[11/26 09:00:59 visual_prompt]: Device used for model: 0
[11/26 09:00:59 visual_prompt]: Setting up Evaluator...
[11/26 09:00:59 visual_prompt]: Setting up Trainer...
[11/26 09:00:59 visual_prompt]: 	Setting up the optimizer...
[11/26 09:00:59 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/26 09:08:04 visual_prompt]: Epoch 1 / 100: avg data time: 4.62e+00, avg batch time: 6.0723, average train loss: 1.4863
[11/26 09:08:52 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.5884, average loss: 1.4553
[11/26 09:08:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/26 09:08:52 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.5
[11/26 09:15:57 visual_prompt]: Epoch 2 / 100: avg data time: 4.61e+00, avg batch time: 6.0607, average train loss: 2.8978
[11/26 09:16:45 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.5855, average loss: 1.1899
[11/26 09:16:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.24	
[11/26 09:16:45 visual_prompt]: Training 3 / 100 epoch, with learning rate 1.0
[11/26 09:23:50 visual_prompt]: Epoch 3 / 100: avg data time: 4.60e+00, avg batch time: 6.0592, average train loss: 0.9268
[11/26 09:24:38 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.5877, average loss: 2.7142
[11/26 09:24:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.76	
[11/26 09:24:38 visual_prompt]: Training 4 / 100 epoch, with learning rate 1.5
[11/26 09:31:42 visual_prompt]: Epoch 4 / 100: avg data time: 4.60e+00, avg batch time: 6.0521, average train loss: 1.0662
[11/26 09:32:30 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.5846, average loss: 1.0212
[11/26 09:32:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.06	
[11/26 09:32:30 visual_prompt]: Training 5 / 100 epoch, with learning rate 2.0
[11/26 09:39:33 visual_prompt]: Epoch 5 / 100: avg data time: 4.58e+00, avg batch time: 6.0413, average train loss: 2.5803
[11/26 09:40:22 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.5882, average loss: 1.5971
[11/26 09:40:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.65	
[11/26 09:40:22 visual_prompt]: Training 6 / 100 epoch, with learning rate 2.5
[11/26 09:47:26 visual_prompt]: Epoch 6 / 100: avg data time: 4.61e+00, avg batch time: 6.0583, average train loss: 4.0769
[11/26 09:48:15 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.5968, average loss: 2.8670
[11/26 09:48:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.65	
[11/26 09:48:15 visual_prompt]: Training 7 / 100 epoch, with learning rate 3.0
[11/26 09:55:17 visual_prompt]: Epoch 7 / 100: avg data time: 4.59e+00, avg batch time: 6.0389, average train loss: 5.1670
[11/26 09:56:06 visual_prompt]: Inference (val):avg data time: 2.05e-05, avg batch time: 0.5829, average loss: 2.9397
[11/26 09:56:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.88	
[11/26 09:56:06 visual_prompt]: Training 8 / 100 epoch, with learning rate 3.5
[11/26 10:03:10 visual_prompt]: Epoch 8 / 100: avg data time: 4.60e+00, avg batch time: 6.0520, average train loss: 4.9820
[11/26 10:03:58 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.5853, average loss: 1.7092
[11/26 10:03:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.12	
[11/26 10:03:58 visual_prompt]: Training 9 / 100 epoch, with learning rate 4.0
[11/26 10:11:04 visual_prompt]: Epoch 9 / 100: avg data time: 4.63e+00, avg batch time: 6.0818, average train loss: 8.7479
[11/26 10:11:52 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.5847, average loss: 14.9935
[11/26 10:11:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.28	
[11/26 10:11:52 visual_prompt]: Training 10 / 100 epoch, with learning rate 4.5
[11/26 10:18:55 visual_prompt]: Epoch 10 / 100: avg data time: 4.59e+00, avg batch time: 6.0377, average train loss: 7.4337
[11/26 10:19:43 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.5888, average loss: 2.8783
[11/26 10:19:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 36.28	
[11/26 10:19:43 visual_prompt]: Training 11 / 100 epoch, with learning rate 5.0
[11/26 10:26:47 visual_prompt]: Epoch 11 / 100: avg data time: 4.60e+00, avg batch time: 6.0569, average train loss: 10.4079
[11/26 10:27:36 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.5869, average loss: 14.2705
[11/26 10:27:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.36	
[11/26 10:27:36 visual_prompt]: Training 12 / 100 epoch, with learning rate 4.998477067547739
[11/26 10:34:39 visual_prompt]: Epoch 12 / 100: avg data time: 4.60e+00, avg batch time: 6.0507, average train loss: 8.1934
[11/26 10:35:28 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.5877, average loss: 1.4378
[11/26 10:35:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.42	
[11/26 10:35:28 visual_prompt]: Best epoch 12: best metric: -1.438
[11/26 10:35:28 visual_prompt]: Training 13 / 100 epoch, with learning rate 4.993910125649561
[11/26 10:42:32 visual_prompt]: Epoch 13 / 100: avg data time: 4.60e+00, avg batch time: 6.0547, average train loss: 6.6119
[11/26 10:43:20 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.5871, average loss: 5.7244
[11/26 10:43:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.10	
[11/26 10:43:20 visual_prompt]: Training 14 / 100 epoch, with learning rate 4.986304738420683
[11/26 10:50:24 visual_prompt]: Epoch 14 / 100: avg data time: 4.59e+00, avg batch time: 6.0451, average train loss: 7.0518
[11/26 10:51:12 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.5877, average loss: 1.4982
[11/26 10:51:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.48	
[11/26 10:51:12 visual_prompt]: Training 15 / 100 epoch, with learning rate 4.975670171853926
[11/26 10:58:15 visual_prompt]: Epoch 15 / 100: avg data time: 4.59e+00, avg batch time: 6.0371, average train loss: 8.7011
[11/26 10:59:03 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.5863, average loss: 19.3746
[11/26 10:59:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.14	
[11/26 10:59:03 visual_prompt]: Training 16 / 100 epoch, with learning rate 4.962019382530521
[11/26 11:06:09 visual_prompt]: Epoch 16 / 100: avg data time: 4.62e+00, avg batch time: 6.0744, average train loss: 11.8345
[11/26 11:06:57 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.5918, average loss: 12.6651
[11/26 11:06:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.78	
[11/26 11:06:57 visual_prompt]: Training 17 / 100 epoch, with learning rate 4.945369001834514
[11/26 11:14:01 visual_prompt]: Epoch 17 / 100: avg data time: 4.60e+00, avg batch time: 6.0512, average train loss: 10.2071
[11/26 11:14:49 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.5868, average loss: 19.4111
[11/26 11:14:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.09	
[11/26 11:14:49 visual_prompt]: Training 18 / 100 epoch, with learning rate 4.925739315689991
[11/26 11:21:52 visual_prompt]: Epoch 18 / 100: avg data time: 4.59e+00, avg batch time: 6.0389, average train loss: 11.8288
[11/26 11:22:41 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.5927, average loss: 8.3764
[11/26 11:22:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 45.77	
[11/26 11:22:41 visual_prompt]: Training 19 / 100 epoch, with learning rate 4.903154239845797
[11/26 11:29:44 visual_prompt]: Epoch 19 / 100: avg data time: 4.59e+00, avg batch time: 6.0449, average train loss: 9.3241
[11/26 11:30:32 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.5878, average loss: 10.6516
[11/26 11:30:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.59	
[11/26 11:30:32 visual_prompt]: Training 20 / 100 epoch, with learning rate 4.877641290737884
[11/26 11:37:37 visual_prompt]: Epoch 20 / 100: avg data time: 4.61e+00, avg batch time: 6.0634, average train loss: 10.6186
[11/26 11:38:25 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.5877, average loss: 43.1789
[11/26 11:38:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.98	
[11/26 11:38:25 visual_prompt]: Training 21 / 100 epoch, with learning rate 4.849231551964771
[11/26 11:45:30 visual_prompt]: Epoch 21 / 100: avg data time: 4.61e+00, avg batch time: 6.0586, average train loss: 11.0316
[11/26 11:46:18 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.5880, average loss: 5.5902
[11/26 11:46:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.13	
[11/26 11:46:18 visual_prompt]: Training 22 / 100 epoch, with learning rate 4.817959636416969
[11/26 11:53:22 visual_prompt]: Epoch 22 / 100: avg data time: 4.60e+00, avg batch time: 6.0486, average train loss: 7.3485
[11/26 11:54:10 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.5882, average loss: 5.8560
[11/26 11:54:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.23	
[11/26 11:54:10 visual_prompt]: Training 23 / 100 epoch, with learning rate 4.783863644106502
[11/26 12:01:15 visual_prompt]: Epoch 23 / 100: avg data time: 4.62e+00, avg batch time: 6.0666, average train loss: 4.9776
[11/26 12:02:03 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.5852, average loss: 8.4203
[11/26 12:02:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.75	
[11/26 12:02:03 visual_prompt]: Training 24 / 100 epoch, with learning rate 4.7469851157479175
[11/26 12:09:07 visual_prompt]: Epoch 24 / 100: avg data time: 4.60e+00, avg batch time: 6.0541, average train loss: 6.1281
[11/26 12:09:56 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.5900, average loss: 9.4248
[11/26 12:09:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.93	rocauc: 51.89	
[11/26 12:09:56 visual_prompt]: Training 25 / 100 epoch, with learning rate 4.707368982147317
[11/26 12:17:00 visual_prompt]: Epoch 25 / 100: avg data time: 4.61e+00, avg batch time: 6.0606, average train loss: 7.9870
[11/26 12:17:48 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.5852, average loss: 6.5772
[11/26 12:17:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.32	
[11/26 12:17:48 visual_prompt]: Training 26 / 100 epoch, with learning rate 4.665063509461097
[11/26 12:24:52 visual_prompt]: Epoch 26 / 100: avg data time: 4.60e+00, avg batch time: 6.0553, average train loss: 6.0641
[11/26 12:25:41 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.5862, average loss: 10.5304
[11/26 12:25:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.37	
[11/26 12:25:41 visual_prompt]: Training 27 / 100 epoch, with learning rate 4.620120240391064
[11/26 12:32:45 visual_prompt]: Epoch 27 / 100: avg data time: 4.61e+00, avg batch time: 6.0636, average train loss: 14.6165
[11/26 12:33:34 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.5849, average loss: 41.1344
[11/26 12:33:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.14	
[11/26 12:33:34 visual_prompt]: Training 28 / 100 epoch, with learning rate 4.572593931387604
[11/26 12:40:38 visual_prompt]: Epoch 28 / 100: avg data time: 4.60e+00, avg batch time: 6.0573, average train loss: 9.5161
[11/26 12:41:26 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.5876, average loss: 6.0066
[11/26 12:41:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.18	
[11/26 12:41:26 visual_prompt]: Training 29 / 100 epoch, with learning rate 4.522542485937368
[11/26 12:48:30 visual_prompt]: Epoch 29 / 100: avg data time: 4.59e+00, avg batch time: 6.0516, average train loss: 11.2949
[11/26 12:49:18 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.5863, average loss: 0.9710
[11/26 12:49:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.70	
[11/26 12:49:18 visual_prompt]: Best epoch 29: best metric: -0.971
[11/26 12:49:18 visual_prompt]: Training 30 / 100 epoch, with learning rate 4.4700268840168045
[11/26 12:56:18 visual_prompt]: Epoch 30 / 100: avg data time: 4.55e+00, avg batch time: 6.0038, average train loss: 7.3331
[11/26 12:57:06 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.5839, average loss: 2.8683
[11/26 12:57:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.01	
[11/26 12:57:06 visual_prompt]: Training 31 / 100 epoch, with learning rate 4.415111107797445
[11/26 13:04:06 visual_prompt]: Epoch 31 / 100: avg data time: 4.54e+00, avg batch time: 5.9892, average train loss: 7.3782
[11/26 13:04:54 visual_prompt]: Inference (val):avg data time: 2.08e-05, avg batch time: 0.5870, average loss: 5.7501
[11/26 13:04:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.65	
[11/26 13:04:54 visual_prompt]: Training 32 / 100 epoch, with learning rate 4.357862063693486
[11/26 13:11:53 visual_prompt]: Epoch 32 / 100: avg data time: 4.54e+00, avg batch time: 5.9933, average train loss: 7.5428
[11/26 13:12:41 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.5872, average loss: 7.7634
[11/26 13:12:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.43	
[11/26 13:12:41 visual_prompt]: Training 33 / 100 epoch, with learning rate 4.298349500846628
[11/26 13:19:42 visual_prompt]: Epoch 33 / 100: avg data time: 4.55e+00, avg batch time: 6.0022, average train loss: 9.2230
[11/26 13:20:30 visual_prompt]: Inference (val):avg data time: 1.99e-05, avg batch time: 0.5836, average loss: 11.5800
[11/26 13:20:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.20	
[11/26 13:20:30 visual_prompt]: Training 34 / 100 epoch, with learning rate 4.236645926147493
[11/26 13:27:32 visual_prompt]: Epoch 34 / 100: avg data time: 4.57e+00, avg batch time: 6.0280, average train loss: 8.8575
[11/26 13:28:20 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.5863, average loss: 11.6292
[11/26 13:28:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.69	
[11/26 13:28:20 visual_prompt]: Training 35 / 100 epoch, with learning rate 4.172826515897146
[11/26 13:35:24 visual_prompt]: Epoch 35 / 100: avg data time: 4.59e+00, avg batch time: 6.0483, average train loss: 5.6028
[11/26 13:36:12 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.5878, average loss: 10.5573
[11/26 13:36:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.53	
[11/26 13:36:12 visual_prompt]: Training 36 / 100 epoch, with learning rate 4.106969024216348
[11/26 13:43:17 visual_prompt]: Epoch 36 / 100: avg data time: 4.62e+00, avg batch time: 6.0706, average train loss: 7.0038
[11/26 13:44:06 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.5895, average loss: 0.9383
[11/26 13:44:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.63	
[11/26 13:44:06 visual_prompt]: Best epoch 36: best metric: -0.938
[11/26 13:44:06 visual_prompt]: Training 37 / 100 epoch, with learning rate 4.039153688314146
[11/26 13:51:10 visual_prompt]: Epoch 37 / 100: avg data time: 4.59e+00, avg batch time: 6.0532, average train loss: 4.1264
[11/26 13:51:58 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.5843, average loss: 0.9051
[11/26 13:51:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.95	
[11/26 13:51:58 visual_prompt]: Best epoch 37: best metric: -0.905
[11/26 13:51:58 visual_prompt]: Training 38 / 100 epoch, with learning rate 3.969463130731183
[11/26 13:59:01 visual_prompt]: Epoch 38 / 100: avg data time: 4.60e+00, avg batch time: 6.0502, average train loss: 8.2128
[11/26 13:59:50 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.5882, average loss: 14.3950
[11/26 13:59:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.68	
[11/26 13:59:50 visual_prompt]: Training 39 / 100 epoch, with learning rate 3.897982258676867
[11/26 14:06:52 visual_prompt]: Epoch 39 / 100: avg data time: 4.57e+00, avg batch time: 6.0264, average train loss: 6.6059
[11/26 14:07:40 visual_prompt]: Inference (val):avg data time: 2.11e-05, avg batch time: 0.5855, average loss: 8.0196
[11/26 14:07:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.96	
[11/26 14:07:40 visual_prompt]: Training 40 / 100 epoch, with learning rate 3.824798160583012
[11/26 14:14:45 visual_prompt]: Epoch 40 / 100: avg data time: 4.62e+00, avg batch time: 6.0803, average train loss: 2.4294
[11/26 14:15:34 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.5899, average loss: 6.8174
[11/26 14:15:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.19	
[11/26 14:15:34 visual_prompt]: Training 41 / 100 epoch, with learning rate 3.75
[11/26 14:22:37 visual_prompt]: Epoch 41 / 100: avg data time: 4.60e+00, avg batch time: 6.0495, average train loss: 4.9195
[11/26 14:23:26 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.5873, average loss: 12.5432
[11/26 14:23:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.43	
[11/26 14:23:26 visual_prompt]: Training 42 / 100 epoch, with learning rate 3.673678906964727
[11/26 14:30:29 visual_prompt]: Epoch 42 / 100: avg data time: 4.59e+00, avg batch time: 6.0436, average train loss: 6.3314
[11/26 14:31:18 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.5850, average loss: 0.9733
[11/26 14:31:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.88	
[11/26 14:31:18 visual_prompt]: Training 43 / 100 epoch, with learning rate 3.5959278669726933
[11/26 14:38:22 visual_prompt]: Epoch 43 / 100: avg data time: 4.60e+00, avg batch time: 6.0580, average train loss: 5.2865
[11/26 14:39:10 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.5831, average loss: 13.8458
[11/26 14:39:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 66.01	
[11/26 14:39:10 visual_prompt]: Training 44 / 100 epoch, with learning rate 3.516841607689501
[11/26 14:46:16 visual_prompt]: Epoch 44 / 100: avg data time: 4.63e+00, avg batch time: 6.0800, average train loss: 8.0973
[11/26 14:47:04 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.5912, average loss: 0.7324
[11/26 14:47:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.64	
[11/26 14:47:04 visual_prompt]: Best epoch 44: best metric: -0.732
[11/26 14:47:04 visual_prompt]: Training 45 / 100 epoch, with learning rate 3.4365164835397803
[11/26 14:54:09 visual_prompt]: Epoch 45 / 100: avg data time: 4.60e+00, avg batch time: 6.0568, average train loss: 5.7246
[11/26 14:54:57 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.5840, average loss: 2.2594
[11/26 14:54:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.84	
[11/26 14:54:57 visual_prompt]: Training 46 / 100 epoch, with learning rate 3.3550503583141724
[11/26 15:01:58 visual_prompt]: Epoch 46 / 100: avg data time: 4.57e+00, avg batch time: 6.0154, average train loss: 4.4382
[11/26 15:02:46 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.5854, average loss: 7.2505
[11/26 15:02:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.83	
[11/26 15:02:46 visual_prompt]: Training 47 / 100 epoch, with learning rate 3.2725424859373686
[11/26 15:09:50 visual_prompt]: Epoch 47 / 100: avg data time: 4.60e+00, avg batch time: 6.0513, average train loss: 3.5499
[11/26 15:10:38 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.5876, average loss: 3.8663
[11/26 15:10:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.13	
[11/26 15:10:38 visual_prompt]: Training 48 / 100 epoch, with learning rate 3.1890933895424975
[11/26 15:17:41 visual_prompt]: Epoch 48 / 100: avg data time: 4.58e+00, avg batch time: 6.0316, average train loss: 5.5084
[11/26 15:18:29 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.5865, average loss: 5.7587
[11/26 15:18:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.40	
[11/26 15:18:29 visual_prompt]: Training 49 / 100 epoch, with learning rate 3.104804738999169
[11/26 15:25:33 visual_prompt]: Epoch 49 / 100: avg data time: 4.60e+00, avg batch time: 6.0469, average train loss: 4.4050
[11/26 15:26:21 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.5896, average loss: 5.3155
[11/26 15:26:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.59	
[11/26 15:26:21 visual_prompt]: Training 50 / 100 epoch, with learning rate 3.019779227044398
[11/26 15:33:25 visual_prompt]: Epoch 50 / 100: avg data time: 4.59e+00, avg batch time: 6.0488, average train loss: 3.9728
[11/26 15:34:13 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.5849, average loss: 7.4160
[11/26 15:34:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.16	
[11/26 15:34:13 visual_prompt]: Training 51 / 100 epoch, with learning rate 2.934120444167326
[11/26 15:41:16 visual_prompt]: Epoch 51 / 100: avg data time: 4.59e+00, avg batch time: 6.0444, average train loss: 3.7919
[11/26 15:42:05 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.5864, average loss: 3.9273
[11/26 15:42:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 40.61	
[11/26 15:42:05 visual_prompt]: Training 52 / 100 epoch, with learning rate 2.8479327524001636
[11/26 15:49:05 visual_prompt]: Epoch 52 / 100: avg data time: 4.56e+00, avg batch time: 6.0075, average train loss: 4.3940
[11/26 15:49:53 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.5877, average loss: 0.8471
[11/26 15:49:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.10	
[11/26 15:49:53 visual_prompt]: Training 53 / 100 epoch, with learning rate 2.761321158169134
[11/26 15:56:58 visual_prompt]: Epoch 53 / 100: avg data time: 4.61e+00, avg batch time: 6.0655, average train loss: 1.9681
[11/26 15:57:46 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.5886, average loss: 0.9335
[11/26 15:57:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.17	
[11/26 15:57:46 visual_prompt]: Training 54 / 100 epoch, with learning rate 2.6743911843603128
[11/26 16:04:50 visual_prompt]: Epoch 54 / 100: avg data time: 4.60e+00, avg batch time: 6.0533, average train loss: 1.8149
[11/26 16:05:38 visual_prompt]: Inference (val):avg data time: 2.00e-05, avg batch time: 0.5871, average loss: 6.0833
[11/26 16:05:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.04	
[11/26 16:05:38 visual_prompt]: Training 55 / 100 epoch, with learning rate 2.5872487417562526
[11/26 16:12:42 visual_prompt]: Epoch 55 / 100: avg data time: 4.60e+00, avg batch time: 6.0493, average train loss: 3.1224
[11/26 16:13:30 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.5840, average loss: 1.0329
[11/26 16:13:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.61	
[11/26 16:13:30 visual_prompt]: Training 56 / 100 epoch, with learning rate 2.5
[11/26 16:20:29 visual_prompt]: Epoch 56 / 100: avg data time: 4.53e+00, avg batch time: 5.9782, average train loss: 2.9985
[11/26 16:21:17 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.5889, average loss: 12.2596
[11/26 16:21:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.37	
[11/26 16:21:17 visual_prompt]: Training 57 / 100 epoch, with learning rate 2.4127512582437483
[11/26 16:28:17 visual_prompt]: Epoch 57 / 100: avg data time: 4.55e+00, avg batch time: 6.0006, average train loss: 5.0121
[11/26 16:29:05 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.5837, average loss: 11.6711
[11/26 16:29:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 43.66	
[11/26 16:29:05 visual_prompt]: Training 58 / 100 epoch, with learning rate 2.325608815639687
[11/26 16:36:04 visual_prompt]: Epoch 58 / 100: avg data time: 4.53e+00, avg batch time: 5.9824, average train loss: 5.5234
[11/26 16:36:52 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.5870, average loss: 1.2080
[11/26 16:36:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.22	
[11/26 16:36:52 visual_prompt]: Training 59 / 100 epoch, with learning rate 2.2386788418308665
[11/26 16:43:52 visual_prompt]: Epoch 59 / 100: avg data time: 4.55e+00, avg batch time: 6.0045, average train loss: 2.2042
[11/26 16:44:40 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.5908, average loss: 1.1903
[11/26 16:44:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.61	
[11/26 16:44:40 visual_prompt]: Training 60 / 100 epoch, with learning rate 2.1520672475998373
[11/26 16:51:40 visual_prompt]: Epoch 60 / 100: avg data time: 4.54e+00, avg batch time: 5.9939, average train loss: 3.0541
[11/26 16:52:28 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.5854, average loss: 0.7440
[11/26 16:52:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.50	
[11/26 16:52:28 visual_prompt]: Training 61 / 100 epoch, with learning rate 2.0658795558326744
[11/26 16:59:28 visual_prompt]: Epoch 61 / 100: avg data time: 4.54e+00, avg batch time: 5.9972, average train loss: 2.2700
[11/26 17:00:16 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.5883, average loss: 2.2233
[11/26 17:00:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.64	
[11/26 17:00:16 visual_prompt]: Training 62 / 100 epoch, with learning rate 1.980220772955602
[11/26 17:07:16 visual_prompt]: Epoch 62 / 100: avg data time: 4.54e+00, avg batch time: 5.9958, average train loss: 1.3604
[11/26 17:08:03 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.5888, average loss: 2.9534
[11/26 17:08:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.84	
[11/26 17:08:03 visual_prompt]: Training 63 / 100 epoch, with learning rate 1.895195261000831
[11/26 17:15:03 visual_prompt]: Epoch 63 / 100: avg data time: 4.54e+00, avg batch time: 5.9916, average train loss: 2.2078
[11/26 17:15:51 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.5843, average loss: 2.2637
[11/26 17:15:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.61	
[11/26 17:15:51 visual_prompt]: Training 64 / 100 epoch, with learning rate 1.8109066104575022
[11/26 17:22:49 visual_prompt]: Epoch 64 / 100: avg data time: 4.52e+00, avg batch time: 5.9750, average train loss: 0.9666
[11/26 17:23:37 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.5898, average loss: 3.0542
[11/26 17:23:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.25	
[11/26 17:23:37 visual_prompt]: Training 65 / 100 epoch, with learning rate 1.7274575140626316
[11/26 17:30:37 visual_prompt]: Epoch 65 / 100: avg data time: 4.54e+00, avg batch time: 5.9912, average train loss: 1.2331
[11/26 17:31:25 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.5893, average loss: 0.6952
[11/26 17:31:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.05	
[11/26 17:31:25 visual_prompt]: Best epoch 65: best metric: -0.695
[11/26 17:31:25 visual_prompt]: Training 66 / 100 epoch, with learning rate 1.6449496416858285
[11/26 17:38:23 visual_prompt]: Epoch 66 / 100: avg data time: 4.52e+00, avg batch time: 5.9760, average train loss: 0.8354
[11/26 17:39:12 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.5854, average loss: 0.8203
[11/26 17:39:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.26	
[11/26 17:39:12 visual_prompt]: Training 67 / 100 epoch, with learning rate 1.5634835164602199
[11/26 17:46:14 visual_prompt]: Epoch 67 / 100: avg data time: 4.58e+00, avg batch time: 6.0372, average train loss: 1.3822
[11/26 17:47:03 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.5855, average loss: 2.3309
[11/26 17:47:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.41	
[11/26 17:47:03 visual_prompt]: Training 68 / 100 epoch, with learning rate 1.4831583923104998
[11/26 17:54:06 visual_prompt]: Epoch 68 / 100: avg data time: 4.59e+00, avg batch time: 6.0420, average train loss: 1.0453
[11/26 17:54:54 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.5909, average loss: 1.1917
[11/26 17:54:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.64	
[11/26 17:54:54 visual_prompt]: Training 69 / 100 epoch, with learning rate 1.4040721330273063
[11/26 18:01:58 visual_prompt]: Epoch 69 / 100: avg data time: 4.60e+00, avg batch time: 6.0566, average train loss: 2.9075
[11/26 18:02:47 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.5880, average loss: 6.1831
[11/26 18:02:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.43	
[11/26 18:02:47 visual_prompt]: Training 70 / 100 epoch, with learning rate 1.3263210930352738
[11/26 18:09:51 visual_prompt]: Epoch 70 / 100: avg data time: 4.60e+00, avg batch time: 6.0567, average train loss: 1.5790
[11/26 18:10:39 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.5863, average loss: 1.2186
[11/26 18:10:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.62	
[11/26 18:10:39 visual_prompt]: Training 71 / 100 epoch, with learning rate 1.2500000000000004
[11/26 18:17:40 visual_prompt]: Epoch 71 / 100: avg data time: 4.56e+00, avg batch time: 6.0126, average train loss: 0.9961
[11/26 18:18:28 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.5880, average loss: 1.0092
[11/26 18:18:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.03	
[11/26 18:18:28 visual_prompt]: Training 72 / 100 epoch, with learning rate 1.175201839416988
[11/26 18:25:27 visual_prompt]: Epoch 72 / 100: avg data time: 4.53e+00, avg batch time: 5.9791, average train loss: 2.1871
[11/26 18:26:15 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.5855, average loss: 0.6937
[11/26 18:26:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.40	
[11/26 18:26:15 visual_prompt]: Best epoch 72: best metric: -0.694
[11/26 18:26:15 visual_prompt]: Training 73 / 100 epoch, with learning rate 1.1020177413231333
[11/26 18:33:15 visual_prompt]: Epoch 73 / 100: avg data time: 4.54e+00, avg batch time: 5.9934, average train loss: 1.3423
[11/26 18:34:03 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.5876, average loss: 0.6954
[11/26 18:34:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.20	
[11/26 18:34:03 visual_prompt]: Training 74 / 100 epoch, with learning rate 1.0305368692688175
[11/26 18:41:02 visual_prompt]: Epoch 74 / 100: avg data time: 4.54e+00, avg batch time: 5.9952, average train loss: 0.8323
[11/26 18:41:50 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.5889, average loss: 1.1337
[11/26 18:41:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.92	
[11/26 18:41:50 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.9608463116858543
[11/26 18:48:50 visual_prompt]: Epoch 75 / 100: avg data time: 4.53e+00, avg batch time: 5.9873, average train loss: 0.9115
[11/26 18:49:37 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.5878, average loss: 1.2367
[11/26 18:49:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.74	
[11/26 18:49:37 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.8930309757836516
[11/26 18:56:36 visual_prompt]: Epoch 76 / 100: avg data time: 4.53e+00, avg batch time: 5.9807, average train loss: 0.8407
[11/26 18:57:24 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.5856, average loss: 0.7425
[11/26 18:57:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.08	
[11/26 18:57:24 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.8271734841028553
[11/26 19:04:27 visual_prompt]: Epoch 77 / 100: avg data time: 4.58e+00, avg batch time: 6.0349, average train loss: 0.8850
[11/26 19:05:15 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.5864, average loss: 0.7927
[11/26 19:05:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.36	
[11/26 19:05:15 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.7633540738525066
[11/26 19:12:18 visual_prompt]: Epoch 78 / 100: avg data time: 4.59e+00, avg batch time: 6.0431, average train loss: 0.7834
[11/26 19:13:07 visual_prompt]: Inference (val):avg data time: 2.03e-03, avg batch time: 0.5886, average loss: 0.7580
[11/26 19:13:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.00	
[11/26 19:13:07 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.7016504991533725
[11/26 19:20:11 visual_prompt]: Epoch 79 / 100: avg data time: 4.61e+00, avg batch time: 6.0568, average train loss: 0.7439
[11/26 19:20:59 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.5844, average loss: 0.6881
[11/26 19:20:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.17	
[11/26 19:20:59 visual_prompt]: Best epoch 79: best metric: -0.688
[11/26 19:20:59 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.6421379363065141
[11/26 19:28:04 visual_prompt]: Epoch 80 / 100: avg data time: 4.61e+00, avg batch time: 6.0669, average train loss: 0.7413
[11/26 19:28:53 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.5841, average loss: 0.7083
[11/26 19:28:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.30	
[11/26 19:28:53 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.5848888922025552
[11/26 19:35:55 visual_prompt]: Epoch 81 / 100: avg data time: 4.59e+00, avg batch time: 6.0372, average train loss: 0.8384
[11/26 19:36:44 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.5876, average loss: 1.9795
[11/26 19:36:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.55	
[11/26 19:36:44 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.5299731159831953
[11/26 19:43:47 visual_prompt]: Epoch 82 / 100: avg data time: 4.59e+00, avg batch time: 6.0425, average train loss: 0.7935
[11/26 19:44:35 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.5890, average loss: 0.9583
[11/26 19:44:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.01	
[11/26 19:44:35 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.47745751406263165
[11/26 19:51:38 visual_prompt]: Epoch 83 / 100: avg data time: 4.58e+00, avg batch time: 6.0312, average train loss: 0.7492
[11/26 19:52:26 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.5849, average loss: 0.6886
[11/26 19:52:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.95	
[11/26 19:52:26 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.42740606861239594
[11/26 19:59:31 visual_prompt]: Epoch 84 / 100: avg data time: 4.62e+00, avg batch time: 6.0727, average train loss: 0.7551
[11/26 20:00:20 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.5884, average loss: 1.5353
[11/26 20:00:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.02	
[11/26 20:00:20 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.3798797596089351
[11/26 20:07:21 visual_prompt]: Epoch 85 / 100: avg data time: 4.57e+00, avg batch time: 6.0229, average train loss: 0.8126
[11/26 20:08:09 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.5835, average loss: 0.7944
[11/26 20:08:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.48	
[11/26 20:08:09 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.33493649053890323
[11/26 20:15:12 visual_prompt]: Epoch 86 / 100: avg data time: 4.59e+00, avg batch time: 6.0379, average train loss: 0.7489
[11/26 20:16:00 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.5856, average loss: 0.6949
[11/26 20:16:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.65	
[11/26 20:16:00 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.29263101785268253
[11/26 20:23:04 visual_prompt]: Epoch 87 / 100: avg data time: 4.60e+00, avg batch time: 6.0528, average train loss: 0.7153
[11/26 20:23:53 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.5876, average loss: 0.7418
[11/26 20:23:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.63	
[11/26 20:23:53 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.25301488425208296
[11/26 20:30:57 visual_prompt]: Epoch 88 / 100: avg data time: 4.61e+00, avg batch time: 6.0620, average train loss: 0.7158
[11/26 20:31:46 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.5865, average loss: 0.7344
[11/26 20:31:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 62.88	
[11/26 20:31:46 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.21613635589349756
[11/26 20:38:50 visual_prompt]: Epoch 89 / 100: avg data time: 4.60e+00, avg batch time: 6.0549, average train loss: 0.6988
[11/26 20:39:38 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.5860, average loss: 0.7769
[11/26 20:39:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.98	
[11/26 20:39:38 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.18204036358303172
[11/26 20:46:43 visual_prompt]: Epoch 90 / 100: avg data time: 4.61e+00, avg batch time: 6.0648, average train loss: 0.7101
[11/26 20:47:31 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.5881, average loss: 0.7787
[11/26 20:47:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.17	
[11/26 20:47:31 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.1507684480352292
[11/26 20:54:34 visual_prompt]: Epoch 91 / 100: avg data time: 4.59e+00, avg batch time: 6.0402, average train loss: 0.7117
[11/26 20:55:23 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.5886, average loss: 0.7336
[11/26 20:55:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.96	
[11/26 20:55:23 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.12235870926211617
[11/26 21:02:26 visual_prompt]: Epoch 92 / 100: avg data time: 4.60e+00, avg batch time: 6.0476, average train loss: 0.7041
[11/26 21:03:15 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.5855, average loss: 0.7462
[11/26 21:03:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.33	
[11/26 21:03:15 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.09684576015420276
[11/26 21:10:18 visual_prompt]: Epoch 93 / 100: avg data time: 4.60e+00, avg batch time: 6.0463, average train loss: 0.7043
[11/26 21:11:06 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.5850, average loss: 0.7003
[11/26 21:11:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 61.06	
[11/26 21:11:06 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.07426068431000882
[11/26 21:18:11 visual_prompt]: Epoch 94 / 100: avg data time: 4.61e+00, avg batch time: 6.0593, average train loss: 0.7037
[11/26 21:18:59 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.5845, average loss: 0.6933
[11/26 21:18:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.62	
[11/26 21:18:59 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.05463099816548578
[11/26 21:26:02 visual_prompt]: Epoch 95 / 100: avg data time: 4.59e+00, avg batch time: 6.0441, average train loss: 0.6915
[11/26 21:26:51 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.5880, average loss: 0.6981
[11/26 21:26:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.81	
[11/26 21:26:51 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.03798061746947995
[11/26 21:33:55 visual_prompt]: Epoch 96 / 100: avg data time: 4.60e+00, avg batch time: 6.0573, average train loss: 0.6870
[11/26 21:34:43 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.5859, average loss: 0.6827
[11/26 21:34:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.73	
[11/26 21:34:43 visual_prompt]: Best epoch 96: best metric: -0.683
[11/26 21:34:43 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.024329828146074095
[11/26 21:41:48 visual_prompt]: Epoch 97 / 100: avg data time: 4.61e+00, avg batch time: 6.0678, average train loss: 0.6815
[11/26 21:42:37 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.5871, average loss: 0.6819
[11/26 21:42:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.47	rocauc: 60.21	
[11/26 21:42:37 visual_prompt]: Best epoch 97: best metric: -0.682
[11/26 21:42:37 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.013695261579316775
[11/26 21:49:37 visual_prompt]: Epoch 98 / 100: avg data time: 4.56e+00, avg batch time: 6.0079, average train loss: 0.6864
[11/26 21:50:25 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.5887, average loss: 0.7115
[11/26 21:50:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.38	
[11/26 21:50:25 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.006089874350439506
[11/26 21:57:26 visual_prompt]: Epoch 99 / 100: avg data time: 4.56e+00, avg batch time: 6.0074, average train loss: 0.6837
[11/26 21:58:15 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.5866, average loss: 0.6830
[11/26 21:58:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 58.97	
[11/26 21:58:15 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0015229324522605947
[11/26 22:05:15 visual_prompt]: Epoch 100 / 100: avg data time: 4.55e+00, avg batch time: 6.0023, average train loss: 0.6718
[11/26 22:06:03 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.5890, average loss: 0.6756
[11/26 22:06:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 58.64	
[11/26 22:06:03 visual_prompt]: Best epoch 100: best metric: -0.676
[11/26 22:06:03 visual_prompt]: Rank of current process: 0. World size: 1
[11/26 22:06:03 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/26 22:06:03 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/26 22:06:03 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/26 22:06:03 visual_prompt]: Training with config:
[11/26 22:06:03 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr5.0_wd0.0001/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 5.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/26 22:06:03 visual_prompt]: Loading training data...
[11/26 22:06:03 visual_prompt]: Constructing mammo-cbis dataset train...
[11/26 22:06:03 visual_prompt]: Loading validation data...
[11/26 22:06:03 visual_prompt]: Constructing mammo-cbis dataset val...
[11/26 22:06:03 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/26 22:06:05 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/26 22:06:05 visual_prompt]: tuned percent:0.532
[11/26 22:06:06 visual_prompt]: Device used for model: 0
[11/26 22:06:06 visual_prompt]: Setting up Evaluator...
[11/26 22:06:06 visual_prompt]: Setting up Trainer...
[11/26 22:06:06 visual_prompt]: 	Setting up the optimizer...
[11/26 22:06:06 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/26 22:13:06 visual_prompt]: Epoch 1 / 100: avg data time: 4.55e+00, avg batch time: 6.0065, average train loss: 1.4863
[11/26 22:13:54 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.5879, average loss: 1.4553
[11/26 22:13:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/26 22:13:54 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.5
[11/26 22:20:54 visual_prompt]: Epoch 2 / 100: avg data time: 4.55e+00, avg batch time: 5.9971, average train loss: 3.1415
[11/26 22:21:42 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.5872, average loss: 1.3160
[11/26 22:21:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.03	
[11/26 22:21:42 visual_prompt]: Training 3 / 100 epoch, with learning rate 1.0
[11/26 22:28:42 visual_prompt]: Epoch 3 / 100: avg data time: 4.55e+00, avg batch time: 6.0003, average train loss: 0.8800
[11/26 22:29:30 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.5902, average loss: 3.0546
[11/26 22:29:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.60	
[11/26 22:29:30 visual_prompt]: Training 4 / 100 epoch, with learning rate 1.5
[11/26 22:36:29 visual_prompt]: Epoch 4 / 100: avg data time: 4.53e+00, avg batch time: 5.9766, average train loss: 2.1609
[11/26 22:37:17 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.5865, average loss: 6.2397
[11/26 22:37:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 42.68	rocauc: 45.98	
[11/26 22:37:17 visual_prompt]: Training 5 / 100 epoch, with learning rate 2.0
[11/26 22:44:16 visual_prompt]: Epoch 5 / 100: avg data time: 4.53e+00, avg batch time: 5.9862, average train loss: 6.3105
[11/26 22:45:04 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.5880, average loss: 2.2250
[11/26 22:45:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.37	
[11/26 22:45:04 visual_prompt]: Training 6 / 100 epoch, with learning rate 2.5
[11/26 22:52:05 visual_prompt]: Epoch 6 / 100: avg data time: 4.56e+00, avg batch time: 6.0139, average train loss: 5.2307
[11/26 22:52:53 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.5886, average loss: 5.6028
[11/26 22:52:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.85	
[11/26 22:52:53 visual_prompt]: Training 7 / 100 epoch, with learning rate 3.0
[11/26 22:59:52 visual_prompt]: Epoch 7 / 100: avg data time: 4.53e+00, avg batch time: 5.9795, average train loss: 2.6285
[11/26 23:00:39 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.5862, average loss: 1.8194
[11/26 23:00:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 62.04	
[11/26 23:00:39 visual_prompt]: Training 8 / 100 epoch, with learning rate 3.5
[11/26 23:07:39 visual_prompt]: Epoch 8 / 100: avg data time: 4.54e+00, avg batch time: 5.9904, average train loss: 2.9380
[11/26 23:08:27 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.5853, average loss: 1.8029
[11/26 23:08:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.73	
[11/26 23:08:27 visual_prompt]: Training 9 / 100 epoch, with learning rate 4.0
[11/26 23:15:27 visual_prompt]: Epoch 9 / 100: avg data time: 4.54e+00, avg batch time: 5.9989, average train loss: 1.6077
[11/26 23:16:15 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.5840, average loss: 10.4896
[11/26 23:16:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.60	
[11/26 23:16:15 visual_prompt]: Training 10 / 100 epoch, with learning rate 4.5
[11/26 23:23:14 visual_prompt]: Epoch 10 / 100: avg data time: 4.52e+00, avg batch time: 5.9761, average train loss: 6.3316
[11/26 23:24:01 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.5864, average loss: 1.6291
[11/26 23:24:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.74	
[11/26 23:24:01 visual_prompt]: Training 11 / 100 epoch, with learning rate 5.0
[11/26 23:31:02 visual_prompt]: Epoch 11 / 100: avg data time: 4.55e+00, avg batch time: 6.0024, average train loss: 2.7613
[11/26 23:31:50 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.5865, average loss: 0.8698
[11/26 23:31:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.13	
[11/26 23:31:50 visual_prompt]: Training 12 / 100 epoch, with learning rate 4.998477067547739
[11/26 23:38:48 visual_prompt]: Epoch 12 / 100: avg data time: 4.53e+00, avg batch time: 5.9789, average train loss: 2.3419
[11/26 23:39:37 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.5894, average loss: 1.0342
[11/26 23:39:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.02	
[11/26 23:39:37 visual_prompt]: Training 13 / 100 epoch, with learning rate 4.993910125649561
[11/26 23:46:37 visual_prompt]: Epoch 13 / 100: avg data time: 4.54e+00, avg batch time: 5.9967, average train loss: 1.7913
[11/26 23:47:25 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.5897, average loss: 0.8108
[11/26 23:47:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.19	
[11/26 23:47:25 visual_prompt]: Best epoch 13: best metric: -0.811
[11/26 23:47:25 visual_prompt]: Training 14 / 100 epoch, with learning rate 4.986304738420683
[11/26 23:54:28 visual_prompt]: Epoch 14 / 100: avg data time: 4.59e+00, avg batch time: 6.0446, average train loss: 3.0682
[11/26 23:55:16 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.5828, average loss: 13.1656
[11/26 23:55:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.51	
[11/26 23:55:16 visual_prompt]: Training 15 / 100 epoch, with learning rate 4.975670171853926
[11/27 00:02:19 visual_prompt]: Epoch 15 / 100: avg data time: 4.59e+00, avg batch time: 6.0350, average train loss: 9.6092
[11/27 00:03:07 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.5886, average loss: 6.3453
[11/27 00:03:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.41	
[11/27 00:03:07 visual_prompt]: Training 16 / 100 epoch, with learning rate 4.962019382530521
[11/27 00:10:12 visual_prompt]: Epoch 16 / 100: avg data time: 4.61e+00, avg batch time: 6.0655, average train loss: 3.2655
[11/27 00:11:00 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.5857, average loss: 2.4876
[11/27 00:11:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.36	
[11/27 00:11:00 visual_prompt]: Training 17 / 100 epoch, with learning rate 4.945369001834514
[11/27 00:18:04 visual_prompt]: Epoch 17 / 100: avg data time: 4.60e+00, avg batch time: 6.0504, average train loss: 4.4160
[11/27 00:18:53 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.5857, average loss: 6.9346
[11/27 00:18:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.33	
[11/27 00:18:53 visual_prompt]: Training 18 / 100 epoch, with learning rate 4.925739315689991
[11/27 00:25:56 visual_prompt]: Epoch 18 / 100: avg data time: 4.60e+00, avg batch time: 6.0500, average train loss: 10.7765
[11/27 00:26:45 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.5861, average loss: 11.4695
[11/27 00:26:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.02	
[11/27 00:26:45 visual_prompt]: Training 19 / 100 epoch, with learning rate 4.903154239845797
[11/27 00:33:48 visual_prompt]: Epoch 19 / 100: avg data time: 4.60e+00, avg batch time: 6.0519, average train loss: 6.7249
[11/27 00:34:37 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.5867, average loss: 16.3497
[11/27 00:34:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.02	
[11/27 00:34:37 visual_prompt]: Training 20 / 100 epoch, with learning rate 4.877641290737884
[11/27 00:41:42 visual_prompt]: Epoch 20 / 100: avg data time: 4.61e+00, avg batch time: 6.0620, average train loss: 6.2630
[11/27 00:42:30 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.5858, average loss: 1.1243
[11/27 00:42:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.98	
[11/27 00:42:30 visual_prompt]: Training 21 / 100 epoch, with learning rate 4.849231551964771
[11/27 00:49:34 visual_prompt]: Epoch 21 / 100: avg data time: 4.60e+00, avg batch time: 6.0541, average train loss: 2.0511
[11/27 00:50:22 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.5868, average loss: 1.7977
[11/27 00:50:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.32	
[11/27 00:50:22 visual_prompt]: Training 22 / 100 epoch, with learning rate 4.817959636416969
[11/27 00:57:26 visual_prompt]: Epoch 22 / 100: avg data time: 4.60e+00, avg batch time: 6.0538, average train loss: 6.9889
[11/27 00:58:15 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.5873, average loss: 1.5059
[11/27 00:58:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.36	
[11/27 00:58:15 visual_prompt]: Training 23 / 100 epoch, with learning rate 4.783863644106502
[11/27 01:05:20 visual_prompt]: Epoch 23 / 100: avg data time: 4.62e+00, avg batch time: 6.0665, average train loss: 9.8862
[11/27 01:06:08 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.5868, average loss: 28.9307
[11/27 01:06:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.67	
[11/27 01:06:08 visual_prompt]: Training 24 / 100 epoch, with learning rate 4.7469851157479175
[11/27 01:13:12 visual_prompt]: Epoch 24 / 100: avg data time: 4.60e+00, avg batch time: 6.0517, average train loss: 12.5138
[11/27 01:14:00 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.5895, average loss: 5.0367
[11/27 01:14:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.15	
[11/27 01:14:00 visual_prompt]: Training 25 / 100 epoch, with learning rate 4.707368982147317
[11/27 01:21:05 visual_prompt]: Epoch 25 / 100: avg data time: 4.61e+00, avg batch time: 6.0612, average train loss: 5.8144
[11/27 01:21:53 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.5867, average loss: 6.2093
[11/27 01:21:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.54	
[11/27 01:21:53 visual_prompt]: Training 26 / 100 epoch, with learning rate 4.665063509461097
[11/27 01:28:57 visual_prompt]: Epoch 26 / 100: avg data time: 4.61e+00, avg batch time: 6.0584, average train loss: 3.7135
[11/27 01:29:46 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.5848, average loss: 1.9935
[11/27 01:29:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.35	
[11/27 01:29:46 visual_prompt]: Training 27 / 100 epoch, with learning rate 4.620120240391064
[11/27 01:36:48 visual_prompt]: Epoch 27 / 100: avg data time: 4.57e+00, avg batch time: 6.0244, average train loss: 2.4783
[11/27 01:37:36 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.5872, average loss: 2.7283
[11/27 01:37:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.93	
[11/27 01:37:36 visual_prompt]: Training 28 / 100 epoch, with learning rate 4.572593931387604
[11/27 01:44:39 visual_prompt]: Epoch 28 / 100: avg data time: 4.60e+00, avg batch time: 6.0463, average train loss: 4.4854
[11/27 01:45:28 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.5833, average loss: 6.9208
[11/27 01:45:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 42.63	
[11/27 01:45:28 visual_prompt]: Training 29 / 100 epoch, with learning rate 4.522542485937368
[11/27 01:52:32 visual_prompt]: Epoch 29 / 100: avg data time: 4.61e+00, avg batch time: 6.0614, average train loss: 2.5198
[11/27 01:53:21 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.5888, average loss: 1.1240
[11/27 01:53:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.11	
[11/27 01:53:21 visual_prompt]: Training 30 / 100 epoch, with learning rate 4.4700268840168045
[11/27 02:00:26 visual_prompt]: Epoch 30 / 100: avg data time: 4.62e+00, avg batch time: 6.0684, average train loss: 1.1627
[11/27 02:01:14 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.5898, average loss: 0.6890
[11/27 02:01:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.27	
[11/27 02:01:14 visual_prompt]: Best epoch 30: best metric: -0.689
[11/27 02:01:14 visual_prompt]: Training 31 / 100 epoch, with learning rate 4.415111107797445
[11/27 02:08:17 visual_prompt]: Epoch 31 / 100: avg data time: 4.59e+00, avg batch time: 6.0398, average train loss: 4.0097
[11/27 02:09:05 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.5859, average loss: 10.0016
[11/27 02:09:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 44.66	
[11/27 02:09:05 visual_prompt]: Training 32 / 100 epoch, with learning rate 4.357862063693486
[11/27 02:16:08 visual_prompt]: Epoch 32 / 100: avg data time: 4.59e+00, avg batch time: 6.0391, average train loss: 6.8595
[11/27 02:16:56 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.5831, average loss: 5.6694
[11/27 02:16:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.65	
[11/27 02:16:56 visual_prompt]: Training 33 / 100 epoch, with learning rate 4.298349500846628
[11/27 02:23:56 visual_prompt]: Epoch 33 / 100: avg data time: 4.55e+00, avg batch time: 5.9955, average train loss: 6.1954
[11/27 02:24:44 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.5861, average loss: 1.5670
[11/27 02:24:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.23	
[11/27 02:24:44 visual_prompt]: Training 34 / 100 epoch, with learning rate 4.236645926147493
[11/27 02:31:43 visual_prompt]: Epoch 34 / 100: avg data time: 4.53e+00, avg batch time: 5.9824, average train loss: 6.5962
[11/27 02:32:31 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.5847, average loss: 4.7637
[11/27 02:32:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.61	
[11/27 02:32:31 visual_prompt]: Training 35 / 100 epoch, with learning rate 4.172826515897146
[11/27 02:39:30 visual_prompt]: Epoch 35 / 100: avg data time: 4.53e+00, avg batch time: 5.9800, average train loss: 3.4015
[11/27 02:40:18 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.5854, average loss: 5.8399
[11/27 02:40:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.14	
[11/27 02:40:18 visual_prompt]: Training 36 / 100 epoch, with learning rate 4.106969024216348
[11/27 02:47:20 visual_prompt]: Epoch 36 / 100: avg data time: 4.58e+00, avg batch time: 6.0311, average train loss: 2.2716
[11/27 02:48:09 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.5856, average loss: 1.7846
[11/27 02:48:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.51	
[11/27 02:48:09 visual_prompt]: Training 37 / 100 epoch, with learning rate 4.039153688314146
[11/27 02:55:12 visual_prompt]: Epoch 37 / 100: avg data time: 4.60e+00, avg batch time: 6.0488, average train loss: 1.9668
[11/27 02:56:01 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.5858, average loss: 1.7135
[11/27 02:56:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.34	
[11/27 02:56:01 visual_prompt]: Training 38 / 100 epoch, with learning rate 3.969463130731183
[11/27 03:03:03 visual_prompt]: Epoch 38 / 100: avg data time: 4.57e+00, avg batch time: 6.0220, average train loss: 1.7722
[11/27 03:03:51 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.5874, average loss: 2.1205
[11/27 03:03:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.71	
[11/27 03:03:51 visual_prompt]: Training 39 / 100 epoch, with learning rate 3.897982258676867
[11/27 03:10:55 visual_prompt]: Epoch 39 / 100: avg data time: 4.61e+00, avg batch time: 6.0566, average train loss: 1.3737
[11/27 03:11:43 visual_prompt]: Inference (val):avg data time: 2.08e-05, avg batch time: 0.5872, average loss: 3.8372
[11/27 03:11:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.67	
[11/27 03:11:43 visual_prompt]: Training 40 / 100 epoch, with learning rate 3.824798160583012
[11/27 03:18:46 visual_prompt]: Epoch 40 / 100: avg data time: 4.59e+00, avg batch time: 6.0369, average train loss: 4.5661
[11/27 03:19:34 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.5922, average loss: 6.2383
[11/27 03:19:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.34	
[11/27 03:19:34 visual_prompt]: Training 41 / 100 epoch, with learning rate 3.75
[11/27 03:26:34 visual_prompt]: Epoch 41 / 100: avg data time: 4.53e+00, avg batch time: 5.9879, average train loss: 3.2616
[11/27 03:27:22 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.5868, average loss: 4.6884
[11/27 03:27:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.49	
[11/27 03:27:22 visual_prompt]: Training 42 / 100 epoch, with learning rate 3.673678906964727
[11/27 03:34:21 visual_prompt]: Epoch 42 / 100: avg data time: 4.54e+00, avg batch time: 5.9895, average train loss: 3.4476
[11/27 03:35:09 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.5895, average loss: 1.7988
[11/27 03:35:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 62.33	
[11/27 03:35:09 visual_prompt]: Training 43 / 100 epoch, with learning rate 3.5959278669726933
[11/27 03:42:10 visual_prompt]: Epoch 43 / 100: avg data time: 4.55e+00, avg batch time: 6.0042, average train loss: 4.9640
[11/27 03:42:58 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.5872, average loss: 0.7669
[11/27 03:42:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.44	
[11/27 03:42:58 visual_prompt]: Training 44 / 100 epoch, with learning rate 3.516841607689501
[11/27 03:50:02 visual_prompt]: Epoch 44 / 100: avg data time: 4.61e+00, avg batch time: 6.0574, average train loss: 2.5307
[11/27 03:50:50 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.5841, average loss: 1.7578
[11/27 03:50:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 62.96	
[11/27 03:50:50 visual_prompt]: Training 45 / 100 epoch, with learning rate 3.4365164835397803
[11/27 03:57:56 visual_prompt]: Epoch 45 / 100: avg data time: 4.62e+00, avg batch time: 6.0749, average train loss: 2.2364
[11/27 03:58:44 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.5901, average loss: 1.7669
[11/27 03:58:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.82	
[11/27 03:58:44 visual_prompt]: Training 46 / 100 epoch, with learning rate 3.3550503583141724
[11/27 04:05:48 visual_prompt]: Epoch 46 / 100: avg data time: 4.59e+00, avg batch time: 6.0432, average train loss: 1.3939
[11/27 04:06:36 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.5837, average loss: 1.8671
[11/27 04:06:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.29	
[11/27 04:06:36 visual_prompt]: Training 47 / 100 epoch, with learning rate 3.2725424859373686
[11/27 04:13:40 visual_prompt]: Epoch 47 / 100: avg data time: 4.60e+00, avg batch time: 6.0535, average train loss: 1.3646
[11/27 04:14:28 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.5911, average loss: 0.8342
[11/27 04:14:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 61.37	
[11/27 04:14:29 visual_prompt]: Training 48 / 100 epoch, with learning rate 3.1890933895424975
[11/27 04:21:32 visual_prompt]: Epoch 48 / 100: avg data time: 4.60e+00, avg batch time: 6.0521, average train loss: 1.1177
[11/27 04:22:21 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.5869, average loss: 1.9598
[11/27 04:22:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.35	
[11/27 04:22:21 visual_prompt]: Training 49 / 100 epoch, with learning rate 3.104804738999169
[11/27 04:29:25 visual_prompt]: Epoch 49 / 100: avg data time: 4.60e+00, avg batch time: 6.0572, average train loss: 1.4130
[11/27 04:30:13 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.5890, average loss: 3.1950
[11/27 04:30:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.96	
[11/27 04:30:14 visual_prompt]: Training 50 / 100 epoch, with learning rate 3.019779227044398
[11/27 04:37:18 visual_prompt]: Epoch 50 / 100: avg data time: 4.61e+00, avg batch time: 6.0582, average train loss: 1.7990
[11/27 04:38:06 visual_prompt]: Inference (val):avg data time: 2.08e-05, avg batch time: 0.5928, average loss: 0.7105
[11/27 04:38:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.06	
[11/27 04:38:06 visual_prompt]: Training 51 / 100 epoch, with learning rate 2.934120444167326
[11/27 04:45:09 visual_prompt]: Epoch 51 / 100: avg data time: 4.59e+00, avg batch time: 6.0406, average train loss: 1.0827
[11/27 04:45:58 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.5913, average loss: 0.7211
[11/27 04:45:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 61.38	
[11/27 04:45:58 visual_prompt]: Stopping early.
[11/27 04:45:58 visual_prompt]: Rank of current process: 0. World size: 1
[11/27 04:45:58 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/27 04:45:58 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/27 04:45:58 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/27 04:45:58 visual_prompt]: Training with config:
[11/27 04:45:58 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr5.0_wd0.0/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 5.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/27 04:45:58 visual_prompt]: Loading training data...
[11/27 04:45:58 visual_prompt]: Constructing mammo-cbis dataset train...
[11/27 04:45:58 visual_prompt]: Loading validation data...
[11/27 04:45:58 visual_prompt]: Constructing mammo-cbis dataset val...
[11/27 04:45:58 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/27 04:46:00 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/27 04:46:00 visual_prompt]: tuned percent:0.532
[11/27 04:46:00 visual_prompt]: Device used for model: 0
[11/27 04:46:00 visual_prompt]: Setting up Evaluator...
[11/27 04:46:00 visual_prompt]: Setting up Trainer...
[11/27 04:46:00 visual_prompt]: 	Setting up the optimizer...
[11/27 04:46:00 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/27 04:53:05 visual_prompt]: Epoch 1 / 100: avg data time: 4.61e+00, avg batch time: 6.0669, average train loss: 1.4863
[11/27 04:53:54 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.5858, average loss: 1.4553
[11/27 04:53:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/27 04:53:54 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.5
[11/27 05:00:59 visual_prompt]: Epoch 2 / 100: avg data time: 4.63e+00, avg batch time: 6.0812, average train loss: 2.6144
[11/27 05:01:48 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.5884, average loss: 1.6850
[11/27 05:01:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.57	
[11/27 05:01:48 visual_prompt]: Training 3 / 100 epoch, with learning rate 1.0
[11/27 05:08:52 visual_prompt]: Epoch 3 / 100: avg data time: 4.60e+00, avg batch time: 6.0568, average train loss: 1.1001
[11/27 05:09:40 visual_prompt]: Inference (val):avg data time: 1.92e-05, avg batch time: 0.5885, average loss: 3.0125
[11/27 05:09:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.64	
[11/27 05:09:40 visual_prompt]: Training 4 / 100 epoch, with learning rate 1.5
[11/27 05:16:44 visual_prompt]: Epoch 4 / 100: avg data time: 4.60e+00, avg batch time: 6.0519, average train loss: 1.9004
[11/27 05:17:33 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.5889, average loss: 0.7538
[11/27 05:17:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.54	
[11/27 05:17:33 visual_prompt]: Training 5 / 100 epoch, with learning rate 2.0
[11/27 05:24:36 visual_prompt]: Epoch 5 / 100: avg data time: 4.60e+00, avg batch time: 6.0511, average train loss: 3.6940
[11/27 05:25:25 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.5841, average loss: 1.7423
[11/27 05:25:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.03	
[11/27 05:25:25 visual_prompt]: Training 6 / 100 epoch, with learning rate 2.5
[11/27 05:32:30 visual_prompt]: Epoch 6 / 100: avg data time: 4.62e+00, avg batch time: 6.0716, average train loss: 4.4831
[11/27 05:33:19 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.5901, average loss: 0.8799
[11/27 05:33:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 61.39	
[11/27 05:33:19 visual_prompt]: Training 7 / 100 epoch, with learning rate 3.0
[11/27 05:40:22 visual_prompt]: Epoch 7 / 100: avg data time: 4.60e+00, avg batch time: 6.0477, average train loss: 3.9795
[11/27 05:41:11 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.5835, average loss: 0.8672
[11/27 05:41:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.40	
[11/27 05:41:11 visual_prompt]: Training 8 / 100 epoch, with learning rate 3.5
[11/27 05:48:15 visual_prompt]: Epoch 8 / 100: avg data time: 4.60e+00, avg batch time: 6.0598, average train loss: 1.3259
[11/27 05:49:03 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.5889, average loss: 3.8142
[11/27 05:49:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.20	
[11/27 05:49:03 visual_prompt]: Training 9 / 100 epoch, with learning rate 4.0
[11/27 05:56:07 visual_prompt]: Epoch 9 / 100: avg data time: 4.60e+00, avg batch time: 6.0542, average train loss: 3.2749
[11/27 05:56:56 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.5893, average loss: 0.7072
[11/27 05:56:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.42	
[11/27 05:56:56 visual_prompt]: Training 10 / 100 epoch, with learning rate 4.5
[11/27 06:03:59 visual_prompt]: Epoch 10 / 100: avg data time: 4.59e+00, avg batch time: 6.0471, average train loss: 5.9248
[11/27 06:04:48 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.5845, average loss: 10.7246
[11/27 06:04:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.68	
[11/27 06:04:48 visual_prompt]: Training 11 / 100 epoch, with learning rate 5.0
[11/27 06:11:52 visual_prompt]: Epoch 11 / 100: avg data time: 4.61e+00, avg batch time: 6.0585, average train loss: 11.3017
[11/27 06:12:40 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.5904, average loss: 7.9929
[11/27 06:12:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.29	
[11/27 06:12:40 visual_prompt]: Training 12 / 100 epoch, with learning rate 4.998477067547739
[11/27 06:19:43 visual_prompt]: Epoch 12 / 100: avg data time: 4.59e+00, avg batch time: 6.0406, average train loss: 8.8127
[11/27 06:20:32 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.5864, average loss: 16.7781
[11/27 06:20:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 61.64	
[11/27 06:20:32 visual_prompt]: Training 13 / 100 epoch, with learning rate 4.993910125649561
[11/27 06:27:36 visual_prompt]: Epoch 13 / 100: avg data time: 4.61e+00, avg batch time: 6.0638, average train loss: 5.9571
[11/27 06:28:25 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.5867, average loss: 5.6421
[11/27 06:28:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.60	
[11/27 06:28:25 visual_prompt]: Best epoch 13: best metric: -5.642
[11/27 06:28:25 visual_prompt]: Training 14 / 100 epoch, with learning rate 4.986304738420683
[11/27 06:35:29 visual_prompt]: Epoch 14 / 100: avg data time: 4.59e+00, avg batch time: 6.0473, average train loss: 2.4866
[11/27 06:36:17 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.5866, average loss: 3.7670
[11/27 06:36:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.67	
[11/27 06:36:17 visual_prompt]: Best epoch 14: best metric: -3.767
[11/27 06:36:17 visual_prompt]: Training 15 / 100 epoch, with learning rate 4.975670171853926
[11/27 06:43:20 visual_prompt]: Epoch 15 / 100: avg data time: 4.59e+00, avg batch time: 6.0416, average train loss: 3.6729
[11/27 06:44:09 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.5921, average loss: 3.9165
[11/27 06:44:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.02	
[11/27 06:44:09 visual_prompt]: Training 16 / 100 epoch, with learning rate 4.962019382530521
[11/27 06:51:12 visual_prompt]: Epoch 16 / 100: avg data time: 4.60e+00, avg batch time: 6.0496, average train loss: 2.0203
[11/27 06:52:01 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.5884, average loss: 1.5735
[11/27 06:52:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.89	
[11/27 06:52:01 visual_prompt]: Best epoch 16: best metric: -1.574
[11/27 06:52:01 visual_prompt]: Training 17 / 100 epoch, with learning rate 4.945369001834514
[11/27 06:59:05 visual_prompt]: Epoch 17 / 100: avg data time: 4.60e+00, avg batch time: 6.0586, average train loss: 3.5485
[11/27 06:59:53 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.5863, average loss: 4.3087
[11/27 06:59:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.93	
[11/27 06:59:53 visual_prompt]: Training 18 / 100 epoch, with learning rate 4.925739315689991
[11/27 07:06:55 visual_prompt]: Epoch 18 / 100: avg data time: 4.57e+00, avg batch time: 6.0231, average train loss: 1.9943
[11/27 07:07:43 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.5859, average loss: 9.7803
[11/27 07:07:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 66.02	
[11/27 07:07:43 visual_prompt]: Training 19 / 100 epoch, with learning rate 4.903154239845797
[11/27 07:14:42 visual_prompt]: Epoch 19 / 100: avg data time: 4.53e+00, avg batch time: 5.9795, average train loss: 3.1845
[11/27 07:15:30 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.5891, average loss: 3.5012
[11/27 07:15:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.63	
[11/27 07:15:30 visual_prompt]: Training 20 / 100 epoch, with learning rate 4.877641290737884
[11/27 07:22:30 visual_prompt]: Epoch 20 / 100: avg data time: 4.55e+00, avg batch time: 5.9986, average train loss: 3.6631
[11/27 07:23:18 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.5906, average loss: 8.6215
[11/27 07:23:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 64.25	
[11/27 07:23:18 visual_prompt]: Training 21 / 100 epoch, with learning rate 4.849231551964771
[11/27 07:30:18 visual_prompt]: Epoch 21 / 100: avg data time: 4.55e+00, avg batch time: 6.0012, average train loss: 2.3673
[11/27 07:31:06 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.5887, average loss: 3.9653
[11/27 07:31:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 66.42	
[11/27 07:31:06 visual_prompt]: Training 22 / 100 epoch, with learning rate 4.817959636416969
[11/27 07:38:06 visual_prompt]: Epoch 22 / 100: avg data time: 4.53e+00, avg batch time: 5.9899, average train loss: 6.5071
[11/27 07:38:54 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.5865, average loss: 9.1794
[11/27 07:38:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 65.55	
[11/27 07:38:54 visual_prompt]: Training 23 / 100 epoch, with learning rate 4.783863644106502
[11/27 07:45:54 visual_prompt]: Epoch 23 / 100: avg data time: 4.55e+00, avg batch time: 6.0073, average train loss: 3.0043
[11/27 07:46:42 visual_prompt]: Inference (val):avg data time: 2.01e-05, avg batch time: 0.5868, average loss: 5.2822
[11/27 07:46:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 66.23	
[11/27 07:46:42 visual_prompt]: Training 24 / 100 epoch, with learning rate 4.7469851157479175
[11/27 07:53:42 visual_prompt]: Epoch 24 / 100: avg data time: 4.54e+00, avg batch time: 5.9904, average train loss: 2.2262
[11/27 07:54:30 visual_prompt]: Inference (val):avg data time: 2.22e-03, avg batch time: 0.6324, average loss: 0.9039
[11/27 07:54:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.54	rocauc: 67.32	
[11/27 07:54:30 visual_prompt]: Best epoch 24: best metric: -0.904
[11/27 07:54:30 visual_prompt]: Training 25 / 100 epoch, with learning rate 4.707368982147317
[11/27 08:01:32 visual_prompt]: Epoch 25 / 100: avg data time: 4.57e+00, avg batch time: 6.0164, average train loss: 1.2421
[11/27 08:02:20 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.5885, average loss: 2.8685
[11/27 08:02:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 66.87	
[11/27 08:02:20 visual_prompt]: Training 26 / 100 epoch, with learning rate 4.665063509461097
[11/27 08:09:19 visual_prompt]: Epoch 26 / 100: avg data time: 4.53e+00, avg batch time: 5.9809, average train loss: 4.3956
[11/27 08:10:07 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.5878, average loss: 6.3707
[11/27 08:10:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 65.38	
[11/27 08:10:07 visual_prompt]: Training 27 / 100 epoch, with learning rate 4.620120240391064
[11/27 08:17:06 visual_prompt]: Epoch 27 / 100: avg data time: 4.53e+00, avg batch time: 5.9888, average train loss: 2.5497
[11/27 08:17:54 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.5877, average loss: 2.3572
[11/27 08:17:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 64.18	
[11/27 08:17:54 visual_prompt]: Training 28 / 100 epoch, with learning rate 4.572593931387604
[11/27 08:24:54 visual_prompt]: Epoch 28 / 100: avg data time: 4.55e+00, avg batch time: 5.9975, average train loss: 1.1325
[11/27 08:25:42 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.5881, average loss: 3.2577
[11/27 08:25:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 69.46	
[11/27 08:25:42 visual_prompt]: Training 29 / 100 epoch, with learning rate 4.522542485937368
[11/27 08:32:44 visual_prompt]: Epoch 29 / 100: avg data time: 4.58e+00, avg batch time: 6.0290, average train loss: 1.8593
[11/27 08:33:33 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.5857, average loss: 0.8613
[11/27 08:33:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 67.33	
[11/27 08:33:33 visual_prompt]: Best epoch 29: best metric: -0.861
[11/27 08:33:33 visual_prompt]: Training 30 / 100 epoch, with learning rate 4.4700268840168045
[11/27 08:40:38 visual_prompt]: Epoch 30 / 100: avg data time: 4.62e+00, avg batch time: 6.0781, average train loss: 1.0190
[11/27 08:41:27 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.5866, average loss: 2.1965
[11/27 08:41:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 66.53	
[11/27 08:41:27 visual_prompt]: Training 31 / 100 epoch, with learning rate 4.415111107797445
[11/27 08:48:30 visual_prompt]: Epoch 31 / 100: avg data time: 4.58e+00, avg batch time: 6.0374, average train loss: 2.8724
[11/27 08:49:18 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.5872, average loss: 2.0827
[11/27 08:49:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 68.06	
[11/27 08:49:18 visual_prompt]: Training 32 / 100 epoch, with learning rate 4.357862063693486
[11/27 08:56:22 visual_prompt]: Epoch 32 / 100: avg data time: 4.61e+00, avg batch time: 6.0588, average train loss: 2.2419
[11/27 08:57:11 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.5837, average loss: 6.7590
[11/27 08:57:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 68.26	
[11/27 08:57:11 visual_prompt]: Training 33 / 100 epoch, with learning rate 4.298349500846628
[11/27 09:04:15 visual_prompt]: Epoch 33 / 100: avg data time: 4.60e+00, avg batch time: 6.0543, average train loss: 2.2798
[11/27 09:05:03 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.5875, average loss: 0.8635
[11/27 09:05:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 68.96	
[11/27 09:05:03 visual_prompt]: Training 34 / 100 epoch, with learning rate 4.236645926147493
[11/27 09:12:06 visual_prompt]: Epoch 34 / 100: avg data time: 4.59e+00, avg batch time: 6.0427, average train loss: 1.6345
[11/27 09:12:55 visual_prompt]: Inference (val):avg data time: 2.01e-05, avg batch time: 0.5859, average loss: 5.9542
[11/27 09:12:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 67.08	
[11/27 09:12:55 visual_prompt]: Training 35 / 100 epoch, with learning rate 4.172826515897146
[11/27 09:19:58 visual_prompt]: Epoch 35 / 100: avg data time: 4.59e+00, avg batch time: 6.0418, average train loss: 1.6118
[11/27 09:20:47 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.5873, average loss: 0.7026
[11/27 09:20:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 70.72	
[11/27 09:20:47 visual_prompt]: Best epoch 35: best metric: -0.703
[11/27 09:20:47 visual_prompt]: Training 36 / 100 epoch, with learning rate 4.106969024216348
[11/27 09:27:51 visual_prompt]: Epoch 36 / 100: avg data time: 4.61e+00, avg batch time: 6.0636, average train loss: 1.4294
[11/27 09:28:40 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.5842, average loss: 2.4456
[11/27 09:28:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 67.76	
[11/27 09:28:40 visual_prompt]: Training 37 / 100 epoch, with learning rate 4.039153688314146
[11/27 09:35:41 visual_prompt]: Epoch 37 / 100: avg data time: 4.55e+00, avg batch time: 6.0069, average train loss: 1.2235
[11/27 09:36:28 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.5874, average loss: 0.6777
[11/27 09:36:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 69.67	
[11/27 09:36:29 visual_prompt]: Best epoch 37: best metric: -0.678
[11/27 09:36:29 visual_prompt]: Training 38 / 100 epoch, with learning rate 3.969463130731183
[11/27 09:43:28 visual_prompt]: Epoch 38 / 100: avg data time: 4.54e+00, avg batch time: 5.9978, average train loss: 1.2389
[11/27 09:44:16 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.5911, average loss: 1.4924
[11/27 09:44:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 67.98	
[11/27 09:44:16 visual_prompt]: Training 39 / 100 epoch, with learning rate 3.897982258676867
[11/27 09:51:27 visual_prompt]: Epoch 39 / 100: avg data time: 4.69e+00, avg batch time: 6.1416, average train loss: 0.9588
[11/27 09:52:15 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.5906, average loss: 0.6362
[11/27 09:52:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 69.88	
[11/27 09:52:15 visual_prompt]: Best epoch 39: best metric: -0.636
[11/27 09:52:15 visual_prompt]: Training 40 / 100 epoch, with learning rate 3.824798160583012
[11/27 09:59:14 visual_prompt]: Epoch 40 / 100: avg data time: 4.54e+00, avg batch time: 5.9928, average train loss: 0.8859
[11/27 10:00:02 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.5870, average loss: 1.1745
[11/27 10:00:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 70.89	
[11/27 10:00:02 visual_prompt]: Training 41 / 100 epoch, with learning rate 3.75
[11/27 10:07:01 visual_prompt]: Epoch 41 / 100: avg data time: 4.53e+00, avg batch time: 5.9850, average train loss: 1.2287
[11/27 10:07:49 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.5846, average loss: 0.6970
[11/27 10:07:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 70.98	
[11/27 10:07:49 visual_prompt]: Training 42 / 100 epoch, with learning rate 3.673678906964727
[11/27 10:15:00 visual_prompt]: Epoch 42 / 100: avg data time: 4.71e+00, avg batch time: 6.1586, average train loss: 1.0386
[11/27 10:15:53 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.5933, average loss: 1.3201
[11/27 10:15:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 70.47	
[11/27 10:15:53 visual_prompt]: Training 43 / 100 epoch, with learning rate 3.5959278669726933
[11/27 10:23:02 visual_prompt]: Epoch 43 / 100: avg data time: 4.66e+00, avg batch time: 6.1258, average train loss: 0.9658
[11/27 10:23:50 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.5858, average loss: 2.7622
[11/27 10:23:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 69.70	
[11/27 10:23:50 visual_prompt]: Training 44 / 100 epoch, with learning rate 3.516841607689501
[11/27 10:30:52 visual_prompt]: Epoch 44 / 100: avg data time: 4.58e+00, avg batch time: 6.0295, average train loss: 1.4320
[11/27 10:31:40 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.5862, average loss: 0.7566
[11/27 10:31:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 72.10	
[11/27 10:31:40 visual_prompt]: Training 45 / 100 epoch, with learning rate 3.4365164835397803
[11/27 10:38:40 visual_prompt]: Epoch 45 / 100: avg data time: 4.55e+00, avg batch time: 6.0019, average train loss: 1.3490
[11/27 10:39:28 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.5889, average loss: 1.6259
[11/27 10:39:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.47	rocauc: 70.33	
[11/27 10:39:28 visual_prompt]: Training 46 / 100 epoch, with learning rate 3.3550503583141724
[11/27 10:46:27 visual_prompt]: Epoch 46 / 100: avg data time: 4.53e+00, avg batch time: 5.9851, average train loss: 1.0446
[11/27 10:47:15 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.5858, average loss: 0.6560
[11/27 10:47:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 69.81	
[11/27 10:47:15 visual_prompt]: Training 47 / 100 epoch, with learning rate 3.2725424859373686
[11/27 10:54:15 visual_prompt]: Epoch 47 / 100: avg data time: 4.55e+00, avg batch time: 5.9962, average train loss: 0.8554
[11/27 10:55:03 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.5857, average loss: 1.0124
[11/27 10:55:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 70.78	
[11/27 10:55:03 visual_prompt]: Training 48 / 100 epoch, with learning rate 3.1890933895424975
[11/27 11:02:03 visual_prompt]: Epoch 48 / 100: avg data time: 4.55e+00, avg batch time: 6.0019, average train loss: 0.8019
[11/27 11:02:51 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.5857, average loss: 2.2158
[11/27 11:02:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 71.12	
[11/27 11:02:51 visual_prompt]: Training 49 / 100 epoch, with learning rate 3.104804738999169
[11/27 11:09:51 visual_prompt]: Epoch 49 / 100: avg data time: 4.55e+00, avg batch time: 5.9969, average train loss: 1.0876
[11/27 11:10:39 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.5846, average loss: 3.0571
[11/27 11:10:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 71.02	
[11/27 11:10:39 visual_prompt]: Training 50 / 100 epoch, with learning rate 3.019779227044398
[11/27 11:17:38 visual_prompt]: Epoch 50 / 100: avg data time: 4.53e+00, avg batch time: 5.9840, average train loss: 1.2478
[11/27 11:18:27 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.5839, average loss: 0.7618
[11/27 11:18:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 70.31	
[11/27 11:18:27 visual_prompt]: Training 51 / 100 epoch, with learning rate 2.934120444167326
[11/27 11:25:26 visual_prompt]: Epoch 51 / 100: avg data time: 4.54e+00, avg batch time: 5.9895, average train loss: 0.8562
[11/27 11:26:14 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.5880, average loss: 0.8258
[11/27 11:26:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 71.06	
[11/27 11:26:14 visual_prompt]: Training 52 / 100 epoch, with learning rate 2.8479327524001636
[11/27 11:33:14 visual_prompt]: Epoch 52 / 100: avg data time: 4.55e+00, avg batch time: 6.0040, average train loss: 0.8619
[11/27 11:34:02 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.5842, average loss: 0.7581
[11/27 11:34:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 71.09	
[11/27 11:34:02 visual_prompt]: Training 53 / 100 epoch, with learning rate 2.761321158169134
[11/27 11:41:04 visual_prompt]: Epoch 53 / 100: avg data time: 4.57e+00, avg batch time: 6.0254, average train loss: 1.0585
[11/27 11:41:53 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.5873, average loss: 0.6482
[11/27 11:41:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 71.67	
[11/27 11:41:53 visual_prompt]: Training 54 / 100 epoch, with learning rate 2.6743911843603128
[11/27 11:48:57 visual_prompt]: Epoch 54 / 100: avg data time: 4.61e+00, avg batch time: 6.0617, average train loss: 0.8703
[11/27 11:49:46 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.5892, average loss: 2.8126
[11/27 11:49:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 71.10	
[11/27 11:49:46 visual_prompt]: Training 55 / 100 epoch, with learning rate 2.5872487417562526
[11/27 11:56:45 visual_prompt]: Epoch 55 / 100: avg data time: 4.54e+00, avg batch time: 5.9954, average train loss: 1.4997
[11/27 11:57:33 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.5911, average loss: 0.9670
[11/27 11:57:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 52.85	rocauc: 72.06	
[11/27 11:57:33 visual_prompt]: Training 56 / 100 epoch, with learning rate 2.5
[11/27 12:04:34 visual_prompt]: Epoch 56 / 100: avg data time: 4.55e+00, avg batch time: 6.0081, average train loss: 0.9510
[11/27 12:05:22 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.5853, average loss: 0.8625
[11/27 12:05:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 71.82	
[11/27 12:05:22 visual_prompt]: Training 57 / 100 epoch, with learning rate 2.4127512582437483
[11/27 12:12:23 visual_prompt]: Epoch 57 / 100: avg data time: 4.56e+00, avg batch time: 6.0087, average train loss: 0.9119
[11/27 12:13:11 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.5835, average loss: 2.1254
[11/27 12:13:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 71.74	
[11/27 12:13:11 visual_prompt]: Training 58 / 100 epoch, with learning rate 2.325608815639687
[11/27 12:20:10 visual_prompt]: Epoch 58 / 100: avg data time: 4.53e+00, avg batch time: 5.9874, average train loss: 0.9925
[11/27 12:20:58 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.5864, average loss: 0.7992
[11/27 12:20:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 71.76	
[11/27 12:20:58 visual_prompt]: Training 59 / 100 epoch, with learning rate 2.2386788418308665
[11/27 12:27:58 visual_prompt]: Epoch 59 / 100: avg data time: 4.55e+00, avg batch time: 5.9989, average train loss: 1.0580
[11/27 12:28:46 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.5884, average loss: 0.6366
[11/27 12:28:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 71.31	
[11/27 12:28:46 visual_prompt]: Training 60 / 100 epoch, with learning rate 2.1520672475998373
[11/27 12:35:47 visual_prompt]: Epoch 60 / 100: avg data time: 4.56e+00, avg batch time: 6.0089, average train loss: 0.8189
[11/27 12:36:35 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.5843, average loss: 0.7810
[11/27 12:36:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 71.27	
[11/27 12:36:35 visual_prompt]: Stopping early.
[11/27 12:36:35 visual_prompt]: Rank of current process: 0. World size: 1
[11/27 12:36:35 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/27 12:36:35 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/27 12:36:35 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/27 12:36:35 visual_prompt]: Training with config:
[11/27 12:36:35 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr2.5_wd0.01/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 2.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/27 12:36:35 visual_prompt]: Loading training data...
[11/27 12:36:35 visual_prompt]: Constructing mammo-cbis dataset train...
[11/27 12:36:35 visual_prompt]: Loading validation data...
[11/27 12:36:35 visual_prompt]: Constructing mammo-cbis dataset val...
[11/27 12:36:35 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/27 12:36:38 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/27 12:36:38 visual_prompt]: tuned percent:0.532
[11/27 12:36:38 visual_prompt]: Device used for model: 0
[11/27 12:36:38 visual_prompt]: Setting up Evaluator...
[11/27 12:36:38 visual_prompt]: Setting up Trainer...
[11/27 12:36:38 visual_prompt]: 	Setting up the optimizer...
[11/27 12:36:38 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/27 12:43:39 visual_prompt]: Epoch 1 / 100: avg data time: 4.56e+00, avg batch time: 6.0105, average train loss: 1.4863
[11/27 12:44:27 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.5903, average loss: 1.4553
[11/27 12:44:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/27 12:44:27 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.25
[11/27 12:51:27 visual_prompt]: Epoch 2 / 100: avg data time: 4.55e+00, avg batch time: 5.9978, average train loss: 1.5538
[11/27 12:52:15 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.5883, average loss: 0.9104
[11/27 12:52:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.18	
[11/27 12:52:15 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.5
[11/27 12:59:15 visual_prompt]: Epoch 3 / 100: avg data time: 4.55e+00, avg batch time: 6.0074, average train loss: 0.7967
[11/27 13:00:03 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.5871, average loss: 1.1474
[11/27 13:00:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.12	
[11/27 13:00:03 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.75
[11/27 13:07:04 visual_prompt]: Epoch 4 / 100: avg data time: 4.54e+00, avg batch time: 6.0039, average train loss: 1.1288
[11/27 13:07:52 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.5901, average loss: 0.7620
[11/27 13:07:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 45.86	
[11/27 13:07:52 visual_prompt]: Training 5 / 100 epoch, with learning rate 1.0
[11/27 13:14:51 visual_prompt]: Epoch 5 / 100: avg data time: 4.53e+00, avg batch time: 5.9865, average train loss: 1.4050
[11/27 13:15:39 visual_prompt]: Inference (val):avg data time: 2.05e-05, avg batch time: 0.5897, average loss: 1.5900
[11/27 13:15:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.49	
[11/27 13:15:39 visual_prompt]: Training 6 / 100 epoch, with learning rate 1.25
[11/27 13:22:39 visual_prompt]: Epoch 6 / 100: avg data time: 4.55e+00, avg batch time: 6.0016, average train loss: 1.9946
[11/27 13:23:27 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.5861, average loss: 0.7178
[11/27 13:23:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.44	
[11/27 13:23:27 visual_prompt]: Training 7 / 100 epoch, with learning rate 1.5
[11/27 13:30:26 visual_prompt]: Epoch 7 / 100: avg data time: 4.52e+00, avg batch time: 5.9747, average train loss: 3.5436
[11/27 13:31:14 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.5919, average loss: 0.7324
[11/27 13:31:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.47	rocauc: 48.82	
[11/27 13:31:14 visual_prompt]: Training 8 / 100 epoch, with learning rate 1.75
[11/27 13:38:13 visual_prompt]: Epoch 8 / 100: avg data time: 4.54e+00, avg batch time: 5.9902, average train loss: 2.5787
[11/27 13:39:01 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.5864, average loss: 5.1541
[11/27 13:39:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.62	
[11/27 13:39:01 visual_prompt]: Training 9 / 100 epoch, with learning rate 2.0
[11/27 13:46:02 visual_prompt]: Epoch 9 / 100: avg data time: 4.55e+00, avg batch time: 6.0098, average train loss: 2.9303
[11/27 13:46:50 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.5876, average loss: 0.7207
[11/27 13:46:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.26	
[11/27 13:46:50 visual_prompt]: Training 10 / 100 epoch, with learning rate 2.25
[11/27 13:53:58 visual_prompt]: Epoch 10 / 100: avg data time: 4.66e+00, avg batch time: 6.1108, average train loss: 4.3887
[11/27 13:54:46 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.5847, average loss: 2.5096
[11/27 13:54:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.03	
[11/27 13:54:46 visual_prompt]: Training 11 / 100 epoch, with learning rate 2.5
[11/27 14:01:46 visual_prompt]: Epoch 11 / 100: avg data time: 4.55e+00, avg batch time: 6.0044, average train loss: 4.1012
[11/27 14:02:34 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.5915, average loss: 2.6728
[11/27 14:02:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.02	
[11/27 14:02:34 visual_prompt]: Training 12 / 100 epoch, with learning rate 2.4992385337738696
[11/27 14:09:33 visual_prompt]: Epoch 12 / 100: avg data time: 4.53e+00, avg batch time: 5.9830, average train loss: 5.3184
[11/27 14:10:21 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.5873, average loss: 1.1836
[11/27 14:10:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.24	
[11/27 14:10:21 visual_prompt]: Best epoch 12: best metric: -1.184
[11/27 14:10:21 visual_prompt]: Training 13 / 100 epoch, with learning rate 2.4969550628247803
[11/27 14:17:21 visual_prompt]: Epoch 13 / 100: avg data time: 4.55e+00, avg batch time: 6.0020, average train loss: 3.7504
[11/27 14:18:09 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.5876, average loss: 1.4799
[11/27 14:18:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.98	
[11/27 14:18:09 visual_prompt]: Training 14 / 100 epoch, with learning rate 2.4931523692103417
[11/27 14:25:08 visual_prompt]: Epoch 14 / 100: avg data time: 4.53e+00, avg batch time: 5.9845, average train loss: 4.2360
[11/27 14:25:57 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.5876, average loss: 13.8317
[11/27 14:25:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.00	
[11/27 14:25:57 visual_prompt]: Training 15 / 100 epoch, with learning rate 2.487835085926963
[11/27 14:32:55 visual_prompt]: Epoch 15 / 100: avg data time: 4.53e+00, avg batch time: 5.9805, average train loss: 5.3924
[11/27 14:33:43 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.5938, average loss: 2.5251
[11/27 14:33:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.43	
[11/27 14:33:43 visual_prompt]: Training 16 / 100 epoch, with learning rate 2.4810096912652604
[11/27 14:40:42 visual_prompt]: Epoch 16 / 100: avg data time: 4.53e+00, avg batch time: 5.9792, average train loss: 3.5871
[11/27 14:41:30 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.5876, average loss: 2.3650
[11/27 14:41:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.85	
[11/27 14:41:30 visual_prompt]: Training 17 / 100 epoch, with learning rate 2.472684500917257
[11/27 14:48:30 visual_prompt]: Epoch 17 / 100: avg data time: 4.54e+00, avg batch time: 5.9935, average train loss: 4.7276
[11/27 14:49:18 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.5866, average loss: 2.5114
[11/27 14:49:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.18	
[11/27 14:49:18 visual_prompt]: Training 18 / 100 epoch, with learning rate 2.4628696578449953
[11/27 14:56:20 visual_prompt]: Epoch 18 / 100: avg data time: 4.58e+00, avg batch time: 6.0323, average train loss: 4.7482
[11/27 14:57:08 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.5907, average loss: 4.3037
[11/27 14:57:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.01	
[11/27 14:57:08 visual_prompt]: Training 19 / 100 epoch, with learning rate 2.4515771199228986
[11/27 15:04:11 visual_prompt]: Epoch 19 / 100: avg data time: 4.59e+00, avg batch time: 6.0409, average train loss: 4.8727
[11/27 15:05:00 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.5852, average loss: 15.6805
[11/27 15:05:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.21	
[11/27 15:05:00 visual_prompt]: Training 20 / 100 epoch, with learning rate 2.438820645368942
[11/27 15:12:04 visual_prompt]: Epoch 20 / 100: avg data time: 4.61e+00, avg batch time: 6.0616, average train loss: 3.9398
[11/27 15:12:53 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.5882, average loss: 4.8538
[11/27 15:12:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.06	
[11/27 15:12:53 visual_prompt]: Training 21 / 100 epoch, with learning rate 2.4246157759823856
[11/27 15:19:57 visual_prompt]: Epoch 21 / 100: avg data time: 4.60e+00, avg batch time: 6.0530, average train loss: 2.6785
[11/27 15:20:45 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.5885, average loss: 2.7862
[11/27 15:20:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.30	
[11/27 15:20:45 visual_prompt]: Training 22 / 100 epoch, with learning rate 2.4089798182084845
[11/27 15:27:49 visual_prompt]: Epoch 22 / 100: avg data time: 4.60e+00, avg batch time: 6.0521, average train loss: 3.1041
[11/27 15:28:37 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.5847, average loss: 4.1943
[11/27 15:28:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.44	
[11/27 15:28:37 visual_prompt]: Training 23 / 100 epoch, with learning rate 2.391931822053251
[11/27 15:35:38 visual_prompt]: Epoch 23 / 100: avg data time: 4.56e+00, avg batch time: 6.0116, average train loss: 4.4100
[11/27 15:36:27 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.5838, average loss: 4.5350
[11/27 15:36:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.91	
[11/27 15:36:27 visual_prompt]: Training 24 / 100 epoch, with learning rate 2.3734925578739587
[11/27 15:43:30 visual_prompt]: Epoch 24 / 100: avg data time: 4.59e+00, avg batch time: 6.0448, average train loss: 2.9875
[11/27 15:44:19 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.5895, average loss: 1.0411
[11/27 15:44:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.31	
[11/27 15:44:19 visual_prompt]: Best epoch 24: best metric: -1.041
[11/27 15:44:19 visual_prompt]: Training 25 / 100 epoch, with learning rate 2.3536844910736585
[11/27 15:51:24 visual_prompt]: Epoch 25 / 100: avg data time: 4.63e+00, avg batch time: 6.0762, average train loss: 3.2723
[11/27 15:52:13 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.5887, average loss: 6.0491
[11/27 15:52:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.69	
[11/27 15:52:13 visual_prompt]: Training 26 / 100 epoch, with learning rate 2.3325317547305486
[11/27 15:59:17 visual_prompt]: Epoch 26 / 100: avg data time: 4.60e+00, avg batch time: 6.0540, average train loss: 5.1346
[11/27 16:00:05 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.5864, average loss: 4.9967
[11/27 16:00:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.25	
[11/27 16:00:05 visual_prompt]: Training 27 / 100 epoch, with learning rate 2.310060120195532
[11/27 16:07:09 visual_prompt]: Epoch 27 / 100: avg data time: 4.60e+00, avg batch time: 6.0530, average train loss: 3.7347
[11/27 16:07:58 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.5828, average loss: 7.5016
[11/27 16:07:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.61	
[11/27 16:07:58 visual_prompt]: Training 28 / 100 epoch, with learning rate 2.286296965693802
[11/27 16:15:02 visual_prompt]: Epoch 28 / 100: avg data time: 4.61e+00, avg batch time: 6.0607, average train loss: 6.7449
[11/27 16:15:51 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.5856, average loss: 6.1131
[11/27 16:15:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.57	
[11/27 16:15:51 visual_prompt]: Training 29 / 100 epoch, with learning rate 2.261271242968684
[11/27 16:22:59 visual_prompt]: Epoch 29 / 100: avg data time: 4.66e+00, avg batch time: 6.1221, average train loss: 4.1330
[11/27 16:23:48 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.5875, average loss: 4.1240
[11/27 16:23:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.20	
[11/27 16:23:48 visual_prompt]: Training 30 / 100 epoch, with learning rate 2.2350134420084022
[11/27 16:30:57 visual_prompt]: Epoch 30 / 100: avg data time: 4.68e+00, avg batch time: 6.1373, average train loss: 6.1640
[11/27 16:31:46 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.5874, average loss: 4.6863
[11/27 16:31:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.86	
[11/27 16:31:46 visual_prompt]: Training 31 / 100 epoch, with learning rate 2.2075555538987226
[11/27 16:38:49 visual_prompt]: Epoch 31 / 100: avg data time: 4.59e+00, avg batch time: 6.0395, average train loss: 2.3970
[11/27 16:39:37 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.5866, average loss: 0.9740
[11/27 16:39:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 43.18	
[11/27 16:39:37 visual_prompt]: Best epoch 31: best metric: -0.974
[11/27 16:39:37 visual_prompt]: Training 32 / 100 epoch, with learning rate 2.178931031846743
[11/27 16:46:41 visual_prompt]: Epoch 32 / 100: avg data time: 4.60e+00, avg batch time: 6.0565, average train loss: 4.0516
[11/27 16:47:30 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.5874, average loss: 5.0493
[11/27 16:47:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.82	
[11/27 16:47:30 visual_prompt]: Training 33 / 100 epoch, with learning rate 2.149174750423314
[11/27 16:54:33 visual_prompt]: Epoch 33 / 100: avg data time: 4.60e+00, avg batch time: 6.0542, average train loss: 3.0158
[11/27 16:55:23 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.5853, average loss: 0.7154
[11/27 16:55:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 45.57	
[11/27 16:55:23 visual_prompt]: Best epoch 33: best metric: -0.715
[11/27 16:55:23 visual_prompt]: Training 34 / 100 epoch, with learning rate 2.1183229630737466
[11/27 17:02:26 visual_prompt]: Epoch 34 / 100: avg data time: 4.60e+00, avg batch time: 6.0505, average train loss: 3.0531
[11/27 17:03:15 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.5879, average loss: 6.5177
[11/27 17:03:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 39.99	
[11/27 17:03:15 visual_prompt]: Training 35 / 100 epoch, with learning rate 2.086413257948573
[11/27 17:10:29 visual_prompt]: Epoch 35 / 100: avg data time: 4.76e+00, avg batch time: 6.2074, average train loss: 3.8015
[11/27 17:11:18 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.5862, average loss: 4.3024
[11/27 17:11:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 42.26	
[11/27 17:11:18 visual_prompt]: Training 36 / 100 epoch, with learning rate 2.053484512108174
[11/27 17:18:24 visual_prompt]: Epoch 36 / 100: avg data time: 4.63e+00, avg batch time: 6.0819, average train loss: 3.6850
[11/27 17:19:12 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.5919, average loss: 1.6586
[11/27 17:19:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.49	
[11/27 17:19:12 visual_prompt]: Training 37 / 100 epoch, with learning rate 2.019576844157073
[11/27 17:26:16 visual_prompt]: Epoch 37 / 100: avg data time: 4.60e+00, avg batch time: 6.0531, average train loss: 2.3560
[11/27 17:27:05 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.5883, average loss: 3.3506
[11/27 17:27:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.18	
[11/27 17:27:05 visual_prompt]: Training 38 / 100 epoch, with learning rate 1.9847315653655915
[11/27 17:34:10 visual_prompt]: Epoch 38 / 100: avg data time: 4.61e+00, avg batch time: 6.0677, average train loss: 2.1797
[11/27 17:34:58 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.5852, average loss: 1.3502
[11/27 17:34:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 42.47	
[11/27 17:34:58 visual_prompt]: Training 39 / 100 epoch, with learning rate 1.9489911293384334
[11/27 17:42:00 visual_prompt]: Epoch 39 / 100: avg data time: 4.57e+00, avg batch time: 6.0242, average train loss: 3.0097
[11/27 17:42:48 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.5881, average loss: 1.6081
[11/27 17:42:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.53	rocauc: 47.02	
[11/27 17:42:48 visual_prompt]: Training 40 / 100 epoch, with learning rate 1.912399080291506
[11/27 17:49:47 visual_prompt]: Epoch 40 / 100: avg data time: 4.53e+00, avg batch time: 5.9803, average train loss: 2.1590
[11/27 17:50:35 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.5892, average loss: 2.5659
[11/27 17:50:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.97	
[11/27 17:50:35 visual_prompt]: Training 41 / 100 epoch, with learning rate 1.875
[11/27 17:57:35 visual_prompt]: Epoch 41 / 100: avg data time: 4.54e+00, avg batch time: 6.0003, average train loss: 3.9374
[11/27 17:58:23 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.5896, average loss: 0.7776
[11/27 17:58:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.58	
[11/27 17:58:23 visual_prompt]: Training 42 / 100 epoch, with learning rate 1.8368394534823635
[11/27 18:05:22 visual_prompt]: Epoch 42 / 100: avg data time: 4.54e+00, avg batch time: 5.9901, average train loss: 3.3744
[11/27 18:06:11 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.5834, average loss: 3.0424
[11/27 18:06:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 44.54	
[11/27 18:06:11 visual_prompt]: Training 43 / 100 epoch, with learning rate 1.7979639334863466
[11/27 18:13:11 visual_prompt]: Epoch 43 / 100: avg data time: 4.55e+00, avg batch time: 6.0037, average train loss: 2.2511
[11/27 18:13:59 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.5925, average loss: 5.2004
[11/27 18:13:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.20	
[11/27 18:13:59 visual_prompt]: Training 44 / 100 epoch, with learning rate 1.7584208038447504
[11/27 18:21:01 visual_prompt]: Epoch 44 / 100: avg data time: 4.57e+00, avg batch time: 6.0219, average train loss: 2.9197
[11/27 18:21:49 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.5880, average loss: 6.6694
[11/27 18:21:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 62.34	
[11/27 18:21:49 visual_prompt]: Training 45 / 100 epoch, with learning rate 1.7182582417698902
[11/27 18:28:48 visual_prompt]: Epoch 45 / 100: avg data time: 4.54e+00, avg batch time: 5.9935, average train loss: 5.4124
[11/27 18:29:36 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.5876, average loss: 2.3087
[11/27 18:29:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 44.23	
[11/27 18:29:36 visual_prompt]: Training 46 / 100 epoch, with learning rate 1.6775251791570862
[11/27 18:36:35 visual_prompt]: Epoch 46 / 100: avg data time: 4.53e+00, avg batch time: 5.9856, average train loss: 3.1880
[11/27 18:37:23 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.5920, average loss: 3.7959
[11/27 18:37:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 40.39	
[11/27 18:37:23 visual_prompt]: Training 47 / 100 epoch, with learning rate 1.6362712429686843
[11/27 18:44:23 visual_prompt]: Epoch 47 / 100: avg data time: 4.54e+00, avg batch time: 5.9968, average train loss: 3.3901
[11/27 18:45:11 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.5861, average loss: 12.2685
[11/27 18:45:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.24	
[11/27 18:45:11 visual_prompt]: Training 48 / 100 epoch, with learning rate 1.5945466947712488
[11/27 18:52:11 visual_prompt]: Epoch 48 / 100: avg data time: 4.54e+00, avg batch time: 5.9919, average train loss: 1.9854
[11/27 18:52:59 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.5884, average loss: 3.1890
[11/27 18:52:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.72	
[11/27 18:52:59 visual_prompt]: Training 49 / 100 epoch, with learning rate 1.5524023694995845
[11/27 18:59:58 visual_prompt]: Epoch 49 / 100: avg data time: 4.54e+00, avg batch time: 5.9904, average train loss: 2.3048
[11/27 19:00:46 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.5855, average loss: 3.6260
[11/27 19:00:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.54	
[11/27 19:00:46 visual_prompt]: Training 50 / 100 epoch, with learning rate 1.509889613522199
[11/27 19:07:45 visual_prompt]: Epoch 50 / 100: avg data time: 4.53e+00, avg batch time: 5.9831, average train loss: 2.0419
[11/27 19:08:33 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.5869, average loss: 1.0535
[11/27 19:08:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 47.97	rocauc: 46.99	
[11/27 19:08:33 visual_prompt]: Training 51 / 100 epoch, with learning rate 1.467060222083663
[11/27 19:15:33 visual_prompt]: Epoch 51 / 100: avg data time: 4.54e+00, avg batch time: 5.9962, average train loss: 1.8535
[11/27 19:16:21 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.5860, average loss: 1.0269
[11/27 19:16:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.20	
[11/27 19:16:21 visual_prompt]: Training 52 / 100 epoch, with learning rate 1.4239663762000818
[11/27 19:23:21 visual_prompt]: Epoch 52 / 100: avg data time: 4.55e+00, avg batch time: 5.9986, average train loss: 1.5567
[11/27 19:24:09 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.5859, average loss: 5.5367
[11/27 19:24:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.75	
[11/27 19:24:09 visual_prompt]: Training 53 / 100 epoch, with learning rate 1.380660579084567
[11/27 19:31:10 visual_prompt]: Epoch 53 / 100: avg data time: 4.55e+00, avg batch time: 6.0063, average train loss: 3.0246
[11/27 19:31:58 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.5831, average loss: 1.7549
[11/27 19:31:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.01	
[11/27 19:31:58 visual_prompt]: Training 54 / 100 epoch, with learning rate 1.3371955921801564
[11/27 19:38:58 visual_prompt]: Epoch 54 / 100: avg data time: 4.56e+00, avg batch time: 6.0081, average train loss: 1.5737
[11/27 19:39:46 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.5872, average loss: 4.8392
[11/27 19:39:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.02	
[11/27 19:39:46 visual_prompt]: Stopping early.
[11/27 19:39:46 visual_prompt]: Rank of current process: 0. World size: 1
[11/27 19:39:46 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/27 19:39:46 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/27 19:39:46 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/27 19:39:46 visual_prompt]: Training with config:
[11/27 19:39:46 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr2.5_wd0.001/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 2.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/27 19:39:46 visual_prompt]: Loading training data...
[11/27 19:39:46 visual_prompt]: Constructing mammo-cbis dataset train...
[11/27 19:39:46 visual_prompt]: Loading validation data...
[11/27 19:39:46 visual_prompt]: Constructing mammo-cbis dataset val...
[11/27 19:39:46 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/27 19:39:49 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/27 19:39:49 visual_prompt]: tuned percent:0.532
[11/27 19:39:49 visual_prompt]: Device used for model: 0
[11/27 19:39:49 visual_prompt]: Setting up Evaluator...
[11/27 19:39:49 visual_prompt]: Setting up Trainer...
[11/27 19:39:49 visual_prompt]: 	Setting up the optimizer...
[11/27 19:39:49 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/27 19:46:49 visual_prompt]: Epoch 1 / 100: avg data time: 4.55e+00, avg batch time: 6.0053, average train loss: 1.4863
[11/27 19:47:37 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.5858, average loss: 1.4553
[11/27 19:47:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/27 19:47:37 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.25
[11/27 19:54:37 visual_prompt]: Epoch 2 / 100: avg data time: 4.53e+00, avg batch time: 5.9894, average train loss: 1.6350
[11/27 19:55:25 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.5900, average loss: 1.0889
[11/27 19:55:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.61	
[11/27 19:55:25 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.5
[11/27 20:02:27 visual_prompt]: Epoch 3 / 100: avg data time: 4.58e+00, avg batch time: 6.0373, average train loss: 0.8564
[11/27 20:03:16 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.5853, average loss: 2.0091
[11/27 20:03:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.74	
[11/27 20:03:16 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.75
[11/27 20:10:18 visual_prompt]: Epoch 4 / 100: avg data time: 4.58e+00, avg batch time: 6.0287, average train loss: 0.8667
[11/27 20:11:07 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.5869, average loss: 0.7010
[11/27 20:11:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.68	
[11/27 20:11:07 visual_prompt]: Training 5 / 100 epoch, with learning rate 1.0
[11/27 20:18:08 visual_prompt]: Epoch 5 / 100: avg data time: 4.56e+00, avg batch time: 6.0172, average train loss: 0.8591
[11/27 20:18:56 visual_prompt]: Inference (val):avg data time: 2.00e-05, avg batch time: 0.5914, average loss: 1.4949
[11/27 20:18:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.80	
[11/27 20:18:56 visual_prompt]: Training 6 / 100 epoch, with learning rate 1.25
[11/27 20:25:57 visual_prompt]: Epoch 6 / 100: avg data time: 4.57e+00, avg batch time: 6.0157, average train loss: 1.0410
[11/27 20:26:45 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.5886, average loss: 1.0563
[11/27 20:26:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.31	
[11/27 20:26:45 visual_prompt]: Training 7 / 100 epoch, with learning rate 1.5
[11/27 20:33:44 visual_prompt]: Epoch 7 / 100: avg data time: 4.53e+00, avg batch time: 5.9801, average train loss: 1.0587
[11/27 20:34:32 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.5849, average loss: 1.5394
[11/27 20:34:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.79	
[11/27 20:34:32 visual_prompt]: Training 8 / 100 epoch, with learning rate 1.75
[11/27 20:41:32 visual_prompt]: Epoch 8 / 100: avg data time: 4.54e+00, avg batch time: 5.9963, average train loss: 0.9856
[11/27 20:42:20 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.5837, average loss: 1.2600
[11/27 20:42:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.60	
[11/27 20:42:20 visual_prompt]: Training 9 / 100 epoch, with learning rate 2.0
[11/27 20:49:19 visual_prompt]: Epoch 9 / 100: avg data time: 4.54e+00, avg batch time: 5.9860, average train loss: 1.1851
[11/27 20:50:07 visual_prompt]: Inference (val):avg data time: 2.05e-05, avg batch time: 0.5832, average loss: 2.2828
[11/27 20:50:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.81	
[11/27 20:50:07 visual_prompt]: Training 10 / 100 epoch, with learning rate 2.25
[11/27 20:57:06 visual_prompt]: Epoch 10 / 100: avg data time: 4.53e+00, avg batch time: 5.9841, average train loss: 6.4870
[11/27 20:57:54 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.5914, average loss: 1.7846
[11/27 20:57:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.25	
[11/27 20:57:54 visual_prompt]: Training 11 / 100 epoch, with learning rate 2.5
[11/27 21:04:54 visual_prompt]: Epoch 11 / 100: avg data time: 4.55e+00, avg batch time: 6.0019, average train loss: 4.1940
[11/27 21:05:42 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.5866, average loss: 0.7725
[11/27 21:05:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.22	
[11/27 21:05:42 visual_prompt]: Training 12 / 100 epoch, with learning rate 2.4992385337738696
[11/27 21:12:41 visual_prompt]: Epoch 12 / 100: avg data time: 4.53e+00, avg batch time: 5.9840, average train loss: 5.2577
[11/27 21:13:29 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.5857, average loss: 1.0665
[11/27 21:13:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.48	
[11/27 21:13:29 visual_prompt]: Training 13 / 100 epoch, with learning rate 2.4969550628247803
[11/27 21:20:29 visual_prompt]: Epoch 13 / 100: avg data time: 4.54e+00, avg batch time: 5.9929, average train loss: 5.7331
[11/27 21:21:17 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.5853, average loss: 0.8797
[11/27 21:21:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.99	
[11/27 21:21:17 visual_prompt]: Training 14 / 100 epoch, with learning rate 2.4931523692103417
[11/27 21:28:16 visual_prompt]: Epoch 14 / 100: avg data time: 4.54e+00, avg batch time: 5.9893, average train loss: 2.3982
[11/27 21:29:04 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.5858, average loss: 2.9792
[11/27 21:29:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.20	
[11/27 21:29:04 visual_prompt]: Training 15 / 100 epoch, with learning rate 2.487835085926963
[11/27 21:36:02 visual_prompt]: Epoch 15 / 100: avg data time: 4.52e+00, avg batch time: 5.9684, average train loss: 1.2540
[11/27 21:36:51 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.5887, average loss: 1.1216
[11/27 21:36:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.35	
[11/27 21:36:51 visual_prompt]: Training 16 / 100 epoch, with learning rate 2.4810096912652604
[11/27 21:43:50 visual_prompt]: Epoch 16 / 100: avg data time: 4.54e+00, avg batch time: 5.9878, average train loss: 3.0308
[11/27 21:44:38 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.5827, average loss: 0.6882
[11/27 21:44:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.51	
[11/27 21:44:38 visual_prompt]: Best epoch 16: best metric: -0.688
[11/27 21:44:38 visual_prompt]: Training 17 / 100 epoch, with learning rate 2.472684500917257
[11/27 21:51:37 visual_prompt]: Epoch 17 / 100: avg data time: 4.53e+00, avg batch time: 5.9834, average train loss: 1.8124
[11/27 21:52:25 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.5896, average loss: 2.5545
[11/27 21:52:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.42	
[11/27 21:52:25 visual_prompt]: Training 18 / 100 epoch, with learning rate 2.4628696578449953
[11/27 21:59:25 visual_prompt]: Epoch 18 / 100: avg data time: 4.55e+00, avg batch time: 5.9987, average train loss: 3.3923
[11/27 22:00:13 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.5851, average loss: 4.1445
[11/27 22:00:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.33	
[11/27 22:00:13 visual_prompt]: Training 19 / 100 epoch, with learning rate 2.4515771199228986
[11/27 22:07:15 visual_prompt]: Epoch 19 / 100: avg data time: 4.57e+00, avg batch time: 6.0214, average train loss: 4.9310
[11/27 22:08:03 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.5858, average loss: 2.9908
[11/27 22:08:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.89	
[11/27 22:08:03 visual_prompt]: Training 20 / 100 epoch, with learning rate 2.438820645368942
[11/27 22:15:08 visual_prompt]: Epoch 20 / 100: avg data time: 4.61e+00, avg batch time: 6.0623, average train loss: 3.1189
[11/27 22:15:56 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.5859, average loss: 1.0089
[11/27 22:15:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.26	
[11/27 22:15:56 visual_prompt]: Training 21 / 100 epoch, with learning rate 2.4246157759823856
[11/27 22:22:57 visual_prompt]: Epoch 21 / 100: avg data time: 4.56e+00, avg batch time: 6.0110, average train loss: 2.4156
[11/27 22:23:46 visual_prompt]: Inference (val):avg data time: 1.92e-05, avg batch time: 0.5862, average loss: 1.3406
[11/27 22:23:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.79	
[11/27 22:23:46 visual_prompt]: Training 22 / 100 epoch, with learning rate 2.4089798182084845
[11/27 22:30:48 visual_prompt]: Epoch 22 / 100: avg data time: 4.58e+00, avg batch time: 6.0333, average train loss: 1.5438
[11/27 22:31:37 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.5853, average loss: 3.6511
[11/27 22:31:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.96	
[11/27 22:31:37 visual_prompt]: Training 23 / 100 epoch, with learning rate 2.391931822053251
[11/27 22:38:41 visual_prompt]: Epoch 23 / 100: avg data time: 4.60e+00, avg batch time: 6.0552, average train loss: 3.9009
[11/27 22:39:29 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.5871, average loss: 4.4872
[11/27 22:39:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.60	
[11/27 22:39:29 visual_prompt]: Training 24 / 100 epoch, with learning rate 2.3734925578739587
[11/27 22:46:32 visual_prompt]: Epoch 24 / 100: avg data time: 4.59e+00, avg batch time: 6.0406, average train loss: 2.8096
[11/27 22:47:21 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.5872, average loss: 2.9821
[11/27 22:47:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 41.71	
[11/27 22:47:21 visual_prompt]: Training 25 / 100 epoch, with learning rate 2.3536844910736585
[11/27 22:54:25 visual_prompt]: Epoch 25 / 100: avg data time: 4.61e+00, avg batch time: 6.0548, average train loss: 2.2089
[11/27 22:55:13 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.5860, average loss: 5.1471
[11/27 22:55:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.62	
[11/27 22:55:13 visual_prompt]: Training 26 / 100 epoch, with learning rate 2.3325317547305486
[11/27 23:02:13 visual_prompt]: Epoch 26 / 100: avg data time: 4.54e+00, avg batch time: 5.9943, average train loss: 3.4482
[11/27 23:03:01 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.5848, average loss: 1.4598
[11/27 23:03:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.86	
[11/27 23:03:01 visual_prompt]: Training 27 / 100 epoch, with learning rate 2.310060120195532
[11/27 23:09:59 visual_prompt]: Epoch 27 / 100: avg data time: 4.51e+00, avg batch time: 5.9700, average train loss: 1.7899
[11/27 23:10:47 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.5837, average loss: 3.3906
[11/27 23:10:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.80	
[11/27 23:10:47 visual_prompt]: Training 28 / 100 epoch, with learning rate 2.286296965693802
[11/27 23:17:47 visual_prompt]: Epoch 28 / 100: avg data time: 4.55e+00, avg batch time: 6.0001, average train loss: 3.2631
[11/27 23:18:35 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.5873, average loss: 0.7212
[11/27 23:18:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.76	
[11/27 23:18:35 visual_prompt]: Training 29 / 100 epoch, with learning rate 2.261271242968684
[11/27 23:25:33 visual_prompt]: Epoch 29 / 100: avg data time: 4.52e+00, avg batch time: 5.9740, average train loss: 2.4844
[11/27 23:26:21 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.5852, average loss: 4.5180
[11/27 23:26:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.72	
[11/27 23:26:21 visual_prompt]: Training 30 / 100 epoch, with learning rate 2.2350134420084022
[11/27 23:33:22 visual_prompt]: Epoch 30 / 100: avg data time: 4.56e+00, avg batch time: 6.0060, average train loss: 2.0008
[11/27 23:34:10 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.5844, average loss: 2.5384
[11/27 23:34:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.94	
[11/27 23:34:10 visual_prompt]: Training 31 / 100 epoch, with learning rate 2.2075555538987226
[11/27 23:41:08 visual_prompt]: Epoch 31 / 100: avg data time: 4.52e+00, avg batch time: 5.9718, average train loss: 2.7431
[11/27 23:41:56 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.5853, average loss: 1.3142
[11/27 23:41:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.91	
[11/27 23:41:56 visual_prompt]: Training 32 / 100 epoch, with learning rate 2.178931031846743
[11/27 23:48:55 visual_prompt]: Epoch 32 / 100: avg data time: 4.54e+00, avg batch time: 5.9863, average train loss: 3.2015
[11/27 23:49:43 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.5865, average loss: 14.4261
[11/27 23:49:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.41	
[11/27 23:49:43 visual_prompt]: Training 33 / 100 epoch, with learning rate 2.149174750423314
[11/27 23:56:43 visual_prompt]: Epoch 33 / 100: avg data time: 4.54e+00, avg batch time: 5.9926, average train loss: 5.1727
[11/27 23:57:31 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.5879, average loss: 2.0695
[11/27 23:57:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.47	
[11/27 23:57:31 visual_prompt]: Training 34 / 100 epoch, with learning rate 2.1183229630737466
[11/28 00:04:30 visual_prompt]: Epoch 34 / 100: avg data time: 4.54e+00, avg batch time: 5.9897, average train loss: 2.4771
[11/28 00:05:18 visual_prompt]: Inference (val):avg data time: 2.00e-05, avg batch time: 0.5864, average loss: 2.2157
[11/28 00:05:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.53	
[11/28 00:05:18 visual_prompt]: Training 35 / 100 epoch, with learning rate 2.086413257948573
[11/28 00:12:30 visual_prompt]: Epoch 35 / 100: avg data time: 4.72e+00, avg batch time: 6.1723, average train loss: 2.2929
[11/28 00:13:20 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.5869, average loss: 4.1066
[11/28 00:13:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.96	
[11/28 00:13:20 visual_prompt]: Training 36 / 100 epoch, with learning rate 2.053484512108174
[11/28 00:20:53 visual_prompt]: Epoch 36 / 100: avg data time: 5.02e+00, avg batch time: 6.4713, average train loss: 3.5507
[11/28 00:21:42 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.5883, average loss: 4.7839
[11/28 00:21:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.70	
[11/28 00:21:42 visual_prompt]: Training 37 / 100 epoch, with learning rate 2.019576844157073
[11/28 00:28:54 visual_prompt]: Epoch 37 / 100: avg data time: 4.72e+00, avg batch time: 6.1722, average train loss: 2.5079
[11/28 00:29:44 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.5897, average loss: 2.0872
[11/28 00:29:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.86	
[11/28 00:29:44 visual_prompt]: Stopping early.
[11/28 00:29:44 visual_prompt]: Rank of current process: 0. World size: 1
[11/28 00:29:44 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/28 00:29:44 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/28 00:29:44 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/28 00:29:44 visual_prompt]: Training with config:
[11/28 00:29:44 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr2.5_wd0.0001/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 2.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/28 00:29:44 visual_prompt]: Loading training data...
[11/28 00:29:44 visual_prompt]: Constructing mammo-cbis dataset train...
[11/28 00:29:44 visual_prompt]: Loading validation data...
[11/28 00:29:44 visual_prompt]: Constructing mammo-cbis dataset val...
[11/28 00:29:44 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/28 00:29:55 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/28 00:29:55 visual_prompt]: tuned percent:0.532
[11/28 00:29:55 visual_prompt]: Device used for model: 0
[11/28 00:29:55 visual_prompt]: Setting up Evaluator...
[11/28 00:29:55 visual_prompt]: Setting up Trainer...
[11/28 00:29:55 visual_prompt]: 	Setting up the optimizer...
[11/28 00:29:55 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/28 00:37:13 visual_prompt]: Epoch 1 / 100: avg data time: 4.79e+00, avg batch time: 6.2500, average train loss: 1.4863
[11/28 00:38:02 visual_prompt]: Inference (val):avg data time: 2.00e-05, avg batch time: 0.5869, average loss: 1.4553
[11/28 00:38:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/28 00:38:02 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.25
[11/28 00:45:14 visual_prompt]: Epoch 2 / 100: avg data time: 4.71e+00, avg batch time: 6.1638, average train loss: 1.6214
[11/28 00:46:03 visual_prompt]: Inference (val):avg data time: 2.01e-05, avg batch time: 0.5861, average loss: 1.1949
[11/28 00:46:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.63	
[11/28 00:46:03 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.5
[11/28 00:53:15 visual_prompt]: Epoch 3 / 100: avg data time: 4.71e+00, avg batch time: 6.1705, average train loss: 0.8810
[11/28 00:54:04 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.5873, average loss: 1.9229
[11/28 00:54:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.67	
[11/28 00:54:04 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.75
[11/28 01:01:17 visual_prompt]: Epoch 4 / 100: avg data time: 4.72e+00, avg batch time: 6.1755, average train loss: 0.8860
[11/28 01:02:06 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.5850, average loss: 0.6878
[11/28 01:02:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 57.24	
[11/28 01:02:06 visual_prompt]: Training 5 / 100 epoch, with learning rate 1.0
[11/28 01:09:17 visual_prompt]: Epoch 5 / 100: avg data time: 4.70e+00, avg batch time: 6.1586, average train loss: 0.9844
[11/28 01:10:06 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.5863, average loss: 1.3880
[11/28 01:10:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.08	
[11/28 01:10:06 visual_prompt]: Training 6 / 100 epoch, with learning rate 1.25
[11/28 01:17:20 visual_prompt]: Epoch 6 / 100: avg data time: 4.74e+00, avg batch time: 6.2015, average train loss: 1.5478
[11/28 01:18:10 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.5880, average loss: 0.8937
[11/28 01:18:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.44	
[11/28 01:18:10 visual_prompt]: Training 7 / 100 epoch, with learning rate 1.5
[11/28 01:25:22 visual_prompt]: Epoch 7 / 100: avg data time: 4.71e+00, avg batch time: 6.1700, average train loss: 1.0173
[11/28 01:26:11 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.5868, average loss: 0.7426
[11/28 01:26:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.80	
[11/28 01:26:11 visual_prompt]: Training 8 / 100 epoch, with learning rate 1.75
[11/28 01:33:22 visual_prompt]: Epoch 8 / 100: avg data time: 4.71e+00, avg batch time: 6.1598, average train loss: 0.8847
[11/28 01:34:12 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.5952, average loss: 1.4942
[11/28 01:34:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.80	
[11/28 01:34:12 visual_prompt]: Training 9 / 100 epoch, with learning rate 2.0
[11/28 01:41:27 visual_prompt]: Epoch 9 / 100: avg data time: 4.75e+00, avg batch time: 6.2208, average train loss: 2.7653
[11/28 01:42:17 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.5833, average loss: 1.0565
[11/28 01:42:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.41	
[11/28 01:42:17 visual_prompt]: Training 10 / 100 epoch, with learning rate 2.25
[11/28 01:49:28 visual_prompt]: Epoch 10 / 100: avg data time: 4.70e+00, avg batch time: 6.1564, average train loss: 2.6951
[11/28 01:50:17 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.5842, average loss: 4.2018
[11/28 01:50:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.56	
[11/28 01:50:17 visual_prompt]: Training 11 / 100 epoch, with learning rate 2.5
[11/28 01:57:28 visual_prompt]: Epoch 11 / 100: avg data time: 4.71e+00, avg batch time: 6.1643, average train loss: 4.0179
[11/28 01:58:18 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.5863, average loss: 6.0288
[11/28 01:58:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.77	
[11/28 01:58:18 visual_prompt]: Training 12 / 100 epoch, with learning rate 2.4992385337738696
[11/28 02:05:29 visual_prompt]: Epoch 12 / 100: avg data time: 4.70e+00, avg batch time: 6.1532, average train loss: 2.0882
[11/28 02:06:18 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.5862, average loss: 1.0290
[11/28 02:06:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.19	
[11/28 02:06:18 visual_prompt]: Best epoch 12: best metric: -1.029
[11/28 02:06:18 visual_prompt]: Training 13 / 100 epoch, with learning rate 2.4969550628247803
[11/28 02:13:30 visual_prompt]: Epoch 13 / 100: avg data time: 4.72e+00, avg batch time: 6.1752, average train loss: 1.2469
[11/28 02:14:19 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.5866, average loss: 1.4594
[11/28 02:14:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.04	
[11/28 02:14:19 visual_prompt]: Training 14 / 100 epoch, with learning rate 2.4931523692103417
[11/28 02:21:32 visual_prompt]: Epoch 14 / 100: avg data time: 4.73e+00, avg batch time: 6.1797, average train loss: 1.1669
[11/28 02:22:21 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.5875, average loss: 1.1698
[11/28 02:22:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.45	
[11/28 02:22:21 visual_prompt]: Training 15 / 100 epoch, with learning rate 2.487835085926963
[11/28 02:29:33 visual_prompt]: Epoch 15 / 100: avg data time: 4.70e+00, avg batch time: 6.1572, average train loss: 0.9826
[11/28 02:30:22 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.5871, average loss: 0.7357
[11/28 02:30:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.94	
[11/28 02:30:22 visual_prompt]: Best epoch 15: best metric: -0.736
[11/28 02:30:22 visual_prompt]: Training 16 / 100 epoch, with learning rate 2.4810096912652604
[11/28 02:37:33 visual_prompt]: Epoch 16 / 100: avg data time: 4.70e+00, avg batch time: 6.1612, average train loss: 1.0206
[11/28 02:38:23 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.5885, average loss: 0.6875
[11/28 02:38:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 58.50	
[11/28 02:38:23 visual_prompt]: Best epoch 16: best metric: -0.687
[11/28 02:38:23 visual_prompt]: Training 17 / 100 epoch, with learning rate 2.472684500917257
[11/28 02:45:33 visual_prompt]: Epoch 17 / 100: avg data time: 4.69e+00, avg batch time: 6.1445, average train loss: 0.9372
[11/28 02:46:22 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.5905, average loss: 0.7151
[11/28 02:46:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.23	
[11/28 02:46:22 visual_prompt]: Training 18 / 100 epoch, with learning rate 2.4628696578449953
[11/28 02:53:33 visual_prompt]: Epoch 18 / 100: avg data time: 4.69e+00, avg batch time: 6.1510, average train loss: 0.8880
[11/28 02:54:22 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.5880, average loss: 1.1504
[11/28 02:54:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.23	
[11/28 02:54:22 visual_prompt]: Training 19 / 100 epoch, with learning rate 2.4515771199228986
[11/28 03:01:33 visual_prompt]: Epoch 19 / 100: avg data time: 4.70e+00, avg batch time: 6.1605, average train loss: 0.9286
[11/28 03:02:23 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.5864, average loss: 1.1004
[11/28 03:02:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 64.36	
[11/28 03:02:23 visual_prompt]: Training 20 / 100 epoch, with learning rate 2.438820645368942
[11/28 03:09:36 visual_prompt]: Epoch 20 / 100: avg data time: 4.74e+00, avg batch time: 6.1891, average train loss: 1.0324
[11/28 03:10:25 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.5892, average loss: 0.7345
[11/28 03:10:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.63	
[11/28 03:10:25 visual_prompt]: Training 21 / 100 epoch, with learning rate 2.4246157759823856
[11/28 03:17:38 visual_prompt]: Epoch 21 / 100: avg data time: 4.72e+00, avg batch time: 6.1784, average train loss: 1.0471
[11/28 03:18:27 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.5894, average loss: 1.3865
[11/28 03:18:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.72	
[11/28 03:18:27 visual_prompt]: Training 22 / 100 epoch, with learning rate 2.4089798182084845
[11/28 03:25:38 visual_prompt]: Epoch 22 / 100: avg data time: 4.70e+00, avg batch time: 6.1516, average train loss: 1.2070
[11/28 03:26:27 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.5909, average loss: 0.9246
[11/28 03:26:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.99	
[11/28 03:26:27 visual_prompt]: Training 23 / 100 epoch, with learning rate 2.391931822053251
[11/28 03:33:40 visual_prompt]: Epoch 23 / 100: avg data time: 4.72e+00, avg batch time: 6.1786, average train loss: 0.8842
[11/28 03:34:29 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.5895, average loss: 1.4459
[11/28 03:34:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.29	
[11/28 03:34:29 visual_prompt]: Training 24 / 100 epoch, with learning rate 2.3734925578739587
[11/28 03:41:41 visual_prompt]: Epoch 24 / 100: avg data time: 4.71e+00, avg batch time: 6.1642, average train loss: 0.9811
[11/28 03:42:30 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.5836, average loss: 0.6807
[11/28 03:42:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.36	
[11/28 03:42:30 visual_prompt]: Best epoch 24: best metric: -0.681
[11/28 03:42:30 visual_prompt]: Training 25 / 100 epoch, with learning rate 2.3536844910736585
[11/28 03:49:42 visual_prompt]: Epoch 25 / 100: avg data time: 4.72e+00, avg batch time: 6.1722, average train loss: 0.9889
[11/28 03:50:32 visual_prompt]: Inference (val):avg data time: 3.20e-03, avg batch time: 0.6544, average loss: 1.7266
[11/28 03:50:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 64.85	
[11/28 03:50:32 visual_prompt]: Training 26 / 100 epoch, with learning rate 2.3325317547305486
[11/28 03:57:45 visual_prompt]: Epoch 26 / 100: avg data time: 4.72e+00, avg batch time: 6.1769, average train loss: 1.1506
[11/28 03:58:35 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.6046, average loss: 1.0583
[11/28 03:58:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 66.25	
[11/28 03:58:35 visual_prompt]: Training 27 / 100 epoch, with learning rate 2.310060120195532
[11/28 04:05:48 visual_prompt]: Epoch 27 / 100: avg data time: 4.73e+00, avg batch time: 6.1853, average train loss: 0.9342
[11/28 04:06:37 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.5886, average loss: 1.0897
[11/28 04:06:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 67.55	
[11/28 04:06:37 visual_prompt]: Training 28 / 100 epoch, with learning rate 2.286296965693802
[11/28 04:13:50 visual_prompt]: Epoch 28 / 100: avg data time: 4.73e+00, avg batch time: 6.1773, average train loss: 0.9433
[11/28 04:14:39 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.5876, average loss: 1.0355
[11/28 04:14:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 66.10	
[11/28 04:14:39 visual_prompt]: Training 29 / 100 epoch, with learning rate 2.261271242968684
[11/28 04:21:50 visual_prompt]: Epoch 29 / 100: avg data time: 4.70e+00, avg batch time: 6.1567, average train loss: 0.8282
[11/28 04:22:39 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.5853, average loss: 1.9617
[11/28 04:22:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 70.40	
[11/28 04:22:39 visual_prompt]: Training 30 / 100 epoch, with learning rate 2.2350134420084022
[11/28 04:29:53 visual_prompt]: Epoch 30 / 100: avg data time: 4.74e+00, avg batch time: 6.1966, average train loss: 0.8803
[11/28 04:30:43 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.5890, average loss: 1.3985
[11/28 04:30:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 64.14	
[11/28 04:30:43 visual_prompt]: Training 31 / 100 epoch, with learning rate 2.2075555538987226
[11/28 04:37:53 visual_prompt]: Epoch 31 / 100: avg data time: 4.68e+00, avg batch time: 6.1409, average train loss: 0.8130
[11/28 04:38:42 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.5917, average loss: 0.6648
[11/28 04:38:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 65.11	
[11/28 04:38:42 visual_prompt]: Best epoch 31: best metric: -0.665
[11/28 04:38:42 visual_prompt]: Training 32 / 100 epoch, with learning rate 2.178931031846743
[11/28 04:45:55 visual_prompt]: Epoch 32 / 100: avg data time: 4.72e+00, avg batch time: 6.1780, average train loss: 0.9211
[11/28 04:46:44 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.5859, average loss: 0.9366
[11/28 04:46:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 63.68	
[11/28 04:46:44 visual_prompt]: Training 33 / 100 epoch, with learning rate 2.149174750423314
[11/28 04:53:56 visual_prompt]: Epoch 33 / 100: avg data time: 4.71e+00, avg batch time: 6.1670, average train loss: 0.9207
[11/28 04:54:46 visual_prompt]: Inference (val):avg data time: 1.66e-04, avg batch time: 0.6004, average loss: 0.7185
[11/28 04:54:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 65.69	
[11/28 04:54:46 visual_prompt]: Training 34 / 100 epoch, with learning rate 2.1183229630737466
[11/28 05:01:58 visual_prompt]: Epoch 34 / 100: avg data time: 4.71e+00, avg batch time: 6.1720, average train loss: 0.9264
[11/28 05:02:48 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.5881, average loss: 1.7004
[11/28 05:02:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 69.54	
[11/28 05:02:48 visual_prompt]: Training 35 / 100 epoch, with learning rate 2.086413257948573
[11/28 05:09:58 visual_prompt]: Epoch 35 / 100: avg data time: 4.70e+00, avg batch time: 6.1489, average train loss: 0.9421
[11/28 05:10:48 visual_prompt]: Inference (val):avg data time: 1.42e-04, avg batch time: 0.6010, average loss: 0.7892
[11/28 05:10:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 68.04	
[11/28 05:10:48 visual_prompt]: Training 36 / 100 epoch, with learning rate 2.053484512108174
[11/28 05:17:59 visual_prompt]: Epoch 36 / 100: avg data time: 4.70e+00, avg batch time: 6.1641, average train loss: 0.7960
[11/28 05:18:48 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.5866, average loss: 0.7737
[11/28 05:18:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 44.72	rocauc: 65.26	
[11/28 05:18:48 visual_prompt]: Training 37 / 100 epoch, with learning rate 2.019576844157073
[11/28 05:26:00 visual_prompt]: Epoch 37 / 100: avg data time: 4.72e+00, avg batch time: 6.1720, average train loss: 0.8507
[11/28 05:26:50 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.5860, average loss: 0.8610
[11/28 05:26:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 66.59	
[11/28 05:26:50 visual_prompt]: Training 38 / 100 epoch, with learning rate 1.9847315653655915
[11/28 05:34:02 visual_prompt]: Epoch 38 / 100: avg data time: 4.72e+00, avg batch time: 6.1776, average train loss: 0.7865
[11/28 05:34:52 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.5851, average loss: 1.3960
[11/28 05:34:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 67.72	
[11/28 05:34:52 visual_prompt]: Training 39 / 100 epoch, with learning rate 1.9489911293384334
[11/28 05:42:05 visual_prompt]: Epoch 39 / 100: avg data time: 4.72e+00, avg batch time: 6.1796, average train loss: 0.8903
[11/28 05:42:54 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.5865, average loss: 1.3137
[11/28 05:42:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 69.14	
[11/28 05:42:54 visual_prompt]: Training 40 / 100 epoch, with learning rate 1.912399080291506
[11/28 05:50:05 visual_prompt]: Epoch 40 / 100: avg data time: 4.70e+00, avg batch time: 6.1510, average train loss: 0.7843
[11/28 05:50:54 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.5859, average loss: 0.6927
[11/28 05:50:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 70.93	
[11/28 05:50:54 visual_prompt]: Training 41 / 100 epoch, with learning rate 1.875
[11/28 05:58:04 visual_prompt]: Epoch 41 / 100: avg data time: 4.69e+00, avg batch time: 6.1414, average train loss: 0.7661
[11/28 05:58:54 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.5887, average loss: 0.8193
[11/28 05:58:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 68.77	
[11/28 05:58:54 visual_prompt]: Training 42 / 100 epoch, with learning rate 1.8368394534823635
[11/28 06:06:05 visual_prompt]: Epoch 42 / 100: avg data time: 4.71e+00, avg batch time: 6.1669, average train loss: 0.7495
[11/28 06:06:54 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.5881, average loss: 0.6496
[11/28 06:06:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.07	rocauc: 70.28	
[11/28 06:06:54 visual_prompt]: Best epoch 42: best metric: -0.650
[11/28 06:06:54 visual_prompt]: Training 43 / 100 epoch, with learning rate 1.7979639334863466
[11/28 06:14:05 visual_prompt]: Epoch 43 / 100: avg data time: 4.70e+00, avg batch time: 6.1559, average train loss: 0.7161
[11/28 06:14:55 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.5899, average loss: 1.9414
[11/28 06:14:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 69.75	
[11/28 06:14:55 visual_prompt]: Training 44 / 100 epoch, with learning rate 1.7584208038447504
[11/28 06:22:09 visual_prompt]: Epoch 44 / 100: avg data time: 4.75e+00, avg batch time: 6.2103, average train loss: 0.8816
[11/28 06:22:59 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.5885, average loss: 0.6577
[11/28 06:22:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 65.47	
[11/28 06:22:59 visual_prompt]: Training 45 / 100 epoch, with learning rate 1.7182582417698902
[11/28 06:30:11 visual_prompt]: Epoch 45 / 100: avg data time: 4.72e+00, avg batch time: 6.1785, average train loss: 0.7604
[11/28 06:31:00 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.5846, average loss: 0.7783
[11/28 06:31:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 65.51	
[11/28 06:31:00 visual_prompt]: Training 46 / 100 epoch, with learning rate 1.6775251791570862
[11/28 06:38:12 visual_prompt]: Epoch 46 / 100: avg data time: 4.71e+00, avg batch time: 6.1648, average train loss: 0.7785
[11/28 06:39:01 visual_prompt]: Inference (val):avg data time: 1.15e-04, avg batch time: 0.5965, average loss: 0.6453
[11/28 06:39:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 67.25	
[11/28 06:39:01 visual_prompt]: Best epoch 46: best metric: -0.645
[11/28 06:39:01 visual_prompt]: Training 47 / 100 epoch, with learning rate 1.6362712429686843
[11/28 06:46:13 visual_prompt]: Epoch 47 / 100: avg data time: 4.71e+00, avg batch time: 6.1680, average train loss: 0.9601
[11/28 06:47:03 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.5978, average loss: 0.7167
[11/28 06:47:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 69.11	
[11/28 06:47:03 visual_prompt]: Training 48 / 100 epoch, with learning rate 1.5945466947712488
[11/28 06:54:18 visual_prompt]: Epoch 48 / 100: avg data time: 4.74e+00, avg batch time: 6.2117, average train loss: 0.6963
[11/28 06:55:07 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.5855, average loss: 1.7540
[11/28 06:55:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 68.67	
[11/28 06:55:07 visual_prompt]: Training 49 / 100 epoch, with learning rate 1.5524023694995845
[11/28 07:02:20 visual_prompt]: Epoch 49 / 100: avg data time: 4.73e+00, avg batch time: 6.1812, average train loss: 0.9557
[11/28 07:03:09 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.5879, average loss: 1.4158
[11/28 07:03:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 67.71	
[11/28 07:03:09 visual_prompt]: Training 50 / 100 epoch, with learning rate 1.509889613522199
[11/28 07:10:23 visual_prompt]: Epoch 50 / 100: avg data time: 4.73e+00, avg batch time: 6.1924, average train loss: 0.9288
[11/28 07:11:12 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.5847, average loss: 0.7403
[11/28 07:11:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 70.05	
[11/28 07:11:12 visual_prompt]: Training 51 / 100 epoch, with learning rate 1.467060222083663
[11/28 07:18:25 visual_prompt]: Epoch 51 / 100: avg data time: 4.72e+00, avg batch time: 6.1868, average train loss: 0.7229
[11/28 07:19:14 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.5908, average loss: 0.8697
[11/28 07:19:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 67.91	
[11/28 07:19:14 visual_prompt]: Training 52 / 100 epoch, with learning rate 1.4239663762000818
[11/28 07:26:26 visual_prompt]: Epoch 52 / 100: avg data time: 4.72e+00, avg batch time: 6.1754, average train loss: 0.7241
[11/28 07:27:16 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.5906, average loss: 0.6523
[11/28 07:27:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 68.87	
[11/28 07:27:16 visual_prompt]: Training 53 / 100 epoch, with learning rate 1.380660579084567
[11/28 07:34:29 visual_prompt]: Epoch 53 / 100: avg data time: 4.73e+00, avg batch time: 6.1850, average train loss: 0.7654
[11/28 07:35:18 visual_prompt]: Inference (val):avg data time: 1.01e-04, avg batch time: 0.5958, average loss: 0.6691
[11/28 07:35:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 69.50	
[11/28 07:35:18 visual_prompt]: Training 54 / 100 epoch, with learning rate 1.3371955921801564
[11/28 07:42:32 visual_prompt]: Epoch 54 / 100: avg data time: 4.73e+00, avg batch time: 6.1920, average train loss: 0.7238
[11/28 07:43:21 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.5917, average loss: 1.7287
[11/28 07:43:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 68.79	
[11/28 07:43:21 visual_prompt]: Training 55 / 100 epoch, with learning rate 1.2936243708781263
[11/28 07:50:29 visual_prompt]: Epoch 55 / 100: avg data time: 4.66e+00, avg batch time: 6.1146, average train loss: 1.0356
[11/28 07:51:19 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.5924, average loss: 2.2162
[11/28 07:51:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 69.28	
[11/28 07:51:19 visual_prompt]: Training 56 / 100 epoch, with learning rate 1.25
[11/28 07:58:28 visual_prompt]: Epoch 56 / 100: avg data time: 4.67e+00, avg batch time: 6.1241, average train loss: 1.2473
[11/28 07:59:17 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.5906, average loss: 0.9496
[11/28 07:59:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 65.13	
[11/28 07:59:17 visual_prompt]: Training 57 / 100 epoch, with learning rate 1.2063756291218741
[11/28 08:06:28 visual_prompt]: Epoch 57 / 100: avg data time: 4.71e+00, avg batch time: 6.1593, average train loss: 0.8415
[11/28 08:07:18 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.5841, average loss: 0.8823
[11/28 08:07:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 64.23	
[11/28 08:07:18 visual_prompt]: Training 58 / 100 epoch, with learning rate 1.1628044078198434
[11/28 08:14:28 visual_prompt]: Epoch 58 / 100: avg data time: 4.69e+00, avg batch time: 6.1523, average train loss: 0.7703
[11/28 08:15:17 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.5870, average loss: 0.9684
[11/28 08:15:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 67.40	
[11/28 08:15:18 visual_prompt]: Training 59 / 100 epoch, with learning rate 1.1193394209154333
[11/28 08:22:33 visual_prompt]: Epoch 59 / 100: avg data time: 4.76e+00, avg batch time: 6.2166, average train loss: 0.7828
[11/28 08:23:22 visual_prompt]: Inference (val):avg data time: 2.00e-05, avg batch time: 0.5879, average loss: 0.6654
[11/28 08:23:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 65.61	
[11/28 08:23:22 visual_prompt]: Training 60 / 100 epoch, with learning rate 1.0760336237999186
[11/28 08:30:32 visual_prompt]: Epoch 60 / 100: avg data time: 4.69e+00, avg batch time: 6.1446, average train loss: 0.6723
[11/28 08:31:22 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.5876, average loss: 0.6401
[11/28 08:31:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 68.13	
[11/28 08:31:22 visual_prompt]: Best epoch 60: best metric: -0.640
[11/28 08:31:22 visual_prompt]: Training 61 / 100 epoch, with learning rate 1.0329397779163372
[11/28 08:38:33 visual_prompt]: Epoch 61 / 100: avg data time: 4.70e+00, avg batch time: 6.1608, average train loss: 0.7060
[11/28 08:39:22 visual_prompt]: Inference (val):avg data time: 1.99e-05, avg batch time: 0.5915, average loss: 0.6808
[11/28 08:39:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 68.25	
[11/28 08:39:22 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.990110386477801
[11/28 08:46:34 visual_prompt]: Epoch 62 / 100: avg data time: 4.71e+00, avg batch time: 6.1628, average train loss: 0.6743
[11/28 08:47:23 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.5886, average loss: 0.7265
[11/28 08:47:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 69.70	
[11/28 08:47:23 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.9475976305004155
[11/28 08:54:34 visual_prompt]: Epoch 63 / 100: avg data time: 4.70e+00, avg batch time: 6.1548, average train loss: 0.6645
[11/28 08:55:23 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.5861, average loss: 0.6328
[11/28 08:55:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 70.30	
[11/28 08:55:23 visual_prompt]: Best epoch 63: best metric: -0.633
[11/28 08:55:23 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.9054533052287511
[11/28 09:02:34 visual_prompt]: Epoch 64 / 100: avg data time: 4.70e+00, avg batch time: 6.1593, average train loss: 0.6621
[11/28 09:03:23 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.5865, average loss: 0.7139
[11/28 09:03:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 68.77	
[11/28 09:03:23 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.8637287570313158
[11/28 09:10:35 visual_prompt]: Epoch 65 / 100: avg data time: 4.70e+00, avg batch time: 6.1709, average train loss: 0.6703
[11/28 09:11:25 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.5871, average loss: 0.6501
[11/28 09:11:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 67.36	
[11/28 09:11:25 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.8224748208429142
[11/28 09:18:36 visual_prompt]: Epoch 66 / 100: avg data time: 4.70e+00, avg batch time: 6.1569, average train loss: 0.7395
[11/28 09:19:25 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.5886, average loss: 0.6679
[11/28 09:19:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.01	rocauc: 67.39	
[11/28 09:19:25 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.7817417582301099
[11/28 09:26:35 visual_prompt]: Epoch 67 / 100: avg data time: 4.69e+00, avg batch time: 6.1448, average train loss: 0.6559
[11/28 09:27:25 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.5936, average loss: 0.7737
[11/28 09:27:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 68.17	
[11/28 09:27:25 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.7415791961552499
[11/28 09:34:36 visual_prompt]: Epoch 68 / 100: avg data time: 4.70e+00, avg batch time: 6.1507, average train loss: 0.7044
[11/28 09:35:25 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.5860, average loss: 0.6332
[11/28 09:35:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 70.44	
[11/28 09:35:25 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.7020360665136531
[11/28 09:42:38 visual_prompt]: Epoch 69 / 100: avg data time: 4.72e+00, avg batch time: 6.1861, average train loss: 0.6891
[11/28 09:43:27 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.5865, average loss: 0.6384
[11/28 09:43:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.01	rocauc: 68.15	
[11/28 09:43:27 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.6631605465176369
[11/28 09:50:40 visual_prompt]: Epoch 70 / 100: avg data time: 4.73e+00, avg batch time: 6.1874, average train loss: 0.6296
[11/28 09:51:29 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.5839, average loss: 0.7300
[11/28 09:51:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 69.00	
[11/28 09:51:29 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.6250000000000002
[11/28 09:58:40 visual_prompt]: Epoch 71 / 100: avg data time: 4.70e+00, avg batch time: 6.1520, average train loss: 0.6490
[11/28 09:59:29 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.5879, average loss: 0.6348
[11/28 09:59:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 68.61	
[11/28 09:59:29 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.587600919708494
[11/28 10:06:40 visual_prompt]: Epoch 72 / 100: avg data time: 4.70e+00, avg batch time: 6.1488, average train loss: 0.6206
[11/28 10:07:29 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.5864, average loss: 0.6337
[11/28 10:07:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 70.83	
[11/28 10:07:29 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.5510088706615667
[11/28 10:14:41 visual_prompt]: Epoch 73 / 100: avg data time: 4.71e+00, avg batch time: 6.1646, average train loss: 0.6205
[11/28 10:15:30 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.5892, average loss: 0.7726
[11/28 10:15:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 67.87	
[11/28 10:15:30 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.5152684346344087
[11/28 10:22:41 visual_prompt]: Epoch 74 / 100: avg data time: 4.71e+00, avg batch time: 6.1609, average train loss: 0.6449
[11/28 10:23:30 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.5887, average loss: 0.6412
[11/28 10:23:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 68.38	
[11/28 10:23:30 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.48042315584292716
[11/28 10:30:42 visual_prompt]: Epoch 75 / 100: avg data time: 4.71e+00, avg batch time: 6.1584, average train loss: 0.6157
[11/28 10:31:31 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.5851, average loss: 0.6767
[11/28 10:31:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 68.55	
[11/28 10:31:31 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.4465154878918258
[11/28 10:38:44 visual_prompt]: Epoch 76 / 100: avg data time: 4.72e+00, avg batch time: 6.1821, average train loss: 0.6182
[11/28 10:39:33 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.5866, average loss: 0.6633
[11/28 10:39:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.01	rocauc: 69.46	
[11/28 10:39:33 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.41358674205142765
[11/28 10:46:44 visual_prompt]: Epoch 77 / 100: avg data time: 4.70e+00, avg batch time: 6.1536, average train loss: 0.6020
[11/28 10:47:33 visual_prompt]: Inference (val):avg data time: 2.02e-05, avg batch time: 0.5885, average loss: 0.7176
[11/28 10:47:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 70.95	
[11/28 10:47:33 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.3816770369262533
[11/28 10:54:45 visual_prompt]: Epoch 78 / 100: avg data time: 4.71e+00, avg batch time: 6.1688, average train loss: 0.5960
[11/28 10:55:35 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.5848, average loss: 0.7108
[11/28 10:55:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 72.09	
[11/28 10:55:35 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.35082524957668626
[11/28 11:02:47 visual_prompt]: Epoch 79 / 100: avg data time: 4.72e+00, avg batch time: 6.1693, average train loss: 0.5873
[11/28 11:03:36 visual_prompt]: Inference (val):avg data time: 1.42e-04, avg batch time: 0.5928, average loss: 0.6371
[11/28 11:03:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 70.07	
[11/28 11:03:36 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.32106896815325703
[11/28 11:10:48 visual_prompt]: Epoch 80 / 100: avg data time: 4.72e+00, avg batch time: 6.1762, average train loss: 0.5784
[11/28 11:11:38 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.5864, average loss: 0.6325
[11/28 11:11:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 70.33	
[11/28 11:11:38 visual_prompt]: Best epoch 80: best metric: -0.633
[11/28 11:11:38 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.2924444461012776
[11/28 11:18:52 visual_prompt]: Epoch 81 / 100: avg data time: 4.74e+00, avg batch time: 6.2032, average train loss: 0.5605
[11/28 11:19:42 visual_prompt]: Inference (val):avg data time: 3.54e-03, avg batch time: 0.5897, average loss: 0.7297
[11/28 11:19:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 74.49	
[11/28 11:19:42 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.26498655799159765
[11/28 11:26:49 visual_prompt]: Epoch 82 / 100: avg data time: 4.64e+00, avg batch time: 6.1012, average train loss: 0.5900
[11/28 11:27:38 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.5893, average loss: 0.6502
[11/28 11:27:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 69.00	
[11/28 11:27:38 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.23872875703131582
[11/28 11:34:53 visual_prompt]: Epoch 83 / 100: avg data time: 4.74e+00, avg batch time: 6.2047, average train loss: 0.5643
[11/28 11:35:42 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.5843, average loss: 0.6655
[11/28 11:35:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 70.90	
[11/28 11:35:42 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.21370303430619797
[11/28 11:42:58 visual_prompt]: Epoch 84 / 100: avg data time: 4.77e+00, avg batch time: 6.2295, average train loss: 0.5724
[11/28 11:43:47 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.5887, average loss: 0.6592
[11/28 11:43:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 68.76	
[11/28 11:43:47 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.18993987980446755
[11/28 11:50:59 visual_prompt]: Epoch 85 / 100: avg data time: 4.71e+00, avg batch time: 6.1647, average train loss: 0.5365
[11/28 11:51:48 visual_prompt]: Inference (val):avg data time: 2.11e-05, avg batch time: 0.5872, average loss: 0.6109
[11/28 11:51:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 71.75	
[11/28 11:51:48 visual_prompt]: Best epoch 85: best metric: -0.611
[11/28 11:51:48 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.16746824526945162
[11/28 11:59:02 visual_prompt]: Epoch 86 / 100: avg data time: 4.74e+00, avg batch time: 6.1965, average train loss: 0.5241
[11/28 11:59:52 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.5856, average loss: 0.7347
[11/28 11:59:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 68.04	
[11/28 11:59:52 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.14631550892634126
[11/28 12:07:13 visual_prompt]: Epoch 87 / 100: avg data time: 4.85e+00, avg batch time: 6.3019, average train loss: 0.5402
[11/28 12:08:07 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.5887, average loss: 0.7204
[11/28 12:08:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 66.43	
[11/28 12:08:07 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.12650744212604148
[11/28 12:15:53 visual_prompt]: Epoch 88 / 100: avg data time: 5.20e+00, avg batch time: 6.6576, average train loss: 0.5067
[11/28 12:16:46 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.5905, average loss: 0.7077
[11/28 12:16:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 68.06	
[11/28 12:16:46 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.10806817794674878
[11/28 12:24:30 visual_prompt]: Epoch 89 / 100: avg data time: 5.17e+00, avg batch time: 6.6258, average train loss: 0.4910
[11/28 12:25:23 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.5913, average loss: 0.7293
[11/28 12:25:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 68.86	
[11/28 12:25:23 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.09102018179151586
[11/28 12:33:08 visual_prompt]: Epoch 90 / 100: avg data time: 5.17e+00, avg batch time: 6.6345, average train loss: 0.4973
[11/28 12:34:00 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.5890, average loss: 0.7170
[11/28 12:34:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 67.91	
[11/28 12:34:00 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.0753842240176146
[11/28 12:41:44 visual_prompt]: Epoch 91 / 100: avg data time: 5.16e+00, avg batch time: 6.6151, average train loss: 0.4893
[11/28 12:42:37 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.5857, average loss: 0.8093
[11/28 12:42:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.01	rocauc: 68.81	
[11/28 12:42:37 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.061179354631058086
[11/28 12:50:18 visual_prompt]: Epoch 92 / 100: avg data time: 5.14e+00, avg batch time: 6.5919, average train loss: 0.4622
[11/28 12:51:11 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.5837, average loss: 0.6774
[11/28 12:51:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 68.46	
[11/28 12:51:11 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.04842288007710138
[11/28 12:58:53 visual_prompt]: Epoch 93 / 100: avg data time: 5.14e+00, avg batch time: 6.5976, average train loss: 0.4419
[11/28 12:59:46 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.5895, average loss: 0.7900
[11/28 12:59:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.01	rocauc: 67.91	
[11/28 12:59:46 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.03713034215500441
[11/28 13:07:32 visual_prompt]: Epoch 94 / 100: avg data time: 5.19e+00, avg batch time: 6.6486, average train loss: 0.4248
[11/28 13:08:25 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.5867, average loss: 0.8497
[11/28 13:08:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 64.43	
[11/28 13:08:25 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.02731549908274289
[11/28 13:16:10 visual_prompt]: Epoch 95 / 100: avg data time: 5.20e+00, avg batch time: 6.6497, average train loss: 0.4215
[11/28 13:17:03 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.5877, average loss: 0.8489
[11/28 13:17:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 63.34	
[11/28 13:17:03 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.018990308734739975
[11/28 13:24:50 visual_prompt]: Epoch 96 / 100: avg data time: 5.21e+00, avg batch time: 6.6602, average train loss: 0.4017
[11/28 13:25:43 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.5913, average loss: 0.8459
[11/28 13:25:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.54	rocauc: 64.88	
[11/28 13:25:43 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.012164914073037048
[11/28 13:33:27 visual_prompt]: Epoch 97 / 100: avg data time: 5.18e+00, avg batch time: 6.6303, average train loss: 0.3947
[11/28 13:34:20 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.5843, average loss: 0.8532
[11/28 13:34:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 65.91	
[11/28 13:34:20 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.006847630789658388
[11/28 13:42:07 visual_prompt]: Epoch 98 / 100: avg data time: 5.21e+00, avg batch time: 6.6713, average train loss: 0.3824
[11/28 13:43:01 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.5861, average loss: 0.9099
[11/28 13:43:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 65.48	
[11/28 13:43:01 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.003044937175219753
[11/28 13:50:44 visual_prompt]: Epoch 99 / 100: avg data time: 5.17e+00, avg batch time: 6.6214, average train loss: 0.3744
[11/28 13:51:37 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.5873, average loss: 0.9119
[11/28 13:51:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 64.96	
[11/28 13:51:37 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0007614662261302974
[11/28 13:59:25 visual_prompt]: Epoch 100 / 100: avg data time: 5.22e+00, avg batch time: 6.6735, average train loss: 0.3741
[11/28 14:00:18 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.5862, average loss: 0.9522
[11/28 14:00:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 65.01	
[11/28 14:00:18 visual_prompt]: Rank of current process: 0. World size: 1
[11/28 14:00:18 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/28 14:00:18 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/28 14:00:18 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/28 14:00:18 visual_prompt]: Training with config:
[11/28 14:00:18 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr2.5_wd0.0/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 2.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/28 14:00:18 visual_prompt]: Loading training data...
[11/28 14:00:18 visual_prompt]: Constructing mammo-cbis dataset train...
[11/28 14:00:18 visual_prompt]: Loading validation data...
[11/28 14:00:18 visual_prompt]: Constructing mammo-cbis dataset val...
[11/28 14:00:18 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/28 14:00:26 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/28 14:00:26 visual_prompt]: tuned percent:0.532
[11/28 14:00:26 visual_prompt]: Device used for model: 0
[11/28 14:00:26 visual_prompt]: Setting up Evaluator...
[11/28 14:00:26 visual_prompt]: Setting up Trainer...
[11/28 14:00:26 visual_prompt]: 	Setting up the optimizer...
[11/28 14:00:26 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/28 14:08:14 visual_prompt]: Epoch 1 / 100: avg data time: 5.22e+00, avg batch time: 6.6735, average train loss: 1.4863
[11/28 14:09:06 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.5878, average loss: 1.4553
[11/28 14:09:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/28 14:09:06 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.25
[11/28 14:16:52 visual_prompt]: Epoch 2 / 100: avg data time: 5.20e+00, avg batch time: 6.6504, average train loss: 1.6234
[11/28 14:17:45 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.5852, average loss: 1.2002
[11/28 14:17:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.39	
[11/28 14:17:45 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.5
[11/28 14:25:30 visual_prompt]: Epoch 3 / 100: avg data time: 5.19e+00, avg batch time: 6.6358, average train loss: 0.8825
[11/28 14:26:23 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.5881, average loss: 1.9262
[11/28 14:26:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.37	
[11/28 14:26:23 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.75
[11/28 14:34:06 visual_prompt]: Epoch 4 / 100: avg data time: 5.17e+00, avg batch time: 6.6220, average train loss: 0.8895
[11/28 14:34:59 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.5855, average loss: 0.6904
[11/28 14:34:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 57.46	
[11/28 14:34:59 visual_prompt]: Training 5 / 100 epoch, with learning rate 1.0
[11/28 14:42:43 visual_prompt]: Epoch 5 / 100: avg data time: 5.17e+00, avg batch time: 6.6255, average train loss: 1.0184
[11/28 14:43:36 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.5915, average loss: 1.2124
[11/28 14:43:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.08	
[11/28 14:43:36 visual_prompt]: Training 6 / 100 epoch, with learning rate 1.25
[11/28 14:51:24 visual_prompt]: Epoch 6 / 100: avg data time: 5.24e+00, avg batch time: 6.6850, average train loss: 1.7453
[11/28 14:52:17 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.5894, average loss: 2.4215
[11/28 14:52:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.67	
[11/28 14:52:17 visual_prompt]: Training 7 / 100 epoch, with learning rate 1.5
[11/28 15:00:02 visual_prompt]: Epoch 7 / 100: avg data time: 5.18e+00, avg batch time: 6.6343, average train loss: 2.6563
[11/28 15:00:55 visual_prompt]: Inference (val):avg data time: 3.51e-05, avg batch time: 0.5867, average loss: 1.1308
[11/28 15:00:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.90	
[11/28 15:00:55 visual_prompt]: Training 8 / 100 epoch, with learning rate 1.75
[11/28 15:08:40 visual_prompt]: Epoch 8 / 100: avg data time: 5.19e+00, avg batch time: 6.6380, average train loss: 0.9193
[11/28 15:09:33 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.5851, average loss: 1.9297
[11/28 15:09:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.54	
[11/28 15:09:33 visual_prompt]: Training 9 / 100 epoch, with learning rate 2.0
[11/28 15:17:17 visual_prompt]: Epoch 9 / 100: avg data time: 5.18e+00, avg batch time: 6.6282, average train loss: 1.5521
[11/28 15:18:10 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.5841, average loss: 0.7257
[11/28 15:18:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.93	rocauc: 62.16	
[11/28 15:18:10 visual_prompt]: Training 10 / 100 epoch, with learning rate 2.25
[11/28 15:25:56 visual_prompt]: Epoch 10 / 100: avg data time: 5.19e+00, avg batch time: 6.6442, average train loss: 1.8357
[11/28 15:26:49 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.5867, average loss: 1.1747
[11/28 15:26:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 63.59	
[11/28 15:26:49 visual_prompt]: Training 11 / 100 epoch, with learning rate 2.5
[11/28 15:34:33 visual_prompt]: Epoch 11 / 100: avg data time: 5.18e+00, avg batch time: 6.6302, average train loss: 1.4509
[11/28 15:35:26 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.5840, average loss: 1.2769
[11/28 15:35:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.49	
[11/28 15:35:26 visual_prompt]: Training 12 / 100 epoch, with learning rate 2.4992385337738696
[11/28 15:43:13 visual_prompt]: Epoch 12 / 100: avg data time: 5.21e+00, avg batch time: 6.6659, average train loss: 1.3602
[11/28 15:44:06 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.5866, average loss: 0.8997
[11/28 15:44:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.84	
[11/28 15:44:06 visual_prompt]: Best epoch 12: best metric: -0.900
[11/28 15:44:06 visual_prompt]: Training 13 / 100 epoch, with learning rate 2.4969550628247803
[11/28 15:51:52 visual_prompt]: Epoch 13 / 100: avg data time: 5.20e+00, avg batch time: 6.6583, average train loss: 1.4793
[11/28 15:52:45 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.5893, average loss: 0.7527
[11/28 15:52:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.07	rocauc: 61.32	
[11/28 15:52:45 visual_prompt]: Best epoch 13: best metric: -0.753
[11/28 15:52:45 visual_prompt]: Training 14 / 100 epoch, with learning rate 2.4931523692103417
[11/28 16:00:30 visual_prompt]: Epoch 14 / 100: avg data time: 5.19e+00, avg batch time: 6.6449, average train loss: 1.3267
[11/28 16:01:23 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.5873, average loss: 0.7889
[11/28 16:01:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 64.60	
[11/28 16:01:23 visual_prompt]: Training 15 / 100 epoch, with learning rate 2.487835085926963
[11/28 16:09:07 visual_prompt]: Epoch 15 / 100: avg data time: 5.17e+00, avg batch time: 6.6232, average train loss: 0.8805
[11/28 16:10:00 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.5875, average loss: 1.0179
[11/28 16:10:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 64.91	
[11/28 16:10:00 visual_prompt]: Training 16 / 100 epoch, with learning rate 2.4810096912652604
[11/28 16:17:48 visual_prompt]: Epoch 16 / 100: avg data time: 5.22e+00, avg batch time: 6.6791, average train loss: 1.0770
[11/28 16:18:41 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.5870, average loss: 0.7695
[11/28 16:18:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.93	rocauc: 60.53	
[11/28 16:18:41 visual_prompt]: Training 17 / 100 epoch, with learning rate 2.472684500917257
[11/28 16:26:28 visual_prompt]: Epoch 17 / 100: avg data time: 5.22e+00, avg batch time: 6.6741, average train loss: 1.0693
[11/28 16:27:21 visual_prompt]: Inference (val):avg data time: 3.56e-05, avg batch time: 0.5854, average loss: 1.1426
[11/28 16:27:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 63.77	
[11/28 16:27:21 visual_prompt]: Training 18 / 100 epoch, with learning rate 2.4628696578449953
[11/28 16:35:07 visual_prompt]: Epoch 18 / 100: avg data time: 5.19e+00, avg batch time: 6.6471, average train loss: 1.7269
[11/28 16:36:00 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.5881, average loss: 3.1994
[11/28 16:36:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.98	
[11/28 16:36:00 visual_prompt]: Training 19 / 100 epoch, with learning rate 2.4515771199228986
[11/28 16:43:45 visual_prompt]: Epoch 19 / 100: avg data time: 5.19e+00, avg batch time: 6.6437, average train loss: 0.9595
[11/28 16:44:38 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.5865, average loss: 1.2690
[11/28 16:44:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.07	rocauc: 66.41	
[11/28 16:44:38 visual_prompt]: Training 20 / 100 epoch, with learning rate 2.438820645368942
[11/28 16:52:27 visual_prompt]: Epoch 20 / 100: avg data time: 5.24e+00, avg batch time: 6.6860, average train loss: 0.9201
[11/28 16:53:20 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.5863, average loss: 1.3413
[11/28 16:53:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 67.75	
[11/28 16:53:20 visual_prompt]: Training 21 / 100 epoch, with learning rate 2.4246157759823856
[11/28 17:01:06 visual_prompt]: Epoch 21 / 100: avg data time: 5.20e+00, avg batch time: 6.6575, average train loss: 0.9774
[11/28 17:01:59 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.5871, average loss: 1.1516
[11/28 17:01:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 66.61	
[11/28 17:01:59 visual_prompt]: Training 22 / 100 epoch, with learning rate 2.4089798182084845
[11/28 17:09:45 visual_prompt]: Epoch 22 / 100: avg data time: 5.20e+00, avg batch time: 6.6561, average train loss: 1.1508
[11/28 17:10:38 visual_prompt]: Inference (val):avg data time: 3.45e-05, avg batch time: 0.5892, average loss: 0.9339
[11/28 17:10:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 67.30	
[11/28 17:10:38 visual_prompt]: Training 23 / 100 epoch, with learning rate 2.391931822053251
[11/28 17:18:28 visual_prompt]: Epoch 23 / 100: avg data time: 5.26e+00, avg batch time: 6.7143, average train loss: 0.9111
[11/28 17:19:21 visual_prompt]: Inference (val):avg data time: 3.84e-05, avg batch time: 0.5931, average loss: 1.0304
[11/28 17:19:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 67.42	
[11/28 17:19:21 visual_prompt]: Training 24 / 100 epoch, with learning rate 2.3734925578739587
[11/28 17:27:06 visual_prompt]: Epoch 24 / 100: avg data time: 5.18e+00, avg batch time: 6.6343, average train loss: 0.8268
[11/28 17:27:59 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.5875, average loss: 1.1132
[11/28 17:27:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 47.97	rocauc: 68.37	
[11/28 17:27:59 visual_prompt]: Training 25 / 100 epoch, with learning rate 2.3536844910736585
[11/28 17:35:43 visual_prompt]: Epoch 25 / 100: avg data time: 5.17e+00, avg batch time: 6.6235, average train loss: 1.0879
[11/28 17:36:36 visual_prompt]: Inference (val):avg data time: 3.53e-05, avg batch time: 0.5862, average loss: 1.8979
[11/28 17:36:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 66.44	
[11/28 17:36:36 visual_prompt]: Training 26 / 100 epoch, with learning rate 2.3325317547305486
[11/28 17:44:19 visual_prompt]: Epoch 26 / 100: avg data time: 5.17e+00, avg batch time: 6.6202, average train loss: 1.1431
[11/28 17:45:12 visual_prompt]: Inference (val):avg data time: 3.43e-05, avg batch time: 0.5885, average loss: 0.7541
[11/28 17:45:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.54	rocauc: 67.81	
[11/28 17:45:12 visual_prompt]: Training 27 / 100 epoch, with learning rate 2.310060120195532
[11/28 17:52:56 visual_prompt]: Epoch 27 / 100: avg data time: 5.16e+00, avg batch time: 6.6184, average train loss: 0.9422
[11/28 17:53:49 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.5932, average loss: 0.8976
[11/28 17:53:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 69.41	
[11/28 17:53:49 visual_prompt]: Training 28 / 100 epoch, with learning rate 2.286296965693802
[11/28 18:01:33 visual_prompt]: Epoch 28 / 100: avg data time: 5.17e+00, avg batch time: 6.6216, average train loss: 0.7822
[11/28 18:02:26 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.5915, average loss: 0.6698
[11/28 18:02:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 70.73	
[11/28 18:02:26 visual_prompt]: Best epoch 28: best metric: -0.670
[11/28 18:02:26 visual_prompt]: Training 29 / 100 epoch, with learning rate 2.261271242968684
[11/28 18:10:12 visual_prompt]: Epoch 29 / 100: avg data time: 5.20e+00, avg batch time: 6.6560, average train loss: 0.6927
[11/28 18:11:05 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.5860, average loss: 1.4558
[11/28 18:11:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 71.04	
[11/28 18:11:05 visual_prompt]: Training 30 / 100 epoch, with learning rate 2.2350134420084022
[11/28 18:18:50 visual_prompt]: Epoch 30 / 100: avg data time: 5.19e+00, avg batch time: 6.6420, average train loss: 0.7463
[11/28 18:19:43 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.5841, average loss: 1.2907
[11/28 18:19:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 69.85	
[11/28 18:19:43 visual_prompt]: Training 31 / 100 epoch, with learning rate 2.2075555538987226
[11/28 18:27:27 visual_prompt]: Epoch 31 / 100: avg data time: 5.18e+00, avg batch time: 6.6295, average train loss: 0.7680
[11/28 18:28:21 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.5923, average loss: 0.6404
[11/28 18:28:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.01	rocauc: 69.08	
[11/28 18:28:21 visual_prompt]: Best epoch 31: best metric: -0.640
[11/28 18:28:21 visual_prompt]: Training 32 / 100 epoch, with learning rate 2.178931031846743
[11/28 18:36:05 visual_prompt]: Epoch 32 / 100: avg data time: 5.18e+00, avg batch time: 6.6328, average train loss: 0.9898
[11/28 18:36:58 visual_prompt]: Inference (val):avg data time: 3.43e-05, avg batch time: 0.5876, average loss: 1.7695
[11/28 18:36:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 72.22	
[11/28 18:36:58 visual_prompt]: Training 33 / 100 epoch, with learning rate 2.149174750423314
[11/28 18:44:43 visual_prompt]: Epoch 33 / 100: avg data time: 5.18e+00, avg batch time: 6.6321, average train loss: 0.7486
[11/28 18:45:36 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.5847, average loss: 0.7089
[11/28 18:45:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 68.69	
[11/28 18:45:36 visual_prompt]: Training 34 / 100 epoch, with learning rate 2.1183229630737466
[11/28 18:53:20 visual_prompt]: Epoch 34 / 100: avg data time: 5.17e+00, avg batch time: 6.6231, average train loss: 0.9704
[11/28 18:54:13 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.5889, average loss: 1.0658
[11/28 18:54:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 69.97	
[11/28 18:54:13 visual_prompt]: Training 35 / 100 epoch, with learning rate 2.086413257948573
[11/28 19:01:57 visual_prompt]: Epoch 35 / 100: avg data time: 5.17e+00, avg batch time: 6.6244, average train loss: 0.7812
[11/28 19:02:50 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.5849, average loss: 0.6667
[11/28 19:02:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 69.03	
[11/28 19:02:50 visual_prompt]: Training 36 / 100 epoch, with learning rate 2.053484512108174
[11/28 19:10:35 visual_prompt]: Epoch 36 / 100: avg data time: 5.19e+00, avg batch time: 6.6420, average train loss: 0.6820
[11/28 19:11:28 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.5886, average loss: 1.3235
[11/28 19:11:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 47.56	rocauc: 70.90	
[11/28 19:11:28 visual_prompt]: Training 37 / 100 epoch, with learning rate 2.019576844157073
[11/28 19:19:13 visual_prompt]: Epoch 37 / 100: avg data time: 5.18e+00, avg batch time: 6.6360, average train loss: 0.7202
[11/28 19:20:06 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.5862, average loss: 0.7041
[11/28 19:20:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 70.96	
[11/28 19:20:06 visual_prompt]: Training 38 / 100 epoch, with learning rate 1.9847315653655915
[11/28 19:27:50 visual_prompt]: Epoch 38 / 100: avg data time: 5.18e+00, avg batch time: 6.6331, average train loss: 0.8081
[11/28 19:28:44 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.5890, average loss: 1.4343
[11/28 19:28:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.93	rocauc: 68.50	
[11/28 19:28:44 visual_prompt]: Training 39 / 100 epoch, with learning rate 1.9489911293384334
[11/28 19:36:28 visual_prompt]: Epoch 39 / 100: avg data time: 5.18e+00, avg batch time: 6.6364, average train loss: 0.7012
[11/28 19:37:22 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.5891, average loss: 1.5978
[11/28 19:37:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 49.19	rocauc: 69.80	
[11/28 19:37:22 visual_prompt]: Training 40 / 100 epoch, with learning rate 1.912399080291506
[11/28 19:45:06 visual_prompt]: Epoch 40 / 100: avg data time: 5.17e+00, avg batch time: 6.6247, average train loss: 0.7909
[11/28 19:46:00 visual_prompt]: Inference (val):avg data time: 3.46e-05, avg batch time: 0.5849, average loss: 0.7338
[11/28 19:46:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 67.81	
[11/28 19:46:00 visual_prompt]: Training 41 / 100 epoch, with learning rate 1.875
[11/28 19:53:43 visual_prompt]: Epoch 41 / 100: avg data time: 5.16e+00, avg batch time: 6.6175, average train loss: 0.6203
[11/28 19:54:36 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.5861, average loss: 0.8296
[11/28 19:54:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 67.49	
[11/28 19:54:36 visual_prompt]: Training 42 / 100 epoch, with learning rate 1.8368394534823635
[11/28 20:02:21 visual_prompt]: Epoch 42 / 100: avg data time: 5.18e+00, avg batch time: 6.6361, average train loss: 0.6744
[11/28 20:03:14 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.5907, average loss: 0.9493
[11/28 20:03:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 66.21	
[11/28 20:03:14 visual_prompt]: Training 43 / 100 epoch, with learning rate 1.7979639334863466
[11/28 20:11:02 visual_prompt]: Epoch 43 / 100: avg data time: 5.24e+00, avg batch time: 6.6929, average train loss: 0.5742
[11/28 20:11:56 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.5877, average loss: 1.5190
[11/28 20:11:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 70.08	
[11/28 20:11:56 visual_prompt]: Training 44 / 100 epoch, with learning rate 1.7584208038447504
[11/28 20:19:40 visual_prompt]: Epoch 44 / 100: avg data time: 5.18e+00, avg batch time: 6.6375, average train loss: 0.8255
[11/28 20:20:34 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.5846, average loss: 1.5172
[11/28 20:20:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.93	rocauc: 67.94	
[11/28 20:20:34 visual_prompt]: Training 45 / 100 epoch, with learning rate 1.7182582417698902
[11/28 20:28:20 visual_prompt]: Epoch 45 / 100: avg data time: 5.21e+00, avg batch time: 6.6637, average train loss: 0.7213
[11/28 20:29:14 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.5850, average loss: 0.7054
[11/28 20:29:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 68.92	
[11/28 20:29:14 visual_prompt]: Training 46 / 100 epoch, with learning rate 1.6775251791570862
[11/28 20:36:59 visual_prompt]: Epoch 46 / 100: avg data time: 5.20e+00, avg batch time: 6.6500, average train loss: 0.5498
[11/28 20:37:53 visual_prompt]: Inference (val):avg data time: 3.23e-05, avg batch time: 0.5877, average loss: 1.0872
[11/28 20:37:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 69.93	
[11/28 20:37:53 visual_prompt]: Training 47 / 100 epoch, with learning rate 1.6362712429686843
[11/28 20:45:40 visual_prompt]: Epoch 47 / 100: avg data time: 5.20e+00, avg batch time: 6.6578, average train loss: 0.7519
[11/28 20:46:33 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.5877, average loss: 0.7525
[11/28 20:46:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 69.94	
[11/28 20:46:33 visual_prompt]: Training 48 / 100 epoch, with learning rate 1.5945466947712488
[11/28 20:54:19 visual_prompt]: Epoch 48 / 100: avg data time: 5.21e+00, avg batch time: 6.6594, average train loss: 0.5363
[11/28 20:55:13 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.5854, average loss: 0.9303
[11/28 20:55:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 68.16	
[11/28 20:55:13 visual_prompt]: Training 49 / 100 epoch, with learning rate 1.5524023694995845
[11/28 21:03:00 visual_prompt]: Epoch 49 / 100: avg data time: 5.21e+00, avg batch time: 6.6689, average train loss: 0.6011
[11/28 21:03:54 visual_prompt]: Inference (val):avg data time: 3.80e-05, avg batch time: 0.5874, average loss: 0.9101
[11/28 21:03:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 68.63	
[11/28 21:03:54 visual_prompt]: Training 50 / 100 epoch, with learning rate 1.509889613522199
[11/28 21:11:38 visual_prompt]: Epoch 50 / 100: avg data time: 5.17e+00, avg batch time: 6.6249, average train loss: 0.6731
[11/28 21:12:31 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.5852, average loss: 1.1816
[11/28 21:12:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 66.92	
[11/28 21:12:31 visual_prompt]: Training 51 / 100 epoch, with learning rate 1.467060222083663
[11/28 21:20:18 visual_prompt]: Epoch 51 / 100: avg data time: 5.21e+00, avg batch time: 6.6709, average train loss: 0.4877
[11/28 21:21:12 visual_prompt]: Inference (val):avg data time: 1.16e-04, avg batch time: 0.5951, average loss: 0.8983
[11/28 21:21:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 64.95	
[11/28 21:21:12 visual_prompt]: Training 52 / 100 epoch, with learning rate 1.4239663762000818
[11/28 21:29:00 visual_prompt]: Epoch 52 / 100: avg data time: 5.23e+00, avg batch time: 6.6839, average train loss: 0.4420
[11/28 21:29:53 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.5897, average loss: 0.8331
[11/28 21:29:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 66.45	
[11/28 21:29:53 visual_prompt]: Stopping early.
[11/28 21:29:53 visual_prompt]: Rank of current process: 0. World size: 1
[11/28 21:29:53 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/28 21:29:53 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/28 21:29:53 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/28 21:29:53 visual_prompt]: Training with config:
[11/28 21:29:53 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr1.0_wd0.01/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 1.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/28 21:29:53 visual_prompt]: Loading training data...
[11/28 21:29:53 visual_prompt]: Constructing mammo-cbis dataset train...
[11/28 21:29:53 visual_prompt]: Loading validation data...
[11/28 21:29:53 visual_prompt]: Constructing mammo-cbis dataset val...
[11/28 21:29:53 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/28 21:29:56 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/28 21:29:56 visual_prompt]: tuned percent:0.532
[11/28 21:29:56 visual_prompt]: Device used for model: 0
[11/28 21:29:56 visual_prompt]: Setting up Evaluator...
[11/28 21:29:56 visual_prompt]: Setting up Trainer...
[11/28 21:29:56 visual_prompt]: 	Setting up the optimizer...
[11/28 21:29:56 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/28 21:37:44 visual_prompt]: Epoch 1 / 100: avg data time: 5.23e+00, avg batch time: 6.6848, average train loss: 1.4863
[11/28 21:38:38 visual_prompt]: Inference (val):avg data time: 3.72e-05, avg batch time: 0.5860, average loss: 1.4553
[11/28 21:38:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/28 21:38:38 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.1
[11/28 21:46:25 visual_prompt]: Epoch 2 / 100: avg data time: 5.22e+00, avg batch time: 6.6767, average train loss: 1.1795
[11/28 21:47:18 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.5848, average loss: 0.6956
[11/28 21:47:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.36	
[11/28 21:47:18 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.2
[11/28 21:55:06 visual_prompt]: Epoch 3 / 100: avg data time: 5.22e+00, avg batch time: 6.6776, average train loss: 0.7272
[11/28 21:55:59 visual_prompt]: Inference (val):avg data time: 3.52e-05, avg batch time: 0.5840, average loss: 0.7472
[11/28 21:55:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.75	
[11/28 21:55:59 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.3
[11/28 22:03:46 visual_prompt]: Epoch 4 / 100: avg data time: 5.22e+00, avg batch time: 6.6722, average train loss: 0.7497
[11/28 22:04:39 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.5878, average loss: 0.7911
[11/28 22:04:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.81	
[11/28 22:04:39 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.4
[11/28 22:12:23 visual_prompt]: Epoch 5 / 100: avg data time: 5.18e+00, avg batch time: 6.6290, average train loss: 0.7555
[11/28 22:13:16 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.5854, average loss: 1.1662
[11/28 22:13:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.83	
[11/28 22:13:16 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.5
[11/28 22:21:13 visual_prompt]: Epoch 6 / 100: avg data time: 5.36e+00, avg batch time: 6.8116, average train loss: 0.7732
[11/28 22:22:06 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.5877, average loss: 0.7100
[11/28 22:22:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 41.75	
[11/28 22:22:06 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.6
[11/28 22:29:53 visual_prompt]: Epoch 7 / 100: avg data time: 5.21e+00, avg batch time: 6.6653, average train loss: 0.7512
[11/28 22:30:46 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.5850, average loss: 0.8093
[11/28 22:30:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.93	
[11/28 22:30:46 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.7
[11/28 22:38:33 visual_prompt]: Epoch 8 / 100: avg data time: 5.22e+00, avg batch time: 6.6721, average train loss: 0.9242
[11/28 22:39:26 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.5855, average loss: 2.3953
[11/28 22:39:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.52	
[11/28 22:39:26 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.8
[11/28 22:47:12 visual_prompt]: Epoch 9 / 100: avg data time: 5.20e+00, avg batch time: 6.6585, average train loss: 0.9086
[11/28 22:48:05 visual_prompt]: Inference (val):avg data time: 3.61e-05, avg batch time: 0.5897, average loss: 0.9776
[11/28 22:48:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.14	
[11/28 22:48:05 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.9
[11/28 22:55:51 visual_prompt]: Epoch 10 / 100: avg data time: 5.20e+00, avg batch time: 6.6573, average train loss: 0.9466
[11/28 22:56:45 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.5862, average loss: 0.9460
[11/28 22:56:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.76	
[11/28 22:56:45 visual_prompt]: Training 11 / 100 epoch, with learning rate 1.0
[11/28 23:04:32 visual_prompt]: Epoch 11 / 100: avg data time: 5.23e+00, avg batch time: 6.6784, average train loss: 1.2816
[11/28 23:05:25 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.5901, average loss: 0.8141
[11/28 23:05:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.91	
[11/28 23:05:25 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.9996954135095479
[11/28 23:13:15 visual_prompt]: Epoch 12 / 100: avg data time: 5.26e+00, avg batch time: 6.7139, average train loss: 1.0734
[11/28 23:14:08 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.5829, average loss: 0.7131
[11/28 23:14:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.28	
[11/28 23:14:08 visual_prompt]: Best epoch 12: best metric: -0.713
[11/28 23:14:08 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.9987820251299121
[11/28 23:21:55 visual_prompt]: Epoch 13 / 100: avg data time: 5.21e+00, avg batch time: 6.6598, average train loss: 0.9674
[11/28 23:22:48 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.5865, average loss: 0.8383
[11/28 23:22:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.55	
[11/28 23:22:48 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.9972609476841366
[11/28 23:30:35 visual_prompt]: Epoch 14 / 100: avg data time: 5.22e+00, avg batch time: 6.6700, average train loss: 1.3544
[11/28 23:31:28 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.5904, average loss: 1.4522
[11/28 23:31:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.14	
[11/28 23:31:28 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.9951340343707852
[11/28 23:39:12 visual_prompt]: Epoch 15 / 100: avg data time: 5.18e+00, avg batch time: 6.6337, average train loss: 0.9761
[11/28 23:40:06 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.5896, average loss: 0.8391
[11/28 23:40:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.29	
[11/28 23:40:06 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.9924038765061041
[11/28 23:47:49 visual_prompt]: Epoch 16 / 100: avg data time: 5.17e+00, avg batch time: 6.6179, average train loss: 0.8855
[11/28 23:48:42 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.5855, average loss: 1.1889
[11/28 23:48:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.95	
[11/28 23:48:42 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.9890738003669028
[11/28 23:56:26 visual_prompt]: Epoch 17 / 100: avg data time: 5.18e+00, avg batch time: 6.6330, average train loss: 0.8701
[11/28 23:57:19 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.5902, average loss: 0.7937
[11/28 23:57:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.73	
[11/28 23:57:19 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.9851478631379982
[11/29 00:05:04 visual_prompt]: Epoch 18 / 100: avg data time: 5.18e+00, avg batch time: 6.6346, average train loss: 1.2564
[11/29 00:05:57 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.5928, average loss: 0.8474
[11/29 00:05:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.37	
[11/29 00:05:57 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.9806308479691594
[11/29 00:13:43 visual_prompt]: Epoch 19 / 100: avg data time: 5.20e+00, avg batch time: 6.6613, average train loss: 1.0420
[11/29 00:14:37 visual_prompt]: Inference (val):avg data time: 3.72e-05, avg batch time: 0.5878, average loss: 2.1713
[11/29 00:14:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.38	
[11/29 00:14:37 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.9755282581475768
[11/29 00:22:21 visual_prompt]: Epoch 20 / 100: avg data time: 5.17e+00, avg batch time: 6.6248, average train loss: 1.6317
[11/29 00:23:14 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.5900, average loss: 2.0296
[11/29 00:23:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 40.89	
[11/29 00:23:14 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.9698463103929542
[11/29 00:30:57 visual_prompt]: Epoch 21 / 100: avg data time: 5.17e+00, avg batch time: 6.6216, average train loss: 1.4047
[11/29 00:31:50 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.5888, average loss: 2.0380
[11/29 00:31:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.06	
[11/29 00:31:50 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.9635919272833937
[11/29 00:39:36 visual_prompt]: Epoch 22 / 100: avg data time: 5.20e+00, avg batch time: 6.6493, average train loss: 1.1997
[11/29 00:40:29 visual_prompt]: Inference (val):avg data time: 3.72e-05, avg batch time: 0.5909, average loss: 1.0199
[11/29 00:40:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.06	
[11/29 00:40:29 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.9567727288213004
[11/29 00:48:18 visual_prompt]: Epoch 23 / 100: avg data time: 5.24e+00, avg batch time: 6.6942, average train loss: 1.6932
[11/29 00:49:11 visual_prompt]: Inference (val):avg data time: 3.46e-05, avg batch time: 0.5894, average loss: 5.9419
[11/29 00:49:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.57	
[11/29 00:49:11 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.9493970231495835
[11/29 00:56:56 visual_prompt]: Epoch 24 / 100: avg data time: 5.18e+00, avg batch time: 6.6343, average train loss: 1.3954
[11/29 00:57:49 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.5824, average loss: 1.0848
[11/29 00:57:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.81	
[11/29 00:57:49 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.9414737964294635
[11/29 01:05:36 visual_prompt]: Epoch 25 / 100: avg data time: 5.22e+00, avg batch time: 6.6725, average train loss: 1.4704
[11/29 01:06:29 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.5881, average loss: 2.5826
[11/29 01:06:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.97	
[11/29 01:06:29 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.9330127018922194
[11/29 01:14:13 visual_prompt]: Epoch 26 / 100: avg data time: 5.17e+00, avg batch time: 6.6237, average train loss: 1.3950
[11/29 01:15:06 visual_prompt]: Inference (val):avg data time: 3.67e-05, avg batch time: 0.5880, average loss: 0.7533
[11/29 01:15:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.11	
[11/29 01:15:06 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.9240240480782129
[11/29 01:22:48 visual_prompt]: Epoch 27 / 100: avg data time: 5.15e+00, avg batch time: 6.6029, average train loss: 1.0333
[11/29 01:23:42 visual_prompt]: Inference (val):avg data time: 3.82e-05, avg batch time: 0.5884, average loss: 1.6533
[11/29 01:23:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.78	
[11/29 01:23:42 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.9145187862775208
[11/29 01:31:26 visual_prompt]: Epoch 28 / 100: avg data time: 5.19e+00, avg batch time: 6.6384, average train loss: 0.9090
[11/29 01:32:20 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.5901, average loss: 1.8687
[11/29 01:32:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.45	
[11/29 01:32:20 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.9045084971874737
[11/29 01:40:05 visual_prompt]: Epoch 29 / 100: avg data time: 5.19e+00, avg batch time: 6.6407, average train loss: 0.8678
[11/29 01:40:58 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.5845, average loss: 1.9958
[11/29 01:40:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.45	
[11/29 01:40:58 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.8940053768033609
[11/29 01:48:43 visual_prompt]: Epoch 30 / 100: avg data time: 5.19e+00, avg batch time: 6.6421, average train loss: 0.9249
[11/29 01:49:36 visual_prompt]: Inference (val):avg data time: 3.26e-05, avg batch time: 0.5861, average loss: 1.8353
[11/29 01:49:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 44.72	rocauc: 50.62	
[11/29 01:49:36 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.883022221559489
[11/29 01:57:19 visual_prompt]: Epoch 31 / 100: avg data time: 5.16e+00, avg batch time: 6.6103, average train loss: 0.8129
[11/29 01:58:12 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.5856, average loss: 0.7329
[11/29 01:58:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.03	
[11/29 01:58:12 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.8715724127386971
[11/29 02:05:57 visual_prompt]: Epoch 32 / 100: avg data time: 5.19e+00, avg batch time: 6.6407, average train loss: 0.9406
[11/29 02:06:50 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.5865, average loss: 2.3936
[11/29 02:06:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.07	
[11/29 02:06:50 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.8596699001693255
[11/29 02:14:39 visual_prompt]: Epoch 33 / 100: avg data time: 5.24e+00, avg batch time: 6.6923, average train loss: 1.1061
[11/29 02:15:32 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.5906, average loss: 0.7082
[11/29 02:15:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.29	
[11/29 02:15:32 visual_prompt]: Best epoch 33: best metric: -0.708
[11/29 02:15:32 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.8473291852294986
[11/29 02:23:17 visual_prompt]: Epoch 34 / 100: avg data time: 5.19e+00, avg batch time: 6.6442, average train loss: 0.8812
[11/29 02:24:11 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.5853, average loss: 1.3829
[11/29 02:24:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.45	
[11/29 02:24:11 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.8345653031794291
[11/29 02:31:54 visual_prompt]: Epoch 35 / 100: avg data time: 5.16e+00, avg batch time: 6.6108, average train loss: 0.8502
[11/29 02:32:47 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.5819, average loss: 0.7145
[11/29 02:32:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.13	
[11/29 02:32:47 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.8213938048432696
[11/29 02:40:33 visual_prompt]: Epoch 36 / 100: avg data time: 5.20e+00, avg batch time: 6.6552, average train loss: 1.0954
[11/29 02:41:26 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.5878, average loss: 1.6097
[11/29 02:41:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.70	
[11/29 02:41:26 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.8078307376628291
[11/29 02:49:12 visual_prompt]: Epoch 37 / 100: avg data time: 5.20e+00, avg batch time: 6.6548, average train loss: 1.1937
[11/29 02:50:05 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.5854, average loss: 1.0441
[11/29 02:50:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 45.13	
[11/29 02:50:05 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.7938926261462366
[11/29 02:57:48 visual_prompt]: Epoch 38 / 100: avg data time: 5.17e+00, avg batch time: 6.6183, average train loss: 0.8430
[11/29 02:58:41 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.5876, average loss: 1.2344
[11/29 02:58:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.61	
[11/29 02:58:41 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.7795964517353734
[11/29 03:06:28 visual_prompt]: Epoch 39 / 100: avg data time: 5.21e+00, avg batch time: 6.6624, average train loss: 0.8832
[11/29 03:07:21 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.5880, average loss: 1.1738
[11/29 03:07:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 43.59	
[11/29 03:07:21 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.7649596321166025
[11/29 03:15:07 visual_prompt]: Epoch 40 / 100: avg data time: 5.20e+00, avg batch time: 6.6560, average train loss: 0.9293
[11/29 03:16:00 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.5863, average loss: 1.2067
[11/29 03:16:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.77	
[11/29 03:16:00 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.75
[11/29 03:23:43 visual_prompt]: Epoch 41 / 100: avg data time: 5.17e+00, avg batch time: 6.6164, average train loss: 1.1113
[11/29 03:24:36 visual_prompt]: Inference (val):avg data time: 3.51e-05, avg batch time: 0.5883, average loss: 0.8516
[11/29 03:24:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 43.90	rocauc: 38.67	
[11/29 03:24:36 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.7347357813929454
[11/29 03:32:21 visual_prompt]: Epoch 42 / 100: avg data time: 5.19e+00, avg batch time: 6.6474, average train loss: 1.0737
[11/29 03:33:14 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.5867, average loss: 0.7843
[11/29 03:33:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.87	
[11/29 03:33:14 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.7191855733945387
[11/29 03:41:03 visual_prompt]: Epoch 43 / 100: avg data time: 5.24e+00, avg batch time: 6.6885, average train loss: 0.8327
[11/29 03:41:56 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.5848, average loss: 1.4727
[11/29 03:41:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.17	
[11/29 03:41:56 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.7033683215379002
[11/29 03:49:42 visual_prompt]: Epoch 44 / 100: avg data time: 5.21e+00, avg batch time: 6.6556, average train loss: 0.9403
[11/29 03:50:34 visual_prompt]: Inference (val):avg data time: 3.43e-05, avg batch time: 0.5876, average loss: 0.7704
[11/29 03:50:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.91	
[11/29 03:50:34 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.6873032967079561
[11/29 03:58:20 visual_prompt]: Epoch 45 / 100: avg data time: 5.20e+00, avg batch time: 6.6550, average train loss: 0.8175
[11/29 03:59:13 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.5860, average loss: 0.8904
[11/29 03:59:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.52	
[11/29 03:59:13 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.6710100716628344
[11/29 04:06:55 visual_prompt]: Epoch 46 / 100: avg data time: 5.14e+00, avg batch time: 6.5983, average train loss: 0.9063
[11/29 04:07:48 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.5872, average loss: 2.5436
[11/29 04:07:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.72	
[11/29 04:07:48 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.6545084971874737
[11/29 04:15:33 visual_prompt]: Epoch 47 / 100: avg data time: 5.18e+00, avg batch time: 6.6379, average train loss: 1.1152
[11/29 04:16:26 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.5900, average loss: 0.7436
[11/29 04:16:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 62.38	
[11/29 04:16:26 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.6378186779084996
[11/29 04:24:11 visual_prompt]: Epoch 48 / 100: avg data time: 5.19e+00, avg batch time: 6.6382, average train loss: 0.9349
[11/29 04:25:04 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.5849, average loss: 4.4291
[11/29 04:25:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 45.62	
[11/29 04:25:04 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.6209609477998338
[11/29 04:32:47 visual_prompt]: Epoch 49 / 100: avg data time: 5.17e+00, avg batch time: 6.6210, average train loss: 1.6249
[11/29 04:33:40 visual_prompt]: Inference (val):avg data time: 3.44e-05, avg batch time: 0.5838, average loss: 2.2219
[11/29 04:33:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.61	
[11/29 04:33:40 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.6039558454088796
[11/29 04:41:24 visual_prompt]: Epoch 50 / 100: avg data time: 5.17e+00, avg batch time: 6.6242, average train loss: 1.0277
[11/29 04:42:17 visual_prompt]: Inference (val):avg data time: 3.26e-05, avg batch time: 0.5897, average loss: 1.0336
[11/29 04:42:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.43	
[11/29 04:42:17 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.5868240888334653
[11/29 04:50:01 visual_prompt]: Epoch 51 / 100: avg data time: 5.16e+00, avg batch time: 6.6144, average train loss: 0.7908
[11/29 04:50:54 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.5865, average loss: 0.8196
[11/29 04:50:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.21	
[11/29 04:50:54 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.5695865504800327
[11/29 04:58:40 visual_prompt]: Epoch 52 / 100: avg data time: 5.20e+00, avg batch time: 6.6546, average train loss: 0.8696
[11/29 04:59:33 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.5857, average loss: 0.8693
[11/29 04:59:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.30	
[11/29 04:59:33 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.5522642316338268
[11/29 05:07:21 visual_prompt]: Epoch 53 / 100: avg data time: 5.23e+00, avg batch time: 6.6851, average train loss: 0.8747
[11/29 05:08:15 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.5919, average loss: 1.3084
[11/29 05:08:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 61.56	
[11/29 05:08:15 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.5348782368720626
[11/29 05:15:59 visual_prompt]: Epoch 54 / 100: avg data time: 5.18e+00, avg batch time: 6.6298, average train loss: 0.8416
[11/29 05:16:52 visual_prompt]: Inference (val):avg data time: 3.53e-05, avg batch time: 0.5844, average loss: 1.8799
[11/29 05:16:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.29	
[11/29 05:16:52 visual_prompt]: Stopping early.
[11/29 05:16:52 visual_prompt]: Rank of current process: 0. World size: 1
[11/29 05:16:52 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/29 05:16:52 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/29 05:16:52 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/29 05:16:52 visual_prompt]: Training with config:
[11/29 05:16:52 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr1.0_wd0.001/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 1.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/29 05:16:52 visual_prompt]: Loading training data...
[11/29 05:16:52 visual_prompt]: Constructing mammo-cbis dataset train...
[11/29 05:16:52 visual_prompt]: Loading validation data...
[11/29 05:16:52 visual_prompt]: Constructing mammo-cbis dataset val...
[11/29 05:16:52 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/29 05:16:55 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/29 05:16:55 visual_prompt]: tuned percent:0.532
[11/29 05:16:55 visual_prompt]: Device used for model: 0
[11/29 05:16:55 visual_prompt]: Setting up Evaluator...
[11/29 05:16:55 visual_prompt]: Setting up Trainer...
[11/29 05:16:55 visual_prompt]: 	Setting up the optimizer...
[11/29 05:16:55 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/29 05:24:43 visual_prompt]: Epoch 1 / 100: avg data time: 5.23e+00, avg batch time: 6.6836, average train loss: 1.4863
[11/29 05:25:37 visual_prompt]: Inference (val):avg data time: 9.23e-05, avg batch time: 0.6128, average loss: 1.4553
[11/29 05:25:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/29 05:25:37 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.1
[11/29 05:33:20 visual_prompt]: Epoch 2 / 100: avg data time: 5.16e+00, avg batch time: 6.6174, average train loss: 1.1983
[11/29 05:34:13 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.5890, average loss: 0.6985
[11/29 05:34:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.37	
[11/29 05:34:13 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.2
[11/29 05:41:56 visual_prompt]: Epoch 3 / 100: avg data time: 5.16e+00, avg batch time: 6.6131, average train loss: 0.7529
[11/29 05:42:49 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.5876, average loss: 0.7602
[11/29 05:42:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.00	
[11/29 05:42:49 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.3
[11/29 05:50:32 visual_prompt]: Epoch 4 / 100: avg data time: 5.16e+00, avg batch time: 6.6112, average train loss: 0.8826
[11/29 05:51:25 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.5870, average loss: 0.8200
[11/29 05:51:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.32	
[11/29 05:51:25 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.4
[11/29 05:59:08 visual_prompt]: Epoch 5 / 100: avg data time: 5.15e+00, avg batch time: 6.6055, average train loss: 0.8840
[11/29 06:00:01 visual_prompt]: Inference (val):avg data time: 3.60e-05, avg batch time: 0.5877, average loss: 1.1470
[11/29 06:00:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.66	
[11/29 06:00:01 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.5
[11/29 06:07:45 visual_prompt]: Epoch 6 / 100: avg data time: 5.17e+00, avg batch time: 6.6235, average train loss: 0.8625
[11/29 06:08:38 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.5880, average loss: 0.6905
[11/29 06:08:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 52.85	rocauc: 62.09	
[11/29 06:08:38 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.6
[11/29 06:16:21 visual_prompt]: Epoch 7 / 100: avg data time: 5.16e+00, avg batch time: 6.6082, average train loss: 0.7278
[11/29 06:17:13 visual_prompt]: Inference (val):avg data time: 3.26e-05, avg batch time: 0.5862, average loss: 0.7797
[11/29 06:17:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.62	
[11/29 06:17:13 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.7
[11/29 06:24:56 visual_prompt]: Epoch 8 / 100: avg data time: 5.16e+00, avg batch time: 6.6085, average train loss: 0.8387
[11/29 06:25:49 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.5883, average loss: 1.8256
[11/29 06:25:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.18	
[11/29 06:25:49 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.8
[11/29 06:33:31 visual_prompt]: Epoch 9 / 100: avg data time: 5.15e+00, avg batch time: 6.6043, average train loss: 0.8937
[11/29 06:34:24 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.5863, average loss: 1.4170
[11/29 06:34:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.00	
[11/29 06:34:24 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.9
[11/29 06:42:08 visual_prompt]: Epoch 10 / 100: avg data time: 5.17e+00, avg batch time: 6.6221, average train loss: 0.8014
[11/29 06:43:01 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.5869, average loss: 0.7553
[11/29 06:43:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 62.26	
[11/29 06:43:01 visual_prompt]: Training 11 / 100 epoch, with learning rate 1.0
[11/29 06:50:45 visual_prompt]: Epoch 11 / 100: avg data time: 5.18e+00, avg batch time: 6.6332, average train loss: 0.7719
[11/29 06:51:38 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.5834, average loss: 1.0939
[11/29 06:51:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.55	
[11/29 06:51:38 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.9996954135095479
[11/29 06:59:23 visual_prompt]: Epoch 12 / 100: avg data time: 5.18e+00, avg batch time: 6.6364, average train loss: 1.2029
[11/29 07:00:16 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.5858, average loss: 0.6821
[11/29 07:00:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 59.40	
[11/29 07:00:16 visual_prompt]: Best epoch 12: best metric: -0.682
[11/29 07:00:16 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.9987820251299121
[11/29 07:08:01 visual_prompt]: Epoch 13 / 100: avg data time: 5.19e+00, avg batch time: 6.6426, average train loss: 0.9304
[11/29 07:08:53 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.5879, average loss: 0.6770
[11/29 07:08:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 61.99	
[11/29 07:08:53 visual_prompt]: Best epoch 13: best metric: -0.677
[11/29 07:08:53 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.9972609476841366
[11/29 07:16:39 visual_prompt]: Epoch 14 / 100: avg data time: 5.20e+00, avg batch time: 6.6537, average train loss: 1.0278
[11/29 07:17:32 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.5865, average loss: 0.7013
[11/29 07:17:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.30	
[11/29 07:17:32 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.9951340343707852
[11/29 07:25:15 visual_prompt]: Epoch 15 / 100: avg data time: 5.16e+00, avg batch time: 6.6123, average train loss: 0.7587
[11/29 07:26:08 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.5889, average loss: 1.3136
[11/29 07:26:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.77	
[11/29 07:26:08 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.9924038765061041
[11/29 07:33:53 visual_prompt]: Epoch 16 / 100: avg data time: 5.18e+00, avg batch time: 6.6353, average train loss: 0.9340
[11/29 07:34:45 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.5858, average loss: 0.8048
[11/29 07:34:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.97	
[11/29 07:34:45 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.9890738003669028
[11/29 07:42:29 visual_prompt]: Epoch 17 / 100: avg data time: 5.16e+00, avg batch time: 6.6231, average train loss: 0.8456
[11/29 07:43:22 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.5907, average loss: 1.1311
[11/29 07:43:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.70	
[11/29 07:43:22 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.9851478631379982
[11/29 07:51:01 visual_prompt]: Epoch 18 / 100: avg data time: 5.11e+00, avg batch time: 6.5613, average train loss: 1.0051
[11/29 07:51:53 visual_prompt]: Inference (val):avg data time: 3.47e-05, avg batch time: 0.5879, average loss: 1.1554
[11/29 07:51:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.01	
[11/29 07:51:53 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.9806308479691594
[11/29 07:59:33 visual_prompt]: Epoch 19 / 100: avg data time: 5.11e+00, avg batch time: 6.5648, average train loss: 0.8364
[11/29 08:00:26 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.5877, average loss: 0.6971
[11/29 08:00:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.09	
[11/29 08:00:26 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.9755282581475768
[11/29 08:08:08 visual_prompt]: Epoch 20 / 100: avg data time: 5.14e+00, avg batch time: 6.5963, average train loss: 0.7105
[11/29 08:09:00 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.5846, average loss: 0.6882
[11/29 08:09:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.63	
[11/29 08:09:00 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.9698463103929542
[11/29 08:16:41 visual_prompt]: Epoch 21 / 100: avg data time: 5.13e+00, avg batch time: 6.5798, average train loss: 0.7184
[11/29 08:17:34 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.5868, average loss: 0.9805
[11/29 08:17:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.33	
[11/29 08:17:34 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.9635919272833937
[11/29 08:25:14 visual_prompt]: Epoch 22 / 100: avg data time: 5.13e+00, avg batch time: 6.5785, average train loss: 0.7620
[11/29 08:26:07 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.5828, average loss: 0.8825
[11/29 08:26:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.87	
[11/29 08:26:07 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.9567727288213004
[11/29 08:33:49 visual_prompt]: Epoch 23 / 100: avg data time: 5.14e+00, avg batch time: 6.5925, average train loss: 0.7701
[11/29 08:34:41 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.5872, average loss: 1.0716
[11/29 08:34:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.25	
[11/29 08:34:41 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.9493970231495835
[11/29 08:42:21 visual_prompt]: Epoch 24 / 100: avg data time: 5.12e+00, avg batch time: 6.5686, average train loss: 0.8550
[11/29 08:43:14 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.5852, average loss: 0.7206
[11/29 08:43:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.65	
[11/29 08:43:14 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.9414737964294635
[11/29 08:50:56 visual_prompt]: Epoch 25 / 100: avg data time: 5.15e+00, avg batch time: 6.5951, average train loss: 1.0153
[11/29 08:51:48 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.5896, average loss: 1.9391
[11/29 08:51:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.55	
[11/29 08:51:48 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.9330127018922194
[11/29 08:59:28 visual_prompt]: Epoch 26 / 100: avg data time: 5.11e+00, avg batch time: 6.5691, average train loss: 1.0461
[11/29 09:00:21 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.5940, average loss: 0.7227
[11/29 09:00:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.77	
[11/29 09:00:21 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.9240240480782129
[11/29 09:08:00 visual_prompt]: Epoch 27 / 100: avg data time: 5.10e+00, avg batch time: 6.5543, average train loss: 0.8019
[11/29 09:08:53 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.5856, average loss: 0.8428
[11/29 09:08:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.40	
[11/29 09:08:53 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.9145187862775208
[11/29 09:16:34 visual_prompt]: Epoch 28 / 100: avg data time: 5.14e+00, avg batch time: 6.5944, average train loss: 0.7877
[11/29 09:17:27 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.5871, average loss: 1.0881
[11/29 09:17:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.28	
[11/29 09:17:27 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.9045084971874737
[11/29 09:25:10 visual_prompt]: Epoch 29 / 100: avg data time: 5.15e+00, avg batch time: 6.6020, average train loss: 0.7945
[11/29 09:26:03 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.5881, average loss: 1.7512
[11/29 09:26:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.43	
[11/29 09:26:03 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.8940053768033609
[11/29 09:33:45 visual_prompt]: Epoch 30 / 100: avg data time: 5.16e+00, avg batch time: 6.6115, average train loss: 0.8148
[11/29 09:34:38 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.5879, average loss: 0.8164
[11/29 09:34:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 61.02	
[11/29 09:34:38 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.883022221559489
[11/29 09:42:18 visual_prompt]: Epoch 31 / 100: avg data time: 5.12e+00, avg batch time: 6.5735, average train loss: 0.7907
[11/29 09:43:11 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.5864, average loss: 0.7302
[11/29 09:43:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.44	
[11/29 09:43:11 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.8715724127386971
[11/29 09:50:52 visual_prompt]: Epoch 32 / 100: avg data time: 5.14e+00, avg batch time: 6.5896, average train loss: 0.7645
[11/29 09:51:45 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.5844, average loss: 1.1444
[11/29 09:51:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.20	
[11/29 09:51:45 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.8596699001693255
[11/29 09:59:27 visual_prompt]: Epoch 33 / 100: avg data time: 5.14e+00, avg batch time: 6.5958, average train loss: 0.9022
[11/29 10:00:20 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.5835, average loss: 0.6880
[11/29 10:00:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.10	
[11/29 10:00:20 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.8473291852294986
[11/29 10:08:00 visual_prompt]: Epoch 34 / 100: avg data time: 5.12e+00, avg batch time: 6.5728, average train loss: 0.7945
[11/29 10:08:53 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.5849, average loss: 0.7226
[11/29 10:08:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.08	
[11/29 10:08:53 visual_prompt]: Stopping early.
[11/29 10:08:53 visual_prompt]: Rank of current process: 0. World size: 1
[11/29 10:08:53 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/29 10:08:53 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/29 10:08:53 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/29 10:08:53 visual_prompt]: Training with config:
[11/29 10:08:53 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr1.0_wd0.0001/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 1.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/29 10:08:53 visual_prompt]: Loading training data...
[11/29 10:08:53 visual_prompt]: Constructing mammo-cbis dataset train...
[11/29 10:08:53 visual_prompt]: Loading validation data...
[11/29 10:08:53 visual_prompt]: Constructing mammo-cbis dataset val...
[11/29 10:08:53 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/29 10:08:56 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/29 10:08:56 visual_prompt]: tuned percent:0.532
[11/29 10:08:56 visual_prompt]: Device used for model: 0
[11/29 10:08:56 visual_prompt]: Setting up Evaluator...
[11/29 10:08:56 visual_prompt]: Setting up Trainer...
[11/29 10:08:56 visual_prompt]: 	Setting up the optimizer...
[11/29 10:08:56 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/29 10:16:39 visual_prompt]: Epoch 1 / 100: avg data time: 5.16e+00, avg batch time: 6.6048, average train loss: 1.4863
[11/29 10:17:32 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.5890, average loss: 1.4553
[11/29 10:17:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/29 10:17:32 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.1
[11/29 10:25:14 visual_prompt]: Epoch 2 / 100: avg data time: 5.15e+00, avg batch time: 6.5991, average train loss: 1.2004
[11/29 10:26:06 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.5916, average loss: 0.6988
[11/29 10:26:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.23	
[11/29 10:26:06 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.2
[11/29 10:33:47 visual_prompt]: Epoch 3 / 100: avg data time: 5.13e+00, avg batch time: 6.5818, average train loss: 0.7590
[11/29 10:34:40 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.5855, average loss: 0.7680
[11/29 10:34:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.84	
[11/29 10:34:40 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.3
[11/29 10:42:20 visual_prompt]: Epoch 4 / 100: avg data time: 5.12e+00, avg batch time: 6.5692, average train loss: 0.8984
[11/29 10:43:13 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.5858, average loss: 0.8087
[11/29 10:43:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.67	
[11/29 10:43:13 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.4
[11/29 10:50:55 visual_prompt]: Epoch 5 / 100: avg data time: 5.16e+00, avg batch time: 6.6100, average train loss: 0.9182
[11/29 10:52:24 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.5832, average loss: 1.3584
[11/29 10:52:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.30	
[11/29 10:52:24 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.5
[11/29 11:00:18 visual_prompt]: Epoch 6 / 100: avg data time: 5.31e+00, avg batch time: 6.7640, average train loss: 0.8877
[11/29 11:01:11 visual_prompt]: Inference (val):avg data time: 3.26e-05, avg batch time: 0.5903, average loss: 0.8583
[11/29 11:01:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.88	
[11/29 11:01:11 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.6
[11/29 11:08:52 visual_prompt]: Epoch 7 / 100: avg data time: 5.13e+00, avg batch time: 6.5801, average train loss: 0.7590
[11/29 11:09:44 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.5883, average loss: 0.9747
[11/29 11:09:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.94	
[11/29 11:09:44 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.7
[11/29 11:17:27 visual_prompt]: Epoch 8 / 100: avg data time: 5.15e+00, avg batch time: 6.6036, average train loss: 0.7757
[11/29 11:18:20 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.5868, average loss: 1.4752
[11/29 11:18:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 65.70	
[11/29 11:18:20 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.8
[11/29 11:26:01 visual_prompt]: Epoch 9 / 100: avg data time: 5.13e+00, avg batch time: 6.5841, average train loss: 0.9687
[11/29 11:26:53 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.5845, average loss: 1.7041
[11/29 11:26:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 65.12	
[11/29 11:26:53 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.9
[11/29 11:34:34 visual_prompt]: Epoch 10 / 100: avg data time: 5.13e+00, avg batch time: 6.5788, average train loss: 0.9234
[11/29 11:35:27 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.5885, average loss: 0.6652
[11/29 11:35:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 64.91	
[11/29 11:35:27 visual_prompt]: Training 11 / 100 epoch, with learning rate 1.0
[11/29 11:43:09 visual_prompt]: Epoch 11 / 100: avg data time: 5.15e+00, avg batch time: 6.6010, average train loss: 0.9014
[11/29 11:44:01 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.5857, average loss: 1.0716
[11/29 11:44:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 65.08	
[11/29 11:44:01 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.9996954135095479
[11/29 11:52:00 visual_prompt]: Epoch 12 / 100: avg data time: 5.38e+00, avg batch time: 6.8293, average train loss: 0.8637
[11/29 11:53:17 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.5850, average loss: 1.0738
[11/29 11:53:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 65.40	
[11/29 11:53:17 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.9987820251299121
[11/29 12:01:02 visual_prompt]: Epoch 13 / 100: avg data time: 5.19e+00, avg batch time: 6.6460, average train loss: 0.7342
[11/29 12:01:55 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.5864, average loss: 0.7680
[11/29 12:01:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 66.86	
[11/29 12:01:55 visual_prompt]: Best epoch 13: best metric: -0.768
[11/29 12:01:55 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.9972609476841366
[11/29 12:09:37 visual_prompt]: Epoch 14 / 100: avg data time: 5.15e+00, avg batch time: 6.6002, average train loss: 0.8942
[11/29 12:10:30 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.5883, average loss: 0.7401
[11/29 12:10:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 47.97	rocauc: 62.99	
[11/29 12:10:30 visual_prompt]: Best epoch 14: best metric: -0.740
[11/29 12:10:30 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.9951340343707852
[11/29 12:18:11 visual_prompt]: Epoch 15 / 100: avg data time: 5.13e+00, avg batch time: 6.5833, average train loss: 0.8148
[11/29 12:19:04 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.5851, average loss: 0.8043
[11/29 12:19:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 66.22	
[11/29 12:19:04 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.9924038765061041
[11/29 12:26:45 visual_prompt]: Epoch 16 / 100: avg data time: 5.13e+00, avg batch time: 6.5813, average train loss: 0.8598
[11/29 12:27:38 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.5853, average loss: 0.6505
[11/29 12:27:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 66.94	
[11/29 12:27:38 visual_prompt]: Best epoch 16: best metric: -0.650
[11/29 12:27:38 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.9890738003669028
[11/29 12:35:19 visual_prompt]: Epoch 17 / 100: avg data time: 5.13e+00, avg batch time: 6.5863, average train loss: 0.7246
[11/29 12:36:12 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.5871, average loss: 0.7440
[11/29 12:36:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 66.41	
[11/29 12:36:12 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.9851478631379982
[11/29 12:43:53 visual_prompt]: Epoch 18 / 100: avg data time: 5.14e+00, avg batch time: 6.5876, average train loss: 0.9067
[11/29 12:44:46 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.5893, average loss: 1.7585
[11/29 12:44:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 64.82	
[11/29 12:44:46 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.9806308479691594
[11/29 12:52:29 visual_prompt]: Epoch 19 / 100: avg data time: 5.15e+00, avg batch time: 6.5989, average train loss: 0.8283
[11/29 12:53:22 visual_prompt]: Inference (val):avg data time: 3.81e-05, avg batch time: 0.5843, average loss: 1.1293
[11/29 12:53:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.66	
[11/29 12:53:22 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.9755282581475768
[11/29 13:01:05 visual_prompt]: Epoch 20 / 100: avg data time: 5.16e+00, avg batch time: 6.6122, average train loss: 0.7449
[11/29 13:01:57 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.5853, average loss: 0.6278
[11/29 13:01:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 70.43	
[11/29 13:01:57 visual_prompt]: Best epoch 20: best metric: -0.628
[11/29 13:01:57 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.9698463103929542
[11/29 13:09:39 visual_prompt]: Epoch 21 / 100: avg data time: 5.15e+00, avg batch time: 6.5965, average train loss: 0.7236
[11/29 13:10:32 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.5852, average loss: 1.1887
[11/29 13:10:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 70.24	
[11/29 13:10:32 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.9635919272833937
[11/29 13:18:16 visual_prompt]: Epoch 22 / 100: avg data time: 5.16e+00, avg batch time: 6.6175, average train loss: 0.7983
[11/29 13:19:08 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.5861, average loss: 1.2417
[11/29 13:19:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 73.28	
[11/29 13:19:08 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.9567727288213004
[11/29 13:26:54 visual_prompt]: Epoch 23 / 100: avg data time: 5.20e+00, avg batch time: 6.6498, average train loss: 0.8778
[11/29 13:27:47 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.5868, average loss: 0.9785
[11/29 13:27:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 70.27	
[11/29 13:27:47 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.9493970231495835
[11/29 13:35:30 visual_prompt]: Epoch 24 / 100: avg data time: 5.16e+00, avg batch time: 6.6097, average train loss: 0.7457
[11/29 13:36:23 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.5869, average loss: 1.3981
[11/29 13:36:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 66.88	
[11/29 13:36:23 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.9414737964294635
[11/29 13:44:06 visual_prompt]: Epoch 25 / 100: avg data time: 5.16e+00, avg batch time: 6.6150, average train loss: 0.7502
[11/29 13:44:59 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.5902, average loss: 0.7029
[11/29 13:44:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.54	rocauc: 69.09	
[11/29 13:44:59 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.9330127018922194
[11/29 13:52:40 visual_prompt]: Epoch 26 / 100: avg data time: 5.13e+00, avg batch time: 6.5832, average train loss: 0.6993
[11/29 13:53:32 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.5847, average loss: 0.6264
[11/29 13:53:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 71.34	
[11/29 13:53:32 visual_prompt]: Best epoch 26: best metric: -0.626
[11/29 13:53:32 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.9240240480782129
[11/29 14:01:24 visual_prompt]: Epoch 27 / 100: avg data time: 5.27e+00, avg batch time: 6.7294, average train loss: 0.7001
[11/29 14:02:30 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.5866, average loss: 0.8586
[11/29 14:02:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 72.79	
[11/29 14:02:30 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.9145187862775208
[11/29 14:10:21 visual_prompt]: Epoch 28 / 100: avg data time: 5.28e+00, avg batch time: 6.7270, average train loss: 0.7071
[11/29 14:11:14 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.5917, average loss: 0.7898
[11/29 14:11:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 74.59	
[11/29 14:11:14 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.9045084971874737
[11/29 14:18:56 visual_prompt]: Epoch 29 / 100: avg data time: 5.14e+00, avg batch time: 6.5903, average train loss: 0.7472
[11/29 14:19:49 visual_prompt]: Inference (val):avg data time: 3.81e-05, avg batch time: 0.5858, average loss: 1.2905
[11/29 14:19:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 73.60	
[11/29 14:19:49 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.8940053768033609
[11/29 14:27:43 visual_prompt]: Epoch 30 / 100: avg data time: 5.31e+00, avg batch time: 6.7665, average train loss: 0.7447
[11/29 14:28:36 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.5900, average loss: 0.7021
[11/29 14:28:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 69.63	
[11/29 14:28:36 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.883022221559489
[11/29 14:36:21 visual_prompt]: Epoch 31 / 100: avg data time: 5.19e+00, avg batch time: 6.6405, average train loss: 0.7410
[11/29 14:37:13 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.5877, average loss: 0.6355
[11/29 14:37:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 72.55	
[11/29 14:37:13 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.8715724127386971
[11/29 14:44:57 visual_prompt]: Epoch 32 / 100: avg data time: 5.17e+00, avg batch time: 6.6245, average train loss: 0.7250
[11/29 14:45:51 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.5873, average loss: 0.6228
[11/29 14:45:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 69.51	rocauc: 73.43	
[11/29 14:45:51 visual_prompt]: Best epoch 32: best metric: -0.623
[11/29 14:45:51 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.8596699001693255
[11/29 14:53:33 visual_prompt]: Epoch 33 / 100: avg data time: 5.15e+00, avg batch time: 6.5970, average train loss: 0.6586
[11/29 14:54:25 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.5867, average loss: 0.6086
[11/29 14:54:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.89	rocauc: 74.28	
[11/29 14:54:25 visual_prompt]: Best epoch 33: best metric: -0.609
[11/29 14:54:25 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.8473291852294986
[11/29 15:02:24 visual_prompt]: Epoch 34 / 100: avg data time: 5.37e+00, avg batch time: 6.8279, average train loss: 0.7196
[11/29 15:03:17 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.5901, average loss: 0.6373
[11/29 15:03:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 69.15	
[11/29 15:03:17 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.8345653031794291
[11/29 15:11:05 visual_prompt]: Epoch 35 / 100: avg data time: 5.24e+00, avg batch time: 6.6913, average train loss: 0.6718
[11/29 15:11:58 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.5863, average loss: 0.6527
[11/29 15:11:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 73.02	
[11/29 15:11:58 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.8213938048432696
[11/29 15:19:51 visual_prompt]: Epoch 36 / 100: avg data time: 5.31e+00, avg batch time: 6.7628, average train loss: 0.7162
[11/29 15:20:44 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.5857, average loss: 1.2581
[11/29 15:20:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 69.58	
[11/29 15:20:44 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.8078307376628291
[11/29 15:28:43 visual_prompt]: Epoch 37 / 100: avg data time: 5.39e+00, avg batch time: 6.8422, average train loss: 0.7757
[11/29 15:29:36 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.5873, average loss: 0.8346
[11/29 15:29:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 52.85	rocauc: 72.84	
[11/29 15:29:36 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.7938926261462366
[11/29 15:37:17 visual_prompt]: Epoch 38 / 100: avg data time: 5.13e+00, avg batch time: 6.5848, average train loss: 0.6646
[11/29 15:38:10 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.5896, average loss: 0.6188
[11/29 15:38:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 72.29	
[11/29 15:38:10 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.7795964517353734
[11/29 15:45:52 visual_prompt]: Epoch 39 / 100: avg data time: 5.15e+00, avg batch time: 6.6040, average train loss: 0.6615
[11/29 15:46:45 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.5879, average loss: 0.6355
[11/29 15:46:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 74.07	
[11/29 15:46:45 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.7649596321166025
[11/29 15:54:29 visual_prompt]: Epoch 40 / 100: avg data time: 5.17e+00, avg batch time: 6.6175, average train loss: 0.7041
[11/29 15:55:22 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.5887, average loss: 0.7088
[11/29 15:55:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 72.97	
[11/29 15:55:22 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.75
[11/29 16:03:03 visual_prompt]: Epoch 41 / 100: avg data time: 5.13e+00, avg batch time: 6.5881, average train loss: 0.6663
[11/29 16:03:56 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.5889, average loss: 0.6483
[11/29 16:03:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 73.61	
[11/29 16:03:56 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.7347357813929454
[11/29 16:11:37 visual_prompt]: Epoch 42 / 100: avg data time: 5.13e+00, avg batch time: 6.5827, average train loss: 0.6256
[11/29 16:12:29 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.5950, average loss: 0.7569
[11/29 16:12:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 72.87	
[11/29 16:12:29 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.7191855733945387
[11/29 16:20:12 visual_prompt]: Epoch 43 / 100: avg data time: 5.15e+00, avg batch time: 6.6022, average train loss: 0.6088
[11/29 16:21:04 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.5884, average loss: 1.1159
[11/29 16:21:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 75.65	
[11/29 16:21:04 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.7033683215379002
[11/29 16:28:48 visual_prompt]: Epoch 44 / 100: avg data time: 5.17e+00, avg batch time: 6.6215, average train loss: 0.7478
[11/29 16:29:41 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.5886, average loss: 0.5945
[11/29 16:29:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 69.92	rocauc: 75.54	
[11/29 16:29:41 visual_prompt]: Best epoch 44: best metric: -0.595
[11/29 16:29:41 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.6873032967079561
[11/29 16:37:24 visual_prompt]: Epoch 45 / 100: avg data time: 5.16e+00, avg batch time: 6.6145, average train loss: 0.6332
[11/29 16:38:17 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.5881, average loss: 0.5908
[11/29 16:38:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 75.64	
[11/29 16:38:17 visual_prompt]: Best epoch 45: best metric: -0.591
[11/29 16:38:17 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.6710100716628344
[11/29 16:45:57 visual_prompt]: Epoch 46 / 100: avg data time: 5.12e+00, avg batch time: 6.5761, average train loss: 0.5853
[11/29 16:46:50 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.5888, average loss: 0.6293
[11/29 16:46:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 68.70	rocauc: 74.87	
[11/29 16:46:50 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.6545084971874737
[11/29 16:54:32 visual_prompt]: Epoch 47 / 100: avg data time: 5.14e+00, avg batch time: 6.5920, average train loss: 0.6431
[11/29 16:55:25 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.5876, average loss: 0.6813
[11/29 16:55:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 73.84	
[11/29 16:55:25 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.6378186779084996
[11/29 17:03:07 visual_prompt]: Epoch 48 / 100: avg data time: 5.14e+00, avg batch time: 6.5917, average train loss: 0.6118
[11/29 17:03:59 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.5860, average loss: 0.7943
[11/29 17:03:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 74.49	
[11/29 17:03:59 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.6209609477998338
[11/29 17:11:42 visual_prompt]: Epoch 49 / 100: avg data time: 5.15e+00, avg batch time: 6.6056, average train loss: 0.6062
[11/29 17:12:34 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.5879, average loss: 0.6202
[11/29 17:12:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 75.99	
[11/29 17:12:34 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.6039558454088796
[11/29 17:20:16 visual_prompt]: Epoch 50 / 100: avg data time: 5.14e+00, avg batch time: 6.5944, average train loss: 0.6151
[11/29 17:21:09 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.5865, average loss: 0.8952
[11/29 17:21:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 74.80	
[11/29 17:21:09 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.5868240888334653
[11/29 17:28:51 visual_prompt]: Epoch 51 / 100: avg data time: 5.14e+00, avg batch time: 6.5879, average train loss: 0.5953
[11/29 17:29:43 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.5881, average loss: 0.8696
[11/29 17:29:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 52.85	rocauc: 74.88	
[11/29 17:29:43 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.5695865504800327
[11/29 17:37:24 visual_prompt]: Epoch 52 / 100: avg data time: 5.13e+00, avg batch time: 6.5800, average train loss: 0.5918
[11/29 17:38:17 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.5869, average loss: 0.6252
[11/29 17:38:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 73.38	
[11/29 17:38:17 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.5522642316338268
[11/29 17:45:59 visual_prompt]: Epoch 53 / 100: avg data time: 5.15e+00, avg batch time: 6.6016, average train loss: 0.6374
[11/29 17:46:52 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.5864, average loss: 0.6561
[11/29 17:46:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 75.69	
[11/29 17:46:52 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.5348782368720626
[11/29 17:54:33 visual_prompt]: Epoch 54 / 100: avg data time: 5.13e+00, avg batch time: 6.5849, average train loss: 0.6122
[11/29 17:55:26 visual_prompt]: Inference (val):avg data time: 3.69e-05, avg batch time: 0.5844, average loss: 0.6972
[11/29 17:55:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 72.11	
[11/29 17:55:26 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.5174497483512506
[11/29 18:03:07 visual_prompt]: Epoch 55 / 100: avg data time: 5.13e+00, avg batch time: 6.5827, average train loss: 0.6575
[11/29 18:04:00 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.5899, average loss: 0.9848
[11/29 18:04:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 71.64	
[11/29 18:04:00 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.5
[11/29 18:11:40 visual_prompt]: Epoch 56 / 100: avg data time: 5.12e+00, avg batch time: 6.5737, average train loss: 0.6801
[11/29 18:12:33 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.5897, average loss: 0.6264
[11/29 18:12:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 74.30	
[11/29 18:12:33 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.48255025164874965
[11/29 18:20:14 visual_prompt]: Epoch 57 / 100: avg data time: 5.13e+00, avg batch time: 6.5875, average train loss: 0.5297
[11/29 18:21:06 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.5874, average loss: 1.1900
[11/29 18:21:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 70.85	
[11/29 18:21:06 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.46512176312793735
[11/29 18:28:47 visual_prompt]: Epoch 58 / 100: avg data time: 5.12e+00, avg batch time: 6.5765, average train loss: 0.5367
[11/29 18:29:40 visual_prompt]: Inference (val):avg data time: 3.75e-05, avg batch time: 0.5859, average loss: 0.7478
[11/29 18:29:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 71.04	
[11/29 18:29:40 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.44773576836617335
[11/29 18:37:22 visual_prompt]: Epoch 59 / 100: avg data time: 5.14e+00, avg batch time: 6.5949, average train loss: 0.5299
[11/29 18:38:14 visual_prompt]: Inference (val):avg data time: 3.64e-05, avg batch time: 0.5896, average loss: 1.0627
[11/29 18:38:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 52.03	rocauc: 65.80	
[11/29 18:38:14 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.4304134495199674
[11/29 18:45:55 visual_prompt]: Epoch 60 / 100: avg data time: 5.13e+00, avg batch time: 6.5791, average train loss: 0.5424
[11/29 18:46:48 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.5861, average loss: 0.7228
[11/29 18:46:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.01	rocauc: 71.89	
[11/29 18:46:48 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.41317591116653485
[11/29 18:54:28 visual_prompt]: Epoch 61 / 100: avg data time: 5.13e+00, avg batch time: 6.5808, average train loss: 0.5362
[11/29 18:55:21 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.5892, average loss: 0.7876
[11/29 18:55:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 72.66	
[11/29 18:55:21 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.3960441545911204
[11/29 19:03:02 visual_prompt]: Epoch 62 / 100: avg data time: 5.13e+00, avg batch time: 6.5880, average train loss: 0.5365
[11/29 19:03:55 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.5852, average loss: 0.8229
[11/29 19:03:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 71.47	
[11/29 19:03:55 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.3790390522001662
[11/29 19:11:35 visual_prompt]: Epoch 63 / 100: avg data time: 5.11e+00, avg batch time: 6.5672, average train loss: 0.5053
[11/29 19:12:28 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.5877, average loss: 0.6705
[11/29 19:12:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.67	rocauc: 73.69	
[11/29 19:12:28 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.36218132209150045
[11/29 19:20:08 visual_prompt]: Epoch 64 / 100: avg data time: 5.11e+00, avg batch time: 6.5658, average train loss: 0.4739
[11/29 19:21:00 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.5875, average loss: 0.9644
[11/29 19:21:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 71.98	
[11/29 19:21:00 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.34549150281252633
[11/29 19:28:40 visual_prompt]: Epoch 65 / 100: avg data time: 5.10e+00, avg batch time: 6.5579, average train loss: 0.5174
[11/29 19:29:32 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.5862, average loss: 0.6204
[11/29 19:29:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 72.14	
[11/29 19:29:32 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.32898992833716567
[11/29 19:37:11 visual_prompt]: Epoch 66 / 100: avg data time: 5.10e+00, avg batch time: 6.5585, average train loss: 0.4549
[11/29 19:38:04 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.5860, average loss: 0.7179
[11/29 19:38:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 69.33	
[11/29 19:38:04 visual_prompt]: Stopping early.
[11/29 19:38:05 visual_prompt]: Rank of current process: 0. World size: 1
[11/29 19:38:05 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/29 19:38:05 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/29 19:38:05 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/29 19:38:05 visual_prompt]: Training with config:
[11/29 19:38:05 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr1.0_wd0.0/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 1.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/29 19:38:05 visual_prompt]: Loading training data...
[11/29 19:38:05 visual_prompt]: Constructing mammo-cbis dataset train...
[11/29 19:38:05 visual_prompt]: Loading validation data...
[11/29 19:38:05 visual_prompt]: Constructing mammo-cbis dataset val...
[11/29 19:38:05 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/29 19:38:07 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/29 19:38:07 visual_prompt]: tuned percent:0.532
[11/29 19:38:08 visual_prompt]: Device used for model: 0
[11/29 19:38:08 visual_prompt]: Setting up Evaluator...
[11/29 19:38:08 visual_prompt]: Setting up Trainer...
[11/29 19:38:08 visual_prompt]: 	Setting up the optimizer...
[11/29 19:38:08 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/29 19:45:51 visual_prompt]: Epoch 1 / 100: avg data time: 5.16e+00, avg batch time: 6.6140, average train loss: 1.4863
[11/29 19:46:44 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.5885, average loss: 1.4553
[11/29 19:46:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/29 19:46:44 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.1
[11/29 19:54:25 visual_prompt]: Epoch 2 / 100: avg data time: 5.14e+00, avg batch time: 6.5937, average train loss: 1.2006
[11/29 19:55:18 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.5895, average loss: 0.6988
[11/29 19:55:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.18	
[11/29 19:55:18 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.2
[11/29 20:02:59 visual_prompt]: Epoch 3 / 100: avg data time: 5.12e+00, avg batch time: 6.5798, average train loss: 0.7595
[11/29 20:03:51 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.5872, average loss: 0.7682
[11/29 20:03:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.81	
[11/29 20:03:51 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.3
[11/29 20:11:31 visual_prompt]: Epoch 4 / 100: avg data time: 5.11e+00, avg batch time: 6.5642, average train loss: 0.8947
[11/29 20:12:24 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.5862, average loss: 0.8124
[11/29 20:12:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.61	
[11/29 20:12:24 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.4
[11/29 20:20:03 visual_prompt]: Epoch 5 / 100: avg data time: 5.11e+00, avg batch time: 6.5632, average train loss: 0.9223
[11/29 20:20:56 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.5897, average loss: 1.3861
[11/29 20:20:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.24	
[11/29 20:20:56 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.5
[11/29 20:28:39 visual_prompt]: Epoch 6 / 100: avg data time: 5.16e+00, avg batch time: 6.6093, average train loss: 0.8900
[11/29 20:29:32 visual_prompt]: Inference (val):avg data time: 3.55e-05, avg batch time: 0.5889, average loss: 0.8766
[11/29 20:29:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.98	
[11/29 20:29:32 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.6
[11/29 20:37:12 visual_prompt]: Epoch 7 / 100: avg data time: 5.12e+00, avg batch time: 6.5724, average train loss: 0.7588
[11/29 20:38:05 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.5884, average loss: 1.0101
[11/29 20:38:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.28	
[11/29 20:38:05 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.7
[11/29 20:45:45 visual_prompt]: Epoch 8 / 100: avg data time: 5.12e+00, avg batch time: 6.5685, average train loss: 0.7895
[11/29 20:46:37 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.5876, average loss: 1.4801
[11/29 20:46:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.99	
[11/29 20:46:37 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.8
[11/29 20:54:17 visual_prompt]: Epoch 9 / 100: avg data time: 5.12e+00, avg batch time: 6.5710, average train loss: 1.0567
[11/29 20:55:10 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.5893, average loss: 1.9678
[11/29 20:55:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 64.97	
[11/29 20:55:10 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.9
[11/29 21:02:51 visual_prompt]: Epoch 10 / 100: avg data time: 5.12e+00, avg batch time: 6.5752, average train loss: 0.8385
[11/29 21:03:43 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.5861, average loss: 0.8806
[11/29 21:03:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 67.53	
[11/29 21:03:43 visual_prompt]: Training 11 / 100 epoch, with learning rate 1.0
[11/29 21:11:25 visual_prompt]: Epoch 11 / 100: avg data time: 5.14e+00, avg batch time: 6.5944, average train loss: 0.9429
[11/29 21:12:18 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.5900, average loss: 1.2620
[11/29 21:12:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 66.87	
[11/29 21:12:18 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.9996954135095479
[11/29 21:19:57 visual_prompt]: Epoch 12 / 100: avg data time: 5.11e+00, avg batch time: 6.5615, average train loss: 0.8875
[11/29 21:20:50 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.5857, average loss: 1.1847
[11/29 21:20:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 66.54	
[11/29 21:20:50 visual_prompt]: Best epoch 12: best metric: -1.185
[11/29 21:20:50 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.9987820251299121
[11/29 21:28:31 visual_prompt]: Epoch 13 / 100: avg data time: 5.12e+00, avg batch time: 6.5793, average train loss: 0.7386
[11/29 21:29:23 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.5861, average loss: 0.9022
[11/29 21:29:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 70.41	
[11/29 21:29:23 visual_prompt]: Best epoch 13: best metric: -0.902
[11/29 21:29:23 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.9972609476841366
[11/29 21:37:03 visual_prompt]: Epoch 14 / 100: avg data time: 5.11e+00, avg batch time: 6.5618, average train loss: 0.9029
[11/29 21:37:55 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.5897, average loss: 0.6527
[11/29 21:37:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 69.88	
[11/29 21:37:56 visual_prompt]: Best epoch 14: best metric: -0.653
[11/29 21:37:56 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.9951340343707852
[11/29 21:45:35 visual_prompt]: Epoch 15 / 100: avg data time: 5.11e+00, avg batch time: 6.5589, average train loss: 0.7763
[11/29 21:46:27 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.5851, average loss: 1.0136
[11/29 21:46:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 71.59	
[11/29 21:46:27 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.9924038765061041
[11/29 21:54:07 visual_prompt]: Epoch 16 / 100: avg data time: 5.11e+00, avg batch time: 6.5673, average train loss: 0.7729
[11/29 21:55:00 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.5949, average loss: 0.7274
[11/29 21:55:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 70.14	
[11/29 21:55:00 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.9890738003669028
[11/29 22:02:41 visual_prompt]: Epoch 17 / 100: avg data time: 5.13e+00, avg batch time: 6.5875, average train loss: 0.7495
[11/29 22:03:34 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.5846, average loss: 0.6481
[11/29 22:03:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 72.01	
[11/29 22:03:34 visual_prompt]: Best epoch 17: best metric: -0.648
[11/29 22:03:34 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.9851478631379982
[11/29 22:11:13 visual_prompt]: Epoch 18 / 100: avg data time: 5.10e+00, avg batch time: 6.5507, average train loss: 1.0452
[11/29 22:12:05 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.5870, average loss: 1.8409
[11/29 22:12:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 68.54	
[11/29 22:12:05 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.9806308479691594
[11/29 22:19:44 visual_prompt]: Epoch 19 / 100: avg data time: 5.10e+00, avg batch time: 6.5556, average train loss: 1.4687
[11/29 22:20:37 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.5866, average loss: 0.8980
[11/29 22:20:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 70.40	
[11/29 22:20:37 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.9755282581475768
[11/29 22:28:18 visual_prompt]: Epoch 20 / 100: avg data time: 5.12e+00, avg batch time: 6.5775, average train loss: 0.7341
[11/29 22:29:10 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.5878, average loss: 0.6098
[11/29 22:29:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 68.70	rocauc: 73.99	
[11/29 22:29:10 visual_prompt]: Best epoch 20: best metric: -0.610
[11/29 22:29:10 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.9698463103929542
[11/29 22:36:51 visual_prompt]: Epoch 21 / 100: avg data time: 5.13e+00, avg batch time: 6.5846, average train loss: 0.7037
[11/29 22:37:44 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.5863, average loss: 1.2582
[11/29 22:37:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 72.44	
[11/29 22:37:44 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.9635919272833937
[11/29 22:45:24 visual_prompt]: Epoch 22 / 100: avg data time: 5.12e+00, avg batch time: 6.5728, average train loss: 0.9042
[11/29 22:46:17 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.5862, average loss: 1.1301
[11/29 22:46:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 72.60	
[11/29 22:46:17 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.9567727288213004
[11/29 22:53:59 visual_prompt]: Epoch 23 / 100: avg data time: 5.15e+00, avg batch time: 6.5992, average train loss: 0.8556
[11/29 22:54:52 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.5885, average loss: 0.7865
[11/29 22:54:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 73.93	
[11/29 22:54:52 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.9493970231495835
[11/29 23:02:32 visual_prompt]: Epoch 24 / 100: avg data time: 5.12e+00, avg batch time: 6.5712, average train loss: 0.7096
[11/29 23:03:25 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.5891, average loss: 1.2536
[11/29 23:03:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 71.79	
[11/29 23:03:25 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.9414737964294635
[11/29 23:11:06 visual_prompt]: Epoch 25 / 100: avg data time: 5.14e+00, avg batch time: 6.5917, average train loss: 0.6866
[11/29 23:11:59 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.5864, average loss: 0.8741
[11/29 23:11:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 72.86	
[11/29 23:11:59 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.9330127018922194
[11/29 23:19:39 visual_prompt]: Epoch 26 / 100: avg data time: 5.12e+00, avg batch time: 6.5711, average train loss: 0.6706
[11/29 23:20:32 visual_prompt]: Inference (val):avg data time: 3.59e-05, avg batch time: 0.5873, average loss: 0.8436
[11/29 23:20:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 53.66	rocauc: 73.76	
[11/29 23:20:32 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.9240240480782129
[11/29 23:28:13 visual_prompt]: Epoch 27 / 100: avg data time: 5.13e+00, avg batch time: 6.5800, average train loss: 0.7306
[11/29 23:29:05 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.5867, average loss: 0.9208
[11/29 23:29:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 75.87	
[11/29 23:29:05 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.9145187862775208
[11/29 23:36:46 visual_prompt]: Epoch 28 / 100: avg data time: 5.13e+00, avg batch time: 6.5852, average train loss: 0.6340
[11/29 23:37:39 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.5906, average loss: 0.6632
[11/29 23:37:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 73.90	
[11/29 23:37:39 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.9045084971874737
[11/29 23:45:18 visual_prompt]: Epoch 29 / 100: avg data time: 5.11e+00, avg batch time: 6.5635, average train loss: 0.6710
[11/29 23:46:12 visual_prompt]: Inference (val):avg data time: 3.44e-05, avg batch time: 0.5900, average loss: 1.4244
[11/29 23:46:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 74.79	
[11/29 23:46:12 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.8940053768033609
[11/29 23:53:54 visual_prompt]: Epoch 30 / 100: avg data time: 5.15e+00, avg batch time: 6.6061, average train loss: 0.6302
[11/29 23:54:47 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.5866, average loss: 1.2564
[11/29 23:54:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 48.78	rocauc: 73.18	
[11/29 23:54:47 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.883022221559489
[11/30 00:02:27 visual_prompt]: Epoch 31 / 100: avg data time: 5.11e+00, avg batch time: 6.5697, average train loss: 0.7490
[11/30 00:03:20 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.5857, average loss: 0.6630
[11/30 00:03:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 68.29	rocauc: 74.20	
[11/30 00:03:20 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.8715724127386971
[11/30 00:11:01 visual_prompt]: Epoch 32 / 100: avg data time: 5.13e+00, avg batch time: 6.5795, average train loss: 0.6544
[11/30 00:11:54 visual_prompt]: Inference (val):avg data time: 3.32e-05, avg batch time: 0.5904, average loss: 0.6319
[11/30 00:11:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 73.40	
[11/30 00:11:54 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.8596699001693255
[11/30 00:19:34 visual_prompt]: Epoch 33 / 100: avg data time: 5.12e+00, avg batch time: 6.5719, average train loss: 0.5834
[11/30 00:20:26 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.5868, average loss: 0.6300
[11/30 00:20:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 73.76	
[11/30 00:20:26 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.8473291852294986
[11/30 00:28:06 visual_prompt]: Epoch 34 / 100: avg data time: 5.11e+00, avg batch time: 6.5602, average train loss: 0.6105
[11/30 00:28:59 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.5876, average loss: 0.9244
[11/30 00:28:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.54	rocauc: 72.72	
[11/30 00:28:59 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.8345653031794291
[11/30 00:36:39 visual_prompt]: Epoch 35 / 100: avg data time: 5.12e+00, avg batch time: 6.5788, average train loss: 0.6015
[11/30 00:37:32 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.5895, average loss: 0.7921
[11/30 00:37:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 73.39	
[11/30 00:37:32 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.8213938048432696
[11/30 00:45:13 visual_prompt]: Epoch 36 / 100: avg data time: 5.14e+00, avg batch time: 6.5897, average train loss: 0.6609
[11/30 00:46:06 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.5890, average loss: 0.6925
[11/30 00:46:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 71.12	
[11/30 00:46:06 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.8078307376628291
[11/30 00:53:46 visual_prompt]: Epoch 37 / 100: avg data time: 5.12e+00, avg batch time: 6.5689, average train loss: 0.5611
[11/30 00:54:39 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.5893, average loss: 0.9730
[11/30 00:54:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 73.01	
[11/30 00:54:39 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.7938926261462366
[11/30 01:02:19 visual_prompt]: Epoch 38 / 100: avg data time: 5.12e+00, avg batch time: 6.5719, average train loss: 0.5647
[11/30 01:03:12 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.5861, average loss: 0.9228
[11/30 01:03:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 69.39	
[11/30 01:03:12 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.7795964517353734
[11/30 01:10:53 visual_prompt]: Epoch 39 / 100: avg data time: 5.13e+00, avg batch time: 6.5781, average train loss: 0.5133
[11/30 01:11:45 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.5866, average loss: 0.9365
[11/30 01:11:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 71.26	
[11/30 01:11:45 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.7649596321166025
[11/30 01:19:26 visual_prompt]: Epoch 40 / 100: avg data time: 5.13e+00, avg batch time: 6.5833, average train loss: 0.5412
[11/30 01:20:19 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.5872, average loss: 0.8052
[11/30 01:20:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 72.99	
[11/30 01:20:19 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.75
[11/30 01:27:59 visual_prompt]: Epoch 41 / 100: avg data time: 5.11e+00, avg batch time: 6.5618, average train loss: 0.4893
[11/30 01:28:51 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.5926, average loss: 0.6847
[11/30 01:28:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 71.80	
[11/30 01:28:51 visual_prompt]: Stopping early.
[11/30 01:28:51 visual_prompt]: Rank of current process: 0. World size: 1
[11/30 01:28:51 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/30 01:28:51 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/30 01:28:51 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/30 01:28:51 visual_prompt]: Training with config:
[11/30 01:28:51 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr0.5_wd0.01/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/30 01:28:51 visual_prompt]: Loading training data...
[11/30 01:28:51 visual_prompt]: Constructing mammo-cbis dataset train...
[11/30 01:28:52 visual_prompt]: Loading validation data...
[11/30 01:28:52 visual_prompt]: Constructing mammo-cbis dataset val...
[11/30 01:28:52 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/30 01:28:54 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/30 01:28:54 visual_prompt]: tuned percent:0.532
[11/30 01:28:55 visual_prompt]: Device used for model: 0
[11/30 01:28:55 visual_prompt]: Setting up Evaluator...
[11/30 01:28:55 visual_prompt]: Setting up Trainer...
[11/30 01:28:55 visual_prompt]: 	Setting up the optimizer...
[11/30 01:28:55 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/30 01:36:35 visual_prompt]: Epoch 1 / 100: avg data time: 5.12e+00, avg batch time: 6.5707, average train loss: 1.4863
[11/30 01:37:27 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.5878, average loss: 1.4553
[11/30 01:37:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/30 01:37:27 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.05
[11/30 01:45:07 visual_prompt]: Epoch 2 / 100: avg data time: 5.12e+00, avg batch time: 6.5698, average train loss: 1.0767
[11/30 01:46:00 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.5844, average loss: 0.7165
[11/30 01:46:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.89	
[11/30 01:46:00 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.1
[11/30 01:53:41 visual_prompt]: Epoch 3 / 100: avg data time: 5.13e+00, avg batch time: 6.5808, average train loss: 0.7123
[11/30 01:54:33 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.5899, average loss: 0.8119
[11/30 01:54:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.06	
[11/30 01:54:33 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.15
[11/30 02:02:13 visual_prompt]: Epoch 4 / 100: avg data time: 5.11e+00, avg batch time: 6.5594, average train loss: 0.7353
[11/30 02:03:05 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.5854, average loss: 0.7853
[11/30 02:03:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.01	
[11/30 02:03:05 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.2
[11/30 02:10:45 visual_prompt]: Epoch 5 / 100: avg data time: 5.11e+00, avg batch time: 6.5636, average train loss: 0.7493
[11/30 02:11:37 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.5875, average loss: 0.7440
[11/30 02:11:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.62	
[11/30 02:11:37 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.25
[11/30 02:19:18 visual_prompt]: Epoch 6 / 100: avg data time: 5.13e+00, avg batch time: 6.5836, average train loss: 0.7282
[11/30 02:20:11 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.5867, average loss: 0.6939
[11/30 02:20:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.75	
[11/30 02:20:11 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.3
[11/30 02:27:50 visual_prompt]: Epoch 7 / 100: avg data time: 5.10e+00, avg batch time: 6.5549, average train loss: 0.7207
[11/30 02:28:43 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.5845, average loss: 1.1219
[11/30 02:28:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.51	
[11/30 02:28:43 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.35
[11/30 02:36:23 visual_prompt]: Epoch 8 / 100: avg data time: 5.12e+00, avg batch time: 6.5711, average train loss: 0.7393
[11/30 02:37:15 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.5896, average loss: 0.8992
[11/30 02:37:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.89	
[11/30 02:37:15 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.4
[11/30 02:44:55 visual_prompt]: Epoch 9 / 100: avg data time: 5.12e+00, avg batch time: 6.5674, average train loss: 0.7502
[11/30 02:45:48 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.5851, average loss: 0.7116
[11/30 02:45:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.54	
[11/30 02:45:48 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.45
[11/30 02:53:27 visual_prompt]: Epoch 10 / 100: avg data time: 5.10e+00, avg batch time: 6.5533, average train loss: 0.7194
[11/30 02:54:19 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.5868, average loss: 0.6989
[11/30 02:54:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.44	
[11/30 02:54:19 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.5
[11/30 03:02:00 visual_prompt]: Epoch 11 / 100: avg data time: 5.13e+00, avg batch time: 6.5794, average train loss: 0.7433
[11/30 03:02:53 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.5922, average loss: 0.8597
[11/30 03:02:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.49	
[11/30 03:02:53 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.49984770675477397
[11/30 03:10:32 visual_prompt]: Epoch 12 / 100: avg data time: 5.11e+00, avg batch time: 6.5617, average train loss: 0.7901
[11/30 03:11:25 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.5849, average loss: 0.7401
[11/30 03:11:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.09	
[11/30 03:11:25 visual_prompt]: Best epoch 12: best metric: -0.740
[11/30 03:11:25 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.49939101256495605
[11/30 03:19:04 visual_prompt]: Epoch 13 / 100: avg data time: 5.11e+00, avg batch time: 6.5659, average train loss: 0.7767
[11/30 03:19:57 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.5869, average loss: 0.7056
[11/30 03:19:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.08	
[11/30 03:19:57 visual_prompt]: Best epoch 13: best metric: -0.706
[11/30 03:19:57 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.4986304738420683
[11/30 03:27:37 visual_prompt]: Epoch 14 / 100: avg data time: 5.12e+00, avg batch time: 6.5758, average train loss: 0.8127
[11/30 03:28:30 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.5870, average loss: 1.2457
[11/30 03:28:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.24	
[11/30 03:28:30 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.4975670171853926
[11/30 03:36:09 visual_prompt]: Epoch 15 / 100: avg data time: 5.10e+00, avg batch time: 6.5490, average train loss: 0.8469
[11/30 03:37:01 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.5889, average loss: 1.0016
[11/30 03:37:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.98	
[11/30 03:37:01 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.49620193825305203
[11/30 03:44:41 visual_prompt]: Epoch 16 / 100: avg data time: 5.11e+00, avg batch time: 6.5595, average train loss: 0.7687
[11/30 03:45:33 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.5859, average loss: 0.7205
[11/30 03:45:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.86	
[11/30 03:45:33 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.4945369001834514
[11/30 03:53:14 visual_prompt]: Epoch 17 / 100: avg data time: 5.12e+00, avg batch time: 6.5718, average train loss: 0.7556
[11/30 03:54:06 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.5880, average loss: 0.8274
[11/30 03:54:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.77	
[11/30 03:54:06 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.4925739315689991
[11/30 04:01:16 visual_prompt]: Epoch 18 / 100: avg data time: 4.69e+00, avg batch time: 6.1435, average train loss: 0.8427
[11/30 04:02:06 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.5851, average loss: 0.9535
[11/30 04:02:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.84	
[11/30 04:02:06 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.4903154239845797
[11/30 04:09:18 visual_prompt]: Epoch 19 / 100: avg data time: 4.72e+00, avg batch time: 6.1758, average train loss: 0.8264
[11/30 04:10:09 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.5863, average loss: 0.6885
[11/30 04:10:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.56	
[11/30 04:10:09 visual_prompt]: Best epoch 19: best metric: -0.689
[11/30 04:10:09 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.4877641290737884
[11/30 04:17:28 visual_prompt]: Epoch 20 / 100: avg data time: 4.82e+00, avg batch time: 6.2708, average train loss: 0.8535
[11/30 04:18:18 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.5851, average loss: 0.6880
[11/30 04:18:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.41	
[11/30 04:18:18 visual_prompt]: Best epoch 20: best metric: -0.688
[11/30 04:18:18 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.4849231551964771
[11/30 04:25:36 visual_prompt]: Epoch 21 / 100: avg data time: 4.81e+00, avg batch time: 6.2668, average train loss: 0.7238
[11/30 04:26:26 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.5859, average loss: 1.0100
[11/30 04:26:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.40	
[11/30 04:26:26 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.48179596364169686
[11/30 04:33:41 visual_prompt]: Epoch 22 / 100: avg data time: 4.75e+00, avg batch time: 6.2088, average train loss: 0.7808
[11/30 04:34:30 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.5872, average loss: 0.8744
[11/30 04:34:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.01	
[11/30 04:34:30 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.4783863644106502
[11/30 04:41:42 visual_prompt]: Epoch 23 / 100: avg data time: 4.71e+00, avg batch time: 6.1638, average train loss: 0.7535
[11/30 04:42:31 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.5840, average loss: 1.0724
[11/30 04:42:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.22	
[11/30 04:42:31 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.47469851157479176
[11/30 04:49:41 visual_prompt]: Epoch 24 / 100: avg data time: 4.68e+00, avg batch time: 6.1341, average train loss: 0.7305
[11/30 04:50:30 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.5863, average loss: 0.6910
[11/30 04:50:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.36	
[11/30 04:50:30 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.47073689821473175
[11/30 04:57:49 visual_prompt]: Epoch 25 / 100: avg data time: 4.82e+00, avg batch time: 6.2696, average train loss: 0.7646
[11/30 04:58:40 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.5855, average loss: 0.7354
[11/30 04:58:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.28	
[11/30 04:58:40 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.4665063509461097
[11/30 05:05:58 visual_prompt]: Epoch 26 / 100: avg data time: 4.81e+00, avg batch time: 6.2666, average train loss: 0.8526
[11/30 05:06:49 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.5877, average loss: 1.0537
[11/30 05:06:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.66	
[11/30 05:06:49 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.46201202403910646
[11/30 05:14:05 visual_prompt]: Epoch 27 / 100: avg data time: 4.78e+00, avg batch time: 6.2290, average train loss: 0.8048
[11/30 05:14:54 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.5895, average loss: 0.9531
[11/30 05:14:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 42.50	
[11/30 05:14:54 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.4572593931387604
[11/30 05:22:06 visual_prompt]: Epoch 28 / 100: avg data time: 4.71e+00, avg batch time: 6.1610, average train loss: 0.8162
[11/30 05:22:55 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.5872, average loss: 0.9955
[11/30 05:22:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.38	
[11/30 05:22:55 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.45225424859373686
[11/30 05:30:05 visual_prompt]: Epoch 29 / 100: avg data time: 4.70e+00, avg batch time: 6.1470, average train loss: 0.7588
[11/30 05:30:55 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.5891, average loss: 1.0721
[11/30 05:30:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.06	
[11/30 05:30:55 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.44700268840168045
[11/30 05:38:13 visual_prompt]: Epoch 30 / 100: avg data time: 4.81e+00, avg batch time: 6.2632, average train loss: 0.7299
[11/30 05:39:03 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.5888, average loss: 0.8199
[11/30 05:39:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.34	
[11/30 05:39:03 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.4415111107797445
[11/30 05:46:20 visual_prompt]: Epoch 31 / 100: avg data time: 4.79e+00, avg batch time: 6.2468, average train loss: 0.7621
[11/30 05:47:11 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.5888, average loss: 0.7268
[11/30 05:47:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.42	
[11/30 05:47:11 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.43578620636934856
[11/30 05:54:30 visual_prompt]: Epoch 32 / 100: avg data time: 4.82e+00, avg batch time: 6.2689, average train loss: 0.7685
[11/30 05:55:20 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.5870, average loss: 0.8899
[11/30 05:55:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.62	
[11/30 05:55:20 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.42983495008466277
[11/30 06:02:35 visual_prompt]: Epoch 33 / 100: avg data time: 4.76e+00, avg batch time: 6.2097, average train loss: 0.7532
[11/30 06:03:24 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.5850, average loss: 0.6912
[11/30 06:03:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.70	
[11/30 06:03:24 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.4236645926147493
[11/30 06:10:38 visual_prompt]: Epoch 34 / 100: avg data time: 4.75e+00, avg batch time: 6.1990, average train loss: 0.8270
[11/30 06:11:28 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.5864, average loss: 1.1602
[11/30 06:11:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.30	
[11/30 06:11:28 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.41728265158971456
[11/30 06:18:48 visual_prompt]: Epoch 35 / 100: avg data time: 4.83e+00, avg batch time: 6.2790, average train loss: 0.8910
[11/30 06:19:38 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.5845, average loss: 0.6892
[11/30 06:19:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.77	
[11/30 06:19:38 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.4106969024216348
[11/30 06:26:59 visual_prompt]: Epoch 36 / 100: avg data time: 4.84e+00, avg batch time: 6.2901, average train loss: 0.7465
[11/30 06:27:49 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.5832, average loss: 0.9442
[11/30 06:27:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.88	
[11/30 06:27:49 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.40391536883141455
[11/30 06:35:09 visual_prompt]: Epoch 37 / 100: avg data time: 4.84e+00, avg batch time: 6.2911, average train loss: 0.7785
[11/30 06:35:59 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.5859, average loss: 0.7648
[11/30 06:35:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 45.63	
[11/30 06:35:59 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.3969463130731183
[11/30 06:43:19 visual_prompt]: Epoch 38 / 100: avg data time: 4.82e+00, avg batch time: 6.2747, average train loss: 0.7660
[11/30 06:44:09 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.5860, average loss: 0.7108
[11/30 06:44:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.11	
[11/30 06:44:09 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.3897982258676867
[11/30 06:51:25 visual_prompt]: Epoch 39 / 100: avg data time: 4.78e+00, avg batch time: 6.2280, average train loss: 0.9831
[11/30 06:52:14 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.5901, average loss: 0.7791
[11/30 06:52:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.45	
[11/30 06:52:14 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.3824798160583012
[11/30 06:59:16 visual_prompt]: Epoch 40 / 100: avg data time: 4.58e+00, avg batch time: 6.0337, average train loss: 0.7358
[11/30 07:00:04 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.5848, average loss: 0.6884
[11/30 07:00:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.04	
[11/30 07:00:04 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.375
[11/30 07:07:14 visual_prompt]: Epoch 41 / 100: avg data time: 4.69e+00, avg batch time: 6.1400, average train loss: 0.7263
[11/30 07:08:04 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.5849, average loss: 0.7577
[11/30 07:08:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.33	
[11/30 07:08:04 visual_prompt]: Stopping early.
[11/30 07:08:04 visual_prompt]: Rank of current process: 0. World size: 1
[11/30 07:08:04 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/30 07:08:04 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/30 07:08:04 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/30 07:08:04 visual_prompt]: Training with config:
[11/30 07:08:04 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr0.5_wd0.001/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/30 07:08:04 visual_prompt]: Loading training data...
[11/30 07:08:04 visual_prompt]: Constructing mammo-cbis dataset train...
[11/30 07:08:04 visual_prompt]: Loading validation data...
[11/30 07:08:04 visual_prompt]: Constructing mammo-cbis dataset val...
[11/30 07:08:04 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/30 07:08:06 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/30 07:08:06 visual_prompt]: tuned percent:0.532
[11/30 07:08:06 visual_prompt]: Device used for model: 0
[11/30 07:08:06 visual_prompt]: Setting up Evaluator...
[11/30 07:08:06 visual_prompt]: Setting up Trainer...
[11/30 07:08:06 visual_prompt]: 	Setting up the optimizer...
[11/30 07:08:06 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/30 07:15:24 visual_prompt]: Epoch 1 / 100: avg data time: 4.80e+00, avg batch time: 6.2539, average train loss: 1.4863
[11/30 07:16:15 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.5877, average loss: 1.4553
[11/30 07:16:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/30 07:16:15 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.05
[11/30 07:23:35 visual_prompt]: Epoch 2 / 100: avg data time: 4.84e+00, avg batch time: 6.2933, average train loss: 1.0889
[11/30 07:24:26 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.5881, average loss: 0.7247
[11/30 07:24:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.45	
[11/30 07:24:26 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.1
[11/30 07:31:48 visual_prompt]: Epoch 3 / 100: avg data time: 4.86e+00, avg batch time: 6.3088, average train loss: 0.7219
[11/30 07:32:38 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.5873, average loss: 0.8414
[11/30 07:32:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.48	
[11/30 07:32:38 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.15
[11/30 07:39:57 visual_prompt]: Epoch 4 / 100: avg data time: 4.82e+00, avg batch time: 6.2722, average train loss: 0.7836
[11/30 07:40:48 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.5893, average loss: 0.8061
[11/30 07:40:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.61	
[11/30 07:40:48 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.2
[11/30 07:48:07 visual_prompt]: Epoch 5 / 100: avg data time: 4.82e+00, avg batch time: 6.2746, average train loss: 0.8177
[11/30 07:48:57 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.5839, average loss: 0.6885
[11/30 07:48:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.74	
[11/30 07:48:57 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.25
[11/30 07:56:13 visual_prompt]: Epoch 6 / 100: avg data time: 4.78e+00, avg batch time: 6.2294, average train loss: 0.7580
[11/30 07:57:10 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.5864, average loss: 0.6742
[11/30 07:57:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 63.82	
[11/30 07:57:10 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.3
[11/30 08:04:22 visual_prompt]: Epoch 7 / 100: avg data time: 4.72e+00, avg batch time: 6.1759, average train loss: 0.7373
[11/30 08:05:12 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.5866, average loss: 1.7252
[11/30 08:05:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.26	
[11/30 08:05:12 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.35
[11/30 08:12:32 visual_prompt]: Epoch 8 / 100: avg data time: 4.84e+00, avg batch time: 6.2847, average train loss: 0.7694
[11/30 08:13:23 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.5874, average loss: 1.1083
[11/30 08:13:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.02	
[11/30 08:13:23 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.4
[11/30 08:20:43 visual_prompt]: Epoch 9 / 100: avg data time: 4.83e+00, avg batch time: 6.2864, average train loss: 0.8029
[11/30 08:21:33 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.5841, average loss: 0.6786
[11/30 08:21:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.02	
[11/30 08:21:33 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.45
[11/30 08:28:52 visual_prompt]: Epoch 10 / 100: avg data time: 4.82e+00, avg batch time: 6.2708, average train loss: 0.7228
[11/30 08:29:42 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.5878, average loss: 0.7685
[11/30 08:29:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.08	
[11/30 08:29:42 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.5
[11/30 08:37:02 visual_prompt]: Epoch 11 / 100: avg data time: 4.84e+00, avg batch time: 6.2870, average train loss: 0.7622
[11/30 08:37:52 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.5880, average loss: 0.7761
[11/30 08:37:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.23	
[11/30 08:37:52 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.49984770675477397
[11/30 08:45:12 visual_prompt]: Epoch 12 / 100: avg data time: 4.82e+00, avg batch time: 6.2716, average train loss: 0.7614
[11/30 08:46:02 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.5841, average loss: 0.7236
[11/30 08:46:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 62.74	
[11/30 08:46:02 visual_prompt]: Best epoch 12: best metric: -0.724
[11/30 08:46:02 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.49939101256495605
[11/30 08:53:17 visual_prompt]: Epoch 13 / 100: avg data time: 4.77e+00, avg batch time: 6.2172, average train loss: 0.7759
[11/30 08:54:07 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.5859, average loss: 0.7158
[11/30 08:54:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.96	
[11/30 08:54:07 visual_prompt]: Best epoch 13: best metric: -0.716
[11/30 08:54:07 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.4986304738420683
[11/30 09:01:19 visual_prompt]: Epoch 14 / 100: avg data time: 4.72e+00, avg batch time: 6.1753, average train loss: 0.7538
[11/30 09:02:09 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.5875, average loss: 0.7155
[11/30 09:02:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.32	
[11/30 09:02:09 visual_prompt]: Best epoch 14: best metric: -0.716
[11/30 09:02:09 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.4975670171853926
[11/30 09:09:18 visual_prompt]: Epoch 15 / 100: avg data time: 4.68e+00, avg batch time: 6.1297, average train loss: 0.7450
[11/30 09:10:07 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.5850, average loss: 0.7131
[11/30 09:10:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.61	
[11/30 09:10:07 visual_prompt]: Best epoch 15: best metric: -0.713
[11/30 09:10:07 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.49620193825305203
[11/30 09:17:26 visual_prompt]: Epoch 16 / 100: avg data time: 4.81e+00, avg batch time: 6.2592, average train loss: 0.7322
[11/30 09:18:16 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.5828, average loss: 0.9053
[11/30 09:18:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.49	
[11/30 09:18:16 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.4945369001834514
[11/30 09:25:34 visual_prompt]: Epoch 17 / 100: avg data time: 4.81e+00, avg batch time: 6.2638, average train loss: 0.7835
[11/30 09:26:24 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.5873, average loss: 0.8792
[11/30 09:26:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.69	
[11/30 09:26:24 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.4925739315689991
[11/30 09:33:40 visual_prompt]: Epoch 18 / 100: avg data time: 4.77e+00, avg batch time: 6.2190, average train loss: 0.7829
[11/30 09:34:29 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.5884, average loss: 0.8792
[11/30 09:34:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.64	
[11/30 09:34:29 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.4903154239845797
[11/30 09:41:41 visual_prompt]: Epoch 19 / 100: avg data time: 4.71e+00, avg batch time: 6.1623, average train loss: 0.7793
[11/30 09:42:30 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.5862, average loss: 0.7425
[11/30 09:42:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.46	
[11/30 09:42:30 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.4877641290737884
[11/30 09:49:42 visual_prompt]: Epoch 20 / 100: avg data time: 4.72e+00, avg batch time: 6.1678, average train loss: 0.7126
[11/30 09:50:32 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.5858, average loss: 0.6826
[11/30 09:50:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.20	
[11/30 09:50:32 visual_prompt]: Best epoch 20: best metric: -0.683
[11/30 09:50:32 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.4849231551964771
[11/30 09:57:51 visual_prompt]: Epoch 21 / 100: avg data time: 4.82e+00, avg batch time: 6.2699, average train loss: 0.7119
[11/30 09:58:41 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.5890, average loss: 0.6854
[11/30 09:58:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 61.80	
[11/30 09:58:41 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.48179596364169686
[11/30 10:06:00 visual_prompt]: Epoch 22 / 100: avg data time: 4.81e+00, avg batch time: 6.2593, average train loss: 0.7526
[11/30 10:06:50 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.5860, average loss: 0.9010
[11/30 10:06:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.97	
[11/30 10:06:50 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.4783863644106502
[11/30 10:14:06 visual_prompt]: Epoch 23 / 100: avg data time: 4.77e+00, avg batch time: 6.2229, average train loss: 0.8169
[11/30 10:14:54 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.5857, average loss: 0.8924
[11/30 10:14:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.24	
[11/30 10:14:54 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.47469851157479176
[11/30 10:21:57 visual_prompt]: Epoch 24 / 100: avg data time: 4.58e+00, avg batch time: 6.0380, average train loss: 0.7557
[11/30 10:22:46 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.5848, average loss: 0.6873
[11/30 10:22:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 62.08	
[11/30 10:22:46 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.47073689821473175
[11/30 10:29:51 visual_prompt]: Epoch 25 / 100: avg data time: 4.63e+00, avg batch time: 6.0805, average train loss: 0.7295
[11/30 10:30:41 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.5881, average loss: 0.6772
[11/30 10:30:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 64.99	
[11/30 10:30:41 visual_prompt]: Best epoch 25: best metric: -0.677
[11/30 10:30:41 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.4665063509461097
[11/30 10:37:51 visual_prompt]: Epoch 26 / 100: avg data time: 4.70e+00, avg batch time: 6.1502, average train loss: 0.7363
[11/30 10:38:42 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.5878, average loss: 0.7935
[11/30 10:38:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.30	
[11/30 10:38:42 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.46201202403910646
[11/30 10:46:01 visual_prompt]: Epoch 27 / 100: avg data time: 4.82e+00, avg batch time: 6.2698, average train loss: 0.7015
[11/30 10:46:52 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.5847, average loss: 0.6977
[11/30 10:46:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 62.49	
[11/30 10:46:52 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.4572593931387604
[11/30 10:54:22 visual_prompt]: Epoch 28 / 100: avg data time: 4.98e+00, avg batch time: 6.4266, average train loss: 0.7252
[11/30 10:55:12 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.5862, average loss: 0.6889
[11/30 10:55:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.72	
[11/30 10:55:12 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.45225424859373686
[11/30 11:02:35 visual_prompt]: Epoch 29 / 100: avg data time: 4.87e+00, avg batch time: 6.3266, average train loss: 0.7129
[11/30 11:03:26 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.5849, average loss: 0.7465
[11/30 11:03:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.58	
[11/30 11:03:26 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.44700268840168045
[11/30 11:11:37 visual_prompt]: Epoch 30 / 100: avg data time: 5.57e+00, avg batch time: 7.0224, average train loss: 0.7191
[11/30 11:12:35 visual_prompt]: Inference (val):avg data time: 3.74e-05, avg batch time: 0.5833, average loss: 0.8272
[11/30 11:12:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.31	
[11/30 11:12:35 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.4415111107797445
[11/30 11:21:06 visual_prompt]: Epoch 31 / 100: avg data time: 5.85e+00, avg batch time: 7.3018, average train loss: 0.7088
[11/30 11:22:03 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.5909, average loss: 0.6902
[11/30 11:22:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.13	
[11/30 11:22:03 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.43578620636934856
[11/30 11:30:24 visual_prompt]: Epoch 32 / 100: avg data time: 5.70e+00, avg batch time: 7.1529, average train loss: 0.7403
[11/30 11:31:21 visual_prompt]: Inference (val):avg data time: 3.93e-05, avg batch time: 0.5863, average loss: 0.8600
[11/30 11:31:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.96	
[11/30 11:31:21 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.42983495008466277
[11/30 11:39:40 visual_prompt]: Epoch 33 / 100: avg data time: 5.67e+00, avg batch time: 7.1210, average train loss: 0.7203
[11/30 11:40:37 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.5886, average loss: 0.6888
[11/30 11:40:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 60.78	
[11/30 11:40:37 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.4236645926147493
[11/30 11:48:52 visual_prompt]: Epoch 34 / 100: avg data time: 5.63e+00, avg batch time: 7.0825, average train loss: 0.7136
[11/30 11:49:50 visual_prompt]: Inference (val):avg data time: 3.54e-05, avg batch time: 0.5873, average loss: 0.6986
[11/30 11:49:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.36	
[11/30 11:49:50 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.41728265158971456
[11/30 11:58:06 visual_prompt]: Epoch 35 / 100: avg data time: 5.65e+00, avg batch time: 7.0976, average train loss: 0.7147
[11/30 11:59:03 visual_prompt]: Inference (val):avg data time: 3.58e-05, avg batch time: 0.5873, average loss: 0.7499
[11/30 11:59:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.63	
[11/30 11:59:03 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.4106969024216348
[11/30 12:07:22 visual_prompt]: Epoch 36 / 100: avg data time: 5.68e+00, avg batch time: 7.1268, average train loss: 0.7125
[11/30 12:08:19 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.5848, average loss: 0.6890
[11/30 12:08:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 60.34	
[11/30 12:08:19 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.40391536883141455
[11/30 12:16:36 visual_prompt]: Epoch 37 / 100: avg data time: 5.64e+00, avg batch time: 7.0951, average train loss: 0.7257
[11/30 12:17:33 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.5914, average loss: 0.7514
[11/30 12:17:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.71	
[11/30 12:17:33 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.3969463130731183
[11/30 12:25:50 visual_prompt]: Epoch 38 / 100: avg data time: 5.65e+00, avg batch time: 7.1021, average train loss: 0.7024
[11/30 12:26:47 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.5861, average loss: 0.6758
[11/30 12:26:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 58.01	
[11/30 12:26:47 visual_prompt]: Best epoch 38: best metric: -0.676
[11/30 12:26:47 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.3897982258676867
[11/30 12:35:08 visual_prompt]: Epoch 39 / 100: avg data time: 5.69e+00, avg batch time: 7.1481, average train loss: 0.7164
[11/30 12:36:05 visual_prompt]: Inference (val):avg data time: 3.43e-05, avg batch time: 0.5852, average loss: 0.7275
[11/30 12:36:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.31	
[11/30 12:36:05 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.3824798160583012
[11/30 12:44:22 visual_prompt]: Epoch 40 / 100: avg data time: 5.64e+00, avg batch time: 7.0948, average train loss: 0.7100
[11/30 12:45:19 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.5880, average loss: 0.7220
[11/30 12:45:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.44	
[11/30 12:45:19 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.375
[11/30 12:53:35 visual_prompt]: Epoch 41 / 100: avg data time: 5.64e+00, avg batch time: 7.0889, average train loss: 0.7213
[11/30 12:54:32 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.5883, average loss: 0.8634
[11/30 12:54:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.46	
[11/30 12:54:32 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.3673678906964727
[11/30 13:02:49 visual_prompt]: Epoch 42 / 100: avg data time: 5.65e+00, avg batch time: 7.1041, average train loss: 0.7201
[11/30 13:03:46 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.5900, average loss: 0.6875
[11/30 13:03:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.03	
[11/30 13:03:46 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.35959278669726935
[11/30 13:12:04 visual_prompt]: Epoch 43 / 100: avg data time: 5.65e+00, avg batch time: 7.1039, average train loss: 0.7456
[11/30 13:13:01 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.5872, average loss: 0.7035
[11/30 13:13:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.30	
[11/30 13:13:01 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.3516841607689501
[11/30 13:21:19 visual_prompt]: Epoch 44 / 100: avg data time: 5.67e+00, avg batch time: 7.1231, average train loss: 0.7153
[11/30 13:22:16 visual_prompt]: Inference (val):avg data time: 3.65e-05, avg batch time: 0.5871, average loss: 0.6854
[11/30 13:22:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 60.85	
[11/30 13:22:16 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.34365164835397805
[11/30 13:30:35 visual_prompt]: Epoch 45 / 100: avg data time: 5.67e+00, avg batch time: 7.1219, average train loss: 0.7200
[11/30 13:31:32 visual_prompt]: Inference (val):avg data time: 3.48e-05, avg batch time: 0.5850, average loss: 0.6873
[11/30 13:31:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.62	
[11/30 13:31:32 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.3355050358314172
[11/30 13:39:51 visual_prompt]: Epoch 46 / 100: avg data time: 5.67e+00, avg batch time: 7.1262, average train loss: 0.7171
[11/30 13:40:48 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.5855, average loss: 0.7302
[11/30 13:40:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.67	
[11/30 13:40:48 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.32725424859373686
[11/30 13:49:10 visual_prompt]: Epoch 47 / 100: avg data time: 5.70e+00, avg batch time: 7.1570, average train loss: 0.7280
[11/30 13:50:06 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.5884, average loss: 0.7229
[11/30 13:50:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.61	
[11/30 13:50:06 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.3189093389542498
[11/30 13:58:24 visual_prompt]: Epoch 48 / 100: avg data time: 5.65e+00, avg batch time: 7.1027, average train loss: 0.7174
[11/30 13:59:21 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.5898, average loss: 0.6994
[11/30 13:59:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.93	
[11/30 13:59:21 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.3104804738999169
[11/30 14:07:38 visual_prompt]: Epoch 49 / 100: avg data time: 5.65e+00, avg batch time: 7.1085, average train loss: 0.7036
[11/30 14:08:35 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.5881, average loss: 0.6869
[11/30 14:08:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.10	
[11/30 14:08:35 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.3019779227044398
[11/30 14:16:55 visual_prompt]: Epoch 50 / 100: avg data time: 5.69e+00, avg batch time: 7.1430, average train loss: 0.7272
[11/30 14:17:53 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.5856, average loss: 0.9267
[11/30 14:17:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.26	
[11/30 14:17:53 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.29341204441673263
[11/30 14:26:13 visual_prompt]: Epoch 51 / 100: avg data time: 5.69e+00, avg batch time: 7.1428, average train loss: 0.7200
[11/30 14:27:10 visual_prompt]: Inference (val):avg data time: 4.10e-05, avg batch time: 0.5893, average loss: 0.7696
[11/30 14:27:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.26	
[11/30 14:27:10 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.28479327524001635
[11/30 14:35:30 visual_prompt]: Epoch 52 / 100: avg data time: 5.68e+00, avg batch time: 7.1298, average train loss: 0.7037
[11/30 14:36:27 visual_prompt]: Inference (val):avg data time: 3.23e-05, avg batch time: 0.5862, average loss: 0.7411
[11/30 14:36:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.82	
[11/30 14:36:27 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.2761321158169134
[11/30 14:44:46 visual_prompt]: Epoch 53 / 100: avg data time: 5.67e+00, avg batch time: 7.1256, average train loss: 0.7169
[11/30 14:45:43 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.5868, average loss: 0.6890
[11/30 14:45:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.98	
[11/30 14:45:43 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.2674391184360313
[11/30 14:53:59 visual_prompt]: Epoch 54 / 100: avg data time: 5.64e+00, avg batch time: 7.0910, average train loss: 0.7059
[11/30 14:54:56 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.5851, average loss: 0.7519
[11/30 14:54:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.75	
[11/30 14:54:56 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.2587248741756253
[11/30 15:03:14 visual_prompt]: Epoch 55 / 100: avg data time: 5.67e+00, avg batch time: 7.1203, average train loss: 0.7153
[11/30 15:04:11 visual_prompt]: Inference (val):avg data time: 3.98e-05, avg batch time: 0.5855, average loss: 0.7024
[11/30 15:04:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.97	
[11/30 15:04:11 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.25
[11/30 15:12:30 visual_prompt]: Epoch 56 / 100: avg data time: 5.66e+00, avg batch time: 7.1141, average train loss: 0.7153
[11/30 15:13:27 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.5847, average loss: 0.7652
[11/30 15:13:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.32	
[11/30 15:13:27 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.24127512582437483
[11/30 15:21:46 visual_prompt]: Epoch 57 / 100: avg data time: 5.68e+00, avg batch time: 7.1256, average train loss: 0.7080
[11/30 15:22:43 visual_prompt]: Inference (val):avg data time: 3.66e-05, avg batch time: 0.5859, average loss: 0.7795
[11/30 15:22:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.96	
[11/30 15:22:43 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.23256088156396867
[11/30 15:31:00 visual_prompt]: Epoch 58 / 100: avg data time: 5.65e+00, avg batch time: 7.1031, average train loss: 0.7036
[11/30 15:31:57 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.5897, average loss: 0.6841
[11/30 15:31:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 61.21	
[11/30 15:31:57 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.22386788418308667
[11/30 15:40:14 visual_prompt]: Epoch 59 / 100: avg data time: 5.65e+00, avg batch time: 7.1055, average train loss: 0.7108
[11/30 15:41:11 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.5877, average loss: 0.6901
[11/30 15:41:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.02	
[11/30 15:41:11 visual_prompt]: Stopping early.
[11/30 15:41:11 visual_prompt]: Rank of current process: 0. World size: 1
[11/30 15:41:11 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/30 15:41:11 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/30 15:41:11 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/30 15:41:11 visual_prompt]: Training with config:
[11/30 15:41:11 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr0.5_wd0.0001/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/30 15:41:11 visual_prompt]: Loading training data...
[11/30 15:41:11 visual_prompt]: Constructing mammo-cbis dataset train...
[11/30 15:41:11 visual_prompt]: Loading validation data...
[11/30 15:41:11 visual_prompt]: Constructing mammo-cbis dataset val...
[11/30 15:41:11 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/30 15:41:14 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/30 15:41:14 visual_prompt]: tuned percent:0.532
[11/30 15:41:14 visual_prompt]: Device used for model: 0
[11/30 15:41:14 visual_prompt]: Setting up Evaluator...
[11/30 15:41:14 visual_prompt]: Setting up Trainer...
[11/30 15:41:14 visual_prompt]: 	Setting up the optimizer...
[11/30 15:41:14 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/30 15:49:32 visual_prompt]: Epoch 1 / 100: avg data time: 5.66e+00, avg batch time: 7.1070, average train loss: 1.4863
[11/30 15:50:28 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.5892, average loss: 1.4553
[11/30 15:50:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/30 15:50:28 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.05
[11/30 15:58:47 visual_prompt]: Epoch 2 / 100: avg data time: 5.67e+00, avg batch time: 7.1198, average train loss: 1.0902
[11/30 15:59:44 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.5850, average loss: 0.7249
[11/30 15:59:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.43	
[11/30 15:59:44 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.1
[11/30 16:08:02 visual_prompt]: Epoch 3 / 100: avg data time: 5.66e+00, avg batch time: 7.1155, average train loss: 0.7235
[11/30 16:08:59 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.5856, average loss: 0.8395
[11/30 16:08:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.53	
[11/30 16:08:59 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.15
[11/30 16:17:15 visual_prompt]: Epoch 4 / 100: avg data time: 5.63e+00, avg batch time: 7.0828, average train loss: 0.7893
[11/30 16:18:12 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.5891, average loss: 0.8533
[11/30 16:18:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.83	
[11/30 16:18:12 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.2
[11/30 16:26:27 visual_prompt]: Epoch 5 / 100: avg data time: 5.62e+00, avg batch time: 7.0724, average train loss: 0.8105
[11/30 16:27:24 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.5885, average loss: 0.7082
[11/30 16:27:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.47	
[11/30 16:27:24 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.25
[11/30 16:35:42 visual_prompt]: Epoch 6 / 100: avg data time: 5.66e+00, avg batch time: 7.1141, average train loss: 0.7664
[11/30 16:36:39 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.5887, average loss: 0.6719
[11/30 16:36:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.28	
[11/30 16:36:39 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.3
[11/30 16:44:53 visual_prompt]: Epoch 7 / 100: avg data time: 5.61e+00, avg batch time: 7.0666, average train loss: 0.7331
[11/30 16:45:50 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.5866, average loss: 1.1880
[11/30 16:45:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.68	
[11/30 16:45:50 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.35
[11/30 16:54:04 visual_prompt]: Epoch 8 / 100: avg data time: 5.60e+00, avg batch time: 7.0519, average train loss: 0.7783
[11/30 16:55:00 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.5870, average loss: 1.4210
[11/30 16:55:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.70	
[11/30 16:55:00 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.4
[11/30 17:03:13 visual_prompt]: Epoch 9 / 100: avg data time: 5.58e+00, avg batch time: 7.0350, average train loss: 0.8966
[11/30 17:04:09 visual_prompt]: Inference (val):avg data time: 3.53e-05, avg batch time: 0.5842, average loss: 0.6636
[11/30 17:04:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 64.04	
[11/30 17:04:09 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.45
[11/30 17:12:22 visual_prompt]: Epoch 10 / 100: avg data time: 5.59e+00, avg batch time: 7.0402, average train loss: 0.7290
[11/30 17:13:19 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.5869, average loss: 0.8045
[11/30 17:13:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 65.91	
[11/30 17:13:19 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.5
[11/30 17:21:38 visual_prompt]: Epoch 11 / 100: avg data time: 5.68e+00, avg batch time: 7.1288, average train loss: 0.7937
[11/30 17:22:35 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.5866, average loss: 1.1487
[11/30 17:22:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 67.00	
[11/30 17:22:35 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.49984770675477397
[11/30 17:30:53 visual_prompt]: Epoch 12 / 100: avg data time: 5.66e+00, avg batch time: 7.1160, average train loss: 0.7618
[11/30 17:31:50 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.5851, average loss: 0.6465
[11/30 17:31:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 69.15	
[11/30 17:31:50 visual_prompt]: Best epoch 12: best metric: -0.647
[11/30 17:31:50 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.49939101256495605
[11/30 17:40:10 visual_prompt]: Epoch 13 / 100: avg data time: 5.68e+00, avg batch time: 7.1275, average train loss: 0.7177
[11/30 17:41:06 visual_prompt]: Inference (val):avg data time: 3.96e-05, avg batch time: 0.5883, average loss: 0.7420
[11/30 17:41:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 67.91	
[11/30 17:41:06 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.4986304738420683
[11/30 17:49:24 visual_prompt]: Epoch 14 / 100: avg data time: 5.65e+00, avg batch time: 7.1069, average train loss: 0.6855
[11/30 17:50:21 visual_prompt]: Inference (val):avg data time: 3.94e-05, avg batch time: 0.5853, average loss: 0.7182
[11/30 17:50:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 71.02	
[11/30 17:50:21 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.4975670171853926
[11/30 17:58:36 visual_prompt]: Epoch 15 / 100: avg data time: 5.62e+00, avg batch time: 7.0720, average train loss: 0.7269
[11/30 17:59:33 visual_prompt]: Inference (val):avg data time: 4.32e-05, avg batch time: 0.5911, average loss: 0.6450
[11/30 17:59:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 70.20	
[11/30 17:59:33 visual_prompt]: Best epoch 15: best metric: -0.645
[11/30 17:59:33 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.49620193825305203
[11/30 18:07:49 visual_prompt]: Epoch 16 / 100: avg data time: 5.63e+00, avg batch time: 7.0829, average train loss: 0.7688
[11/30 18:08:45 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.5920, average loss: 0.7389
[11/30 18:08:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.93	rocauc: 65.84	
[11/30 18:08:45 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.4945369001834514
[11/30 18:17:01 visual_prompt]: Epoch 17 / 100: avg data time: 5.62e+00, avg batch time: 7.0747, average train loss: 0.7174
[11/30 18:17:57 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.5870, average loss: 0.8170
[11/30 18:17:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 70.48	
[11/30 18:17:57 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.4925739315689991
[11/30 18:26:11 visual_prompt]: Epoch 18 / 100: avg data time: 5.59e+00, avg batch time: 7.0473, average train loss: 0.7280
[11/30 18:27:07 visual_prompt]: Inference (val):avg data time: 3.43e-05, avg batch time: 0.5857, average loss: 1.0515
[11/30 18:27:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 70.65	
[11/30 18:27:07 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.4903154239845797
[11/30 18:35:20 visual_prompt]: Epoch 19 / 100: avg data time: 5.59e+00, avg batch time: 7.0380, average train loss: 0.7665
[11/30 18:36:16 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.5841, average loss: 0.7208
[11/30 18:36:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 72.37	
[11/30 18:36:16 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.4877641290737884
[11/30 18:44:33 visual_prompt]: Epoch 20 / 100: avg data time: 5.64e+00, avg batch time: 7.0891, average train loss: 0.6482
[11/30 18:45:30 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.5866, average loss: 0.6210
[11/30 18:45:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 70.33	rocauc: 73.19	
[11/30 18:45:30 visual_prompt]: Best epoch 20: best metric: -0.621
[11/30 18:45:30 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.4849231551964771
[11/30 18:53:49 visual_prompt]: Epoch 21 / 100: avg data time: 5.67e+00, avg batch time: 7.1242, average train loss: 0.6475
[11/30 18:54:46 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.5902, average loss: 0.9763
[11/30 18:54:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 73.13	
[11/30 18:54:46 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.48179596364169686
[11/30 19:03:04 visual_prompt]: Epoch 22 / 100: avg data time: 5.65e+00, avg batch time: 7.1062, average train loss: 0.6757
[11/30 19:04:00 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.5895, average loss: 0.8792
[11/30 19:04:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 73.96	
[11/30 19:04:00 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.4783863644106502
[11/30 19:12:17 visual_prompt]: Epoch 23 / 100: avg data time: 5.64e+00, avg batch time: 7.0900, average train loss: 0.6603
[11/30 19:13:13 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.5878, average loss: 1.1808
[11/30 19:13:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 72.05	
[11/30 19:13:13 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.47469851157479176
[11/30 19:21:29 visual_prompt]: Epoch 24 / 100: avg data time: 5.63e+00, avg batch time: 7.0826, average train loss: 0.6834
[11/30 19:22:26 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.5906, average loss: 0.6618
[11/30 19:22:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 71.24	
[11/30 19:22:26 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.47073689821473175
[11/30 19:30:45 visual_prompt]: Epoch 25 / 100: avg data time: 5.67e+00, avg batch time: 7.1248, average train loss: 0.6908
[11/30 19:31:42 visual_prompt]: Inference (val):avg data time: 3.79e-05, avg batch time: 0.5863, average loss: 0.7300
[11/30 19:31:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 74.09	
[11/30 19:31:42 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.4665063509461097
[11/30 19:39:59 visual_prompt]: Epoch 26 / 100: avg data time: 5.64e+00, avg batch time: 7.0964, average train loss: 0.6515
[11/30 19:40:56 visual_prompt]: Inference (val):avg data time: 3.59e-05, avg batch time: 0.5863, average loss: 0.6007
[11/30 19:40:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 71.54	rocauc: 73.94	
[11/30 19:40:56 visual_prompt]: Best epoch 26: best metric: -0.601
[11/30 19:40:56 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.46201202403910646
[11/30 19:49:12 visual_prompt]: Epoch 27 / 100: avg data time: 5.63e+00, avg batch time: 7.0800, average train loss: 0.6220
[11/30 19:50:09 visual_prompt]: Inference (val):avg data time: 3.92e-05, avg batch time: 0.5855, average loss: 0.6727
[11/30 19:50:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 76.09	
[11/30 19:50:09 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.4572593931387604
[11/30 19:58:25 visual_prompt]: Epoch 28 / 100: avg data time: 5.64e+00, avg batch time: 7.0932, average train loss: 0.6932
[11/30 19:59:22 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.5891, average loss: 0.7420
[11/30 19:59:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 75.80	
[11/30 19:59:22 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.45225424859373686
[11/30 20:07:36 visual_prompt]: Epoch 29 / 100: avg data time: 5.61e+00, avg batch time: 7.0649, average train loss: 0.6056
[11/30 20:08:33 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.5905, average loss: 0.6275
[11/30 20:08:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 75.67	
[11/30 20:08:33 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.44700268840168045
[11/30 20:16:52 visual_prompt]: Epoch 30 / 100: avg data time: 5.66e+00, avg batch time: 7.1159, average train loss: 0.5842
[11/30 20:17:49 visual_prompt]: Inference (val):avg data time: 3.54e-05, avg batch time: 0.5884, average loss: 1.5055
[11/30 20:17:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 46.34	rocauc: 72.48	
[11/30 20:17:49 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.4415111107797445
[11/30 20:26:06 visual_prompt]: Epoch 31 / 100: avg data time: 5.65e+00, avg batch time: 7.1015, average train loss: 0.6911
[11/30 20:27:03 visual_prompt]: Inference (val):avg data time: 3.86e-05, avg batch time: 0.5883, average loss: 0.6117
[11/30 20:27:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 69.11	rocauc: 74.46	
[11/30 20:27:03 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.43578620636934856
[11/30 20:35:20 visual_prompt]: Epoch 32 / 100: avg data time: 5.65e+00, avg batch time: 7.1071, average train loss: 0.6841
[11/30 20:36:17 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.5887, average loss: 1.1420
[11/30 20:36:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 72.26	
[11/30 20:36:17 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.42983495008466277
[11/30 20:44:32 visual_prompt]: Epoch 33 / 100: avg data time: 5.62e+00, avg batch time: 7.0727, average train loss: 0.6362
[11/30 20:45:29 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.5879, average loss: 0.6317
[11/30 20:45:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 69.51	rocauc: 74.48	
[11/30 20:45:29 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.4236645926147493
[11/30 20:53:44 visual_prompt]: Epoch 34 / 100: avg data time: 5.61e+00, avg batch time: 7.0645, average train loss: 0.6442
[11/30 20:54:40 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.5883, average loss: 0.6702
[11/30 20:54:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 74.03	
[11/30 20:54:40 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.41728265158971456
[11/30 21:02:56 visual_prompt]: Epoch 35 / 100: avg data time: 5.63e+00, avg batch time: 7.0799, average train loss: 0.5889
[11/30 21:03:53 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.5878, average loss: 0.6170
[11/30 21:03:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 71.54	rocauc: 74.47	
[11/30 21:03:53 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.4106969024216348
[11/30 21:12:11 visual_prompt]: Epoch 36 / 100: avg data time: 5.66e+00, avg batch time: 7.1123, average train loss: 0.5843
[11/30 21:13:08 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.5860, average loss: 1.2020
[11/30 21:13:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 49.19	rocauc: 74.43	
[11/30 21:13:08 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.40391536883141455
[11/30 21:21:23 visual_prompt]: Epoch 37 / 100: avg data time: 5.61e+00, avg batch time: 7.0649, average train loss: 0.6478
[11/30 21:22:20 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.5844, average loss: 0.7317
[11/30 21:22:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 74.28	
[11/30 21:22:20 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.3969463130731183
[11/30 21:30:35 visual_prompt]: Epoch 38 / 100: avg data time: 5.63e+00, avg batch time: 7.0794, average train loss: 0.5724
[11/30 21:31:32 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.5849, average loss: 0.6365
[11/30 21:31:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 68.29	rocauc: 73.94	
[11/30 21:31:32 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.3897982258676867
[11/30 21:39:49 visual_prompt]: Epoch 39 / 100: avg data time: 5.64e+00, avg batch time: 7.0918, average train loss: 0.5634
[11/30 21:40:46 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.5912, average loss: 0.7090
[11/30 21:40:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.67	rocauc: 72.80	
[11/30 21:40:46 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.3824798160583012
[11/30 21:49:02 visual_prompt]: Epoch 40 / 100: avg data time: 5.64e+00, avg batch time: 7.0903, average train loss: 0.6224
[11/30 21:49:59 visual_prompt]: Inference (val):avg data time: 3.50e-05, avg batch time: 0.5902, average loss: 0.9828
[11/30 21:49:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 49.59	rocauc: 73.65	
[11/30 21:49:59 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.375
[11/30 21:58:17 visual_prompt]: Epoch 41 / 100: avg data time: 5.66e+00, avg batch time: 7.1114, average train loss: 0.5899
[11/30 21:59:14 visual_prompt]: Inference (val):avg data time: 3.61e-05, avg batch time: 0.5854, average loss: 0.7612
[11/30 21:59:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 71.99	
[11/30 21:59:14 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.3673678906964727
[11/30 22:07:32 visual_prompt]: Epoch 42 / 100: avg data time: 5.65e+00, avg batch time: 7.1089, average train loss: 0.5473
[11/30 22:08:29 visual_prompt]: Inference (val):avg data time: 4.17e-05, avg batch time: 0.5970, average loss: 0.6148
[11/30 22:08:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.07	rocauc: 74.45	
[11/30 22:08:29 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.35959278669726935
[11/30 22:16:45 visual_prompt]: Epoch 43 / 100: avg data time: 5.63e+00, avg batch time: 7.0878, average train loss: 0.5674
[11/30 22:17:42 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.5875, average loss: 0.6081
[11/30 22:17:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 71.14	rocauc: 73.91	
[11/30 22:17:42 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.3516841607689501
[11/30 22:26:00 visual_prompt]: Epoch 44 / 100: avg data time: 5.66e+00, avg batch time: 7.1138, average train loss: 0.5809
[11/30 22:26:57 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.5873, average loss: 0.6708
[11/30 22:26:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 71.89	
[11/30 22:26:57 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.34365164835397805
[11/30 22:35:13 visual_prompt]: Epoch 45 / 100: avg data time: 5.63e+00, avg batch time: 7.0859, average train loss: 0.5514
[11/30 22:36:10 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.5883, average loss: 0.7234
[11/30 22:36:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 74.39	
[11/30 22:36:10 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.3355050358314172
[11/30 22:44:25 visual_prompt]: Epoch 46 / 100: avg data time: 5.62e+00, avg batch time: 7.0764, average train loss: 0.5194
[11/30 22:45:22 visual_prompt]: Inference (val):avg data time: 4.51e-05, avg batch time: 0.5889, average loss: 0.6551
[11/30 22:45:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.89	rocauc: 76.75	
[11/30 22:45:22 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.32725424859373686
[11/30 22:53:39 visual_prompt]: Epoch 47 / 100: avg data time: 5.65e+00, avg batch time: 7.0986, average train loss: 0.5439
[11/30 22:54:36 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.5885, average loss: 0.8558
[11/30 22:54:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 71.35	
[11/30 22:54:36 visual_prompt]: Stopping early.
[11/30 22:54:36 visual_prompt]: Rank of current process: 0. World size: 1
[11/30 22:54:36 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/30 22:54:36 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/30 22:54:36 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/30 22:54:36 visual_prompt]: Training with config:
[11/30 22:54:36 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr0.5_wd0.0/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/30 22:54:36 visual_prompt]: Loading training data...
[11/30 22:54:36 visual_prompt]: Constructing mammo-cbis dataset train...
[11/30 22:54:36 visual_prompt]: Loading validation data...
[11/30 22:54:36 visual_prompt]: Constructing mammo-cbis dataset val...
[11/30 22:54:36 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/30 22:54:39 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/30 22:54:39 visual_prompt]: tuned percent:0.532
[11/30 22:54:39 visual_prompt]: Device used for model: 0
[11/30 22:54:39 visual_prompt]: Setting up Evaluator...
[11/30 22:54:39 visual_prompt]: Setting up Trainer...
[11/30 22:54:39 visual_prompt]: 	Setting up the optimizer...
[11/30 22:54:39 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/30 23:02:58 visual_prompt]: Epoch 1 / 100: avg data time: 5.67e+00, avg batch time: 7.1289, average train loss: 1.4863
[11/30 23:03:55 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.5896, average loss: 1.4553
[11/30 23:03:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/30 23:03:55 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.05
[11/30 23:12:14 visual_prompt]: Epoch 2 / 100: avg data time: 5.67e+00, avg batch time: 7.1201, average train loss: 1.0903
[11/30 23:13:11 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.5905, average loss: 0.7250
[11/30 23:13:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.42	
[11/30 23:13:11 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.1
[11/30 23:21:27 visual_prompt]: Epoch 3 / 100: avg data time: 5.63e+00, avg batch time: 7.0814, average train loss: 0.7237
[11/30 23:22:23 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.5933, average loss: 0.8399
[11/30 23:22:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.60	
[11/30 23:22:24 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.15
[11/30 23:30:39 visual_prompt]: Epoch 4 / 100: avg data time: 5.63e+00, avg batch time: 7.0827, average train loss: 0.7933
[11/30 23:31:36 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.5894, average loss: 0.8096
[11/30 23:31:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.88	
[11/30 23:31:36 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.2
[11/30 23:39:49 visual_prompt]: Epoch 5 / 100: avg data time: 5.59e+00, avg batch time: 7.0439, average train loss: 0.8336
[11/30 23:40:46 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.5863, average loss: 0.6890
[11/30 23:40:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.67	
[11/30 23:40:46 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.25
[11/30 23:49:00 visual_prompt]: Epoch 6 / 100: avg data time: 5.61e+00, avg batch time: 7.0609, average train loss: 0.7535
[11/30 23:49:56 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.5865, average loss: 0.6721
[11/30 23:49:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 63.13	
[11/30 23:49:56 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.3
[11/30 23:58:10 visual_prompt]: Epoch 7 / 100: avg data time: 5.59e+00, avg batch time: 7.0427, average train loss: 0.7298
[11/30 23:59:07 visual_prompt]: Inference (val):avg data time: 3.82e-05, avg batch time: 0.5937, average loss: 1.6587
[11/30 23:59:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.39	
[11/30 23:59:07 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.35
[12/01 00:07:25 visual_prompt]: Epoch 8 / 100: avg data time: 5.66e+00, avg batch time: 7.1171, average train loss: 0.7889
[12/01 00:08:22 visual_prompt]: Inference (val):avg data time: 3.71e-05, avg batch time: 0.5890, average loss: 1.3869
[12/01 00:08:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 64.23	
[12/01 00:08:22 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.4
[12/01 00:16:40 visual_prompt]: Epoch 9 / 100: avg data time: 5.66e+00, avg batch time: 7.1141, average train loss: 0.9032
[12/01 00:17:37 visual_prompt]: Inference (val):avg data time: 3.26e-05, avg batch time: 0.5904, average loss: 0.6673
[12/01 00:17:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 62.27	
[12/01 00:17:37 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.45
[12/01 00:25:53 visual_prompt]: Epoch 10 / 100: avg data time: 5.63e+00, avg batch time: 7.0836, average train loss: 0.7352
[12/01 00:26:50 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.5859, average loss: 0.8182
[12/01 00:26:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 65.40	
[12/01 00:26:50 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.5
[12/01 00:35:07 visual_prompt]: Epoch 11 / 100: avg data time: 5.64e+00, avg batch time: 7.0952, average train loss: 0.7594
[12/01 00:36:03 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.5890, average loss: 1.1425
[12/01 00:36:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 65.76	
[12/01 00:36:03 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.49984770675477397
[12/01 00:44:19 visual_prompt]: Epoch 12 / 100: avg data time: 5.63e+00, avg batch time: 7.0803, average train loss: 0.7588
[12/01 00:45:16 visual_prompt]: Inference (val):avg data time: 3.72e-05, avg batch time: 0.5881, average loss: 0.6451
[12/01 00:45:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 68.14	
[12/01 00:45:16 visual_prompt]: Best epoch 12: best metric: -0.645
[12/01 00:45:16 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.49939101256495605
[12/01 00:53:35 visual_prompt]: Epoch 13 / 100: avg data time: 5.66e+00, avg batch time: 7.1201, average train loss: 0.7121
[12/01 00:54:32 visual_prompt]: Inference (val):avg data time: 3.41e-05, avg batch time: 0.5863, average loss: 0.7472
[12/01 00:54:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 66.42	
[12/01 00:54:32 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.4986304738420683
[12/01 01:02:49 visual_prompt]: Epoch 14 / 100: avg data time: 5.65e+00, avg batch time: 7.1008, average train loss: 0.6895
[12/01 01:03:46 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.5880, average loss: 0.7282
[12/01 01:03:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 69.06	
[12/01 01:03:46 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.4975670171853926
[12/01 01:11:59 visual_prompt]: Epoch 15 / 100: avg data time: 5.59e+00, avg batch time: 7.0441, average train loss: 0.7205
[12/01 01:12:56 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.5894, average loss: 0.8441
[12/01 01:12:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 68.12	
[12/01 01:12:56 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.49620193825305203
[12/01 01:21:10 visual_prompt]: Epoch 16 / 100: avg data time: 5.61e+00, avg batch time: 7.0610, average train loss: 0.7952
[12/01 01:22:07 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.5922, average loss: 0.7576
[12/01 01:22:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 51.22	rocauc: 68.69	
[12/01 01:22:07 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.4945369001834514
[12/01 01:30:23 visual_prompt]: Epoch 17 / 100: avg data time: 5.64e+00, avg batch time: 7.0939, average train loss: 0.6727
[12/01 01:31:20 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.5875, average loss: 0.6680
[12/01 01:31:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 68.51	
[12/01 01:31:20 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.4925739315689991
[12/01 01:39:37 visual_prompt]: Epoch 18 / 100: avg data time: 5.64e+00, avg batch time: 7.0896, average train loss: 0.7205
[12/01 01:40:33 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.5867, average loss: 1.2647
[12/01 01:40:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 68.77	
[12/01 01:40:33 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.4903154239845797
[12/01 01:48:48 visual_prompt]: Epoch 19 / 100: avg data time: 5.61e+00, avg batch time: 7.0636, average train loss: 0.8198
[12/01 01:49:44 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.5869, average loss: 0.7814
[12/01 01:49:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 69.80	
[12/01 01:49:44 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.4877641290737884
[12/01 01:58:01 visual_prompt]: Epoch 20 / 100: avg data time: 5.65e+00, avg batch time: 7.0997, average train loss: 0.6516
[12/01 01:58:58 visual_prompt]: Inference (val):avg data time: 3.85e-05, avg batch time: 0.5931, average loss: 0.6210
[12/01 01:58:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 69.92	rocauc: 72.00	
[12/01 01:58:58 visual_prompt]: Best epoch 20: best metric: -0.621
[12/01 01:58:58 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.4849231551964771
[12/01 02:07:14 visual_prompt]: Epoch 21 / 100: avg data time: 5.63e+00, avg batch time: 7.0879, average train loss: 0.6324
[12/01 02:08:11 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.5866, average loss: 1.2250
[12/01 02:08:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 71.95	
[12/01 02:08:11 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.48179596364169686
[12/01 02:16:26 visual_prompt]: Epoch 22 / 100: avg data time: 5.62e+00, avg batch time: 7.0760, average train loss: 0.6627
[12/01 02:17:23 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.5891, average loss: 1.0498
[12/01 02:17:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 72.57	
[12/01 02:17:23 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.4783863644106502
[12/01 02:25:41 visual_prompt]: Epoch 23 / 100: avg data time: 5.66e+00, avg batch time: 7.1121, average train loss: 0.6718
[12/01 02:26:38 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.5863, average loss: 1.0461
[12/01 02:26:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 71.55	
[12/01 02:26:38 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.47469851157479176
[12/01 02:34:56 visual_prompt]: Epoch 24 / 100: avg data time: 5.66e+00, avg batch time: 7.1156, average train loss: 0.6677
[12/01 02:35:53 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.5904, average loss: 0.8375
[12/01 02:35:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 53.66	rocauc: 72.36	
[12/01 02:35:53 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.47073689821473175
[12/01 02:44:09 visual_prompt]: Epoch 25 / 100: avg data time: 5.63e+00, avg batch time: 7.0843, average train loss: 0.7134
[12/01 02:45:06 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.5867, average loss: 0.8246
[12/01 02:45:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 72.03	
[12/01 02:45:06 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.4665063509461097
[12/01 02:53:25 visual_prompt]: Epoch 26 / 100: avg data time: 5.67e+00, avg batch time: 7.1241, average train loss: 0.6137
[12/01 02:54:21 visual_prompt]: Inference (val):avg data time: 4.45e-05, avg batch time: 0.5884, average loss: 0.6522
[12/01 02:54:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 70.61	
[12/01 02:54:22 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.46201202403910646
[12/01 03:02:37 visual_prompt]: Epoch 27 / 100: avg data time: 5.62e+00, avg batch time: 7.0757, average train loss: 0.6254
[12/01 03:03:33 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.5859, average loss: 0.7248
[12/01 03:03:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 71.15	
[12/01 03:03:33 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.4572593931387604
[12/01 03:11:51 visual_prompt]: Epoch 28 / 100: avg data time: 5.65e+00, avg batch time: 7.1003, average train loss: 0.6796
[12/01 03:12:47 visual_prompt]: Inference (val):avg data time: 3.23e-05, avg batch time: 0.5906, average loss: 0.9833
[12/01 03:12:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 73.61	
[12/01 03:12:47 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.45225424859373686
[12/01 03:21:04 visual_prompt]: Epoch 29 / 100: avg data time: 5.64e+00, avg batch time: 7.0947, average train loss: 0.5688
[12/01 03:22:01 visual_prompt]: Inference (val):avg data time: 3.50e-05, avg batch time: 0.5857, average loss: 0.7330
[12/01 03:22:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 72.07	
[12/01 03:22:01 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.44700268840168045
[12/01 03:30:20 visual_prompt]: Epoch 30 / 100: avg data time: 5.67e+00, avg batch time: 7.1231, average train loss: 0.5600
[12/01 03:31:17 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.5869, average loss: 0.8735
[12/01 03:31:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 72.21	
[12/01 03:31:17 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.4415111107797445
[12/01 03:39:31 visual_prompt]: Epoch 31 / 100: avg data time: 5.60e+00, avg batch time: 7.0556, average train loss: 0.7012
[12/01 03:40:27 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.5875, average loss: 0.8545
[12/01 03:40:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 71.82	
[12/01 03:40:27 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.43578620636934856
[12/01 03:48:42 visual_prompt]: Epoch 32 / 100: avg data time: 5.61e+00, avg batch time: 7.0603, average train loss: 0.5778
[12/01 03:49:38 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.5875, average loss: 0.8196
[12/01 03:49:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 70.62	
[12/01 03:49:38 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.42983495008466277
[12/01 03:57:53 visual_prompt]: Epoch 33 / 100: avg data time: 5.62e+00, avg batch time: 7.0733, average train loss: 0.4920
[12/01 03:58:50 visual_prompt]: Inference (val):avg data time: 3.53e-05, avg batch time: 0.5904, average loss: 0.6100
[12/01 03:58:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 68.70	rocauc: 74.01	
[12/01 03:58:50 visual_prompt]: Best epoch 33: best metric: -0.610
[12/01 03:58:50 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.4236645926147493
[12/01 04:07:06 visual_prompt]: Epoch 34 / 100: avg data time: 5.62e+00, avg batch time: 7.0787, average train loss: 0.5615
[12/01 04:08:02 visual_prompt]: Inference (val):avg data time: 3.23e-05, avg batch time: 0.5853, average loss: 0.7080
[12/01 04:08:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 70.86	
[12/01 04:08:02 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.41728265158971456
[12/01 04:16:17 visual_prompt]: Epoch 35 / 100: avg data time: 5.61e+00, avg batch time: 7.0624, average train loss: 0.4871
[12/01 04:17:14 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.5861, average loss: 0.7610
[12/01 04:17:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 69.58	
[12/01 04:17:14 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.4106969024216348
[12/01 04:25:31 visual_prompt]: Epoch 36 / 100: avg data time: 5.65e+00, avg batch time: 7.1040, average train loss: 0.5539
[12/01 04:26:28 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.5868, average loss: 0.8829
[12/01 04:26:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 69.72	
[12/01 04:26:28 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.40391536883141455
[12/01 04:34:46 visual_prompt]: Epoch 37 / 100: avg data time: 5.65e+00, avg batch time: 7.1034, average train loss: 0.5321
[12/01 04:35:43 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.5853, average loss: 0.7572
[12/01 04:35:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 73.35	
[12/01 04:35:43 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.3969463130731183
[12/01 04:43:58 visual_prompt]: Epoch 38 / 100: avg data time: 5.62e+00, avg batch time: 7.0724, average train loss: 0.4925
[12/01 04:44:55 visual_prompt]: Inference (val):avg data time: 3.79e-05, avg batch time: 0.5861, average loss: 0.7586
[12/01 04:44:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 67.71	
[12/01 04:44:55 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.3897982258676867
[12/01 04:53:10 visual_prompt]: Epoch 39 / 100: avg data time: 5.62e+00, avg batch time: 7.0692, average train loss: 0.4526
[12/01 04:54:06 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.5900, average loss: 0.7618
[12/01 04:54:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 69.27	
[12/01 04:54:06 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.3824798160583012
[12/01 05:02:23 visual_prompt]: Epoch 40 / 100: avg data time: 5.63e+00, avg batch time: 7.0851, average train loss: 0.5335
[12/01 05:03:20 visual_prompt]: Inference (val):avg data time: 4.35e-05, avg batch time: 0.5893, average loss: 0.8272
[12/01 05:03:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 70.72	
[12/01 05:03:20 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.375
[12/01 05:11:37 visual_prompt]: Epoch 41 / 100: avg data time: 5.65e+00, avg batch time: 7.1032, average train loss: 0.4302
[12/01 05:12:34 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.5861, average loss: 0.8510
[12/01 05:12:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 68.20	
[12/01 05:12:34 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.3673678906964727
[12/01 05:20:51 visual_prompt]: Epoch 42 / 100: avg data time: 5.64e+00, avg batch time: 7.0937, average train loss: 0.4105
[12/01 05:21:47 visual_prompt]: Inference (val):avg data time: 3.55e-05, avg batch time: 0.5847, average loss: 0.8181
[12/01 05:21:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 67.17	
[12/01 05:21:47 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.35959278669726935
[12/01 05:30:04 visual_prompt]: Epoch 43 / 100: avg data time: 5.63e+00, avg batch time: 7.0843, average train loss: 0.3656
[12/01 05:31:00 visual_prompt]: Inference (val):avg data time: 3.79e-05, avg batch time: 0.5851, average loss: 0.8438
[12/01 05:31:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.54	rocauc: 69.46	
[12/01 05:31:00 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.3516841607689501
[12/01 05:39:17 visual_prompt]: Epoch 44 / 100: avg data time: 5.64e+00, avg batch time: 7.0942, average train loss: 0.5307
[12/01 05:40:14 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.5887, average loss: 0.7134
[12/01 05:40:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 69.11	rocauc: 74.65	
[12/01 05:40:14 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.34365164835397805
[12/01 05:48:31 visual_prompt]: Epoch 45 / 100: avg data time: 5.65e+00, avg batch time: 7.1016, average train loss: 0.4474
[12/01 05:49:28 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.5872, average loss: 0.9216
[12/01 05:49:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 72.13	
[12/01 05:49:28 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.3355050358314172
[12/01 05:57:45 visual_prompt]: Epoch 46 / 100: avg data time: 5.64e+00, avg batch time: 7.0990, average train loss: 0.3648
[12/01 05:58:42 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.5885, average loss: 0.7875
[12/01 05:58:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 67.94	
[12/01 05:58:42 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.32725424859373686
[12/01 06:07:00 visual_prompt]: Epoch 47 / 100: avg data time: 5.65e+00, avg batch time: 7.1078, average train loss: 0.3626
[12/01 06:07:57 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.5885, average loss: 0.9018
[12/01 06:07:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 65.84	
[12/01 06:07:57 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.3189093389542498
[12/01 06:16:01 visual_prompt]: Epoch 48 / 100: avg data time: 5.46e+00, avg batch time: 6.9116, average train loss: 0.3312
[12/01 06:16:50 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.5911, average loss: 0.8962
[12/01 06:16:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.01	rocauc: 67.09	
[12/01 06:16:50 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.3104804738999169
[12/01 06:24:08 visual_prompt]: Epoch 49 / 100: avg data time: 4.79e+00, avg batch time: 6.2499, average train loss: 0.3418
[12/01 06:24:58 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.5864, average loss: 1.0086
[12/01 06:24:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 65.90	
[12/01 06:24:58 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.3019779227044398
[12/01 06:32:11 visual_prompt]: Epoch 50 / 100: avg data time: 4.72e+00, avg batch time: 6.1792, average train loss: 0.3455
[12/01 06:33:00 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.5870, average loss: 1.0704
[12/01 06:33:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 66.49	
[12/01 06:33:00 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.29341204441673263
[12/01 06:40:13 visual_prompt]: Epoch 51 / 100: avg data time: 4.73e+00, avg batch time: 6.1804, average train loss: 0.2895
[12/01 06:41:02 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.5908, average loss: 1.0092
[12/01 06:41:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 68.07	
[12/01 06:41:02 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.28479327524001635
[12/01 06:48:20 visual_prompt]: Epoch 52 / 100: avg data time: 4.80e+00, avg batch time: 6.2474, average train loss: 0.2558
[12/01 06:49:10 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.5860, average loss: 1.0656
[12/01 06:49:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 66.58	
[12/01 06:49:10 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.2761321158169134
[12/01 06:56:27 visual_prompt]: Epoch 53 / 100: avg data time: 4.80e+00, avg batch time: 6.2483, average train loss: 0.2840
[12/01 06:57:17 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.5863, average loss: 1.2235
[12/01 06:57:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 64.79	
[12/01 06:57:17 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.2674391184360313
[12/01 07:04:35 visual_prompt]: Epoch 54 / 100: avg data time: 4.80e+00, avg batch time: 6.2551, average train loss: 0.2728
[12/01 07:05:25 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.5897, average loss: 1.2895
[12/01 07:05:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 66.99	
[12/01 07:05:25 visual_prompt]: Stopping early.
[12/01 07:05:25 visual_prompt]: Rank of current process: 0. World size: 1
[12/01 07:05:25 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[12/01 07:05:25 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[12/01 07:05:25 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[12/01 07:05:25 visual_prompt]: Training with config:
[12/01 07:05:25 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr0.25_wd0.01/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.25, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[12/01 07:05:25 visual_prompt]: Loading training data...
[12/01 07:05:25 visual_prompt]: Constructing mammo-cbis dataset train...
[12/01 07:05:25 visual_prompt]: Loading validation data...
[12/01 07:05:25 visual_prompt]: Constructing mammo-cbis dataset val...
[12/01 07:05:25 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[12/01 07:05:28 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[12/01 07:05:28 visual_prompt]: tuned percent:0.532
[12/01 07:05:28 visual_prompt]: Device used for model: 0
[12/01 07:05:28 visual_prompt]: Setting up Evaluator...
[12/01 07:05:28 visual_prompt]: Setting up Trainer...
[12/01 07:05:28 visual_prompt]: 	Setting up the optimizer...
[12/01 07:05:28 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[12/01 07:12:44 visual_prompt]: Epoch 1 / 100: avg data time: 4.78e+00, avg batch time: 6.2354, average train loss: 1.4863
[12/01 07:13:34 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.5859, average loss: 1.4553
[12/01 07:13:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[12/01 07:13:34 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.025
[12/01 07:20:47 visual_prompt]: Epoch 2 / 100: avg data time: 4.72e+00, avg batch time: 6.1772, average train loss: 0.9713
[12/01 07:21:36 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.5889, average loss: 0.7147
[12/01 07:21:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.04	
[12/01 07:21:36 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.05
[12/01 07:28:50 visual_prompt]: Epoch 3 / 100: avg data time: 4.74e+00, avg batch time: 6.1965, average train loss: 0.7077
[12/01 07:29:41 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.5910, average loss: 0.7279
[12/01 07:29:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.31	
[12/01 07:29:41 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.075
[12/01 07:36:59 visual_prompt]: Epoch 4 / 100: avg data time: 4.80e+00, avg batch time: 6.2557, average train loss: 0.7346
[12/01 07:37:49 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.5881, average loss: 0.7681
[12/01 07:37:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.08	
[12/01 07:37:49 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.1
[12/01 07:45:05 visual_prompt]: Epoch 5 / 100: avg data time: 4.78e+00, avg batch time: 6.2356, average train loss: 0.7304
[12/01 07:45:55 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.5867, average loss: 0.7125
[12/01 07:45:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.44	
[12/01 07:45:55 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.125
[12/01 07:53:13 visual_prompt]: Epoch 6 / 100: avg data time: 4.80e+00, avg batch time: 6.2580, average train loss: 0.7356
[12/01 07:54:03 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.5908, average loss: 0.7261
[12/01 07:54:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 64.04	
[12/01 07:54:03 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.15
[12/01 08:01:19 visual_prompt]: Epoch 7 / 100: avg data time: 4.78e+00, avg batch time: 6.2267, average train loss: 0.7236
[12/01 08:02:09 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.5882, average loss: 0.6945
[12/01 08:02:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.11	
[12/01 08:02:09 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.175
[12/01 08:09:11 visual_prompt]: Epoch 8 / 100: avg data time: 4.57e+00, avg batch time: 6.0179, average train loss: 0.7090
[12/01 08:10:00 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.5848, average loss: 0.6984
[12/01 08:10:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.53	
[12/01 08:10:00 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.2
[12/01 08:17:11 visual_prompt]: Epoch 9 / 100: avg data time: 4.70e+00, avg batch time: 6.1482, average train loss: 0.7234
[12/01 08:18:00 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.5839, average loss: 0.7273
[12/01 08:18:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.54	
[12/01 08:18:00 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.225
[12/01 08:25:17 visual_prompt]: Epoch 10 / 100: avg data time: 4.77e+00, avg batch time: 6.2288, average train loss: 0.7094
[12/01 08:26:06 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.5862, average loss: 0.6893
[12/01 08:26:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.66	
[12/01 08:26:06 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.25
[12/01 08:33:25 visual_prompt]: Epoch 11 / 100: avg data time: 4.81e+00, avg batch time: 6.2603, average train loss: 0.7365
[12/01 08:34:15 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.5888, average loss: 1.6830
[12/01 08:34:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.81	
[12/01 08:34:15 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.24992385337738698
[12/01 08:41:31 visual_prompt]: Epoch 12 / 100: avg data time: 4.78e+00, avg batch time: 6.2338, average train loss: 0.8243
[12/01 08:42:21 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.5870, average loss: 0.7700
[12/01 08:42:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 61.65	
[12/01 08:42:21 visual_prompt]: Best epoch 12: best metric: -0.770
[12/01 08:42:21 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.24969550628247802
[12/01 08:49:39 visual_prompt]: Epoch 13 / 100: avg data time: 4.80e+00, avg batch time: 6.2502, average train loss: 0.7388
[12/01 08:50:29 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.5931, average loss: 0.7423
[12/01 08:50:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.05	
[12/01 08:50:29 visual_prompt]: Best epoch 13: best metric: -0.742
[12/01 08:50:29 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.24931523692103416
[12/01 08:57:47 visual_prompt]: Epoch 14 / 100: avg data time: 4.79e+00, avg batch time: 6.2446, average train loss: 0.7283
[12/01 08:58:37 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.5868, average loss: 0.6983
[12/01 08:58:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 65.01	
[12/01 08:58:37 visual_prompt]: Best epoch 14: best metric: -0.698
[12/01 08:58:37 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.2487835085926963
[12/01 09:05:49 visual_prompt]: Epoch 15 / 100: avg data time: 4.72e+00, avg batch time: 6.1681, average train loss: 0.7070
[12/01 09:06:38 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.5883, average loss: 0.7123
[12/01 09:06:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.66	
[12/01 09:06:38 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.24810096912652602
[12/01 09:13:49 visual_prompt]: Epoch 16 / 100: avg data time: 4.70e+00, avg batch time: 6.1517, average train loss: 0.7516
[12/01 09:14:38 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.5889, average loss: 0.8885
[12/01 09:14:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.15	
[12/01 09:14:38 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.2472684500917257
[12/01 09:21:50 visual_prompt]: Epoch 17 / 100: avg data time: 4.72e+00, avg batch time: 6.1700, average train loss: 0.7496
[12/01 09:22:40 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.5873, average loss: 0.7649
[12/01 09:22:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.67	
[12/01 09:22:40 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.24628696578449955
[12/01 09:29:57 visual_prompt]: Epoch 18 / 100: avg data time: 4.78e+00, avg batch time: 6.2364, average train loss: 0.7239
[12/01 09:30:47 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.5887, average loss: 0.8876
[12/01 09:30:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.50	
[12/01 09:30:47 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.24515771199228986
[12/01 09:38:04 visual_prompt]: Epoch 19 / 100: avg data time: 4.78e+00, avg batch time: 6.2354, average train loss: 0.7588
[12/01 09:38:54 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.5872, average loss: 0.9257
[12/01 09:38:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.64	
[12/01 09:38:54 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.2438820645368942
[12/01 09:47:07 visual_prompt]: Epoch 20 / 100: avg data time: 5.59e+00, avg batch time: 7.0374, average train loss: 0.7332
[12/01 09:48:04 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.5849, average loss: 0.6889
[12/01 09:48:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.95	
[12/01 09:48:04 visual_prompt]: Best epoch 20: best metric: -0.689
[12/01 09:48:04 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.24246157759823855
[12/01 09:56:26 visual_prompt]: Epoch 21 / 100: avg data time: 5.71e+00, avg batch time: 7.1598, average train loss: 0.7300
[12/01 09:57:23 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.5900, average loss: 0.7571
[12/01 09:57:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.96	
[12/01 09:57:23 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.24089798182084843
[12/01 10:05:43 visual_prompt]: Epoch 22 / 100: avg data time: 5.69e+00, avg batch time: 7.1451, average train loss: 0.7172
[12/01 10:06:40 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.5871, average loss: 0.6923
[12/01 10:06:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.01	
[12/01 10:06:40 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.2391931822053251
[12/01 10:14:59 visual_prompt]: Epoch 23 / 100: avg data time: 5.67e+00, avg batch time: 7.1216, average train loss: 0.7126
[12/01 10:15:56 visual_prompt]: Inference (val):avg data time: 4.70e-05, avg batch time: 0.5874, average loss: 0.8270
[12/01 10:15:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.00	
[12/01 10:15:56 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.23734925578739588
[12/01 10:24:13 visual_prompt]: Epoch 24 / 100: avg data time: 5.63e+00, avg batch time: 7.0913, average train loss: 0.7236
[12/01 10:25:10 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.5867, average loss: 0.6880
[12/01 10:25:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.68	
[12/01 10:25:10 visual_prompt]: Best epoch 24: best metric: -0.688
[12/01 10:25:10 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.23536844910736587
[12/01 10:33:30 visual_prompt]: Epoch 25 / 100: avg data time: 5.69e+00, avg batch time: 7.1399, average train loss: 0.7185
[12/01 10:34:27 visual_prompt]: Inference (val):avg data time: 3.35e-05, avg batch time: 0.5862, average loss: 0.7078
[12/01 10:34:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.93	
[12/01 10:34:27 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.23325317547305485
[12/01 10:42:45 visual_prompt]: Epoch 26 / 100: avg data time: 5.66e+00, avg batch time: 7.1140, average train loss: 0.7332
[12/01 10:43:42 visual_prompt]: Inference (val):avg data time: 3.95e-05, avg batch time: 0.5948, average loss: 0.7030
[12/01 10:43:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.86	
[12/01 10:43:42 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.23100601201955323
[12/01 10:51:58 visual_prompt]: Epoch 27 / 100: avg data time: 5.63e+00, avg batch time: 7.0809, average train loss: 0.7164
[12/01 10:52:55 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.5835, average loss: 0.7465
[12/01 10:52:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.03	
[12/01 10:52:55 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.2286296965693802
[12/01 11:01:15 visual_prompt]: Epoch 28 / 100: avg data time: 5.68e+00, avg batch time: 7.1329, average train loss: 0.7176
[12/01 11:02:12 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.5879, average loss: 0.7000
[12/01 11:02:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.23	
[12/01 11:02:12 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.22612712429686843
[12/01 11:10:30 visual_prompt]: Epoch 29 / 100: avg data time: 5.65e+00, avg batch time: 7.1069, average train loss: 0.7115
[12/01 11:11:27 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.5873, average loss: 0.7236
[12/01 11:11:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.00	
[12/01 11:11:27 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.22350134420084022
[12/01 11:19:47 visual_prompt]: Epoch 30 / 100: avg data time: 5.68e+00, avg batch time: 7.1310, average train loss: 0.7374
[12/01 11:20:44 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.5889, average loss: 0.7976
[12/01 11:20:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.02	
[12/01 11:20:44 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.22075555538987224
[12/01 11:29:02 visual_prompt]: Epoch 31 / 100: avg data time: 5.66e+00, avg batch time: 7.1188, average train loss: 0.7095
[12/01 11:29:59 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.5867, average loss: 0.7002
[12/01 11:29:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.53	
[12/01 11:29:59 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.21789310318467428
[12/01 11:38:18 visual_prompt]: Epoch 32 / 100: avg data time: 5.66e+00, avg batch time: 7.1143, average train loss: 0.7094
[12/01 11:39:15 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.5859, average loss: 0.6956
[12/01 11:39:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.12	
[12/01 11:39:15 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.21491747504233139
[12/01 11:47:33 visual_prompt]: Epoch 33 / 100: avg data time: 5.66e+00, avg batch time: 7.1135, average train loss: 0.7092
[12/01 11:48:30 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.5854, average loss: 0.6954
[12/01 11:48:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.81	
[12/01 11:48:30 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.21183229630737466
[12/01 11:56:48 visual_prompt]: Epoch 34 / 100: avg data time: 5.67e+00, avg batch time: 7.1179, average train loss: 0.7079
[12/01 11:57:45 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.5924, average loss: 0.7223
[12/01 11:57:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 45.37	
[12/01 11:57:45 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.20864132579485728
[12/01 12:06:02 visual_prompt]: Epoch 35 / 100: avg data time: 5.64e+00, avg batch time: 7.0882, average train loss: 0.7151
[12/01 12:06:58 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.5825, average loss: 0.7002
[12/01 12:06:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.15	
[12/01 12:06:58 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.2053484512108174
[12/01 12:15:19 visual_prompt]: Epoch 36 / 100: avg data time: 5.69e+00, avg batch time: 7.1446, average train loss: 0.7300
[12/01 12:16:16 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.5891, average loss: 0.6908
[12/01 12:16:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.08	
[12/01 12:16:16 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.20195768441570727
[12/01 12:24:34 visual_prompt]: Epoch 37 / 100: avg data time: 5.67e+00, avg batch time: 7.1194, average train loss: 0.7034
[12/01 12:25:31 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.5900, average loss: 0.7173
[12/01 12:25:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.52	
[12/01 12:25:31 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.19847315653655914
[12/01 12:33:49 visual_prompt]: Epoch 38 / 100: avg data time: 5.66e+00, avg batch time: 7.1113, average train loss: 0.6983
[12/01 12:34:46 visual_prompt]: Inference (val):avg data time: 3.45e-05, avg batch time: 0.5881, average loss: 0.6937
[12/01 12:34:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.59	
[12/01 12:34:46 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.19489911293384335
[12/01 12:43:03 visual_prompt]: Epoch 39 / 100: avg data time: 5.65e+00, avg batch time: 7.1000, average train loss: 0.7262
[12/01 12:44:00 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.5879, average loss: 0.6917
[12/01 12:44:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.28	
[12/01 12:44:00 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.1912399080291506
[12/01 12:52:17 visual_prompt]: Epoch 40 / 100: avg data time: 5.65e+00, avg batch time: 7.0968, average train loss: 0.7181
[12/01 12:53:14 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.5865, average loss: 0.7256
[12/01 12:53:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.71	
[12/01 12:53:14 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.1875
[12/01 13:01:29 visual_prompt]: Epoch 41 / 100: avg data time: 5.62e+00, avg batch time: 7.0726, average train loss: 0.7110
[12/01 13:02:26 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.5878, average loss: 0.7952
[12/01 13:02:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.52	
[12/01 13:02:26 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.18368394534823634
[12/01 13:10:38 visual_prompt]: Epoch 42 / 100: avg data time: 5.58e+00, avg batch time: 7.0324, average train loss: 0.7237
[12/01 13:11:35 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.5851, average loss: 0.6888
[12/01 13:11:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 45.37	
[12/01 13:11:35 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.17979639334863468
[12/01 13:19:49 visual_prompt]: Epoch 43 / 100: avg data time: 5.61e+00, avg batch time: 7.0645, average train loss: 0.7307
[12/01 13:20:46 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.5874, average loss: 0.6896
[12/01 13:20:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.07	rocauc: 48.58	
[12/01 13:20:46 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.17584208038447505
[12/01 13:29:05 visual_prompt]: Epoch 44 / 100: avg data time: 5.67e+00, avg batch time: 7.1253, average train loss: 0.7098
[12/01 13:30:02 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.5882, average loss: 0.6942
[12/01 13:30:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.92	
[12/01 13:30:02 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.17182582417698902
[12/01 13:38:19 visual_prompt]: Epoch 45 / 100: avg data time: 5.65e+00, avg batch time: 7.1008, average train loss: 0.7133
[12/01 13:39:16 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.5879, average loss: 0.7370
[12/01 13:39:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 37.89	
[12/01 13:39:16 visual_prompt]: Stopping early.
[12/01 13:39:16 visual_prompt]: Rank of current process: 0. World size: 1
[12/01 13:39:16 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[12/01 13:39:16 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[12/01 13:39:16 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[12/01 13:39:16 visual_prompt]: Training with config:
[12/01 13:39:16 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr0.25_wd0.001/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.25, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[12/01 13:39:16 visual_prompt]: Loading training data...
[12/01 13:39:16 visual_prompt]: Constructing mammo-cbis dataset train...
[12/01 13:39:16 visual_prompt]: Loading validation data...
[12/01 13:39:16 visual_prompt]: Constructing mammo-cbis dataset val...
[12/01 13:39:16 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[12/01 13:39:19 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[12/01 13:39:19 visual_prompt]: tuned percent:0.532
[12/01 13:39:19 visual_prompt]: Device used for model: 0
[12/01 13:39:19 visual_prompt]: Setting up Evaluator...
[12/01 13:39:19 visual_prompt]: Setting up Trainer...
[12/01 13:39:19 visual_prompt]: 	Setting up the optimizer...
[12/01 13:39:19 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[12/01 13:47:36 visual_prompt]: Epoch 1 / 100: avg data time: 5.64e+00, avg batch time: 7.0911, average train loss: 1.4863
[12/01 13:48:33 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.5890, average loss: 1.4553
[12/01 13:48:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[12/01 13:48:33 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.025
[12/01 13:56:47 visual_prompt]: Epoch 2 / 100: avg data time: 5.62e+00, avg batch time: 7.0682, average train loss: 0.9787
[12/01 13:57:44 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.5884, average loss: 0.7197
[12/01 13:57:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.26	
[12/01 13:57:44 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.05
[12/01 14:05:59 visual_prompt]: Epoch 3 / 100: avg data time: 5.61e+00, avg batch time: 7.0644, average train loss: 0.7152
[12/01 14:06:56 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.5898, average loss: 0.7403
[12/01 14:06:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.92	
[12/01 14:06:56 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.075
[12/01 14:15:11 visual_prompt]: Epoch 4 / 100: avg data time: 5.62e+00, avg batch time: 7.0712, average train loss: 0.7463
[12/01 14:16:07 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.5883, average loss: 0.8057
[12/01 14:16:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.20	
[12/01 14:16:07 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.1
[12/01 14:24:23 visual_prompt]: Epoch 5 / 100: avg data time: 5.62e+00, avg batch time: 7.0702, average train loss: 0.7599
[12/01 14:25:19 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.5841, average loss: 0.7011
[12/01 14:25:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.33	
[12/01 14:25:19 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.125
[12/01 14:33:36 visual_prompt]: Epoch 6 / 100: avg data time: 5.64e+00, avg batch time: 7.0914, average train loss: 0.7519
[12/01 14:34:33 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.5872, average loss: 0.6936
[12/01 14:34:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.84	
[12/01 14:34:33 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.15
[12/01 14:42:46 visual_prompt]: Epoch 7 / 100: avg data time: 5.59e+00, avg batch time: 7.0451, average train loss: 0.7046
[12/01 14:43:43 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.5910, average loss: 1.2620
[12/01 14:43:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 65.61	
[12/01 14:43:43 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.175
[12/01 14:51:59 visual_prompt]: Epoch 8 / 100: avg data time: 5.64e+00, avg batch time: 7.0930, average train loss: 0.7436
[12/01 14:52:56 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.5855, average loss: 0.8723
[12/01 14:52:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.27	
[12/01 14:52:56 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.2
[12/01 15:01:12 visual_prompt]: Epoch 9 / 100: avg data time: 5.63e+00, avg batch time: 7.0825, average train loss: 0.8027
[12/01 15:02:09 visual_prompt]: Inference (val):avg data time: 3.90e-05, avg batch time: 0.5945, average loss: 0.7010
[12/01 15:02:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.93	
[12/01 15:02:09 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.225
[12/01 15:10:25 visual_prompt]: Epoch 10 / 100: avg data time: 5.63e+00, avg batch time: 7.0848, average train loss: 0.6891
[12/01 15:11:22 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.5862, average loss: 0.6902
[12/01 15:11:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 64.57	
[12/01 15:11:22 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.25
[12/01 15:19:36 visual_prompt]: Epoch 11 / 100: avg data time: 5.61e+00, avg batch time: 7.0580, average train loss: 0.7356
[12/01 15:20:33 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.5878, average loss: 0.9048
[12/01 15:20:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.27	
[12/01 15:20:33 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.24992385337738698
[12/01 15:28:46 visual_prompt]: Epoch 12 / 100: avg data time: 5.60e+00, avg batch time: 7.0517, average train loss: 0.7116
[12/01 15:29:43 visual_prompt]: Inference (val):avg data time: 4.00e-05, avg batch time: 0.5911, average loss: 0.7177
[12/01 15:29:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.53	rocauc: 62.19	
[12/01 15:29:43 visual_prompt]: Best epoch 12: best metric: -0.718
[12/01 15:29:43 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.24969550628247802
[12/01 15:37:58 visual_prompt]: Epoch 13 / 100: avg data time: 5.61e+00, avg batch time: 7.0655, average train loss: 0.7795
[12/01 15:38:54 visual_prompt]: Inference (val):avg data time: 3.49e-05, avg batch time: 0.5874, average loss: 0.7248
[12/01 15:38:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 62.76	
[12/01 15:38:54 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.24931523692103416
[12/01 15:47:09 visual_prompt]: Epoch 14 / 100: avg data time: 5.62e+00, avg batch time: 7.0712, average train loss: 0.7045
[12/01 15:48:06 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.5877, average loss: 0.7934
[12/01 15:48:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 64.19	
[12/01 15:48:06 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.2487835085926963
[12/01 15:56:18 visual_prompt]: Epoch 15 / 100: avg data time: 5.58e+00, avg batch time: 7.0315, average train loss: 0.7067
[12/01 15:57:15 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.5871, average loss: 0.6787
[12/01 15:57:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.64	
[12/01 15:57:15 visual_prompt]: Best epoch 15: best metric: -0.679
[12/01 15:57:15 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.24810096912652602
[12/01 16:05:29 visual_prompt]: Epoch 16 / 100: avg data time: 5.60e+00, avg batch time: 7.0505, average train loss: 0.6990
[12/01 16:06:25 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.5867, average loss: 0.8309
[12/01 16:06:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.56	
[12/01 16:06:25 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.2472684500917257
[12/01 16:14:42 visual_prompt]: Epoch 17 / 100: avg data time: 5.63e+00, avg batch time: 7.0875, average train loss: 0.7265
[12/01 16:15:38 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.5900, average loss: 0.6797
[12/01 16:15:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 65.64	
[12/01 16:15:38 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.24628696578449955
[12/01 16:23:51 visual_prompt]: Epoch 18 / 100: avg data time: 5.58e+00, avg batch time: 7.0307, average train loss: 0.7005
[12/01 16:24:47 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.5883, average loss: 0.8577
[12/01 16:24:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 65.23	
[12/01 16:24:47 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.24515771199228986
[12/01 16:33:03 visual_prompt]: Epoch 19 / 100: avg data time: 5.62e+00, avg batch time: 7.0783, average train loss: 0.7024
[12/01 16:33:59 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.5861, average loss: 0.8868
[12/01 16:33:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 65.23	
[12/01 16:33:59 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.2438820645368942
[12/01 16:42:18 visual_prompt]: Epoch 20 / 100: avg data time: 5.67e+00, avg batch time: 7.1234, average train loss: 0.6821
[12/01 16:43:15 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.5877, average loss: 0.6721
[12/01 16:43:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 66.12	
[12/01 16:43:15 visual_prompt]: Best epoch 20: best metric: -0.672
[12/01 16:43:15 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.24246157759823855
[12/01 16:51:35 visual_prompt]: Epoch 21 / 100: avg data time: 5.69e+00, avg batch time: 7.1436, average train loss: 0.6701
[12/01 16:52:32 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.5867, average loss: 0.6847
[12/01 16:52:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 68.76	
[12/01 16:52:32 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.24089798182084843
[12/01 17:00:49 visual_prompt]: Epoch 22 / 100: avg data time: 5.64e+00, avg batch time: 7.0927, average train loss: 0.7164
[12/01 17:01:46 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.5867, average loss: 0.6723
[12/01 17:01:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 63.43	
[12/01 17:01:46 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.2391931822053251
[12/01 17:10:08 visual_prompt]: Epoch 23 / 100: avg data time: 5.71e+00, avg batch time: 7.1601, average train loss: 0.6818
[12/01 17:11:04 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.5887, average loss: 0.6745
[12/01 17:11:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 64.96	
[12/01 17:11:04 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.23734925578739588
[12/01 17:19:22 visual_prompt]: Epoch 24 / 100: avg data time: 5.66e+00, avg batch time: 7.1094, average train loss: 0.6996
[12/01 17:20:20 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.5868, average loss: 0.6857
[12/01 17:20:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.47	rocauc: 58.95	
[12/01 17:20:20 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.23536844910736587
[12/01 17:28:40 visual_prompt]: Epoch 25 / 100: avg data time: 5.69e+00, avg batch time: 7.1383, average train loss: 0.6996
[12/01 17:29:37 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.5887, average loss: 0.6993
[12/01 17:29:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.18	
[12/01 17:29:37 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.23325317547305485
[12/01 17:37:52 visual_prompt]: Epoch 26 / 100: avg data time: 5.63e+00, avg batch time: 7.0798, average train loss: 0.7013
[12/01 17:38:49 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.5890, average loss: 0.6865
[12/01 17:38:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 64.57	
[12/01 17:38:49 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.23100601201955323
[12/01 17:47:04 visual_prompt]: Epoch 27 / 100: avg data time: 5.62e+00, avg batch time: 7.0708, average train loss: 0.6826
[12/01 17:48:01 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.5869, average loss: 0.6718
[12/01 17:48:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 62.49	
[12/01 17:48:01 visual_prompt]: Best epoch 27: best metric: -0.672
[12/01 17:48:01 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.2286296965693802
[12/01 17:56:16 visual_prompt]: Epoch 28 / 100: avg data time: 5.62e+00, avg batch time: 7.0713, average train loss: 0.7039
[12/01 17:57:12 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.5901, average loss: 0.6836
[12/01 17:57:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 64.31	
[12/01 17:57:12 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.22612712429686843
[12/01 18:05:24 visual_prompt]: Epoch 29 / 100: avg data time: 5.58e+00, avg batch time: 7.0293, average train loss: 0.6924
[12/01 18:06:21 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.5873, average loss: 0.7310
[12/01 18:06:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 68.40	
[12/01 18:06:21 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.22350134420084022
[12/01 18:14:35 visual_prompt]: Epoch 30 / 100: avg data time: 5.60e+00, avg batch time: 7.0548, average train loss: 0.7119
[12/01 18:15:31 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.5880, average loss: 0.7704
[12/01 18:15:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 44.72	rocauc: 65.69	
[12/01 18:15:31 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.22075555538987224
[12/01 18:23:43 visual_prompt]: Epoch 31 / 100: avg data time: 5.57e+00, avg batch time: 7.0293, average train loss: 0.6892
[12/01 18:24:40 visual_prompt]: Inference (val):avg data time: 3.50e-05, avg batch time: 0.5861, average loss: 0.6581
[12/01 18:24:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 65.57	
[12/01 18:24:40 visual_prompt]: Best epoch 31: best metric: -0.658
[12/01 18:24:40 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.21789310318467428
[12/01 18:32:58 visual_prompt]: Epoch 32 / 100: avg data time: 5.65e+00, avg batch time: 7.1041, average train loss: 0.6905
[12/01 18:33:55 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.5855, average loss: 0.6783
[12/01 18:33:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 69.53	
[12/01 18:33:55 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.21491747504233139
[12/01 18:42:12 visual_prompt]: Epoch 33 / 100: avg data time: 5.65e+00, avg batch time: 7.1030, average train loss: 0.6884
[12/01 18:43:09 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.5910, average loss: 0.7002
[12/01 18:43:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 66.79	
[12/01 18:43:09 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.21183229630737466
[12/01 18:51:23 visual_prompt]: Epoch 34 / 100: avg data time: 5.60e+00, avg batch time: 7.0516, average train loss: 0.6877
[12/01 18:52:19 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.5879, average loss: 0.7005
[12/01 18:52:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 61.91	
[12/01 18:52:19 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.20864132579485728
[12/01 19:00:33 visual_prompt]: Epoch 35 / 100: avg data time: 5.60e+00, avg batch time: 7.0518, average train loss: 0.7012
[12/01 19:01:29 visual_prompt]: Inference (val):avg data time: 3.49e-05, avg batch time: 0.5872, average loss: 0.7992
[12/01 19:01:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 66.87	
[12/01 19:01:29 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.2053484512108174
[12/01 19:09:46 visual_prompt]: Epoch 36 / 100: avg data time: 5.64e+00, avg batch time: 7.0909, average train loss: 0.7084
[12/01 19:10:43 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.5923, average loss: 0.6597
[12/01 19:10:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 67.41	
[12/01 19:10:43 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.20195768441570727
[12/01 19:18:59 visual_prompt]: Epoch 37 / 100: avg data time: 5.63e+00, avg batch time: 7.0811, average train loss: 0.6951
[12/01 19:19:55 visual_prompt]: Inference (val):avg data time: 3.62e-05, avg batch time: 0.5883, average loss: 0.6763
[12/01 19:19:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 65.55	
[12/01 19:19:55 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.19847315653655914
[12/01 19:28:11 visual_prompt]: Epoch 38 / 100: avg data time: 5.62e+00, avg batch time: 7.0737, average train loss: 0.6856
[12/01 19:29:07 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.5860, average loss: 0.6744
[12/01 19:29:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 67.77	
[12/01 19:29:07 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.19489911293384335
[12/01 19:37:22 visual_prompt]: Epoch 39 / 100: avg data time: 5.61e+00, avg batch time: 7.0619, average train loss: 0.6952
[12/01 19:38:19 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.5910, average loss: 0.7184
[12/01 19:38:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.60	
[12/01 19:38:19 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.1912399080291506
[12/01 19:46:33 visual_prompt]: Epoch 40 / 100: avg data time: 5.61e+00, avg batch time: 7.0610, average train loss: 0.7074
[12/01 19:47:30 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.5875, average loss: 0.7180
[12/01 19:47:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 65.84	
[12/01 19:47:30 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.1875
[12/01 19:55:48 visual_prompt]: Epoch 41 / 100: avg data time: 5.65e+00, avg batch time: 7.1098, average train loss: 0.7145
[12/01 19:56:45 visual_prompt]: Inference (val):avg data time: 3.83e-05, avg batch time: 0.5895, average loss: 0.8335
[12/01 19:56:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.42	
[12/01 19:56:45 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.18368394534823634
[12/01 20:04:59 visual_prompt]: Epoch 42 / 100: avg data time: 5.60e+00, avg batch time: 7.0586, average train loss: 0.6988
[12/01 20:05:56 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.5879, average loss: 0.6622
[12/01 20:05:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 65.68	
[12/01 20:05:56 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.17979639334863468
[12/01 20:14:11 visual_prompt]: Epoch 43 / 100: avg data time: 5.62e+00, avg batch time: 7.0770, average train loss: 0.7157
[12/01 20:15:08 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.5847, average loss: 0.7004
[12/01 20:15:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 64.63	
[12/01 20:15:08 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.17584208038447505
[12/01 20:23:24 visual_prompt]: Epoch 44 / 100: avg data time: 5.63e+00, avg batch time: 7.0811, average train loss: 0.7020
[12/01 20:24:20 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.5886, average loss: 0.6900
[12/01 20:24:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.10	
[12/01 20:24:20 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.17182582417698902
[12/01 20:32:35 visual_prompt]: Epoch 45 / 100: avg data time: 5.61e+00, avg batch time: 7.0676, average train loss: 0.6992
[12/01 20:33:32 visual_prompt]: Inference (val):avg data time: 3.49e-05, avg batch time: 0.5861, average loss: 0.7374
[12/01 20:33:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.72	
[12/01 20:33:32 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.1677525179157086
[12/01 20:41:47 visual_prompt]: Epoch 46 / 100: avg data time: 5.62e+00, avg batch time: 7.0716, average train loss: 0.7064
[12/01 20:42:44 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.5870, average loss: 0.6984
[12/01 20:42:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.66	
[12/01 20:42:44 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.16362712429686843
[12/01 20:50:59 visual_prompt]: Epoch 47 / 100: avg data time: 5.63e+00, avg batch time: 7.0784, average train loss: 0.6976
[12/01 20:51:56 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.5844, average loss: 0.7159
[12/01 20:51:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 61.75	
[12/01 20:51:56 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.1594546694771249
[12/01 21:00:09 visual_prompt]: Epoch 48 / 100: avg data time: 5.59e+00, avg batch time: 7.0445, average train loss: 0.6983
[12/01 21:01:05 visual_prompt]: Inference (val):avg data time: 3.47e-05, avg batch time: 0.5885, average loss: 0.7039
[12/01 21:01:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.98	
[12/01 21:01:05 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.15524023694995845
[12/01 21:09:20 visual_prompt]: Epoch 49 / 100: avg data time: 5.61e+00, avg batch time: 7.0666, average train loss: 0.6992
[12/01 21:10:17 visual_prompt]: Inference (val):avg data time: 3.77e-05, avg batch time: 0.5903, average loss: 0.6877
[12/01 21:10:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.16	
[12/01 21:10:17 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.1509889613522199
[12/01 21:18:31 visual_prompt]: Epoch 50 / 100: avg data time: 5.60e+00, avg batch time: 7.0512, average train loss: 0.7008
[12/01 21:19:27 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.5897, average loss: 0.8691
[12/01 21:19:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.94	
[12/01 21:19:27 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.14670602220836632
[12/01 21:27:43 visual_prompt]: Epoch 51 / 100: avg data time: 5.63e+00, avg batch time: 7.0872, average train loss: 0.7152
[12/01 21:28:41 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.5871, average loss: 0.7722
[12/01 21:28:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.80	
[12/01 21:28:41 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.14239663762000818
[12/01 21:36:58 visual_prompt]: Epoch 52 / 100: avg data time: 5.65e+00, avg batch time: 7.1017, average train loss: 0.6983
[12/01 21:37:55 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.5867, average loss: 0.7585
[12/01 21:37:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 61.21	
[12/01 21:37:55 visual_prompt]: Stopping early.
[12/01 21:37:55 visual_prompt]: Rank of current process: 0. World size: 1
[12/01 21:37:55 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[12/01 21:37:55 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[12/01 21:37:55 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[12/01 21:37:55 visual_prompt]: Training with config:
[12/01 21:37:55 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr0.25_wd0.0001/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.25, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[12/01 21:37:55 visual_prompt]: Loading training data...
[12/01 21:37:55 visual_prompt]: Constructing mammo-cbis dataset train...
[12/01 21:37:55 visual_prompt]: Loading validation data...
[12/01 21:37:55 visual_prompt]: Constructing mammo-cbis dataset val...
[12/01 21:37:55 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[12/01 21:37:58 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[12/01 21:37:58 visual_prompt]: tuned percent:0.532
[12/01 21:37:58 visual_prompt]: Device used for model: 0
[12/01 21:37:58 visual_prompt]: Setting up Evaluator...
[12/01 21:37:58 visual_prompt]: Setting up Trainer...
[12/01 21:37:58 visual_prompt]: 	Setting up the optimizer...
[12/01 21:37:58 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[12/01 21:46:13 visual_prompt]: Epoch 1 / 100: avg data time: 5.61e+00, avg batch time: 7.0688, average train loss: 1.4863
[12/01 21:47:10 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.5856, average loss: 1.4553
[12/01 21:47:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[12/01 21:47:10 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.025
[12/01 21:55:24 visual_prompt]: Epoch 2 / 100: avg data time: 5.60e+00, avg batch time: 7.0514, average train loss: 0.9796
[12/01 21:56:20 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.5899, average loss: 0.7201
[12/01 21:56:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.32	
[12/01 21:56:20 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.05
[12/01 22:04:35 visual_prompt]: Epoch 3 / 100: avg data time: 5.61e+00, avg batch time: 7.0610, average train loss: 0.7161
[12/01 22:05:31 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.5840, average loss: 0.7424
[12/01 22:05:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.72	
[12/01 22:05:31 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.075
[12/01 22:13:44 visual_prompt]: Epoch 4 / 100: avg data time: 5.59e+00, avg batch time: 7.0430, average train loss: 0.7472
[12/01 22:14:41 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.5897, average loss: 0.7975
[12/01 22:14:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.16	
[12/01 22:14:41 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.1
[12/01 22:22:54 visual_prompt]: Epoch 5 / 100: avg data time: 5.59e+00, avg batch time: 7.0401, average train loss: 0.7629
[12/01 22:23:51 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.5852, average loss: 0.7072
[12/01 22:23:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.71	
[12/01 22:23:51 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.125
[12/01 22:32:10 visual_prompt]: Epoch 6 / 100: avg data time: 5.68e+00, avg batch time: 7.1280, average train loss: 0.7481
[12/01 22:33:07 visual_prompt]: Inference (val):avg data time: 3.64e-05, avg batch time: 0.5901, average loss: 0.6844
[12/01 22:33:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.57	
[12/01 22:33:07 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.15
[12/01 22:41:23 visual_prompt]: Epoch 7 / 100: avg data time: 5.64e+00, avg batch time: 7.0909, average train loss: 0.7037
[12/01 22:42:20 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.5873, average loss: 1.2721
[12/01 22:42:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 64.71	
[12/01 22:42:20 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.175
[12/01 22:50:34 visual_prompt]: Epoch 8 / 100: avg data time: 5.60e+00, avg batch time: 7.0546, average train loss: 0.7266
[12/01 22:51:31 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.5879, average loss: 1.0836
[12/01 22:51:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 64.69	
[12/01 22:51:31 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.2
[12/01 22:59:44 visual_prompt]: Epoch 9 / 100: avg data time: 5.60e+00, avg batch time: 7.0503, average train loss: 0.8072
[12/01 23:00:41 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.5875, average loss: 0.6764
[12/01 23:00:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 63.50	
[12/01 23:00:41 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.225
[12/01 23:08:56 visual_prompt]: Epoch 10 / 100: avg data time: 5.61e+00, avg batch time: 7.0660, average train loss: 0.6825
[12/01 23:09:53 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.5859, average loss: 0.6855
[12/01 23:09:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 62.88	
[12/01 23:09:53 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.25
[12/01 23:18:09 visual_prompt]: Epoch 11 / 100: avg data time: 5.64e+00, avg batch time: 7.0937, average train loss: 0.7438
[12/01 23:19:06 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.5903, average loss: 0.8196
[12/01 23:19:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 67.03	
[12/01 23:19:06 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.24992385337738698
[12/01 23:27:21 visual_prompt]: Epoch 12 / 100: avg data time: 5.62e+00, avg batch time: 7.0719, average train loss: 0.7379
[12/01 23:28:18 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.5892, average loss: 0.7108
[12/01 23:28:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 50.00	rocauc: 65.13	
[12/01 23:28:18 visual_prompt]: Best epoch 12: best metric: -0.711
[12/01 23:28:18 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.24969550628247802
[12/01 23:36:34 visual_prompt]: Epoch 13 / 100: avg data time: 5.62e+00, avg batch time: 7.0785, average train loss: 0.7528
[12/01 23:37:31 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.5874, average loss: 0.6814
[12/01 23:37:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 66.50	
[12/01 23:37:31 visual_prompt]: Best epoch 13: best metric: -0.681
[12/01 23:37:31 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.24931523692103416
[12/01 23:45:45 visual_prompt]: Epoch 14 / 100: avg data time: 5.60e+00, avg batch time: 7.0613, average train loss: 0.7016
[12/01 23:46:42 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.5904, average loss: 0.7179
[12/01 23:46:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 50.00	rocauc: 67.36	
[12/01 23:46:42 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.2487835085926963
[12/01 23:54:58 visual_prompt]: Epoch 15 / 100: avg data time: 5.63e+00, avg batch time: 7.0842, average train loss: 0.7037
[12/01 23:55:55 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.5892, average loss: 0.6512
[12/01 23:55:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 68.06	
[12/01 23:55:55 visual_prompt]: Best epoch 15: best metric: -0.651
[12/01 23:55:55 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.24810096912652602
[12/02 00:04:13 visual_prompt]: Epoch 16 / 100: avg data time: 5.65e+00, avg batch time: 7.1091, average train loss: 0.6772
[12/02 00:05:09 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.5880, average loss: 0.6825
[12/02 00:05:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 68.43	
[12/02 00:05:09 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.2472684500917257
[12/02 00:13:23 visual_prompt]: Epoch 17 / 100: avg data time: 5.60e+00, avg batch time: 7.0502, average train loss: 0.7071
[12/02 00:14:20 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.5868, average loss: 0.7372
[12/02 00:14:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 69.35	
[12/02 00:14:20 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.24628696578449955
[12/02 00:22:33 visual_prompt]: Epoch 18 / 100: avg data time: 5.59e+00, avg batch time: 7.0407, average train loss: 0.6589
[12/02 00:23:29 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.5870, average loss: 0.8665
[12/02 00:23:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 67.24	
[12/02 00:23:29 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.24515771199228986
[12/02 00:31:44 visual_prompt]: Epoch 19 / 100: avg data time: 5.61e+00, avg batch time: 7.0654, average train loss: 0.6976
[12/02 00:32:41 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.5908, average loss: 0.7330
[12/02 00:32:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 69.00	
[12/02 00:32:41 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.2438820645368942
[12/02 00:41:00 visual_prompt]: Epoch 20 / 100: avg data time: 5.67e+00, avg batch time: 7.1226, average train loss: 0.6483
[12/02 00:41:56 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.5900, average loss: 0.6675
[12/02 00:41:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 68.89	
[12/02 00:41:56 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.24246157759823855
[12/02 00:50:11 visual_prompt]: Epoch 21 / 100: avg data time: 5.62e+00, avg batch time: 7.0740, average train loss: 0.6479
[12/02 00:51:08 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.5840, average loss: 0.6294
[12/02 00:51:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 70.52	
[12/02 00:51:08 visual_prompt]: Best epoch 21: best metric: -0.629
[12/02 00:51:08 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.24089798182084843
[12/02 00:59:23 visual_prompt]: Epoch 22 / 100: avg data time: 5.61e+00, avg batch time: 7.0642, average train loss: 0.6924
[12/02 01:00:19 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.5897, average loss: 0.7633
[12/02 01:00:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 70.28	
[12/02 01:00:19 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.2391931822053251
[12/02 01:08:35 visual_prompt]: Epoch 23 / 100: avg data time: 5.63e+00, avg batch time: 7.0845, average train loss: 0.6249
[12/02 01:09:32 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.5859, average loss: 0.6565
[12/02 01:09:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 70.39	
[12/02 01:09:32 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.23734925578739588
[12/02 01:17:46 visual_prompt]: Epoch 24 / 100: avg data time: 5.61e+00, avg batch time: 7.0606, average train loss: 0.6188
[12/02 01:18:43 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.5910, average loss: 0.6495
[12/02 01:18:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 70.65	
[12/02 01:18:43 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.23536844910736587
[12/02 01:27:01 visual_prompt]: Epoch 25 / 100: avg data time: 5.66e+00, avg batch time: 7.1072, average train loss: 0.6241
[12/02 01:27:58 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.5864, average loss: 0.6280
[12/02 01:27:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.07	rocauc: 71.39	
[12/02 01:27:58 visual_prompt]: Best epoch 25: best metric: -0.628
[12/02 01:27:58 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.23325317547305485
[12/02 01:36:12 visual_prompt]: Epoch 26 / 100: avg data time: 5.60e+00, avg batch time: 7.0596, average train loss: 0.6357
[12/02 01:37:09 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.5865, average loss: 0.7313
[12/02 01:37:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 69.71	
[12/02 01:37:09 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.23100601201955323
[12/02 01:45:22 visual_prompt]: Epoch 27 / 100: avg data time: 5.59e+00, avg batch time: 7.0405, average train loss: 0.6302
[12/02 01:46:18 visual_prompt]: Inference (val):avg data time: 3.83e-05, avg batch time: 0.5849, average loss: 0.6566
[12/02 01:46:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 69.82	
[12/02 01:46:18 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.2286296965693802
[12/02 01:54:33 visual_prompt]: Epoch 28 / 100: avg data time: 5.61e+00, avg batch time: 7.0629, average train loss: 0.6583
[12/02 01:55:29 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.5894, average loss: 0.6500
[12/02 01:55:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 71.31	
[12/02 01:55:29 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.22612712429686843
[12/02 02:03:43 visual_prompt]: Epoch 29 / 100: avg data time: 5.59e+00, avg batch time: 7.0465, average train loss: 0.5901
[12/02 02:04:39 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.5900, average loss: 0.8336
[12/02 02:04:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 70.95	
[12/02 02:04:39 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.22350134420084022
[12/02 02:12:54 visual_prompt]: Epoch 30 / 100: avg data time: 5.62e+00, avg batch time: 7.0694, average train loss: 0.6291
[12/02 02:13:51 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.5857, average loss: 0.7306
[12/02 02:13:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 73.39	
[12/02 02:13:51 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.22075555538987224
[12/02 02:22:07 visual_prompt]: Epoch 31 / 100: avg data time: 5.62e+00, avg batch time: 7.0779, average train loss: 0.5906
[12/02 02:23:04 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.5891, average loss: 0.6496
[12/02 02:23:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.07	rocauc: 71.02	
[12/02 02:23:04 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.21789310318467428
[12/02 02:31:19 visual_prompt]: Epoch 32 / 100: avg data time: 5.61e+00, avg batch time: 7.0654, average train loss: 0.5705
[12/02 02:32:15 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.5894, average loss: 0.8293
[12/02 02:32:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 53.66	rocauc: 69.90	
[12/02 02:32:15 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.21491747504233139
[12/02 02:40:30 visual_prompt]: Epoch 33 / 100: avg data time: 5.61e+00, avg batch time: 7.0679, average train loss: 0.5882
[12/02 02:41:27 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.5874, average loss: 0.6304
[12/02 02:41:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 71.57	
[12/02 02:41:27 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.21183229630737466
[12/02 02:49:41 visual_prompt]: Epoch 34 / 100: avg data time: 5.60e+00, avg batch time: 7.0575, average train loss: 0.5776
[12/02 02:50:37 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.5868, average loss: 0.7886
[12/02 02:50:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 69.24	
[12/02 02:50:37 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.20864132579485728
[12/02 02:58:52 visual_prompt]: Epoch 35 / 100: avg data time: 5.61e+00, avg batch time: 7.0648, average train loss: 0.5387
[12/02 02:59:49 visual_prompt]: Inference (val):avg data time: 3.41e-05, avg batch time: 0.5918, average loss: 0.7839
[12/02 02:59:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 70.40	
[12/02 02:59:49 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.2053484512108174
[12/02 03:08:04 visual_prompt]: Epoch 36 / 100: avg data time: 5.62e+00, avg batch time: 7.0716, average train loss: 0.5418
[12/02 03:09:00 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.5864, average loss: 0.6763
[12/02 03:09:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 73.05	
[12/02 03:09:00 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.20195768441570727
[12/02 03:17:17 visual_prompt]: Epoch 37 / 100: avg data time: 5.64e+00, avg batch time: 7.0964, average train loss: 0.5536
[12/02 03:18:14 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.5890, average loss: 0.6677
[12/02 03:18:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.67	rocauc: 72.03	
[12/02 03:18:14 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.19847315653655914
[12/02 03:26:32 visual_prompt]: Epoch 38 / 100: avg data time: 5.66e+00, avg batch time: 7.1086, average train loss: 0.5113
[12/02 03:27:29 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.5862, average loss: 0.7031
[12/02 03:27:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 69.23	
[12/02 03:27:29 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.19489911293384335
[12/02 03:35:45 visual_prompt]: Epoch 39 / 100: avg data time: 5.62e+00, avg batch time: 7.0810, average train loss: 0.5325
[12/02 03:36:41 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.5889, average loss: 0.6422
[12/02 03:36:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.07	rocauc: 72.11	
[12/02 03:36:41 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.1912399080291506
[12/02 03:44:55 visual_prompt]: Epoch 40 / 100: avg data time: 5.59e+00, avg batch time: 7.0475, average train loss: 0.5404
[12/02 03:45:52 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.5926, average loss: 0.8179
[12/02 03:45:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 70.55	
[12/02 03:45:52 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.1875
[12/02 03:54:06 visual_prompt]: Epoch 41 / 100: avg data time: 5.61e+00, avg batch time: 7.0617, average train loss: 0.5060
[12/02 03:55:03 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.5854, average loss: 0.7034
[12/02 03:55:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 68.82	
[12/02 03:55:03 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.18368394534823634
[12/02 04:03:19 visual_prompt]: Epoch 42 / 100: avg data time: 5.63e+00, avg batch time: 7.0812, average train loss: 0.4729
[12/02 04:04:16 visual_prompt]: Inference (val):avg data time: 3.68e-05, avg batch time: 0.5887, average loss: 0.6900
[12/02 04:04:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 67.80	
[12/02 04:04:16 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.17979639334863468
[12/02 04:12:33 visual_prompt]: Epoch 43 / 100: avg data time: 5.64e+00, avg batch time: 7.0969, average train loss: 0.4820
[12/02 04:13:29 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.5899, average loss: 0.6674
[12/02 04:13:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 72.68	
[12/02 04:13:29 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.17584208038447505
[12/02 04:21:46 visual_prompt]: Epoch 44 / 100: avg data time: 5.63e+00, avg batch time: 7.0869, average train loss: 0.4856
[12/02 04:22:42 visual_prompt]: Inference (val):avg data time: 3.26e-05, avg batch time: 0.5928, average loss: 0.7338
[12/02 04:22:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 69.77	
[12/02 04:22:42 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.17182582417698902
[12/02 04:30:57 visual_prompt]: Epoch 45 / 100: avg data time: 5.60e+00, avg batch time: 7.0615, average train loss: 0.5048
[12/02 04:31:53 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.5888, average loss: 0.7481
[12/02 04:31:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 70.72	
[12/02 04:31:53 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.1677525179157086
[12/02 04:40:08 visual_prompt]: Epoch 46 / 100: avg data time: 5.61e+00, avg batch time: 7.0665, average train loss: 0.4395
[12/02 04:41:05 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.5880, average loss: 0.7621
[12/02 04:41:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 68.24	
[12/02 04:41:05 visual_prompt]: Stopping early.
[12/02 04:41:05 visual_prompt]: Rank of current process: 0. World size: 1
[12/02 04:41:05 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[12/02 04:41:05 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[12/02 04:41:05 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[12/02 04:41:05 visual_prompt]: Training with config:
[12/02 04:41:05 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr0.25_wd0.0/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.25, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[12/02 04:41:05 visual_prompt]: Loading training data...
[12/02 04:41:05 visual_prompt]: Constructing mammo-cbis dataset train...
[12/02 04:41:05 visual_prompt]: Loading validation data...
[12/02 04:41:05 visual_prompt]: Constructing mammo-cbis dataset val...
[12/02 04:41:05 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[12/02 04:41:09 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[12/02 04:41:09 visual_prompt]: tuned percent:0.532
[12/02 04:41:09 visual_prompt]: Device used for model: 0
[12/02 04:41:09 visual_prompt]: Setting up Evaluator...
[12/02 04:41:09 visual_prompt]: Setting up Trainer...
[12/02 04:41:09 visual_prompt]: 	Setting up the optimizer...
[12/02 04:41:09 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[12/02 04:49:25 visual_prompt]: Epoch 1 / 100: avg data time: 5.64e+00, avg batch time: 7.0912, average train loss: 1.4863
[12/02 04:50:22 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.5877, average loss: 1.4553
[12/02 04:50:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[12/02 04:50:22 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.025
[12/02 04:58:37 visual_prompt]: Epoch 2 / 100: avg data time: 5.61e+00, avg batch time: 7.0676, average train loss: 0.9797
[12/02 04:59:33 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.5920, average loss: 0.7201
[12/02 04:59:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.31	
[12/02 04:59:33 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.05
[12/02 05:07:48 visual_prompt]: Epoch 3 / 100: avg data time: 5.61e+00, avg batch time: 7.0660, average train loss: 0.7163
[12/02 05:08:45 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.5871, average loss: 0.7427
[12/02 05:08:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.67	
[12/02 05:08:45 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.075
[12/02 05:16:58 visual_prompt]: Epoch 4 / 100: avg data time: 5.59e+00, avg batch time: 7.0402, average train loss: 0.7474
[12/02 05:17:54 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.5891, average loss: 0.7969
[12/02 05:17:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.16	
[12/02 05:17:54 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.1
[12/02 05:26:08 visual_prompt]: Epoch 5 / 100: avg data time: 5.59e+00, avg batch time: 7.0454, average train loss: 0.7629
[12/02 05:27:04 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.5865, average loss: 0.7053
[12/02 05:27:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.74	
[12/02 05:27:04 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.125
[12/02 05:35:23 visual_prompt]: Epoch 6 / 100: avg data time: 5.67e+00, avg batch time: 7.1171, average train loss: 0.7480
[12/02 05:36:19 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.5889, average loss: 0.6837
[12/02 05:36:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.51	
[12/02 05:36:19 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.15
[12/02 05:44:34 visual_prompt]: Epoch 7 / 100: avg data time: 5.61e+00, avg batch time: 7.0672, average train loss: 0.7033
[12/02 05:45:31 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.5871, average loss: 1.2788
[12/02 05:45:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 64.86	
[12/02 05:45:31 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.175
[12/02 05:53:46 visual_prompt]: Epoch 8 / 100: avg data time: 5.62e+00, avg batch time: 7.0689, average train loss: 0.7262
[12/02 05:54:43 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.5889, average loss: 1.1075
[12/02 05:54:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 65.03	
[12/02 05:54:43 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.2
[12/02 06:02:57 visual_prompt]: Epoch 9 / 100: avg data time: 5.61e+00, avg batch time: 7.0670, average train loss: 0.7955
[12/02 06:03:54 visual_prompt]: Inference (val):avg data time: 4.32e-05, avg batch time: 0.5941, average loss: 0.6798
[12/02 06:03:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 63.99	
[12/02 06:03:54 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.225
[12/02 06:12:08 visual_prompt]: Epoch 10 / 100: avg data time: 5.61e+00, avg batch time: 7.0606, average train loss: 0.6855
[12/02 06:13:05 visual_prompt]: Inference (val):avg data time: 3.57e-05, avg batch time: 0.5905, average loss: 0.6707
[12/02 06:13:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 66.98	
[12/02 06:13:05 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.25
[12/02 06:21:21 visual_prompt]: Epoch 11 / 100: avg data time: 5.63e+00, avg batch time: 7.0870, average train loss: 0.7567
[12/02 06:22:18 visual_prompt]: Inference (val):avg data time: 3.47e-05, avg batch time: 0.5851, average loss: 0.8582
[12/02 06:22:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 66.06	
[12/02 06:22:18 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.24992385337738698
[12/02 06:30:37 visual_prompt]: Epoch 12 / 100: avg data time: 5.66e+00, avg batch time: 7.1170, average train loss: 0.7438
[12/02 06:31:33 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.5902, average loss: 0.6770
[12/02 06:31:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 67.46	
[12/02 06:31:33 visual_prompt]: Best epoch 12: best metric: -0.677
[12/02 06:31:33 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.24969550628247802
[12/02 06:39:48 visual_prompt]: Epoch 13 / 100: avg data time: 5.61e+00, avg batch time: 7.0617, average train loss: 0.7849
[12/02 06:40:44 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.5858, average loss: 0.6623
[12/02 06:40:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 65.83	
[12/02 06:40:44 visual_prompt]: Best epoch 13: best metric: -0.662
[12/02 06:40:44 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.24931523692103416
[12/02 06:48:59 visual_prompt]: Epoch 14 / 100: avg data time: 5.61e+00, avg batch time: 7.0604, average train loss: 0.6978
[12/02 06:49:55 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.5944, average loss: 0.6987
[12/02 06:49:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.07	rocauc: 68.24	
[12/02 06:49:55 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.2487835085926963
[12/02 06:58:08 visual_prompt]: Epoch 15 / 100: avg data time: 5.58e+00, avg batch time: 7.0387, average train loss: 0.7028
[12/02 06:59:05 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.5865, average loss: 0.6472
[12/02 06:59:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 68.56	
[12/02 06:59:05 visual_prompt]: Best epoch 15: best metric: -0.647
[12/02 06:59:05 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.24810096912652602
[12/02 07:07:19 visual_prompt]: Epoch 16 / 100: avg data time: 5.61e+00, avg batch time: 7.0635, average train loss: 0.6770
[12/02 07:08:16 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.5857, average loss: 0.6824
[12/02 07:08:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 67.82	
[12/02 07:08:16 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.2472684500917257
[12/02 07:16:28 visual_prompt]: Epoch 17 / 100: avg data time: 5.58e+00, avg batch time: 7.0349, average train loss: 0.7268
[12/02 07:17:25 visual_prompt]: Inference (val):avg data time: 3.38e-05, avg batch time: 0.5871, average loss: 0.7043
[12/02 07:17:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 69.13	
[12/02 07:17:25 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.24628696578449955
[12/02 07:25:41 visual_prompt]: Epoch 18 / 100: avg data time: 5.64e+00, avg batch time: 7.0917, average train loss: 0.6486
[12/02 07:26:38 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.5892, average loss: 0.8783
[12/02 07:26:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 67.12	
[12/02 07:26:38 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.24515771199228986
[12/02 07:34:54 visual_prompt]: Epoch 19 / 100: avg data time: 5.62e+00, avg batch time: 7.0761, average train loss: 0.6995
[12/02 07:35:50 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.5864, average loss: 0.7400
[12/02 07:35:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 68.44	
[12/02 07:35:50 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.2438820645368942
[12/02 07:44:06 visual_prompt]: Epoch 20 / 100: avg data time: 5.63e+00, avg batch time: 7.0799, average train loss: 0.6414
[12/02 07:45:03 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.5901, average loss: 0.6653
[12/02 07:45:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 69.60	
[12/02 07:45:03 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.24246157759823855
[12/02 07:53:17 visual_prompt]: Epoch 21 / 100: avg data time: 5.61e+00, avg batch time: 7.0664, average train loss: 0.6528
[12/02 07:54:14 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.5886, average loss: 0.6631
[12/02 07:54:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 70.48	
[12/02 07:54:14 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.24089798182084843
[12/02 08:02:29 visual_prompt]: Epoch 22 / 100: avg data time: 5.62e+00, avg batch time: 7.0722, average train loss: 0.6738
[12/02 08:03:26 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.5852, average loss: 0.7469
[12/02 08:03:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 71.20	
[12/02 08:03:26 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.2391931822053251
[12/02 08:11:44 visual_prompt]: Epoch 23 / 100: avg data time: 5.66e+00, avg batch time: 7.1091, average train loss: 0.6244
[12/02 08:12:41 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.5913, average loss: 0.6813
[12/02 08:12:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 69.94	
[12/02 08:12:41 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.23734925578739588
[12/02 08:20:56 visual_prompt]: Epoch 24 / 100: avg data time: 5.62e+00, avg batch time: 7.0740, average train loss: 0.6168
[12/02 08:21:53 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.5892, average loss: 0.6321
[12/02 08:21:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.89	rocauc: 70.16	
[12/02 08:21:53 visual_prompt]: Best epoch 24: best metric: -0.632
[12/02 08:21:53 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.23536844910736587
[12/02 08:30:08 visual_prompt]: Epoch 25 / 100: avg data time: 5.62e+00, avg batch time: 7.0693, average train loss: 0.6264
[12/02 08:31:04 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.5891, average loss: 0.6319
[12/02 08:31:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 70.70	
[12/02 08:31:04 visual_prompt]: Best epoch 25: best metric: -0.632
[12/02 08:31:04 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.23325317547305485
[12/02 08:39:18 visual_prompt]: Epoch 26 / 100: avg data time: 5.60e+00, avg batch time: 7.0535, average train loss: 0.6416
[12/02 08:40:15 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.5879, average loss: 0.7645
[12/02 08:40:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 70.99	
[12/02 08:40:15 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.23100601201955323
[12/02 08:48:31 visual_prompt]: Epoch 27 / 100: avg data time: 5.64e+00, avg batch time: 7.0907, average train loss: 0.6318
[12/02 08:49:28 visual_prompt]: Inference (val):avg data time: 3.59e-05, avg batch time: 0.5844, average loss: 0.6800
[12/02 08:49:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 72.19	
[12/02 08:49:28 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.2286296965693802
[12/02 08:57:44 visual_prompt]: Epoch 28 / 100: avg data time: 5.62e+00, avg batch time: 7.0790, average train loss: 0.6410
[12/02 08:58:41 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.5898, average loss: 0.6618
[12/02 08:58:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 70.80	
[12/02 08:58:41 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.22612712429686843
[12/02 09:06:55 visual_prompt]: Epoch 29 / 100: avg data time: 5.61e+00, avg batch time: 7.0577, average train loss: 0.5998
[12/02 09:07:52 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.5929, average loss: 0.8979
[12/02 09:07:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 70.34	
[12/02 09:07:52 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.22350134420084022
[12/02 09:16:07 visual_prompt]: Epoch 30 / 100: avg data time: 5.63e+00, avg batch time: 7.0817, average train loss: 0.6431
[12/02 09:17:04 visual_prompt]: Inference (val):avg data time: 3.32e-05, avg batch time: 0.5883, average loss: 0.7204
[12/02 09:17:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.01	rocauc: 70.93	
[12/02 09:17:04 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.22075555538987224
[12/02 09:25:18 visual_prompt]: Epoch 31 / 100: avg data time: 5.60e+00, avg batch time: 7.0523, average train loss: 0.5813
[12/02 09:26:15 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.5892, average loss: 0.6421
[12/02 09:26:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 70.18	
[12/02 09:26:15 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.21789310318467428
[12/02 09:34:30 visual_prompt]: Epoch 32 / 100: avg data time: 5.62e+00, avg batch time: 7.0717, average train loss: 0.5795
[12/02 09:35:27 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.5901, average loss: 0.7390
[12/02 09:35:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 73.18	
[12/02 09:35:27 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.21491747504233139
[12/02 09:43:46 visual_prompt]: Epoch 33 / 100: avg data time: 5.67e+00, avg batch time: 7.1226, average train loss: 0.6177
[12/02 09:44:43 visual_prompt]: Inference (val):avg data time: 3.38e-05, avg batch time: 0.5869, average loss: 0.6541
[12/02 09:44:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 71.09	
[12/02 09:44:43 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.21183229630737466
[12/02 09:52:57 visual_prompt]: Epoch 34 / 100: avg data time: 5.60e+00, avg batch time: 7.0580, average train loss: 0.5526
[12/02 09:53:54 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.5894, average loss: 0.6405
[12/02 09:53:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 68.70	rocauc: 71.90	
[12/02 09:53:54 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.20864132579485728
[12/02 10:02:08 visual_prompt]: Epoch 35 / 100: avg data time: 5.61e+00, avg batch time: 7.0619, average train loss: 0.5288
[12/02 10:03:05 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.5881, average loss: 0.6733
[12/02 10:03:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.07	rocauc: 70.59	
[12/02 10:03:05 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.2053484512108174
[12/02 10:11:21 visual_prompt]: Epoch 36 / 100: avg data time: 5.63e+00, avg batch time: 7.0843, average train loss: 0.5462
[12/02 10:12:17 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.5846, average loss: 0.7197
[12/02 10:12:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 69.81	
[12/02 10:12:17 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.20195768441570727
[12/02 10:20:32 visual_prompt]: Epoch 37 / 100: avg data time: 5.61e+00, avg batch time: 7.0598, average train loss: 0.5590
[12/02 10:21:28 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.5878, average loss: 0.6606
[12/02 10:21:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 68.70	rocauc: 70.86	
[12/02 10:21:28 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.19847315653655914
[12/02 10:29:41 visual_prompt]: Epoch 38 / 100: avg data time: 5.59e+00, avg batch time: 7.0389, average train loss: 0.5231
[12/02 10:30:37 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.5896, average loss: 0.6995
[12/02 10:30:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 71.39	
[12/02 10:30:37 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.19489911293384335
[12/02 10:38:54 visual_prompt]: Epoch 39 / 100: avg data time: 5.63e+00, avg batch time: 7.0865, average train loss: 0.5196
[12/02 10:39:51 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.5873, average loss: 0.6612
[12/02 10:39:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 72.29	
[12/02 10:39:51 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.1912399080291506
[12/02 10:48:07 visual_prompt]: Epoch 40 / 100: avg data time: 5.63e+00, avg batch time: 7.0891, average train loss: 0.5347
[12/02 10:49:04 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.5858, average loss: 0.6859
[12/02 10:49:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.89	rocauc: 71.09	
[12/02 10:49:04 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.1875
[12/02 10:57:17 visual_prompt]: Epoch 41 / 100: avg data time: 5.60e+00, avg batch time: 7.0515, average train loss: 0.4957
[12/02 10:58:14 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.5884, average loss: 0.7321
[12/02 10:58:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 70.92	
[12/02 10:58:14 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.18368394534823634
[12/02 11:06:26 visual_prompt]: Epoch 42 / 100: avg data time: 5.57e+00, avg batch time: 7.0276, average train loss: 0.4701
[12/02 11:07:16 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.5869, average loss: 0.7339
[12/02 11:07:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 65.27	
[12/02 11:07:16 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.17979639334863468
[12/02 11:14:34 visual_prompt]: Epoch 43 / 100: avg data time: 4.80e+00, avg batch time: 6.2553, average train loss: 0.4696
[12/02 11:15:24 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.5863, average loss: 0.6568
[12/02 11:15:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 73.15	
[12/02 11:15:25 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.17584208038447505
[12/02 11:22:43 visual_prompt]: Epoch 44 / 100: avg data time: 4.80e+00, avg batch time: 6.2560, average train loss: 0.4941
[12/02 11:23:32 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.5869, average loss: 0.7012
[12/02 11:23:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 70.78	
[12/02 11:23:32 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.17182582417698902
[12/02 11:30:44 visual_prompt]: Epoch 45 / 100: avg data time: 4.71e+00, avg batch time: 6.1639, average train loss: 0.5093
[12/02 11:31:33 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.5870, average loss: 0.8928
[12/02 11:31:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 69.38	
[12/02 11:31:33 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.1677525179157086
[12/02 11:38:44 visual_prompt]: Epoch 46 / 100: avg data time: 4.69e+00, avg batch time: 6.1478, average train loss: 0.4583
[12/02 11:39:33 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.5874, average loss: 0.7513
[12/02 11:39:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 67.17	
[12/02 11:39:33 visual_prompt]: Stopping early.
[12/02 11:39:33 visual_prompt]: Rank of current process: 0. World size: 1
[12/02 11:39:33 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[12/02 11:39:33 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[12/02 11:39:33 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[12/02 11:39:33 visual_prompt]: Training with config:
[12/02 11:39:33 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr0.1_wd0.01/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.1, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[12/02 11:39:33 visual_prompt]: Loading training data...
[12/02 11:39:33 visual_prompt]: Constructing mammo-cbis dataset train...
[12/02 11:39:33 visual_prompt]: Loading validation data...
[12/02 11:39:33 visual_prompt]: Constructing mammo-cbis dataset val...
[12/02 11:39:33 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[12/02 11:39:36 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[12/02 11:39:36 visual_prompt]: tuned percent:0.532
[12/02 11:39:36 visual_prompt]: Device used for model: 0
[12/02 11:39:36 visual_prompt]: Setting up Evaluator...
[12/02 11:39:36 visual_prompt]: Setting up Trainer...
[12/02 11:39:36 visual_prompt]: 	Setting up the optimizer...
[12/02 11:39:36 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[12/02 11:46:50 visual_prompt]: Epoch 1 / 100: avg data time: 4.75e+00, avg batch time: 6.2014, average train loss: 1.4863
[12/02 11:47:40 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.5872, average loss: 1.4553
[12/02 11:47:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[12/02 11:47:40 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.010000000000000002
[12/02 11:54:58 visual_prompt]: Epoch 2 / 100: avg data time: 4.79e+00, avg batch time: 6.2487, average train loss: 0.9470
[12/02 11:55:48 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.5888, average loss: 0.6877
[12/02 11:55:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 52.80	
[12/02 11:55:48 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.020000000000000004
[12/02 12:03:05 visual_prompt]: Epoch 3 / 100: avg data time: 4.79e+00, avg batch time: 6.2455, average train loss: 0.7053
[12/02 12:03:55 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.5893, average loss: 0.7360
[12/02 12:03:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.49	
[12/02 12:03:55 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.03
[12/02 12:11:04 visual_prompt]: Epoch 4 / 100: avg data time: 4.68e+00, avg batch time: 6.1320, average train loss: 0.7236
[12/02 12:11:53 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.5888, average loss: 0.7160
[12/02 12:11:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.61	
[12/02 12:11:53 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.04000000000000001
[12/02 12:19:03 visual_prompt]: Epoch 5 / 100: avg data time: 4.68e+00, avg batch time: 6.1319, average train loss: 0.7178
[12/02 12:19:52 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.5870, average loss: 0.6843
[12/02 12:19:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.98	
[12/02 12:19:52 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.05
[12/02 12:27:07 visual_prompt]: Epoch 6 / 100: avg data time: 4.76e+00, avg batch time: 6.2106, average train loss: 0.7115
[12/02 12:27:56 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.5888, average loss: 0.7212
[12/02 12:27:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.97	
[12/02 12:27:56 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.06
[12/02 12:35:13 visual_prompt]: Epoch 7 / 100: avg data time: 4.78e+00, avg batch time: 6.2313, average train loss: 0.7270
[12/02 12:36:03 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.5864, average loss: 0.6919
[12/02 12:36:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 50.41	rocauc: 58.95	
[12/02 12:36:03 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.06999999999999999
[12/02 12:43:18 visual_prompt]: Epoch 8 / 100: avg data time: 4.77e+00, avg batch time: 6.2208, average train loss: 0.7129
[12/02 12:44:08 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.5943, average loss: 0.6984
[12/02 12:44:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.30	
[12/02 12:44:08 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.08000000000000002
[12/02 12:51:18 visual_prompt]: Epoch 9 / 100: avg data time: 4.69e+00, avg batch time: 6.1469, average train loss: 0.7031
[12/02 12:52:07 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.5861, average loss: 0.7259
[12/02 12:52:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.53	
[12/02 12:52:07 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.09000000000000001
[12/02 12:59:18 visual_prompt]: Epoch 10 / 100: avg data time: 4.69e+00, avg batch time: 6.1457, average train loss: 0.6923
[12/02 13:00:07 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.5855, average loss: 0.6895
[12/02 13:00:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.06	
[12/02 13:00:07 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.1
[12/02 13:07:23 visual_prompt]: Epoch 11 / 100: avg data time: 4.78e+00, avg batch time: 6.2307, average train loss: 0.6961
[12/02 13:08:13 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.5861, average loss: 0.6916
[12/02 13:08:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 56.39	
[12/02 13:08:13 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0999695413509548
[12/02 13:15:29 visual_prompt]: Epoch 12 / 100: avg data time: 4.77e+00, avg batch time: 6.2275, average train loss: 0.6969
[12/02 13:16:19 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.5889, average loss: 0.6994
[12/02 13:16:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.45	
[12/02 13:16:19 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.09987820251299122
[12/02 13:23:35 visual_prompt]: Epoch 13 / 100: avg data time: 4.77e+00, avg batch time: 6.2235, average train loss: 0.7053
[12/02 13:24:23 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.5879, average loss: 0.6900
[12/02 13:24:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.61	
[12/02 13:24:23 visual_prompt]: Best epoch 13: best metric: -0.690
[12/02 13:24:23 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.09972609476841367
[12/02 13:31:30 visual_prompt]: Epoch 14 / 100: avg data time: 4.64e+00, avg batch time: 6.0954, average train loss: 0.7083
[12/02 13:32:19 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.5866, average loss: 0.6885
[12/02 13:32:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.32	
[12/02 13:32:19 visual_prompt]: Best epoch 14: best metric: -0.688
[12/02 13:32:19 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.09951340343707853
[12/02 13:39:31 visual_prompt]: Epoch 15 / 100: avg data time: 4.71e+00, avg batch time: 6.1642, average train loss: 0.7088
[12/02 13:40:21 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.5906, average loss: 0.7085
[12/02 13:40:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.31	
[12/02 13:40:21 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.09924038765061041
[12/02 13:47:38 visual_prompt]: Epoch 16 / 100: avg data time: 4.79e+00, avg batch time: 6.2486, average train loss: 0.7287
[12/02 13:48:28 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.5843, average loss: 0.8338
[12/02 13:48:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.60	
[12/02 13:48:28 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.09890738003669029
[12/02 13:55:46 visual_prompt]: Epoch 17 / 100: avg data time: 4.79e+00, avg batch time: 6.2418, average train loss: 0.7250
[12/02 13:56:36 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.5848, average loss: 0.6892
[12/02 13:56:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.81	
[12/02 13:56:36 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.09851478631379983
[12/02 14:03:52 visual_prompt]: Epoch 18 / 100: avg data time: 4.78e+00, avg batch time: 6.2304, average train loss: 0.7213
[12/02 14:04:42 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.5879, average loss: 0.8450
[12/02 14:04:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.84	
[12/02 14:04:42 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.09806308479691594
[12/02 14:11:57 visual_prompt]: Epoch 19 / 100: avg data time: 4.77e+00, avg batch time: 6.2177, average train loss: 0.7093
[12/02 14:12:47 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.5859, average loss: 0.7779
[12/02 14:12:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.53	
[12/02 14:12:47 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.09755282581475769
[12/02 14:20:03 visual_prompt]: Epoch 20 / 100: avg data time: 4.78e+00, avg batch time: 6.2276, average train loss: 0.7058
[12/02 14:20:53 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.5883, average loss: 0.7007
[12/02 14:20:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.80	
[12/02 14:20:53 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.09698463103929543
[12/02 14:28:04 visual_prompt]: Epoch 21 / 100: avg data time: 4.71e+00, avg batch time: 6.1558, average train loss: 0.7006
[12/02 14:28:53 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.5895, average loss: 0.7117
[12/02 14:28:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.88	
[12/02 14:28:53 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.09635919272833937
[12/02 14:36:11 visual_prompt]: Epoch 22 / 100: avg data time: 4.80e+00, avg batch time: 6.2551, average train loss: 0.7042
[12/02 14:37:01 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.5886, average loss: 0.6975
[12/02 14:37:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.84	
[12/02 14:37:01 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.09567727288213004
[12/02 14:44:20 visual_prompt]: Epoch 23 / 100: avg data time: 4.82e+00, avg batch time: 6.2706, average train loss: 0.6960
[12/02 14:45:10 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.5854, average loss: 0.7023
[12/02 14:45:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 63.91	
[12/02 14:45:10 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.09493970231495835
[12/02 14:52:27 visual_prompt]: Epoch 24 / 100: avg data time: 4.79e+00, avg batch time: 6.2416, average train loss: 0.6960
[12/02 14:53:17 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.5862, average loss: 0.6989
[12/02 14:53:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.51	
[12/02 14:53:17 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.09414737964294635
[12/02 15:00:34 visual_prompt]: Epoch 25 / 100: avg data time: 4.80e+00, avg batch time: 6.2522, average train loss: 0.6955
[12/02 15:01:24 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.5945, average loss: 0.7162
[12/02 15:01:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.74	
[12/02 15:01:24 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.09330127018922195
[12/02 15:08:39 visual_prompt]: Epoch 26 / 100: avg data time: 4.75e+00, avg batch time: 6.2035, average train loss: 0.7033
[12/02 15:09:28 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.5883, average loss: 0.6946
[12/02 15:09:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.68	
[12/02 15:09:28 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.0924024048078213
[12/02 15:16:38 visual_prompt]: Epoch 27 / 100: avg data time: 4.68e+00, avg batch time: 6.1354, average train loss: 0.6954
[12/02 15:17:27 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.5870, average loss: 0.6879
[12/02 15:17:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.16	
[12/02 15:17:27 visual_prompt]: Best epoch 27: best metric: -0.688
[12/02 15:17:27 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.09145187862775209
[12/02 15:24:54 visual_prompt]: Epoch 28 / 100: avg data time: 4.92e+00, avg batch time: 6.3795, average train loss: 0.6974
[12/02 15:25:44 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.5869, average loss: 0.6960
[12/02 15:25:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.43	
[12/02 15:25:44 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.09045084971874738
[12/02 15:33:03 visual_prompt]: Epoch 29 / 100: avg data time: 4.82e+00, avg batch time: 6.2725, average train loss: 0.6916
[12/02 15:33:55 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.5908, average loss: 0.6871
[12/02 15:33:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.03	
[12/02 15:33:55 visual_prompt]: Best epoch 29: best metric: -0.687
[12/02 15:33:55 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.0894005376803361
[12/02 15:41:14 visual_prompt]: Epoch 30 / 100: avg data time: 4.81e+00, avg batch time: 6.2624, average train loss: 0.6998
[12/02 15:42:04 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.5861, average loss: 0.6899
[12/02 15:42:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.69	
[12/02 15:42:04 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.0883022221559489
[12/02 15:49:20 visual_prompt]: Epoch 31 / 100: avg data time: 4.78e+00, avg batch time: 6.2340, average train loss: 0.6951
[12/02 15:50:10 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.5858, average loss: 0.6898
[12/02 15:50:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.87	
[12/02 15:50:10 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.08715724127386971
[12/02 15:57:27 visual_prompt]: Epoch 32 / 100: avg data time: 4.79e+00, avg batch time: 6.2415, average train loss: 0.7010
[12/02 15:58:18 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.5852, average loss: 0.7336
[12/02 15:58:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.85	
[12/02 15:58:18 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.08596699001693256
[12/02 16:05:32 visual_prompt]: Epoch 33 / 100: avg data time: 4.75e+00, avg batch time: 6.2032, average train loss: 0.6965
[12/02 16:06:21 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.5843, average loss: 0.6917
[12/02 16:06:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 53.66	rocauc: 62.27	
[12/02 16:06:21 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.08473291852294987
[12/02 16:13:32 visual_prompt]: Epoch 34 / 100: avg data time: 4.69e+00, avg batch time: 6.1470, average train loss: 0.6946
[12/02 16:14:21 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.5871, average loss: 0.6879
[12/02 16:14:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.21	
[12/02 16:14:21 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.08345653031794292
[12/02 16:21:31 visual_prompt]: Epoch 35 / 100: avg data time: 4.70e+00, avg batch time: 6.1463, average train loss: 0.7001
[12/02 16:22:21 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.5876, average loss: 0.6938
[12/02 16:22:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.13	
[12/02 16:22:21 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.08213938048432697
[12/02 16:29:36 visual_prompt]: Epoch 36 / 100: avg data time: 4.77e+00, avg batch time: 6.2254, average train loss: 0.6927
[12/02 16:30:26 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.5932, average loss: 0.6883
[12/02 16:30:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.65	
[12/02 16:30:26 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.08078307376628291
[12/02 16:37:40 visual_prompt]: Epoch 37 / 100: avg data time: 4.75e+00, avg batch time: 6.2011, average train loss: 0.6931
[12/02 16:38:30 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.5886, average loss: 0.7913
[12/02 16:38:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.57	
[12/02 16:38:30 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.07938926261462366
[12/02 16:45:44 visual_prompt]: Epoch 38 / 100: avg data time: 4.75e+00, avg batch time: 6.2034, average train loss: 0.6962
[12/02 16:46:34 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.5884, average loss: 0.6965
[12/02 16:46:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.03	
[12/02 16:46:34 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.07795964517353735
[12/02 16:53:47 visual_prompt]: Epoch 39 / 100: avg data time: 4.73e+00, avg batch time: 6.1876, average train loss: 0.7008
[12/02 16:54:36 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.5900, average loss: 0.6908
[12/02 16:54:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.58	
[12/02 16:54:36 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.07649596321166025
[12/02 17:01:51 visual_prompt]: Epoch 40 / 100: avg data time: 4.75e+00, avg batch time: 6.2089, average train loss: 0.6914
[12/02 17:02:41 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.5909, average loss: 0.6844
[12/02 17:02:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.77	
[12/02 17:02:41 visual_prompt]: Best epoch 40: best metric: -0.684
[12/02 17:02:41 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.07500000000000001
[12/02 17:09:55 visual_prompt]: Epoch 41 / 100: avg data time: 4.75e+00, avg batch time: 6.2023, average train loss: 0.6982
[12/02 17:10:45 visual_prompt]: Inference (val):avg data time: 1.86e-04, avg batch time: 0.6285, average loss: 0.6918
[12/02 17:10:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.87	
[12/02 17:10:45 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.07347357813929455
[12/02 17:17:59 visual_prompt]: Epoch 42 / 100: avg data time: 4.73e+00, avg batch time: 6.1856, average train loss: 0.7008
[12/02 17:18:48 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.5837, average loss: 0.7023
[12/02 17:18:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.80	
[12/02 17:18:48 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.07191855733945388
[12/02 17:25:52 visual_prompt]: Epoch 43 / 100: avg data time: 4.60e+00, avg batch time: 6.0540, average train loss: 0.6960
[12/02 17:26:41 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.5872, average loss: 0.6900
[12/02 17:26:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.63	
[12/02 17:26:41 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.07033683215379002
[12/02 17:33:49 visual_prompt]: Epoch 44 / 100: avg data time: 4.66e+00, avg batch time: 6.1138, average train loss: 0.6979
[12/02 17:34:38 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.5879, average loss: 0.7074
[12/02 17:34:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.46	
[12/02 17:34:38 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.0687303296707956
[12/02 17:41:49 visual_prompt]: Epoch 45 / 100: avg data time: 4.70e+00, avg batch time: 6.1496, average train loss: 0.6933
[12/02 17:42:38 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.5865, average loss: 0.7020
[12/02 17:42:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.02	
[12/02 17:42:38 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.06710100716628345
[12/02 17:49:48 visual_prompt]: Epoch 46 / 100: avg data time: 4.68e+00, avg batch time: 6.1406, average train loss: 0.6962
[12/02 17:50:37 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.5906, average loss: 0.6898
[12/02 17:50:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.06	
[12/02 17:50:37 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.06545084971874737
[12/02 17:57:53 visual_prompt]: Epoch 47 / 100: avg data time: 4.77e+00, avg batch time: 6.2274, average train loss: 0.7006
[12/02 17:58:43 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.5883, average loss: 0.6995
[12/02 17:58:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.47	
[12/02 17:58:43 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.06378186779084996
[12/02 18:05:56 visual_prompt]: Epoch 48 / 100: avg data time: 4.73e+00, avg batch time: 6.1844, average train loss: 0.7027
[12/02 18:06:47 visual_prompt]: Inference (val):avg data time: 1.18e-04, avg batch time: 0.6054, average loss: 0.7172
[12/02 18:06:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.75	
[12/02 18:06:47 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.06209609477998338
[12/02 18:14:01 visual_prompt]: Epoch 49 / 100: avg data time: 4.75e+00, avg batch time: 6.1968, average train loss: 0.6985
[12/02 18:14:50 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.5852, average loss: 0.6913
[12/02 18:14:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.02	
[12/02 18:14:50 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.06039558454088796
[12/02 18:22:04 visual_prompt]: Epoch 50 / 100: avg data time: 4.73e+00, avg batch time: 6.1892, average train loss: 0.6974
[12/02 18:22:53 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.5882, average loss: 0.6969
[12/02 18:22:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.89	
[12/02 18:22:53 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.058682408883346526
[12/02 18:30:07 visual_prompt]: Epoch 51 / 100: avg data time: 4.74e+00, avg batch time: 6.1996, average train loss: 0.7010
[12/02 18:30:57 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.5877, average loss: 0.6943
[12/02 18:30:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.81	
[12/02 18:30:57 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.05695865504800327
[12/02 18:38:12 visual_prompt]: Epoch 52 / 100: avg data time: 4.76e+00, avg batch time: 6.2103, average train loss: 0.6984
[12/02 18:39:02 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.5866, average loss: 0.6894
[12/02 18:39:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.22	
[12/02 18:39:02 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.05522642316338268
[12/02 18:46:17 visual_prompt]: Epoch 53 / 100: avg data time: 4.77e+00, avg batch time: 6.2227, average train loss: 0.6958
[12/02 18:47:07 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.5912, average loss: 0.6893
[12/02 18:47:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.15	
[12/02 18:47:07 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.05348782368720626
[12/02 18:54:21 visual_prompt]: Epoch 54 / 100: avg data time: 4.74e+00, avg batch time: 6.1930, average train loss: 0.6962
[12/02 18:55:10 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.5874, average loss: 0.7089
[12/02 18:55:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.54	
[12/02 18:55:10 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.05174497483512506
[12/02 19:02:20 visual_prompt]: Epoch 55 / 100: avg data time: 4.69e+00, avg batch time: 6.1407, average train loss: 0.6967
[12/02 19:03:09 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.5885, average loss: 0.6962
[12/02 19:03:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.26	
[12/02 19:03:09 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.05
[12/02 19:10:20 visual_prompt]: Epoch 56 / 100: avg data time: 4.69e+00, avg batch time: 6.1457, average train loss: 0.6972
[12/02 19:11:09 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.5857, average loss: 0.6885
[12/02 19:11:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.59	
[12/02 19:11:09 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.04825502516487497
[12/02 19:18:24 visual_prompt]: Epoch 57 / 100: avg data time: 4.76e+00, avg batch time: 6.2169, average train loss: 0.6957
[12/02 19:19:14 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.5855, average loss: 0.6904
[12/02 19:19:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.51	
[12/02 19:19:14 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.04651217631279374
[12/02 19:26:27 visual_prompt]: Epoch 58 / 100: avg data time: 4.73e+00, avg batch time: 6.1855, average train loss: 0.6987
[12/02 19:27:17 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.5844, average loss: 0.6883
[12/02 19:27:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.56	
[12/02 19:27:17 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.04477357683661734
[12/02 19:34:32 visual_prompt]: Epoch 59 / 100: avg data time: 4.76e+00, avg batch time: 6.2155, average train loss: 0.6923
[12/02 19:35:21 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.5925, average loss: 0.6913
[12/02 19:35:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.70	
[12/02 19:35:21 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.04304134495199674
[12/02 19:42:36 visual_prompt]: Epoch 60 / 100: avg data time: 4.75e+00, avg batch time: 6.2023, average train loss: 0.6916
[12/02 19:43:25 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.5865, average loss: 0.7004
[12/02 19:43:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.36	
[12/02 19:43:25 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.041317591116653486
[12/02 19:50:41 visual_prompt]: Epoch 61 / 100: avg data time: 4.77e+00, avg batch time: 6.2210, average train loss: 0.6921
[12/02 19:51:31 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.5841, average loss: 0.6935
[12/02 19:51:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.50	
[12/02 19:51:31 visual_prompt]: Stopping early.
[12/02 19:51:31 visual_prompt]: Rank of current process: 0. World size: 1
[12/02 19:51:31 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[12/02 19:51:31 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[12/02 19:51:31 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[12/02 19:51:31 visual_prompt]: Training with config:
[12/02 19:51:31 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr0.1_wd0.001/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.1, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[12/02 19:51:31 visual_prompt]: Loading training data...
[12/02 19:51:31 visual_prompt]: Constructing mammo-cbis dataset train...
[12/02 19:51:31 visual_prompt]: Loading validation data...
[12/02 19:51:31 visual_prompt]: Constructing mammo-cbis dataset val...
[12/02 19:51:31 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[12/02 19:51:33 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[12/02 19:51:33 visual_prompt]: tuned percent:0.532
[12/02 19:51:33 visual_prompt]: Device used for model: 0
[12/02 19:51:33 visual_prompt]: Setting up Evaluator...
[12/02 19:51:33 visual_prompt]: Setting up Trainer...
[12/02 19:51:33 visual_prompt]: 	Setting up the optimizer...
[12/02 19:51:33 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[12/02 19:58:50 visual_prompt]: Epoch 1 / 100: avg data time: 4.78e+00, avg batch time: 6.2330, average train loss: 1.4863
[12/02 19:59:39 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.5859, average loss: 1.4553
[12/02 19:59:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[12/02 19:59:39 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.010000000000000002
[12/02 20:07:22 visual_prompt]: Epoch 2 / 100: avg data time: 5.15e+00, avg batch time: 6.6019, average train loss: 0.9491
[12/02 20:08:24 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.5846, average loss: 0.6880
[12/02 20:08:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.07	rocauc: 52.60	
[12/02 20:08:24 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.020000000000000004
[12/02 20:16:54 visual_prompt]: Epoch 3 / 100: avg data time: 5.83e+00, avg batch time: 7.2829, average train loss: 0.7079
[12/02 20:17:52 visual_prompt]: Inference (val):avg data time: 3.67e-05, avg batch time: 0.5881, average loss: 0.7342
[12/02 20:17:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.19	
[12/02 20:17:52 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.03
[12/02 20:26:08 visual_prompt]: Epoch 4 / 100: avg data time: 5.64e+00, avg batch time: 7.0887, average train loss: 0.7299
[12/02 20:27:07 visual_prompt]: Inference (val):avg data time: 5.29e-05, avg batch time: 0.5887, average loss: 0.7114
[12/02 20:27:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.37	
[12/02 20:27:07 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.04000000000000001
[12/02 20:35:33 visual_prompt]: Epoch 5 / 100: avg data time: 5.77e+00, avg batch time: 7.2235, average train loss: 0.7246
[12/02 20:36:31 visual_prompt]: Inference (val):avg data time: 4.09e-05, avg batch time: 0.5871, average loss: 0.6841
[12/02 20:36:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.20	
[12/02 20:36:31 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.05
[12/02 20:44:59 visual_prompt]: Epoch 6 / 100: avg data time: 5.80e+00, avg batch time: 7.2511, average train loss: 0.7315
[12/02 20:45:56 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.5871, average loss: 0.7569
[12/02 20:45:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.02	
[12/02 20:45:56 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.06
[12/02 20:54:18 visual_prompt]: Epoch 7 / 100: avg data time: 5.72e+00, avg batch time: 7.1706, average train loss: 0.7253
[12/02 20:55:17 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.5847, average loss: 0.8021
[12/02 20:55:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.19	
[12/02 20:55:17 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.06999999999999999
[12/02 21:03:41 visual_prompt]: Epoch 8 / 100: avg data time: 5.74e+00, avg batch time: 7.1960, average train loss: 0.7479
[12/02 21:04:38 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.5875, average loss: 0.6975
[12/02 21:04:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.47	rocauc: 60.55	
[12/02 21:04:38 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.08000000000000002
[12/02 21:13:03 visual_prompt]: Epoch 9 / 100: avg data time: 5.75e+00, avg batch time: 7.2043, average train loss: 0.7136
[12/02 21:14:00 visual_prompt]: Inference (val):avg data time: 3.77e-05, avg batch time: 0.5871, average loss: 0.7153
[12/02 21:14:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.35	
[12/02 21:14:00 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.09000000000000001
[12/02 21:22:23 visual_prompt]: Epoch 10 / 100: avg data time: 5.74e+00, avg batch time: 7.1900, average train loss: 0.6824
[12/02 21:23:20 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.5847, average loss: 0.6736
[12/02 21:23:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 63.72	
[12/02 21:23:20 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.1
[12/02 21:31:43 visual_prompt]: Epoch 11 / 100: avg data time: 5.73e+00, avg batch time: 7.1818, average train loss: 0.6939
[12/02 21:32:40 visual_prompt]: Inference (val):avg data time: 3.75e-05, avg batch time: 0.5898, average loss: 0.7041
[12/02 21:32:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 63.79	
[12/02 21:32:40 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0999695413509548
[12/02 21:40:59 visual_prompt]: Epoch 12 / 100: avg data time: 5.67e+00, avg batch time: 7.1252, average train loss: 0.6945
[12/02 21:41:57 visual_prompt]: Inference (val):avg data time: 3.44e-05, avg batch time: 0.5873, average loss: 0.7523
[12/02 21:41:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 47.15	rocauc: 63.40	
[12/02 21:41:57 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.09987820251299122
[12/02 21:50:19 visual_prompt]: Epoch 13 / 100: avg data time: 5.73e+00, avg batch time: 7.1787, average train loss: 0.7125
[12/02 21:51:17 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.5866, average loss: 0.6589
[12/02 21:51:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 65.36	
[12/02 21:51:17 visual_prompt]: Best epoch 13: best metric: -0.659
[12/02 21:51:17 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.09972609476841367
[12/02 21:59:40 visual_prompt]: Epoch 14 / 100: avg data time: 5.73e+00, avg batch time: 7.1832, average train loss: 0.6953
[12/02 22:00:37 visual_prompt]: Inference (val):avg data time: 5.68e-05, avg batch time: 0.5900, average loss: 0.6672
[12/02 22:00:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 66.62	
[12/02 22:00:37 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.09951340343707853
[12/02 22:08:58 visual_prompt]: Epoch 15 / 100: avg data time: 5.70e+00, avg batch time: 7.1546, average train loss: 0.6676
[12/02 22:09:56 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.5852, average loss: 0.6714
[12/02 22:09:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 64.34	
[12/02 22:09:56 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.09924038765061041
[12/02 22:18:16 visual_prompt]: Epoch 16 / 100: avg data time: 5.68e+00, avg batch time: 7.1430, average train loss: 0.6789
[12/02 22:19:14 visual_prompt]: Inference (val):avg data time: 3.73e-05, avg batch time: 0.5883, average loss: 0.8728
[12/02 22:19:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 64.69	
[12/02 22:19:14 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.09890738003669029
[12/02 22:27:37 visual_prompt]: Epoch 17 / 100: avg data time: 5.73e+00, avg batch time: 7.1888, average train loss: 0.6780
[12/02 22:28:35 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.5867, average loss: 0.7124
[12/02 22:28:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 67.82	
[12/02 22:28:35 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.09851478631379983
[12/02 22:36:56 visual_prompt]: Epoch 18 / 100: avg data time: 5.71e+00, avg batch time: 7.1658, average train loss: 0.6630
[12/02 22:37:53 visual_prompt]: Inference (val):avg data time: 3.99e-05, avg batch time: 0.5881, average loss: 1.0120
[12/02 22:37:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 67.82	
[12/02 22:37:53 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.09806308479691594
[12/02 22:46:13 visual_prompt]: Epoch 19 / 100: avg data time: 5.69e+00, avg batch time: 7.1411, average train loss: 0.6533
[12/02 22:47:11 visual_prompt]: Inference (val):avg data time: 3.85e-05, avg batch time: 0.5929, average loss: 0.7548
[12/02 22:47:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 66.16	
[12/02 22:47:11 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.09755282581475769
[12/02 22:55:38 visual_prompt]: Epoch 20 / 100: avg data time: 5.79e+00, avg batch time: 7.2473, average train loss: 0.6409
[12/02 22:56:36 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.5915, average loss: 0.6403
[12/02 22:56:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 69.84	
[12/02 22:56:36 visual_prompt]: Best epoch 20: best metric: -0.640
[12/02 22:56:36 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.09698463103929543
[12/02 23:05:00 visual_prompt]: Epoch 21 / 100: avg data time: 5.74e+00, avg batch time: 7.1960, average train loss: 0.6575
[12/02 23:05:59 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.5851, average loss: 0.6794
[12/02 23:05:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 67.00	
[12/02 23:05:59 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.09635919272833937
[12/02 23:14:20 visual_prompt]: Epoch 22 / 100: avg data time: 5.70e+00, avg batch time: 7.1584, average train loss: 0.6453
[12/02 23:15:17 visual_prompt]: Inference (val):avg data time: 4.35e-05, avg batch time: 0.5885, average loss: 0.7086
[12/02 23:15:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 67.86	
[12/02 23:15:17 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.09567727288213004
[12/02 23:23:40 visual_prompt]: Epoch 23 / 100: avg data time: 5.73e+00, avg batch time: 7.1792, average train loss: 0.6508
[12/02 23:24:36 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.5865, average loss: 0.6641
[12/02 23:24:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 71.18	
[12/02 23:24:36 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.09493970231495835
[12/02 23:32:57 visual_prompt]: Epoch 24 / 100: avg data time: 5.69e+00, avg batch time: 7.1492, average train loss: 0.6235
[12/02 23:33:54 visual_prompt]: Inference (val):avg data time: 3.53e-05, avg batch time: 0.5890, average loss: 0.6345
[12/02 23:33:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 71.71	
[12/02 23:33:54 visual_prompt]: Best epoch 24: best metric: -0.635
[12/02 23:33:54 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.09414737964294635
[12/02 23:42:17 visual_prompt]: Epoch 25 / 100: avg data time: 5.73e+00, avg batch time: 7.1878, average train loss: 0.6316
[12/02 23:43:15 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.5882, average loss: 0.6336
[12/02 23:43:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 74.01	
[12/02 23:43:15 visual_prompt]: Best epoch 25: best metric: -0.634
[12/02 23:43:15 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.09330127018922195
[12/02 23:51:35 visual_prompt]: Epoch 26 / 100: avg data time: 5.68e+00, avg batch time: 7.1311, average train loss: 0.6342
[12/02 23:52:33 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.5865, average loss: 0.6540
[12/02 23:52:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 72.22	
[12/02 23:52:33 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.0924024048078213
[12/03 00:00:52 visual_prompt]: Epoch 27 / 100: avg data time: 5.68e+00, avg batch time: 7.1340, average train loss: 0.6237
[12/03 00:01:50 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.5909, average loss: 0.6221
[12/03 00:01:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.07	rocauc: 70.81	
[12/03 00:01:50 visual_prompt]: Best epoch 27: best metric: -0.622
[12/03 00:01:50 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.09145187862775209
[12/03 00:10:12 visual_prompt]: Epoch 28 / 100: avg data time: 5.72e+00, avg batch time: 7.1680, average train loss: 0.6257
[12/03 00:11:09 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.5892, average loss: 0.6117
[12/03 00:11:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 68.70	rocauc: 72.43	
[12/03 00:11:09 visual_prompt]: Best epoch 28: best metric: -0.612
[12/03 00:11:09 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.09045084971874738
[12/03 00:19:29 visual_prompt]: Epoch 29 / 100: avg data time: 5.68e+00, avg batch time: 7.1375, average train loss: 0.6023
[12/03 00:20:28 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.5909, average loss: 0.6587
[12/03 00:20:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 74.41	
[12/03 00:20:28 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.0894005376803361
[12/03 00:28:52 visual_prompt]: Epoch 30 / 100: avg data time: 5.75e+00, avg batch time: 7.2029, average train loss: 0.6069
[12/03 00:29:50 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.5881, average loss: 0.7991
[12/03 00:29:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.53	rocauc: 66.86	
[12/03 00:29:50 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.0883022221559489
[12/03 00:38:12 visual_prompt]: Epoch 31 / 100: avg data time: 5.71e+00, avg batch time: 7.1684, average train loss: 0.6304
[12/03 00:39:11 visual_prompt]: Inference (val):avg data time: 3.38e-05, avg batch time: 0.5877, average loss: 0.6113
[12/03 00:39:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 73.51	
[12/03 00:39:11 visual_prompt]: Best epoch 31: best metric: -0.611
[12/03 00:39:11 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.08715724127386971
[12/03 00:47:34 visual_prompt]: Epoch 32 / 100: avg data time: 5.73e+00, avg batch time: 7.1866, average train loss: 0.6053
[12/03 00:48:32 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.5866, average loss: 0.6145
[12/03 00:48:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 68.29	rocauc: 73.04	
[12/03 00:48:32 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.08596699001693256
[12/03 00:56:52 visual_prompt]: Epoch 33 / 100: avg data time: 5.69e+00, avg batch time: 7.1475, average train loss: 0.6138
[12/03 00:57:50 visual_prompt]: Inference (val):avg data time: 3.59e-05, avg batch time: 0.5945, average loss: 0.6364
[12/03 00:57:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 73.65	
[12/03 00:57:50 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.08473291852294987
[12/03 01:06:12 visual_prompt]: Epoch 34 / 100: avg data time: 5.71e+00, avg batch time: 7.1641, average train loss: 0.6090
[12/03 01:07:09 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.5873, average loss: 0.7317
[12/03 01:07:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 72.51	
[12/03 01:07:09 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.08345653031794292
[12/03 01:15:32 visual_prompt]: Epoch 35 / 100: avg data time: 5.72e+00, avg batch time: 7.1775, average train loss: 0.6169
[12/03 01:16:31 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.5842, average loss: 0.6880
[12/03 01:16:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 72.57	
[12/03 01:16:31 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.08213938048432697
[12/03 01:24:55 visual_prompt]: Epoch 36 / 100: avg data time: 5.75e+00, avg batch time: 7.2015, average train loss: 0.5850
[12/03 01:25:53 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.5885, average loss: 0.7057
[12/03 01:25:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 75.65	
[12/03 01:25:53 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.08078307376628291
[12/03 01:34:17 visual_prompt]: Epoch 37 / 100: avg data time: 5.74e+00, avg batch time: 7.1964, average train loss: 0.5986
[12/03 01:35:14 visual_prompt]: Inference (val):avg data time: 3.47e-05, avg batch time: 0.5901, average loss: 0.6743
[12/03 01:35:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 75.61	
[12/03 01:35:14 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.07938926261462366
[12/03 01:43:37 visual_prompt]: Epoch 38 / 100: avg data time: 5.73e+00, avg batch time: 7.1831, average train loss: 0.5664
[12/03 01:44:35 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.5867, average loss: 0.6420
[12/03 01:44:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 71.45	
[12/03 01:44:35 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.07795964517353735
[12/03 01:52:55 visual_prompt]: Epoch 39 / 100: avg data time: 5.69e+00, avg batch time: 7.1469, average train loss: 0.5699
[12/03 01:53:53 visual_prompt]: Inference (val):avg data time: 3.23e-05, avg batch time: 0.5872, average loss: 0.6260
[12/03 01:53:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 73.13	
[12/03 01:53:53 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.07649596321166025
[12/03 02:02:13 visual_prompt]: Epoch 40 / 100: avg data time: 5.69e+00, avg batch time: 7.1409, average train loss: 0.5997
[12/03 02:03:10 visual_prompt]: Inference (val):avg data time: 3.87e-05, avg batch time: 0.5944, average loss: 0.5932
[12/03 02:03:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 70.73	rocauc: 75.42	
[12/03 02:03:10 visual_prompt]: Best epoch 40: best metric: -0.593
[12/03 02:03:10 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.07500000000000001
[12/03 02:11:33 visual_prompt]: Epoch 41 / 100: avg data time: 5.72e+00, avg batch time: 7.1739, average train loss: 0.5634
[12/03 02:12:30 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.5875, average loss: 0.7009
[12/03 02:12:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 71.43	
[12/03 02:12:30 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.07347357813929455
[12/03 02:20:48 visual_prompt]: Epoch 42 / 100: avg data time: 5.66e+00, avg batch time: 7.1142, average train loss: 0.6058
[12/03 02:21:46 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.5881, average loss: 0.5875
[12/03 02:21:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 75.65	
[12/03 02:21:46 visual_prompt]: Best epoch 42: best metric: -0.587
[12/03 02:21:46 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.07191855733945388
[12/03 02:30:09 visual_prompt]: Epoch 43 / 100: avg data time: 5.73e+00, avg batch time: 7.1905, average train loss: 0.5846
[12/03 02:31:07 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.5857, average loss: 0.6091
[12/03 02:31:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.89	rocauc: 75.52	
[12/03 02:31:07 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.07033683215379002
[12/03 02:39:31 visual_prompt]: Epoch 44 / 100: avg data time: 5.73e+00, avg batch time: 7.1877, average train loss: 0.5680
[12/03 02:40:27 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.5841, average loss: 0.5974
[12/03 02:40:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 68.70	rocauc: 76.07	
[12/03 02:40:27 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.0687303296707956
[12/03 02:48:47 visual_prompt]: Epoch 45 / 100: avg data time: 5.69e+00, avg batch time: 7.1430, average train loss: 0.5466
[12/03 02:49:45 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.5895, average loss: 0.6223
[12/03 02:49:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 75.90	
[12/03 02:49:45 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.06710100716628345
[12/03 02:58:04 visual_prompt]: Epoch 46 / 100: avg data time: 5.67e+00, avg batch time: 7.1293, average train loss: 0.5373
[12/03 02:59:01 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.5876, average loss: 0.6129
[12/03 02:59:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.07	rocauc: 74.76	
[12/03 02:59:01 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.06545084971874737
[12/03 03:07:26 visual_prompt]: Epoch 47 / 100: avg data time: 5.75e+00, avg batch time: 7.2072, average train loss: 0.5616
[12/03 03:08:25 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.5868, average loss: 0.6943
[12/03 03:08:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 72.03	
[12/03 03:08:25 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.06378186779084996
[12/03 03:16:47 visual_prompt]: Epoch 48 / 100: avg data time: 5.71e+00, avg batch time: 7.1640, average train loss: 0.5120
[12/03 03:17:44 visual_prompt]: Inference (val):avg data time: 3.82e-05, avg batch time: 0.5885, average loss: 0.6919
[12/03 03:17:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 71.48	
[12/03 03:17:45 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.06209609477998338
[12/03 03:26:04 visual_prompt]: Epoch 49 / 100: avg data time: 5.68e+00, avg batch time: 7.1310, average train loss: 0.5427
[12/03 03:27:01 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.5877, average loss: 0.6314
[12/03 03:27:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 69.11	rocauc: 75.06	
[12/03 03:27:01 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.06039558454088796
[12/03 03:35:23 visual_prompt]: Epoch 50 / 100: avg data time: 5.71e+00, avg batch time: 7.1688, average train loss: 0.5317
[12/03 03:36:22 visual_prompt]: Inference (val):avg data time: 4.76e-05, avg batch time: 0.5885, average loss: 0.7702
[12/03 03:36:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 76.09	
[12/03 03:36:22 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.058682408883346526
[12/03 03:44:50 visual_prompt]: Epoch 51 / 100: avg data time: 5.80e+00, avg batch time: 7.2556, average train loss: 0.4982
[12/03 03:45:48 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.5887, average loss: 0.6444
[12/03 03:45:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 73.14	
[12/03 03:45:48 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.05695865504800327
[12/03 03:54:17 visual_prompt]: Epoch 52 / 100: avg data time: 5.81e+00, avg batch time: 7.2642, average train loss: 0.4847
[12/03 03:55:15 visual_prompt]: Inference (val):avg data time: 4.07e-05, avg batch time: 0.5893, average loss: 0.8787
[12/03 03:55:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 71.97	
[12/03 03:55:15 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.05522642316338268
[12/03 04:03:41 visual_prompt]: Epoch 53 / 100: avg data time: 5.77e+00, avg batch time: 7.2261, average train loss: 0.4954
[12/03 04:04:38 visual_prompt]: Inference (val):avg data time: 3.87e-05, avg batch time: 0.5878, average loss: 0.6453
[12/03 04:04:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 69.51	rocauc: 74.61	
[12/03 04:04:38 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.05348782368720626
[12/03 04:13:03 visual_prompt]: Epoch 54 / 100: avg data time: 5.76e+00, avg batch time: 7.2120, average train loss: 0.5597
[12/03 04:14:01 visual_prompt]: Inference (val):avg data time: 3.79e-05, avg batch time: 0.5887, average loss: 0.6251
[12/03 04:14:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 71.91	
[12/03 04:14:01 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.05174497483512506
[12/03 04:22:25 visual_prompt]: Epoch 55 / 100: avg data time: 5.75e+00, avg batch time: 7.2004, average train loss: 0.4767
[12/03 04:23:23 visual_prompt]: Inference (val):avg data time: 3.67e-05, avg batch time: 0.5873, average loss: 0.8301
[12/03 04:23:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 74.13	
[12/03 04:23:23 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.05
[12/03 04:31:44 visual_prompt]: Epoch 56 / 100: avg data time: 5.71e+00, avg batch time: 7.1588, average train loss: 0.4914
[12/03 04:32:42 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.5848, average loss: 0.7185
[12/03 04:32:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 74.06	
[12/03 04:32:42 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.04825502516487497
[12/03 04:41:05 visual_prompt]: Epoch 57 / 100: avg data time: 5.72e+00, avg batch time: 7.1725, average train loss: 0.5066
[12/03 04:42:03 visual_prompt]: Inference (val):avg data time: 3.90e-05, avg batch time: 0.5878, average loss: 0.6712
[12/03 04:42:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.67	rocauc: 74.36	
[12/03 04:42:03 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.04651217631279374
[12/03 04:50:24 visual_prompt]: Epoch 58 / 100: avg data time: 5.70e+00, avg batch time: 7.1605, average train loss: 0.4873
[12/03 04:51:22 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.5900, average loss: 0.6319
[12/03 04:51:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.67	rocauc: 73.83	
[12/03 04:51:22 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.04477357683661734
[12/03 04:59:48 visual_prompt]: Epoch 59 / 100: avg data time: 5.76e+00, avg batch time: 7.2230, average train loss: 0.4520
[12/03 05:00:46 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.5891, average loss: 0.6102
[12/03 05:00:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 68.29	rocauc: 76.37	
[12/03 05:00:46 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.04304134495199674
[12/03 05:09:13 visual_prompt]: Epoch 60 / 100: avg data time: 5.79e+00, avg batch time: 7.2426, average train loss: 0.4187
[12/03 05:10:12 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.5887, average loss: 0.6204
[12/03 05:10:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 68.29	rocauc: 75.50	
[12/03 05:10:12 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.041317591116653486
[12/03 05:18:37 visual_prompt]: Epoch 61 / 100: avg data time: 5.77e+00, avg batch time: 7.2231, average train loss: 0.4173
[12/03 05:19:36 visual_prompt]: Inference (val):avg data time: 3.91e-05, avg batch time: 0.5887, average loss: 0.7421
[12/03 05:19:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 68.29	rocauc: 74.18	
[12/03 05:19:36 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.039604415459112044
[12/03 05:27:58 visual_prompt]: Epoch 62 / 100: avg data time: 5.72e+00, avg batch time: 7.1744, average train loss: 0.4491
[12/03 05:28:56 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.5905, average loss: 0.6413
[12/03 05:28:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 69.11	rocauc: 75.07	
[12/03 05:28:56 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.037903905220016625
[12/03 05:37:19 visual_prompt]: Epoch 63 / 100: avg data time: 5.73e+00, avg batch time: 7.1840, average train loss: 0.3861
[12/03 05:38:17 visual_prompt]: Inference (val):avg data time: 4.74e-05, avg batch time: 0.5916, average loss: 0.6985
[12/03 05:38:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 69.11	rocauc: 77.37	
[12/03 05:38:17 visual_prompt]: Stopping early.
[12/03 05:38:17 visual_prompt]: Rank of current process: 0. World size: 1
[12/03 05:38:17 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[12/03 05:38:17 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[12/03 05:38:17 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[12/03 05:38:17 visual_prompt]: Training with config:
[12/03 05:38:17 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr0.1_wd0.0001/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.1, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[12/03 05:38:17 visual_prompt]: Loading training data...
[12/03 05:38:17 visual_prompt]: Constructing mammo-cbis dataset train...
[12/03 05:38:17 visual_prompt]: Loading validation data...
[12/03 05:38:17 visual_prompt]: Constructing mammo-cbis dataset val...
[12/03 05:38:17 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[12/03 05:38:20 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[12/03 05:38:20 visual_prompt]: tuned percent:0.532
[12/03 05:38:21 visual_prompt]: Device used for model: 0
[12/03 05:38:21 visual_prompt]: Setting up Evaluator...
[12/03 05:38:21 visual_prompt]: Setting up Trainer...
[12/03 05:38:21 visual_prompt]: 	Setting up the optimizer...
[12/03 05:38:21 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[12/03 05:46:43 visual_prompt]: Epoch 1 / 100: avg data time: 5.73e+00, avg batch time: 7.1783, average train loss: 1.4863
[12/03 05:47:42 visual_prompt]: Inference (val):avg data time: 4.24e-05, avg batch time: 0.5906, average loss: 1.4553
[12/03 05:47:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[12/03 05:47:42 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.010000000000000002
[12/03 05:56:04 visual_prompt]: Epoch 2 / 100: avg data time: 5.72e+00, avg batch time: 7.1762, average train loss: 0.9493
[12/03 05:57:04 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.5889, average loss: 0.6880
[12/03 05:57:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.47	rocauc: 52.59	
[12/03 05:57:04 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.020000000000000004
[12/03 06:05:27 visual_prompt]: Epoch 3 / 100: avg data time: 5.73e+00, avg batch time: 7.1858, average train loss: 0.7082
[12/03 06:06:25 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.5896, average loss: 0.7340
[12/03 06:06:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.09	
[12/03 06:06:25 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.03
[12/03 06:14:45 visual_prompt]: Epoch 4 / 100: avg data time: 5.69e+00, avg batch time: 7.1389, average train loss: 0.7307
[12/03 06:15:43 visual_prompt]: Inference (val):avg data time: 3.52e-05, avg batch time: 0.5877, average loss: 0.7090
[12/03 06:15:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.16	
[12/03 06:15:43 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.04000000000000001
[12/03 06:24:04 visual_prompt]: Epoch 5 / 100: avg data time: 5.71e+00, avg batch time: 7.1618, average train loss: 0.7252
[12/03 06:25:02 visual_prompt]: Inference (val):avg data time: 3.48e-05, avg batch time: 0.5884, average loss: 0.6838
[12/03 06:25:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.11	
[12/03 06:25:02 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.05
[12/03 06:33:28 visual_prompt]: Epoch 6 / 100: avg data time: 5.77e+00, avg batch time: 7.2224, average train loss: 0.7344
[12/03 06:34:25 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.5875, average loss: 0.7577
[12/03 06:34:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.33	
[12/03 06:34:25 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.06
[12/03 06:42:46 visual_prompt]: Epoch 7 / 100: avg data time: 5.70e+00, avg batch time: 7.1572, average train loss: 0.7242
[12/03 06:43:45 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.5877, average loss: 0.8504
[12/03 06:43:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.99	
[12/03 06:43:45 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.06999999999999999
[12/03 06:52:04 visual_prompt]: Epoch 8 / 100: avg data time: 5.69e+00, avg batch time: 7.1373, average train loss: 0.7499
[12/03 06:53:02 visual_prompt]: Inference (val):avg data time: 4.58e-05, avg batch time: 0.5882, average loss: 0.6996
[12/03 06:53:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.74	
[12/03 06:53:02 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.08000000000000002
[12/03 07:01:22 visual_prompt]: Epoch 9 / 100: avg data time: 5.70e+00, avg batch time: 7.1508, average train loss: 0.7138
[12/03 07:02:20 visual_prompt]: Inference (val):avg data time: 3.60e-05, avg batch time: 0.5887, average loss: 0.7163
[12/03 07:02:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.63	
[12/03 07:02:20 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.09000000000000001
[12/03 07:10:40 visual_prompt]: Epoch 10 / 100: avg data time: 5.68e+00, avg batch time: 7.1325, average train loss: 0.6878
[12/03 07:11:37 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.5879, average loss: 0.6738
[12/03 07:11:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 63.82	
[12/03 07:11:37 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.1
[12/03 07:19:59 visual_prompt]: Epoch 11 / 100: avg data time: 5.70e+00, avg batch time: 7.1602, average train loss: 0.6977
[12/03 07:20:56 visual_prompt]: Inference (val):avg data time: 3.64e-05, avg batch time: 0.5903, average loss: 0.7571
[12/03 07:20:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 66.04	
[12/03 07:20:56 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0999695413509548
[12/03 07:29:18 visual_prompt]: Epoch 12 / 100: avg data time: 5.71e+00, avg batch time: 7.1627, average train loss: 0.6979
[12/03 07:30:15 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.5887, average loss: 0.7149
[12/03 07:30:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 48.37	rocauc: 65.36	
[12/03 07:30:15 visual_prompt]: Best epoch 12: best metric: -0.715
[12/03 07:30:15 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.09987820251299122
[12/03 07:38:37 visual_prompt]: Epoch 13 / 100: avg data time: 5.71e+00, avg batch time: 7.1606, average train loss: 0.7183
[12/03 07:39:34 visual_prompt]: Inference (val):avg data time: 4.24e-05, avg batch time: 0.5862, average loss: 0.6856
[12/03 07:39:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 63.96	
[12/03 07:39:34 visual_prompt]: Best epoch 13: best metric: -0.686
[12/03 07:39:34 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.09972609476841367
[12/03 07:47:55 visual_prompt]: Epoch 14 / 100: avg data time: 5.71e+00, avg batch time: 7.1629, average train loss: 0.7036
[12/03 07:48:53 visual_prompt]: Inference (val):avg data time: 3.83e-05, avg batch time: 0.5876, average loss: 0.6629
[12/03 07:48:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 66.57	
[12/03 07:48:53 visual_prompt]: Best epoch 14: best metric: -0.663
[12/03 07:48:53 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.09951340343707853
[12/03 07:57:12 visual_prompt]: Epoch 15 / 100: avg data time: 5.67e+00, avg batch time: 7.1263, average train loss: 0.6662
[12/03 07:58:09 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.5866, average loss: 0.6723
[12/03 07:58:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 64.41	
[12/03 07:58:09 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.09924038765061041
[12/03 08:06:31 visual_prompt]: Epoch 16 / 100: avg data time: 5.72e+00, avg batch time: 7.1735, average train loss: 0.6771
[12/03 08:07:28 visual_prompt]: Inference (val):avg data time: 3.64e-05, avg batch time: 0.5890, average loss: 0.8632
[12/03 08:07:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 66.55	
[12/03 08:07:28 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.09890738003669029
[12/03 08:15:49 visual_prompt]: Epoch 17 / 100: avg data time: 5.71e+00, avg batch time: 7.1626, average train loss: 0.6680
[12/03 08:16:47 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.5876, average loss: 0.7518
[12/03 08:16:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 67.51	
[12/03 08:16:47 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.09851478631379983
[12/03 08:25:07 visual_prompt]: Epoch 18 / 100: avg data time: 5.69e+00, avg batch time: 7.1433, average train loss: 0.6712
[12/03 08:26:05 visual_prompt]: Inference (val):avg data time: 4.86e-05, avg batch time: 0.5877, average loss: 1.0761
[12/03 08:26:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 66.45	
[12/03 08:26:05 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.09806308479691594
[12/03 08:34:26 visual_prompt]: Epoch 19 / 100: avg data time: 5.70e+00, avg batch time: 7.1524, average train loss: 0.6538
[12/03 08:35:24 visual_prompt]: Inference (val):avg data time: 4.37e-05, avg batch time: 0.5877, average loss: 0.7831
[12/03 08:35:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 65.54	
[12/03 08:35:24 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.09755282581475769
[12/03 08:43:47 visual_prompt]: Epoch 20 / 100: avg data time: 5.73e+00, avg batch time: 7.1850, average train loss: 0.6353
[12/03 08:44:44 visual_prompt]: Inference (val):avg data time: 3.99e-05, avg batch time: 0.5853, average loss: 0.6844
[12/03 08:44:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 67.62	
[12/03 08:44:44 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.09698463103929543
[12/03 08:53:08 visual_prompt]: Epoch 21 / 100: avg data time: 5.74e+00, avg batch time: 7.1980, average train loss: 0.6583
[12/03 08:54:06 visual_prompt]: Inference (val):avg data time: 4.01e-05, avg batch time: 0.5866, average loss: 0.6848
[12/03 08:54:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 68.09	
[12/03 08:54:06 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.09635919272833937
[12/03 09:02:36 visual_prompt]: Epoch 22 / 100: avg data time: 5.82e+00, avg batch time: 7.2747, average train loss: 0.6308
[12/03 09:03:34 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.5905, average loss: 0.6568
[12/03 09:03:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 67.63	
[12/03 09:03:34 visual_prompt]: Best epoch 22: best metric: -0.657
[12/03 09:03:34 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.09567727288213004
[12/03 09:11:56 visual_prompt]: Epoch 23 / 100: avg data time: 5.72e+00, avg batch time: 7.1732, average train loss: 0.6247
[12/03 09:12:52 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.5923, average loss: 0.6477
[12/03 09:12:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 67.17	
[12/03 09:12:52 visual_prompt]: Best epoch 23: best metric: -0.648
[12/03 09:12:52 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.09493970231495835
[12/03 09:21:13 visual_prompt]: Epoch 24 / 100: avg data time: 5.70e+00, avg batch time: 7.1528, average train loss: 0.6228
[12/03 09:22:11 visual_prompt]: Inference (val):avg data time: 4.19e-05, avg batch time: 0.5844, average loss: 0.6699
[12/03 09:22:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 65.81	
[12/03 09:22:11 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.09414737964294635
[12/03 09:30:34 visual_prompt]: Epoch 25 / 100: avg data time: 5.74e+00, avg batch time: 7.1915, average train loss: 0.6063
[12/03 09:31:32 visual_prompt]: Inference (val):avg data time: 5.34e-05, avg batch time: 0.5877, average loss: 0.6647
[12/03 09:31:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 68.21	
[12/03 09:31:32 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.09330127018922195
[12/03 09:39:52 visual_prompt]: Epoch 26 / 100: avg data time: 5.69e+00, avg batch time: 7.1401, average train loss: 0.6318
[12/03 09:40:49 visual_prompt]: Inference (val):avg data time: 3.35e-05, avg batch time: 0.5935, average loss: 0.6728
[12/03 09:40:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 69.67	
[12/03 09:40:49 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.0924024048078213
[12/03 09:49:10 visual_prompt]: Epoch 27 / 100: avg data time: 5.71e+00, avg batch time: 7.1635, average train loss: 0.6058
[12/03 09:50:08 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.5904, average loss: 0.6466
[12/03 09:50:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 68.45	
[12/03 09:50:08 visual_prompt]: Best epoch 27: best metric: -0.647
[12/03 09:50:08 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.09145187862775209
[12/03 09:58:30 visual_prompt]: Epoch 28 / 100: avg data time: 5.72e+00, avg batch time: 7.1779, average train loss: 0.6088
[12/03 09:59:27 visual_prompt]: Inference (val):avg data time: 4.50e-05, avg batch time: 0.5878, average loss: 0.7036
[12/03 09:59:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 67.76	
[12/03 09:59:27 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.09045084971874738
[12/03 10:07:47 visual_prompt]: Epoch 29 / 100: avg data time: 5.68e+00, avg batch time: 7.1327, average train loss: 0.5846
[12/03 10:08:44 visual_prompt]: Inference (val):avg data time: 3.79e-05, avg batch time: 0.5874, average loss: 0.7227
[12/03 10:08:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 68.44	
[12/03 10:08:44 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.0894005376803361
[12/03 10:17:07 visual_prompt]: Epoch 30 / 100: avg data time: 5.73e+00, avg batch time: 7.1807, average train loss: 0.6079
[12/03 10:18:05 visual_prompt]: Inference (val):avg data time: 3.63e-05, avg batch time: 0.5859, average loss: 0.7836
[12/03 10:18:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 70.22	
[12/03 10:18:05 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.0883022221559489
[12/03 10:26:25 visual_prompt]: Epoch 31 / 100: avg data time: 5.69e+00, avg batch time: 7.1486, average train loss: 0.6060
[12/03 10:27:23 visual_prompt]: Inference (val):avg data time: 4.82e-05, avg batch time: 0.5866, average loss: 0.7220
[12/03 10:27:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 67.14	
[12/03 10:27:23 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.08715724127386971
[12/03 10:35:46 visual_prompt]: Epoch 32 / 100: avg data time: 5.73e+00, avg batch time: 7.1834, average train loss: 0.5640
[12/03 10:36:43 visual_prompt]: Inference (val):avg data time: 4.03e-05, avg batch time: 0.5879, average loss: 0.6857
[12/03 10:36:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 66.42	
[12/03 10:36:43 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.08596699001693256
[12/03 10:45:05 visual_prompt]: Epoch 33 / 100: avg data time: 5.72e+00, avg batch time: 7.1694, average train loss: 0.5462
[12/03 10:46:03 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.5870, average loss: 0.7013
[12/03 10:46:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 64.37	
[12/03 10:46:03 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.08473291852294987
[12/03 10:54:23 visual_prompt]: Epoch 34 / 100: avg data time: 5.69e+00, avg batch time: 7.1459, average train loss: 0.5520
[12/03 10:55:21 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.5882, average loss: 0.7849
[12/03 10:55:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 51.22	rocauc: 65.99	
[12/03 10:55:21 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.08345653031794292
[12/03 11:03:41 visual_prompt]: Epoch 35 / 100: avg data time: 5.68e+00, avg batch time: 7.1326, average train loss: 0.5556
[12/03 11:04:37 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.5907, average loss: 0.6753
[12/03 11:04:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 67.29	
[12/03 11:04:37 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.08213938048432697
[12/03 11:13:03 visual_prompt]: Epoch 36 / 100: avg data time: 5.77e+00, avg batch time: 7.2255, average train loss: 0.5255
[12/03 11:14:01 visual_prompt]: Inference (val):avg data time: 4.05e-05, avg batch time: 0.5865, average loss: 0.6607
[12/03 11:14:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 68.71	
[12/03 11:14:01 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.08078307376628291
[12/03 11:22:26 visual_prompt]: Epoch 37 / 100: avg data time: 5.76e+00, avg batch time: 7.2163, average train loss: 0.5362
[12/03 11:23:23 visual_prompt]: Inference (val):avg data time: 4.40e-05, avg batch time: 0.5867, average loss: 0.6948
[12/03 11:23:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 68.23	
[12/03 11:23:23 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.07938926261462366
[12/03 11:31:44 visual_prompt]: Epoch 38 / 100: avg data time: 5.70e+00, avg batch time: 7.1554, average train loss: 0.4919
[12/03 11:32:42 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.5851, average loss: 0.7667
[12/03 11:32:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 64.60	
[12/03 11:32:42 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.07795964517353735
[12/03 11:41:01 visual_prompt]: Epoch 39 / 100: avg data time: 5.68e+00, avg batch time: 7.1329, average train loss: 0.5148
[12/03 11:41:59 visual_prompt]: Inference (val):avg data time: 4.29e-05, avg batch time: 0.5900, average loss: 0.8777
[12/03 11:41:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 67.50	
[12/03 11:41:59 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.07649596321166025
[12/03 11:50:20 visual_prompt]: Epoch 40 / 100: avg data time: 5.70e+00, avg batch time: 7.1533, average train loss: 0.4917
[12/03 11:51:17 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.5859, average loss: 0.7124
[12/03 11:51:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.01	rocauc: 65.92	
[12/03 11:51:17 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.07500000000000001
[12/03 11:59:46 visual_prompt]: Epoch 41 / 100: avg data time: 5.82e+00, avg batch time: 7.2756, average train loss: 0.4651
[12/03 12:00:46 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.5858, average loss: 0.6851
[12/03 12:00:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 67.68	
[12/03 12:00:46 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.07347357813929455
[12/03 12:09:21 visual_prompt]: Epoch 42 / 100: avg data time: 5.90e+00, avg batch time: 7.3545, average train loss: 0.4644
[12/03 12:10:19 visual_prompt]: Inference (val):avg data time: 4.16e-05, avg batch time: 0.5876, average loss: 0.7240
[12/03 12:10:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 66.14	
[12/03 12:10:19 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.07191855733945388
[12/03 12:18:46 visual_prompt]: Epoch 43 / 100: avg data time: 5.80e+00, avg batch time: 7.2506, average train loss: 0.4817
[12/03 12:19:44 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.5923, average loss: 0.7124
[12/03 12:19:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 65.90	
[12/03 12:19:44 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.07033683215379002
[12/03 12:28:05 visual_prompt]: Epoch 44 / 100: avg data time: 5.69e+00, avg batch time: 7.1508, average train loss: 0.4750
[12/03 12:29:02 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.5886, average loss: 0.7353
[12/03 12:29:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 65.23	
[12/03 12:29:02 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.0687303296707956
[12/03 12:37:22 visual_prompt]: Epoch 45 / 100: avg data time: 5.69e+00, avg batch time: 7.1417, average train loss: 0.4530
[12/03 12:38:20 visual_prompt]: Inference (val):avg data time: 3.56e-05, avg batch time: 0.5901, average loss: 0.7804
[12/03 12:38:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 65.96	
[12/03 12:38:20 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.06710100716628345
[12/03 12:46:41 visual_prompt]: Epoch 46 / 100: avg data time: 5.70e+00, avg batch time: 7.1587, average train loss: 0.4438
[12/03 12:47:38 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.5916, average loss: 0.8097
[12/03 12:47:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 64.23	
[12/03 12:47:38 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.06545084971874737
[12/03 12:56:00 visual_prompt]: Epoch 47 / 100: avg data time: 5.71e+00, avg batch time: 7.1622, average train loss: 0.4422
[12/03 12:56:57 visual_prompt]: Inference (val):avg data time: 5.28e-05, avg batch time: 0.5943, average loss: 0.7893
[12/03 12:56:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 64.52	
[12/03 12:56:57 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.06378186779084996
[12/03 13:05:20 visual_prompt]: Epoch 48 / 100: avg data time: 5.73e+00, avg batch time: 7.1868, average train loss: 0.3943
[12/03 13:06:17 visual_prompt]: Inference (val):avg data time: 3.69e-05, avg batch time: 0.5922, average loss: 0.8071
[12/03 13:06:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 65.30	
[12/03 13:06:17 visual_prompt]: Stopping early.
[12/03 13:06:18 visual_prompt]: Rank of current process: 0. World size: 1
[12/03 13:06:18 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[12/03 13:06:18 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[12/03 13:06:18 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[12/03 13:06:18 visual_prompt]: Training with config:
[12/03 13:06:18 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr0.1_wd0.0/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.1, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[12/03 13:06:18 visual_prompt]: Loading training data...
[12/03 13:06:18 visual_prompt]: Constructing mammo-cbis dataset train...
[12/03 13:06:18 visual_prompt]: Loading validation data...
[12/03 13:06:18 visual_prompt]: Constructing mammo-cbis dataset val...
[12/03 13:06:18 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[12/03 13:06:21 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[12/03 13:06:21 visual_prompt]: tuned percent:0.532
[12/03 13:06:21 visual_prompt]: Device used for model: 0
[12/03 13:06:21 visual_prompt]: Setting up Evaluator...
[12/03 13:06:21 visual_prompt]: Setting up Trainer...
[12/03 13:06:21 visual_prompt]: 	Setting up the optimizer...
[12/03 13:06:21 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[12/03 13:14:47 visual_prompt]: Epoch 1 / 100: avg data time: 5.76e+00, avg batch time: 7.2169, average train loss: 1.4863
[12/03 13:15:44 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.5879, average loss: 1.4553
[12/03 13:15:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[12/03 13:15:44 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.010000000000000002
[12/03 13:24:07 visual_prompt]: Epoch 2 / 100: avg data time: 5.73e+00, avg batch time: 7.1878, average train loss: 0.9493
[12/03 13:25:04 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.5860, average loss: 0.6880
[12/03 13:25:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.47	rocauc: 52.59	
[12/03 13:25:04 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.020000000000000004
[12/03 13:33:29 visual_prompt]: Epoch 3 / 100: avg data time: 5.77e+00, avg batch time: 7.2152, average train loss: 0.7082
[12/03 13:34:27 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.5869, average loss: 0.7340
[12/03 13:34:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.09	
[12/03 13:34:27 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.03
[12/03 13:42:55 visual_prompt]: Epoch 4 / 100: avg data time: 5.80e+00, avg batch time: 7.2520, average train loss: 0.7307
[12/03 13:43:52 visual_prompt]: Inference (val):avg data time: 4.02e-05, avg batch time: 0.5903, average loss: 0.7090
[12/03 13:43:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.11	
[12/03 13:43:52 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.04000000000000001
[12/03 13:52:20 visual_prompt]: Epoch 5 / 100: avg data time: 5.79e+00, avg batch time: 7.2421, average train loss: 0.7252
[12/03 13:53:18 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.5859, average loss: 0.6838
[12/03 13:53:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.10	
[12/03 13:53:18 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.05
[12/03 14:01:44 visual_prompt]: Epoch 6 / 100: avg data time: 5.77e+00, avg batch time: 7.2246, average train loss: 0.7346
[12/03 14:02:42 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.5901, average loss: 0.7580
[12/03 14:02:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.48	
[12/03 14:02:42 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.06
[12/03 14:11:01 visual_prompt]: Epoch 7 / 100: avg data time: 5.67e+00, avg batch time: 7.1231, average train loss: 0.7241
[12/03 14:11:57 visual_prompt]: Inference (val):avg data time: 3.96e-05, avg batch time: 0.5893, average loss: 0.8533
[12/03 14:11:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.05	
[12/03 14:11:57 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.06999999999999999
[12/03 14:20:19 visual_prompt]: Epoch 8 / 100: avg data time: 5.71e+00, avg batch time: 7.1677, average train loss: 0.7501
[12/03 14:21:17 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.5894, average loss: 0.6991
[12/03 14:21:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.87	
[12/03 14:21:17 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.08000000000000002
[12/03 14:29:38 visual_prompt]: Epoch 9 / 100: avg data time: 5.71e+00, avg batch time: 7.1613, average train loss: 0.7138
[12/03 14:30:36 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.5876, average loss: 0.7123
[12/03 14:30:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.66	
[12/03 14:30:36 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.09000000000000001
[12/03 14:38:57 visual_prompt]: Epoch 10 / 100: avg data time: 5.69e+00, avg batch time: 7.1495, average train loss: 0.6878
[12/03 14:39:55 visual_prompt]: Inference (val):avg data time: 3.51e-05, avg batch time: 0.5860, average loss: 0.6762
[12/03 14:39:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 64.28	
[12/03 14:39:55 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.1
[12/03 14:48:19 visual_prompt]: Epoch 11 / 100: avg data time: 5.74e+00, avg batch time: 7.1923, average train loss: 0.6993
[12/03 14:49:16 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.5876, average loss: 0.7623
[12/03 14:49:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 66.42	
[12/03 14:49:16 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0999695413509548
[12/03 14:57:39 visual_prompt]: Epoch 12 / 100: avg data time: 5.73e+00, avg batch time: 7.1861, average train loss: 0.6965
[12/03 14:58:37 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.5890, average loss: 0.6973
[12/03 14:58:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 52.44	rocauc: 66.15	
[12/03 14:58:37 visual_prompt]: Best epoch 12: best metric: -0.697
[12/03 14:58:37 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.09987820251299122
[12/03 15:07:05 visual_prompt]: Epoch 13 / 100: avg data time: 5.80e+00, avg batch time: 7.2506, average train loss: 0.7136
[12/03 15:08:04 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.5866, average loss: 0.6711
[12/03 15:08:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 66.31	
[12/03 15:08:04 visual_prompt]: Best epoch 13: best metric: -0.671
[12/03 15:08:04 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.09972609476841367
[12/03 15:16:33 visual_prompt]: Epoch 14 / 100: avg data time: 5.82e+00, avg batch time: 7.2683, average train loss: 0.7001
[12/03 15:17:32 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.5868, average loss: 0.6705
[12/03 15:17:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 67.28	
[12/03 15:17:32 visual_prompt]: Best epoch 14: best metric: -0.671
[12/03 15:17:32 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.09951340343707853
[12/03 15:26:08 visual_prompt]: Epoch 15 / 100: avg data time: 5.92e+00, avg batch time: 7.3771, average train loss: 0.6658
[12/03 15:27:29 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.5846, average loss: 0.6716
[12/03 15:27:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 64.17	
[12/03 15:27:29 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.09924038765061041
[12/03 15:39:10 visual_prompt]: Epoch 16 / 100: avg data time: 8.55e+00, avg batch time: 10.0004, average train loss: 0.6782
[12/03 15:40:07 visual_prompt]: Inference (val):avg data time: 3.94e-05, avg batch time: 0.5876, average loss: 0.8483
[12/03 15:40:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.47	rocauc: 66.90	
[12/03 15:40:07 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.09890738003669029
[12/03 15:48:30 visual_prompt]: Epoch 17 / 100: avg data time: 5.73e+00, avg batch time: 7.1783, average train loss: 0.6665
[12/03 15:49:27 visual_prompt]: Inference (val):avg data time: 3.58e-05, avg batch time: 0.5844, average loss: 0.7558
[12/03 15:49:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 67.99	
[12/03 15:49:27 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.09851478631379983
[12/03 15:57:47 visual_prompt]: Epoch 18 / 100: avg data time: 5.69e+00, avg batch time: 7.1418, average train loss: 0.6763
[12/03 15:58:44 visual_prompt]: Inference (val):avg data time: 1.57e-03, avg batch time: 0.5893, average loss: 1.0653
[12/03 15:58:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 66.73	
[12/03 15:58:44 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.09806308479691594
[12/03 16:07:04 visual_prompt]: Epoch 19 / 100: avg data time: 5.68e+00, avg batch time: 7.1331, average train loss: 0.6516
[12/03 16:08:02 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.5937, average loss: 0.8032
[12/03 16:08:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 64.79	
[12/03 16:08:02 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.09755282581475769
[12/03 16:16:23 visual_prompt]: Epoch 20 / 100: avg data time: 5.71e+00, avg batch time: 7.1637, average train loss: 0.6418
[12/03 16:17:21 visual_prompt]: Inference (val):avg data time: 4.35e-05, avg batch time: 0.5867, average loss: 0.7043
[12/03 16:17:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 67.41	
[12/03 16:17:21 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.09698463103929543
[12/03 16:25:41 visual_prompt]: Epoch 21 / 100: avg data time: 5.69e+00, avg batch time: 7.1445, average train loss: 0.6660
[12/03 16:26:38 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.5872, average loss: 0.6824
[12/03 16:26:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 68.57	
[12/03 16:26:38 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.09635919272833937
[12/03 16:34:58 visual_prompt]: Epoch 22 / 100: avg data time: 5.69e+00, avg batch time: 7.1407, average train loss: 0.6309
[12/03 16:35:56 visual_prompt]: Inference (val):avg data time: 4.40e-05, avg batch time: 0.5881, average loss: 0.6781
[12/03 16:35:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 67.91	
[12/03 16:35:56 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.09567727288213004
[12/03 16:44:19 visual_prompt]: Epoch 23 / 100: avg data time: 5.73e+00, avg batch time: 7.1834, average train loss: 0.6169
[12/03 16:45:16 visual_prompt]: Inference (val):avg data time: 3.23e-05, avg batch time: 0.5878, average loss: 0.6407
[12/03 16:45:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 67.87	
[12/03 16:45:16 visual_prompt]: Best epoch 23: best metric: -0.641
[12/03 16:45:16 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.09493970231495835
[12/03 16:53:41 visual_prompt]: Epoch 24 / 100: avg data time: 5.76e+00, avg batch time: 7.2100, average train loss: 0.6264
[12/03 16:54:38 visual_prompt]: Inference (val):avg data time: 4.77e-05, avg batch time: 0.5910, average loss: 0.6560
[12/03 16:54:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 67.63	
[12/03 16:54:38 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.09414737964294635
[12/03 17:03:02 visual_prompt]: Epoch 25 / 100: avg data time: 5.74e+00, avg batch time: 7.1956, average train loss: 0.6078
[12/03 17:04:00 visual_prompt]: Inference (val):avg data time: 3.41e-05, avg batch time: 0.5886, average loss: 0.6657
[12/03 17:04:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 69.50	
[12/03 17:04:00 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.09330127018922195
[12/03 17:12:20 visual_prompt]: Epoch 26 / 100: avg data time: 5.70e+00, avg batch time: 7.1502, average train loss: 0.6258
[12/03 17:13:18 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.5887, average loss: 0.6963
[12/03 17:13:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 69.07	
[12/03 17:13:18 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.0924024048078213
[12/03 17:21:40 visual_prompt]: Epoch 27 / 100: avg data time: 5.72e+00, avg batch time: 7.1738, average train loss: 0.6132
[12/03 17:22:38 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.5894, average loss: 0.6699
[12/03 17:22:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.01	rocauc: 68.37	
[12/03 17:22:38 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.09145187862775209
[12/03 17:30:59 visual_prompt]: Epoch 28 / 100: avg data time: 5.71e+00, avg batch time: 7.1614, average train loss: 0.6172
[12/03 17:31:57 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.5871, average loss: 0.6365
[12/03 17:31:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 68.74	
[12/03 17:31:57 visual_prompt]: Best epoch 28: best metric: -0.637
[12/03 17:31:57 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.09045084971874738
[12/03 17:40:18 visual_prompt]: Epoch 29 / 100: avg data time: 5.69e+00, avg batch time: 7.1492, average train loss: 0.5780
[12/03 17:41:16 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.5848, average loss: 0.7155
[12/03 17:41:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 67.52	
[12/03 17:41:16 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.0894005376803361
[12/03 17:49:37 visual_prompt]: Epoch 30 / 100: avg data time: 5.71e+00, avg batch time: 7.1624, average train loss: 0.5834
[12/03 17:50:34 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.5867, average loss: 0.8498
[12/03 17:50:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.47	rocauc: 69.05	
[12/03 17:50:34 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.0883022221559489
[12/03 17:58:52 visual_prompt]: Epoch 31 / 100: avg data time: 5.65e+00, avg batch time: 7.1067, average train loss: 0.5799
[12/03 17:59:50 visual_prompt]: Inference (val):avg data time: 3.76e-05, avg batch time: 0.5919, average loss: 0.6682
[12/03 17:59:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 68.53	
[12/03 17:59:50 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.08715724127386971
[12/03 18:08:09 visual_prompt]: Epoch 32 / 100: avg data time: 5.68e+00, avg batch time: 7.1346, average train loss: 0.5594
[12/03 18:09:07 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.5858, average loss: 0.6407
[12/03 18:09:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 69.75	
[12/03 18:09:07 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.08596699001693256
[12/03 18:17:27 visual_prompt]: Epoch 33 / 100: avg data time: 5.69e+00, avg batch time: 7.1454, average train loss: 0.5476
[12/03 18:18:26 visual_prompt]: Inference (val):avg data time: 4.57e-05, avg batch time: 0.5856, average loss: 0.6488
[12/03 18:18:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 67.11	
[12/03 18:18:26 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.08473291852294987
[12/03 18:26:46 visual_prompt]: Epoch 34 / 100: avg data time: 5.69e+00, avg batch time: 7.1430, average train loss: 0.5400
[12/03 18:27:44 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.5858, average loss: 0.6222
[12/03 18:27:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.89	rocauc: 70.72	
[12/03 18:27:44 visual_prompt]: Best epoch 34: best metric: -0.622
[12/03 18:27:44 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.08345653031794292
[12/03 18:36:02 visual_prompt]: Epoch 35 / 100: avg data time: 5.67e+00, avg batch time: 7.1226, average train loss: 0.5361
[12/03 18:37:00 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.5886, average loss: 0.6581
[12/03 18:37:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 67.89	
[12/03 18:37:00 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.08213938048432697
[12/03 18:45:23 visual_prompt]: Epoch 36 / 100: avg data time: 5.73e+00, avg batch time: 7.1878, average train loss: 0.5185
[12/03 18:46:21 visual_prompt]: Inference (val):avg data time: 3.91e-05, avg batch time: 0.5942, average loss: 0.6436
[12/03 18:46:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 68.56	
[12/03 18:46:21 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.08078307376628291
[12/03 18:54:41 visual_prompt]: Epoch 37 / 100: avg data time: 5.68e+00, avg batch time: 7.1397, average train loss: 0.5165
[12/03 18:55:39 visual_prompt]: Inference (val):avg data time: 3.43e-05, avg batch time: 0.5872, average loss: 0.6916
[12/03 18:55:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 67.67	
[12/03 18:55:39 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.07938926261462366
[12/03 19:04:00 visual_prompt]: Epoch 38 / 100: avg data time: 5.70e+00, avg batch time: 7.1563, average train loss: 0.4875
[12/03 19:04:58 visual_prompt]: Inference (val):avg data time: 3.52e-05, avg batch time: 0.5873, average loss: 0.7744
[12/03 19:04:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 68.36	
[12/03 19:04:58 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.07795964517353735
[12/03 19:13:24 visual_prompt]: Epoch 39 / 100: avg data time: 5.77e+00, avg batch time: 7.2234, average train loss: 0.5244
[12/03 19:14:22 visual_prompt]: Inference (val):avg data time: 4.31e-05, avg batch time: 0.5872, average loss: 0.7858
[12/03 19:14:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.01	rocauc: 67.88	
[12/03 19:14:22 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.07649596321166025
[12/03 19:22:44 visual_prompt]: Epoch 40 / 100: avg data time: 5.71e+00, avg batch time: 7.1669, average train loss: 0.4886
[12/03 19:23:41 visual_prompt]: Inference (val):avg data time: 4.04e-05, avg batch time: 0.5891, average loss: 0.6871
[12/03 19:23:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 68.20	
[12/03 19:23:41 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.07500000000000001
[12/03 19:32:04 visual_prompt]: Epoch 41 / 100: avg data time: 5.72e+00, avg batch time: 7.1705, average train loss: 0.4619
[12/03 19:33:01 visual_prompt]: Inference (val):avg data time: 4.06e-05, avg batch time: 0.5877, average loss: 0.8473
[12/03 19:33:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 68.15	
[12/03 19:33:01 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.07347357813929455
[12/03 19:41:21 visual_prompt]: Epoch 42 / 100: avg data time: 5.69e+00, avg batch time: 7.1434, average train loss: 0.4683
[12/03 19:42:19 visual_prompt]: Inference (val):avg data time: 3.50e-05, avg batch time: 0.5892, average loss: 0.6786
[12/03 19:42:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 68.96	
[12/03 19:42:19 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.07191855733945388
[12/03 19:50:42 visual_prompt]: Epoch 43 / 100: avg data time: 5.74e+00, avg batch time: 7.1898, average train loss: 0.4916
[12/03 19:51:40 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.5885, average loss: 0.7111
[12/03 19:51:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 68.59	
[12/03 19:51:40 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.07033683215379002
[12/03 20:00:03 visual_prompt]: Epoch 44 / 100: avg data time: 5.73e+00, avg batch time: 7.1813, average train loss: 0.4377
[12/03 20:01:00 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.5905, average loss: 0.7217
[12/03 20:01:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 68.48	
[12/03 20:01:00 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.0687303296707956
[12/03 20:09:23 visual_prompt]: Epoch 45 / 100: avg data time: 5.73e+00, avg batch time: 7.1813, average train loss: 0.4268
[12/03 20:10:20 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.5853, average loss: 0.7279
[12/03 20:10:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.67	rocauc: 69.61	
[12/03 20:10:20 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.06710100716628345
[12/03 20:18:41 visual_prompt]: Epoch 46 / 100: avg data time: 5.71e+00, avg batch time: 7.1572, average train loss: 0.4284
[12/03 20:19:38 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.5867, average loss: 0.7365
[12/03 20:19:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 68.32	
[12/03 20:19:38 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.06545084971874737
[12/03 20:28:00 visual_prompt]: Epoch 47 / 100: avg data time: 5.71e+00, avg batch time: 7.1688, average train loss: 0.4294
[12/03 20:28:58 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.5875, average loss: 0.7785
[12/03 20:28:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 68.86	
[12/03 20:28:58 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.06378186779084996
[12/03 20:37:21 visual_prompt]: Epoch 48 / 100: avg data time: 5.74e+00, avg batch time: 7.1910, average train loss: 0.3932
[12/03 20:38:19 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.5857, average loss: 0.7197
[12/03 20:38:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 68.17	
[12/03 20:38:19 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.06209609477998338
[12/03 20:46:41 visual_prompt]: Epoch 49 / 100: avg data time: 5.71e+00, avg batch time: 7.1651, average train loss: 0.3624
[12/03 20:47:38 visual_prompt]: Inference (val):avg data time: 3.63e-05, avg batch time: 0.5855, average loss: 0.7938
[12/03 20:47:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 65.25	
[12/03 20:47:38 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.06039558454088796
[12/03 20:55:59 visual_prompt]: Epoch 50 / 100: avg data time: 5.71e+00, avg batch time: 7.1574, average train loss: 0.4148
[12/03 20:56:56 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.5863, average loss: 0.9198
[12/03 20:56:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 65.42	
[12/03 20:56:56 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.058682408883346526
[12/03 21:05:17 visual_prompt]: Epoch 51 / 100: avg data time: 5.70e+00, avg batch time: 7.1524, average train loss: 0.3522
[12/03 21:06:14 visual_prompt]: Inference (val):avg data time: 4.35e-05, avg batch time: 0.5904, average loss: 0.8160
[12/03 21:06:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 67.76	
[12/03 21:06:14 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.05695865504800327
[12/03 21:14:34 visual_prompt]: Epoch 52 / 100: avg data time: 5.68e+00, avg batch time: 7.1377, average train loss: 0.3208
[12/03 21:15:33 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.5876, average loss: 1.2260
[12/03 21:15:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.07	rocauc: 64.60	
[12/03 21:15:33 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.05522642316338268
[12/03 21:23:59 visual_prompt]: Epoch 53 / 100: avg data time: 5.77e+00, avg batch time: 7.2270, average train loss: 0.3864
[12/03 21:24:58 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.5851, average loss: 0.9157
[12/03 21:24:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 63.23	
[12/03 21:24:58 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.05348782368720626
[12/03 21:36:38 visual_prompt]: Epoch 54 / 100: avg data time: 8.55e+00, avg batch time: 9.9944, average train loss: 0.3588
[12/03 21:37:48 visual_prompt]: Inference (val):avg data time: 3.63e-05, avg batch time: 0.5884, average loss: 0.7953
[12/03 21:37:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 66.52	
[12/03 21:37:48 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.05174497483512506
[12/03 21:46:26 visual_prompt]: Epoch 55 / 100: avg data time: 5.94e+00, avg batch time: 7.3914, average train loss: 0.3227
[12/03 21:47:23 visual_prompt]: Inference (val):avg data time: 4.06e-05, avg batch time: 0.5913, average loss: 0.8700
[12/03 21:47:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.01	rocauc: 66.93	
[12/03 21:47:23 visual_prompt]: Stopping early.
[12/03 21:47:24 visual_prompt]: Rank of current process: 0. World size: 1
[12/03 21:47:24 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[12/03 21:47:24 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[12/03 21:47:24 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[12/03 21:47:24 visual_prompt]: Training with config:
[12/03 21:47:24 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr0.05_wd0.01/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.05, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[12/03 21:47:24 visual_prompt]: Loading training data...
[12/03 21:47:24 visual_prompt]: Constructing mammo-cbis dataset train...
[12/03 21:47:24 visual_prompt]: Loading validation data...
[12/03 21:47:24 visual_prompt]: Constructing mammo-cbis dataset val...
[12/03 21:47:24 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[12/03 21:47:43 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[12/03 21:47:43 visual_prompt]: tuned percent:0.532
[12/03 21:47:43 visual_prompt]: Device used for model: 0
[12/03 21:47:43 visual_prompt]: Setting up Evaluator...
[12/03 21:47:43 visual_prompt]: Setting up Trainer...
[12/03 21:47:43 visual_prompt]: 	Setting up the optimizer...
[12/03 21:47:43 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[12/03 21:56:05 visual_prompt]: Epoch 1 / 100: avg data time: 5.71e+00, avg batch time: 7.1663, average train loss: 1.4863
[12/03 21:57:03 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.5888, average loss: 1.4553
[12/03 21:57:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[12/03 21:57:03 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.005000000000000001
[12/03 22:05:26 visual_prompt]: Epoch 2 / 100: avg data time: 5.72e+00, avg batch time: 7.1754, average train loss: 0.8422
[12/03 22:06:23 visual_prompt]: Inference (val):avg data time: 4.00e-05, avg batch time: 0.5900, average loss: 0.6853
[12/03 22:06:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 53.22	
[12/03 22:06:23 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.010000000000000002
[12/03 22:14:48 visual_prompt]: Epoch 3 / 100: avg data time: 5.75e+00, avg batch time: 7.2055, average train loss: 0.7065
[12/03 22:15:46 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.5880, average loss: 0.7517
[12/03 22:15:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.97	
[12/03 22:15:46 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.015
[12/03 22:24:11 visual_prompt]: Epoch 4 / 100: avg data time: 5.76e+00, avg batch time: 7.2152, average train loss: 0.7180
[12/03 22:25:09 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.5916, average loss: 0.7093
[12/03 22:25:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.05	
[12/03 22:25:09 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.020000000000000004
[12/03 22:33:31 visual_prompt]: Epoch 5 / 100: avg data time: 5.71e+00, avg batch time: 7.1587, average train loss: 0.7251
[12/03 22:34:28 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.5867, average loss: 0.6796
[12/03 22:34:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 62.36	
[12/03 22:34:28 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.025
[12/03 22:42:52 visual_prompt]: Epoch 6 / 100: avg data time: 5.74e+00, avg batch time: 7.1921, average train loss: 0.7305
[12/03 22:43:49 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.5865, average loss: 0.7493
[12/03 22:43:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.37	
[12/03 22:43:49 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.03
[12/03 22:52:09 visual_prompt]: Epoch 7 / 100: avg data time: 5.69e+00, avg batch time: 7.1420, average train loss: 0.7018
[12/03 22:53:06 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.5891, average loss: 0.8585
[12/03 22:53:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.09	
[12/03 22:53:06 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.034999999999999996
[12/03 23:01:29 visual_prompt]: Epoch 8 / 100: avg data time: 5.73e+00, avg batch time: 7.1828, average train loss: 0.7259
[12/03 23:02:27 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.5877, average loss: 0.6974
[12/03 23:02:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.00	
[12/03 23:02:27 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.04000000000000001
[12/03 23:10:48 visual_prompt]: Epoch 9 / 100: avg data time: 5.71e+00, avg batch time: 7.1604, average train loss: 0.6999
[12/03 23:11:46 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.5889, average loss: 0.7333
[12/03 23:11:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.43	
[12/03 23:11:46 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.045000000000000005
[12/03 23:20:05 visual_prompt]: Epoch 10 / 100: avg data time: 5.68e+00, avg batch time: 7.1281, average train loss: 0.6850
[12/03 23:21:02 visual_prompt]: Inference (val):avg data time: 3.82e-05, avg batch time: 0.5889, average loss: 0.6883
[12/03 23:21:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.24	
[12/03 23:21:02 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.05
[12/03 23:29:24 visual_prompt]: Epoch 11 / 100: avg data time: 5.71e+00, avg batch time: 7.1626, average train loss: 0.7027
[12/03 23:30:22 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.5863, average loss: 0.6872
[12/03 23:30:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.04	
[12/03 23:30:22 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0499847706754774
[12/03 23:38:46 visual_prompt]: Epoch 12 / 100: avg data time: 5.75e+00, avg batch time: 7.2027, average train loss: 0.6914
[12/03 23:39:44 visual_prompt]: Inference (val):avg data time: 4.76e-05, avg batch time: 0.5880, average loss: 0.7007
[12/03 23:39:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.53	rocauc: 60.32	
[12/03 23:39:44 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.04993910125649561
[12/03 23:48:05 visual_prompt]: Epoch 13 / 100: avg data time: 5.70e+00, avg batch time: 7.1529, average train loss: 0.7069
[12/03 23:49:02 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.5912, average loss: 0.6902
[12/03 23:49:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 57.51	
[12/03 23:49:02 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.049863047384206834
[12/03 23:57:26 visual_prompt]: Epoch 14 / 100: avg data time: 5.75e+00, avg batch time: 7.2023, average train loss: 0.6959
[12/03 23:58:24 visual_prompt]: Inference (val):avg data time: 3.82e-05, avg batch time: 0.5839, average loss: 0.7292
[12/03 23:58:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.10	
[12/03 23:58:24 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.04975670171853926
[12/04 00:06:51 visual_prompt]: Epoch 15 / 100: avg data time: 5.79e+00, avg batch time: 7.2419, average train loss: 0.6943
[12/04 00:07:51 visual_prompt]: Inference (val):avg data time: 4.50e-05, avg batch time: 0.5869, average loss: 0.6879
[12/04 00:07:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.16	
[12/04 00:07:51 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.049620193825305206
[12/04 00:16:14 visual_prompt]: Epoch 16 / 100: avg data time: 5.73e+00, avg batch time: 7.1883, average train loss: 0.6996
[12/04 00:17:13 visual_prompt]: Inference (val):avg data time: 4.76e-05, avg batch time: 0.5820, average loss: 0.7077
[12/04 00:17:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.62	
[12/04 00:17:13 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.049453690018345146
[12/04 00:25:35 visual_prompt]: Epoch 17 / 100: avg data time: 5.72e+00, avg batch time: 7.1700, average train loss: 0.6983
[12/04 00:26:32 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.5848, average loss: 0.7014
[12/04 00:26:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.40	
[12/04 00:26:32 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.04925739315689991
[12/04 00:34:51 visual_prompt]: Epoch 18 / 100: avg data time: 5.68e+00, avg batch time: 7.1296, average train loss: 0.6996
[12/04 00:35:49 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.5907, average loss: 0.7535
[12/04 00:35:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.60	
[12/04 00:35:49 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.04903154239845797
[12/04 00:44:09 visual_prompt]: Epoch 19 / 100: avg data time: 5.69e+00, avg batch time: 7.1383, average train loss: 0.7045
[12/04 00:45:06 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.5883, average loss: 0.7193
[12/04 00:45:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.47	
[12/04 00:45:06 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.048776412907378844
[12/04 00:53:30 visual_prompt]: Epoch 20 / 100: avg data time: 5.75e+00, avg batch time: 7.2004, average train loss: 0.6974
[12/04 00:54:29 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.5875, average loss: 0.6886
[12/04 00:54:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.41	
[12/04 00:54:29 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.048492315519647715
[12/04 01:02:50 visual_prompt]: Epoch 21 / 100: avg data time: 5.71e+00, avg batch time: 7.1660, average train loss: 0.6972
[12/04 01:03:48 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.5843, average loss: 0.6912
[12/04 01:03:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.55	
[12/04 01:03:48 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.048179596364169686
[12/04 01:12:10 visual_prompt]: Epoch 22 / 100: avg data time: 5.73e+00, avg batch time: 7.1783, average train loss: 0.6963
[12/04 01:13:08 visual_prompt]: Inference (val):avg data time: 4.91e-05, avg batch time: 0.5854, average loss: 0.6882
[12/04 01:13:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.08	
[12/04 01:13:08 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.04783863644106502
[12/04 01:21:31 visual_prompt]: Epoch 23 / 100: avg data time: 5.73e+00, avg batch time: 7.1897, average train loss: 0.6904
[12/04 01:22:28 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.5891, average loss: 0.6909
[12/04 01:22:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.12	
[12/04 01:22:28 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.047469851157479176
[12/04 01:30:55 visual_prompt]: Epoch 24 / 100: avg data time: 5.79e+00, avg batch time: 7.2401, average train loss: 0.6938
[12/04 01:31:53 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.5872, average loss: 0.6930
[12/04 01:31:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 57.48	
[12/04 01:31:53 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.047073689821473176
[12/04 01:40:24 visual_prompt]: Epoch 25 / 100: avg data time: 5.84e+00, avg batch time: 7.2885, average train loss: 0.6929
[12/04 01:41:22 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.5865, average loss: 0.6916
[12/04 01:41:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.80	
[12/04 01:41:22 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.046650635094610975
[12/04 01:49:46 visual_prompt]: Epoch 26 / 100: avg data time: 5.74e+00, avg batch time: 7.1936, average train loss: 0.6934
[12/04 01:50:44 visual_prompt]: Inference (val):avg data time: 3.60e-05, avg batch time: 0.5893, average loss: 0.6946
[12/04 01:50:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.71	
[12/04 01:50:44 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.04620120240391065
[12/04 01:59:05 visual_prompt]: Epoch 27 / 100: avg data time: 5.69e+00, avg batch time: 7.1517, average train loss: 0.6919
[12/04 02:00:02 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.5844, average loss: 0.6883
[12/04 02:00:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.06	
[12/04 02:00:02 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.04572593931387604
[12/04 02:08:23 visual_prompt]: Epoch 28 / 100: avg data time: 5.70e+00, avg batch time: 7.1532, average train loss: 0.6916
[12/04 02:09:21 visual_prompt]: Inference (val):avg data time: 3.63e-05, avg batch time: 0.5852, average loss: 0.6925
[12/04 02:09:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.88	
[12/04 02:09:21 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.04522542485937369
[12/04 02:17:41 visual_prompt]: Epoch 29 / 100: avg data time: 5.68e+00, avg batch time: 7.1393, average train loss: 0.6919
[12/04 02:18:38 visual_prompt]: Inference (val):avg data time: 3.38e-05, avg batch time: 0.5889, average loss: 0.6876
[12/04 02:18:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.89	
[12/04 02:18:38 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.04470026884016805
[12/04 02:27:00 visual_prompt]: Epoch 30 / 100: avg data time: 5.72e+00, avg batch time: 7.1697, average train loss: 0.6927
[12/04 02:27:58 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.5831, average loss: 0.6901
[12/04 02:27:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.84	
[12/04 02:27:58 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.04415111107797445
[12/04 02:36:18 visual_prompt]: Epoch 31 / 100: avg data time: 5.69e+00, avg batch time: 7.1404, average train loss: 0.6951
[12/04 02:37:15 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.5864, average loss: 0.6891
[12/04 02:37:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.08	
[12/04 02:37:15 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.04357862063693486
[12/04 02:45:38 visual_prompt]: Epoch 32 / 100: avg data time: 5.74e+00, avg batch time: 7.1899, average train loss: 0.6991
[12/04 02:46:36 visual_prompt]: Inference (val):avg data time: 4.51e-05, avg batch time: 0.5893, average loss: 0.6945
[12/04 02:46:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.13	
[12/04 02:46:36 visual_prompt]: Stopping early.
[12/04 02:46:37 visual_prompt]: Rank of current process: 0. World size: 1
[12/04 02:46:37 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[12/04 02:46:37 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[12/04 02:46:37 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[12/04 02:46:37 visual_prompt]: Training with config:
[12/04 02:46:37 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr0.05_wd0.001/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.05, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[12/04 02:46:37 visual_prompt]: Loading training data...
[12/04 02:46:37 visual_prompt]: Constructing mammo-cbis dataset train...
[12/04 02:46:37 visual_prompt]: Loading validation data...
[12/04 02:46:37 visual_prompt]: Constructing mammo-cbis dataset val...
[12/04 02:46:37 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[12/04 02:46:40 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[12/04 02:46:40 visual_prompt]: tuned percent:0.532
[12/04 02:46:40 visual_prompt]: Device used for model: 0
[12/04 02:46:40 visual_prompt]: Setting up Evaluator...
[12/04 02:46:40 visual_prompt]: Setting up Trainer...
[12/04 02:46:40 visual_prompt]: 	Setting up the optimizer...
[12/04 02:46:40 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[12/04 02:55:01 visual_prompt]: Epoch 1 / 100: avg data time: 5.70e+00, avg batch time: 7.1517, average train loss: 1.4863
[12/04 02:55:58 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.5910, average loss: 1.4553
[12/04 02:55:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[12/04 02:55:58 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.005000000000000001
[12/04 03:04:22 visual_prompt]: Epoch 2 / 100: avg data time: 5.74e+00, avg batch time: 7.1909, average train loss: 0.8431
[12/04 03:05:20 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.5885, average loss: 0.6853
[12/04 03:05:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 53.14	
[12/04 03:05:20 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.010000000000000002
[12/04 03:13:46 visual_prompt]: Epoch 3 / 100: avg data time: 5.78e+00, avg batch time: 7.2301, average train loss: 0.7076
[12/04 03:14:44 visual_prompt]: Inference (val):avg data time: 4.54e-05, avg batch time: 0.5863, average loss: 0.7529
[12/04 03:14:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.85	
[12/04 03:14:44 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.015
[12/04 03:23:08 visual_prompt]: Epoch 4 / 100: avg data time: 5.75e+00, avg batch time: 7.2027, average train loss: 0.7220
[12/04 03:24:06 visual_prompt]: Inference (val):avg data time: 3.87e-05, avg batch time: 0.5886, average loss: 0.7055
[12/04 03:24:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.66	
[12/04 03:24:06 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.020000000000000004
[12/04 03:32:26 visual_prompt]: Epoch 5 / 100: avg data time: 5.70e+00, avg batch time: 7.1525, average train loss: 0.7266
[12/04 03:33:24 visual_prompt]: Inference (val):avg data time: 4.82e-05, avg batch time: 0.5878, average loss: 0.6776
[12/04 03:33:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 61.00	
[12/04 03:33:24 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.025
[12/04 03:41:47 visual_prompt]: Epoch 6 / 100: avg data time: 5.73e+00, avg batch time: 7.1800, average train loss: 0.7288
[12/04 03:42:45 visual_prompt]: Inference (val):avg data time: 3.64e-05, avg batch time: 0.5859, average loss: 0.7306
[12/04 03:42:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.49	
[12/04 03:42:45 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.03
[12/04 03:51:03 visual_prompt]: Epoch 7 / 100: avg data time: 5.66e+00, avg batch time: 7.1097, average train loss: 0.6904
[12/04 03:52:00 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.5867, average loss: 1.0579
[12/04 03:52:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.54	
[12/04 03:52:00 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.034999999999999996
[12/04 04:00:22 visual_prompt]: Epoch 8 / 100: avg data time: 5.71e+00, avg batch time: 7.1665, average train loss: 0.7330
[12/04 04:01:20 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.5893, average loss: 0.6750
[12/04 04:01:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 62.60	
[12/04 04:01:20 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.04000000000000001
[12/04 04:09:39 visual_prompt]: Epoch 9 / 100: avg data time: 5.68e+00, avg batch time: 7.1307, average train loss: 0.7118
[12/04 04:10:37 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.5847, average loss: 0.6890
[12/04 04:10:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 64.22	
[12/04 04:10:37 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.045000000000000005
[12/04 04:18:57 visual_prompt]: Epoch 10 / 100: avg data time: 5.68e+00, avg batch time: 7.1370, average train loss: 0.6765
[12/04 04:19:54 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.5897, average loss: 0.6570
[12/04 04:19:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 65.48	
[12/04 04:19:54 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.05
[12/04 04:28:15 visual_prompt]: Epoch 11 / 100: avg data time: 5.70e+00, avg batch time: 7.1569, average train loss: 0.6915
[12/04 04:29:13 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.5849, average loss: 0.7256
[12/04 04:29:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 65.81	
[12/04 04:29:13 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0499847706754774
[12/04 04:37:36 visual_prompt]: Epoch 12 / 100: avg data time: 5.72e+00, avg batch time: 7.1764, average train loss: 0.6836
[12/04 04:38:33 visual_prompt]: Inference (val):avg data time: 4.36e-05, avg batch time: 0.5895, average loss: 0.7535
[12/04 04:38:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 49.59	rocauc: 65.73	
[12/04 04:38:33 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.04993910125649561
[12/04 04:46:58 visual_prompt]: Epoch 13 / 100: avg data time: 5.76e+00, avg batch time: 7.2090, average train loss: 0.6943
[12/04 04:47:55 visual_prompt]: Inference (val):avg data time: 4.04e-05, avg batch time: 0.5906, average loss: 0.6464
[12/04 04:47:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 67.93	
[12/04 04:47:55 visual_prompt]: Best epoch 13: best metric: -0.646
[12/04 04:47:55 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.049863047384206834
[12/04 04:56:15 visual_prompt]: Epoch 14 / 100: avg data time: 5.69e+00, avg batch time: 7.1420, average train loss: 0.6748
[12/04 04:57:13 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.5851, average loss: 0.7117
[12/04 04:57:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 53.66	rocauc: 66.82	
[12/04 04:57:13 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.04975670171853926
[12/04 05:05:32 visual_prompt]: Epoch 15 / 100: avg data time: 5.68e+00, avg batch time: 7.1277, average train loss: 0.6696
[12/04 05:06:29 visual_prompt]: Inference (val):avg data time: 4.97e-05, avg batch time: 0.5913, average loss: 0.6578
[12/04 05:06:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 66.53	
[12/04 05:06:29 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.049620193825305206
[12/04 05:14:49 visual_prompt]: Epoch 16 / 100: avg data time: 5.68e+00, avg batch time: 7.1383, average train loss: 0.6590
[12/04 05:15:45 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.5857, average loss: 0.7779
[12/04 05:15:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.47	rocauc: 68.18	
[12/04 05:15:45 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.049453690018345146
[12/04 05:24:04 visual_prompt]: Epoch 17 / 100: avg data time: 5.67e+00, avg batch time: 7.1246, average train loss: 0.6642
[12/04 05:25:02 visual_prompt]: Inference (val):avg data time: 3.50e-05, avg batch time: 0.5912, average loss: 0.6924
[12/04 05:25:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 69.02	
[12/04 05:25:02 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.04925739315689991
[12/04 05:33:22 visual_prompt]: Epoch 18 / 100: avg data time: 5.68e+00, avg batch time: 7.1338, average train loss: 0.6564
[12/04 05:34:20 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.5898, average loss: 1.0889
[12/04 05:34:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 68.52	
[12/04 05:34:20 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.04903154239845797
[12/04 05:42:38 visual_prompt]: Epoch 19 / 100: avg data time: 5.66e+00, avg batch time: 7.1138, average train loss: 0.6626
[12/04 05:43:36 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.5887, average loss: 0.7817
[12/04 05:43:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 67.29	
[12/04 05:43:36 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.048776412907378844
[12/04 05:51:58 visual_prompt]: Epoch 20 / 100: avg data time: 5.71e+00, avg batch time: 7.1639, average train loss: 0.6401
[12/04 05:52:55 visual_prompt]: Inference (val):avg data time: 4.71e-05, avg batch time: 0.5863, average loss: 0.7243
[12/04 05:52:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 68.44	
[12/04 05:52:55 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.048492315519647715
[12/04 06:01:17 visual_prompt]: Epoch 21 / 100: avg data time: 5.72e+00, avg batch time: 7.1688, average train loss: 0.6559
[12/04 06:02:14 visual_prompt]: Inference (val):avg data time: 3.62e-05, avg batch time: 0.5905, average loss: 0.6843
[12/04 06:02:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 69.96	
[12/04 06:02:14 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.048179596364169686
[12/04 06:10:34 visual_prompt]: Epoch 22 / 100: avg data time: 5.69e+00, avg batch time: 7.1405, average train loss: 0.6299
[12/04 06:11:31 visual_prompt]: Inference (val):avg data time: 3.91e-05, avg batch time: 0.5883, average loss: 0.6498
[12/04 06:11:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 67.49	
[12/04 06:11:31 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.04783863644106502
[12/04 06:19:52 visual_prompt]: Epoch 23 / 100: avg data time: 5.70e+00, avg batch time: 7.1560, average train loss: 0.6491
[12/04 06:20:49 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.5866, average loss: 0.6622
[12/04 06:20:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 69.56	
[12/04 06:20:49 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.047469851157479176
[12/04 06:29:10 visual_prompt]: Epoch 24 / 100: avg data time: 5.69e+00, avg batch time: 7.1432, average train loss: 0.6324
[12/04 06:30:06 visual_prompt]: Inference (val):avg data time: 4.14e-05, avg batch time: 0.5870, average loss: 0.6624
[12/04 06:30:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 66.60	
[12/04 06:30:06 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.047073689821473176
[12/04 06:38:28 visual_prompt]: Epoch 25 / 100: avg data time: 5.71e+00, avg batch time: 7.1695, average train loss: 0.6289
[12/04 06:39:26 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.5916, average loss: 0.6822
[12/04 06:39:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 70.96	
[12/04 06:39:26 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.046650635094610975
[12/04 06:47:47 visual_prompt]: Epoch 26 / 100: avg data time: 5.70e+00, avg batch time: 7.1598, average train loss: 0.6338
[12/04 06:48:45 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.5847, average loss: 0.6584
[12/04 06:48:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 71.50	
[12/04 06:48:45 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.04620120240391065
[12/04 06:57:10 visual_prompt]: Epoch 27 / 100: avg data time: 5.75e+00, avg batch time: 7.2091, average train loss: 0.6139
[12/04 06:58:08 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.5869, average loss: 0.6436
[12/04 06:58:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.67	rocauc: 68.89	
[12/04 06:58:08 visual_prompt]: Best epoch 27: best metric: -0.644
[12/04 06:58:08 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.04572593931387604
[12/04 07:06:31 visual_prompt]: Epoch 28 / 100: avg data time: 5.73e+00, avg batch time: 7.1859, average train loss: 0.6221
[12/04 07:07:28 visual_prompt]: Inference (val):avg data time: 3.92e-05, avg batch time: 0.5877, average loss: 0.6307
[12/04 07:07:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 71.14	rocauc: 71.24	
[12/04 07:07:28 visual_prompt]: Best epoch 28: best metric: -0.631
[12/04 07:07:28 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.04522542485937369
[12/04 07:15:47 visual_prompt]: Epoch 29 / 100: avg data time: 5.66e+00, avg batch time: 7.1154, average train loss: 0.5977
[12/04 07:16:44 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.5870, average loss: 0.6694
[12/04 07:16:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 70.86	
[12/04 07:16:44 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.04470026884016805
[12/04 07:25:08 visual_prompt]: Epoch 30 / 100: avg data time: 5.75e+00, avg batch time: 7.1999, average train loss: 0.6014
[12/04 07:26:05 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.5876, average loss: 0.8873
[12/04 07:26:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 51.22	rocauc: 69.76	
[12/04 07:26:05 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.04415111107797445
[12/04 07:34:26 visual_prompt]: Epoch 31 / 100: avg data time: 5.70e+00, avg batch time: 7.1506, average train loss: 0.6307
[12/04 07:35:24 visual_prompt]: Inference (val):avg data time: 4.20e-05, avg batch time: 0.5889, average loss: 0.6445
[12/04 07:35:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 69.04	
[12/04 07:35:24 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.04357862063693486
[12/04 07:43:45 visual_prompt]: Epoch 32 / 100: avg data time: 5.70e+00, avg batch time: 7.1586, average train loss: 0.5969
[12/04 07:44:42 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.5890, average loss: 0.6285
[12/04 07:44:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 69.51	rocauc: 70.91	
[12/04 07:44:42 visual_prompt]: Best epoch 32: best metric: -0.628
[12/04 07:44:42 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.04298349500846628
[12/04 07:53:03 visual_prompt]: Epoch 33 / 100: avg data time: 5.70e+00, avg batch time: 7.1496, average train loss: 0.5855
[12/04 07:54:01 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.5887, average loss: 0.6271
[12/04 07:54:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.89	rocauc: 71.76	
[12/04 07:54:01 visual_prompt]: Best epoch 33: best metric: -0.627
[12/04 07:54:01 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.042366459261474934
[12/04 08:02:20 visual_prompt]: Epoch 34 / 100: avg data time: 5.67e+00, avg batch time: 7.1257, average train loss: 0.5756
[12/04 08:03:18 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.5865, average loss: 0.7462
[12/04 08:03:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 53.66	rocauc: 68.40	
[12/04 08:03:18 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.04172826515897146
[12/04 08:11:36 visual_prompt]: Epoch 35 / 100: avg data time: 5.66e+00, avg batch time: 7.1105, average train loss: 0.5896
[12/04 08:12:33 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.5892, average loss: 0.7076
[12/04 08:12:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 70.34	
[12/04 08:12:33 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.04106969024216348
[12/04 08:20:55 visual_prompt]: Epoch 36 / 100: avg data time: 5.70e+00, avg batch time: 7.1596, average train loss: 0.5709
[12/04 08:21:52 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.5878, average loss: 0.6264
[12/04 08:21:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 71.24	
[12/04 08:21:52 visual_prompt]: Best epoch 36: best metric: -0.626
[12/04 08:21:52 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.040391536883141455
[12/04 08:30:12 visual_prompt]: Epoch 37 / 100: avg data time: 5.70e+00, avg batch time: 7.1495, average train loss: 0.5619
[12/04 08:31:10 visual_prompt]: Inference (val):avg data time: 3.93e-05, avg batch time: 0.5867, average loss: 0.6681
[12/04 08:31:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 71.46	
[12/04 08:31:10 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.03969463130731183
[12/04 08:39:30 visual_prompt]: Epoch 38 / 100: avg data time: 5.70e+00, avg batch time: 7.1506, average train loss: 0.5672
[12/04 08:40:28 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.5917, average loss: 0.6902
[12/04 08:40:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 70.49	
[12/04 08:40:28 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.03897982258676867
[12/04 08:48:47 visual_prompt]: Epoch 39 / 100: avg data time: 5.68e+00, avg batch time: 7.1339, average train loss: 0.5799
[12/04 08:49:44 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.5866, average loss: 0.6602
[12/04 08:49:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 70.56	
[12/04 08:49:44 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.03824798160583012
[12/04 08:58:04 visual_prompt]: Epoch 40 / 100: avg data time: 5.69e+00, avg batch time: 7.1402, average train loss: 0.5735
[12/04 08:59:01 visual_prompt]: Inference (val):avg data time: 3.57e-05, avg batch time: 0.5881, average loss: 0.6906
[12/04 08:59:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 69.83	
[12/04 08:59:01 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.037500000000000006
[12/04 09:07:22 visual_prompt]: Epoch 41 / 100: avg data time: 5.70e+00, avg batch time: 7.1533, average train loss: 0.5849
[12/04 09:08:20 visual_prompt]: Inference (val):avg data time: 5.58e-05, avg batch time: 0.5898, average loss: 0.7252
[12/04 09:08:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 69.56	
[12/04 09:08:20 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.03673678906964727
[12/04 09:16:45 visual_prompt]: Epoch 42 / 100: avg data time: 5.75e+00, avg batch time: 7.2013, average train loss: 0.5599
[12/04 09:17:42 visual_prompt]: Inference (val):avg data time: 3.62e-05, avg batch time: 0.5861, average loss: 0.6449
[12/04 09:17:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 70.32	
[12/04 09:17:42 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.03595927866972694
[12/04 09:26:09 visual_prompt]: Epoch 43 / 100: avg data time: 5.78e+00, avg batch time: 7.2308, average train loss: 0.5567
[12/04 09:27:07 visual_prompt]: Inference (val):avg data time: 4.14e-05, avg batch time: 0.5862, average loss: 0.6291
[12/04 09:27:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 71.34	
[12/04 09:27:07 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.03516841607689501
[12/04 09:35:35 visual_prompt]: Epoch 44 / 100: avg data time: 5.81e+00, avg batch time: 7.2580, average train loss: 0.5366
[12/04 09:36:34 visual_prompt]: Inference (val):avg data time: 3.90e-05, avg batch time: 0.5845, average loss: 0.6660
[12/04 09:36:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.89	rocauc: 70.39	
[12/04 09:36:34 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.0343651648353978
[12/04 09:44:54 visual_prompt]: Epoch 45 / 100: avg data time: 5.70e+00, avg batch time: 7.1529, average train loss: 0.5454
[12/04 09:45:53 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.5851, average loss: 0.6666
[12/04 09:45:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 68.39	
[12/04 09:45:53 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.033550503583141725
[12/04 09:54:11 visual_prompt]: Epoch 46 / 100: avg data time: 5.66e+00, avg batch time: 7.1177, average train loss: 0.5282
[12/04 09:55:08 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.5884, average loss: 0.7362
[12/04 09:55:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 69.04	
[12/04 09:55:08 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.032725424859373686
[12/04 10:03:29 visual_prompt]: Epoch 47 / 100: avg data time: 5.69e+00, avg batch time: 7.1419, average train loss: 0.5651
[12/04 10:04:27 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.5898, average loss: 0.6073
[12/04 10:04:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 69.92	rocauc: 72.34	
[12/04 10:04:27 visual_prompt]: Best epoch 47: best metric: -0.607
[12/04 10:04:27 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.03189093389542498
[12/04 10:12:48 visual_prompt]: Epoch 48 / 100: avg data time: 5.70e+00, avg batch time: 7.1544, average train loss: 0.5237
[12/04 10:13:45 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.5869, average loss: 0.7246
[12/04 10:13:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 67.25	
[12/04 10:13:45 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.03104804738999169
[12/04 10:22:08 visual_prompt]: Epoch 49 / 100: avg data time: 5.72e+00, avg batch time: 7.1778, average train loss: 0.5024
[12/04 10:23:05 visual_prompt]: Inference (val):avg data time: 4.24e-05, avg batch time: 0.5889, average loss: 0.6710
[12/04 10:23:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 67.08	
[12/04 10:23:05 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.03019779227044398
[12/04 10:31:26 visual_prompt]: Epoch 50 / 100: avg data time: 5.69e+00, avg batch time: 7.1466, average train loss: 0.5634
[12/04 10:32:23 visual_prompt]: Inference (val):avg data time: 4.04e-05, avg batch time: 0.5900, average loss: 0.7786
[12/04 10:32:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.01	rocauc: 72.90	
[12/04 10:32:23 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.029341204441673263
[12/04 10:40:41 visual_prompt]: Epoch 51 / 100: avg data time: 5.65e+00, avg batch time: 7.1087, average train loss: 0.5155
[12/04 10:41:38 visual_prompt]: Inference (val):avg data time: 3.81e-05, avg batch time: 0.5936, average loss: 0.8086
[12/04 10:41:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 69.38	
[12/04 10:41:38 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.028479327524001636
[12/04 10:51:16 visual_prompt]: Epoch 52 / 100: avg data time: 6.80e+00, avg batch time: 8.2533, average train loss: 0.4766
[12/04 10:52:32 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.5848, average loss: 0.8776
[12/04 10:52:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 70.20	
[12/04 10:52:32 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.02761321158169134
[12/04 11:01:26 visual_prompt]: Epoch 53 / 100: avg data time: 6.16e+00, avg batch time: 7.6127, average train loss: 0.4970
[12/04 11:02:22 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.5898, average loss: 0.7031
[12/04 11:02:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 71.29	
[12/04 11:02:22 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.02674391184360313
[12/04 11:10:48 visual_prompt]: Epoch 54 / 100: avg data time: 5.77e+00, avg batch time: 7.2259, average train loss: 0.4744
[12/04 11:11:49 visual_prompt]: Inference (val):avg data time: 3.79e-05, avg batch time: 0.5866, average loss: 0.7263
[12/04 11:11:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 68.97	
[12/04 11:11:49 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.02587248741756253
[12/04 11:20:45 visual_prompt]: Epoch 55 / 100: avg data time: 6.19e+00, avg batch time: 7.6427, average train loss: 0.4531
[12/04 11:21:46 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.5886, average loss: 1.4392
[12/04 11:21:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 46.75	rocauc: 69.81	
[12/04 11:21:46 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.025
[12/04 11:30:45 visual_prompt]: Epoch 56 / 100: avg data time: 6.25e+00, avg batch time: 7.7036, average train loss: 0.4702
[12/04 11:31:47 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.5880, average loss: 0.7472
[12/04 11:31:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 68.98	
[12/04 11:31:47 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.024127512582437484
[12/04 11:40:32 visual_prompt]: Epoch 57 / 100: avg data time: 6.05e+00, avg batch time: 7.5005, average train loss: 0.4749
[12/04 11:41:32 visual_prompt]: Inference (val):avg data time: 3.38e-05, avg batch time: 0.5856, average loss: 0.7562
[12/04 11:41:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 71.51	
[12/04 11:41:32 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.02325608815639687
[12/04 11:50:53 visual_prompt]: Epoch 58 / 100: avg data time: 6.55e+00, avg batch time: 8.0059, average train loss: 0.4300
[12/04 11:51:57 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.5896, average loss: 0.7666
[12/04 11:51:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 67.75	
[12/04 11:51:57 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.02238678841830867
[12/04 12:01:00 visual_prompt]: Epoch 59 / 100: avg data time: 6.29e+00, avg batch time: 7.7438, average train loss: 0.4288
[12/04 12:02:04 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.5836, average loss: 0.7432
[12/04 12:02:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.07	rocauc: 69.49	
[12/04 12:02:04 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.02152067247599837
[12/04 12:11:20 visual_prompt]: Epoch 60 / 100: avg data time: 6.49e+00, avg batch time: 7.9373, average train loss: 0.4378
[12/04 12:12:19 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.5884, average loss: 0.7932
[12/04 12:12:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 70.62	
[12/04 12:12:19 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.020658795558326743
[12/04 12:20:49 visual_prompt]: Epoch 61 / 100: avg data time: 5.83e+00, avg batch time: 7.2865, average train loss: 0.4043
[12/04 12:21:52 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.5842, average loss: 0.8499
[12/04 12:21:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 65.49	
[12/04 12:21:52 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.019802207729556022
[12/04 12:30:18 visual_prompt]: Epoch 62 / 100: avg data time: 5.78e+00, avg batch time: 7.2329, average train loss: 0.4275
[12/04 12:31:17 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.5860, average loss: 0.7589
[12/04 12:31:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 69.02	
[12/04 12:31:17 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.018951952610008312
[12/04 12:39:38 visual_prompt]: Epoch 63 / 100: avg data time: 5.70e+00, avg batch time: 7.1557, average train loss: 0.3939
[12/04 12:40:36 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.5914, average loss: 0.9179
[12/04 12:40:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 69.40	
[12/04 12:40:36 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.018109066104575022
[12/04 12:49:00 visual_prompt]: Epoch 64 / 100: avg data time: 5.75e+00, avg batch time: 7.2039, average train loss: 0.3738
[12/04 12:49:59 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.5898, average loss: 1.2675
[12/04 12:49:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 64.76	
[12/04 12:49:59 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.017274575140626316
[12/04 12:58:25 visual_prompt]: Epoch 65 / 100: avg data time: 5.77e+00, avg batch time: 7.2172, average train loss: 0.3679
[12/04 12:59:24 visual_prompt]: Inference (val):avg data time: 4.19e-05, avg batch time: 0.5856, average loss: 0.8442
[12/04 12:59:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 68.21	
[12/04 12:59:24 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.016449496416858285
[12/04 13:07:50 visual_prompt]: Epoch 66 / 100: avg data time: 5.77e+00, avg batch time: 7.2245, average train loss: 0.3313
[12/04 13:08:50 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.5874, average loss: 0.9447
[12/04 13:08:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 67.28	
[12/04 13:08:50 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.0156348351646022
[12/04 13:17:28 visual_prompt]: Epoch 67 / 100: avg data time: 5.94e+00, avg batch time: 7.3969, average train loss: 0.2897
[12/04 13:18:27 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.5897, average loss: 1.1046
[12/04 13:18:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 66.60	
[12/04 13:18:27 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.014831583923105
[12/04 13:26:52 visual_prompt]: Epoch 68 / 100: avg data time: 5.76e+00, avg batch time: 7.2103, average train loss: 0.3076
[12/04 13:27:50 visual_prompt]: Inference (val):avg data time: 4.03e-05, avg batch time: 0.5886, average loss: 1.0492
[12/04 13:27:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 67.47	
[12/04 13:27:50 visual_prompt]: Stopping early.
[12/04 13:27:51 visual_prompt]: Rank of current process: 0. World size: 1
[12/04 13:27:51 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[12/04 13:27:51 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[12/04 13:27:51 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[12/04 13:27:51 visual_prompt]: Training with config:
[12/04 13:27:51 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr0.05_wd0.0001/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.05, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[12/04 13:27:51 visual_prompt]: Loading training data...
[12/04 13:27:51 visual_prompt]: Constructing mammo-cbis dataset train...
[12/04 13:27:51 visual_prompt]: Loading validation data...
[12/04 13:27:51 visual_prompt]: Constructing mammo-cbis dataset val...
[12/04 13:27:51 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[12/04 13:27:55 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[12/04 13:27:55 visual_prompt]: tuned percent:0.532
[12/04 13:27:55 visual_prompt]: Device used for model: 0
[12/04 13:27:55 visual_prompt]: Setting up Evaluator...
[12/04 13:27:55 visual_prompt]: Setting up Trainer...
[12/04 13:27:55 visual_prompt]: 	Setting up the optimizer...
[12/04 13:27:56 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[12/04 13:36:18 visual_prompt]: Epoch 1 / 100: avg data time: 5.71e+00, avg batch time: 7.1638, average train loss: 1.4863
[12/04 13:37:16 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.5853, average loss: 1.4553
[12/04 13:37:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[12/04 13:37:16 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.005000000000000001
[12/04 13:46:01 visual_prompt]: Epoch 2 / 100: avg data time: 6.05e+00, avg batch time: 7.5051, average train loss: 0.8431
[12/04 13:47:00 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.5855, average loss: 0.6853
[12/04 13:47:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 53.16	
[12/04 13:47:00 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.010000000000000002
[12/04 13:55:44 visual_prompt]: Epoch 3 / 100: avg data time: 6.04e+00, avg batch time: 7.4933, average train loss: 0.7078
[12/04 13:56:43 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.5866, average loss: 0.7530
[12/04 13:56:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.84	
[12/04 13:56:43 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.015
[12/04 14:05:22 visual_prompt]: Epoch 4 / 100: avg data time: 5.96e+00, avg batch time: 7.4170, average train loss: 0.7224
[12/04 14:06:20 visual_prompt]: Inference (val):avg data time: 3.71e-05, avg batch time: 0.5867, average loss: 0.7051
[12/04 14:06:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.60	
[12/04 14:06:20 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.020000000000000004
[12/04 14:14:41 visual_prompt]: Epoch 5 / 100: avg data time: 5.70e+00, avg batch time: 7.1536, average train loss: 0.7267
[12/04 14:15:39 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.5841, average loss: 0.6773
[12/04 14:15:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 60.93	
[12/04 14:15:39 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.025
[12/04 14:24:08 visual_prompt]: Epoch 6 / 100: avg data time: 5.81e+00, avg batch time: 7.2677, average train loss: 0.7296
[12/04 14:25:06 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.5883, average loss: 0.7267
[12/04 14:25:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.25	
[12/04 14:25:06 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.03
[12/04 14:33:31 visual_prompt]: Epoch 7 / 100: avg data time: 5.76e+00, avg batch time: 7.2088, average train loss: 0.6895
[12/04 14:34:28 visual_prompt]: Inference (val):avg data time: 3.62e-05, avg batch time: 0.5913, average loss: 1.0714
[12/04 14:34:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.78	
[12/04 14:34:28 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.034999999999999996
[12/04 14:42:49 visual_prompt]: Epoch 8 / 100: avg data time: 5.70e+00, avg batch time: 7.1541, average train loss: 0.7390
[12/04 14:43:46 visual_prompt]: Inference (val):avg data time: 3.50e-05, avg batch time: 0.5899, average loss: 0.6757
[12/04 14:43:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 62.14	
[12/04 14:43:46 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.04000000000000001
[12/04 14:52:22 visual_prompt]: Epoch 9 / 100: avg data time: 5.91e+00, avg batch time: 7.3606, average train loss: 0.7079
[12/04 14:53:23 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.5840, average loss: 0.6737
[12/04 14:53:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 63.94	
[12/04 14:53:23 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.045000000000000005
[12/04 15:02:54 visual_prompt]: Epoch 10 / 100: avg data time: 6.70e+00, avg batch time: 8.1499, average train loss: 0.6807
[12/04 15:03:54 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.5873, average loss: 0.6586
[12/04 15:03:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 65.20	
[12/04 15:03:54 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.05
[12/04 15:12:45 visual_prompt]: Epoch 11 / 100: avg data time: 6.14e+00, avg batch time: 7.5898, average train loss: 0.6923
[12/04 15:13:46 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.5851, average loss: 0.8105
[12/04 15:13:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 65.61	
[12/04 15:13:46 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0499847706754774
[12/04 15:22:07 visual_prompt]: Epoch 12 / 100: avg data time: 5.70e+00, avg batch time: 7.1542, average train loss: 0.6918
[12/04 15:23:05 visual_prompt]: Inference (val):avg data time: 3.78e-05, avg batch time: 0.5896, average loss: 0.7250
[12/04 15:23:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 52.44	rocauc: 65.50	
[12/04 15:23:05 visual_prompt]: Best epoch 12: best metric: -0.725
[12/04 15:23:05 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.04993910125649561
[12/04 15:31:29 visual_prompt]: Epoch 13 / 100: avg data time: 5.74e+00, avg batch time: 7.2006, average train loss: 0.6972
[12/04 15:32:27 visual_prompt]: Inference (val):avg data time: 3.46e-05, avg batch time: 0.5873, average loss: 0.6751
[12/04 15:32:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 64.41	
[12/04 15:32:27 visual_prompt]: Best epoch 13: best metric: -0.675
[12/04 15:32:27 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.049863047384206834
[12/04 15:40:50 visual_prompt]: Epoch 14 / 100: avg data time: 5.74e+00, avg batch time: 7.1899, average train loss: 0.6911
[12/04 15:41:47 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.5895, average loss: 0.6561
[12/04 15:41:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 64.65	
[12/04 15:41:47 visual_prompt]: Best epoch 14: best metric: -0.656
[12/04 15:41:47 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.04975670171853926
[12/04 15:50:18 visual_prompt]: Epoch 15 / 100: avg data time: 5.84e+00, avg batch time: 7.2922, average train loss: 0.6706
[12/04 15:51:18 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.5864, average loss: 0.6711
[12/04 15:51:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 64.49	
[12/04 15:51:18 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.049620193825305206
[12/04 16:00:08 visual_prompt]: Epoch 16 / 100: avg data time: 6.12e+00, avg batch time: 7.5782, average train loss: 0.6559
[12/04 16:01:08 visual_prompt]: Inference (val):avg data time: 3.43e-05, avg batch time: 0.5849, average loss: 0.7662
[12/04 16:01:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 66.72	
[12/04 16:01:08 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.049453690018345146
[12/04 16:09:52 visual_prompt]: Epoch 17 / 100: avg data time: 6.03e+00, avg batch time: 7.4877, average train loss: 0.6630
[12/04 16:10:50 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.5889, average loss: 0.6724
[12/04 16:10:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 68.13	
[12/04 16:10:50 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.04925739315689991
[12/04 16:19:20 visual_prompt]: Epoch 18 / 100: avg data time: 5.84e+00, avg batch time: 7.2905, average train loss: 0.6605
[12/04 16:20:20 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.5862, average loss: 1.0637
[12/04 16:20:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 68.67	
[12/04 16:20:20 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.04903154239845797
[12/04 16:29:24 visual_prompt]: Epoch 19 / 100: avg data time: 6.31e+00, avg batch time: 7.7636, average train loss: 0.6713
[12/04 16:30:28 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.5856, average loss: 0.7874
[12/04 16:30:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 67.81	
[12/04 16:30:28 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.048776412907378844
[12/04 16:39:39 visual_prompt]: Epoch 20 / 100: avg data time: 6.43e+00, avg batch time: 7.8770, average train loss: 0.6501
[12/04 16:40:39 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.5886, average loss: 0.7581
[12/04 16:40:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 52.44	rocauc: 68.52	
[12/04 16:40:39 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.048492315519647715
[12/04 16:49:22 visual_prompt]: Epoch 21 / 100: avg data time: 6.01e+00, avg batch time: 7.4682, average train loss: 0.6566
[12/04 16:50:21 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.5881, average loss: 0.6609
[12/04 16:50:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 68.76	
[12/04 16:50:21 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.048179596364169686
[12/04 16:58:44 visual_prompt]: Epoch 22 / 100: avg data time: 5.74e+00, avg batch time: 7.1904, average train loss: 0.6297
[12/04 16:59:44 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.5890, average loss: 0.6419
[12/04 16:59:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.01	rocauc: 69.03	
[12/04 16:59:44 visual_prompt]: Best epoch 22: best metric: -0.642
[12/04 16:59:44 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.04783863644106502
[12/04 17:08:18 visual_prompt]: Epoch 23 / 100: avg data time: 5.88e+00, avg batch time: 7.3323, average train loss: 0.6311
[12/04 17:09:15 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.5895, average loss: 0.6729
[12/04 17:09:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 69.72	
[12/04 17:09:15 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.047469851157479176
[12/04 17:17:37 visual_prompt]: Epoch 24 / 100: avg data time: 5.72e+00, avg batch time: 7.1696, average train loss: 0.6284
[12/04 17:18:34 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.5868, average loss: 0.6512
[12/04 17:18:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 67.25	
[12/04 17:18:34 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.047073689821473176
[12/04 17:26:56 visual_prompt]: Epoch 25 / 100: avg data time: 5.72e+00, avg batch time: 7.1750, average train loss: 0.6217
[12/04 17:27:53 visual_prompt]: Inference (val):avg data time: 3.84e-05, avg batch time: 0.5914, average loss: 0.6718
[12/04 17:27:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 69.16	
[12/04 17:27:53 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.046650635094610975
[12/04 17:36:16 visual_prompt]: Epoch 26 / 100: avg data time: 5.72e+00, avg batch time: 7.1769, average train loss: 0.6380
[12/04 17:37:13 visual_prompt]: Inference (val):avg data time: 4.17e-05, avg batch time: 0.5889, average loss: 0.6347
[12/04 17:37:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 70.25	
[12/04 17:37:13 visual_prompt]: Best epoch 26: best metric: -0.635
[12/04 17:37:13 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.04620120240391065
[12/04 17:45:40 visual_prompt]: Epoch 27 / 100: avg data time: 5.78e+00, avg batch time: 7.2344, average train loss: 0.6137
[12/04 17:46:38 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.5839, average loss: 0.6418
[12/04 17:46:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 69.54	
[12/04 17:46:38 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.04572593931387604
[12/04 17:58:18 visual_prompt]: Epoch 28 / 100: avg data time: 8.55e+00, avg batch time: 9.9995, average train loss: 0.6274
[12/04 17:59:45 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.5889, average loss: 0.6696
[12/04 17:59:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 67.59	
[12/04 17:59:45 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.04522542485937369
[12/04 18:08:22 visual_prompt]: Epoch 29 / 100: avg data time: 5.92e+00, avg batch time: 7.3696, average train loss: 0.6088
[12/04 18:09:19 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.5876, average loss: 0.6306
[12/04 18:09:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 70.44	
[12/04 18:09:19 visual_prompt]: Best epoch 29: best metric: -0.631
[12/04 18:09:19 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.04470026884016805
[12/04 18:17:43 visual_prompt]: Epoch 30 / 100: avg data time: 5.74e+00, avg batch time: 7.1920, average train loss: 0.6092
[12/04 18:18:41 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.5904, average loss: 0.7062
[12/04 18:18:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 69.40	
[12/04 18:18:41 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.04415111107797445
[12/04 18:27:07 visual_prompt]: Epoch 31 / 100: avg data time: 5.77e+00, avg batch time: 7.2281, average train loss: 0.5999
[12/04 18:28:06 visual_prompt]: Inference (val):avg data time: 5.37e-05, avg batch time: 0.5928, average loss: 0.6650
[12/04 18:28:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 69.49	
[12/04 18:28:06 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.04357862063693486
[12/04 18:36:29 visual_prompt]: Epoch 32 / 100: avg data time: 5.73e+00, avg batch time: 7.1865, average train loss: 0.5929
[12/04 18:37:27 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.5906, average loss: 0.6516
[12/04 18:37:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 67.03	
[12/04 18:37:27 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.04298349500846628
[12/04 18:45:48 visual_prompt]: Epoch 33 / 100: avg data time: 5.70e+00, avg batch time: 7.1554, average train loss: 0.5790
[12/04 18:46:45 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.5877, average loss: 0.6460
[12/04 18:46:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 68.78	
[12/04 18:46:45 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.042366459261474934
[12/04 18:55:11 visual_prompt]: Epoch 34 / 100: avg data time: 5.78e+00, avg batch time: 7.2289, average train loss: 0.5761
[12/04 18:56:10 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.5907, average loss: 0.7361
[12/04 18:56:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 68.03	
[12/04 18:56:10 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.04172826515897146
[12/04 19:04:48 visual_prompt]: Epoch 35 / 100: avg data time: 5.95e+00, avg batch time: 7.4031, average train loss: 0.6047
[12/04 19:05:47 visual_prompt]: Inference (val):avg data time: 3.60e-05, avg batch time: 0.5874, average loss: 0.7291
[12/04 19:05:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 66.20	
[12/04 19:05:47 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.04106969024216348
[12/04 19:14:21 visual_prompt]: Epoch 36 / 100: avg data time: 5.89e+00, avg batch time: 7.3445, average train loss: 0.5773
[12/04 19:15:19 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.5899, average loss: 0.6869
[12/04 19:15:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 67.75	
[12/04 19:15:19 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.040391536883141455
[12/04 19:23:43 visual_prompt]: Epoch 37 / 100: avg data time: 5.75e+00, avg batch time: 7.2015, average train loss: 0.5445
[12/04 19:24:41 visual_prompt]: Inference (val):avg data time: 3.63e-05, avg batch time: 0.5903, average loss: 0.6399
[12/04 19:24:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.89	rocauc: 71.12	
[12/04 19:24:41 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.03969463130731183
[12/04 19:33:05 visual_prompt]: Epoch 38 / 100: avg data time: 5.75e+00, avg batch time: 7.1990, average train loss: 0.5441
[12/04 19:34:02 visual_prompt]: Inference (val):avg data time: 4.02e-05, avg batch time: 0.5848, average loss: 0.6602
[12/04 19:34:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.89	rocauc: 69.34	
[12/04 19:34:02 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.03897982258676867
[12/04 19:42:24 visual_prompt]: Epoch 39 / 100: avg data time: 5.72e+00, avg batch time: 7.1697, average train loss: 0.5625
[12/04 19:43:21 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.5871, average loss: 0.7640
[12/04 19:43:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 68.06	
[12/04 19:43:21 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.03824798160583012
[12/04 19:51:42 visual_prompt]: Epoch 40 / 100: avg data time: 5.69e+00, avg batch time: 7.1452, average train loss: 0.5447
[12/04 19:52:39 visual_prompt]: Inference (val):avg data time: 3.45e-05, avg batch time: 0.5881, average loss: 0.6610
[12/04 19:52:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 68.43	
[12/04 19:52:39 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.037500000000000006
[12/04 20:00:59 visual_prompt]: Epoch 41 / 100: avg data time: 5.70e+00, avg batch time: 7.1515, average train loss: 0.5229
[12/04 20:01:56 visual_prompt]: Inference (val):avg data time: 4.74e-05, avg batch time: 0.5891, average loss: 0.7517
[12/04 20:01:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 67.97	
[12/04 20:01:56 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.03673678906964727
[12/04 20:10:16 visual_prompt]: Epoch 42 / 100: avg data time: 5.68e+00, avg batch time: 7.1376, average train loss: 0.5255
[12/04 20:11:13 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.5907, average loss: 0.7114
[12/04 20:11:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 68.27	
[12/04 20:11:13 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.03595927866972694
[12/04 20:19:35 visual_prompt]: Epoch 43 / 100: avg data time: 5.72e+00, avg batch time: 7.1708, average train loss: 0.5436
[12/04 20:20:32 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.5887, average loss: 0.6570
[12/04 20:20:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 68.37	
[12/04 20:20:32 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.03516841607689501
[12/04 20:28:54 visual_prompt]: Epoch 44 / 100: avg data time: 5.72e+00, avg batch time: 7.1693, average train loss: 0.5338
[12/04 20:29:51 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.5857, average loss: 0.7001
[12/04 20:29:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 67.63	
[12/04 20:29:51 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.0343651648353978
[12/04 20:38:11 visual_prompt]: Epoch 45 / 100: avg data time: 5.69e+00, avg batch time: 7.1440, average train loss: 0.5160
[12/04 20:39:08 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.5915, average loss: 0.7002
[12/04 20:39:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 68.57	
[12/04 20:39:08 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.033550503583141725
[12/04 20:47:29 visual_prompt]: Epoch 46 / 100: avg data time: 5.70e+00, avg batch time: 7.1569, average train loss: 0.5011
[12/04 20:48:27 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.5882, average loss: 0.8003
[12/04 20:48:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 69.24	
[12/04 20:48:27 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.032725424859373686
[12/04 20:56:47 visual_prompt]: Epoch 47 / 100: avg data time: 5.70e+00, avg batch time: 7.1488, average train loss: 0.5061
[12/04 20:57:44 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.5862, average loss: 0.7556
[12/04 20:57:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 66.35	
[12/04 20:57:44 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.03189093389542498
[12/04 21:06:04 visual_prompt]: Epoch 48 / 100: avg data time: 5.68e+00, avg batch time: 7.1312, average train loss: 0.4753
[12/04 21:07:01 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.5857, average loss: 0.7033
[12/04 21:07:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 65.63	
[12/04 21:07:01 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.03104804738999169
[12/04 21:15:22 visual_prompt]: Epoch 49 / 100: avg data time: 5.71e+00, avg batch time: 7.1546, average train loss: 0.4537
[12/04 21:16:19 visual_prompt]: Inference (val):avg data time: 3.54e-05, avg batch time: 0.5878, average loss: 0.7161
[12/04 21:16:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 66.55	
[12/04 21:16:19 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.03019779227044398
[12/04 21:24:40 visual_prompt]: Epoch 50 / 100: avg data time: 5.70e+00, avg batch time: 7.1550, average train loss: 0.5150
[12/04 21:25:38 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.5869, average loss: 0.7739
[12/04 21:25:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 68.92	
[12/04 21:25:38 visual_prompt]: Stopping early.
[12/04 21:25:38 visual_prompt]: Rank of current process: 0. World size: 1
[12/04 21:25:38 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[12/04 21:25:38 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[12/04 21:25:38 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[12/04 21:25:38 visual_prompt]: Training with config:
[12/04 21:25:38 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr0.05_wd0.0/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.05, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[12/04 21:25:38 visual_prompt]: Loading training data...
[12/04 21:25:38 visual_prompt]: Constructing mammo-cbis dataset train...
[12/04 21:25:38 visual_prompt]: Loading validation data...
[12/04 21:25:38 visual_prompt]: Constructing mammo-cbis dataset val...
[12/04 21:25:38 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[12/04 21:25:43 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[12/04 21:25:43 visual_prompt]: tuned percent:0.532
[12/04 21:25:43 visual_prompt]: Device used for model: 0
[12/04 21:25:43 visual_prompt]: Setting up Evaluator...
[12/04 21:25:43 visual_prompt]: Setting up Trainer...
[12/04 21:25:43 visual_prompt]: 	Setting up the optimizer...
[12/04 21:25:43 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[12/04 21:34:07 visual_prompt]: Epoch 1 / 100: avg data time: 5.73e+00, avg batch time: 7.1861, average train loss: 1.4863
[12/04 21:35:05 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.5870, average loss: 1.4553
[12/04 21:35:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[12/04 21:35:05 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.005000000000000001
[12/04 21:43:28 visual_prompt]: Epoch 2 / 100: avg data time: 5.74e+00, avg batch time: 7.1897, average train loss: 0.8432
[12/04 21:44:27 visual_prompt]: Inference (val):avg data time: 5.50e-05, avg batch time: 0.5856, average loss: 0.6853
[12/04 21:44:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 53.16	
[12/04 21:44:27 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.010000000000000002
[12/04 21:52:53 visual_prompt]: Epoch 3 / 100: avg data time: 5.79e+00, avg batch time: 7.2391, average train loss: 0.7078
[12/04 21:53:51 visual_prompt]: Inference (val):avg data time: 5.11e-05, avg batch time: 0.5872, average loss: 0.7530
[12/04 21:53:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.84	
[12/04 21:53:51 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.015
[12/04 22:02:15 visual_prompt]: Epoch 4 / 100: avg data time: 5.73e+00, avg batch time: 7.1904, average train loss: 0.7225
[12/04 22:03:12 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.5850, average loss: 0.7051
[12/04 22:03:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.60	
[12/04 22:03:12 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.020000000000000004
[12/04 22:11:32 visual_prompt]: Epoch 5 / 100: avg data time: 5.69e+00, avg batch time: 7.1410, average train loss: 0.7267
[12/04 22:12:30 visual_prompt]: Inference (val):avg data time: 4.93e-05, avg batch time: 0.5851, average loss: 0.6773
[12/04 22:12:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 60.93	
[12/04 22:12:30 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.025
[12/04 22:20:53 visual_prompt]: Epoch 6 / 100: avg data time: 5.73e+00, avg batch time: 7.1811, average train loss: 0.7297
[12/04 22:21:50 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.5896, average loss: 0.7267
[12/04 22:21:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.22	
[12/04 22:21:50 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.03
[12/04 22:30:11 visual_prompt]: Epoch 7 / 100: avg data time: 5.70e+00, avg batch time: 7.1529, average train loss: 0.6895
[12/04 22:31:08 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.5844, average loss: 1.0738
[12/04 22:31:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.76	
[12/04 22:31:08 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.034999999999999996
[12/04 22:39:29 visual_prompt]: Epoch 8 / 100: avg data time: 5.70e+00, avg batch time: 7.1524, average train loss: 0.7385
[12/04 22:40:26 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.5871, average loss: 0.6748
[12/04 22:40:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 62.05	
[12/04 22:40:26 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.04000000000000001
[12/04 22:48:48 visual_prompt]: Epoch 9 / 100: avg data time: 5.72e+00, avg batch time: 7.1694, average train loss: 0.7085
[12/04 22:49:46 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.5858, average loss: 0.6724
[12/04 22:49:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 63.93	
[12/04 22:49:46 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.045000000000000005
[12/04 22:58:05 visual_prompt]: Epoch 10 / 100: avg data time: 5.68e+00, avg batch time: 7.1291, average train loss: 0.6812
[12/04 22:59:03 visual_prompt]: Inference (val):avg data time: 4.04e-05, avg batch time: 0.5886, average loss: 0.6603
[12/04 22:59:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 65.03	
[12/04 22:59:03 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.05
[12/04 23:07:39 visual_prompt]: Epoch 11 / 100: avg data time: 5.91e+00, avg batch time: 7.3610, average train loss: 0.6882
[12/04 23:08:38 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.5872, average loss: 0.7809
[12/04 23:08:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 65.30	
[12/04 23:08:38 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0499847706754774
[12/04 23:17:13 visual_prompt]: Epoch 12 / 100: avg data time: 5.90e+00, avg batch time: 7.3518, average train loss: 0.6901
[12/04 23:18:11 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.5866, average loss: 0.7514
[12/04 23:18:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 50.41	rocauc: 65.45	
[12/04 23:18:11 visual_prompt]: Best epoch 12: best metric: -0.751
[12/04 23:18:11 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.04993910125649561
[12/04 23:26:39 visual_prompt]: Epoch 13 / 100: avg data time: 5.80e+00, avg batch time: 7.2468, average train loss: 0.6934
[12/04 23:27:37 visual_prompt]: Inference (val):avg data time: 4.05e-05, avg batch time: 0.5874, average loss: 0.6889
[12/04 23:27:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 65.23	
[12/04 23:27:37 visual_prompt]: Best epoch 13: best metric: -0.689
[12/04 23:27:37 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.049863047384206834
[12/04 23:35:56 visual_prompt]: Epoch 14 / 100: avg data time: 5.68e+00, avg batch time: 7.1348, average train loss: 0.6939
[12/04 23:36:54 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.5862, average loss: 0.6556
[12/04 23:36:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 64.74	
[12/04 23:36:54 visual_prompt]: Best epoch 14: best metric: -0.656
[12/04 23:36:54 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.04975670171853926
[12/04 23:45:17 visual_prompt]: Epoch 15 / 100: avg data time: 5.73e+00, avg batch time: 7.1817, average train loss: 0.6700
[12/04 23:46:14 visual_prompt]: Inference (val):avg data time: 3.47e-05, avg batch time: 0.5984, average loss: 0.6707
[12/04 23:46:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 63.61	
[12/04 23:46:14 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.049620193825305206
[12/04 23:54:38 visual_prompt]: Epoch 16 / 100: avg data time: 5.75e+00, avg batch time: 7.2031, average train loss: 0.6586
[12/04 23:55:35 visual_prompt]: Inference (val):avg data time: 3.86e-05, avg batch time: 0.5890, average loss: 0.7681
[12/04 23:55:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 67.02	
[12/04 23:55:35 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.049453690018345146
[12/05 00:03:56 visual_prompt]: Epoch 17 / 100: avg data time: 5.70e+00, avg batch time: 7.1565, average train loss: 0.6625
[12/05 00:04:54 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.5834, average loss: 0.6725
[12/05 00:04:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.54	rocauc: 67.48	
[12/05 00:04:54 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.04925739315689991
[12/05 00:13:15 visual_prompt]: Epoch 18 / 100: avg data time: 5.70e+00, avg batch time: 7.1507, average train loss: 0.6607
[12/05 00:14:13 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.5827, average loss: 1.0596
[12/05 00:14:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.47	rocauc: 68.26	
[12/05 00:14:13 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.04903154239845797
[12/05 00:22:34 visual_prompt]: Epoch 19 / 100: avg data time: 5.70e+00, avg batch time: 7.1554, average train loss: 0.6714
[12/05 00:23:32 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.5863, average loss: 0.7832
[12/05 00:23:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 67.68	
[12/05 00:23:32 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.048776412907378844
[12/05 00:31:55 visual_prompt]: Epoch 20 / 100: avg data time: 5.73e+00, avg batch time: 7.1839, average train loss: 0.6487
[12/05 00:32:53 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.5843, average loss: 0.7532
[12/05 00:32:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 52.03	rocauc: 69.13	
[12/05 00:32:53 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.048492315519647715
[12/05 00:41:19 visual_prompt]: Epoch 21 / 100: avg data time: 5.78e+00, avg batch time: 7.2334, average train loss: 0.6566
[12/05 00:42:17 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.5854, average loss: 0.6650
[12/05 00:42:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 68.57	
[12/05 00:42:17 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.048179596364169686
[12/05 00:50:38 visual_prompt]: Epoch 22 / 100: avg data time: 5.71e+00, avg batch time: 7.1575, average train loss: 0.6296
[12/05 00:51:36 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.5886, average loss: 0.6475
[12/05 00:51:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 68.04	
[12/05 00:51:36 visual_prompt]: Best epoch 22: best metric: -0.648
[12/05 00:51:36 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.04783863644106502
[12/05 01:00:00 visual_prompt]: Epoch 23 / 100: avg data time: 5.75e+00, avg batch time: 7.2011, average train loss: 0.6316
[12/05 01:00:58 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.5885, average loss: 0.6820
[12/05 01:00:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 68.50	
[12/05 01:00:58 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.047469851157479176
[12/05 01:09:19 visual_prompt]: Epoch 24 / 100: avg data time: 5.70e+00, avg batch time: 7.1545, average train loss: 0.6271
[12/05 01:10:43 visual_prompt]: Inference (val):avg data time: 4.06e-05, avg batch time: 0.5874, average loss: 0.6606
[12/05 01:10:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 66.80	
[12/05 01:10:43 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.047073689821473176
[12/05 01:26:35 visual_prompt]: Epoch 25 / 100: avg data time: 1.21e+01, avg batch time: 13.5929, average train loss: 0.6238
[12/05 01:27:42 visual_prompt]: Inference (val):avg data time: 4.68e-05, avg batch time: 0.5874, average loss: 0.6906
[12/05 01:27:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 68.54	
[12/05 01:27:42 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.046650635094610975
[12/05 01:36:04 visual_prompt]: Epoch 26 / 100: avg data time: 5.71e+00, avg batch time: 7.1659, average train loss: 0.6513
[12/05 01:37:02 visual_prompt]: Inference (val):avg data time: 4.22e-05, avg batch time: 0.5866, average loss: 0.6421
[12/05 01:37:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 68.50	
[12/05 01:37:02 visual_prompt]: Best epoch 26: best metric: -0.642
[12/05 01:37:02 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.04620120240391065
[12/05 01:45:23 visual_prompt]: Epoch 27 / 100: avg data time: 5.70e+00, avg batch time: 7.1520, average train loss: 0.6194
[12/05 01:46:20 visual_prompt]: Inference (val):avg data time: 4.67e-05, avg batch time: 0.5899, average loss: 0.6408
[12/05 01:46:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 68.59	
[12/05 01:46:20 visual_prompt]: Best epoch 27: best metric: -0.641
[12/05 01:46:20 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.04572593931387604
[12/05 01:54:43 visual_prompt]: Epoch 28 / 100: avg data time: 5.72e+00, avg batch time: 7.1750, average train loss: 0.6269
[12/05 01:55:40 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.5881, average loss: 0.6471
[12/05 01:55:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 68.85	
[12/05 01:55:40 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.04522542485937369
[12/05 02:04:38 visual_prompt]: Epoch 29 / 100: avg data time: 6.23e+00, avg batch time: 7.6810, average train loss: 0.6018
[12/05 02:05:39 visual_prompt]: Inference (val):avg data time: 3.54e-05, avg batch time: 0.5850, average loss: 0.6456
[12/05 02:05:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 70.18	
[12/05 02:05:39 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.04470026884016805
[12/05 02:14:32 visual_prompt]: Epoch 30 / 100: avg data time: 6.15e+00, avg batch time: 7.6046, average train loss: 0.6280
[12/05 02:15:31 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.5847, average loss: 0.6589
[12/05 02:15:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.89	rocauc: 69.73	
[12/05 02:15:31 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.04415111107797445
[12/05 02:23:48 visual_prompt]: Epoch 31 / 100: avg data time: 5.65e+00, avg batch time: 7.1011, average train loss: 0.6087
[12/05 02:24:46 visual_prompt]: Inference (val):avg data time: 3.55e-05, avg batch time: 0.5858, average loss: 0.6833
[12/05 02:24:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 69.21	
[12/05 02:24:46 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.04357862063693486
[12/05 02:33:08 visual_prompt]: Epoch 32 / 100: avg data time: 5.71e+00, avg batch time: 7.1669, average train loss: 0.6043
[12/05 02:34:06 visual_prompt]: Inference (val):avg data time: 4.01e-05, avg batch time: 0.5910, average loss: 0.6363
[12/05 02:34:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 69.62	
[12/05 02:34:06 visual_prompt]: Best epoch 32: best metric: -0.636
[12/05 02:34:06 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.04298349500846628
[12/05 02:42:27 visual_prompt]: Epoch 33 / 100: avg data time: 5.70e+00, avg batch time: 7.1666, average train loss: 0.5774
[12/05 02:43:25 visual_prompt]: Inference (val):avg data time: 4.02e-05, avg batch time: 0.5987, average loss: 0.6667
[12/05 02:43:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.01	rocauc: 68.45	
[12/05 02:43:25 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.042366459261474934
[12/05 02:51:50 visual_prompt]: Epoch 34 / 100: avg data time: 5.73e+00, avg batch time: 7.2039, average train loss: 0.5808
[12/05 02:52:48 visual_prompt]: Inference (val):avg data time: 3.55e-05, avg batch time: 0.5944, average loss: 0.7417
[12/05 02:52:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 65.59	
[12/05 02:52:48 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.04172826515897146
[12/05 03:01:12 visual_prompt]: Epoch 35 / 100: avg data time: 5.72e+00, avg batch time: 7.2021, average train loss: 0.5970
[12/05 03:02:10 visual_prompt]: Inference (val):avg data time: 3.97e-05, avg batch time: 0.6001, average loss: 0.7648
[12/05 03:02:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 65.57	
[12/05 03:02:10 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.04106969024216348
[12/05 03:10:33 visual_prompt]: Epoch 36 / 100: avg data time: 5.71e+00, avg batch time: 7.1827, average train loss: 0.5903
[12/05 03:11:30 visual_prompt]: Inference (val):avg data time: 4.32e-05, avg batch time: 0.5927, average loss: 0.6946
[12/05 03:11:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 67.53	
[12/05 03:11:30 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.040391536883141455
[12/05 03:19:51 visual_prompt]: Epoch 37 / 100: avg data time: 5.70e+00, avg batch time: 7.1537, average train loss: 0.5536
[12/05 03:20:52 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.5891, average loss: 0.6790
[12/05 03:20:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 69.39	
[12/05 03:20:52 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.03969463130731183
[12/05 03:29:14 visual_prompt]: Epoch 38 / 100: avg data time: 5.73e+00, avg batch time: 7.1755, average train loss: 0.5459
[12/05 03:30:11 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.5883, average loss: 0.6606
[12/05 03:30:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 67.44	
[12/05 03:30:11 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.03897982258676867
[12/05 03:38:33 visual_prompt]: Epoch 39 / 100: avg data time: 5.71e+00, avg batch time: 7.1613, average train loss: 0.5585
[12/05 03:39:30 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.5906, average loss: 0.7769
[12/05 03:39:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 67.85	
[12/05 03:39:30 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.03824798160583012
[12/05 03:47:53 visual_prompt]: Epoch 40 / 100: avg data time: 5.72e+00, avg batch time: 7.1753, average train loss: 0.5547
[12/05 03:48:50 visual_prompt]: Inference (val):avg data time: 3.84e-05, avg batch time: 0.5867, average loss: 0.6710
[12/05 03:48:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 68.24	
[12/05 03:48:50 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.037500000000000006
[12/05 03:57:12 visual_prompt]: Epoch 41 / 100: avg data time: 5.72e+00, avg batch time: 7.1737, average train loss: 0.5301
[12/05 03:58:10 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.5922, average loss: 0.7916
[12/05 03:58:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 67.70	
[12/05 03:58:10 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.03673678906964727
[12/05 04:06:33 visual_prompt]: Epoch 42 / 100: avg data time: 5.72e+00, avg batch time: 7.1743, average train loss: 0.5373
[12/05 04:07:30 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.5924, average loss: 0.6978
[12/05 04:07:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 67.96	
[12/05 04:07:30 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.03595927866972694
[12/05 04:15:53 visual_prompt]: Epoch 43 / 100: avg data time: 5.72e+00, avg batch time: 7.1744, average train loss: 0.5485
[12/05 04:16:50 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.5908, average loss: 0.6925
[12/05 04:16:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 68.48	
[12/05 04:16:50 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.03516841607689501
[12/05 04:25:16 visual_prompt]: Epoch 44 / 100: avg data time: 5.77e+00, avg batch time: 7.2256, average train loss: 0.5330
[12/05 04:26:12 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.5877, average loss: 0.6939
[12/05 04:26:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 69.14	
[12/05 04:26:12 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.0343651648353978
[12/05 04:34:38 visual_prompt]: Epoch 45 / 100: avg data time: 5.76e+00, avg batch time: 7.2192, average train loss: 0.5118
[12/05 04:35:34 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.5908, average loss: 0.7227
[12/05 04:35:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 67.63	
[12/05 04:35:34 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.033550503583141725
[12/05 04:43:58 visual_prompt]: Epoch 46 / 100: avg data time: 5.74e+00, avg batch time: 7.1968, average train loss: 0.5233
[12/05 04:44:54 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.5958, average loss: 0.7341
[12/05 04:44:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 69.45	
[12/05 04:44:54 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.032725424859373686
[12/05 04:53:17 visual_prompt]: Epoch 47 / 100: avg data time: 5.73e+00, avg batch time: 7.1815, average train loss: 0.5013
[12/05 04:54:15 visual_prompt]: Inference (val):avg data time: 3.43e-05, avg batch time: 0.5883, average loss: 0.7991
[12/05 04:54:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 66.36	
[12/05 04:54:15 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.03189093389542498
[12/05 05:02:40 visual_prompt]: Epoch 48 / 100: avg data time: 5.75e+00, avg batch time: 7.2099, average train loss: 0.4881
[12/05 05:03:37 visual_prompt]: Inference (val):avg data time: 3.53e-05, avg batch time: 0.5908, average loss: 0.7464
[12/05 05:03:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 66.80	
[12/05 05:03:37 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.03104804738999169
[12/05 05:12:07 visual_prompt]: Epoch 49 / 100: avg data time: 5.80e+00, avg batch time: 7.2689, average train loss: 0.4750
[12/05 05:13:05 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.5963, average loss: 0.7269
[12/05 05:13:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 65.97	
[12/05 05:13:05 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.03019779227044398
[12/05 05:21:28 visual_prompt]: Epoch 50 / 100: avg data time: 5.72e+00, avg batch time: 7.1855, average train loss: 0.5230
[12/05 05:22:26 visual_prompt]: Inference (val):avg data time: 3.67e-05, avg batch time: 0.5895, average loss: 0.7247
[12/05 05:22:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.01	rocauc: 66.78	
[12/05 05:22:26 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.029341204441673263
[12/05 05:30:49 visual_prompt]: Epoch 51 / 100: avg data time: 5.73e+00, avg batch time: 7.1900, average train loss: 0.4704
[12/05 05:31:46 visual_prompt]: Inference (val):avg data time: 4.77e-05, avg batch time: 0.5889, average loss: 0.8625
[12/05 05:31:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 66.20	
[12/05 05:31:46 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.028479327524001636
[12/05 05:40:09 visual_prompt]: Epoch 52 / 100: avg data time: 5.72e+00, avg batch time: 7.1780, average train loss: 0.4406
[12/05 05:41:07 visual_prompt]: Inference (val):avg data time: 3.71e-05, avg batch time: 0.5879, average loss: 0.8174
[12/05 05:41:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 66.80	
[12/05 05:41:07 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.02761321158169134
[12/05 05:49:32 visual_prompt]: Epoch 53 / 100: avg data time: 5.75e+00, avg batch time: 7.2063, average train loss: 0.4854
[12/05 05:50:30 visual_prompt]: Inference (val):avg data time: 4.66e-05, avg batch time: 0.5862, average loss: 0.7524
[12/05 05:50:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 65.08	
[12/05 05:50:30 visual_prompt]: Stopping early.
[12/05 05:51:10 visual_prompt]: Rank of current process: 0. World size: 1
[12/05 05:51:10 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[12/05 05:51:10 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[12/05 05:51:10 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[12/05 05:51:10 visual_prompt]: Training with config:
[12/05 05:51:10 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/test/seed9805/lr0.5_wd0.0001/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 9805, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[12/05 05:51:10 visual_prompt]: Loading training data...
[12/05 05:51:10 visual_prompt]: Constructing mammo-cbis dataset train...
[12/05 05:51:10 visual_prompt]: Loading validation data...
[12/05 05:51:10 visual_prompt]: Constructing mammo-cbis dataset val...
[12/05 05:51:10 visual_prompt]: Loading test data...
[12/05 05:51:10 visual_prompt]: Constructing mammo-cbis dataset test...
[12/05 05:51:10 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[12/05 05:51:15 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[12/05 05:51:15 visual_prompt]: tuned percent:0.532
[12/05 05:51:15 visual_prompt]: Device used for model: 0
[12/05 05:51:15 visual_prompt]: Setting up Evaluator...
[12/05 05:51:15 visual_prompt]: Setting up Trainer...
[12/05 05:51:15 visual_prompt]: 	Setting up the optimizer...
[12/05 05:51:16 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[12/05 05:59:40 visual_prompt]: Epoch 1 / 100: avg data time: 5.75e+00, avg batch time: 7.2002, average train loss: 0.8250
[12/05 06:00:38 visual_prompt]: Inference (val):avg data time: 3.32e-05, avg batch time: 0.5865, average loss: 0.7794
[12/05 06:00:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 47.56	rocauc: 46.51	
[12/05 06:07:21 visual_prompt]: Inference (test):avg data time: 4.17e-05, avg batch time: 0.5839, average loss: 0.7537
[12/05 06:07:21 visual_prompt]: Classification results with test_mammo-cbis: top1: 51.32	rocauc: 48.86	
[12/05 06:07:21 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.05
[12/05 06:15:45 visual_prompt]: Epoch 2 / 100: avg data time: 5.75e+00, avg batch time: 7.2004, average train loss: 0.9774
[12/05 06:16:43 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.5877, average loss: 0.7209
[12/05 06:16:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.10	
[12/05 06:19:08 visual_prompt]: Inference (test):avg data time: 5.29e-05, avg batch time: 0.5872, average loss: 0.6899
[12/05 06:19:08 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 51.01	
[12/05 06:19:08 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.1
[12/05 06:27:31 visual_prompt]: Epoch 3 / 100: avg data time: 5.73e+00, avg batch time: 7.1884, average train loss: 0.7441
[12/05 06:28:29 visual_prompt]: Inference (val):avg data time: 4.02e-05, avg batch time: 0.5902, average loss: 0.7173
[12/05 06:28:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.43	
[12/05 06:30:54 visual_prompt]: Inference (test):avg data time: 4.52e-05, avg batch time: 0.5931, average loss: 0.6864
[12/05 06:30:54 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 53.42	
[12/05 06:30:54 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.15
[12/05 06:39:16 visual_prompt]: Epoch 4 / 100: avg data time: 5.71e+00, avg batch time: 7.1695, average train loss: 0.7249
[12/05 06:40:13 visual_prompt]: Inference (val):avg data time: 3.61e-05, avg batch time: 0.5899, average loss: 0.6915
[12/05 06:40:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 50.81	rocauc: 58.06	
[12/05 06:42:38 visual_prompt]: Inference (test):avg data time: 5.96e-05, avg batch time: 0.5893, average loss: 0.6947
[12/05 06:42:38 visual_prompt]: Classification results with test_mammo-cbis: top1: 49.92	rocauc: 57.33	
[12/05 06:42:38 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.2
[12/05 06:50:58 visual_prompt]: Epoch 5 / 100: avg data time: 5.69e+00, avg batch time: 7.1460, average train loss: 0.7964
[12/05 06:51:56 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.5879, average loss: 1.2192
[12/05 06:51:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.13	
[12/05 06:54:20 visual_prompt]: Inference (test):avg data time: 4.56e-05, avg batch time: 0.5877, average loss: 1.2993
[12/05 06:54:20 visual_prompt]: Classification results with test_mammo-cbis: top1: 40.93	rocauc: 58.49	
[12/05 06:54:20 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.25
[12/05 07:02:41 visual_prompt]: Epoch 6 / 100: avg data time: 5.70e+00, avg batch time: 7.1551, average train loss: 0.7602
[12/05 07:03:38 visual_prompt]: Inference (val):avg data time: 4.08e-05, avg batch time: 0.5943, average loss: 0.7807
[12/05 07:03:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.93	
[12/05 07:06:03 visual_prompt]: Inference (test):avg data time: 4.77e-05, avg batch time: 0.5885, average loss: 0.7301
[12/05 07:06:03 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 61.48	
[12/05 07:06:03 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.3
[12/05 07:14:24 visual_prompt]: Epoch 7 / 100: avg data time: 5.70e+00, avg batch time: 7.1563, average train loss: 0.7618
[12/05 07:15:21 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.5872, average loss: 0.9331
[12/05 07:15:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.68	
[12/05 07:17:45 visual_prompt]: Inference (test):avg data time: 5.32e-05, avg batch time: 0.5860, average loss: 0.8511
[12/05 07:17:45 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 63.68	
[12/05 07:17:45 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.35
[12/05 07:26:07 visual_prompt]: Epoch 8 / 100: avg data time: 5.71e+00, avg batch time: 7.1633, average train loss: 0.7189
[12/05 07:27:05 visual_prompt]: Inference (val):avg data time: 3.32e-05, avg batch time: 0.5905, average loss: 0.6958
[12/05 07:27:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 64.26	
[12/05 07:29:29 visual_prompt]: Inference (test):avg data time: 4.91e-05, avg batch time: 0.5867, average loss: 0.6602
[12/05 07:29:29 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 65.66	
[12/05 07:29:29 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.4
[12/05 07:37:48 visual_prompt]: Epoch 9 / 100: avg data time: 5.66e+00, avg batch time: 7.1266, average train loss: 0.8718
[12/05 07:38:45 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.5948, average loss: 1.0359
[12/05 07:38:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.91	
[12/05 07:41:08 visual_prompt]: Inference (test):avg data time: 4.42e-05, avg batch time: 0.5970, average loss: 0.9322
[12/05 07:41:08 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 64.63	
[12/05 07:41:08 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.45
[12/05 07:49:26 visual_prompt]: Epoch 10 / 100: avg data time: 5.63e+00, avg batch time: 7.1111, average train loss: 0.7353
[12/05 07:50:24 visual_prompt]: Inference (val):avg data time: 4.00e-05, avg batch time: 0.5961, average loss: 0.8782
[12/05 07:50:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 66.22	
[12/05 07:52:48 visual_prompt]: Inference (test):avg data time: 4.60e-05, avg batch time: 0.5970, average loss: 0.9447
[12/05 07:52:48 visual_prompt]: Classification results with test_mammo-cbis: top1: 40.93	rocauc: 65.27	
[12/05 07:52:48 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.5
[12/05 08:01:18 visual_prompt]: Epoch 11 / 100: avg data time: 5.81e+00, avg batch time: 7.2879, average train loss: 0.7750
[12/05 08:02:16 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.5983, average loss: 1.0458
[12/05 08:02:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 66.88	
[12/05 08:04:43 visual_prompt]: Inference (test):avg data time: 6.59e-05, avg batch time: 0.5964, average loss: 0.9362
[12/05 08:04:43 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 65.44	
[12/05 08:04:43 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.49984770675477397
[12/05 08:13:11 visual_prompt]: Epoch 12 / 100: avg data time: 5.78e+00, avg batch time: 7.2582, average train loss: 0.8614
[12/05 08:14:11 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.5990, average loss: 1.9321
[12/05 08:14:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 65.94	
[12/05 08:16:36 visual_prompt]: Inference (test):avg data time: 4.30e-05, avg batch time: 0.5982, average loss: 1.7248
[12/05 08:16:36 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 65.72	
[12/05 08:16:36 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.49939101256495605
[12/05 08:24:58 visual_prompt]: Epoch 13 / 100: avg data time: 5.72e+00, avg batch time: 7.1737, average train loss: 1.0131
[12/05 08:25:55 visual_prompt]: Inference (val):avg data time: 3.50e-05, avg batch time: 0.5878, average loss: 0.6515
[12/05 08:25:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 66.48	
[12/05 08:28:20 visual_prompt]: Inference (test):avg data time: 4.49e-05, avg batch time: 0.5856, average loss: 0.6714
[12/05 08:28:20 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.22	rocauc: 65.74	
[12/05 08:28:20 visual_prompt]: Best epoch 13: best metric: -0.652
[12/05 08:28:20 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.4986304738420683
[12/05 08:36:42 visual_prompt]: Epoch 14 / 100: avg data time: 5.72e+00, avg batch time: 7.1685, average train loss: 0.7749
[12/05 08:37:40 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.5880, average loss: 0.7502
[12/05 08:37:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.47	rocauc: 64.65	
[12/05 08:40:03 visual_prompt]: Inference (test):avg data time: 4.29e-05, avg batch time: 0.5896, average loss: 0.6863
[12/05 08:40:03 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.69	rocauc: 67.47	
[12/05 08:40:03 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.4975670171853926
[12/05 08:48:23 visual_prompt]: Epoch 15 / 100: avg data time: 5.69e+00, avg batch time: 7.1373, average train loss: 0.7276
[12/05 08:49:20 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.5884, average loss: 0.6637
[12/05 08:49:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 68.19	
[12/05 08:51:44 visual_prompt]: Inference (test):avg data time: 5.60e-05, avg batch time: 0.5909, average loss: 0.6384
[12/05 08:51:44 visual_prompt]: Classification results with test_mammo-cbis: top1: 63.10	rocauc: 67.82	
[12/05 08:51:44 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.49620193825305203
[12/05 09:00:09 visual_prompt]: Epoch 16 / 100: avg data time: 5.76e+00, avg batch time: 7.2073, average train loss: 0.6970
[12/05 09:01:09 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.5920, average loss: 0.7224
[12/05 09:01:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 50.81	rocauc: 69.33	
[12/05 09:03:34 visual_prompt]: Inference (test):avg data time: 4.80e-05, avg batch time: 0.5867, average loss: 0.7681
[12/05 09:03:34 visual_prompt]: Classification results with test_mammo-cbis: top1: 48.99	rocauc: 67.77	
[12/05 09:03:34 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.4945369001834514
[12/05 09:11:59 visual_prompt]: Epoch 17 / 100: avg data time: 5.76e+00, avg batch time: 7.2179, average train loss: 0.8144
[12/05 09:12:56 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.5891, average loss: 0.6333
[12/05 09:12:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 70.49	
[12/05 09:15:20 visual_prompt]: Inference (test):avg data time: 4.33e-05, avg batch time: 0.5877, average loss: 0.6662
[12/05 09:15:20 visual_prompt]: Classification results with test_mammo-cbis: top1: 60.62	rocauc: 67.69	
[12/05 09:15:20 visual_prompt]: Best epoch 17: best metric: -0.633
[12/05 09:15:20 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.4925739315689991
[12/05 09:23:46 visual_prompt]: Epoch 18 / 100: avg data time: 5.75e+00, avg batch time: 7.2196, average train loss: 0.7113
[12/05 09:24:45 visual_prompt]: Inference (val):avg data time: 3.70e-05, avg batch time: 0.5938, average loss: 0.8004
[12/05 09:24:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 70.89	
[12/05 09:27:13 visual_prompt]: Inference (test):avg data time: 5.50e-05, avg batch time: 0.5982, average loss: 0.7385
[12/05 09:27:13 visual_prompt]: Classification results with test_mammo-cbis: top1: 61.24	rocauc: 67.64	
[12/05 09:27:13 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.4903154239845797
[12/05 09:35:55 visual_prompt]: Epoch 19 / 100: avg data time: 5.97e+00, avg batch time: 7.4555, average train loss: 0.7025
[12/05 09:36:54 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.5967, average loss: 1.0753
[12/05 09:36:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 71.45	
[12/05 09:39:25 visual_prompt]: Inference (test):avg data time: 4.93e-05, avg batch time: 0.5995, average loss: 1.1964
[12/05 09:39:25 visual_prompt]: Classification results with test_mammo-cbis: top1: 40.93	rocauc: 67.88	
[12/05 09:39:25 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.4877641290737884
[12/05 09:48:00 visual_prompt]: Epoch 20 / 100: avg data time: 5.89e+00, avg batch time: 7.3602, average train loss: 0.6991
[12/05 09:48:58 visual_prompt]: Inference (val):avg data time: 3.55e-05, avg batch time: 0.5894, average loss: 0.8120
[12/05 09:48:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 69.22	
[12/05 09:51:28 visual_prompt]: Inference (test):avg data time: 4.96e-05, avg batch time: 0.5863, average loss: 0.9681
[12/05 09:51:28 visual_prompt]: Classification results with test_mammo-cbis: top1: 48.84	rocauc: 62.74	
[12/05 09:51:28 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.4849231551964771
[12/05 10:00:11 visual_prompt]: Epoch 21 / 100: avg data time: 6.01e+00, avg batch time: 7.4642, average train loss: 0.7160
[12/05 10:01:10 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.5855, average loss: 0.8591
[12/05 10:01:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.07	rocauc: 72.52	
[12/05 10:03:42 visual_prompt]: Inference (test):avg data time: 4.75e-05, avg batch time: 0.5847, average loss: 1.0258
[12/05 10:03:42 visual_prompt]: Classification results with test_mammo-cbis: top1: 48.22	rocauc: 66.68	
[12/05 10:03:42 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.48179596364169686
[12/05 10:12:15 visual_prompt]: Epoch 22 / 100: avg data time: 5.87e+00, avg batch time: 7.3257, average train loss: 0.6884
[12/05 10:13:13 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.5871, average loss: 1.2270
[12/05 10:13:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 72.64	
[12/05 10:15:39 visual_prompt]: Inference (test):avg data time: 5.03e-05, avg batch time: 0.5901, average loss: 1.1003
[12/05 10:15:39 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 68.83	
[12/05 10:15:39 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.4783863644106502
[12/05 10:24:06 visual_prompt]: Epoch 23 / 100: avg data time: 5.79e+00, avg batch time: 7.2439, average train loss: 0.7554
[12/05 10:25:06 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.5882, average loss: 0.6246
[12/05 10:25:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.89	rocauc: 72.33	
[12/05 10:27:34 visual_prompt]: Inference (test):avg data time: 3.98e-05, avg batch time: 0.5873, average loss: 0.6630
[12/05 10:27:34 visual_prompt]: Classification results with test_mammo-cbis: top1: 62.95	rocauc: 68.26	
[12/05 10:27:34 visual_prompt]: Best epoch 23: best metric: -0.625
[12/05 10:27:34 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.47469851157479176
[12/05 10:36:10 visual_prompt]: Epoch 24 / 100: avg data time: 5.92e+00, avg batch time: 7.3677, average train loss: 0.7195
[12/05 10:37:07 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.5842, average loss: 1.4001
[12/05 10:37:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 72.03	
[12/05 10:39:32 visual_prompt]: Inference (test):avg data time: 5.04e-05, avg batch time: 0.5877, average loss: 1.2416
[12/05 10:39:32 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 68.82	
[12/05 10:39:32 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.47073689821473175
[12/05 10:48:00 visual_prompt]: Epoch 25 / 100: avg data time: 5.79e+00, avg batch time: 7.2446, average train loss: 0.6623
[12/05 10:49:01 visual_prompt]: Inference (val):avg data time: 4.20e-05, avg batch time: 0.5829, average loss: 0.6204
[12/05 10:49:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 69.92	rocauc: 72.75	
[12/05 10:51:30 visual_prompt]: Inference (test):avg data time: 8.20e-04, avg batch time: 0.5924, average loss: 0.6987
[12/05 10:51:31 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.69	rocauc: 66.10	
[12/05 10:51:31 visual_prompt]: Best epoch 25: best metric: -0.620
[12/05 10:51:31 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.4665063509461097
[12/05 11:00:31 visual_prompt]: Epoch 26 / 100: avg data time: 6.24e+00, avg batch time: 7.7194, average train loss: 0.6331
[12/05 11:01:31 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.5974, average loss: 0.6567
[12/05 11:01:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.89	rocauc: 72.96	
[12/05 11:04:00 visual_prompt]: Inference (test):avg data time: 4.97e-05, avg batch time: 0.6032, average loss: 0.7659
[12/05 11:04:00 visual_prompt]: Classification results with test_mammo-cbis: top1: 55.35	rocauc: 66.06	
[12/05 11:04:00 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.46201202403910646
[12/05 11:12:25 visual_prompt]: Epoch 27 / 100: avg data time: 5.73e+00, avg batch time: 7.2113, average train loss: 0.6448
[12/05 11:13:23 visual_prompt]: Inference (val):avg data time: 4.20e-05, avg batch time: 0.5972, average loss: 0.8789
[12/05 11:13:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 47.97	rocauc: 73.86	
[12/05 11:15:46 visual_prompt]: Inference (test):avg data time: 4.50e-05, avg batch time: 0.5927, average loss: 1.0577
[12/05 11:15:46 visual_prompt]: Classification results with test_mammo-cbis: top1: 45.58	rocauc: 69.30	
[12/05 11:15:46 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.4572593931387604
[12/05 11:24:08 visual_prompt]: Epoch 28 / 100: avg data time: 5.71e+00, avg batch time: 7.1640, average train loss: 0.7218
[12/05 11:25:05 visual_prompt]: Inference (val):avg data time: 3.67e-05, avg batch time: 0.5915, average loss: 1.0084
[12/05 11:25:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.53	rocauc: 74.82	
[12/05 11:27:29 visual_prompt]: Inference (test):avg data time: 4.40e-05, avg batch time: 0.5862, average loss: 1.1844
[12/05 11:27:29 visual_prompt]: Classification results with test_mammo-cbis: top1: 40.93	rocauc: 68.20	
[12/05 11:27:29 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.45225424859373686
[12/05 11:35:52 visual_prompt]: Epoch 29 / 100: avg data time: 5.74e+00, avg batch time: 7.1894, average train loss: 0.6551
[12/05 11:36:49 visual_prompt]: Inference (val):avg data time: 3.85e-05, avg batch time: 0.5870, average loss: 0.7895
[12/05 11:36:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 53.66	rocauc: 74.05	
[12/05 11:39:14 visual_prompt]: Inference (test):avg data time: 5.54e-05, avg batch time: 0.5850, average loss: 0.9161
[12/05 11:39:14 visual_prompt]: Classification results with test_mammo-cbis: top1: 47.60	rocauc: 70.09	
[12/05 11:39:14 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.44700268840168045
[12/05 11:47:40 visual_prompt]: Epoch 30 / 100: avg data time: 5.77e+00, avg batch time: 7.2204, average train loss: 0.6372
[12/05 11:48:37 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.5869, average loss: 0.7617
[12/05 11:48:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.01	rocauc: 75.00	
[12/05 11:51:03 visual_prompt]: Inference (test):avg data time: 4.38e-05, avg batch time: 0.5890, average loss: 0.7246
[12/05 11:51:03 visual_prompt]: Classification results with test_mammo-cbis: top1: 64.65	rocauc: 69.00	
[12/05 11:51:03 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.4415111107797445
[12/05 11:59:26 visual_prompt]: Epoch 31 / 100: avg data time: 5.74e+00, avg batch time: 7.1953, average train loss: 0.6606
[12/05 12:00:23 visual_prompt]: Inference (val):avg data time: 4.17e-05, avg batch time: 0.5879, average loss: 0.9852
[12/05 12:00:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 47.15	rocauc: 74.33	
[12/05 12:02:48 visual_prompt]: Inference (test):avg data time: 4.57e-05, avg batch time: 0.5862, average loss: 1.2083
[12/05 12:02:48 visual_prompt]: Classification results with test_mammo-cbis: top1: 43.41	rocauc: 69.42	
[12/05 12:02:48 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.43578620636934856
[12/05 12:11:12 visual_prompt]: Epoch 32 / 100: avg data time: 5.73e+00, avg batch time: 7.1883, average train loss: 0.6679
[12/05 12:12:09 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.5861, average loss: 0.7623
[12/05 12:12:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 73.79	
[12/05 12:14:34 visual_prompt]: Inference (test):avg data time: 4.91e-05, avg batch time: 0.5913, average loss: 0.7256
[12/05 12:14:34 visual_prompt]: Classification results with test_mammo-cbis: top1: 64.03	rocauc: 67.45	
[12/05 12:14:34 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.42983495008466277
[12/05 12:22:59 visual_prompt]: Epoch 33 / 100: avg data time: 5.75e+00, avg batch time: 7.2007, average train loss: 0.6385
[12/05 12:23:56 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.5898, average loss: 0.7506
[12/05 12:23:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 74.51	
[12/05 12:26:23 visual_prompt]: Inference (test):avg data time: 5.82e-05, avg batch time: 0.5924, average loss: 0.8651
[12/05 12:26:23 visual_prompt]: Classification results with test_mammo-cbis: top1: 49.77	rocauc: 69.42	
[12/05 12:26:23 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.4236645926147493
[12/05 12:34:51 visual_prompt]: Epoch 34 / 100: avg data time: 5.78e+00, avg batch time: 7.2549, average train loss: 0.6321
[12/05 12:35:50 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.5976, average loss: 0.6775
[12/05 12:35:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 76.43	
[12/05 12:38:16 visual_prompt]: Inference (test):avg data time: 4.90e-05, avg batch time: 0.5922, average loss: 0.6526
[12/05 12:38:16 visual_prompt]: Classification results with test_mammo-cbis: top1: 66.36	rocauc: 70.54	
[12/05 12:38:16 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.41728265158971456
[12/05 12:46:51 visual_prompt]: Epoch 35 / 100: avg data time: 5.90e+00, avg batch time: 7.3582, average train loss: 0.6011
[12/05 12:47:51 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.5875, average loss: 0.6713
[12/05 12:47:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 69.51	rocauc: 75.66	
[12/05 12:50:18 visual_prompt]: Inference (test):avg data time: 4.98e-05, avg batch time: 0.5873, average loss: 0.8215
[12/05 12:50:18 visual_prompt]: Classification results with test_mammo-cbis: top1: 58.29	rocauc: 69.80	
[12/05 12:50:18 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.4106969024216348
[12/05 12:58:43 visual_prompt]: Epoch 36 / 100: avg data time: 5.76e+00, avg batch time: 7.2097, average train loss: 0.6113
[12/05 12:59:42 visual_prompt]: Inference (val):avg data time: 3.90e-05, avg batch time: 0.5909, average loss: 0.6006
[12/05 12:59:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 75.78	
[12/05 13:02:06 visual_prompt]: Inference (test):avg data time: 3.70e-05, avg batch time: 0.5899, average loss: 0.6777
[12/05 13:02:06 visual_prompt]: Classification results with test_mammo-cbis: top1: 64.34	rocauc: 71.65	
[12/05 13:02:06 visual_prompt]: Best epoch 36: best metric: -0.601
[12/05 13:02:06 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.40391536883141455
[12/05 13:10:33 visual_prompt]: Epoch 37 / 100: avg data time: 5.79e+00, avg batch time: 7.2433, average train loss: 0.5921
[12/05 13:11:32 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.5901, average loss: 0.6213
[12/05 13:11:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 75.82	
[12/05 13:13:57 visual_prompt]: Inference (test):avg data time: 5.25e-05, avg batch time: 0.5874, average loss: 0.6904
[12/05 13:13:57 visual_prompt]: Classification results with test_mammo-cbis: top1: 64.81	rocauc: 68.05	
[12/05 13:13:57 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.3969463130731183
[12/05 13:22:24 visual_prompt]: Epoch 38 / 100: avg data time: 5.77e+00, avg batch time: 7.2292, average train loss: 0.5878
[12/05 13:23:22 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.5871, average loss: 0.6014
[12/05 13:23:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 69.92	rocauc: 75.32	
[12/05 13:25:47 visual_prompt]: Inference (test):avg data time: 5.05e-05, avg batch time: 0.5903, average loss: 0.6472
[12/05 13:25:47 visual_prompt]: Classification results with test_mammo-cbis: top1: 64.50	rocauc: 71.05	
[12/05 13:25:47 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.3897982258676867
[12/05 13:34:22 visual_prompt]: Epoch 39 / 100: avg data time: 5.90e+00, avg batch time: 7.3545, average train loss: 0.5674
[12/05 13:35:20 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.5875, average loss: 0.6957
[12/05 13:35:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 73.97	
[12/05 13:37:47 visual_prompt]: Inference (test):avg data time: 4.23e-05, avg batch time: 0.5909, average loss: 0.6687
[12/05 13:37:47 visual_prompt]: Classification results with test_mammo-cbis: top1: 64.65	rocauc: 69.29	
[12/05 13:37:47 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.3824798160583012
[12/05 13:46:14 visual_prompt]: Epoch 40 / 100: avg data time: 5.78e+00, avg batch time: 7.2369, average train loss: 0.5623
[12/05 13:47:14 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.5865, average loss: 0.6534
[12/05 13:47:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 74.47	
[12/05 13:49:42 visual_prompt]: Inference (test):avg data time: 3.92e-05, avg batch time: 0.5887, average loss: 0.6495
[12/05 13:49:42 visual_prompt]: Classification results with test_mammo-cbis: top1: 67.13	rocauc: 70.38	
[12/05 13:49:42 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.375
[12/05 13:58:13 visual_prompt]: Epoch 41 / 100: avg data time: 5.85e+00, avg batch time: 7.3029, average train loss: 0.5929
[12/05 13:59:11 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.5863, average loss: 0.6087
[12/05 13:59:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 69.11	rocauc: 73.95	
[12/05 14:01:37 visual_prompt]: Inference (test):avg data time: 4.50e-05, avg batch time: 0.5881, average loss: 0.6363
[12/05 14:01:37 visual_prompt]: Classification results with test_mammo-cbis: top1: 61.55	rocauc: 68.54	
[12/05 14:01:37 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.3673678906964727
[12/05 14:10:05 visual_prompt]: Epoch 42 / 100: avg data time: 5.80e+00, avg batch time: 7.2535, average train loss: 0.6286
[12/05 14:11:03 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.5867, average loss: 0.6330
[12/05 14:11:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 74.19	
[12/05 14:13:35 visual_prompt]: Inference (test):avg data time: 5.50e-05, avg batch time: 0.5889, average loss: 0.7212
[12/05 14:13:35 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.22	rocauc: 69.93	
[12/05 14:13:35 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.35959278669726935
[12/05 14:22:39 visual_prompt]: Epoch 43 / 100: avg data time: 6.32e+00, avg batch time: 7.7693, average train loss: 0.5643
[12/05 14:23:40 visual_prompt]: Inference (val):avg data time: 5.18e-05, avg batch time: 0.5890, average loss: 0.6774
[12/05 14:23:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 72.44	
[12/05 14:26:09 visual_prompt]: Inference (test):avg data time: 4.99e-05, avg batch time: 0.5879, average loss: 0.7543
[12/05 14:26:09 visual_prompt]: Classification results with test_mammo-cbis: top1: 56.74	rocauc: 68.25	
[12/05 14:26:09 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.3516841607689501
[12/05 14:35:09 visual_prompt]: Epoch 44 / 100: avg data time: 6.25e+00, avg batch time: 7.7044, average train loss: 0.5545
[12/05 14:36:09 visual_prompt]: Inference (val):avg data time: 4.68e-05, avg batch time: 0.5841, average loss: 0.8763
[12/05 14:36:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 73.93	
[12/05 14:38:44 visual_prompt]: Inference (test):avg data time: 4.43e-05, avg batch time: 0.5904, average loss: 1.0624
[12/05 14:38:44 visual_prompt]: Classification results with test_mammo-cbis: top1: 49.30	rocauc: 69.01	
[12/05 14:38:44 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.34365164835397805
[12/05 14:47:27 visual_prompt]: Epoch 45 / 100: avg data time: 5.98e+00, avg batch time: 7.4619, average train loss: 0.5763
[12/05 14:48:26 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.6004, average loss: 0.6651
[12/05 14:48:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 69.51	rocauc: 75.34	
[12/05 14:50:54 visual_prompt]: Inference (test):avg data time: 5.20e-05, avg batch time: 0.5915, average loss: 0.8005
[12/05 14:50:54 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.38	rocauc: 70.56	
[12/05 14:50:54 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.3355050358314172
[12/05 14:59:29 visual_prompt]: Epoch 46 / 100: avg data time: 5.90e+00, avg batch time: 7.3585, average train loss: 0.5283
[12/05 15:00:27 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.5867, average loss: 0.7822
[12/05 15:00:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 74.81	
[12/05 15:02:53 visual_prompt]: Inference (test):avg data time: 4.63e-05, avg batch time: 0.5885, average loss: 0.9665
[12/05 15:02:53 visual_prompt]: Classification results with test_mammo-cbis: top1: 55.35	rocauc: 71.86	
[12/05 15:02:53 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.32725424859373686
[12/05 15:11:24 visual_prompt]: Epoch 47 / 100: avg data time: 5.84e+00, avg batch time: 7.2920, average train loss: 0.5420
[12/05 15:12:25 visual_prompt]: Inference (val):avg data time: 4.89e-05, avg batch time: 0.5875, average loss: 0.6257
[12/05 15:12:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 69.11	rocauc: 74.50	
[12/05 15:15:01 visual_prompt]: Inference (test):avg data time: 4.84e-05, avg batch time: 0.5884, average loss: 0.6757
[12/05 15:15:01 visual_prompt]: Classification results with test_mammo-cbis: top1: 64.50	rocauc: 69.74	
[12/05 15:15:01 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.3189093389542498
[12/05 15:23:46 visual_prompt]: Epoch 48 / 100: avg data time: 6.03e+00, avg batch time: 7.4892, average train loss: 0.4998
[12/05 15:24:48 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.5850, average loss: 0.7165
[12/05 15:24:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 71.65	
[12/05 15:27:16 visual_prompt]: Inference (test):avg data time: 5.42e-05, avg batch time: 0.5866, average loss: 0.7848
[12/05 15:27:16 visual_prompt]: Classification results with test_mammo-cbis: top1: 56.43	rocauc: 70.75	
[12/05 15:27:16 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.3104804738999169
[12/05 15:35:59 visual_prompt]: Epoch 49 / 100: avg data time: 6.02e+00, avg batch time: 7.4717, average train loss: 0.5305
[12/05 15:36:57 visual_prompt]: Inference (val):avg data time: 4.74e-05, avg batch time: 0.5898, average loss: 0.6698
[12/05 15:36:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 73.87	
[12/05 15:39:23 visual_prompt]: Inference (test):avg data time: 4.77e-05, avg batch time: 0.5869, average loss: 0.7678
[12/05 15:39:23 visual_prompt]: Classification results with test_mammo-cbis: top1: 60.78	rocauc: 71.24	
[12/05 15:39:23 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.3019779227044398
[12/05 15:47:53 visual_prompt]: Epoch 50 / 100: avg data time: 5.83e+00, avg batch time: 7.2793, average train loss: 0.4741
[12/05 15:48:57 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.5863, average loss: 0.7636
[12/05 15:48:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 75.06	
[12/05 15:51:35 visual_prompt]: Inference (test):avg data time: 4.33e-04, avg batch time: 0.5890, average loss: 0.9749
[12/05 15:51:35 visual_prompt]: Classification results with test_mammo-cbis: top1: 55.81	rocauc: 70.14	
[12/05 15:51:35 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.29341204441673263
[12/05 16:00:50 visual_prompt]: Epoch 51 / 100: avg data time: 6.48e+00, avg batch time: 7.9388, average train loss: 0.5583
[12/05 16:01:51 visual_prompt]: Inference (val):avg data time: 4.08e-05, avg batch time: 0.5867, average loss: 0.6435
[12/05 16:01:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 76.48	
[12/05 16:04:20 visual_prompt]: Inference (test):avg data time: 4.56e-05, avg batch time: 0.5880, average loss: 0.6573
[12/05 16:04:20 visual_prompt]: Classification results with test_mammo-cbis: top1: 67.13	rocauc: 70.69	
[12/05 16:04:20 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.28479327524001635
[12/05 16:13:01 visual_prompt]: Epoch 52 / 100: avg data time: 5.99e+00, avg batch time: 7.4383, average train loss: 0.5039
[12/05 16:13:59 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.5884, average loss: 0.6448
[12/05 16:13:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 74.74	
[12/05 16:16:24 visual_prompt]: Inference (test):avg data time: 4.88e-05, avg batch time: 0.5884, average loss: 0.7291
[12/05 16:16:24 visual_prompt]: Classification results with test_mammo-cbis: top1: 64.65	rocauc: 70.79	
[12/05 16:16:24 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.2761321158169134
[12/05 16:24:51 visual_prompt]: Epoch 53 / 100: avg data time: 5.79e+00, avg batch time: 7.2434, average train loss: 0.5237
[12/05 16:25:52 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.5895, average loss: 0.7226
[12/05 16:25:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 75.03	
[12/05 16:28:18 visual_prompt]: Inference (test):avg data time: 4.76e-05, avg batch time: 0.5877, average loss: 0.6923
[12/05 16:28:18 visual_prompt]: Classification results with test_mammo-cbis: top1: 69.61	rocauc: 72.67	
[12/05 16:28:18 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.2674391184360313
[12/05 16:36:47 visual_prompt]: Epoch 54 / 100: avg data time: 5.82e+00, avg batch time: 7.2719, average train loss: 0.4678
[12/05 16:37:46 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.5873, average loss: 0.8161
[12/05 16:37:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 72.13	
[12/05 16:40:11 visual_prompt]: Inference (test):avg data time: 5.78e-05, avg batch time: 0.5863, average loss: 0.7271
[12/05 16:40:11 visual_prompt]: Classification results with test_mammo-cbis: top1: 68.06	rocauc: 72.69	
[12/05 16:40:11 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.2587248741756253
[12/05 16:48:39 visual_prompt]: Epoch 55 / 100: avg data time: 5.79e+00, avg batch time: 7.2453, average train loss: 0.4618
[12/05 16:49:37 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.5927, average loss: 0.7164
[12/05 16:49:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 69.92	rocauc: 76.32	
[12/05 16:52:04 visual_prompt]: Inference (test):avg data time: 5.00e-05, avg batch time: 0.5886, average loss: 0.7501
[12/05 16:52:04 visual_prompt]: Classification results with test_mammo-cbis: top1: 68.84	rocauc: 71.32	
[12/05 16:52:04 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.25
[12/05 17:00:31 visual_prompt]: Epoch 56 / 100: avg data time: 5.77e+00, avg batch time: 7.2355, average train loss: 0.4576
[12/05 17:01:29 visual_prompt]: Inference (val):avg data time: 4.15e-05, avg batch time: 0.5916, average loss: 0.8646
[12/05 17:01:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 74.14	
[12/05 17:03:55 visual_prompt]: Inference (test):avg data time: 2.12e-04, avg batch time: 0.5979, average loss: 1.0368
[12/05 17:03:55 visual_prompt]: Classification results with test_mammo-cbis: top1: 57.83	rocauc: 72.84	
[12/05 17:03:55 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.24127512582437483
[12/05 17:12:33 visual_prompt]: Epoch 57 / 100: avg data time: 5.92e+00, avg batch time: 7.3981, average train loss: 0.4140
[12/05 17:13:32 visual_prompt]: Inference (val):avg data time: 6.42e-05, avg batch time: 0.5984, average loss: 0.8949
[12/05 17:13:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 68.91	
[12/05 17:16:06 visual_prompt]: Inference (test):avg data time: 5.28e-05, avg batch time: 0.5956, average loss: 1.0124
[12/05 17:16:06 visual_prompt]: Classification results with test_mammo-cbis: top1: 55.35	rocauc: 65.53	
[12/05 17:16:06 visual_prompt]: Stopping early.
[12/05 17:16:07 visual_prompt]: Rank of current process: 0. World size: 1
[12/05 17:16:07 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[12/05 17:16:07 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[12/05 17:16:07 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[12/05 17:16:07 visual_prompt]: Training with config:
[12/05 17:16:07 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/test/seed875/lr0.5_wd0.0001/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 875, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[12/05 17:16:07 visual_prompt]: Loading training data...
[12/05 17:16:07 visual_prompt]: Constructing mammo-cbis dataset train...
[12/05 17:16:07 visual_prompt]: Loading validation data...
[12/05 17:16:07 visual_prompt]: Constructing mammo-cbis dataset val...
[12/05 17:16:07 visual_prompt]: Loading test data...
[12/05 17:16:07 visual_prompt]: Constructing mammo-cbis dataset test...
[12/05 17:16:07 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[12/05 17:16:10 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[12/05 17:16:10 visual_prompt]: tuned percent:0.532
[12/05 17:16:11 visual_prompt]: Device used for model: 0
[12/05 17:16:11 visual_prompt]: Setting up Evaluator...
[12/05 17:16:11 visual_prompt]: Setting up Trainer...
[12/05 17:16:11 visual_prompt]: 	Setting up the optimizer...
[12/05 17:16:11 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[12/05 17:28:50 visual_prompt]: Epoch 1 / 100: avg data time: 9.37e+00, avg batch time: 10.8391, average train loss: 0.8888
[12/05 17:30:37 visual_prompt]: Inference (val):avg data time: 3.81e-05, avg batch time: 0.5837, average loss: 0.8371
[12/05 17:30:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.47	rocauc: 48.05	
[12/05 17:34:58 visual_prompt]: Inference (test):avg data time: 5.22e-05, avg batch time: 0.5847, average loss: 0.7990
[12/05 17:34:58 visual_prompt]: Classification results with test_mammo-cbis: top1: 58.91	rocauc: 49.38	
[12/05 17:34:58 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.05
[12/05 17:50:40 visual_prompt]: Epoch 2 / 100: avg data time: 1.20e+01, avg batch time: 13.4543, average train loss: 0.9185
[12/05 17:52:25 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.5869, average loss: 0.7934
[12/05 17:52:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.78	
[12/05 17:55:12 visual_prompt]: Inference (test):avg data time: 3.96e-05, avg batch time: 0.5912, average loss: 0.7405
[12/05 17:55:12 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 55.92	
[12/05 17:55:12 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.1
[12/05 18:03:41 visual_prompt]: Epoch 3 / 100: avg data time: 5.82e+00, avg batch time: 7.2716, average train loss: 0.7676
[12/05 18:04:39 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.5895, average loss: 0.6863
[12/05 18:04:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.30	
[12/05 18:07:05 visual_prompt]: Inference (test):avg data time: 3.81e-05, avg batch time: 0.5886, average loss: 0.6813
[12/05 18:07:05 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.53	rocauc: 51.91	
[12/05 18:07:05 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.15
[12/05 18:15:30 visual_prompt]: Epoch 4 / 100: avg data time: 5.76e+00, avg batch time: 7.2118, average train loss: 0.7793
[12/05 18:16:27 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.5885, average loss: 0.6818
[12/05 18:16:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 58.32	
[12/05 18:18:53 visual_prompt]: Inference (test):avg data time: 5.74e-05, avg batch time: 0.5872, average loss: 0.6778
[12/05 18:18:53 visual_prompt]: Classification results with test_mammo-cbis: top1: 60.47	rocauc: 56.68	
[12/05 18:18:53 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.2
[12/05 18:27:21 visual_prompt]: Epoch 5 / 100: avg data time: 5.80e+00, avg batch time: 7.2514, average train loss: 0.7546
[12/05 18:28:19 visual_prompt]: Inference (val):avg data time: 3.87e-05, avg batch time: 0.5882, average loss: 0.9168
[12/05 18:28:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.71	
[12/05 18:30:47 visual_prompt]: Inference (test):avg data time: 4.14e-05, avg batch time: 0.5893, average loss: 0.8440
[12/05 18:30:47 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 59.22	
[12/05 18:30:47 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.25
[12/05 18:39:17 visual_prompt]: Epoch 6 / 100: avg data time: 5.83e+00, avg batch time: 7.2850, average train loss: 0.7453
[12/05 18:40:17 visual_prompt]: Inference (val):avg data time: 4.78e-05, avg batch time: 0.5834, average loss: 1.2115
[12/05 18:40:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 63.86	
[12/05 18:42:43 visual_prompt]: Inference (test):avg data time: 5.43e-05, avg batch time: 0.5867, average loss: 1.3066
[12/05 18:42:43 visual_prompt]: Classification results with test_mammo-cbis: top1: 40.93	rocauc: 62.21	
[12/05 18:42:43 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.3
[12/05 18:51:27 visual_prompt]: Epoch 7 / 100: avg data time: 6.03e+00, avg batch time: 7.4839, average train loss: 0.8020
[12/05 18:52:29 visual_prompt]: Inference (val):avg data time: 3.79e-05, avg batch time: 0.5862, average loss: 1.0569
[12/05 18:52:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 65.48	
[12/05 18:55:04 visual_prompt]: Inference (test):avg data time: 4.32e-05, avg batch time: 0.5890, average loss: 0.9647
[12/05 18:55:04 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 62.95	
[12/05 18:55:04 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.35
[12/05 19:03:57 visual_prompt]: Epoch 8 / 100: avg data time: 6.16e+00, avg batch time: 7.6124, average train loss: 0.8577
[12/05 19:05:00 visual_prompt]: Inference (val):avg data time: 5.68e-05, avg batch time: 0.5886, average loss: 0.7689
[12/05 19:05:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.43	
[12/05 19:07:27 visual_prompt]: Inference (test):avg data time: 4.43e-05, avg batch time: 0.5865, average loss: 0.7196
[12/05 19:07:27 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 63.51	
[12/05 19:07:27 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.4
[12/05 19:19:37 visual_prompt]: Epoch 9 / 100: avg data time: 8.98e+00, avg batch time: 10.4220, average train loss: 0.7580
[12/05 19:20:48 visual_prompt]: Inference (val):avg data time: 3.66e-05, avg batch time: 0.5881, average loss: 0.6648
[12/05 19:20:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 65.11	
[12/05 19:23:30 visual_prompt]: Inference (test):avg data time: 4.39e-05, avg batch time: 0.5869, average loss: 0.6688
[12/05 19:23:30 visual_prompt]: Classification results with test_mammo-cbis: top1: 60.47	rocauc: 62.69	
[12/05 19:23:30 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.45
[12/05 19:32:02 visual_prompt]: Epoch 10 / 100: avg data time: 5.87e+00, avg batch time: 7.3170, average train loss: 0.8416
[12/05 19:33:01 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.5856, average loss: 0.8353
[12/05 19:33:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 65.96	
[12/05 19:35:25 visual_prompt]: Inference (test):avg data time: 5.09e-05, avg batch time: 0.5882, average loss: 0.7732
[12/05 19:35:25 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 64.29	
[12/05 19:35:25 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.5
[12/05 19:43:56 visual_prompt]: Epoch 11 / 100: avg data time: 5.84e+00, avg batch time: 7.2953, average train loss: 1.0667
[12/05 19:44:57 visual_prompt]: Inference (val):avg data time: 5.11e-05, avg batch time: 0.5978, average loss: 0.6704
[12/05 19:44:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 65.17	
[12/05 19:47:25 visual_prompt]: Inference (test):avg data time: 5.40e-05, avg batch time: 0.5980, average loss: 0.6769
[12/05 19:47:25 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.69	rocauc: 64.98	
[12/05 19:47:25 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.49984770675477397
[12/05 19:56:00 visual_prompt]: Epoch 12 / 100: avg data time: 5.88e+00, avg batch time: 7.3579, average train loss: 0.7190
[12/05 19:56:59 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.6004, average loss: 0.7707
[12/05 19:56:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 65.43	
[12/05 19:59:27 visual_prompt]: Inference (test):avg data time: 5.51e-05, avg batch time: 0.5948, average loss: 0.8196
[12/05 19:59:27 visual_prompt]: Classification results with test_mammo-cbis: top1: 40.93	rocauc: 64.49	
[12/05 19:59:27 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.49939101256495605
[12/05 20:07:58 visual_prompt]: Epoch 13 / 100: avg data time: 5.80e+00, avg batch time: 7.2858, average train loss: 0.7115
[12/05 20:08:55 visual_prompt]: Inference (val):avg data time: 4.72e-05, avg batch time: 0.6003, average loss: 0.9165
[12/05 20:08:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 68.54	
[12/05 20:11:21 visual_prompt]: Inference (test):avg data time: 4.67e-05, avg batch time: 0.5937, average loss: 0.8290
[12/05 20:11:21 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 67.11	
[12/05 20:11:21 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.4986304738420683
[12/05 20:19:46 visual_prompt]: Epoch 14 / 100: avg data time: 5.76e+00, avg batch time: 7.2121, average train loss: 0.6923
[12/05 20:20:44 visual_prompt]: Inference (val):avg data time: 3.91e-05, avg batch time: 0.5912, average loss: 0.6348
[12/05 20:20:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 70.26	
[12/05 20:23:09 visual_prompt]: Inference (test):avg data time: 4.18e-05, avg batch time: 0.5884, average loss: 0.6380
[12/05 20:23:09 visual_prompt]: Classification results with test_mammo-cbis: top1: 61.71	rocauc: 66.33	
[12/05 20:23:09 visual_prompt]: Best epoch 14: best metric: -0.635
[12/05 20:23:09 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.4975670171853926
[12/05 20:31:34 visual_prompt]: Epoch 15 / 100: avg data time: 5.75e+00, avg batch time: 7.2076, average train loss: 0.7956
[12/05 20:32:32 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.5858, average loss: 0.8514
[12/05 20:32:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 71.52	
[12/05 20:34:57 visual_prompt]: Inference (test):avg data time: 5.46e-05, avg batch time: 0.5864, average loss: 0.7766
[12/05 20:34:57 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 68.09	
[12/05 20:34:57 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.49620193825305203
[12/05 20:43:21 visual_prompt]: Epoch 16 / 100: avg data time: 5.74e+00, avg batch time: 7.1949, average train loss: 0.7615
[12/05 20:44:20 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.5848, average loss: 0.6324
[12/05 20:44:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.01	rocauc: 71.76	
[12/05 20:46:44 visual_prompt]: Inference (test):avg data time: 4.62e-05, avg batch time: 0.5882, average loss: 0.6351
[12/05 20:46:44 visual_prompt]: Classification results with test_mammo-cbis: top1: 65.43	rocauc: 66.88	
[12/05 20:46:44 visual_prompt]: Best epoch 16: best metric: -0.632
[12/05 20:46:44 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.4945369001834514
[12/05 20:55:08 visual_prompt]: Epoch 17 / 100: avg data time: 5.73e+00, avg batch time: 7.1872, average train loss: 0.8948
[12/05 20:56:05 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.5854, average loss: 1.8240
[12/05 20:56:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 70.56	
[12/05 20:58:31 visual_prompt]: Inference (test):avg data time: 5.56e-05, avg batch time: 0.5901, average loss: 1.6223
[12/05 20:58:31 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 68.63	
[12/05 20:58:31 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.4925739315689991
[12/05 21:08:24 visual_prompt]: Epoch 18 / 100: avg data time: 7.01e+00, avg batch time: 8.4595, average train loss: 0.8211
[12/05 21:09:27 visual_prompt]: Inference (val):avg data time: 3.86e-05, avg batch time: 0.5884, average loss: 1.1029
[12/05 21:09:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 70.65	
[12/05 21:12:28 visual_prompt]: Inference (test):avg data time: 4.03e-05, avg batch time: 0.5901, average loss: 0.9791
[12/05 21:12:28 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 68.03	
[12/05 21:12:28 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.4903154239845797
[12/05 21:22:03 visual_prompt]: Epoch 19 / 100: avg data time: 6.73e+00, avg batch time: 8.2013, average train loss: 0.7253
[12/05 21:23:02 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.6004, average loss: 0.6148
[12/05 21:23:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.89	rocauc: 73.09	
[12/05 21:25:31 visual_prompt]: Inference (test):avg data time: 4.42e-05, avg batch time: 0.5996, average loss: 0.6676
[12/05 21:25:31 visual_prompt]: Classification results with test_mammo-cbis: top1: 62.64	rocauc: 67.88	
[12/05 21:25:31 visual_prompt]: Best epoch 19: best metric: -0.615
[12/05 21:25:31 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.4877641290737884
[12/05 21:34:17 visual_prompt]: Epoch 20 / 100: avg data time: 6.04e+00, avg batch time: 7.5153, average train loss: 0.6416
[12/05 21:35:14 visual_prompt]: Inference (val):avg data time: 3.60e-05, avg batch time: 0.5997, average loss: 0.6358
[12/05 21:35:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 70.58	
[12/05 21:37:40 visual_prompt]: Inference (test):avg data time: 4.49e-05, avg batch time: 0.5966, average loss: 0.6626
[12/05 21:37:40 visual_prompt]: Classification results with test_mammo-cbis: top1: 62.95	rocauc: 65.37	
[12/05 21:37:40 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.4849231551964771
[12/05 21:46:01 visual_prompt]: Epoch 21 / 100: avg data time: 5.69e+00, avg batch time: 7.1646, average train loss: 0.6656
[12/05 21:46:59 visual_prompt]: Inference (val):avg data time: 4.62e-05, avg batch time: 0.5860, average loss: 0.6199
[12/05 21:46:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 73.80	
[12/05 21:49:22 visual_prompt]: Inference (test):avg data time: 4.94e-05, avg batch time: 0.5882, average loss: 0.6845
[12/05 21:49:23 visual_prompt]: Classification results with test_mammo-cbis: top1: 58.14	rocauc: 67.47	
[12/05 21:49:23 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.48179596364169686
[12/05 21:57:41 visual_prompt]: Epoch 22 / 100: avg data time: 5.67e+00, avg batch time: 7.1253, average train loss: 0.6718
[12/05 21:58:39 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.5895, average loss: 0.6624
[12/05 21:58:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 73.48	
[12/05 22:01:02 visual_prompt]: Inference (test):avg data time: 4.93e-05, avg batch time: 0.5884, average loss: 0.6337
[12/05 22:01:02 visual_prompt]: Classification results with test_mammo-cbis: top1: 64.19	rocauc: 68.92	
[12/05 22:01:02 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.4783863644106502
[12/05 22:09:22 visual_prompt]: Epoch 23 / 100: avg data time: 5.68e+00, avg batch time: 7.1406, average train loss: 0.7042
[12/05 22:10:20 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.5895, average loss: 0.9562
[12/05 22:10:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 74.03	
[12/05 22:12:44 visual_prompt]: Inference (test):avg data time: 4.98e-05, avg batch time: 0.5892, average loss: 1.1450
[12/05 22:12:44 visual_prompt]: Classification results with test_mammo-cbis: top1: 40.93	rocauc: 68.43	
[12/05 22:12:44 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.47469851157479176
[12/05 22:21:06 visual_prompt]: Epoch 24 / 100: avg data time: 5.72e+00, avg batch time: 7.1697, average train loss: 0.7121
[12/05 22:22:03 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.5861, average loss: 0.7156
[12/05 22:22:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 74.20	
[12/05 22:24:27 visual_prompt]: Inference (test):avg data time: 5.66e-05, avg batch time: 0.5897, average loss: 0.8266
[12/05 22:24:27 visual_prompt]: Classification results with test_mammo-cbis: top1: 52.40	rocauc: 68.47	
[12/05 22:24:27 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.47073689821473175
[12/05 22:32:48 visual_prompt]: Epoch 25 / 100: avg data time: 5.70e+00, avg batch time: 7.1510, average train loss: 0.6780
[12/05 22:33:45 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.5912, average loss: 0.6050
[12/05 22:33:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 70.33	rocauc: 74.31	
[12/05 22:36:09 visual_prompt]: Inference (test):avg data time: 3.89e-05, avg batch time: 0.5903, average loss: 0.6282
[12/05 22:36:09 visual_prompt]: Classification results with test_mammo-cbis: top1: 64.19	rocauc: 68.72	
[12/05 22:36:09 visual_prompt]: Best epoch 25: best metric: -0.605
[12/05 22:36:09 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.4665063509461097
[12/05 22:44:28 visual_prompt]: Epoch 26 / 100: avg data time: 5.67e+00, avg batch time: 7.1301, average train loss: 0.7135
[12/05 22:45:26 visual_prompt]: Inference (val):avg data time: 3.48e-05, avg batch time: 0.5854, average loss: 0.7303
[12/05 22:45:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 75.38	
[12/05 22:47:49 visual_prompt]: Inference (test):avg data time: 5.67e-05, avg batch time: 0.5896, average loss: 0.6903
[12/05 22:47:49 visual_prompt]: Classification results with test_mammo-cbis: top1: 62.33	rocauc: 68.89	
[12/05 22:47:49 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.46201202403910646
[12/05 22:56:12 visual_prompt]: Epoch 27 / 100: avg data time: 5.71e+00, avg batch time: 7.1857, average train loss: 0.6277
[12/05 22:57:10 visual_prompt]: Inference (val):avg data time: 3.60e-05, avg batch time: 0.5993, average loss: 0.9561
[12/05 22:57:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 49.59	rocauc: 75.87	
[12/05 22:59:35 visual_prompt]: Inference (test):avg data time: 5.35e-05, avg batch time: 0.5989, average loss: 1.1953
[12/05 22:59:35 visual_prompt]: Classification results with test_mammo-cbis: top1: 44.03	rocauc: 66.73	
[12/05 22:59:35 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.4572593931387604
[12/05 23:07:56 visual_prompt]: Epoch 28 / 100: avg data time: 5.69e+00, avg batch time: 7.1559, average train loss: 0.6629
[12/05 23:08:53 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.5895, average loss: 0.9476
[12/05 23:08:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 74.58	
[12/05 23:11:17 visual_prompt]: Inference (test):avg data time: 4.63e-05, avg batch time: 0.5885, average loss: 0.8462
[12/05 23:11:17 visual_prompt]: Classification results with test_mammo-cbis: top1: 60.93	rocauc: 69.30	
[12/05 23:11:17 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.45225424859373686
[12/05 23:19:39 visual_prompt]: Epoch 29 / 100: avg data time: 5.71e+00, avg batch time: 7.1668, average train loss: 0.6422
[12/05 23:20:37 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.5878, average loss: 0.6646
[12/05 23:20:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 71.39	
[12/05 23:23:00 visual_prompt]: Inference (test):avg data time: 4.63e-05, avg batch time: 0.5890, average loss: 0.7142
[12/05 23:23:01 visual_prompt]: Classification results with test_mammo-cbis: top1: 55.19	rocauc: 68.45	
[12/05 23:23:01 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.44700268840168045
[12/05 23:31:22 visual_prompt]: Epoch 30 / 100: avg data time: 5.71e+00, avg batch time: 7.1605, average train loss: 0.6061
[12/05 23:32:19 visual_prompt]: Inference (val):avg data time: 4.02e-05, avg batch time: 0.5880, average loss: 0.8045
[12/05 23:32:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 74.53	
[12/05 23:34:44 visual_prompt]: Inference (test):avg data time: 4.47e-05, avg batch time: 0.5873, average loss: 0.7519
[12/05 23:34:44 visual_prompt]: Classification results with test_mammo-cbis: top1: 63.88	rocauc: 68.67	
[12/05 23:34:44 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.4415111107797445
[12/05 23:43:05 visual_prompt]: Epoch 31 / 100: avg data time: 5.71e+00, avg batch time: 7.1597, average train loss: 0.6220
[12/05 23:44:02 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.5852, average loss: 0.6580
[12/05 23:44:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.07	rocauc: 70.41	
[12/05 23:46:28 visual_prompt]: Inference (test):avg data time: 6.15e-05, avg batch time: 0.5887, average loss: 0.6937
[12/05 23:46:28 visual_prompt]: Classification results with test_mammo-cbis: top1: 61.40	rocauc: 69.45	
[12/05 23:46:28 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.43578620636934856
[12/05 23:54:48 visual_prompt]: Epoch 32 / 100: avg data time: 5.69e+00, avg batch time: 7.1474, average train loss: 0.5963
[12/05 23:55:46 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.5879, average loss: 0.6262
[12/05 23:55:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 68.29	rocauc: 72.78	
[12/05 23:58:11 visual_prompt]: Inference (test):avg data time: 4.42e-05, avg batch time: 0.5876, average loss: 0.6955
[12/05 23:58:11 visual_prompt]: Classification results with test_mammo-cbis: top1: 60.93	rocauc: 67.54	
[12/05 23:58:11 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.42983495008466277
[12/06 00:06:30 visual_prompt]: Epoch 33 / 100: avg data time: 5.68e+00, avg batch time: 7.1315, average train loss: 0.6029
[12/06 00:07:28 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.5893, average loss: 0.9390
[12/06 00:07:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.53	rocauc: 70.75	
[12/06 00:09:51 visual_prompt]: Inference (test):avg data time: 4.83e-05, avg batch time: 0.5889, average loss: 1.0392
[12/06 00:09:51 visual_prompt]: Classification results with test_mammo-cbis: top1: 40.62	rocauc: 69.77	
[12/06 00:09:51 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.4236645926147493
[12/06 00:18:11 visual_prompt]: Epoch 34 / 100: avg data time: 5.68e+00, avg batch time: 7.1363, average train loss: 0.6656
[12/06 00:19:08 visual_prompt]: Inference (val):avg data time: 3.92e-05, avg batch time: 0.5858, average loss: 0.7013
[12/06 00:19:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 73.39	
[12/06 00:21:32 visual_prompt]: Inference (test):avg data time: 4.52e-05, avg batch time: 0.5893, average loss: 0.6825
[12/06 00:21:32 visual_prompt]: Classification results with test_mammo-cbis: top1: 63.26	rocauc: 68.52	
[12/06 00:21:32 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.41728265158971456
[12/06 00:29:52 visual_prompt]: Epoch 35 / 100: avg data time: 5.69e+00, avg batch time: 7.1424, average train loss: 0.6141
[12/06 00:30:49 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.5859, average loss: 0.6351
[12/06 00:30:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 72.72	
[12/06 00:33:13 visual_prompt]: Inference (test):avg data time: 4.71e-05, avg batch time: 0.5896, average loss: 0.6558
[12/06 00:33:13 visual_prompt]: Classification results with test_mammo-cbis: top1: 62.95	rocauc: 67.08	
[12/06 00:33:13 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.4106969024216348
[12/06 00:42:44 visual_prompt]: Epoch 36 / 100: avg data time: 6.71e+00, avg batch time: 8.1601, average train loss: 0.5754
[12/06 00:43:48 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.5894, average loss: 0.7788
[12/06 00:43:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 70.14	
[12/06 00:46:23 visual_prompt]: Inference (test):avg data time: 4.51e-05, avg batch time: 0.5876, average loss: 0.8880
[12/06 00:46:23 visual_prompt]: Classification results with test_mammo-cbis: top1: 53.33	rocauc: 66.40	
[12/06 00:46:23 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.40391536883141455
[12/06 00:54:52 visual_prompt]: Epoch 37 / 100: avg data time: 5.82e+00, avg batch time: 7.2698, average train loss: 0.6058
[12/06 00:55:49 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.5882, average loss: 0.9160
[12/06 00:55:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 71.76	
[12/06 00:58:13 visual_prompt]: Inference (test):avg data time: 4.62e-05, avg batch time: 0.5890, average loss: 1.1115
[12/06 00:58:13 visual_prompt]: Classification results with test_mammo-cbis: top1: 48.22	rocauc: 66.01	
[12/06 00:58:13 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.3969463130731183
[12/06 01:06:38 visual_prompt]: Epoch 38 / 100: avg data time: 5.76e+00, avg batch time: 7.2157, average train loss: 0.5853
[12/06 01:07:37 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.5898, average loss: 0.6753
[12/06 01:07:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.01	rocauc: 72.76	
[12/06 01:10:03 visual_prompt]: Inference (test):avg data time: 4.83e-05, avg batch time: 0.5875, average loss: 0.6708
[12/06 01:10:03 visual_prompt]: Classification results with test_mammo-cbis: top1: 62.79	rocauc: 66.36	
[12/06 01:10:03 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.3897982258676867
[12/06 01:18:29 visual_prompt]: Epoch 39 / 100: avg data time: 5.77e+00, avg batch time: 7.2225, average train loss: 0.6003
[12/06 01:19:26 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.5865, average loss: 0.6278
[12/06 01:19:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 68.70	rocauc: 71.87	
[12/06 01:21:51 visual_prompt]: Inference (test):avg data time: 4.70e-05, avg batch time: 0.5887, average loss: 0.6778
[12/06 01:21:51 visual_prompt]: Classification results with test_mammo-cbis: top1: 64.19	rocauc: 68.51	
[12/06 01:21:51 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.3824798160583012
[12/06 01:30:14 visual_prompt]: Epoch 40 / 100: avg data time: 5.73e+00, avg batch time: 7.1841, average train loss: 0.5742
[12/06 01:31:12 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.5917, average loss: 0.6041
[12/06 01:31:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 69.11	rocauc: 74.15	
[12/06 01:33:38 visual_prompt]: Inference (test):avg data time: 4.91e-05, avg batch time: 0.5867, average loss: 0.6702
[12/06 01:33:38 visual_prompt]: Classification results with test_mammo-cbis: top1: 64.19	rocauc: 68.91	
[12/06 01:33:38 visual_prompt]: Best epoch 40: best metric: -0.604
[12/06 01:33:38 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.375
[12/06 01:42:03 visual_prompt]: Epoch 41 / 100: avg data time: 5.76e+00, avg batch time: 7.2117, average train loss: 0.5469
[12/06 01:43:00 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.5868, average loss: 0.7661
[12/06 01:43:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 69.51	
[12/06 01:45:26 visual_prompt]: Inference (test):avg data time: 5.36e-05, avg batch time: 0.5860, average loss: 0.8650
[12/06 01:45:26 visual_prompt]: Classification results with test_mammo-cbis: top1: 57.98	rocauc: 66.71	
[12/06 01:45:26 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.3673678906964727
[12/06 01:53:49 visual_prompt]: Epoch 42 / 100: avg data time: 5.73e+00, avg batch time: 7.1860, average train loss: 0.5466
[12/06 01:54:46 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.5904, average loss: 0.6482
[12/06 01:54:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 73.22	
[12/06 01:57:11 visual_prompt]: Inference (test):avg data time: 4.19e-05, avg batch time: 0.5862, average loss: 0.6968
[12/06 01:57:11 visual_prompt]: Classification results with test_mammo-cbis: top1: 62.48	rocauc: 67.46	
[12/06 01:57:11 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.35959278669726935
[12/06 02:05:34 visual_prompt]: Epoch 43 / 100: avg data time: 5.73e+00, avg batch time: 7.1855, average train loss: 0.5602
[12/06 02:06:32 visual_prompt]: Inference (val):avg data time: 3.85e-05, avg batch time: 0.5870, average loss: 0.6294
[12/06 02:06:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.89	rocauc: 71.99	
[12/06 02:08:58 visual_prompt]: Inference (test):avg data time: 4.52e-05, avg batch time: 0.5886, average loss: 0.6894
[12/06 02:08:58 visual_prompt]: Classification results with test_mammo-cbis: top1: 61.40	rocauc: 66.97	
[12/06 02:08:58 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.3516841607689501
[12/06 02:17:24 visual_prompt]: Epoch 44 / 100: avg data time: 5.78e+00, avg batch time: 7.2298, average train loss: 0.5763
[12/06 02:18:21 visual_prompt]: Inference (val):avg data time: 4.05e-05, avg batch time: 0.5857, average loss: 0.6740
[12/06 02:18:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 71.04	
[12/06 02:20:48 visual_prompt]: Inference (test):avg data time: 5.56e-04, avg batch time: 0.5868, average loss: 0.7139
[12/06 02:20:48 visual_prompt]: Classification results with test_mammo-cbis: top1: 63.10	rocauc: 65.51	
[12/06 02:20:48 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.34365164835397805
[12/06 02:29:13 visual_prompt]: Epoch 45 / 100: avg data time: 5.75e+00, avg batch time: 7.2067, average train loss: 0.5255
[12/06 02:30:10 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.5880, average loss: 0.7066
[12/06 02:30:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 74.04	
[12/06 02:32:36 visual_prompt]: Inference (test):avg data time: 4.41e-05, avg batch time: 0.5851, average loss: 0.7034
[12/06 02:32:36 visual_prompt]: Classification results with test_mammo-cbis: top1: 63.72	rocauc: 66.87	
[12/06 02:32:36 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.3355050358314172
[12/06 02:41:00 visual_prompt]: Epoch 46 / 100: avg data time: 5.75e+00, avg batch time: 7.2107, average train loss: 0.5133
[12/06 02:41:59 visual_prompt]: Inference (val):avg data time: 3.59e-05, avg batch time: 0.5896, average loss: 0.8662
[12/06 02:41:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 73.00	
[12/06 02:44:25 visual_prompt]: Inference (test):avg data time: 4.70e-05, avg batch time: 0.5885, average loss: 0.8220
[12/06 02:44:25 visual_prompt]: Classification results with test_mammo-cbis: top1: 63.26	rocauc: 68.35	
[12/06 02:44:25 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.32725424859373686
[12/06 02:52:50 visual_prompt]: Epoch 47 / 100: avg data time: 5.76e+00, avg batch time: 7.2123, average train loss: 0.5272
[12/06 02:53:48 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.5852, average loss: 0.7308
[12/06 02:53:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 68.97	
[12/06 02:56:13 visual_prompt]: Inference (test):avg data time: 4.90e-05, avg batch time: 0.5905, average loss: 0.8073
[12/06 02:56:13 visual_prompt]: Classification results with test_mammo-cbis: top1: 57.67	rocauc: 66.67	
[12/06 02:56:13 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.3189093389542498
[12/06 03:04:39 visual_prompt]: Epoch 48 / 100: avg data time: 5.77e+00, avg batch time: 7.2231, average train loss: 0.5347
[12/06 03:05:37 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.5856, average loss: 0.6362
[12/06 03:05:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 72.53	
[12/06 03:08:04 visual_prompt]: Inference (test):avg data time: 4.77e-05, avg batch time: 0.5903, average loss: 0.7151
[12/06 03:08:04 visual_prompt]: Classification results with test_mammo-cbis: top1: 63.57	rocauc: 66.82	
[12/06 03:08:04 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.3104804738999169
[12/06 03:16:35 visual_prompt]: Epoch 49 / 100: avg data time: 5.84e+00, avg batch time: 7.2909, average train loss: 0.5087
[12/06 03:17:33 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.5824, average loss: 0.6618
[12/06 03:17:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 71.49	
[12/06 03:20:01 visual_prompt]: Inference (test):avg data time: 5.15e-05, avg batch time: 0.5881, average loss: 0.7397
[12/06 03:20:01 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.84	rocauc: 67.93	
[12/06 03:20:01 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.3019779227044398
[12/06 03:28:26 visual_prompt]: Epoch 50 / 100: avg data time: 5.75e+00, avg batch time: 7.2044, average train loss: 0.5153
[12/06 03:29:24 visual_prompt]: Inference (val):avg data time: 4.19e-05, avg batch time: 0.5889, average loss: 1.1388
[12/06 03:29:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 50.81	rocauc: 67.08	
[12/06 03:31:49 visual_prompt]: Inference (test):avg data time: 4.88e-05, avg batch time: 0.5872, average loss: 1.3009
[12/06 03:31:49 visual_prompt]: Classification results with test_mammo-cbis: top1: 45.89	rocauc: 65.84	
[12/06 03:31:49 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.29341204441673263
[12/06 03:40:13 visual_prompt]: Epoch 51 / 100: avg data time: 5.74e+00, avg batch time: 7.1910, average train loss: 0.5858
[12/06 03:41:11 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.5889, average loss: 0.6674
[12/06 03:41:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 71.75	
[12/06 03:43:36 visual_prompt]: Inference (test):avg data time: 4.46e-05, avg batch time: 0.5892, average loss: 0.6735
[12/06 03:43:36 visual_prompt]: Classification results with test_mammo-cbis: top1: 63.88	rocauc: 68.84	
[12/06 03:43:36 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.28479327524001635
[12/06 03:52:00 visual_prompt]: Epoch 52 / 100: avg data time: 5.75e+00, avg batch time: 7.1988, average train loss: 0.5027
[12/06 03:52:58 visual_prompt]: Inference (val):avg data time: 4.65e-05, avg batch time: 0.5874, average loss: 0.7270
[12/06 03:52:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 71.98	
[12/06 03:55:23 visual_prompt]: Inference (test):avg data time: 3.71e-05, avg batch time: 0.5873, average loss: 0.7218
[12/06 03:55:23 visual_prompt]: Classification results with test_mammo-cbis: top1: 63.10	rocauc: 67.55	
[12/06 03:55:23 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.2761321158169134
[12/06 04:04:18 visual_prompt]: Epoch 53 / 100: avg data time: 6.18e+00, avg batch time: 7.6350, average train loss: 0.5046
[12/06 04:05:53 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.5848, average loss: 1.0765
[12/06 04:05:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 68.68	
[12/06 04:08:48 visual_prompt]: Inference (test):avg data time: 5.16e-05, avg batch time: 0.5856, average loss: 1.3155
[12/06 04:08:48 visual_prompt]: Classification results with test_mammo-cbis: top1: 45.89	rocauc: 63.95	
[12/06 04:08:48 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.2674391184360313
[12/06 04:18:22 visual_prompt]: Epoch 54 / 100: avg data time: 6.74e+00, avg batch time: 8.1852, average train loss: 0.4725
[12/06 04:19:19 visual_prompt]: Inference (val):avg data time: 5.63e-05, avg batch time: 0.5904, average loss: 0.8501
[12/06 04:19:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.01	rocauc: 68.02	
[12/06 04:21:44 visual_prompt]: Inference (test):avg data time: 4.70e-05, avg batch time: 0.5866, average loss: 0.9541
[12/06 04:21:44 visual_prompt]: Classification results with test_mammo-cbis: top1: 60.16	rocauc: 67.02	
[12/06 04:21:44 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.2587248741756253
[12/06 04:30:10 visual_prompt]: Epoch 55 / 100: avg data time: 5.76e+00, avg batch time: 7.2164, average train loss: 0.4645
[12/06 04:31:08 visual_prompt]: Inference (val):avg data time: 5.87e-05, avg batch time: 0.5867, average loss: 0.7098
[12/06 04:31:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 67.03	
[12/06 04:33:34 visual_prompt]: Inference (test):avg data time: 5.44e-05, avg batch time: 0.5873, average loss: 0.7321
[12/06 04:33:34 visual_prompt]: Classification results with test_mammo-cbis: top1: 60.31	rocauc: 66.94	
[12/06 04:33:34 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.25
[12/06 04:42:01 visual_prompt]: Epoch 56 / 100: avg data time: 5.78e+00, avg batch time: 7.2370, average train loss: 0.4805
[12/06 04:42:59 visual_prompt]: Inference (val):avg data time: 4.17e-05, avg batch time: 0.5882, average loss: 0.9322
[12/06 04:42:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 67.33	
[12/06 04:45:25 visual_prompt]: Inference (test):avg data time: 5.60e-05, avg batch time: 0.5885, average loss: 1.0490
[12/06 04:45:25 visual_prompt]: Classification results with test_mammo-cbis: top1: 54.11	rocauc: 65.88	
[12/06 04:45:25 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.24127512582437483
[12/06 04:53:52 visual_prompt]: Epoch 57 / 100: avg data time: 5.78e+00, avg batch time: 7.2362, average train loss: 0.4661
[12/06 04:54:51 visual_prompt]: Inference (val):avg data time: 4.46e-05, avg batch time: 0.5941, average loss: 0.7931
[12/06 04:54:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 69.86	
[12/06 04:57:15 visual_prompt]: Inference (test):avg data time: 5.36e-05, avg batch time: 0.5903, average loss: 0.9502
[12/06 04:57:15 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.22	rocauc: 63.94	
[12/06 04:57:15 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.23256088156396867
[12/06 05:05:42 visual_prompt]: Epoch 58 / 100: avg data time: 5.79e+00, avg batch time: 7.2427, average train loss: 0.4708
[12/06 05:06:40 visual_prompt]: Inference (val):avg data time: 5.55e-05, avg batch time: 0.5888, average loss: 0.7257
[12/06 05:06:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 69.31	
[12/06 05:09:06 visual_prompt]: Inference (test):avg data time: 4.79e-05, avg batch time: 0.5877, average loss: 0.7947
[12/06 05:09:06 visual_prompt]: Classification results with test_mammo-cbis: top1: 62.48	rocauc: 67.21	
[12/06 05:09:06 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.22386788418308667
[12/06 05:17:33 visual_prompt]: Epoch 59 / 100: avg data time: 5.78e+00, avg batch time: 7.2325, average train loss: 0.4118
[12/06 05:18:31 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.5872, average loss: 0.8502
[12/06 05:18:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 70.46	
[12/06 05:20:57 visual_prompt]: Inference (test):avg data time: 6.04e-05, avg batch time: 0.5877, average loss: 0.8671
[12/06 05:20:57 visual_prompt]: Classification results with test_mammo-cbis: top1: 62.33	rocauc: 64.76	
[12/06 05:20:57 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.2152067247599837
[12/06 05:29:22 visual_prompt]: Epoch 60 / 100: avg data time: 5.77e+00, avg batch time: 7.2212, average train loss: 0.3952
[12/06 05:30:20 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.5917, average loss: 1.0119
[12/06 05:30:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 68.66	
[12/06 05:32:45 visual_prompt]: Inference (test):avg data time: 5.47e-05, avg batch time: 0.5879, average loss: 1.1257
[12/06 05:32:45 visual_prompt]: Classification results with test_mammo-cbis: top1: 61.09	rocauc: 67.01	
[12/06 05:32:45 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.20658795558326742
[12/06 05:41:11 visual_prompt]: Epoch 61 / 100: avg data time: 5.77e+00, avg batch time: 7.2275, average train loss: 0.3623
[12/06 05:42:09 visual_prompt]: Inference (val):avg data time: 3.85e-05, avg batch time: 0.5939, average loss: 0.9479
[12/06 05:42:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 66.05	
[12/06 05:44:36 visual_prompt]: Inference (test):avg data time: 5.58e-05, avg batch time: 0.5902, average loss: 0.9577
[12/06 05:44:36 visual_prompt]: Classification results with test_mammo-cbis: top1: 62.79	rocauc: 66.18	
[12/06 05:44:36 visual_prompt]: Stopping early.
[12/06 05:44:37 visual_prompt]: Rank of current process: 0. World size: 1
[12/06 05:44:37 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[12/06 05:44:37 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[12/06 05:44:37 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[12/06 05:44:37 visual_prompt]: Training with config:
[12/06 05:44:37 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/test/seed4536/lr0.5_wd0.0001/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 4536, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[12/06 05:44:37 visual_prompt]: Loading training data...
[12/06 05:44:37 visual_prompt]: Constructing mammo-cbis dataset train...
[12/06 05:44:38 visual_prompt]: Loading validation data...
[12/06 05:44:38 visual_prompt]: Constructing mammo-cbis dataset val...
[12/06 05:44:38 visual_prompt]: Loading test data...
[12/06 05:44:38 visual_prompt]: Constructing mammo-cbis dataset test...
[12/06 05:44:38 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[12/06 05:44:52 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[12/06 05:44:52 visual_prompt]: tuned percent:0.532
[12/06 05:44:52 visual_prompt]: Device used for model: 0
[12/06 05:44:52 visual_prompt]: Setting up Evaluator...
[12/06 05:44:52 visual_prompt]: Setting up Trainer...
[12/06 05:44:52 visual_prompt]: 	Setting up the optimizer...
[12/06 05:44:52 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[12/06 05:53:19 visual_prompt]: Epoch 1 / 100: avg data time: 5.79e+00, avg batch time: 7.2454, average train loss: 1.3501
[12/06 05:54:17 visual_prompt]: Inference (val):avg data time: 4.62e-05, avg batch time: 0.5870, average loss: 1.2508
[12/06 05:54:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.13	
[12/06 05:56:44 visual_prompt]: Inference (test):avg data time: 4.89e-05, avg batch time: 0.5894, average loss: 1.1557
[12/06 05:56:44 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 48.53	
[12/06 05:56:44 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.05
[12/06 06:05:12 visual_prompt]: Epoch 2 / 100: avg data time: 5.80e+00, avg batch time: 7.2557, average train loss: 1.1721
[12/06 06:06:10 visual_prompt]: Inference (val):avg data time: 3.53e-05, avg batch time: 0.5931, average loss: 0.7946
[12/06 06:06:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.35	
[12/06 06:08:37 visual_prompt]: Inference (test):avg data time: 4.66e-05, avg batch time: 0.5918, average loss: 0.7406
[12/06 06:08:37 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 53.03	
[12/06 06:08:37 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.1
[12/06 06:17:01 visual_prompt]: Epoch 3 / 100: avg data time: 5.74e+00, avg batch time: 7.1959, average train loss: 0.7320
[12/06 06:17:58 visual_prompt]: Inference (val):avg data time: 3.85e-05, avg batch time: 0.5895, average loss: 0.7060
[12/06 06:17:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.97	
[12/06 06:20:24 visual_prompt]: Inference (test):avg data time: 5.15e-05, avg batch time: 0.5885, average loss: 0.7145
[12/06 06:20:24 visual_prompt]: Classification results with test_mammo-cbis: top1: 41.24	rocauc: 59.01	
[12/06 06:20:24 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.15
[12/06 06:28:46 visual_prompt]: Epoch 4 / 100: avg data time: 5.72e+00, avg batch time: 7.1766, average train loss: 0.7858
[12/06 06:29:44 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.5867, average loss: 0.6879
[12/06 06:29:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.47	rocauc: 58.56	
[12/06 06:32:10 visual_prompt]: Inference (test):avg data time: 5.05e-05, avg batch time: 0.5881, average loss: 0.6663
[12/06 06:32:10 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 60.57	
[12/06 06:32:10 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.2
[12/06 06:40:36 visual_prompt]: Epoch 5 / 100: avg data time: 5.78e+00, avg batch time: 7.2288, average train loss: 0.7320
[12/06 06:41:34 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.5846, average loss: 0.6772
[12/06 06:41:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 59.63	
[12/06 06:44:00 visual_prompt]: Inference (test):avg data time: 4.59e-05, avg batch time: 0.5876, average loss: 0.6654
[12/06 06:44:00 visual_prompt]: Classification results with test_mammo-cbis: top1: 60.62	rocauc: 61.17	
[12/06 06:44:00 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.25
[12/06 06:52:26 visual_prompt]: Epoch 6 / 100: avg data time: 5.78e+00, avg batch time: 7.2323, average train loss: 0.7204
[12/06 06:53:25 visual_prompt]: Inference (val):avg data time: 3.84e-05, avg batch time: 0.5859, average loss: 0.6689
[12/06 06:53:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 63.96	
[12/06 06:55:51 visual_prompt]: Inference (test):avg data time: 5.87e-05, avg batch time: 0.5863, average loss: 0.6665
[12/06 06:55:51 visual_prompt]: Classification results with test_mammo-cbis: top1: 60.47	rocauc: 62.32	
[12/06 06:55:51 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.3
[12/06 07:04:18 visual_prompt]: Epoch 7 / 100: avg data time: 5.78e+00, avg batch time: 7.2329, average train loss: 0.7433
[12/06 07:05:16 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.5879, average loss: 0.8708
[12/06 07:05:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 65.73	
[12/06 07:07:41 visual_prompt]: Inference (test):avg data time: 4.48e-05, avg batch time: 0.5893, average loss: 0.9298
[12/06 07:07:41 visual_prompt]: Classification results with test_mammo-cbis: top1: 40.93	rocauc: 63.86	
[12/06 07:07:41 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.35
[12/06 07:16:12 visual_prompt]: Epoch 8 / 100: avg data time: 5.84e+00, avg batch time: 7.2947, average train loss: 0.8089
[12/06 07:17:11 visual_prompt]: Inference (val):avg data time: 4.20e-05, avg batch time: 0.5897, average loss: 1.0784
[12/06 07:17:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 64.13	
[12/06 07:19:39 visual_prompt]: Inference (test):avg data time: 6.40e-05, avg batch time: 0.5883, average loss: 1.1615
[12/06 07:19:39 visual_prompt]: Classification results with test_mammo-cbis: top1: 40.93	rocauc: 63.71	
[12/06 07:19:39 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.4
[12/06 07:28:09 visual_prompt]: Epoch 9 / 100: avg data time: 5.83e+00, avg batch time: 7.2806, average train loss: 0.8165
[12/06 07:29:07 visual_prompt]: Inference (val):avg data time: 4.46e-05, avg batch time: 0.5953, average loss: 0.6884
[12/06 07:29:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 66.14	
[12/06 07:31:35 visual_prompt]: Inference (test):avg data time: 5.74e-05, avg batch time: 0.5979, average loss: 0.6628
[12/06 07:31:35 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.53	rocauc: 64.15	
[12/06 07:31:35 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.45
[12/06 07:40:01 visual_prompt]: Epoch 10 / 100: avg data time: 5.77e+00, avg batch time: 7.2266, average train loss: 0.6853
[12/06 07:40:59 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.5921, average loss: 0.6466
[12/06 07:40:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 68.17	
[12/06 07:43:25 visual_prompt]: Inference (test):avg data time: 5.10e-05, avg batch time: 0.5923, average loss: 0.6551
[12/06 07:43:25 visual_prompt]: Classification results with test_mammo-cbis: top1: 63.41	rocauc: 65.77	
[12/06 07:43:25 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.5
[12/06 07:51:48 visual_prompt]: Epoch 11 / 100: avg data time: 5.73e+00, avg batch time: 7.1849, average train loss: 0.8909
[12/06 07:52:46 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.5870, average loss: 0.6860
[12/06 07:52:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 68.57	
[12/06 07:55:12 visual_prompt]: Inference (test):avg data time: 5.08e-05, avg batch time: 0.5881, average loss: 0.6617
[12/06 07:55:12 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 64.63	
[12/06 07:55:12 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.49984770675477397
[12/06 08:03:37 visual_prompt]: Epoch 12 / 100: avg data time: 5.76e+00, avg batch time: 7.2136, average train loss: 0.7019
[12/06 08:04:35 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.5906, average loss: 0.6583
[12/06 08:04:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 67.88	
[12/06 08:07:00 visual_prompt]: Inference (test):avg data time: 4.85e-05, avg batch time: 0.5892, average loss: 0.6316
[12/06 08:07:00 visual_prompt]: Classification results with test_mammo-cbis: top1: 62.64	rocauc: 68.04	
[12/06 08:07:00 visual_prompt]: Best epoch 12: best metric: -0.658
[12/06 08:07:00 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.49939101256495605
[12/06 08:15:23 visual_prompt]: Epoch 13 / 100: avg data time: 5.73e+00, avg batch time: 7.1802, average train loss: 0.7585
[12/06 08:16:20 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.5852, average loss: 0.8928
[12/06 08:16:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 70.33	
[12/06 08:18:44 visual_prompt]: Inference (test):avg data time: 4.72e-05, avg batch time: 0.5875, average loss: 0.9799
[12/06 08:18:44 visual_prompt]: Classification results with test_mammo-cbis: top1: 40.93	rocauc: 66.54	
[12/06 08:18:44 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.4986304738420683
[12/06 08:27:06 visual_prompt]: Epoch 14 / 100: avg data time: 5.71e+00, avg batch time: 7.1685, average train loss: 0.7947
[12/06 08:28:04 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.5864, average loss: 1.1269
[12/06 08:28:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 68.19	
[12/06 08:30:29 visual_prompt]: Inference (test):avg data time: 5.45e-05, avg batch time: 0.5868, average loss: 1.0084
[12/06 08:30:29 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 66.81	
[12/06 08:30:29 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.4975670171853926
[12/06 08:38:51 visual_prompt]: Epoch 15 / 100: avg data time: 5.72e+00, avg batch time: 7.1739, average train loss: 0.7214
[12/06 08:39:49 visual_prompt]: Inference (val):avg data time: 3.77e-05, avg batch time: 0.5894, average loss: 0.6538
[12/06 08:39:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 67.30	
[12/06 08:42:15 visual_prompt]: Inference (test):avg data time: 4.92e-05, avg batch time: 0.5952, average loss: 0.6263
[12/06 08:42:15 visual_prompt]: Classification results with test_mammo-cbis: top1: 64.50	rocauc: 68.40	
[12/06 08:42:15 visual_prompt]: Best epoch 15: best metric: -0.654
[12/06 08:42:15 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.49620193825305203
[12/06 08:51:41 visual_prompt]: Epoch 16 / 100: avg data time: 6.61e+00, avg batch time: 8.0816, average train loss: 0.7161
[12/06 08:52:45 visual_prompt]: Inference (val):avg data time: 3.84e-05, avg batch time: 0.5902, average loss: 0.8667
[12/06 08:52:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 70.67	
[12/06 08:55:27 visual_prompt]: Inference (test):avg data time: 5.38e-05, avg batch time: 0.5886, average loss: 0.7797
[12/06 08:55:27 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 68.49	
[12/06 08:55:27 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.4945369001834514
[12/06 09:04:07 visual_prompt]: Epoch 17 / 100: avg data time: 5.97e+00, avg batch time: 7.4265, average train loss: 0.7356
[12/06 09:05:06 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.5865, average loss: 1.0414
[12/06 09:05:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 71.61	
[12/06 09:07:31 visual_prompt]: Inference (test):avg data time: 4.48e-05, avg batch time: 0.5856, average loss: 0.9348
[12/06 09:07:31 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 67.91	
[12/06 09:07:31 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.4925739315689991
[12/06 09:15:58 visual_prompt]: Epoch 18 / 100: avg data time: 5.79e+00, avg batch time: 7.2456, average train loss: 0.7923
[12/06 09:16:56 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.5868, average loss: 1.4956
[12/06 09:16:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 70.35	
[12/06 09:19:22 visual_prompt]: Inference (test):avg data time: 5.00e-05, avg batch time: 0.5867, average loss: 1.3368
[12/06 09:19:22 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 67.00	
[12/06 09:19:22 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.4903154239845797
[12/06 09:27:49 visual_prompt]: Epoch 19 / 100: avg data time: 5.79e+00, avg batch time: 7.2487, average train loss: 0.7995
[12/06 09:28:47 visual_prompt]: Inference (val):avg data time: 4.29e-05, avg batch time: 0.5880, average loss: 1.1972
[12/06 09:28:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 65.19	
[12/06 09:31:11 visual_prompt]: Inference (test):avg data time: 4.79e-05, avg batch time: 0.5896, average loss: 1.3440
[12/06 09:31:11 visual_prompt]: Classification results with test_mammo-cbis: top1: 40.93	rocauc: 65.46	
[12/06 09:31:11 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.4877641290737884
[12/06 09:39:30 visual_prompt]: Epoch 20 / 100: avg data time: 5.67e+00, avg batch time: 7.1233, average train loss: 0.7367
[12/06 09:40:28 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.5869, average loss: 0.6950
[12/06 09:40:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 72.97	
[12/06 09:42:52 visual_prompt]: Inference (test):avg data time: 4.28e-05, avg batch time: 0.5874, average loss: 0.6612
[12/06 09:42:52 visual_prompt]: Classification results with test_mammo-cbis: top1: 65.58	rocauc: 67.94	
[12/06 09:42:52 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.4849231551964771
[12/06 09:51:14 visual_prompt]: Epoch 21 / 100: avg data time: 5.71e+00, avg batch time: 7.1689, average train loss: 0.6945
[12/06 09:52:12 visual_prompt]: Inference (val):avg data time: 3.81e-05, avg batch time: 0.5886, average loss: 0.6415
[12/06 09:52:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 70.05	
[12/06 09:54:36 visual_prompt]: Inference (test):avg data time: 5.17e-05, avg batch time: 0.5917, average loss: 0.6389
[12/06 09:54:36 visual_prompt]: Classification results with test_mammo-cbis: top1: 65.74	rocauc: 69.15	
[12/06 09:54:36 visual_prompt]: Best epoch 21: best metric: -0.641
[12/06 09:54:36 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.48179596364169686
[12/06 10:02:57 visual_prompt]: Epoch 22 / 100: avg data time: 5.70e+00, avg batch time: 7.1478, average train loss: 0.7032
[12/06 10:03:54 visual_prompt]: Inference (val):avg data time: 4.46e-05, avg batch time: 0.5913, average loss: 0.6371
[12/06 10:03:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 70.84	
[12/06 10:06:18 visual_prompt]: Inference (test):avg data time: 4.19e-05, avg batch time: 0.5891, average loss: 0.6196
[12/06 10:06:18 visual_prompt]: Classification results with test_mammo-cbis: top1: 64.50	rocauc: 69.49	
[12/06 10:06:18 visual_prompt]: Best epoch 22: best metric: -0.637
[12/06 10:06:18 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.4783863644106502
[12/06 10:14:40 visual_prompt]: Epoch 23 / 100: avg data time: 5.71e+00, avg batch time: 7.1575, average train loss: 0.6323
[12/06 10:15:37 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.5887, average loss: 0.6378
[12/06 10:15:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 73.06	
[12/06 10:18:01 visual_prompt]: Inference (test):avg data time: 5.32e-05, avg batch time: 0.5905, average loss: 0.6211
[12/06 10:18:01 visual_prompt]: Classification results with test_mammo-cbis: top1: 64.34	rocauc: 68.42	
[12/06 10:18:01 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.47469851157479176
[12/06 10:26:21 visual_prompt]: Epoch 24 / 100: avg data time: 5.68e+00, avg batch time: 7.1375, average train loss: 0.6685
[12/06 10:27:18 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.5912, average loss: 0.6599
[12/06 10:27:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 72.89	
[12/06 10:29:42 visual_prompt]: Inference (test):avg data time: 5.24e-05, avg batch time: 0.5890, average loss: 0.7435
[12/06 10:29:42 visual_prompt]: Classification results with test_mammo-cbis: top1: 58.29	rocauc: 68.44	
[12/06 10:29:42 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.47073689821473175
[12/06 10:38:02 visual_prompt]: Epoch 25 / 100: avg data time: 5.69e+00, avg batch time: 7.1392, average train loss: 0.6496
[12/06 10:38:59 visual_prompt]: Inference (val):avg data time: 3.64e-05, avg batch time: 0.5888, average loss: 0.6301
[12/06 10:38:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 72.40	
[12/06 10:41:24 visual_prompt]: Inference (test):avg data time: 4.22e-05, avg batch time: 0.5885, average loss: 0.6689
[12/06 10:41:24 visual_prompt]: Classification results with test_mammo-cbis: top1: 61.40	rocauc: 70.05	
[12/06 10:41:24 visual_prompt]: Best epoch 25: best metric: -0.630
[12/06 10:41:24 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.4665063509461097
[12/06 10:50:24 visual_prompt]: Epoch 26 / 100: avg data time: 6.26e+00, avg batch time: 7.7109, average train loss: 0.6354
[12/06 10:51:32 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.5828, average loss: 0.6886
[12/06 10:51:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 73.36	
[12/06 10:54:21 visual_prompt]: Inference (test):avg data time: 4.70e-05, avg batch time: 0.5871, average loss: 0.7741
[12/06 10:54:21 visual_prompt]: Classification results with test_mammo-cbis: top1: 53.95	rocauc: 69.11	
[12/06 10:54:21 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.46201202403910646
[12/06 11:04:06 visual_prompt]: Epoch 27 / 100: avg data time: 6.91e+00, avg batch time: 8.3607, average train loss: 0.6254
[12/06 11:05:05 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.5908, average loss: 0.7013
[12/06 11:05:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 74.07	
[12/06 11:07:31 visual_prompt]: Inference (test):avg data time: 6.24e-05, avg batch time: 0.5876, average loss: 0.7866
[12/06 11:07:31 visual_prompt]: Classification results with test_mammo-cbis: top1: 49.46	rocauc: 69.69	
[12/06 11:07:31 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.4572593931387604
[12/06 11:16:34 visual_prompt]: Epoch 28 / 100: avg data time: 6.27e+00, avg batch time: 7.7481, average train loss: 0.6295
[12/06 11:17:50 visual_prompt]: Inference (val):avg data time: 4.27e-05, avg batch time: 0.5978, average loss: 0.6408
[12/06 11:17:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 73.19	
[12/06 11:20:47 visual_prompt]: Inference (test):avg data time: 4.46e-05, avg batch time: 0.5987, average loss: 0.6193
[12/06 11:20:47 visual_prompt]: Classification results with test_mammo-cbis: top1: 66.20	rocauc: 70.48	
[12/06 11:20:47 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.45225424859373686
[12/06 11:30:17 visual_prompt]: Epoch 29 / 100: avg data time: 6.66e+00, avg batch time: 8.1394, average train loss: 0.6248
[12/06 11:31:14 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.6005, average loss: 0.6766
[12/06 11:31:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.67	rocauc: 75.03	
[12/06 11:33:39 visual_prompt]: Inference (test):avg data time: 4.91e-05, avg batch time: 0.5998, average loss: 0.6632
[12/06 11:33:39 visual_prompt]: Classification results with test_mammo-cbis: top1: 66.67	rocauc: 70.01	
[12/06 11:33:39 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.44700268840168045
[12/06 11:42:02 visual_prompt]: Epoch 30 / 100: avg data time: 5.71e+00, avg batch time: 7.1793, average train loss: 0.5980
[12/06 11:43:00 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.5974, average loss: 0.7429
[12/06 11:43:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 73.56	
[12/06 11:45:25 visual_prompt]: Inference (test):avg data time: 4.17e-05, avg batch time: 0.5987, average loss: 0.6881
[12/06 11:45:25 visual_prompt]: Classification results with test_mammo-cbis: top1: 65.43	rocauc: 69.63	
[12/06 11:45:25 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.4415111107797445
[12/06 11:53:48 visual_prompt]: Epoch 31 / 100: avg data time: 5.71e+00, avg batch time: 7.1842, average train loss: 0.6113
[12/06 11:54:45 visual_prompt]: Inference (val):avg data time: 4.47e-05, avg batch time: 0.5975, average loss: 0.6040
[12/06 11:54:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 68.70	rocauc: 72.92	
[12/06 11:57:10 visual_prompt]: Inference (test):avg data time: 5.01e-05, avg batch time: 0.5953, average loss: 0.6329
[12/06 11:57:10 visual_prompt]: Classification results with test_mammo-cbis: top1: 63.26	rocauc: 67.80	
[12/06 11:57:10 visual_prompt]: Best epoch 31: best metric: -0.604
[12/06 11:57:10 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.43578620636934856
[12/06 12:05:34 visual_prompt]: Epoch 32 / 100: avg data time: 5.71e+00, avg batch time: 7.1926, average train loss: 0.6214
[12/06 12:06:32 visual_prompt]: Inference (val):avg data time: 4.22e-05, avg batch time: 0.6046, average loss: 0.6259
[12/06 12:06:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 71.50	
[12/06 12:08:58 visual_prompt]: Inference (test):avg data time: 4.66e-05, avg batch time: 0.5979, average loss: 0.6482
[12/06 12:08:58 visual_prompt]: Classification results with test_mammo-cbis: top1: 64.50	rocauc: 69.11	
[12/06 12:08:58 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.42983495008466277
[12/06 12:17:24 visual_prompt]: Epoch 33 / 100: avg data time: 5.75e+00, avg batch time: 7.2305, average train loss: 0.5768
[12/06 12:18:22 visual_prompt]: Inference (val):avg data time: 5.84e-05, avg batch time: 0.5952, average loss: 0.9975
[12/06 12:18:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 72.42	
[12/06 12:20:47 visual_prompt]: Inference (test):avg data time: 4.74e-05, avg batch time: 0.5959, average loss: 1.1294
[12/06 12:20:47 visual_prompt]: Classification results with test_mammo-cbis: top1: 40.93	rocauc: 69.41	
[12/06 12:20:47 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.4236645926147493
[12/06 12:29:09 visual_prompt]: Epoch 34 / 100: avg data time: 5.70e+00, avg batch time: 7.1770, average train loss: 0.6209
[12/06 12:30:08 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.5957, average loss: 0.6798
[12/06 12:30:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.54	rocauc: 60.51	
[12/06 12:32:32 visual_prompt]: Inference (test):avg data time: 4.97e-05, avg batch time: 0.5982, average loss: 0.6939
[12/06 12:32:32 visual_prompt]: Classification results with test_mammo-cbis: top1: 53.64	rocauc: 56.15	
[12/06 12:32:32 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.41728265158971456
[12/06 12:40:56 visual_prompt]: Epoch 35 / 100: avg data time: 5.71e+00, avg batch time: 7.1926, average train loss: 0.6360
[12/06 12:41:54 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.6011, average loss: 0.6389
[12/06 12:41:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 75.17	
[12/06 12:44:18 visual_prompt]: Inference (test):avg data time: 5.14e-05, avg batch time: 0.5981, average loss: 0.6460
[12/06 12:44:18 visual_prompt]: Classification results with test_mammo-cbis: top1: 66.51	rocauc: 69.44	
[12/06 12:44:18 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.4106969024216348
[12/06 12:52:38 visual_prompt]: Epoch 36 / 100: avg data time: 5.67e+00, avg batch time: 7.1492, average train loss: 0.6488
[12/06 12:53:35 visual_prompt]: Inference (val):avg data time: 3.47e-05, avg batch time: 0.6044, average loss: 0.7041
[12/06 12:53:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 74.08	
[12/06 12:55:59 visual_prompt]: Inference (test):avg data time: 5.37e-05, avg batch time: 0.5993, average loss: 0.6684
[12/06 12:55:59 visual_prompt]: Classification results with test_mammo-cbis: top1: 66.36	rocauc: 69.83	
[12/06 12:55:59 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.40391536883141455
[12/06 13:04:21 visual_prompt]: Epoch 37 / 100: avg data time: 5.68e+00, avg batch time: 7.1667, average train loss: 0.5885
[12/06 13:05:19 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.5994, average loss: 0.6404
[12/06 13:05:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 74.68	
[12/06 13:07:43 visual_prompt]: Inference (test):avg data time: 5.47e-05, avg batch time: 0.6016, average loss: 0.6388
[12/06 13:07:43 visual_prompt]: Classification results with test_mammo-cbis: top1: 66.20	rocauc: 70.48	
[12/06 13:07:43 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.3969463130731183
[12/06 13:16:03 visual_prompt]: Epoch 38 / 100: avg data time: 5.66e+00, avg batch time: 7.1397, average train loss: 0.5805
[12/06 13:17:00 visual_prompt]: Inference (val):avg data time: 3.69e-05, avg batch time: 0.5968, average loss: 0.6922
[12/06 13:17:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 73.78	
[12/06 13:19:23 visual_prompt]: Inference (test):avg data time: 3.94e-05, avg batch time: 0.5969, average loss: 0.8059
[12/06 13:19:23 visual_prompt]: Classification results with test_mammo-cbis: top1: 56.74	rocauc: 70.17	
[12/06 13:19:23 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.3897982258676867
[12/06 13:27:44 visual_prompt]: Epoch 39 / 100: avg data time: 5.67e+00, avg batch time: 7.1479, average train loss: 0.6046
[12/06 13:28:41 visual_prompt]: Inference (val):avg data time: 3.64e-05, avg batch time: 0.5980, average loss: 0.6311
[12/06 13:28:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 72.58	
[12/06 13:31:06 visual_prompt]: Inference (test):avg data time: 5.54e-05, avg batch time: 0.5968, average loss: 0.7156
[12/06 13:31:06 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.38	rocauc: 67.95	
[12/06 13:31:06 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.3824798160583012
[12/06 13:39:27 visual_prompt]: Epoch 40 / 100: avg data time: 5.69e+00, avg batch time: 7.1638, average train loss: 0.5581
[12/06 13:40:25 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.5979, average loss: 0.6334
[12/06 13:40:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.89	rocauc: 74.08	
[12/06 13:42:49 visual_prompt]: Inference (test):avg data time: 4.68e-05, avg batch time: 0.5960, average loss: 0.7221
[12/06 13:42:49 visual_prompt]: Classification results with test_mammo-cbis: top1: 60.47	rocauc: 69.59	
[12/06 13:42:49 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.375
[12/06 13:51:10 visual_prompt]: Epoch 41 / 100: avg data time: 5.68e+00, avg batch time: 7.1613, average train loss: 0.5298
[12/06 13:52:07 visual_prompt]: Inference (val):avg data time: 3.82e-05, avg batch time: 0.5980, average loss: 0.6019
[12/06 13:52:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 69.11	rocauc: 73.44	
[12/06 13:54:32 visual_prompt]: Inference (test):avg data time: 4.36e-05, avg batch time: 0.5983, average loss: 0.6601
[12/06 13:54:32 visual_prompt]: Classification results with test_mammo-cbis: top1: 66.20	rocauc: 69.05	
[12/06 13:54:32 visual_prompt]: Best epoch 41: best metric: -0.602
[12/06 13:54:32 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.3673678906964727
[12/06 14:02:56 visual_prompt]: Epoch 42 / 100: avg data time: 5.70e+00, avg batch time: 7.1896, average train loss: 0.5500
[12/06 14:03:54 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.5997, average loss: 0.6842
[12/06 14:03:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 73.96	
[12/06 14:06:22 visual_prompt]: Inference (test):avg data time: 4.46e-05, avg batch time: 0.5993, average loss: 0.8246
[12/06 14:06:22 visual_prompt]: Classification results with test_mammo-cbis: top1: 56.59	rocauc: 67.59	
[12/06 14:06:22 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.35959278669726935
[12/06 14:15:03 visual_prompt]: Epoch 43 / 100: avg data time: 5.96e+00, avg batch time: 7.4341, average train loss: 0.5181
[12/06 14:16:01 visual_prompt]: Inference (val):avg data time: 4.21e-05, avg batch time: 0.5960, average loss: 0.6350
[12/06 14:16:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.89	rocauc: 73.68	
[12/06 14:18:33 visual_prompt]: Inference (test):avg data time: 4.89e-05, avg batch time: 0.5967, average loss: 0.6840
[12/06 14:18:33 visual_prompt]: Classification results with test_mammo-cbis: top1: 66.20	rocauc: 71.92	
[12/06 14:18:33 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.3516841607689501
[12/06 14:27:18 visual_prompt]: Epoch 44 / 100: avg data time: 6.01e+00, avg batch time: 7.4858, average train loss: 0.5588
[12/06 14:28:15 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.5923, average loss: 0.7695
[12/06 14:28:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 74.19	
[12/06 14:30:39 visual_prompt]: Inference (test):avg data time: 4.83e-05, avg batch time: 0.5975, average loss: 0.7514
[12/06 14:30:39 visual_prompt]: Classification results with test_mammo-cbis: top1: 65.89	rocauc: 69.55	
[12/06 14:30:39 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.34365164835397805
[12/06 14:39:01 visual_prompt]: Epoch 45 / 100: avg data time: 5.67e+00, avg batch time: 7.1547, average train loss: 0.5079
[12/06 14:39:58 visual_prompt]: Inference (val):avg data time: 5.39e-05, avg batch time: 0.5997, average loss: 0.7323
[12/06 14:39:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 72.70	
[12/06 14:42:22 visual_prompt]: Inference (test):avg data time: 4.24e-05, avg batch time: 0.6001, average loss: 0.8621
[12/06 14:42:22 visual_prompt]: Classification results with test_mammo-cbis: top1: 57.05	rocauc: 70.14	
[12/06 14:42:22 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.3355050358314172
[12/06 14:50:52 visual_prompt]: Epoch 46 / 100: avg data time: 5.81e+00, avg batch time: 7.2898, average train loss: 0.5123
[12/06 14:51:51 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.5962, average loss: 0.6454
[12/06 14:51:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 70.73	
[12/06 14:54:15 visual_prompt]: Inference (test):avg data time: 4.38e-05, avg batch time: 0.5999, average loss: 0.6990
[12/06 14:54:15 visual_prompt]: Classification results with test_mammo-cbis: top1: 60.62	rocauc: 67.27	
[12/06 14:54:15 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.32725424859373686
[12/06 15:02:35 visual_prompt]: Epoch 47 / 100: avg data time: 5.65e+00, avg batch time: 7.1313, average train loss: 0.4746
[12/06 15:03:33 visual_prompt]: Inference (val):avg data time: 3.71e-05, avg batch time: 0.6002, average loss: 0.6823
[12/06 15:03:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 67.92	
[12/06 15:05:57 visual_prompt]: Inference (test):avg data time: 4.28e-05, avg batch time: 0.5975, average loss: 0.7450
[12/06 15:05:57 visual_prompt]: Classification results with test_mammo-cbis: top1: 60.47	rocauc: 65.57	
[12/06 15:05:57 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.3189093389542498
[12/06 15:14:36 visual_prompt]: Epoch 48 / 100: avg data time: 5.94e+00, avg batch time: 7.4165, average train loss: 0.5014
[12/06 15:15:34 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.6035, average loss: 0.9861
[12/06 15:15:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 72.98	
[12/06 15:17:59 visual_prompt]: Inference (test):avg data time: 5.39e-05, avg batch time: 0.5987, average loss: 1.2332
[12/06 15:17:59 visual_prompt]: Classification results with test_mammo-cbis: top1: 49.77	rocauc: 64.41	
[12/06 15:17:59 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.3104804738999169
[12/06 15:26:23 visual_prompt]: Epoch 49 / 100: avg data time: 5.73e+00, avg batch time: 7.2043, average train loss: 0.4810
[12/06 15:27:21 visual_prompt]: Inference (val):avg data time: 3.84e-05, avg batch time: 0.5957, average loss: 0.9726
[12/06 15:27:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 73.39	
[12/06 15:29:47 visual_prompt]: Inference (test):avg data time: 5.64e-05, avg batch time: 0.5985, average loss: 1.2501
[12/06 15:29:47 visual_prompt]: Classification results with test_mammo-cbis: top1: 52.40	rocauc: 67.73	
[12/06 15:29:47 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.3019779227044398
[12/06 15:38:10 visual_prompt]: Epoch 50 / 100: avg data time: 5.71e+00, avg batch time: 7.1815, average train loss: 0.4533
[12/06 15:39:07 visual_prompt]: Inference (val):avg data time: 3.67e-05, avg batch time: 0.5977, average loss: 0.6755
[12/06 15:39:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 75.32	
[12/06 15:41:31 visual_prompt]: Inference (test):avg data time: 6.33e-05, avg batch time: 0.5961, average loss: 0.8536
[12/06 15:41:31 visual_prompt]: Classification results with test_mammo-cbis: top1: 60.93	rocauc: 67.24	
[12/06 15:41:31 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.29341204441673263
[12/06 15:48:56 visual_prompt]: Epoch 51 / 100: avg data time: 4.87e+00, avg batch time: 6.3541, average train loss: 0.4846
[12/06 15:49:45 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.5957, average loss: 0.8229
[12/06 15:49:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 71.39	
[12/06 15:51:50 visual_prompt]: Inference (test):avg data time: 3.67e-05, avg batch time: 0.5970, average loss: 0.7524
[12/06 15:51:50 visual_prompt]: Classification results with test_mammo-cbis: top1: 66.98	rocauc: 70.43	
[12/06 15:51:50 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.28479327524001635
[12/06 15:58:59 visual_prompt]: Epoch 52 / 100: avg data time: 4.65e+00, avg batch time: 6.1299, average train loss: 0.4625
[12/06 15:59:49 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.5908, average loss: 0.7721
[12/06 15:59:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 70.23	
[12/06 16:01:53 visual_prompt]: Inference (test):avg data time: 3.74e-05, avg batch time: 0.5948, average loss: 0.7533
[12/06 16:01:53 visual_prompt]: Classification results with test_mammo-cbis: top1: 66.05	rocauc: 69.10	
[12/06 16:01:53 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.2761321158169134
[12/06 16:09:03 visual_prompt]: Epoch 53 / 100: avg data time: 4.67e+00, avg batch time: 6.1421, average train loss: 0.4263
[12/06 16:09:52 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.5972, average loss: 0.7840
[12/06 16:09:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 72.68	
[12/06 16:11:56 visual_prompt]: Inference (test):avg data time: 3.77e-05, avg batch time: 0.5972, average loss: 0.7839
[12/06 16:11:56 visual_prompt]: Classification results with test_mammo-cbis: top1: 65.74	rocauc: 68.15	
[12/06 16:11:56 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.2674391184360313
[12/06 16:19:08 visual_prompt]: Epoch 54 / 100: avg data time: 4.69e+00, avg batch time: 6.1784, average train loss: 0.4488
[12/06 16:19:58 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.5996, average loss: 0.8531
[12/06 16:19:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 69.92	
[12/06 16:22:01 visual_prompt]: Inference (test):avg data time: 3.38e-05, avg batch time: 0.5986, average loss: 0.9505
[12/06 16:22:01 visual_prompt]: Classification results with test_mammo-cbis: top1: 60.93	rocauc: 67.25	
[12/06 16:22:01 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.2587248741756253
[12/06 16:29:13 visual_prompt]: Epoch 55 / 100: avg data time: 4.70e+00, avg batch time: 6.1726, average train loss: 0.4468
[12/06 16:30:02 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.5950, average loss: 0.7758
[12/06 16:30:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 70.41	
[12/06 16:32:05 visual_prompt]: Inference (test):avg data time: 3.40e-05, avg batch time: 0.5981, average loss: 0.8823
[12/06 16:32:05 visual_prompt]: Classification results with test_mammo-cbis: top1: 56.59	rocauc: 66.58	
[12/06 16:32:05 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.25
[12/06 16:39:16 visual_prompt]: Epoch 56 / 100: avg data time: 4.67e+00, avg batch time: 6.1563, average train loss: 0.4467
[12/06 16:40:06 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.5942, average loss: 0.9862
[12/06 16:40:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 73.72	
[12/06 16:42:10 visual_prompt]: Inference (test):avg data time: 3.48e-05, avg batch time: 0.5965, average loss: 1.2118
[12/06 16:42:10 visual_prompt]: Classification results with test_mammo-cbis: top1: 51.78	rocauc: 67.99	
[12/06 16:42:10 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.24127512582437483
[12/06 16:49:20 visual_prompt]: Epoch 57 / 100: avg data time: 4.67e+00, avg batch time: 6.1514, average train loss: 0.3857
[12/06 16:50:09 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.5964, average loss: 1.4230
[12/06 16:50:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 69.44	
[12/06 16:52:13 visual_prompt]: Inference (test):avg data time: 3.68e-05, avg batch time: 0.5941, average loss: 1.3330
[12/06 16:52:13 visual_prompt]: Classification results with test_mammo-cbis: top1: 60.31	rocauc: 65.35	
[12/06 16:52:13 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.23256088156396867
[12/06 16:59:23 visual_prompt]: Epoch 58 / 100: avg data time: 4.66e+00, avg batch time: 6.1355, average train loss: 0.4832
[12/06 17:00:12 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.5967, average loss: 0.7301
[12/06 17:00:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.07	rocauc: 71.51	
[12/06 17:02:15 visual_prompt]: Inference (test):avg data time: 4.01e-05, avg batch time: 0.5966, average loss: 0.7508
[12/06 17:02:15 visual_prompt]: Classification results with test_mammo-cbis: top1: 64.34	rocauc: 68.25	
[12/06 17:02:15 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.22386788418308667
[12/06 17:09:25 visual_prompt]: Epoch 59 / 100: avg data time: 4.66e+00, avg batch time: 6.1421, average train loss: 0.4258
[12/06 17:10:14 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.6002, average loss: 1.0003
[12/06 17:10:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 71.22	
[12/06 17:12:18 visual_prompt]: Inference (test):avg data time: 3.49e-05, avg batch time: 0.5932, average loss: 1.2085
[12/06 17:12:18 visual_prompt]: Classification results with test_mammo-cbis: top1: 52.87	rocauc: 65.38	
[12/06 17:12:18 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.2152067247599837
[12/06 17:19:27 visual_prompt]: Epoch 60 / 100: avg data time: 4.66e+00, avg batch time: 6.1392, average train loss: 0.4157
[12/06 17:20:17 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.5982, average loss: 0.8136
[12/06 17:20:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 68.29	rocauc: 70.30	
[12/06 17:22:20 visual_prompt]: Inference (test):avg data time: 3.66e-05, avg batch time: 0.5947, average loss: 0.8257
[12/06 17:22:20 visual_prompt]: Classification results with test_mammo-cbis: top1: 62.17	rocauc: 68.30	
[12/06 17:22:20 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.20658795558326742
[12/06 17:29:29 visual_prompt]: Epoch 61 / 100: avg data time: 4.65e+00, avg batch time: 6.1265, average train loss: 0.3557
[12/06 17:30:19 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.5931, average loss: 0.9977
[12/06 17:30:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 68.22	
[12/06 17:32:22 visual_prompt]: Inference (test):avg data time: 3.40e-05, avg batch time: 0.5990, average loss: 0.9020
[12/06 17:32:22 visual_prompt]: Classification results with test_mammo-cbis: top1: 65.43	rocauc: 69.33	
[12/06 17:32:22 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.1980220772955602
[12/06 17:39:33 visual_prompt]: Epoch 62 / 100: avg data time: 4.66e+00, avg batch time: 6.1535, average train loss: 0.3595
[12/06 17:40:22 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.6040, average loss: 1.0049
[12/06 17:40:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.89	rocauc: 72.55	
[12/06 17:42:26 visual_prompt]: Inference (test):avg data time: 3.85e-05, avg batch time: 0.5985, average loss: 1.2063
[12/06 17:42:26 visual_prompt]: Classification results with test_mammo-cbis: top1: 60.78	rocauc: 67.75	
[12/06 17:42:26 visual_prompt]: Stopping early.
[12/06 17:42:26 visual_prompt]: Rank of current process: 0. World size: 1
[12/06 17:42:26 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[12/06 17:42:26 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[12/06 17:42:26 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[12/06 17:42:26 visual_prompt]: Training with config:
[12/06 17:42:26 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/test/seed3172/lr0.5_wd0.0001/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 3172, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[12/06 17:42:26 visual_prompt]: Loading training data...
[12/06 17:42:26 visual_prompt]: Constructing mammo-cbis dataset train...
[12/06 17:42:26 visual_prompt]: Loading validation data...
[12/06 17:42:26 visual_prompt]: Constructing mammo-cbis dataset val...
[12/06 17:42:26 visual_prompt]: Loading test data...
[12/06 17:42:26 visual_prompt]: Constructing mammo-cbis dataset test...
[12/06 17:42:26 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[12/06 17:42:29 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[12/06 17:42:29 visual_prompt]: tuned percent:0.532
[12/06 17:42:29 visual_prompt]: Device used for model: 0
[12/06 17:42:29 visual_prompt]: Setting up Evaluator...
[12/06 17:42:29 visual_prompt]: Setting up Trainer...
[12/06 17:42:29 visual_prompt]: 	Setting up the optimizer...
[12/06 17:42:29 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[12/06 17:49:40 visual_prompt]: Epoch 1 / 100: avg data time: 4.68e+00, avg batch time: 6.1566, average train loss: 1.0702
[12/06 17:50:29 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.5958, average loss: 1.0277
[12/06 17:50:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 44.72	rocauc: 50.42	
[12/06 17:52:32 visual_prompt]: Inference (test):avg data time: 3.46e-05, avg batch time: 0.5982, average loss: 1.0873
[12/06 17:52:32 visual_prompt]: Classification results with test_mammo-cbis: top1: 41.24	rocauc: 47.79	
[12/06 17:52:32 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.05
[12/06 17:59:41 visual_prompt]: Epoch 2 / 100: avg data time: 4.66e+00, avg batch time: 6.1356, average train loss: 1.0250
[12/06 18:00:30 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.5956, average loss: 0.6851
[12/06 18:00:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 53.82	
[12/06 18:02:33 visual_prompt]: Inference (test):avg data time: 3.26e-05, avg batch time: 0.5989, average loss: 0.6712
[12/06 18:02:33 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.69	rocauc: 57.02	
[12/06 18:02:33 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.1
[12/06 18:09:43 visual_prompt]: Epoch 3 / 100: avg data time: 4.65e+00, avg batch time: 6.1306, average train loss: 0.7116
[12/06 18:10:32 visual_prompt]: Inference (val):avg data time: 2.11e-05, avg batch time: 0.6016, average loss: 0.6806
[12/06 18:10:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.93	
[12/06 18:12:35 visual_prompt]: Inference (test):avg data time: 3.50e-05, avg batch time: 0.5971, average loss: 0.6783
[12/06 18:12:35 visual_prompt]: Classification results with test_mammo-cbis: top1: 58.60	rocauc: 58.99	
[12/06 18:12:35 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.15
[12/06 18:19:45 visual_prompt]: Epoch 4 / 100: avg data time: 4.67e+00, avg batch time: 6.1409, average train loss: 0.7360
[12/06 18:20:35 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.5971, average loss: 0.6790
[12/06 18:20:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 58.87	
[12/06 18:22:38 visual_prompt]: Inference (test):avg data time: 3.56e-05, avg batch time: 0.5960, average loss: 0.6653
[12/06 18:22:38 visual_prompt]: Classification results with test_mammo-cbis: top1: 60.00	rocauc: 60.14	
[12/06 18:22:38 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.2
[12/06 18:31:13 visual_prompt]: Epoch 5 / 100: avg data time: 5.88e+00, avg batch time: 7.3589, average train loss: 0.7267
[12/06 18:32:27 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.5948, average loss: 0.8590
[12/06 18:32:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.78	
[12/06 18:35:58 visual_prompt]: Inference (test):avg data time: 3.32e-05, avg batch time: 0.5977, average loss: 0.9082
[12/06 18:35:58 visual_prompt]: Classification results with test_mammo-cbis: top1: 40.93	rocauc: 61.86	
[12/06 18:35:58 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.25
[12/06 18:44:38 visual_prompt]: Epoch 6 / 100: avg data time: 5.95e+00, avg batch time: 7.4305, average train loss: 0.7617
[12/06 18:45:28 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.5978, average loss: 0.6965
[12/06 18:45:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 48.78	rocauc: 61.11	
[12/06 18:47:35 visual_prompt]: Inference (test):avg data time: 3.74e-05, avg batch time: 0.5974, average loss: 0.7085
[12/06 18:47:35 visual_prompt]: Classification results with test_mammo-cbis: top1: 43.88	rocauc: 62.96	
[12/06 18:47:35 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.3
[12/06 18:54:55 visual_prompt]: Epoch 7 / 100: avg data time: 4.81e+00, avg batch time: 6.2934, average train loss: 0.9231
[12/06 18:55:46 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.5994, average loss: 0.7134
[12/06 18:55:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.17	
