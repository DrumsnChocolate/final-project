/bin/bash: /home/s1952889/miniconda3/envs/prompt/lib/libtinfo.so.6: no version information available (required by /bin/bash)
An exception occurred in telemetry logging.Disabling telemetry to prevent further exceptions.
Traceback (most recent call last):
  File "/home/s1952889/miniconda3/envs/prompt/lib/python3.11/site-packages/iopath/common/file_io.py", line 946, in __log_tmetry_keys
    handler.log_event()
  File "/home/s1952889/miniconda3/envs/prompt/lib/python3.11/site-packages/iopath/common/event_logger.py", line 97, in log_event
    del self._evt
        ^^^^^^^^^
AttributeError: 'NativePathHandler' object has no attribute '_evt'
Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss', 'RECORD_GPU_SNAPSHOT', 'True'])
[11/28 13:02:35 visual_prompt]: Rank of current process: 0. World size: 1
[11/28 13:02:37 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA TITAN Xp
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/28 13:02:37 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss', 'RECORD_GPU_SNAPSHOT', 'True'])
[11/28 13:02:37 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/28 13:02:37 visual_prompt]: Training with config:
[11/28 13:02:37 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr50.0_wd0.01/patience7/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 50.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True}), 'RECORD_GPU_SNAPSHOT': True})
[11/28 13:02:37 visual_prompt]: Loading training data...
[11/28 13:02:37 visual_prompt]: Constructing mammo-cbis dataset train...
[11/28 13:02:37 visual_prompt]: Loading validation data...
[11/28 13:02:37 visual_prompt]: Constructing mammo-cbis dataset val...
[11/28 13:02:37 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[11/28 13:02:42 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[11/28 13:02:42 visual_prompt]: tuned percent:0.536
[11/28 13:02:42 visual_prompt]: Device used for model: 0
[11/28 13:02:42 visual_prompt]: Setting up Evaluator...
[11/28 13:02:42 visual_prompt]: Setting up Trainer...
[11/28 13:02:42 visual_prompt]: 	Setting up the optimizer...
[11/28 13:02:42 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/28 13:10:28 visual_prompt]: Epoch 1 / 100: avg data time: 1.23e+01, avg batch time: 13.3108, average train loss: 1.4006
[11/28 13:11:21 visual_prompt]: Inference (val):avg data time: 4.32e-05, avg batch time: 0.5242, average loss: 1.2969
[11/28 13:11:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[11/28 13:11:21 visual_prompt]: Training 2 / 100 epoch, with learning rate 5.0
[11/28 13:18:58 visual_prompt]: Epoch 2 / 100: avg data time: 1.22e+01, avg batch time: 13.0800, average train loss: 47.2207
[11/28 13:19:52 visual_prompt]: Inference (val):avg data time: 6.48e-05, avg batch time: 0.5251, average loss: 21.1442
[11/28 13:19:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.51	
[11/28 13:19:52 visual_prompt]: Training 3 / 100 epoch, with learning rate 10.0
[11/28 13:27:29 visual_prompt]: Epoch 3 / 100: avg data time: 1.22e+01, avg batch time: 13.0468, average train loss: 21.4057
[11/28 13:28:21 visual_prompt]: Inference (val):avg data time: 4.68e-05, avg batch time: 0.5291, average loss: 7.6746
[11/28 13:28:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.11	
[11/28 13:28:21 visual_prompt]: Training 4 / 100 epoch, with learning rate 15.0
[11/28 13:35:57 visual_prompt]: Epoch 4 / 100: avg data time: 1.22e+01, avg batch time: 13.0292, average train loss: 25.2795
[11/28 13:36:48 visual_prompt]: Inference (val):avg data time: 4.09e-05, avg batch time: 0.5243, average loss: 29.5045
[11/28 13:36:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.18	
[11/28 13:36:48 visual_prompt]: Training 5 / 100 epoch, with learning rate 20.0
[11/28 13:44:09 visual_prompt]: Epoch 5 / 100: avg data time: 1.17e+01, avg batch time: 12.5918, average train loss: 35.3392
[11/28 13:45:00 visual_prompt]: Inference (val):avg data time: 3.53e-05, avg batch time: 0.5223, average loss: 40.5801
[11/28 13:45:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.15	
[11/28 13:45:00 visual_prompt]: Training 6 / 100 epoch, with learning rate 25.0
[11/28 13:52:32 visual_prompt]: Epoch 6 / 100: avg data time: 1.20e+01, avg batch time: 12.9069, average train loss: 75.6072
[11/28 13:53:25 visual_prompt]: Inference (val):avg data time: 3.82e-05, avg batch time: 0.5254, average loss: 46.1451
[11/28 13:53:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.12	
[11/28 13:53:25 visual_prompt]: Training 7 / 100 epoch, with learning rate 30.0
[11/28 14:01:05 visual_prompt]: Epoch 7 / 100: avg data time: 1.23e+01, avg batch time: 13.1256, average train loss: 64.3204
[11/28 14:01:57 visual_prompt]: Inference (val):avg data time: 3.90e-05, avg batch time: 0.5261, average loss: 126.3663
[11/28 14:01:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.34	
[11/28 14:01:57 visual_prompt]: Training 8 / 100 epoch, with learning rate 35.0
[11/28 14:09:33 visual_prompt]: Epoch 8 / 100: avg data time: 1.22e+01, avg batch time: 13.0153, average train loss: 84.2415
[11/28 14:10:26 visual_prompt]: Inference (val):avg data time: 3.67e-05, avg batch time: 0.5233, average loss: 21.1667
[11/28 14:10:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 44.31	rocauc: 48.56	
[11/28 14:10:26 visual_prompt]: Training 9 / 100 epoch, with learning rate 40.0
[11/28 14:18:04 visual_prompt]: Epoch 9 / 100: avg data time: 1.22e+01, avg batch time: 13.0813, average train loss: 122.1390
[11/28 14:18:57 visual_prompt]: Inference (val):avg data time: 5.14e-05, avg batch time: 0.5257, average loss: 82.8475
[11/28 14:18:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.13	
[11/28 14:18:57 visual_prompt]: Training 10 / 100 epoch, with learning rate 45.0
[11/28 14:26:36 visual_prompt]: Epoch 10 / 100: avg data time: 1.22e+01, avg batch time: 13.0973, average train loss: 89.4662
[11/28 14:27:28 visual_prompt]: Inference (val):avg data time: 4.85e-05, avg batch time: 0.5237, average loss: 129.9683
[11/28 14:27:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 42.94	
[11/28 14:27:28 visual_prompt]: Training 11 / 100 epoch, with learning rate 50.0
[11/28 14:35:05 visual_prompt]: Epoch 11 / 100: avg data time: 1.22e+01, avg batch time: 13.0445, average train loss: 121.1973
[11/28 14:35:58 visual_prompt]: Inference (val):avg data time: 4.36e-05, avg batch time: 0.5317, average loss: 28.3087
[11/28 14:35:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.33	
[11/28 14:35:58 visual_prompt]: Training 12 / 100 epoch, with learning rate 49.9847706754774
[11/28 14:43:36 visual_prompt]: Epoch 12 / 100: avg data time: 1.22e+01, avg batch time: 13.0813, average train loss: 118.6507
[11/28 14:44:29 visual_prompt]: Inference (val):avg data time: 5.65e-05, avg batch time: 0.5272, average loss: 4.7298
[11/28 14:44:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.62	
[11/28 14:44:29 visual_prompt]: Best epoch 12: best metric: -4.730
[11/28 14:44:29 visual_prompt]: Training 13 / 100 epoch, with learning rate 49.939101256495604
[11/28 14:51:55 visual_prompt]: Epoch 13 / 100: avg data time: 1.19e+01, avg batch time: 12.7233, average train loss: 99.8405
[11/28 14:52:46 visual_prompt]: Inference (val):avg data time: 5.61e-05, avg batch time: 0.5276, average loss: 268.0182
[11/28 14:52:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 41.27	
[11/28 14:52:46 visual_prompt]: Training 14 / 100 epoch, with learning rate 49.86304738420683
[11/28 15:00:08 visual_prompt]: Epoch 14 / 100: avg data time: 1.18e+01, avg batch time: 12.6203, average train loss: 128.8177
[11/28 15:00:59 visual_prompt]: Inference (val):avg data time: 4.91e-05, avg batch time: 0.5279, average loss: 32.0419
[11/28 15:00:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.65	
[11/28 15:00:59 visual_prompt]: Training 15 / 100 epoch, with learning rate 49.75670171853926
[11/28 15:08:22 visual_prompt]: Epoch 15 / 100: avg data time: 1.18e+01, avg batch time: 12.6469, average train loss: 143.5749
[11/28 15:09:13 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.5283, average loss: 5.4027
[11/28 15:09:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.66	
[11/28 15:09:13 visual_prompt]: Training 16 / 100 epoch, with learning rate 49.6201938253052
[11/28 15:16:35 visual_prompt]: Epoch 16 / 100: avg data time: 1.18e+01, avg batch time: 12.6235, average train loss: 153.1298
[11/28 15:17:29 visual_prompt]: Inference (val):avg data time: 4.33e-05, avg batch time: 0.5252, average loss: 64.2137
[11/28 15:17:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.48	
[11/28 15:17:29 visual_prompt]: Training 17 / 100 epoch, with learning rate 49.45369001834514
[11/28 15:25:20 visual_prompt]: Epoch 17 / 100: avg data time: 1.26e+01, avg batch time: 13.4737, average train loss: 122.3338
[11/28 15:26:14 visual_prompt]: Inference (val):avg data time: 5.26e-05, avg batch time: 0.5271, average loss: 93.1703
[11/28 15:26:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.70	
[11/28 15:26:14 visual_prompt]: Training 18 / 100 epoch, with learning rate 49.25739315689991
[11/28 15:33:54 visual_prompt]: Epoch 18 / 100: avg data time: 1.23e+01, avg batch time: 13.1486, average train loss: 141.9983
[11/28 15:34:47 visual_prompt]: Inference (val):avg data time: 5.05e-05, avg batch time: 0.5298, average loss: 13.3476
[11/28 15:34:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.66	
[11/28 15:34:47 visual_prompt]: Training 19 / 100 epoch, with learning rate 49.03154239845797
[11/28 15:42:23 visual_prompt]: Epoch 19 / 100: avg data time: 1.22e+01, avg batch time: 13.0358, average train loss: 107.0472
[11/28 15:43:16 visual_prompt]: Inference (val):avg data time: 4.91e-05, avg batch time: 0.5259, average loss: 40.1287
[11/28 15:43:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.11	
[11/28 15:43:16 visual_prompt]: Stopping early.
[11/28 15:43:17 visual_prompt]: Rank of current process: 0. World size: 1
[11/28 15:43:17 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA TITAN Xp
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/28 15:43:17 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss', 'RECORD_GPU_SNAPSHOT', 'True'])
[11/28 15:43:17 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/28 15:43:17 visual_prompt]: Training with config:
[11/28 15:43:17 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr50.0_wd0.001/patience7/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 50.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True}), 'RECORD_GPU_SNAPSHOT': True})
[11/28 15:43:17 visual_prompt]: Loading training data...
[11/28 15:43:17 visual_prompt]: Constructing mammo-cbis dataset train...
[11/28 15:43:17 visual_prompt]: Loading validation data...
[11/28 15:43:17 visual_prompt]: Constructing mammo-cbis dataset val...
[11/28 15:43:17 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[11/28 15:43:24 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[11/28 15:43:24 visual_prompt]: tuned percent:0.536
[11/28 15:43:24 visual_prompt]: Device used for model: 0
[11/28 15:43:24 visual_prompt]: Setting up Evaluator...
[11/28 15:43:24 visual_prompt]: Setting up Trainer...
[11/28 15:43:24 visual_prompt]: 	Setting up the optimizer...
[11/28 15:43:24 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/28 15:51:03 visual_prompt]: Epoch 1 / 100: avg data time: 1.22e+01, avg batch time: 13.0873, average train loss: 1.4006
[11/28 15:51:56 visual_prompt]: Inference (val):avg data time: 5.67e-05, avg batch time: 0.5190, average loss: 1.2969
[11/28 15:51:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[11/28 15:51:56 visual_prompt]: Training 2 / 100 epoch, with learning rate 5.0
[11/28 15:59:33 visual_prompt]: Epoch 2 / 100: avg data time: 1.22e+01, avg batch time: 13.0687, average train loss: 27.0155
[11/28 16:00:26 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.5263, average loss: 10.3730
[11/28 16:00:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.98	
[11/28 16:00:26 visual_prompt]: Training 3 / 100 epoch, with learning rate 10.0
[11/28 16:08:04 visual_prompt]: Epoch 3 / 100: avg data time: 1.22e+01, avg batch time: 13.0786, average train loss: 24.1599
[11/28 16:08:57 visual_prompt]: Inference (val):avg data time: 4.05e-05, avg batch time: 0.5213, average loss: 43.2925
[11/28 16:08:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.26	
[11/28 16:08:57 visual_prompt]: Training 4 / 100 epoch, with learning rate 15.0
[11/28 16:16:35 visual_prompt]: Epoch 4 / 100: avg data time: 1.22e+01, avg batch time: 13.0830, average train loss: 28.1329
[11/28 16:17:29 visual_prompt]: Inference (val):avg data time: 5.29e-05, avg batch time: 0.5211, average loss: 34.0368
[11/28 16:17:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.94	
[11/28 16:17:29 visual_prompt]: Training 5 / 100 epoch, with learning rate 20.0
[11/28 16:24:52 visual_prompt]: Epoch 5 / 100: avg data time: 1.18e+01, avg batch time: 12.6551, average train loss: 38.8075
[11/28 16:25:43 visual_prompt]: Inference (val):avg data time: 3.93e-05, avg batch time: 0.5248, average loss: 24.0847
[11/28 16:25:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.62	
[11/28 16:25:43 visual_prompt]: Training 6 / 100 epoch, with learning rate 25.0
[11/28 16:33:06 visual_prompt]: Epoch 6 / 100: avg data time: 1.18e+01, avg batch time: 12.6612, average train loss: 68.2230
[11/28 16:33:58 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.5216, average loss: 4.7247
[11/28 16:33:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.24	
[11/28 16:33:58 visual_prompt]: Training 7 / 100 epoch, with learning rate 30.0
[11/28 16:41:21 visual_prompt]: Epoch 7 / 100: avg data time: 1.18e+01, avg batch time: 12.6686, average train loss: 68.6292
[11/28 16:42:13 visual_prompt]: Inference (val):avg data time: 5.39e-05, avg batch time: 0.5296, average loss: 267.1232
[11/28 16:42:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 45.87	
[11/28 16:42:13 visual_prompt]: Training 8 / 100 epoch, with learning rate 35.0
[11/28 16:49:36 visual_prompt]: Epoch 8 / 100: avg data time: 1.18e+01, avg batch time: 12.6435, average train loss: 117.2350
[11/28 16:50:27 visual_prompt]: Inference (val):avg data time: 4.01e-05, avg batch time: 0.5250, average loss: 28.0913
[11/28 16:50:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.17	
[11/28 16:50:27 visual_prompt]: Training 9 / 100 epoch, with learning rate 40.0
[11/28 16:57:51 visual_prompt]: Epoch 9 / 100: avg data time: 1.18e+01, avg batch time: 12.6781, average train loss: 78.8698
[11/28 16:58:42 visual_prompt]: Inference (val):avg data time: 4.56e-05, avg batch time: 0.5278, average loss: 38.8818
[11/28 16:58:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.94	
[11/28 16:58:42 visual_prompt]: Training 10 / 100 epoch, with learning rate 45.0
[11/28 17:06:05 visual_prompt]: Epoch 10 / 100: avg data time: 1.18e+01, avg batch time: 12.6438, average train loss: 74.8236
[11/28 17:06:56 visual_prompt]: Inference (val):avg data time: 3.58e-05, avg batch time: 0.5228, average loss: 67.9963
[11/28 17:06:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 42.31	
[11/28 17:06:56 visual_prompt]: Training 11 / 100 epoch, with learning rate 50.0
[11/28 17:14:35 visual_prompt]: Epoch 11 / 100: avg data time: 1.23e+01, avg batch time: 13.1247, average train loss: 79.9933
[11/28 17:15:34 visual_prompt]: Inference (val):avg data time: 4.92e-05, avg batch time: 0.5217, average loss: 158.3058
[11/28 17:15:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.29	
[11/28 17:15:34 visual_prompt]: Training 12 / 100 epoch, with learning rate 49.9847706754774
[11/28 17:23:30 visual_prompt]: Epoch 12 / 100: avg data time: 1.27e+01, avg batch time: 13.5888, average train loss: 107.5670
[11/28 17:24:23 visual_prompt]: Inference (val):avg data time: 3.78e-05, avg batch time: 0.5200, average loss: 46.9732
[11/28 17:24:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.28	
[11/28 17:24:23 visual_prompt]: Best epoch 12: best metric: -46.973
[11/28 17:24:23 visual_prompt]: Training 13 / 100 epoch, with learning rate 49.939101256495604
[11/28 17:32:05 visual_prompt]: Epoch 13 / 100: avg data time: 1.23e+01, avg batch time: 13.1909, average train loss: 183.5818
[11/28 17:33:02 visual_prompt]: Inference (val):avg data time: 5.29e-05, avg batch time: 0.5189, average loss: 55.5075
[11/28 17:33:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.34	
[11/28 17:33:02 visual_prompt]: Training 14 / 100 epoch, with learning rate 49.86304738420683
[11/28 17:40:44 visual_prompt]: Epoch 14 / 100: avg data time: 1.23e+01, avg batch time: 13.2149, average train loss: 126.3127
[11/28 17:41:37 visual_prompt]: Inference (val):avg data time: 5.20e-05, avg batch time: 0.5253, average loss: 63.5713
[11/28 17:41:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.71	
[11/28 17:41:37 visual_prompt]: Training 15 / 100 epoch, with learning rate 49.75670171853926
[11/28 17:49:28 visual_prompt]: Epoch 15 / 100: avg data time: 1.26e+01, avg batch time: 13.4370, average train loss: 131.3694
[11/28 17:50:22 visual_prompt]: Inference (val):avg data time: 5.95e-05, avg batch time: 0.5237, average loss: 136.1798
[11/28 17:50:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.79	
[11/28 17:50:22 visual_prompt]: Training 16 / 100 epoch, with learning rate 49.6201938253052
[11/28 17:58:12 visual_prompt]: Epoch 16 / 100: avg data time: 1.26e+01, avg batch time: 13.4231, average train loss: 105.8246
[11/28 17:59:06 visual_prompt]: Inference (val):avg data time: 6.04e-05, avg batch time: 0.5205, average loss: 209.0344
[11/28 17:59:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.94	
[11/28 17:59:06 visual_prompt]: Training 17 / 100 epoch, with learning rate 49.45369001834514
[11/28 18:06:46 visual_prompt]: Epoch 17 / 100: avg data time: 1.23e+01, avg batch time: 13.1359, average train loss: 186.2917
[11/28 18:07:39 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.5223, average loss: 115.1705
[11/28 18:07:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 41.51	
[11/28 18:07:39 visual_prompt]: Training 18 / 100 epoch, with learning rate 49.25739315689991
[11/28 18:15:19 visual_prompt]: Epoch 18 / 100: avg data time: 1.23e+01, avg batch time: 13.1232, average train loss: 120.0132
[11/28 18:16:12 visual_prompt]: Inference (val):avg data time: 4.80e-05, avg batch time: 0.5297, average loss: 433.3973
[11/28 18:16:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.83	
[11/28 18:16:12 visual_prompt]: Training 19 / 100 epoch, with learning rate 49.03154239845797
[11/28 18:23:50 visual_prompt]: Epoch 19 / 100: avg data time: 1.22e+01, avg batch time: 13.0752, average train loss: 168.5670
[11/28 18:24:43 visual_prompt]: Inference (val):avg data time: 4.05e-05, avg batch time: 0.5180, average loss: 122.0169
[11/28 18:24:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.69	
[11/28 18:24:43 visual_prompt]: Stopping early.
[11/28 18:24:44 visual_prompt]: Rank of current process: 0. World size: 1
[11/28 18:24:44 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA TITAN Xp
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/28 18:24:44 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss', 'RECORD_GPU_SNAPSHOT', 'True'])
[11/28 18:24:44 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/28 18:24:44 visual_prompt]: Training with config:
[11/28 18:24:44 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr50.0_wd0.0001/patience7/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 50.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True}), 'RECORD_GPU_SNAPSHOT': True})
[11/28 18:24:44 visual_prompt]: Loading training data...
[11/28 18:24:44 visual_prompt]: Constructing mammo-cbis dataset train...
[11/28 18:24:44 visual_prompt]: Loading validation data...
[11/28 18:24:44 visual_prompt]: Constructing mammo-cbis dataset val...
[11/28 18:24:44 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[11/28 18:24:52 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[11/28 18:24:52 visual_prompt]: tuned percent:0.536
[11/28 18:24:52 visual_prompt]: Device used for model: 0
[11/28 18:24:52 visual_prompt]: Setting up Evaluator...
[11/28 18:24:52 visual_prompt]: Setting up Trainer...
[11/28 18:24:52 visual_prompt]: 	Setting up the optimizer...
[11/28 18:24:52 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/28 18:32:32 visual_prompt]: Epoch 1 / 100: avg data time: 1.23e+01, avg batch time: 13.1347, average train loss: 1.4006
[11/28 18:33:25 visual_prompt]: Inference (val):avg data time: 5.54e-05, avg batch time: 0.5266, average loss: 1.2969
[11/28 18:33:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[11/28 18:33:25 visual_prompt]: Training 2 / 100 epoch, with learning rate 5.0
[11/28 18:41:01 visual_prompt]: Epoch 2 / 100: avg data time: 1.21e+01, avg batch time: 13.0241, average train loss: 21.6884
[11/28 18:41:53 visual_prompt]: Inference (val):avg data time: 4.69e-05, avg batch time: 0.5245, average loss: 1.0083
[11/28 18:41:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 49.59	rocauc: 57.03	
[11/28 18:41:53 visual_prompt]: Training 3 / 100 epoch, with learning rate 10.0
[11/28 18:49:17 visual_prompt]: Epoch 3 / 100: avg data time: 1.18e+01, avg batch time: 12.6746, average train loss: 38.6201
[11/28 18:50:08 visual_prompt]: Inference (val):avg data time: 3.73e-05, avg batch time: 0.5262, average loss: 0.7869
[11/28 18:50:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 50.00	rocauc: 57.16	
[11/28 18:50:08 visual_prompt]: Training 4 / 100 epoch, with learning rate 15.0
[11/28 18:57:31 visual_prompt]: Epoch 4 / 100: avg data time: 1.18e+01, avg batch time: 12.6495, average train loss: 16.9552
[11/28 18:58:22 visual_prompt]: Inference (val):avg data time: 5.10e-05, avg batch time: 0.5294, average loss: 5.0919
[11/28 18:58:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.75	
[11/28 18:58:22 visual_prompt]: Training 5 / 100 epoch, with learning rate 20.0
[11/28 19:05:45 visual_prompt]: Epoch 5 / 100: avg data time: 1.18e+01, avg batch time: 12.6359, average train loss: 19.9032
[11/28 19:06:37 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.5256, average loss: 45.1114
[11/28 19:06:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.01	
[11/28 19:06:37 visual_prompt]: Training 6 / 100 epoch, with learning rate 25.0
[11/28 19:14:00 visual_prompt]: Epoch 6 / 100: avg data time: 1.18e+01, avg batch time: 12.6673, average train loss: 35.5889
[11/28 19:14:52 visual_prompt]: Inference (val):avg data time: 4.69e-05, avg batch time: 0.5245, average loss: 26.3993
[11/28 19:14:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.96	
[11/28 19:14:52 visual_prompt]: Training 7 / 100 epoch, with learning rate 30.0
[11/28 19:22:15 visual_prompt]: Epoch 7 / 100: avg data time: 1.18e+01, avg batch time: 12.6575, average train loss: 31.7600
[11/28 19:23:06 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.5281, average loss: 42.0422
[11/28 19:23:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 40.99	
[11/28 19:23:06 visual_prompt]: Training 8 / 100 epoch, with learning rate 35.0
[11/28 19:30:29 visual_prompt]: Epoch 8 / 100: avg data time: 1.18e+01, avg batch time: 12.6394, average train loss: 91.7362
[11/28 19:31:20 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.5254, average loss: 71.1311
[11/28 19:31:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.15	
[11/28 19:31:20 visual_prompt]: Training 9 / 100 epoch, with learning rate 40.0
[11/28 19:38:44 visual_prompt]: Epoch 9 / 100: avg data time: 1.18e+01, avg batch time: 12.6765, average train loss: 88.7644
[11/28 19:39:36 visual_prompt]: Inference (val):avg data time: 4.53e-05, avg batch time: 0.5286, average loss: 27.8329
[11/28 19:39:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.10	
[11/28 19:39:36 visual_prompt]: Training 10 / 100 epoch, with learning rate 45.0
[11/28 19:46:59 visual_prompt]: Epoch 10 / 100: avg data time: 1.18e+01, avg batch time: 12.6570, average train loss: 91.6330
[11/28 19:47:51 visual_prompt]: Inference (val):avg data time: 4.36e-05, avg batch time: 0.5357, average loss: 92.8379
[11/28 19:47:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.37	
[11/28 19:47:51 visual_prompt]: Training 11 / 100 epoch, with learning rate 50.0
[11/28 19:55:13 visual_prompt]: Epoch 11 / 100: avg data time: 1.18e+01, avg batch time: 12.6410, average train loss: 123.4984
[11/28 19:56:05 visual_prompt]: Inference (val):avg data time: 3.58e-05, avg batch time: 0.5290, average loss: 14.5397
[11/28 19:56:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.09	
[11/28 19:56:05 visual_prompt]: Training 12 / 100 epoch, with learning rate 49.9847706754774
[11/28 20:03:28 visual_prompt]: Epoch 12 / 100: avg data time: 1.18e+01, avg batch time: 12.6427, average train loss: 93.7713
[11/28 20:04:19 visual_prompt]: Inference (val):avg data time: 3.76e-05, avg batch time: 0.5266, average loss: 33.3844
[11/28 20:04:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.21	
[11/28 20:04:19 visual_prompt]: Training 13 / 100 epoch, with learning rate 49.939101256495604
[11/28 20:11:42 visual_prompt]: Epoch 13 / 100: avg data time: 1.18e+01, avg batch time: 12.6512, average train loss: 204.6375
[11/28 20:12:33 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.5221, average loss: 87.7408
[11/28 20:12:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.99	
[11/28 20:12:33 visual_prompt]: Training 14 / 100 epoch, with learning rate 49.86304738420683
[11/28 20:19:56 visual_prompt]: Epoch 14 / 100: avg data time: 1.18e+01, avg batch time: 12.6374, average train loss: 86.7965
[11/28 20:20:47 visual_prompt]: Inference (val):avg data time: 5.54e-05, avg batch time: 0.5251, average loss: 96.9401
[11/28 20:20:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 39.79	
[11/28 20:20:47 visual_prompt]: Training 15 / 100 epoch, with learning rate 49.75670171853926
[11/28 20:28:12 visual_prompt]: Epoch 15 / 100: avg data time: 1.18e+01, avg batch time: 12.6895, average train loss: 101.9606
[11/28 20:29:03 visual_prompt]: Inference (val):avg data time: 4.65e-05, avg batch time: 0.5222, average loss: 15.5796
[11/28 20:29:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.35	
[11/28 20:29:04 visual_prompt]: Training 16 / 100 epoch, with learning rate 49.6201938253052
[11/28 20:36:27 visual_prompt]: Epoch 16 / 100: avg data time: 1.18e+01, avg batch time: 12.6629, average train loss: 108.8948
[11/28 20:37:18 visual_prompt]: Inference (val):avg data time: 4.99e-05, avg batch time: 0.5302, average loss: 10.1484
[11/28 20:37:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.41	
[11/28 20:37:18 visual_prompt]: Best epoch 16: best metric: -10.148
[11/28 20:37:18 visual_prompt]: Training 17 / 100 epoch, with learning rate 49.45369001834514
[11/28 20:44:41 visual_prompt]: Epoch 17 / 100: avg data time: 1.18e+01, avg batch time: 12.6468, average train loss: 140.4017
[11/28 20:45:33 visual_prompt]: Inference (val):avg data time: 4.47e-05, avg batch time: 0.5317, average loss: 28.2596
[11/28 20:45:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.51	
[11/28 20:45:33 visual_prompt]: Training 18 / 100 epoch, with learning rate 49.25739315689991
[11/28 20:52:56 visual_prompt]: Epoch 18 / 100: avg data time: 1.18e+01, avg batch time: 12.6516, average train loss: 76.1672
[11/28 20:53:47 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.5318, average loss: 94.7159
[11/28 20:53:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.16	
[11/28 20:53:47 visual_prompt]: Training 19 / 100 epoch, with learning rate 49.03154239845797
[11/28 21:01:10 visual_prompt]: Epoch 19 / 100: avg data time: 1.18e+01, avg batch time: 12.6417, average train loss: 77.4839
[11/28 21:02:01 visual_prompt]: Inference (val):avg data time: 6.13e-05, avg batch time: 0.5278, average loss: 48.5832
[11/28 21:02:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.16	
[11/28 21:02:01 visual_prompt]: Training 20 / 100 epoch, with learning rate 48.77641290737884
[11/28 21:09:24 visual_prompt]: Epoch 20 / 100: avg data time: 1.18e+01, avg batch time: 12.6449, average train loss: 74.0089
[11/28 21:10:16 visual_prompt]: Inference (val):avg data time: 5.84e-05, avg batch time: 0.5299, average loss: 73.6098
[11/28 21:10:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.86	
[11/28 21:10:16 visual_prompt]: Training 21 / 100 epoch, with learning rate 48.49231551964771
[11/28 21:17:39 visual_prompt]: Epoch 21 / 100: avg data time: 1.18e+01, avg batch time: 12.6562, average train loss: 46.9716
[11/28 21:18:30 visual_prompt]: Inference (val):avg data time: 4.36e-05, avg batch time: 0.5234, average loss: 68.4389
[11/28 21:18:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.13	
[11/28 21:18:30 visual_prompt]: Training 22 / 100 epoch, with learning rate 48.17959636416968
[11/28 21:25:52 visual_prompt]: Epoch 22 / 100: avg data time: 1.17e+01, avg batch time: 12.6188, average train loss: 53.8320
[11/28 21:26:44 visual_prompt]: Inference (val):avg data time: 4.13e-05, avg batch time: 0.5307, average loss: 103.9562
[11/28 21:26:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.67	
[11/28 21:26:44 visual_prompt]: Training 23 / 100 epoch, with learning rate 47.83863644106502
[11/28 21:34:06 visual_prompt]: Epoch 23 / 100: avg data time: 1.18e+01, avg batch time: 12.6425, average train loss: 64.1752
[11/28 21:34:58 visual_prompt]: Inference (val):avg data time: 4.15e-05, avg batch time: 0.5319, average loss: 8.6518
[11/28 21:34:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.81	
[11/28 21:34:58 visual_prompt]: Best epoch 23: best metric: -8.652
[11/28 21:34:58 visual_prompt]: Training 24 / 100 epoch, with learning rate 47.46985115747918
[11/28 21:42:22 visual_prompt]: Epoch 24 / 100: avg data time: 1.18e+01, avg batch time: 12.6975, average train loss: 53.3917
[11/28 21:43:15 visual_prompt]: Inference (val):avg data time: 5.03e-05, avg batch time: 0.5282, average loss: 79.1550
[11/28 21:43:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.53	
[11/28 21:43:15 visual_prompt]: Training 25 / 100 epoch, with learning rate 47.073689821473174
[11/28 21:50:45 visual_prompt]: Epoch 25 / 100: avg data time: 1.20e+01, avg batch time: 12.8454, average train loss: 83.9509
[11/28 21:51:36 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.5291, average loss: 121.5777
[11/28 21:51:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 45.93	
[11/28 21:51:36 visual_prompt]: Training 26 / 100 epoch, with learning rate 46.65063509461097
[11/28 21:58:59 visual_prompt]: Epoch 26 / 100: avg data time: 1.18e+01, avg batch time: 12.6600, average train loss: 100.4154
[11/28 21:59:51 visual_prompt]: Inference (val):avg data time: 5.59e-05, avg batch time: 0.5236, average loss: 50.2287
[11/28 21:59:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.91	
[11/28 21:59:51 visual_prompt]: Training 27 / 100 epoch, with learning rate 46.20120240391065
[11/28 22:07:14 visual_prompt]: Epoch 27 / 100: avg data time: 1.18e+01, avg batch time: 12.6487, average train loss: 56.2868
[11/28 22:08:05 visual_prompt]: Inference (val):avg data time: 3.89e-05, avg batch time: 0.5284, average loss: 45.5013
[11/28 22:08:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.50	
[11/28 22:08:05 visual_prompt]: Training 28 / 100 epoch, with learning rate 45.72593931387604
[11/28 22:15:29 visual_prompt]: Epoch 28 / 100: avg data time: 1.18e+01, avg batch time: 12.6819, average train loss: 67.3416
[11/28 22:16:21 visual_prompt]: Inference (val):avg data time: 5.13e-05, avg batch time: 0.5257, average loss: 4.4116
[11/28 22:16:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 45.03	
[11/28 22:16:21 visual_prompt]: Best epoch 28: best metric: -4.412
[11/28 22:16:21 visual_prompt]: Training 29 / 100 epoch, with learning rate 45.22542485937369
[11/28 22:23:49 visual_prompt]: Epoch 29 / 100: avg data time: 1.19e+01, avg batch time: 12.8135, average train loss: 67.4864
[11/28 22:24:41 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.5193, average loss: 11.7534
[11/28 22:24:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.43	
[11/28 22:24:41 visual_prompt]: Training 30 / 100 epoch, with learning rate 44.70026884016804
[11/28 22:32:03 visual_prompt]: Epoch 30 / 100: avg data time: 1.18e+01, avg batch time: 12.6260, average train loss: 118.5525
[11/28 22:32:54 visual_prompt]: Inference (val):avg data time: 3.96e-05, avg batch time: 0.5307, average loss: 26.2126
[11/28 22:32:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 45.01	
[11/28 22:32:54 visual_prompt]: Training 31 / 100 epoch, with learning rate 44.15111107797445
[11/28 22:40:16 visual_prompt]: Epoch 31 / 100: avg data time: 1.18e+01, avg batch time: 12.6351, average train loss: 127.2978
[11/28 22:41:08 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.5264, average loss: 29.5896
[11/28 22:41:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.84	
[11/28 22:41:08 visual_prompt]: Training 32 / 100 epoch, with learning rate 43.57862063693486
[11/28 22:48:31 visual_prompt]: Epoch 32 / 100: avg data time: 1.18e+01, avg batch time: 12.6624, average train loss: 82.8848
[11/28 22:49:23 visual_prompt]: Inference (val):avg data time: 4.23e-05, avg batch time: 0.5272, average loss: 126.7155
[11/28 22:49:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.09	
[11/28 22:49:23 visual_prompt]: Training 33 / 100 epoch, with learning rate 42.98349500846628
[11/28 22:56:45 visual_prompt]: Epoch 33 / 100: avg data time: 1.18e+01, avg batch time: 12.6334, average train loss: 78.9427
[11/28 22:57:36 visual_prompt]: Inference (val):avg data time: 4.69e-05, avg batch time: 0.5315, average loss: 105.0000
[11/28 22:57:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.73	
[11/28 22:57:36 visual_prompt]: Training 34 / 100 epoch, with learning rate 42.36645926147493
[11/28 23:04:58 visual_prompt]: Epoch 34 / 100: avg data time: 1.17e+01, avg batch time: 12.6061, average train loss: 55.3709
[11/28 23:05:50 visual_prompt]: Inference (val):avg data time: 4.43e-05, avg batch time: 0.5259, average loss: 73.8822
[11/28 23:05:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.97	
[11/28 23:05:50 visual_prompt]: Training 35 / 100 epoch, with learning rate 41.72826515897145
[11/28 23:13:12 visual_prompt]: Epoch 35 / 100: avg data time: 1.18e+01, avg batch time: 12.6483, average train loss: 65.2232
[11/28 23:14:04 visual_prompt]: Inference (val):avg data time: 4.51e-05, avg batch time: 0.5229, average loss: 634.3558
[11/28 23:14:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.99	
[11/28 23:14:04 visual_prompt]: Stopping early.
[11/28 23:14:04 visual_prompt]: Rank of current process: 0. World size: 1
[11/28 23:14:04 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA TITAN Xp
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/28 23:14:04 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss', 'RECORD_GPU_SNAPSHOT', 'True'])
[11/28 23:14:04 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/28 23:14:04 visual_prompt]: Training with config:
[11/28 23:14:04 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr50.0_wd0.0/patience7/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 50.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True}), 'RECORD_GPU_SNAPSHOT': True})
[11/28 23:14:04 visual_prompt]: Loading training data...
[11/28 23:14:04 visual_prompt]: Constructing mammo-cbis dataset train...
[11/28 23:14:04 visual_prompt]: Loading validation data...
[11/28 23:14:04 visual_prompt]: Constructing mammo-cbis dataset val...
[11/28 23:14:04 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[11/28 23:14:13 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[11/28 23:14:13 visual_prompt]: tuned percent:0.536
[11/28 23:14:13 visual_prompt]: Device used for model: 0
[11/28 23:14:13 visual_prompt]: Setting up Evaluator...
[11/28 23:14:13 visual_prompt]: Setting up Trainer...
[11/28 23:14:13 visual_prompt]: 	Setting up the optimizer...
[11/28 23:14:13 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/28 23:21:36 visual_prompt]: Epoch 1 / 100: avg data time: 1.18e+01, avg batch time: 12.6418, average train loss: 1.4006
[11/28 23:22:28 visual_prompt]: Inference (val):avg data time: 4.04e-05, avg batch time: 0.5247, average loss: 1.2969
[11/28 23:22:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[11/28 23:22:28 visual_prompt]: Training 2 / 100 epoch, with learning rate 5.0
[11/28 23:29:49 visual_prompt]: Epoch 2 / 100: avg data time: 1.17e+01, avg batch time: 12.6107, average train loss: 22.2948
[11/28 23:30:40 visual_prompt]: Inference (val):avg data time: 3.80e-05, avg batch time: 0.5210, average loss: 17.1110
[11/28 23:30:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.22	
[11/28 23:30:40 visual_prompt]: Training 3 / 100 epoch, with learning rate 10.0
[11/28 23:38:03 visual_prompt]: Epoch 3 / 100: avg data time: 1.18e+01, avg batch time: 12.6407, average train loss: 22.4783
[11/28 23:38:54 visual_prompt]: Inference (val):avg data time: 5.19e-05, avg batch time: 0.5273, average loss: 22.4050
[11/28 23:38:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.81	
[11/28 23:38:54 visual_prompt]: Training 4 / 100 epoch, with learning rate 15.0
[11/28 23:46:15 visual_prompt]: Epoch 4 / 100: avg data time: 1.17e+01, avg batch time: 12.6135, average train loss: 41.8588
[11/28 23:47:07 visual_prompt]: Inference (val):avg data time: 4.37e-05, avg batch time: 0.5291, average loss: 27.7860
[11/28 23:47:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.88	
[11/28 23:47:07 visual_prompt]: Training 5 / 100 epoch, with learning rate 20.0
[11/28 23:54:29 visual_prompt]: Epoch 5 / 100: avg data time: 1.17e+01, avg batch time: 12.6151, average train loss: 54.8232
[11/28 23:55:20 visual_prompt]: Inference (val):avg data time: 3.46e-05, avg batch time: 0.5252, average loss: 24.0043
[11/28 23:55:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.88	
[11/28 23:55:20 visual_prompt]: Training 6 / 100 epoch, with learning rate 25.0
[11/29 00:02:43 visual_prompt]: Epoch 6 / 100: avg data time: 1.18e+01, avg batch time: 12.6451, average train loss: 54.2931
[11/29 00:03:34 visual_prompt]: Inference (val):avg data time: 4.18e-05, avg batch time: 0.5301, average loss: 55.2725
[11/29 00:03:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.53	
[11/29 00:03:34 visual_prompt]: Training 7 / 100 epoch, with learning rate 30.0
[11/29 00:10:57 visual_prompt]: Epoch 7 / 100: avg data time: 1.18e+01, avg batch time: 12.6530, average train loss: 27.7218
[11/29 00:11:49 visual_prompt]: Inference (val):avg data time: 4.11e-05, avg batch time: 0.5260, average loss: 7.0102
[11/29 00:11:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.49	
[11/29 00:11:49 visual_prompt]: Training 8 / 100 epoch, with learning rate 35.0
[11/29 00:19:10 visual_prompt]: Epoch 8 / 100: avg data time: 1.17e+01, avg batch time: 12.6081, average train loss: 81.4585
[11/29 00:20:02 visual_prompt]: Inference (val):avg data time: 4.88e-05, avg batch time: 0.5250, average loss: 160.3830
[11/29 00:20:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.04	
[11/29 00:20:02 visual_prompt]: Training 9 / 100 epoch, with learning rate 40.0
[11/29 00:27:25 visual_prompt]: Epoch 9 / 100: avg data time: 1.18e+01, avg batch time: 12.6555, average train loss: 39.7723
[11/29 00:28:16 visual_prompt]: Inference (val):avg data time: 6.26e-05, avg batch time: 0.5227, average loss: 20.0599
[11/29 00:28:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.98	
[11/29 00:28:16 visual_prompt]: Training 10 / 100 epoch, with learning rate 45.0
[11/29 00:35:38 visual_prompt]: Epoch 10 / 100: avg data time: 1.18e+01, avg batch time: 12.6314, average train loss: 53.7560
[11/29 00:36:29 visual_prompt]: Inference (val):avg data time: 4.99e-05, avg batch time: 0.5259, average loss: 55.4346
[11/29 00:36:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.93	
[11/29 00:36:29 visual_prompt]: Training 11 / 100 epoch, with learning rate 50.0
[11/29 00:43:52 visual_prompt]: Epoch 11 / 100: avg data time: 1.18e+01, avg batch time: 12.6273, average train loss: 38.6414
[11/29 00:44:43 visual_prompt]: Inference (val):avg data time: 4.52e-05, avg batch time: 0.5239, average loss: 56.3611
[11/29 00:44:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.28	
[11/29 00:44:43 visual_prompt]: Training 12 / 100 epoch, with learning rate 49.9847706754774
[11/29 00:52:05 visual_prompt]: Epoch 12 / 100: avg data time: 1.18e+01, avg batch time: 12.6309, average train loss: 45.0364
[11/29 00:52:57 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.5242, average loss: 43.5440
[11/29 00:52:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.31	
[11/29 00:52:57 visual_prompt]: Best epoch 12: best metric: -43.544
[11/29 00:52:57 visual_prompt]: Training 13 / 100 epoch, with learning rate 49.939101256495604
[11/29 01:00:20 visual_prompt]: Epoch 13 / 100: avg data time: 1.18e+01, avg batch time: 12.6571, average train loss: 30.3548
[11/29 01:01:11 visual_prompt]: Inference (val):avg data time: 4.07e-05, avg batch time: 0.5239, average loss: 18.9613
[11/29 01:01:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.15	
[11/29 01:01:11 visual_prompt]: Best epoch 13: best metric: -18.961
[11/29 01:01:11 visual_prompt]: Training 14 / 100 epoch, with learning rate 49.86304738420683
[11/29 01:08:33 visual_prompt]: Epoch 14 / 100: avg data time: 1.18e+01, avg batch time: 12.6293, average train loss: 53.3074
[11/29 01:09:24 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.5285, average loss: 0.7582
[11/29 01:09:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.52	
[11/29 01:09:24 visual_prompt]: Best epoch 14: best metric: -0.758
[11/29 01:09:24 visual_prompt]: Training 15 / 100 epoch, with learning rate 49.75670171853926
[11/29 01:16:47 visual_prompt]: Epoch 15 / 100: avg data time: 1.18e+01, avg batch time: 12.6508, average train loss: 32.6008
[11/29 01:17:39 visual_prompt]: Inference (val):avg data time: 5.20e-05, avg batch time: 0.5300, average loss: 55.0331
[11/29 01:17:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.51	
[11/29 01:17:39 visual_prompt]: Training 16 / 100 epoch, with learning rate 49.6201938253052
[11/29 01:25:01 visual_prompt]: Epoch 16 / 100: avg data time: 1.17e+01, avg batch time: 12.6176, average train loss: 23.8085
[11/29 01:25:52 visual_prompt]: Inference (val):avg data time: 5.33e-05, avg batch time: 0.5282, average loss: 25.0575
[11/29 01:25:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.27	
[11/29 01:25:52 visual_prompt]: Training 17 / 100 epoch, with learning rate 49.45369001834514
[11/29 01:33:14 visual_prompt]: Epoch 17 / 100: avg data time: 1.17e+01, avg batch time: 12.6211, average train loss: 21.4958
[11/29 01:34:06 visual_prompt]: Inference (val):avg data time: 4.82e-05, avg batch time: 0.5307, average loss: 54.8485
[11/29 01:34:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.94	
[11/29 01:34:06 visual_prompt]: Training 18 / 100 epoch, with learning rate 49.25739315689991
[11/29 01:41:28 visual_prompt]: Epoch 18 / 100: avg data time: 1.18e+01, avg batch time: 12.6414, average train loss: 76.7608
[11/29 01:42:20 visual_prompt]: Inference (val):avg data time: 4.33e-05, avg batch time: 0.5222, average loss: 93.1804
[11/29 01:42:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.08	
[11/29 01:42:20 visual_prompt]: Training 19 / 100 epoch, with learning rate 49.03154239845797
[11/29 01:49:41 visual_prompt]: Epoch 19 / 100: avg data time: 1.17e+01, avg batch time: 12.6115, average train loss: 28.2852
[11/29 01:50:32 visual_prompt]: Inference (val):avg data time: 4.83e-05, avg batch time: 0.5224, average loss: 19.4200
[11/29 01:50:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.33	
[11/29 01:50:32 visual_prompt]: Training 20 / 100 epoch, with learning rate 48.77641290737884
[11/29 01:57:54 visual_prompt]: Epoch 20 / 100: avg data time: 1.18e+01, avg batch time: 12.6205, average train loss: 39.3531
[11/29 01:58:45 visual_prompt]: Inference (val):avg data time: 5.61e-05, avg batch time: 0.5188, average loss: 93.7001
[11/29 01:58:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.31	
[11/29 01:58:46 visual_prompt]: Training 21 / 100 epoch, with learning rate 48.49231551964771
[11/29 02:06:09 visual_prompt]: Epoch 21 / 100: avg data time: 1.18e+01, avg batch time: 12.6738, average train loss: 24.9626
[11/29 02:07:00 visual_prompt]: Inference (val):avg data time: 5.13e-05, avg batch time: 0.5228, average loss: 30.7846
[11/29 02:07:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.94	
[11/29 02:07:00 visual_prompt]: Stopping early.
[11/29 02:07:01 visual_prompt]: Rank of current process: 0. World size: 1
[11/29 02:07:01 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA TITAN Xp
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/29 02:07:01 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss', 'RECORD_GPU_SNAPSHOT', 'True'])
[11/29 02:07:01 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/29 02:07:01 visual_prompt]: Training with config:
[11/29 02:07:01 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr25.0_wd0.01/patience7/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 25.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True}), 'RECORD_GPU_SNAPSHOT': True})
[11/29 02:07:01 visual_prompt]: Loading training data...
[11/29 02:07:01 visual_prompt]: Constructing mammo-cbis dataset train...
[11/29 02:07:01 visual_prompt]: Loading validation data...
[11/29 02:07:01 visual_prompt]: Constructing mammo-cbis dataset val...
[11/29 02:07:01 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[11/29 02:07:04 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[11/29 02:07:04 visual_prompt]: tuned percent:0.536
[11/29 02:07:05 visual_prompt]: Device used for model: 0
[11/29 02:07:05 visual_prompt]: Setting up Evaluator...
[11/29 02:07:05 visual_prompt]: Setting up Trainer...
[11/29 02:07:05 visual_prompt]: 	Setting up the optimizer...
[11/29 02:07:05 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/29 02:14:28 visual_prompt]: Epoch 1 / 100: avg data time: 1.18e+01, avg batch time: 12.6676, average train loss: 1.4006
[11/29 02:15:20 visual_prompt]: Inference (val):avg data time: 4.76e-05, avg batch time: 0.5354, average loss: 1.2969
[11/29 02:15:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[11/29 02:15:20 visual_prompt]: Training 2 / 100 epoch, with learning rate 2.5
[11/29 02:22:43 visual_prompt]: Epoch 2 / 100: avg data time: 1.18e+01, avg batch time: 12.6595, average train loss: 15.7918
[11/29 02:23:35 visual_prompt]: Inference (val):avg data time: 3.87e-05, avg batch time: 0.5202, average loss: 6.8894
[11/29 02:23:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.72	
[11/29 02:23:35 visual_prompt]: Training 3 / 100 epoch, with learning rate 5.0
[11/29 02:30:59 visual_prompt]: Epoch 3 / 100: avg data time: 1.18e+01, avg batch time: 12.6717, average train loss: 10.7627
[11/29 02:31:50 visual_prompt]: Inference (val):avg data time: 5.12e-05, avg batch time: 0.5276, average loss: 7.5916
[11/29 02:31:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 45.39	
[11/29 02:31:50 visual_prompt]: Training 4 / 100 epoch, with learning rate 7.5
[11/29 02:39:12 visual_prompt]: Epoch 4 / 100: avg data time: 1.17e+01, avg batch time: 12.6128, average train loss: 16.2732
[11/29 02:40:03 visual_prompt]: Inference (val):avg data time: 4.04e-05, avg batch time: 0.5238, average loss: 4.7213
[11/29 02:40:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.61	
[11/29 02:40:03 visual_prompt]: Training 5 / 100 epoch, with learning rate 10.0
[11/29 02:47:26 visual_prompt]: Epoch 5 / 100: avg data time: 1.18e+01, avg batch time: 12.6385, average train loss: 37.4550
[11/29 02:48:17 visual_prompt]: Inference (val):avg data time: 4.85e-05, avg batch time: 0.5270, average loss: 19.0919
[11/29 02:48:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.24	
[11/29 02:48:17 visual_prompt]: Training 6 / 100 epoch, with learning rate 12.5
[11/29 02:55:41 visual_prompt]: Epoch 6 / 100: avg data time: 1.18e+01, avg batch time: 12.6629, average train loss: 39.3881
[11/29 02:56:31 visual_prompt]: Inference (val):avg data time: 3.95e-05, avg batch time: 0.5191, average loss: 102.4557
[11/29 02:56:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.86	
[11/29 02:56:31 visual_prompt]: Training 7 / 100 epoch, with learning rate 15.0
[11/29 03:03:51 visual_prompt]: Epoch 7 / 100: avg data time: 1.17e+01, avg batch time: 12.5690, average train loss: 39.6249
[11/29 03:04:42 visual_prompt]: Inference (val):avg data time: 4.06e-05, avg batch time: 0.5279, average loss: 64.6401
[11/29 03:04:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.81	
[11/29 03:04:42 visual_prompt]: Training 8 / 100 epoch, with learning rate 17.5
[11/29 03:12:05 visual_prompt]: Epoch 8 / 100: avg data time: 1.18e+01, avg batch time: 12.6335, average train loss: 49.9475
[11/29 03:12:56 visual_prompt]: Inference (val):avg data time: 3.60e-05, avg batch time: 0.5241, average loss: 160.6079
[11/29 03:12:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.92	
[11/29 03:12:56 visual_prompt]: Training 9 / 100 epoch, with learning rate 20.0
[11/29 03:20:18 visual_prompt]: Epoch 9 / 100: avg data time: 1.17e+01, avg batch time: 12.6159, average train loss: 45.3639
[11/29 03:21:09 visual_prompt]: Inference (val):avg data time: 3.73e-05, avg batch time: 0.5340, average loss: 67.4572
[11/29 03:21:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 42.20	
[11/29 03:21:09 visual_prompt]: Training 10 / 100 epoch, with learning rate 22.5
[11/29 03:28:29 visual_prompt]: Epoch 10 / 100: avg data time: 1.17e+01, avg batch time: 12.5704, average train loss: 65.7773
[11/29 03:29:20 visual_prompt]: Inference (val):avg data time: 4.14e-05, avg batch time: 0.5241, average loss: 56.5179
[11/29 03:29:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.09	
[11/29 03:29:20 visual_prompt]: Training 11 / 100 epoch, with learning rate 25.0
[11/29 03:36:41 visual_prompt]: Epoch 11 / 100: avg data time: 1.17e+01, avg batch time: 12.5800, average train loss: 45.6347
[11/29 03:37:31 visual_prompt]: Inference (val):avg data time: 4.54e-05, avg batch time: 0.5296, average loss: 54.4974
[11/29 03:37:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.88	
[11/29 03:37:31 visual_prompt]: Training 12 / 100 epoch, with learning rate 24.9923853377387
[11/29 03:44:51 visual_prompt]: Epoch 12 / 100: avg data time: 1.17e+01, avg batch time: 12.5632, average train loss: 49.6809
[11/29 03:45:43 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.5232, average loss: 17.6987
[11/29 03:45:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 41.14	
[11/29 03:45:43 visual_prompt]: Best epoch 12: best metric: -17.699
[11/29 03:45:43 visual_prompt]: Training 13 / 100 epoch, with learning rate 24.969550628247802
[11/29 03:53:01 visual_prompt]: Epoch 13 / 100: avg data time: 1.17e+01, avg batch time: 12.5253, average train loss: 66.5660
[11/29 03:53:52 visual_prompt]: Inference (val):avg data time: 4.58e-05, avg batch time: 0.5206, average loss: 68.4455
[11/29 03:53:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.13	
[11/29 03:53:52 visual_prompt]: Training 14 / 100 epoch, with learning rate 24.931523692103415
[11/29 04:01:08 visual_prompt]: Epoch 14 / 100: avg data time: 1.16e+01, avg batch time: 12.4577, average train loss: 83.4128
[11/29 04:01:59 visual_prompt]: Inference (val):avg data time: 4.85e-05, avg batch time: 0.5264, average loss: 299.3634
[11/29 04:01:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.00	
[11/29 04:01:59 visual_prompt]: Training 15 / 100 epoch, with learning rate 24.87835085926963
[11/29 04:09:17 visual_prompt]: Epoch 15 / 100: avg data time: 1.16e+01, avg batch time: 12.4961, average train loss: 130.0345
[11/29 04:10:08 visual_prompt]: Inference (val):avg data time: 3.71e-05, avg batch time: 0.5326, average loss: 2.0601
[11/29 04:10:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 61.65	
[11/29 04:10:08 visual_prompt]: Best epoch 15: best metric: -2.060
[11/29 04:10:08 visual_prompt]: Training 16 / 100 epoch, with learning rate 24.8100969126526
[11/29 04:17:26 visual_prompt]: Epoch 16 / 100: avg data time: 1.16e+01, avg batch time: 12.5047, average train loss: 74.8319
[11/29 04:18:17 visual_prompt]: Inference (val):avg data time: 3.71e-05, avg batch time: 0.5250, average loss: 105.7599
[11/29 04:18:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.21	
[11/29 04:18:17 visual_prompt]: Training 17 / 100 epoch, with learning rate 24.72684500917257
[11/29 04:25:35 visual_prompt]: Epoch 17 / 100: avg data time: 1.16e+01, avg batch time: 12.5055, average train loss: 63.3187
[11/29 04:26:26 visual_prompt]: Inference (val):avg data time: 4.67e-05, avg batch time: 0.5227, average loss: 30.9655
[11/29 04:26:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.98	
[11/29 04:26:26 visual_prompt]: Training 18 / 100 epoch, with learning rate 24.628696578449954
[11/29 04:33:44 visual_prompt]: Epoch 18 / 100: avg data time: 1.17e+01, avg batch time: 12.5262, average train loss: 82.0289
[11/29 04:34:35 visual_prompt]: Inference (val):avg data time: 4.73e-05, avg batch time: 0.5350, average loss: 174.5963
[11/29 04:34:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.96	
[11/29 04:34:35 visual_prompt]: Training 19 / 100 epoch, with learning rate 24.515771199228986
[11/29 04:41:54 visual_prompt]: Epoch 19 / 100: avg data time: 1.16e+01, avg batch time: 12.5134, average train loss: 71.7941
[11/29 04:42:45 visual_prompt]: Inference (val):avg data time: 5.32e-05, avg batch time: 0.5229, average loss: 134.8451
[11/29 04:42:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.59	
[11/29 04:42:45 visual_prompt]: Training 20 / 100 epoch, with learning rate 24.38820645368942
[11/29 04:50:04 visual_prompt]: Epoch 20 / 100: avg data time: 1.17e+01, avg batch time: 12.5494, average train loss: 62.4867
[11/29 04:50:55 visual_prompt]: Inference (val):avg data time: 4.39e-05, avg batch time: 0.5299, average loss: 30.6840
[11/29 04:50:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.36	
[11/29 04:50:55 visual_prompt]: Training 21 / 100 epoch, with learning rate 24.246157759823856
[11/29 04:58:15 visual_prompt]: Epoch 21 / 100: avg data time: 1.17e+01, avg batch time: 12.5609, average train loss: 95.0501
[11/29 04:59:06 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.5276, average loss: 190.0296
[11/29 04:59:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.43	
[11/29 04:59:06 visual_prompt]: Training 22 / 100 epoch, with learning rate 24.08979818208484
[11/29 05:06:25 visual_prompt]: Epoch 22 / 100: avg data time: 1.16e+01, avg batch time: 12.5195, average train loss: 80.5103
[11/29 05:07:15 visual_prompt]: Inference (val):avg data time: 4.65e-05, avg batch time: 0.5226, average loss: 122.3092
[11/29 05:07:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.20	
[11/29 05:07:15 visual_prompt]: Stopping early.
[11/29 05:07:16 visual_prompt]: Rank of current process: 0. World size: 1
[11/29 05:07:16 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA TITAN Xp
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/29 05:07:16 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss', 'RECORD_GPU_SNAPSHOT', 'True'])
[11/29 05:07:16 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/29 05:07:16 visual_prompt]: Training with config:
[11/29 05:07:16 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr25.0_wd0.001/patience7/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 25.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True}), 'RECORD_GPU_SNAPSHOT': True})
[11/29 05:07:16 visual_prompt]: Loading training data...
[11/29 05:07:16 visual_prompt]: Constructing mammo-cbis dataset train...
[11/29 05:07:16 visual_prompt]: Loading validation data...
[11/29 05:07:16 visual_prompt]: Constructing mammo-cbis dataset val...
[11/29 05:07:16 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[11/29 05:07:19 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[11/29 05:07:19 visual_prompt]: tuned percent:0.536
[11/29 05:07:19 visual_prompt]: Device used for model: 0
[11/29 05:07:19 visual_prompt]: Setting up Evaluator...
[11/29 05:07:19 visual_prompt]: Setting up Trainer...
[11/29 05:07:19 visual_prompt]: 	Setting up the optimizer...
[11/29 05:07:19 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/29 05:14:39 visual_prompt]: Epoch 1 / 100: avg data time: 1.17e+01, avg batch time: 12.5570, average train loss: 1.4006
[11/29 05:15:30 visual_prompt]: Inference (val):avg data time: 4.81e-05, avg batch time: 0.5305, average loss: 1.2969
[11/29 05:15:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[11/29 05:15:30 visual_prompt]: Training 2 / 100 epoch, with learning rate 2.5
[11/29 05:22:49 visual_prompt]: Epoch 2 / 100: avg data time: 1.17e+01, avg batch time: 12.5434, average train loss: 23.9563
[11/29 05:23:40 visual_prompt]: Inference (val):avg data time: 4.20e-05, avg batch time: 0.5306, average loss: 2.2611
[11/29 05:23:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.94	
[11/29 05:23:40 visual_prompt]: Training 3 / 100 epoch, with learning rate 5.0
[11/29 05:30:58 visual_prompt]: Epoch 3 / 100: avg data time: 1.16e+01, avg batch time: 12.5208, average train loss: 12.5572
[11/29 05:31:49 visual_prompt]: Inference (val):avg data time: 4.37e-05, avg batch time: 0.5254, average loss: 5.1162
[11/29 05:31:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.45	
[11/29 05:31:49 visual_prompt]: Training 4 / 100 epoch, with learning rate 7.5
[11/29 05:39:09 visual_prompt]: Epoch 4 / 100: avg data time: 1.17e+01, avg batch time: 12.5702, average train loss: 11.6014
[11/29 05:40:00 visual_prompt]: Inference (val):avg data time: 5.29e-05, avg batch time: 0.5273, average loss: 5.2183
[11/29 05:40:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.73	
[11/29 05:40:00 visual_prompt]: Training 5 / 100 epoch, with learning rate 10.0
[11/29 05:47:17 visual_prompt]: Epoch 5 / 100: avg data time: 1.16e+01, avg batch time: 12.4840, average train loss: 28.7568
[11/29 05:48:08 visual_prompt]: Inference (val):avg data time: 4.64e-05, avg batch time: 0.5182, average loss: 15.6132
[11/29 05:48:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.37	
[11/29 05:48:08 visual_prompt]: Training 6 / 100 epoch, with learning rate 12.5
[11/29 05:55:26 visual_prompt]: Epoch 6 / 100: avg data time: 1.17e+01, avg batch time: 12.5275, average train loss: 17.9456
[11/29 05:56:18 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.5312, average loss: 11.7070
[11/29 05:56:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.61	
[11/29 05:56:18 visual_prompt]: Training 7 / 100 epoch, with learning rate 15.0
[11/29 06:03:36 visual_prompt]: Epoch 7 / 100: avg data time: 1.17e+01, avg batch time: 12.5343, average train loss: 25.2146
[11/29 06:04:28 visual_prompt]: Inference (val):avg data time: 3.93e-05, avg batch time: 0.5256, average loss: 8.6318
[11/29 06:04:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.34	
[11/29 06:04:28 visual_prompt]: Training 8 / 100 epoch, with learning rate 17.5
[11/29 06:11:45 visual_prompt]: Epoch 8 / 100: avg data time: 1.16e+01, avg batch time: 12.4902, average train loss: 33.6537
[11/29 06:12:36 visual_prompt]: Inference (val):avg data time: 3.76e-05, avg batch time: 0.5240, average loss: 3.5247
[11/29 06:12:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.36	
[11/29 06:12:36 visual_prompt]: Training 9 / 100 epoch, with learning rate 20.0
[11/29 06:19:54 visual_prompt]: Epoch 9 / 100: avg data time: 1.16e+01, avg batch time: 12.5091, average train loss: 46.5278
[11/29 06:20:46 visual_prompt]: Inference (val):avg data time: 3.85e-05, avg batch time: 0.5220, average loss: 21.3520
[11/29 06:20:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.28	
[11/29 06:20:46 visual_prompt]: Training 10 / 100 epoch, with learning rate 22.5
[11/29 06:28:04 visual_prompt]: Epoch 10 / 100: avg data time: 1.16e+01, avg batch time: 12.5131, average train loss: 53.4978
[11/29 06:28:54 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.5176, average loss: 34.7211
[11/29 06:28:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.19	
[11/29 06:28:54 visual_prompt]: Training 11 / 100 epoch, with learning rate 25.0
[11/29 06:36:12 visual_prompt]: Epoch 11 / 100: avg data time: 1.16e+01, avg batch time: 12.4886, average train loss: 39.1158
[11/29 06:37:02 visual_prompt]: Inference (val):avg data time: 3.94e-05, avg batch time: 0.5268, average loss: 85.8978
[11/29 06:37:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.06	
[11/29 06:37:02 visual_prompt]: Training 12 / 100 epoch, with learning rate 24.9923853377387
[11/29 06:44:18 visual_prompt]: Epoch 12 / 100: avg data time: 1.16e+01, avg batch time: 12.4667, average train loss: 89.5430
[11/29 06:45:08 visual_prompt]: Inference (val):avg data time: 4.58e-05, avg batch time: 0.5280, average loss: 4.1313
[11/29 06:45:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.58	
[11/29 06:45:08 visual_prompt]: Best epoch 12: best metric: -4.131
[11/29 06:45:08 visual_prompt]: Training 13 / 100 epoch, with learning rate 24.969550628247802
[11/29 06:52:26 visual_prompt]: Epoch 13 / 100: avg data time: 1.16e+01, avg batch time: 12.4956, average train loss: 71.3667
[11/29 06:53:16 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.5168, average loss: 4.0069
[11/29 06:53:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.74	
[11/29 06:53:16 visual_prompt]: Best epoch 13: best metric: -4.007
[11/29 06:53:16 visual_prompt]: Training 14 / 100 epoch, with learning rate 24.931523692103415
[11/29 07:00:31 visual_prompt]: Epoch 14 / 100: avg data time: 1.16e+01, avg batch time: 12.4426, average train loss: 54.6791
[11/29 07:01:22 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.5186, average loss: 50.7133
[11/29 07:01:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.42	
[11/29 07:01:22 visual_prompt]: Training 15 / 100 epoch, with learning rate 24.87835085926963
[11/29 07:08:39 visual_prompt]: Epoch 15 / 100: avg data time: 1.16e+01, avg batch time: 12.4738, average train loss: 46.9962
[11/29 07:09:30 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.5244, average loss: 33.4857
[11/29 07:09:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.11	
[11/29 07:09:30 visual_prompt]: Training 16 / 100 epoch, with learning rate 24.8100969126526
[11/29 07:16:47 visual_prompt]: Epoch 16 / 100: avg data time: 1.16e+01, avg batch time: 12.4965, average train loss: 53.9086
[11/29 07:17:38 visual_prompt]: Inference (val):avg data time: 4.39e-05, avg batch time: 0.5220, average loss: 64.7179
[11/29 07:17:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.62	
[11/29 07:17:38 visual_prompt]: Training 17 / 100 epoch, with learning rate 24.72684500917257
[11/29 07:24:56 visual_prompt]: Epoch 17 / 100: avg data time: 1.16e+01, avg batch time: 12.4918, average train loss: 38.0387
[11/29 07:25:47 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.5240, average loss: 39.6790
[11/29 07:25:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.57	
[11/29 07:25:47 visual_prompt]: Training 18 / 100 epoch, with learning rate 24.628696578449954
[11/29 07:33:04 visual_prompt]: Epoch 18 / 100: avg data time: 1.16e+01, avg batch time: 12.4962, average train loss: 53.2982
[11/29 07:33:55 visual_prompt]: Inference (val):avg data time: 4.57e-05, avg batch time: 0.5232, average loss: 64.1893
[11/29 07:33:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 45.51	
[11/29 07:33:55 visual_prompt]: Training 19 / 100 epoch, with learning rate 24.515771199228986
[11/29 07:41:13 visual_prompt]: Epoch 19 / 100: avg data time: 1.16e+01, avg batch time: 12.4901, average train loss: 67.6427
[11/29 07:42:04 visual_prompt]: Inference (val):avg data time: 5.82e-05, avg batch time: 0.5217, average loss: 32.7374
[11/29 07:42:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.62	
[11/29 07:42:04 visual_prompt]: Training 20 / 100 epoch, with learning rate 24.38820645368942
[11/29 07:49:21 visual_prompt]: Epoch 20 / 100: avg data time: 1.16e+01, avg batch time: 12.4981, average train loss: 65.8348
[11/29 07:50:12 visual_prompt]: Inference (val):avg data time: 4.50e-05, avg batch time: 0.5229, average loss: 170.4924
[11/29 07:50:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.49	
[11/29 07:50:12 visual_prompt]: Stopping early.
[11/29 07:50:13 visual_prompt]: Rank of current process: 0. World size: 1
[11/29 07:50:13 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA TITAN Xp
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/29 07:50:13 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss', 'RECORD_GPU_SNAPSHOT', 'True'])
[11/29 07:50:13 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/29 07:50:13 visual_prompt]: Training with config:
[11/29 07:50:13 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr25.0_wd0.0001/patience7/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 25.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True}), 'RECORD_GPU_SNAPSHOT': True})
[11/29 07:50:13 visual_prompt]: Loading training data...
[11/29 07:50:13 visual_prompt]: Constructing mammo-cbis dataset train...
[11/29 07:50:13 visual_prompt]: Loading validation data...
[11/29 07:50:13 visual_prompt]: Constructing mammo-cbis dataset val...
[11/29 07:50:13 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[11/29 07:50:16 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[11/29 07:50:16 visual_prompt]: tuned percent:0.536
[11/29 07:50:16 visual_prompt]: Device used for model: 0
[11/29 07:50:16 visual_prompt]: Setting up Evaluator...
[11/29 07:50:16 visual_prompt]: Setting up Trainer...
[11/29 07:50:16 visual_prompt]: 	Setting up the optimizer...
[11/29 07:50:16 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/29 07:57:34 visual_prompt]: Epoch 1 / 100: avg data time: 1.16e+01, avg batch time: 12.5150, average train loss: 1.4006
[11/29 07:58:25 visual_prompt]: Inference (val):avg data time: 4.22e-05, avg batch time: 0.5196, average loss: 1.2969
[11/29 07:58:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[11/29 07:58:25 visual_prompt]: Training 2 / 100 epoch, with learning rate 2.5
[11/29 08:05:42 visual_prompt]: Epoch 2 / 100: avg data time: 1.16e+01, avg batch time: 12.5013, average train loss: 23.3420
[11/29 08:06:33 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.5159, average loss: 1.6945
[11/29 08:06:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.77	
[11/29 08:06:33 visual_prompt]: Training 3 / 100 epoch, with learning rate 5.0
[11/29 08:13:49 visual_prompt]: Epoch 3 / 100: avg data time: 1.16e+01, avg batch time: 12.4536, average train loss: 6.8467
[11/29 08:14:40 visual_prompt]: Inference (val):avg data time: 4.33e-05, avg batch time: 0.5222, average loss: 3.2745
[11/29 08:14:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.98	
[11/29 08:14:40 visual_prompt]: Training 4 / 100 epoch, with learning rate 7.5
[11/29 08:21:57 visual_prompt]: Epoch 4 / 100: avg data time: 1.16e+01, avg batch time: 12.4859, average train loss: 13.5289
[11/29 08:22:48 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.5183, average loss: 31.5207
[11/29 08:22:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.00	
[11/29 08:22:48 visual_prompt]: Training 5 / 100 epoch, with learning rate 10.0
[11/29 08:30:05 visual_prompt]: Epoch 5 / 100: avg data time: 1.16e+01, avg batch time: 12.4936, average train loss: 17.9638
[11/29 08:30:56 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.5256, average loss: 4.0814
[11/29 08:30:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.27	
[11/29 08:30:56 visual_prompt]: Training 6 / 100 epoch, with learning rate 12.5
[11/29 08:38:14 visual_prompt]: Epoch 6 / 100: avg data time: 1.16e+01, avg batch time: 12.5038, average train loss: 23.6279
[11/29 08:39:05 visual_prompt]: Inference (val):avg data time: 3.74e-05, avg batch time: 0.5238, average loss: 16.5253
[11/29 08:39:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.50	
[11/29 08:39:05 visual_prompt]: Training 7 / 100 epoch, with learning rate 15.0
[11/29 08:46:22 visual_prompt]: Epoch 7 / 100: avg data time: 1.16e+01, avg batch time: 12.4753, average train loss: 42.5847
[11/29 08:47:13 visual_prompt]: Inference (val):avg data time: 4.49e-05, avg batch time: 0.5223, average loss: 28.9656
[11/29 08:47:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.21	
[11/29 08:47:13 visual_prompt]: Training 8 / 100 epoch, with learning rate 17.5
[11/29 08:54:28 visual_prompt]: Epoch 8 / 100: avg data time: 1.16e+01, avg batch time: 12.4401, average train loss: 34.4184
[11/29 08:55:19 visual_prompt]: Inference (val):avg data time: 3.71e-05, avg batch time: 0.5193, average loss: 25.3895
[11/29 08:55:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.06	
[11/29 08:55:19 visual_prompt]: Training 9 / 100 epoch, with learning rate 20.0
[11/29 09:02:36 visual_prompt]: Epoch 9 / 100: avg data time: 1.16e+01, avg batch time: 12.4858, average train loss: 10.9663
[11/29 09:03:27 visual_prompt]: Inference (val):avg data time: 3.62e-05, avg batch time: 0.5220, average loss: 6.2567
[11/29 09:03:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 61.19	
[11/29 09:03:27 visual_prompt]: Training 10 / 100 epoch, with learning rate 22.5
[11/29 09:10:45 visual_prompt]: Epoch 10 / 100: avg data time: 1.16e+01, avg batch time: 12.5097, average train loss: 29.6243
[11/29 09:11:36 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.5161, average loss: 50.6515
[11/29 09:11:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 62.30	
[11/29 09:11:36 visual_prompt]: Training 11 / 100 epoch, with learning rate 25.0
[11/29 09:18:56 visual_prompt]: Epoch 11 / 100: avg data time: 1.17e+01, avg batch time: 12.5815, average train loss: 36.6971
[11/29 09:19:48 visual_prompt]: Inference (val):avg data time: 3.38e-05, avg batch time: 0.5234, average loss: 67.0725
[11/29 09:19:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.37	
[11/29 09:19:48 visual_prompt]: Training 12 / 100 epoch, with learning rate 24.9923853377387
[11/29 09:27:11 visual_prompt]: Epoch 12 / 100: avg data time: 1.18e+01, avg batch time: 12.6471, average train loss: 43.5188
[11/29 09:28:02 visual_prompt]: Inference (val):avg data time: 5.15e-05, avg batch time: 0.5182, average loss: 47.8986
[11/29 09:28:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.15	
[11/29 09:28:02 visual_prompt]: Best epoch 12: best metric: -47.899
[11/29 09:28:02 visual_prompt]: Training 13 / 100 epoch, with learning rate 24.969550628247802
[11/29 09:35:23 visual_prompt]: Epoch 13 / 100: avg data time: 1.17e+01, avg batch time: 12.5759, average train loss: 27.3156
[11/29 09:36:14 visual_prompt]: Inference (val):avg data time: 5.16e-05, avg batch time: 0.5172, average loss: 10.5741
[11/29 09:36:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.03	
[11/29 09:36:14 visual_prompt]: Best epoch 13: best metric: -10.574
[11/29 09:36:14 visual_prompt]: Training 14 / 100 epoch, with learning rate 24.931523692103415
[11/29 09:43:32 visual_prompt]: Epoch 14 / 100: avg data time: 1.16e+01, avg batch time: 12.5195, average train loss: 31.3186
[11/29 09:44:23 visual_prompt]: Inference (val):avg data time: 5.01e-05, avg batch time: 0.5149, average loss: 1.0008
[11/29 09:44:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 48.37	rocauc: 57.16	
[11/29 09:44:23 visual_prompt]: Best epoch 14: best metric: -1.001
[11/29 09:44:23 visual_prompt]: Training 15 / 100 epoch, with learning rate 24.87835085926963
[11/29 09:51:43 visual_prompt]: Epoch 15 / 100: avg data time: 1.17e+01, avg batch time: 12.5605, average train loss: 32.5071
[11/29 09:52:34 visual_prompt]: Inference (val):avg data time: 4.85e-05, avg batch time: 0.5211, average loss: 13.2455
[11/29 09:52:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.11	
[11/29 09:52:34 visual_prompt]: Training 16 / 100 epoch, with learning rate 24.8100969126526
[11/29 09:59:56 visual_prompt]: Epoch 16 / 100: avg data time: 1.18e+01, avg batch time: 12.6214, average train loss: 80.8210
[11/29 10:00:47 visual_prompt]: Inference (val):avg data time: 3.71e-05, avg batch time: 0.5227, average loss: 134.5552
[11/29 10:00:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.44	
[11/29 10:00:47 visual_prompt]: Training 17 / 100 epoch, with learning rate 24.72684500917257
[11/29 10:08:05 visual_prompt]: Epoch 17 / 100: avg data time: 1.17e+01, avg batch time: 12.5202, average train loss: 55.7091
[11/29 10:08:56 visual_prompt]: Inference (val):avg data time: 5.48e-05, avg batch time: 0.5312, average loss: 29.5391
[11/29 10:08:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.83	
[11/29 10:08:56 visual_prompt]: Training 18 / 100 epoch, with learning rate 24.628696578449954
[11/29 10:16:17 visual_prompt]: Epoch 18 / 100: avg data time: 1.17e+01, avg batch time: 12.5853, average train loss: 27.6651
[11/29 10:17:08 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.5185, average loss: 17.4893
[11/29 10:17:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.62	
[11/29 10:17:08 visual_prompt]: Training 19 / 100 epoch, with learning rate 24.515771199228986
[11/29 10:24:29 visual_prompt]: Epoch 19 / 100: avg data time: 1.17e+01, avg batch time: 12.5705, average train loss: 30.7046
[11/29 10:25:19 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.5139, average loss: 41.1395
[11/29 10:25:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.63	
[11/29 10:25:19 visual_prompt]: Training 20 / 100 epoch, with learning rate 24.38820645368942
[11/29 10:32:38 visual_prompt]: Epoch 20 / 100: avg data time: 1.16e+01, avg batch time: 12.5254, average train loss: 19.0451
[11/29 10:33:29 visual_prompt]: Inference (val):avg data time: 3.95e-05, avg batch time: 0.5155, average loss: 8.2098
[11/29 10:33:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.27	
[11/29 10:33:29 visual_prompt]: Training 21 / 100 epoch, with learning rate 24.246157759823856
[11/29 10:40:47 visual_prompt]: Epoch 21 / 100: avg data time: 1.16e+01, avg batch time: 12.5033, average train loss: 38.2065
[11/29 10:41:38 visual_prompt]: Inference (val):avg data time: 3.70e-05, avg batch time: 0.5223, average loss: 87.9089
[11/29 10:41:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 44.20	
[11/29 10:41:38 visual_prompt]: Stopping early.
[11/29 10:41:38 visual_prompt]: Rank of current process: 0. World size: 1
[11/29 10:41:38 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA TITAN Xp
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/29 10:41:38 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss', 'RECORD_GPU_SNAPSHOT', 'True'])
[11/29 10:41:38 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/29 10:41:38 visual_prompt]: Training with config:
[11/29 10:41:38 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr25.0_wd0.0/patience7/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 25.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True}), 'RECORD_GPU_SNAPSHOT': True})
[11/29 10:41:38 visual_prompt]: Loading training data...
[11/29 10:41:38 visual_prompt]: Constructing mammo-cbis dataset train...
[11/29 10:41:38 visual_prompt]: Loading validation data...
[11/29 10:41:38 visual_prompt]: Constructing mammo-cbis dataset val...
[11/29 10:41:38 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[11/29 10:41:41 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[11/29 10:41:41 visual_prompt]: tuned percent:0.536
[11/29 10:41:42 visual_prompt]: Device used for model: 0
[11/29 10:41:42 visual_prompt]: Setting up Evaluator...
[11/29 10:41:42 visual_prompt]: Setting up Trainer...
[11/29 10:41:42 visual_prompt]: 	Setting up the optimizer...
[11/29 10:41:42 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/29 10:49:02 visual_prompt]: Epoch 1 / 100: avg data time: 1.17e+01, avg batch time: 12.5703, average train loss: 1.4006
[11/29 10:49:52 visual_prompt]: Inference (val):avg data time: 4.43e-05, avg batch time: 0.5276, average loss: 1.2969
[11/29 10:49:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[11/29 10:49:52 visual_prompt]: Training 2 / 100 epoch, with learning rate 2.5
[11/29 10:57:19 visual_prompt]: Epoch 2 / 100: avg data time: 1.19e+01, avg batch time: 12.7563, average train loss: 23.2444
[11/29 10:58:11 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.5190, average loss: 0.7595
[11/29 10:58:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 47.15	rocauc: 56.32	
[11/29 10:58:11 visual_prompt]: Training 3 / 100 epoch, with learning rate 5.0
[11/29 11:05:29 visual_prompt]: Epoch 3 / 100: avg data time: 1.17e+01, avg batch time: 12.5360, average train loss: 12.6302
[11/29 11:06:20 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.5161, average loss: 5.1407
[11/29 11:06:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.78	
[11/29 11:06:20 visual_prompt]: Training 4 / 100 epoch, with learning rate 7.5
[11/29 11:13:36 visual_prompt]: Epoch 4 / 100: avg data time: 1.16e+01, avg batch time: 12.4632, average train loss: 12.7690
[11/29 11:14:27 visual_prompt]: Inference (val):avg data time: 4.61e-05, avg batch time: 0.5216, average loss: 22.4596
[11/29 11:14:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.25	
[11/29 11:14:27 visual_prompt]: Training 5 / 100 epoch, with learning rate 10.0
[11/29 11:21:46 visual_prompt]: Epoch 5 / 100: avg data time: 1.17e+01, avg batch time: 12.5404, average train loss: 14.5014
[11/29 11:22:37 visual_prompt]: Inference (val):avg data time: 4.17e-05, avg batch time: 0.5178, average loss: 8.8947
[11/29 11:22:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.46	
[11/29 11:22:37 visual_prompt]: Training 6 / 100 epoch, with learning rate 12.5
[11/29 11:29:56 visual_prompt]: Epoch 6 / 100: avg data time: 1.17e+01, avg batch time: 12.5443, average train loss: 19.9883
[11/29 11:30:47 visual_prompt]: Inference (val):avg data time: 3.86e-05, avg batch time: 0.5167, average loss: 49.3884
[11/29 11:30:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.02	
[11/29 11:30:47 visual_prompt]: Training 7 / 100 epoch, with learning rate 15.0
[11/29 11:38:07 visual_prompt]: Epoch 7 / 100: avg data time: 1.17e+01, avg batch time: 12.5721, average train loss: 37.1695
[11/29 11:38:59 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.5262, average loss: 18.4642
[11/29 11:38:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.75	
[11/29 11:38:59 visual_prompt]: Training 8 / 100 epoch, with learning rate 17.5
[11/29 11:46:16 visual_prompt]: Epoch 8 / 100: avg data time: 1.16e+01, avg batch time: 12.4806, average train loss: 10.4049
[11/29 11:47:06 visual_prompt]: Inference (val):avg data time: 4.59e-05, avg batch time: 0.5180, average loss: 2.4897
[11/29 11:47:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.40	
[11/29 11:47:06 visual_prompt]: Training 9 / 100 epoch, with learning rate 20.0
[11/29 11:54:33 visual_prompt]: Epoch 9 / 100: avg data time: 1.19e+01, avg batch time: 12.7703, average train loss: 23.1159
[11/29 11:55:24 visual_prompt]: Inference (val):avg data time: 3.68e-05, avg batch time: 0.5237, average loss: 1.9623
[11/29 11:55:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.83	
[11/29 11:55:24 visual_prompt]: Training 10 / 100 epoch, with learning rate 22.5
[11/29 12:02:42 visual_prompt]: Epoch 10 / 100: avg data time: 1.16e+01, avg batch time: 12.4969, average train loss: 40.3583
[11/29 12:03:32 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.5181, average loss: 94.7424
[11/29 12:03:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 45.32	
[11/29 12:03:32 visual_prompt]: Training 11 / 100 epoch, with learning rate 25.0
[11/29 12:10:52 visual_prompt]: Epoch 11 / 100: avg data time: 1.17e+01, avg batch time: 12.5619, average train loss: 55.4712
[11/29 12:11:43 visual_prompt]: Inference (val):avg data time: 4.98e-05, avg batch time: 0.5215, average loss: 162.2737
[11/29 12:11:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.03	
[11/29 12:11:43 visual_prompt]: Training 12 / 100 epoch, with learning rate 24.9923853377387
[11/29 12:19:03 visual_prompt]: Epoch 12 / 100: avg data time: 1.17e+01, avg batch time: 12.5791, average train loss: 35.7930
[11/29 12:19:54 visual_prompt]: Inference (val):avg data time: 3.62e-05, avg batch time: 0.5179, average loss: 1.2686
[11/29 12:19:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.94	
[11/29 12:19:54 visual_prompt]: Best epoch 12: best metric: -1.269
[11/29 12:19:54 visual_prompt]: Training 13 / 100 epoch, with learning rate 24.969550628247802
[11/29 12:27:14 visual_prompt]: Epoch 13 / 100: avg data time: 1.17e+01, avg batch time: 12.5502, average train loss: 44.0898
[11/29 12:28:04 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.5192, average loss: 38.4840
[11/29 12:28:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.53	
[11/29 12:28:04 visual_prompt]: Training 14 / 100 epoch, with learning rate 24.931523692103415
[11/29 12:35:21 visual_prompt]: Epoch 14 / 100: avg data time: 1.16e+01, avg batch time: 12.4626, average train loss: 59.5598
[11/29 12:36:12 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.5221, average loss: 82.5873
[11/29 12:36:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.52	
[11/29 12:36:12 visual_prompt]: Training 15 / 100 epoch, with learning rate 24.87835085926963
[11/29 12:43:30 visual_prompt]: Epoch 15 / 100: avg data time: 1.16e+01, avg batch time: 12.5220, average train loss: 38.4200
[11/29 12:44:21 visual_prompt]: Inference (val):avg data time: 4.86e-05, avg batch time: 0.5275, average loss: 45.0434
[11/29 12:44:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.27	
[11/29 12:44:21 visual_prompt]: Training 16 / 100 epoch, with learning rate 24.8100969126526
[11/29 12:51:41 visual_prompt]: Epoch 16 / 100: avg data time: 1.17e+01, avg batch time: 12.5527, average train loss: 32.8641
[11/29 12:52:32 visual_prompt]: Inference (val):avg data time: 3.64e-05, avg batch time: 0.5269, average loss: 23.7690
[11/29 12:52:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.69	
[11/29 12:52:32 visual_prompt]: Training 17 / 100 epoch, with learning rate 24.72684500917257
[11/29 12:59:49 visual_prompt]: Epoch 17 / 100: avg data time: 1.16e+01, avg batch time: 12.5034, average train loss: 15.7211
[11/29 13:00:40 visual_prompt]: Inference (val):avg data time: 3.58e-05, avg batch time: 0.5197, average loss: 30.0516
[11/29 13:00:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.51	
[11/29 13:00:40 visual_prompt]: Training 18 / 100 epoch, with learning rate 24.628696578449954
[11/29 13:07:58 visual_prompt]: Epoch 18 / 100: avg data time: 1.16e+01, avg batch time: 12.4984, average train loss: 16.7668
[11/29 13:08:49 visual_prompt]: Inference (val):avg data time: 3.75e-05, avg batch time: 0.5233, average loss: 34.4558
[11/29 13:08:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.33	
[11/29 13:08:49 visual_prompt]: Training 19 / 100 epoch, with learning rate 24.515771199228986
[11/29 13:16:32 visual_prompt]: Epoch 19 / 100: avg data time: 1.24e+01, avg batch time: 13.2390, average train loss: 12.1271
[11/29 13:17:29 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.5149, average loss: 19.3706
[11/29 13:17:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.33	
[11/29 13:17:29 visual_prompt]: Stopping early.
[11/29 13:17:30 visual_prompt]: Rank of current process: 0. World size: 1
[11/29 13:17:30 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA TITAN Xp
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/29 13:17:30 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss', 'RECORD_GPU_SNAPSHOT', 'True'])
[11/29 13:17:30 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/29 13:17:30 visual_prompt]: Training with config:
[11/29 13:17:30 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr10.0_wd0.01/patience7/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 10.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True}), 'RECORD_GPU_SNAPSHOT': True})
[11/29 13:17:30 visual_prompt]: Loading training data...
[11/29 13:17:30 visual_prompt]: Constructing mammo-cbis dataset train...
[11/29 13:17:30 visual_prompt]: Loading validation data...
[11/29 13:17:30 visual_prompt]: Constructing mammo-cbis dataset val...
[11/29 13:17:30 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[11/29 13:17:45 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[11/29 13:17:45 visual_prompt]: tuned percent:0.536
[11/29 13:17:45 visual_prompt]: Device used for model: 0
[11/29 13:17:45 visual_prompt]: Setting up Evaluator...
[11/29 13:17:45 visual_prompt]: Setting up Trainer...
[11/29 13:17:45 visual_prompt]: 	Setting up the optimizer...
[11/29 13:17:45 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/29 13:25:21 visual_prompt]: Epoch 1 / 100: avg data time: 1.22e+01, avg batch time: 13.0347, average train loss: 1.4006
[11/29 13:26:12 visual_prompt]: Inference (val):avg data time: 3.73e-05, avg batch time: 0.5263, average loss: 1.2969
[11/29 13:26:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[11/29 13:26:12 visual_prompt]: Training 2 / 100 epoch, with learning rate 1.0
[11/29 13:33:31 visual_prompt]: Epoch 2 / 100: avg data time: 1.17e+01, avg batch time: 12.5328, average train loss: 9.6878
[11/29 13:34:21 visual_prompt]: Inference (val):avg data time: 5.17e-05, avg batch time: 0.5268, average loss: 1.7040
[11/29 13:34:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.49	
[11/29 13:34:21 visual_prompt]: Training 3 / 100 epoch, with learning rate 2.0
[11/29 13:41:38 visual_prompt]: Epoch 3 / 100: avg data time: 1.16e+01, avg batch time: 12.4858, average train loss: 2.8475
[11/29 13:42:29 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.5251, average loss: 0.7634
[11/29 13:42:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.50	
[11/29 13:42:29 visual_prompt]: Training 4 / 100 epoch, with learning rate 3.0
[11/29 13:49:47 visual_prompt]: Epoch 4 / 100: avg data time: 1.16e+01, avg batch time: 12.5091, average train loss: 6.9648
[11/29 13:50:38 visual_prompt]: Inference (val):avg data time: 4.66e-05, avg batch time: 0.5208, average loss: 0.7041
[11/29 13:50:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.91	
[11/29 13:50:38 visual_prompt]: Training 5 / 100 epoch, with learning rate 4.0
[11/29 13:57:55 visual_prompt]: Epoch 5 / 100: avg data time: 1.16e+01, avg batch time: 12.4852, average train loss: 10.4579
[11/29 13:58:49 visual_prompt]: Inference (val):avg data time: 3.57e-05, avg batch time: 0.5258, average loss: 13.9793
[11/29 13:58:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 44.79	
[11/29 13:58:49 visual_prompt]: Training 6 / 100 epoch, with learning rate 5.0
[11/29 14:06:14 visual_prompt]: Epoch 6 / 100: avg data time: 1.19e+01, avg batch time: 12.7289, average train loss: 7.5407
[11/29 14:07:05 visual_prompt]: Inference (val):avg data time: 3.92e-05, avg batch time: 0.5291, average loss: 8.0931
[11/29 14:07:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.43	
[11/29 14:07:05 visual_prompt]: Training 7 / 100 epoch, with learning rate 6.0
[11/29 14:14:23 visual_prompt]: Epoch 7 / 100: avg data time: 1.16e+01, avg batch time: 12.5123, average train loss: 12.2111
[11/29 14:15:14 visual_prompt]: Inference (val):avg data time: 3.64e-05, avg batch time: 0.5239, average loss: 3.7391
[11/29 14:15:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.29	
[11/29 14:15:14 visual_prompt]: Training 8 / 100 epoch, with learning rate 7.0
[11/29 14:22:40 visual_prompt]: Epoch 8 / 100: avg data time: 1.19e+01, avg batch time: 12.7600, average train loss: 15.8164
[11/29 14:23:31 visual_prompt]: Inference (val):avg data time: 3.64e-05, avg batch time: 0.5225, average loss: 13.4892
[11/29 14:23:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.16	
[11/29 14:23:31 visual_prompt]: Training 9 / 100 epoch, with learning rate 8.0
[11/29 14:30:52 visual_prompt]: Epoch 9 / 100: avg data time: 1.17e+01, avg batch time: 12.5708, average train loss: 14.4870
[11/29 14:31:47 visual_prompt]: Inference (val):avg data time: 5.05e-05, avg batch time: 0.5278, average loss: 52.3034
[11/29 14:31:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.99	
[11/29 14:31:47 visual_prompt]: Training 10 / 100 epoch, with learning rate 9.0
[11/29 14:38:56 visual_prompt]: Epoch 10 / 100: avg data time: 1.14e+01, avg batch time: 12.2613, average train loss: 24.2669
[11/29 14:39:45 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.5214, average loss: 5.5893
[11/29 14:39:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.14	
[11/29 14:39:45 visual_prompt]: Training 11 / 100 epoch, with learning rate 10.0
[11/29 14:46:51 visual_prompt]: Epoch 11 / 100: avg data time: 1.13e+01, avg batch time: 12.1658, average train loss: 27.1817
[11/29 14:47:40 visual_prompt]: Inference (val):avg data time: 3.46e-05, avg batch time: 0.5239, average loss: 27.1629
[11/29 14:47:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.60	
[11/29 14:47:40 visual_prompt]: Training 12 / 100 epoch, with learning rate 9.996954135095478
[11/29 14:55:12 visual_prompt]: Epoch 12 / 100: avg data time: 1.20e+01, avg batch time: 12.8984, average train loss: 30.5393
[11/29 14:56:07 visual_prompt]: Inference (val):avg data time: 3.47e-05, avg batch time: 0.5204, average loss: 59.9750
[11/29 14:56:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 39.84	
[11/29 14:56:07 visual_prompt]: Training 13 / 100 epoch, with learning rate 9.987820251299121
[11/29 15:03:38 visual_prompt]: Epoch 13 / 100: avg data time: 1.20e+01, avg batch time: 12.8983, average train loss: 23.8207
[11/29 15:04:32 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.5216, average loss: 14.0262
[11/29 15:04:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.08	
[11/29 15:04:32 visual_prompt]: Best epoch 13: best metric: -14.026
[11/29 15:04:32 visual_prompt]: Training 14 / 100 epoch, with learning rate 9.972609476841367
[11/29 15:12:47 visual_prompt]: Epoch 14 / 100: avg data time: 1.33e+01, avg batch time: 14.1346, average train loss: 18.6387
[11/29 15:13:39 visual_prompt]: Inference (val):avg data time: 3.85e-05, avg batch time: 0.5259, average loss: 7.5840
[11/29 15:13:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.62	
[11/29 15:13:39 visual_prompt]: Best epoch 14: best metric: -7.584
[11/29 15:13:39 visual_prompt]: Training 15 / 100 epoch, with learning rate 9.951340343707852
[11/29 15:21:39 visual_prompt]: Epoch 15 / 100: avg data time: 1.28e+01, avg batch time: 13.7174, average train loss: 22.0395
[11/29 15:22:31 visual_prompt]: Inference (val):avg data time: 4.95e-05, avg batch time: 0.5266, average loss: 5.9340
[11/29 15:22:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.48	
[11/29 15:22:31 visual_prompt]: Best epoch 15: best metric: -5.934
[11/29 15:22:31 visual_prompt]: Training 16 / 100 epoch, with learning rate 9.924038765061042
[11/29 15:30:04 visual_prompt]: Epoch 16 / 100: avg data time: 1.21e+01, avg batch time: 12.9438, average train loss: 30.3283
[11/29 15:30:55 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.5273, average loss: 30.8174
[11/29 15:30:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 45.80	
[11/29 15:30:55 visual_prompt]: Training 17 / 100 epoch, with learning rate 9.890738003669028
[11/29 15:38:20 visual_prompt]: Epoch 17 / 100: avg data time: 1.18e+01, avg batch time: 12.7210, average train loss: 20.2773
[11/29 15:39:12 visual_prompt]: Inference (val):avg data time: 4.28e-05, avg batch time: 0.5240, average loss: 3.7752
[11/29 15:39:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 45.46	
[11/29 15:39:12 visual_prompt]: Best epoch 17: best metric: -3.775
[11/29 15:39:12 visual_prompt]: Training 18 / 100 epoch, with learning rate 9.851478631379981
[11/29 15:46:31 visual_prompt]: Epoch 18 / 100: avg data time: 1.17e+01, avg batch time: 12.5365, average train loss: 19.0705
[11/29 15:47:22 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.5237, average loss: 3.9265
[11/29 15:47:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.95	
[11/29 15:47:22 visual_prompt]: Training 19 / 100 epoch, with learning rate 9.806308479691594
[11/29 15:54:51 visual_prompt]: Epoch 19 / 100: avg data time: 1.20e+01, avg batch time: 12.8198, average train loss: 25.8139
[11/29 15:55:43 visual_prompt]: Inference (val):avg data time: 3.68e-05, avg batch time: 0.5261, average loss: 2.0072
[11/29 15:55:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.23	
[11/29 15:55:43 visual_prompt]: Best epoch 19: best metric: -2.007
[11/29 15:55:43 visual_prompt]: Training 20 / 100 epoch, with learning rate 9.755282581475768
[11/29 16:03:07 visual_prompt]: Epoch 20 / 100: avg data time: 1.18e+01, avg batch time: 12.6877, average train loss: 17.3089
[11/29 16:03:58 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.5218, average loss: 6.7882
[11/29 16:03:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 45.71	
[11/29 16:03:58 visual_prompt]: Training 21 / 100 epoch, with learning rate 9.698463103929543
[11/29 16:11:20 visual_prompt]: Epoch 21 / 100: avg data time: 1.17e+01, avg batch time: 12.6219, average train loss: 19.3203
[11/29 16:12:11 visual_prompt]: Inference (val):avg data time: 4.68e-05, avg batch time: 0.5233, average loss: 11.3943
[11/29 16:12:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.03	
[11/29 16:12:11 visual_prompt]: Training 22 / 100 epoch, with learning rate 9.635919272833938
[11/29 16:19:17 visual_prompt]: Epoch 22 / 100: avg data time: 1.13e+01, avg batch time: 12.1621, average train loss: 14.7027
[11/29 16:20:06 visual_prompt]: Inference (val):avg data time: 3.80e-05, avg batch time: 0.5253, average loss: 15.7471
[11/29 16:20:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.99	
[11/29 16:20:06 visual_prompt]: Training 23 / 100 epoch, with learning rate 9.567727288213003
[11/29 16:27:10 visual_prompt]: Epoch 23 / 100: avg data time: 1.12e+01, avg batch time: 12.0969, average train loss: 27.0608
[11/29 16:27:59 visual_prompt]: Inference (val):avg data time: 3.93e-05, avg batch time: 0.5240, average loss: 41.6329
[11/29 16:27:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.62	
[11/29 16:27:59 visual_prompt]: Training 24 / 100 epoch, with learning rate 9.493970231495835
[11/29 16:35:02 visual_prompt]: Epoch 24 / 100: avg data time: 1.12e+01, avg batch time: 12.0918, average train loss: 21.6319
[11/29 16:35:51 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.5304, average loss: 3.8854
[11/29 16:35:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.14	
[11/29 16:35:51 visual_prompt]: Training 25 / 100 epoch, with learning rate 9.414737964294634
[11/29 16:42:54 visual_prompt]: Epoch 25 / 100: avg data time: 1.12e+01, avg batch time: 12.0634, average train loss: 20.8695
[11/29 16:43:43 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.5246, average loss: 40.8797
[11/29 16:43:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 45.46	
[11/29 16:43:43 visual_prompt]: Training 26 / 100 epoch, with learning rate 9.330127018922195
[11/29 16:50:53 visual_prompt]: Epoch 26 / 100: avg data time: 1.14e+01, avg batch time: 12.2971, average train loss: 21.9512
[11/29 16:51:45 visual_prompt]: Inference (val):avg data time: 3.75e-05, avg batch time: 0.5172, average loss: 26.2833
[11/29 16:51:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.09	
[11/29 16:51:45 visual_prompt]: Stopping early.
[11/29 16:51:45 visual_prompt]: Rank of current process: 0. World size: 1
[11/29 16:51:45 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA TITAN Xp
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/29 16:51:45 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss', 'RECORD_GPU_SNAPSHOT', 'True'])
[11/29 16:51:45 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/29 16:51:45 visual_prompt]: Training with config:
[11/29 16:51:45 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr10.0_wd0.001/patience7/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 10.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True}), 'RECORD_GPU_SNAPSHOT': True})
[11/29 16:51:45 visual_prompt]: Loading training data...
[11/29 16:51:45 visual_prompt]: Constructing mammo-cbis dataset train...
[11/29 16:51:45 visual_prompt]: Loading validation data...
[11/29 16:51:45 visual_prompt]: Constructing mammo-cbis dataset val...
[11/29 16:51:45 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[11/29 16:51:55 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[11/29 16:51:55 visual_prompt]: tuned percent:0.536
[11/29 16:51:55 visual_prompt]: Device used for model: 0
[11/29 16:51:55 visual_prompt]: Setting up Evaluator...
[11/29 16:51:55 visual_prompt]: Setting up Trainer...
[11/29 16:51:55 visual_prompt]: 	Setting up the optimizer...
[11/29 16:51:55 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/29 16:59:13 visual_prompt]: Epoch 1 / 100: avg data time: 1.16e+01, avg batch time: 12.5018, average train loss: 1.4006
[11/29 17:00:04 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.5255, average loss: 1.2969
[11/29 17:00:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[11/29 17:00:04 visual_prompt]: Training 2 / 100 epoch, with learning rate 1.0
[11/29 17:07:06 visual_prompt]: Epoch 2 / 100: avg data time: 1.12e+01, avg batch time: 12.0578, average train loss: 10.1201
[11/29 17:07:55 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.5279, average loss: 2.1930
[11/29 17:07:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.01	
[11/29 17:07:55 visual_prompt]: Training 3 / 100 epoch, with learning rate 2.0
[11/29 17:15:13 visual_prompt]: Epoch 3 / 100: avg data time: 1.16e+01, avg batch time: 12.4972, average train loss: 3.4053
[11/29 17:16:04 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.5237, average loss: 3.8260
[11/29 17:16:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.26	
[11/29 17:16:04 visual_prompt]: Training 4 / 100 epoch, with learning rate 3.0
[11/29 17:23:17 visual_prompt]: Epoch 4 / 100: avg data time: 1.15e+01, avg batch time: 12.3850, average train loss: 2.3014
[11/29 17:24:08 visual_prompt]: Inference (val):avg data time: 3.80e-05, avg batch time: 0.5195, average loss: 1.4221
[11/29 17:24:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.75	
[11/29 17:24:08 visual_prompt]: Training 5 / 100 epoch, with learning rate 4.0
[11/29 17:31:19 visual_prompt]: Epoch 5 / 100: avg data time: 1.14e+01, avg batch time: 12.3213, average train loss: 4.2847
[11/29 17:32:09 visual_prompt]: Inference (val):avg data time: 3.77e-05, avg batch time: 0.5225, average loss: 2.4232
[11/29 17:32:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.93	
[11/29 17:32:09 visual_prompt]: Training 6 / 100 epoch, with learning rate 5.0
[11/29 17:39:15 visual_prompt]: Epoch 6 / 100: avg data time: 1.13e+01, avg batch time: 12.1630, average train loss: 4.8928
[11/29 17:40:05 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.5241, average loss: 6.3698
[11/29 17:40:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.97	
[11/29 17:40:05 visual_prompt]: Training 7 / 100 epoch, with learning rate 6.0
[11/29 17:47:22 visual_prompt]: Epoch 7 / 100: avg data time: 1.16e+01, avg batch time: 12.4692, average train loss: 6.9463
[11/29 17:48:11 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.5280, average loss: 0.7822
[11/29 17:48:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.04	
[11/29 17:48:11 visual_prompt]: Training 8 / 100 epoch, with learning rate 7.0
[11/29 17:55:24 visual_prompt]: Epoch 8 / 100: avg data time: 1.15e+01, avg batch time: 12.3628, average train loss: 8.9275
[11/29 17:56:14 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.5257, average loss: 14.4215
[11/29 17:56:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.16	
[11/29 17:56:14 visual_prompt]: Training 9 / 100 epoch, with learning rate 8.0
[11/29 18:03:27 visual_prompt]: Epoch 9 / 100: avg data time: 1.15e+01, avg batch time: 12.3582, average train loss: 12.5080
[11/29 18:04:17 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.5277, average loss: 2.9173
[11/29 18:04:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.68	
[11/29 18:04:17 visual_prompt]: Training 10 / 100 epoch, with learning rate 9.0
[11/29 18:11:28 visual_prompt]: Epoch 10 / 100: avg data time: 1.14e+01, avg batch time: 12.3116, average train loss: 15.9372
[11/29 18:12:17 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.5224, average loss: 9.9117
[11/29 18:12:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 45.83	
[11/29 18:12:17 visual_prompt]: Training 11 / 100 epoch, with learning rate 10.0
[11/29 18:19:16 visual_prompt]: Epoch 11 / 100: avg data time: 1.11e+01, avg batch time: 11.9741, average train loss: 15.8442
[11/29 18:20:04 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.5224, average loss: 23.2342
[11/29 18:20:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.81	
[11/29 18:20:04 visual_prompt]: Training 12 / 100 epoch, with learning rate 9.996954135095478
[11/29 18:27:03 visual_prompt]: Epoch 12 / 100: avg data time: 1.11e+01, avg batch time: 11.9464, average train loss: 24.9834
[11/29 18:27:51 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.5260, average loss: 2.3868
[11/29 18:27:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.44	
[11/29 18:27:51 visual_prompt]: Best epoch 12: best metric: -2.387
[11/29 18:27:51 visual_prompt]: Training 13 / 100 epoch, with learning rate 9.987820251299121
[11/29 18:34:49 visual_prompt]: Epoch 13 / 100: avg data time: 1.11e+01, avg batch time: 11.9520, average train loss: 13.8200
[11/29 18:35:38 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.5251, average loss: 5.9859
[11/29 18:35:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.45	
[11/29 18:35:38 visual_prompt]: Training 14 / 100 epoch, with learning rate 9.972609476841367
[11/29 18:42:37 visual_prompt]: Epoch 14 / 100: avg data time: 1.11e+01, avg batch time: 11.9803, average train loss: 11.9746
[11/29 18:43:26 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.5257, average loss: 1.8129
[11/29 18:43:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.24	
[11/29 18:43:26 visual_prompt]: Best epoch 14: best metric: -1.813
[11/29 18:43:26 visual_prompt]: Training 15 / 100 epoch, with learning rate 9.951340343707852
[11/29 18:50:26 visual_prompt]: Epoch 15 / 100: avg data time: 1.11e+01, avg batch time: 12.0018, average train loss: 20.0068
[11/29 18:51:15 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.5259, average loss: 27.1529
[11/29 18:51:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.63	
[11/29 18:51:15 visual_prompt]: Training 16 / 100 epoch, with learning rate 9.924038765061042
[11/29 18:58:15 visual_prompt]: Epoch 16 / 100: avg data time: 1.11e+01, avg batch time: 11.9898, average train loss: 20.6050
[11/29 18:59:03 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.5208, average loss: 15.1098
[11/29 18:59:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.14	
[11/29 18:59:03 visual_prompt]: Training 17 / 100 epoch, with learning rate 9.890738003669028
[11/29 19:06:00 visual_prompt]: Epoch 17 / 100: avg data time: 1.10e+01, avg batch time: 11.9072, average train loss: 25.0266
[11/29 19:06:48 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.5201, average loss: 14.8906
[11/29 19:06:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.17	
[11/29 19:06:48 visual_prompt]: Training 18 / 100 epoch, with learning rate 9.851478631379981
[11/29 19:13:45 visual_prompt]: Epoch 18 / 100: avg data time: 1.10e+01, avg batch time: 11.9177, average train loss: 18.4176
[11/29 19:14:33 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.5247, average loss: 6.2258
[11/29 19:14:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.20	
[11/29 19:14:33 visual_prompt]: Training 19 / 100 epoch, with learning rate 9.806308479691594
[11/29 19:21:29 visual_prompt]: Epoch 19 / 100: avg data time: 1.10e+01, avg batch time: 11.8930, average train loss: 23.5572
[11/29 19:22:18 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.5226, average loss: 55.8363
[11/29 19:22:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.49	
[11/29 19:22:18 visual_prompt]: Training 20 / 100 epoch, with learning rate 9.755282581475768
[11/29 19:29:14 visual_prompt]: Epoch 20 / 100: avg data time: 1.10e+01, avg batch time: 11.8841, average train loss: 26.3414
[11/29 19:30:02 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.5232, average loss: 39.1729
[11/29 19:30:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 45.58	
[11/29 19:30:02 visual_prompt]: Training 21 / 100 epoch, with learning rate 9.698463103929543
[11/29 19:36:59 visual_prompt]: Epoch 21 / 100: avg data time: 1.10e+01, avg batch time: 11.8903, average train loss: 21.2023
[11/29 19:37:47 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.5252, average loss: 24.5147
[11/29 19:37:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.00	
[11/29 19:37:47 visual_prompt]: Stopping early.
[11/29 19:37:47 visual_prompt]: Rank of current process: 0. World size: 1
[11/29 19:37:47 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA TITAN Xp
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/29 19:37:47 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss', 'RECORD_GPU_SNAPSHOT', 'True'])
[11/29 19:37:47 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/29 19:37:47 visual_prompt]: Training with config:
[11/29 19:37:47 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr10.0_wd0.0001/patience7/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 10.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True}), 'RECORD_GPU_SNAPSHOT': True})
[11/29 19:37:47 visual_prompt]: Loading training data...
[11/29 19:37:47 visual_prompt]: Constructing mammo-cbis dataset train...
[11/29 19:37:48 visual_prompt]: Loading validation data...
[11/29 19:37:48 visual_prompt]: Constructing mammo-cbis dataset val...
[11/29 19:37:48 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[11/29 19:37:57 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[11/29 19:37:57 visual_prompt]: tuned percent:0.536
[11/29 19:37:57 visual_prompt]: Device used for model: 0
[11/29 19:37:57 visual_prompt]: Setting up Evaluator...
[11/29 19:37:57 visual_prompt]: Setting up Trainer...
[11/29 19:37:57 visual_prompt]: 	Setting up the optimizer...
[11/29 19:37:57 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/29 19:44:55 visual_prompt]: Epoch 1 / 100: avg data time: 1.11e+01, avg batch time: 11.9480, average train loss: 1.4006
[11/29 19:45:43 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.5261, average loss: 1.2969
[11/29 19:45:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[11/29 19:45:43 visual_prompt]: Training 2 / 100 epoch, with learning rate 1.0
[11/29 19:52:42 visual_prompt]: Epoch 2 / 100: avg data time: 1.11e+01, avg batch time: 11.9603, average train loss: 10.1987
[11/29 19:53:30 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.5251, average loss: 2.5202
[11/29 19:53:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.96	
[11/29 19:53:30 visual_prompt]: Training 3 / 100 epoch, with learning rate 2.0
[11/29 20:00:27 visual_prompt]: Epoch 3 / 100: avg data time: 1.10e+01, avg batch time: 11.9131, average train loss: 2.5644
[11/29 20:01:15 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.5270, average loss: 3.9701
[11/29 20:01:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.83	
[11/29 20:01:15 visual_prompt]: Training 4 / 100 epoch, with learning rate 3.0
[11/29 20:08:14 visual_prompt]: Epoch 4 / 100: avg data time: 1.11e+01, avg batch time: 11.9699, average train loss: 2.8702
[11/29 20:09:03 visual_prompt]: Inference (val):avg data time: 3.45e-05, avg batch time: 0.5193, average loss: 1.1752
[11/29 20:09:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.86	
[11/29 20:09:03 visual_prompt]: Training 5 / 100 epoch, with learning rate 4.0
[11/29 20:15:59 visual_prompt]: Epoch 5 / 100: avg data time: 1.10e+01, avg batch time: 11.8838, average train loss: 6.8052
[11/29 20:16:47 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.5233, average loss: 8.3414
[11/29 20:16:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.14	
[11/29 20:16:47 visual_prompt]: Training 6 / 100 epoch, with learning rate 5.0
[11/29 20:23:44 visual_prompt]: Epoch 6 / 100: avg data time: 1.10e+01, avg batch time: 11.9107, average train loss: 8.7556
[11/29 20:24:33 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.5249, average loss: 2.1012
[11/29 20:24:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.26	
[11/29 20:24:33 visual_prompt]: Training 7 / 100 epoch, with learning rate 6.0
[11/29 20:31:30 visual_prompt]: Epoch 7 / 100: avg data time: 1.10e+01, avg batch time: 11.9147, average train loss: 4.3254
[11/29 20:32:18 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.5290, average loss: 3.5681
[11/29 20:32:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.86	
[11/29 20:32:18 visual_prompt]: Training 8 / 100 epoch, with learning rate 7.0
[11/29 20:39:13 visual_prompt]: Epoch 8 / 100: avg data time: 1.10e+01, avg batch time: 11.8719, average train loss: 3.1552
[11/29 20:40:02 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.5224, average loss: 2.1651
[11/29 20:40:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.32	
[11/29 20:40:02 visual_prompt]: Training 9 / 100 epoch, with learning rate 8.0
[11/29 20:46:59 visual_prompt]: Epoch 9 / 100: avg data time: 1.10e+01, avg batch time: 11.9212, average train loss: 8.6852
[11/29 20:47:47 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.5301, average loss: 2.7322
[11/29 20:47:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.15	
[11/29 20:47:47 visual_prompt]: Training 10 / 100 epoch, with learning rate 9.0
[11/29 20:54:43 visual_prompt]: Epoch 10 / 100: avg data time: 1.10e+01, avg batch time: 11.8871, average train loss: 12.1530
[11/29 20:55:32 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.5210, average loss: 7.9331
[11/29 20:55:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.03	
[11/29 20:55:32 visual_prompt]: Training 11 / 100 epoch, with learning rate 10.0
[11/29 21:02:29 visual_prompt]: Epoch 11 / 100: avg data time: 1.11e+01, avg batch time: 11.9232, average train loss: 23.0792
[11/29 21:03:17 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.5287, average loss: 16.2686
[11/29 21:03:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 42.97	
[11/29 21:03:17 visual_prompt]: Training 12 / 100 epoch, with learning rate 9.996954135095478
[11/29 21:10:13 visual_prompt]: Epoch 12 / 100: avg data time: 1.10e+01, avg batch time: 11.8820, average train loss: 24.5487
[11/29 21:11:01 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.5262, average loss: 49.6954
[11/29 21:11:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 45.95	
[11/29 21:11:01 visual_prompt]: Training 13 / 100 epoch, with learning rate 9.987820251299121
[11/29 21:17:58 visual_prompt]: Epoch 13 / 100: avg data time: 1.10e+01, avg batch time: 11.9100, average train loss: 21.6232
[11/29 21:18:47 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.5218, average loss: 38.3648
[11/29 21:18:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.55	
[11/29 21:18:47 visual_prompt]: Training 14 / 100 epoch, with learning rate 9.972609476841367
[11/29 21:25:43 visual_prompt]: Epoch 14 / 100: avg data time: 1.10e+01, avg batch time: 11.8784, average train loss: 28.2021
[11/29 21:26:31 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.5230, average loss: 11.8693
[11/29 21:26:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.33	
[11/29 21:26:31 visual_prompt]: Best epoch 14: best metric: -11.869
[11/29 21:26:31 visual_prompt]: Training 15 / 100 epoch, with learning rate 9.951340343707852
[11/29 21:33:29 visual_prompt]: Epoch 15 / 100: avg data time: 1.11e+01, avg batch time: 11.9302, average train loss: 7.1888
[11/29 21:34:17 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.5232, average loss: 11.5257
[11/29 21:34:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.11	
[11/29 21:34:17 visual_prompt]: Best epoch 15: best metric: -11.526
[11/29 21:34:17 visual_prompt]: Training 16 / 100 epoch, with learning rate 9.924038765061042
[11/29 21:41:13 visual_prompt]: Epoch 16 / 100: avg data time: 1.10e+01, avg batch time: 11.8836, average train loss: 5.9526
[11/29 21:42:01 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.5239, average loss: 10.4423
[11/29 21:42:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.45	
[11/29 21:42:01 visual_prompt]: Best epoch 16: best metric: -10.442
[11/29 21:42:01 visual_prompt]: Training 17 / 100 epoch, with learning rate 9.890738003669028
[11/29 21:48:58 visual_prompt]: Epoch 17 / 100: avg data time: 1.10e+01, avg batch time: 11.8978, average train loss: 8.1148
[11/29 21:49:46 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.5220, average loss: 6.6077
[11/29 21:49:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.45	
[11/29 21:49:46 visual_prompt]: Best epoch 17: best metric: -6.608
[11/29 21:49:46 visual_prompt]: Training 18 / 100 epoch, with learning rate 9.851478631379981
[11/29 21:56:42 visual_prompt]: Epoch 18 / 100: avg data time: 1.10e+01, avg batch time: 11.8786, average train loss: 11.7990
[11/29 21:57:30 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.5260, average loss: 3.0264
[11/29 21:57:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.08	
[11/29 21:57:30 visual_prompt]: Best epoch 18: best metric: -3.026
[11/29 21:57:30 visual_prompt]: Training 19 / 100 epoch, with learning rate 9.806308479691594
[11/29 22:04:30 visual_prompt]: Epoch 19 / 100: avg data time: 1.11e+01, avg batch time: 12.0041, average train loss: 8.5704
[11/29 22:05:21 visual_prompt]: Inference (val):avg data time: 3.80e-05, avg batch time: 0.5253, average loss: 0.7341
[11/29 22:05:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.34	
[11/29 22:05:21 visual_prompt]: Best epoch 19: best metric: -0.734
[11/29 22:05:21 visual_prompt]: Training 20 / 100 epoch, with learning rate 9.755282581475768
[11/29 22:12:34 visual_prompt]: Epoch 20 / 100: avg data time: 1.15e+01, avg batch time: 12.3757, average train loss: 3.7360
[11/29 22:13:22 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.5239, average loss: 4.5141
[11/29 22:13:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.24	
[11/29 22:13:22 visual_prompt]: Training 21 / 100 epoch, with learning rate 9.698463103929543
[11/29 22:20:33 visual_prompt]: Epoch 21 / 100: avg data time: 1.14e+01, avg batch time: 12.3063, average train loss: 5.4714
[11/29 22:21:23 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.5287, average loss: 0.8325
[11/29 22:21:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.81	
[11/29 22:21:23 visual_prompt]: Training 22 / 100 epoch, with learning rate 9.635919272833938
[11/29 22:28:29 visual_prompt]: Epoch 22 / 100: avg data time: 1.13e+01, avg batch time: 12.1564, average train loss: 8.2995
[11/29 22:29:19 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.5251, average loss: 0.7415
[11/29 22:29:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.99	
[11/29 22:29:19 visual_prompt]: Training 23 / 100 epoch, with learning rate 9.567727288213003
[11/29 22:36:30 visual_prompt]: Epoch 23 / 100: avg data time: 1.14e+01, avg batch time: 12.2874, average train loss: 3.8361
[11/29 22:37:17 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.5203, average loss: 17.2913
[11/29 22:37:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.17	
[11/29 22:37:17 visual_prompt]: Training 24 / 100 epoch, with learning rate 9.493970231495835
[11/29 22:44:14 visual_prompt]: Epoch 24 / 100: avg data time: 1.10e+01, avg batch time: 11.8973, average train loss: 5.9416
[11/29 22:45:02 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.5240, average loss: 1.0192
[11/29 22:45:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.13	
[11/29 22:45:02 visual_prompt]: Training 25 / 100 epoch, with learning rate 9.414737964294634
[11/29 22:51:58 visual_prompt]: Epoch 25 / 100: avg data time: 1.10e+01, avg batch time: 11.8819, average train loss: 14.1372
[11/29 22:52:46 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.5280, average loss: 9.3590
[11/29 22:52:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.62	
[11/29 22:52:46 visual_prompt]: Training 26 / 100 epoch, with learning rate 9.330127018922195
[11/29 22:59:44 visual_prompt]: Epoch 26 / 100: avg data time: 1.11e+01, avg batch time: 11.9246, average train loss: 10.5590
[11/29 23:00:32 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.5257, average loss: 6.5284
[11/29 23:00:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.73	
[11/29 23:00:32 visual_prompt]: Stopping early.
[11/29 23:00:32 visual_prompt]: Rank of current process: 0. World size: 1
[11/29 23:00:32 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA TITAN Xp
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/29 23:00:32 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss', 'RECORD_GPU_SNAPSHOT', 'True'])
[11/29 23:00:32 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/29 23:00:32 visual_prompt]: Training with config:
[11/29 23:00:32 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr10.0_wd0.0/patience7/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 10.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True}), 'RECORD_GPU_SNAPSHOT': True})
[11/29 23:00:32 visual_prompt]: Loading training data...
[11/29 23:00:32 visual_prompt]: Constructing mammo-cbis dataset train...
[11/29 23:00:32 visual_prompt]: Loading validation data...
[11/29 23:00:32 visual_prompt]: Constructing mammo-cbis dataset val...
[11/29 23:00:32 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[11/29 23:00:40 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[11/29 23:00:40 visual_prompt]: tuned percent:0.536
[11/29 23:00:40 visual_prompt]: Device used for model: 0
[11/29 23:00:40 visual_prompt]: Setting up Evaluator...
[11/29 23:00:40 visual_prompt]: Setting up Trainer...
[11/29 23:00:40 visual_prompt]: 	Setting up the optimizer...
[11/29 23:00:40 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/29 23:07:36 visual_prompt]: Epoch 1 / 100: avg data time: 1.10e+01, avg batch time: 11.8965, average train loss: 1.4006
[11/29 23:08:25 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.5288, average loss: 1.2969
[11/29 23:08:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[11/29 23:08:25 visual_prompt]: Training 2 / 100 epoch, with learning rate 1.0
[11/29 23:15:21 visual_prompt]: Epoch 2 / 100: avg data time: 1.10e+01, avg batch time: 11.8895, average train loss: 10.2088
[11/29 23:16:09 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.5331, average loss: 2.5505
[11/29 23:16:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.17	
[11/29 23:16:09 visual_prompt]: Training 3 / 100 epoch, with learning rate 2.0
[11/29 23:23:48 visual_prompt]: Epoch 3 / 100: avg data time: 1.22e+01, avg batch time: 13.1025, average train loss: 1.4470
[11/29 23:24:39 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.5277, average loss: 0.9457
[11/29 23:24:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.98	
[11/29 23:24:39 visual_prompt]: Training 4 / 100 epoch, with learning rate 3.0
[11/29 23:32:02 visual_prompt]: Epoch 4 / 100: avg data time: 1.18e+01, avg batch time: 12.6468, average train loss: 3.2261
[11/29 23:32:53 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.5314, average loss: 4.6026
[11/29 23:32:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.94	
[11/29 23:32:53 visual_prompt]: Training 5 / 100 epoch, with learning rate 4.0
[11/29 23:40:14 visual_prompt]: Epoch 5 / 100: avg data time: 1.17e+01, avg batch time: 12.6038, average train loss: 8.2075
[11/29 23:41:05 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.5268, average loss: 0.9075
[11/29 23:41:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.71	
[11/29 23:41:05 visual_prompt]: Training 6 / 100 epoch, with learning rate 5.0
[11/29 23:48:28 visual_prompt]: Epoch 6 / 100: avg data time: 1.18e+01, avg batch time: 12.6364, average train loss: 8.0717
[11/29 23:49:19 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.5261, average loss: 6.1090
[11/29 23:49:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.48	
[11/29 23:49:19 visual_prompt]: Training 7 / 100 epoch, with learning rate 6.0
[11/29 23:56:41 visual_prompt]: Epoch 7 / 100: avg data time: 1.17e+01, avg batch time: 12.6275, average train loss: 6.7583
[11/29 23:57:32 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.5315, average loss: 10.7021
[11/29 23:57:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.98	
[11/29 23:57:32 visual_prompt]: Training 8 / 100 epoch, with learning rate 7.0
[11/30 00:04:53 visual_prompt]: Epoch 8 / 100: avg data time: 1.17e+01, avg batch time: 12.6098, average train loss: 9.9355
[11/30 00:05:44 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.5233, average loss: 0.7084
[11/30 00:05:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.04	
[11/30 00:05:44 visual_prompt]: Training 9 / 100 epoch, with learning rate 8.0
[11/30 00:13:07 visual_prompt]: Epoch 9 / 100: avg data time: 1.18e+01, avg batch time: 12.6404, average train loss: 3.5084
[11/30 00:13:57 visual_prompt]: Inference (val):avg data time: 3.74e-05, avg batch time: 0.5288, average loss: 7.9393
[11/30 00:13:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.22	
[11/30 00:13:57 visual_prompt]: Training 10 / 100 epoch, with learning rate 9.0
[11/30 00:21:19 visual_prompt]: Epoch 10 / 100: avg data time: 1.17e+01, avg batch time: 12.6157, average train loss: 8.4031
[11/30 00:22:10 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.5304, average loss: 14.8827
[11/30 00:22:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.81	
[11/30 00:22:10 visual_prompt]: Training 11 / 100 epoch, with learning rate 10.0
[11/30 00:29:32 visual_prompt]: Epoch 11 / 100: avg data time: 1.17e+01, avg batch time: 12.6135, average train loss: 8.3237
[11/30 00:30:23 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.5300, average loss: 3.5747
[11/30 00:30:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.38	
[11/30 00:30:23 visual_prompt]: Training 12 / 100 epoch, with learning rate 9.996954135095478
[11/30 00:37:44 visual_prompt]: Epoch 12 / 100: avg data time: 1.17e+01, avg batch time: 12.6115, average train loss: 6.5167
[11/30 00:38:35 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.5253, average loss: 15.7908
[11/30 00:38:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.81	
[11/30 00:38:35 visual_prompt]: Training 13 / 100 epoch, with learning rate 9.987820251299121
[11/30 00:45:57 visual_prompt]: Epoch 13 / 100: avg data time: 1.18e+01, avg batch time: 12.6288, average train loss: 6.7646
[11/30 00:46:48 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.5339, average loss: 3.6533
[11/30 00:46:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.14	
[11/30 00:46:48 visual_prompt]: Training 14 / 100 epoch, with learning rate 9.972609476841367
[11/30 00:54:10 visual_prompt]: Epoch 14 / 100: avg data time: 1.17e+01, avg batch time: 12.6021, average train loss: 2.7122
[11/30 00:55:00 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.5285, average loss: 1.0168
[11/30 00:55:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.00	
[11/30 00:55:01 visual_prompt]: Best epoch 14: best metric: -1.017
[11/30 00:55:01 visual_prompt]: Training 15 / 100 epoch, with learning rate 9.951340343707852
[11/30 01:02:36 visual_prompt]: Epoch 15 / 100: avg data time: 1.21e+01, avg batch time: 13.0097, average train loss: 6.1370
[11/30 01:03:28 visual_prompt]: Inference (val):avg data time: 3.57e-05, avg batch time: 0.5313, average loss: 3.7023
[11/30 01:03:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.86	
[11/30 01:03:28 visual_prompt]: Training 16 / 100 epoch, with learning rate 9.924038765061042
[11/30 01:10:55 visual_prompt]: Epoch 16 / 100: avg data time: 1.19e+01, avg batch time: 12.7546, average train loss: 10.8778
[11/30 01:11:46 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.5269, average loss: 4.6222
[11/30 01:11:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.79	
[11/30 01:11:46 visual_prompt]: Training 17 / 100 epoch, with learning rate 9.890738003669028
[11/30 01:19:07 visual_prompt]: Epoch 17 / 100: avg data time: 1.17e+01, avg batch time: 12.5887, average train loss: 4.8772
[11/30 01:19:58 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.5318, average loss: 10.4433
[11/30 01:19:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.85	
[11/30 01:19:58 visual_prompt]: Training 18 / 100 epoch, with learning rate 9.851478631379981
[11/30 01:26:59 visual_prompt]: Epoch 18 / 100: avg data time: 1.12e+01, avg batch time: 12.0321, average train loss: 12.3658
[11/30 01:27:47 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.5326, average loss: 4.3448
[11/30 01:27:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.19	
[11/30 01:27:47 visual_prompt]: Training 19 / 100 epoch, with learning rate 9.806308479691594
[11/30 01:34:43 visual_prompt]: Epoch 19 / 100: avg data time: 1.10e+01, avg batch time: 11.8779, average train loss: 15.7922
[11/30 01:35:31 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.5286, average loss: 8.2085
[11/30 01:35:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.86	
[11/30 01:35:31 visual_prompt]: Training 20 / 100 epoch, with learning rate 9.755282581475768
[11/30 01:42:26 visual_prompt]: Epoch 20 / 100: avg data time: 1.10e+01, avg batch time: 11.8530, average train loss: 5.2009
[11/30 01:43:14 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.5254, average loss: 1.2667
[11/30 01:43:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.51	
[11/30 01:43:14 visual_prompt]: Training 21 / 100 epoch, with learning rate 9.698463103929543
[11/30 01:50:09 visual_prompt]: Epoch 21 / 100: avg data time: 1.10e+01, avg batch time: 11.8608, average train loss: 7.9571
[11/30 01:50:57 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.5290, average loss: 13.6850
[11/30 01:50:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.65	
[11/30 01:50:57 visual_prompt]: Stopping early.
[11/30 01:50:57 visual_prompt]: Rank of current process: 0. World size: 1
[11/30 01:50:57 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA TITAN Xp
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/30 01:50:57 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss', 'RECORD_GPU_SNAPSHOT', 'True'])
[11/30 01:50:57 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/30 01:50:57 visual_prompt]: Training with config:
[11/30 01:50:57 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr5.0_wd0.01/patience7/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 5.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True}), 'RECORD_GPU_SNAPSHOT': True})
[11/30 01:50:57 visual_prompt]: Loading training data...
[11/30 01:50:57 visual_prompt]: Constructing mammo-cbis dataset train...
[11/30 01:50:58 visual_prompt]: Loading validation data...
[11/30 01:50:58 visual_prompt]: Constructing mammo-cbis dataset val...
[11/30 01:50:58 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[11/30 01:51:05 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[11/30 01:51:05 visual_prompt]: tuned percent:0.536
[11/30 01:51:05 visual_prompt]: Device used for model: 0
[11/30 01:51:05 visual_prompt]: Setting up Evaluator...
[11/30 01:51:05 visual_prompt]: Setting up Trainer...
[11/30 01:51:05 visual_prompt]: 	Setting up the optimizer...
[11/30 01:51:05 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/30 01:58:04 visual_prompt]: Epoch 1 / 100: avg data time: 1.11e+01, avg batch time: 11.9497, average train loss: 1.4006
[11/30 01:58:52 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.5261, average loss: 1.2969
[11/30 01:58:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[11/30 01:58:52 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.5
[11/30 02:05:49 visual_prompt]: Epoch 2 / 100: avg data time: 1.10e+01, avg batch time: 11.9112, average train loss: 5.3540
[11/30 02:06:37 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.5165, average loss: 0.9691
[11/30 02:06:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.01	
[11/30 02:06:37 visual_prompt]: Training 3 / 100 epoch, with learning rate 1.0
[11/30 02:13:33 visual_prompt]: Epoch 3 / 100: avg data time: 1.10e+01, avg batch time: 11.8794, average train loss: 1.2822
[11/30 02:14:21 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.5247, average loss: 0.6994
[11/30 02:14:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.19	
[11/30 02:14:21 visual_prompt]: Training 4 / 100 epoch, with learning rate 1.5
[11/30 02:21:18 visual_prompt]: Epoch 4 / 100: avg data time: 1.10e+01, avg batch time: 11.8978, average train loss: 1.1404
[11/30 02:22:06 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.5336, average loss: 1.8387
[11/30 02:22:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.47	
[11/30 02:22:06 visual_prompt]: Training 5 / 100 epoch, with learning rate 2.0
[11/30 02:29:01 visual_prompt]: Epoch 5 / 100: avg data time: 1.10e+01, avg batch time: 11.8742, average train loss: 2.1522
[11/30 02:29:50 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.5152, average loss: 0.6887
[11/30 02:29:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.17	
[11/30 02:29:50 visual_prompt]: Training 6 / 100 epoch, with learning rate 2.5
[11/30 02:36:46 visual_prompt]: Epoch 6 / 100: avg data time: 1.10e+01, avg batch time: 11.9001, average train loss: 6.3042
[11/30 02:37:34 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.5252, average loss: 5.0757
[11/30 02:37:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 41.47	
[11/30 02:37:34 visual_prompt]: Training 7 / 100 epoch, with learning rate 3.0
[11/30 02:44:31 visual_prompt]: Epoch 7 / 100: avg data time: 1.10e+01, avg batch time: 11.9143, average train loss: 5.9115
[11/30 02:45:20 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.5144, average loss: 1.5645
[11/30 02:45:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.22	
[11/30 02:45:20 visual_prompt]: Training 8 / 100 epoch, with learning rate 3.5
[11/30 02:52:16 visual_prompt]: Epoch 8 / 100: avg data time: 1.10e+01, avg batch time: 11.9102, average train loss: 8.5357
[11/30 02:53:05 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.5266, average loss: 5.0684
[11/30 02:53:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.48	
[11/30 02:53:05 visual_prompt]: Training 9 / 100 epoch, with learning rate 4.0
[11/30 03:00:01 visual_prompt]: Epoch 9 / 100: avg data time: 1.10e+01, avg batch time: 11.8976, average train loss: 5.7838
[11/30 03:00:50 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.5181, average loss: 24.0742
[11/30 03:00:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.85	
[11/30 03:00:50 visual_prompt]: Training 10 / 100 epoch, with learning rate 4.5
[11/30 03:07:45 visual_prompt]: Epoch 10 / 100: avg data time: 1.10e+01, avg batch time: 11.8683, average train loss: 7.1797
[11/30 03:08:33 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.5208, average loss: 7.2378
[11/30 03:08:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.00	
[11/30 03:08:33 visual_prompt]: Training 11 / 100 epoch, with learning rate 5.0
[11/30 03:15:32 visual_prompt]: Epoch 11 / 100: avg data time: 1.11e+01, avg batch time: 11.9528, average train loss: 10.4551
[11/30 03:16:20 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.5199, average loss: 34.7399
[11/30 03:16:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.90	
[11/30 03:16:20 visual_prompt]: Training 12 / 100 epoch, with learning rate 4.998477067547739
[11/30 03:23:18 visual_prompt]: Epoch 12 / 100: avg data time: 1.10e+01, avg batch time: 11.9199, average train loss: 15.2720
[11/30 03:24:06 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.5186, average loss: 3.7902
[11/30 03:24:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.45	
[11/30 03:24:06 visual_prompt]: Best epoch 12: best metric: -3.790
[11/30 03:24:06 visual_prompt]: Training 13 / 100 epoch, with learning rate 4.993910125649561
[11/30 03:31:04 visual_prompt]: Epoch 13 / 100: avg data time: 1.11e+01, avg batch time: 11.9290, average train loss: 10.2133
[11/30 03:31:52 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.5214, average loss: 4.6997
[11/30 03:31:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.53	rocauc: 47.95	
[11/30 03:31:52 visual_prompt]: Training 14 / 100 epoch, with learning rate 4.986304738420683
[11/30 03:38:48 visual_prompt]: Epoch 14 / 100: avg data time: 1.10e+01, avg batch time: 11.8826, average train loss: 11.8191
[11/30 03:39:36 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.5188, average loss: 1.1306
[11/30 03:39:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.56	
[11/30 03:39:36 visual_prompt]: Best epoch 14: best metric: -1.131
[11/30 03:39:36 visual_prompt]: Training 15 / 100 epoch, with learning rate 4.975670171853926
[11/30 03:46:33 visual_prompt]: Epoch 15 / 100: avg data time: 1.10e+01, avg batch time: 11.9179, average train loss: 9.8719
[11/30 03:47:22 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.5242, average loss: 7.8313
[11/30 03:47:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.07	
[11/30 03:47:22 visual_prompt]: Training 16 / 100 epoch, with learning rate 4.962019382530521
[11/30 03:54:18 visual_prompt]: Epoch 16 / 100: avg data time: 1.10e+01, avg batch time: 11.9005, average train loss: 11.0199
[11/30 03:55:02 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.5235, average loss: 0.7000
[11/30 03:55:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 42.68	rocauc: 43.42	
[11/30 03:55:02 visual_prompt]: Best epoch 16: best metric: -0.700
[11/30 03:55:02 visual_prompt]: Training 17 / 100 epoch, with learning rate 4.945369001834514
[11/30 04:01:16 visual_prompt]: Epoch 17 / 100: avg data time: 9.82e+00, avg batch time: 10.6901, average train loss: 13.2595
[11/30 04:01:59 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.5380, average loss: 2.2908
[11/30 04:01:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.87	
[11/30 04:01:59 visual_prompt]: Training 18 / 100 epoch, with learning rate 4.925739315689991
[11/30 04:08:14 visual_prompt]: Epoch 18 / 100: avg data time: 9.82e+00, avg batch time: 10.6943, average train loss: 13.2253
[11/30 04:08:57 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.5194, average loss: 6.6935
[11/30 04:08:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.36	
[11/30 04:08:57 visual_prompt]: Training 19 / 100 epoch, with learning rate 4.903154239845797
[11/30 04:15:11 visual_prompt]: Epoch 19 / 100: avg data time: 9.81e+00, avg batch time: 10.6815, average train loss: 8.1761
[11/30 04:15:55 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.5100, average loss: 20.1681
[11/30 04:15:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 42.01	
[11/30 04:15:55 visual_prompt]: Training 20 / 100 epoch, with learning rate 4.877641290737884
[11/30 04:22:09 visual_prompt]: Epoch 20 / 100: avg data time: 9.82e+00, avg batch time: 10.6930, average train loss: 11.8562
[11/30 04:22:53 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.5159, average loss: 10.9958
[11/30 04:22:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.62	
[11/30 04:22:53 visual_prompt]: Training 21 / 100 epoch, with learning rate 4.849231551964771
[11/30 04:29:07 visual_prompt]: Epoch 21 / 100: avg data time: 9.82e+00, avg batch time: 10.6884, average train loss: 7.4542
[11/30 04:29:50 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.5258, average loss: 12.9450
[11/30 04:29:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 37.12	
[11/30 04:29:50 visual_prompt]: Training 22 / 100 epoch, with learning rate 4.817959636416969
[11/30 04:36:04 visual_prompt]: Epoch 22 / 100: avg data time: 9.81e+00, avg batch time: 10.6860, average train loss: 10.5049
[11/30 04:36:48 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.5167, average loss: 12.7140
[11/30 04:36:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.13	
[11/30 04:36:48 visual_prompt]: Training 23 / 100 epoch, with learning rate 4.783863644106502
[11/30 04:43:02 visual_prompt]: Epoch 23 / 100: avg data time: 9.83e+00, avg batch time: 10.6955, average train loss: 7.5065
[11/30 04:43:46 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.5134, average loss: 17.8515
[11/30 04:43:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.70	
[11/30 04:43:46 visual_prompt]: Stopping early.
[11/30 04:43:46 visual_prompt]: Rank of current process: 0. World size: 1
[11/30 04:43:46 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA TITAN Xp
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/30 04:43:46 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss', 'RECORD_GPU_SNAPSHOT', 'True'])
[11/30 04:43:46 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/30 04:43:46 visual_prompt]: Training with config:
[11/30 04:43:46 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr5.0_wd0.001/patience7/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 5.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True}), 'RECORD_GPU_SNAPSHOT': True})
[11/30 04:43:46 visual_prompt]: Loading training data...
[11/30 04:43:46 visual_prompt]: Constructing mammo-cbis dataset train...
[11/30 04:43:46 visual_prompt]: Loading validation data...
[11/30 04:43:46 visual_prompt]: Constructing mammo-cbis dataset val...
[11/30 04:43:46 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[11/30 04:43:49 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[11/30 04:43:49 visual_prompt]: tuned percent:0.536
[11/30 04:43:49 visual_prompt]: Device used for model: 0
[11/30 04:43:49 visual_prompt]: Setting up Evaluator...
[11/30 04:43:49 visual_prompt]: Setting up Trainer...
[11/30 04:43:49 visual_prompt]: 	Setting up the optimizer...
[11/30 04:43:49 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/30 04:50:04 visual_prompt]: Epoch 1 / 100: avg data time: 9.84e+00, avg batch time: 10.7204, average train loss: 1.4006
[11/30 04:50:48 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.5269, average loss: 1.2969
[11/30 04:50:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[11/30 04:50:48 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.5
[11/30 04:57:02 visual_prompt]: Epoch 2 / 100: avg data time: 9.81e+00, avg batch time: 10.6918, average train loss: 5.6515
[11/30 04:57:45 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.5203, average loss: 1.1846
[11/30 04:57:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.47	
[11/30 04:57:45 visual_prompt]: Training 3 / 100 epoch, with learning rate 1.0
[11/30 05:04:00 visual_prompt]: Epoch 3 / 100: avg data time: 9.83e+00, avg batch time: 10.7025, average train loss: 0.9254
[11/30 05:04:44 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.5159, average loss: 0.7127
[11/30 05:04:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.36	
[11/30 05:04:44 visual_prompt]: Training 4 / 100 epoch, with learning rate 1.5
[11/30 05:10:58 visual_prompt]: Epoch 4 / 100: avg data time: 9.83e+00, avg batch time: 10.7010, average train loss: 1.5246
[11/30 05:11:42 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.5215, average loss: 0.8991
[11/30 05:11:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.06	
[11/30 05:11:42 visual_prompt]: Training 5 / 100 epoch, with learning rate 2.0
[11/30 05:17:56 visual_prompt]: Epoch 5 / 100: avg data time: 9.81e+00, avg batch time: 10.6851, average train loss: 1.1852
[11/30 05:18:39 visual_prompt]: Inference (val):avg data time: 2.11e-05, avg batch time: 0.5209, average loss: 0.8050
[11/30 05:18:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.98	
[11/30 05:18:39 visual_prompt]: Training 6 / 100 epoch, with learning rate 2.5
[11/30 05:24:54 visual_prompt]: Epoch 6 / 100: avg data time: 9.84e+00, avg batch time: 10.7087, average train loss: 3.0204
[11/30 05:25:38 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.5143, average loss: 4.9522
[11/30 05:25:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.74	
[11/30 05:25:38 visual_prompt]: Training 7 / 100 epoch, with learning rate 3.0
[11/30 05:31:52 visual_prompt]: Epoch 7 / 100: avg data time: 9.83e+00, avg batch time: 10.7047, average train loss: 4.1733
[11/30 05:32:36 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.5263, average loss: 4.9571
[11/30 05:32:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.44	
[11/30 05:32:36 visual_prompt]: Training 8 / 100 epoch, with learning rate 3.5
[11/30 05:38:50 visual_prompt]: Epoch 8 / 100: avg data time: 9.81e+00, avg batch time: 10.6894, average train loss: 3.5050
[11/30 05:39:33 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.5256, average loss: 13.0725
[11/30 05:39:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.72	
[11/30 05:39:33 visual_prompt]: Training 9 / 100 epoch, with learning rate 4.0
[11/30 05:45:49 visual_prompt]: Epoch 9 / 100: avg data time: 9.84e+00, avg batch time: 10.7146, average train loss: 5.9956
[11/30 05:46:32 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.5224, average loss: 1.8695
[11/30 05:46:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.56	
[11/30 05:46:32 visual_prompt]: Training 10 / 100 epoch, with learning rate 4.5
[11/30 05:52:47 visual_prompt]: Epoch 10 / 100: avg data time: 9.83e+00, avg batch time: 10.7041, average train loss: 7.1528
[11/30 05:53:30 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.5165, average loss: 18.8593
[11/30 05:53:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.79	
[11/30 05:53:30 visual_prompt]: Training 11 / 100 epoch, with learning rate 5.0
[11/30 05:59:45 visual_prompt]: Epoch 11 / 100: avg data time: 9.83e+00, avg batch time: 10.7127, average train loss: 12.3416
[11/30 06:00:29 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.5274, average loss: 12.8336
[11/30 06:00:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.99	
[11/30 06:00:29 visual_prompt]: Training 12 / 100 epoch, with learning rate 4.998477067547739
[11/30 06:06:43 visual_prompt]: Epoch 12 / 100: avg data time: 9.82e+00, avg batch time: 10.6995, average train loss: 7.6709
[11/30 06:07:27 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.5161, average loss: 6.9060
[11/30 06:07:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.25	
[11/30 06:07:27 visual_prompt]: Best epoch 12: best metric: -6.906
[11/30 06:07:27 visual_prompt]: Training 13 / 100 epoch, with learning rate 4.993910125649561
[11/30 06:13:41 visual_prompt]: Epoch 13 / 100: avg data time: 9.83e+00, avg batch time: 10.7030, average train loss: 10.3000
[11/30 06:14:25 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.5206, average loss: 5.5765
[11/30 06:14:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.12	
[11/30 06:14:25 visual_prompt]: Best epoch 13: best metric: -5.576
[11/30 06:14:25 visual_prompt]: Training 14 / 100 epoch, with learning rate 4.986304738420683
[11/30 06:20:39 visual_prompt]: Epoch 14 / 100: avg data time: 9.81e+00, avg batch time: 10.6827, average train loss: 5.7824
[11/30 06:21:22 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.5107, average loss: 8.5292
[11/30 06:21:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.53	
[11/30 06:21:22 visual_prompt]: Training 15 / 100 epoch, with learning rate 4.975670171853926
[11/30 06:27:37 visual_prompt]: Epoch 15 / 100: avg data time: 9.83e+00, avg batch time: 10.7024, average train loss: 6.0883
[11/30 06:28:20 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.5278, average loss: 6.2720
[11/30 06:28:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.47	
[11/30 06:28:20 visual_prompt]: Training 16 / 100 epoch, with learning rate 4.962019382530521
[11/30 06:34:35 visual_prompt]: Epoch 16 / 100: avg data time: 9.81e+00, avg batch time: 10.6876, average train loss: 5.6700
[11/30 06:35:18 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.5236, average loss: 1.3561
[11/30 06:35:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.82	
[11/30 06:35:18 visual_prompt]: Best epoch 16: best metric: -1.356
[11/30 06:35:18 visual_prompt]: Training 17 / 100 epoch, with learning rate 4.945369001834514
[11/30 06:41:32 visual_prompt]: Epoch 17 / 100: avg data time: 9.80e+00, avg batch time: 10.6755, average train loss: 7.1390
[11/30 06:42:15 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.5209, average loss: 0.7291
[11/30 06:42:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.13	
[11/30 06:42:15 visual_prompt]: Best epoch 17: best metric: -0.729
[11/30 06:42:15 visual_prompt]: Training 18 / 100 epoch, with learning rate 4.925739315689991
[11/30 06:48:29 visual_prompt]: Epoch 18 / 100: avg data time: 9.81e+00, avg batch time: 10.6915, average train loss: 7.4325
[11/30 06:49:13 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.5229, average loss: 3.8594
[11/30 06:49:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.68	
[11/30 06:49:13 visual_prompt]: Training 19 / 100 epoch, with learning rate 4.903154239845797
[11/30 06:55:28 visual_prompt]: Epoch 19 / 100: avg data time: 9.83e+00, avg batch time: 10.7034, average train loss: 5.6259
[11/30 06:56:11 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.5153, average loss: 5.7350
[11/30 06:56:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.33	
[11/30 06:56:11 visual_prompt]: Training 20 / 100 epoch, with learning rate 4.877641290737884
[11/30 07:02:26 visual_prompt]: Epoch 20 / 100: avg data time: 9.83e+00, avg batch time: 10.7017, average train loss: 4.2629
[11/30 07:03:09 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.5255, average loss: 0.6868
[11/30 07:03:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 57.13	
[11/30 07:03:09 visual_prompt]: Best epoch 20: best metric: -0.687
[11/30 07:03:09 visual_prompt]: Training 21 / 100 epoch, with learning rate 4.849231551964771
[11/30 07:09:23 visual_prompt]: Epoch 21 / 100: avg data time: 9.81e+00, avg batch time: 10.6886, average train loss: 4.0492
[11/30 07:10:07 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.5243, average loss: 4.1133
[11/30 07:10:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.81	
[11/30 07:10:07 visual_prompt]: Training 22 / 100 epoch, with learning rate 4.817959636416969
[11/30 07:16:21 visual_prompt]: Epoch 22 / 100: avg data time: 9.81e+00, avg batch time: 10.6843, average train loss: 4.6679
[11/30 07:17:04 visual_prompt]: Inference (val):avg data time: 2.11e-05, avg batch time: 0.5196, average loss: 5.4969
[11/30 07:17:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.48	
[11/30 07:17:04 visual_prompt]: Training 23 / 100 epoch, with learning rate 4.783863644106502
[11/30 07:23:19 visual_prompt]: Epoch 23 / 100: avg data time: 9.83e+00, avg batch time: 10.7064, average train loss: 10.6579
[11/30 07:24:03 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.5271, average loss: 1.3095
[11/30 07:24:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.06	
[11/30 07:24:03 visual_prompt]: Training 24 / 100 epoch, with learning rate 4.7469851157479175
[11/30 07:30:18 visual_prompt]: Epoch 24 / 100: avg data time: 9.85e+00, avg batch time: 10.7202, average train loss: 4.0030
[11/30 07:31:03 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.5283, average loss: 0.7067
[11/30 07:31:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.04	
[11/30 07:31:03 visual_prompt]: Training 25 / 100 epoch, with learning rate 4.707368982147317
[11/30 07:37:17 visual_prompt]: Epoch 25 / 100: avg data time: 9.81e+00, avg batch time: 10.6895, average train loss: 5.7001
[11/30 07:38:00 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.5288, average loss: 7.7067
[11/30 07:38:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.19	
[11/30 07:38:00 visual_prompt]: Training 26 / 100 epoch, with learning rate 4.665063509461097
[11/30 07:44:14 visual_prompt]: Epoch 26 / 100: avg data time: 9.81e+00, avg batch time: 10.6886, average train loss: 3.7169
[11/30 07:44:58 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.5259, average loss: 5.6729
[11/30 07:44:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.40	
[11/30 07:44:58 visual_prompt]: Training 27 / 100 epoch, with learning rate 4.620120240391064
[11/30 07:51:12 visual_prompt]: Epoch 27 / 100: avg data time: 9.81e+00, avg batch time: 10.6871, average train loss: 8.9983
[11/30 07:51:55 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.5259, average loss: 0.9146
[11/30 07:51:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.02	
[11/30 07:51:55 visual_prompt]: Stopping early.
[11/30 07:51:56 visual_prompt]: Rank of current process: 0. World size: 1
[11/30 07:51:56 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA TITAN Xp
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/30 07:51:56 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss', 'RECORD_GPU_SNAPSHOT', 'True'])
[11/30 07:51:56 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/30 07:51:56 visual_prompt]: Training with config:
[11/30 07:51:56 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr5.0_wd0.0001/patience7/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 5.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True}), 'RECORD_GPU_SNAPSHOT': True})
[11/30 07:51:56 visual_prompt]: Loading training data...
[11/30 07:51:56 visual_prompt]: Constructing mammo-cbis dataset train...
[11/30 07:51:56 visual_prompt]: Loading validation data...
[11/30 07:51:56 visual_prompt]: Constructing mammo-cbis dataset val...
[11/30 07:51:56 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[11/30 07:51:58 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[11/30 07:51:58 visual_prompt]: tuned percent:0.536
[11/30 07:51:58 visual_prompt]: Device used for model: 0
[11/30 07:51:58 visual_prompt]: Setting up Evaluator...
[11/30 07:51:58 visual_prompt]: Setting up Trainer...
[11/30 07:51:58 visual_prompt]: 	Setting up the optimizer...
[11/30 07:51:58 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/30 07:58:19 visual_prompt]: Epoch 1 / 100: avg data time: 1.00e+01, avg batch time: 10.8803, average train loss: 1.4006
[11/30 07:59:03 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.5187, average loss: 1.2969
[11/30 07:59:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[11/30 07:59:03 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.5
[11/30 08:05:18 visual_prompt]: Epoch 2 / 100: avg data time: 9.86e+00, avg batch time: 10.7302, average train loss: 5.6991
[11/30 08:06:02 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.5097, average loss: 1.3484
[11/30 08:06:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.43	
[11/30 08:06:02 visual_prompt]: Training 3 / 100 epoch, with learning rate 1.0
[11/30 08:12:17 visual_prompt]: Epoch 3 / 100: avg data time: 9.84e+00, avg batch time: 10.7115, average train loss: 0.9334
[11/30 08:13:00 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.5225, average loss: 0.7732
[11/30 08:13:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.68	
[11/30 08:13:00 visual_prompt]: Training 4 / 100 epoch, with learning rate 1.5
[11/30 08:19:15 visual_prompt]: Epoch 4 / 100: avg data time: 9.84e+00, avg batch time: 10.7051, average train loss: 1.5592
[11/30 08:19:59 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.5206, average loss: 0.7553
[11/30 08:19:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.69	
[11/30 08:19:59 visual_prompt]: Training 5 / 100 epoch, with learning rate 2.0
[11/30 08:26:13 visual_prompt]: Epoch 5 / 100: avg data time: 9.82e+00, avg batch time: 10.6933, average train loss: 3.2565
[11/30 08:26:57 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.5183, average loss: 6.8707
[11/30 08:26:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.82	
[11/30 08:26:57 visual_prompt]: Training 6 / 100 epoch, with learning rate 2.5
[11/30 08:33:12 visual_prompt]: Epoch 6 / 100: avg data time: 9.85e+00, avg batch time: 10.7266, average train loss: 3.6536
[11/30 08:33:56 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.5172, average loss: 5.5577
[11/30 08:33:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.85	
[11/30 08:33:56 visual_prompt]: Training 7 / 100 epoch, with learning rate 3.0
[11/30 08:40:11 visual_prompt]: Epoch 7 / 100: avg data time: 9.85e+00, avg batch time: 10.7178, average train loss: 4.7739
[11/30 08:40:54 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.5219, average loss: 6.8771
[11/30 08:40:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.32	
[11/30 08:40:54 visual_prompt]: Training 8 / 100 epoch, with learning rate 3.5
[11/30 08:47:09 visual_prompt]: Epoch 8 / 100: avg data time: 9.83e+00, avg batch time: 10.7002, average train loss: 4.3686
[11/30 08:47:52 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.5231, average loss: 0.6893
[11/30 08:47:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.69	
[11/30 08:47:52 visual_prompt]: Training 9 / 100 epoch, with learning rate 4.0
[11/30 08:54:16 visual_prompt]: Epoch 9 / 100: avg data time: 1.01e+01, avg batch time: 10.9582, average train loss: 3.1863
[11/30 08:55:02 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.5222, average loss: 1.6099
[11/30 08:55:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.93	
[11/30 08:55:02 visual_prompt]: Training 10 / 100 epoch, with learning rate 4.5
[11/30 09:01:36 visual_prompt]: Epoch 10 / 100: avg data time: 1.04e+01, avg batch time: 11.2657, average train loss: 1.8370
[11/30 09:02:21 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.5121, average loss: 2.4886
[11/30 09:02:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.29	
[11/30 09:02:21 visual_prompt]: Training 11 / 100 epoch, with learning rate 5.0
[11/30 09:08:38 visual_prompt]: Epoch 11 / 100: avg data time: 9.88e+00, avg batch time: 10.7438, average train loss: 2.9984
[11/30 09:09:21 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.5187, average loss: 2.5507
[11/30 09:09:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.14	
[11/30 09:09:21 visual_prompt]: Training 12 / 100 epoch, with learning rate 4.998477067547739
[11/30 09:15:35 visual_prompt]: Epoch 12 / 100: avg data time: 9.82e+00, avg batch time: 10.6945, average train loss: 9.4320
[11/30 09:16:19 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.5181, average loss: 10.1587
[11/30 09:16:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.34	
[11/30 09:16:19 visual_prompt]: Training 13 / 100 epoch, with learning rate 4.993910125649561
[11/30 09:22:34 visual_prompt]: Epoch 13 / 100: avg data time: 9.84e+00, avg batch time: 10.7071, average train loss: 11.7931
[11/30 09:23:17 visual_prompt]: Inference (val):avg data time: 1.98e-05, avg batch time: 0.5228, average loss: 1.5056
[11/30 09:23:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.05	
[11/30 09:23:17 visual_prompt]: Best epoch 13: best metric: -1.506
[11/30 09:23:17 visual_prompt]: Training 14 / 100 epoch, with learning rate 4.986304738420683
[11/30 09:29:31 visual_prompt]: Epoch 14 / 100: avg data time: 9.82e+00, avg batch time: 10.6933, average train loss: 8.6446
[11/30 09:30:15 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.5176, average loss: 3.5846
[11/30 09:30:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.64	
[11/30 09:30:15 visual_prompt]: Training 15 / 100 epoch, with learning rate 4.975670171853926
[11/30 09:36:30 visual_prompt]: Epoch 15 / 100: avg data time: 9.84e+00, avg batch time: 10.7137, average train loss: 6.4145
[11/30 09:37:13 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.5221, average loss: 5.1652
[11/30 09:37:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.25	
[11/30 09:37:13 visual_prompt]: Training 16 / 100 epoch, with learning rate 4.962019382530521
[11/30 09:43:30 visual_prompt]: Epoch 16 / 100: avg data time: 9.87e+00, avg batch time: 10.7441, average train loss: 11.6323
[11/30 09:44:13 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.5209, average loss: 5.3893
[11/30 09:44:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.74	
[11/30 09:44:13 visual_prompt]: Training 17 / 100 epoch, with learning rate 4.945369001834514
[11/30 09:50:27 visual_prompt]: Epoch 17 / 100: avg data time: 9.81e+00, avg batch time: 10.6843, average train loss: 10.2096
[11/30 09:51:10 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.5108, average loss: 14.3606
[11/30 09:51:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.17	
[11/30 09:51:10 visual_prompt]: Training 18 / 100 epoch, with learning rate 4.925739315689991
[11/30 09:57:25 visual_prompt]: Epoch 18 / 100: avg data time: 9.83e+00, avg batch time: 10.6937, average train loss: 12.3201
[11/30 09:58:08 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.5186, average loss: 30.1740
[11/30 09:58:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.58	
[11/30 09:58:08 visual_prompt]: Training 19 / 100 epoch, with learning rate 4.903154239845797
[11/30 10:04:22 visual_prompt]: Epoch 19 / 100: avg data time: 9.81e+00, avg batch time: 10.6861, average train loss: 11.5244
[11/30 10:05:06 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.5267, average loss: 5.7095
[11/30 10:05:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.61	
[11/30 10:05:06 visual_prompt]: Training 20 / 100 epoch, with learning rate 4.877641290737884
[11/30 10:11:21 visual_prompt]: Epoch 20 / 100: avg data time: 9.84e+00, avg batch time: 10.7086, average train loss: 7.2507
[11/30 10:12:04 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.5208, average loss: 4.1722
[11/30 10:12:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.17	
[11/30 10:12:04 visual_prompt]: Stopping early.
[11/30 10:12:04 visual_prompt]: Rank of current process: 0. World size: 1
[11/30 10:12:04 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA TITAN Xp
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/30 10:12:04 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss', 'RECORD_GPU_SNAPSHOT', 'True'])
[11/30 10:12:04 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/30 10:12:04 visual_prompt]: Training with config:
[11/30 10:12:04 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr5.0_wd0.0/patience7/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 5.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True}), 'RECORD_GPU_SNAPSHOT': True})
[11/30 10:12:04 visual_prompt]: Loading training data...
[11/30 10:12:04 visual_prompt]: Constructing mammo-cbis dataset train...
[11/30 10:12:04 visual_prompt]: Loading validation data...
[11/30 10:12:04 visual_prompt]: Constructing mammo-cbis dataset val...
[11/30 10:12:04 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[11/30 10:12:13 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[11/30 10:12:13 visual_prompt]: tuned percent:0.536
[11/30 10:12:13 visual_prompt]: Device used for model: 0
[11/30 10:12:13 visual_prompt]: Setting up Evaluator...
[11/30 10:12:13 visual_prompt]: Setting up Trainer...
[11/30 10:12:13 visual_prompt]: 	Setting up the optimizer...
[11/30 10:12:13 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/30 10:18:28 visual_prompt]: Epoch 1 / 100: avg data time: 9.83e+00, avg batch time: 10.7021, average train loss: 1.4006
[11/30 10:19:11 visual_prompt]: Inference (val):avg data time: 1.98e-05, avg batch time: 0.5142, average loss: 1.2969
[11/30 10:19:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[11/30 10:19:11 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.5
[11/30 10:25:25 visual_prompt]: Epoch 2 / 100: avg data time: 9.81e+00, avg batch time: 10.6857, average train loss: 5.6945
[11/30 10:26:08 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.5237, average loss: 1.3670
[11/30 10:26:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.55	
[11/30 10:26:08 visual_prompt]: Training 3 / 100 epoch, with learning rate 1.0
[11/30 10:32:22 visual_prompt]: Epoch 3 / 100: avg data time: 9.81e+00, avg batch time: 10.6847, average train loss: 0.9387
[11/30 10:33:06 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.5223, average loss: 0.7804
[11/30 10:33:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.10	
[11/30 10:33:06 visual_prompt]: Training 4 / 100 epoch, with learning rate 1.5
[11/30 10:39:20 visual_prompt]: Epoch 4 / 100: avg data time: 9.82e+00, avg batch time: 10.6901, average train loss: 1.6253
[11/30 10:40:04 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.5233, average loss: 5.5548
[11/30 10:40:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.64	
[11/30 10:40:04 visual_prompt]: Training 5 / 100 epoch, with learning rate 2.0
[11/30 10:46:17 visual_prompt]: Epoch 5 / 100: avg data time: 9.79e+00, avg batch time: 10.6654, average train loss: 2.0992
[11/30 10:47:00 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.5271, average loss: 3.6663
[11/30 10:47:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.35	
[11/30 10:47:00 visual_prompt]: Training 6 / 100 epoch, with learning rate 2.5
[11/30 10:53:17 visual_prompt]: Epoch 6 / 100: avg data time: 9.87e+00, avg batch time: 10.7468, average train loss: 4.8855
[11/30 10:54:00 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.5163, average loss: 6.1723
[11/30 10:54:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.58	
[11/30 10:54:00 visual_prompt]: Training 7 / 100 epoch, with learning rate 3.0
[11/30 11:00:15 visual_prompt]: Epoch 7 / 100: avg data time: 9.85e+00, avg batch time: 10.7166, average train loss: 4.1054
[11/30 11:00:59 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.5264, average loss: 6.9784
[11/30 11:00:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.44	
[11/30 11:00:59 visual_prompt]: Training 8 / 100 epoch, with learning rate 3.5
[11/30 11:07:13 visual_prompt]: Epoch 8 / 100: avg data time: 9.81e+00, avg batch time: 10.6892, average train loss: 7.3526
[11/30 11:07:56 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.5242, average loss: 1.3838
[11/30 11:07:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.31	
[11/30 11:07:56 visual_prompt]: Training 9 / 100 epoch, with learning rate 4.0
[11/30 11:14:43 visual_prompt]: Epoch 9 / 100: avg data time: 1.08e+01, avg batch time: 11.6323, average train loss: 5.3312
[11/30 11:15:32 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.5230, average loss: 7.9830
[11/30 11:15:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.21	
[11/30 11:15:32 visual_prompt]: Training 10 / 100 epoch, with learning rate 4.5
[11/30 11:22:01 visual_prompt]: Epoch 10 / 100: avg data time: 1.03e+01, avg batch time: 11.1340, average train loss: 2.3202
[11/30 11:22:45 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.5268, average loss: 0.7197
[11/30 11:22:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.66	
[11/30 11:22:45 visual_prompt]: Training 11 / 100 epoch, with learning rate 5.0
[11/30 11:28:59 visual_prompt]: Epoch 11 / 100: avg data time: 9.83e+00, avg batch time: 10.7058, average train loss: 2.4559
[11/30 11:29:43 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.5182, average loss: 0.7193
[11/30 11:29:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.18	
[11/30 11:29:43 visual_prompt]: Training 12 / 100 epoch, with learning rate 4.998477067547739
[11/30 11:35:57 visual_prompt]: Epoch 12 / 100: avg data time: 9.82e+00, avg batch time: 10.6958, average train loss: 3.2892
[11/30 11:36:41 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.5157, average loss: 8.5075
[11/30 11:36:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.61	
[11/30 11:36:41 visual_prompt]: Training 13 / 100 epoch, with learning rate 4.993910125649561
[11/30 11:42:55 visual_prompt]: Epoch 13 / 100: avg data time: 9.83e+00, avg batch time: 10.6979, average train loss: 2.4713
[11/30 11:43:38 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.5244, average loss: 1.1359
[11/30 11:43:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.74	
[11/30 11:43:39 visual_prompt]: Training 14 / 100 epoch, with learning rate 4.986304738420683
[11/30 11:49:53 visual_prompt]: Epoch 14 / 100: avg data time: 9.81e+00, avg batch time: 10.6857, average train loss: 2.4583
[11/30 11:50:36 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.5217, average loss: 2.7678
[11/30 11:50:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.16	
[11/30 11:50:36 visual_prompt]: Training 15 / 100 epoch, with learning rate 4.975670171853926
[11/30 11:56:51 visual_prompt]: Epoch 15 / 100: avg data time: 9.83e+00, avg batch time: 10.7069, average train loss: 4.0242
[11/30 11:57:34 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.5238, average loss: 1.1153
[11/30 11:57:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.12	
[11/30 11:57:34 visual_prompt]: Training 16 / 100 epoch, with learning rate 4.962019382530521
[11/30 12:03:48 visual_prompt]: Epoch 16 / 100: avg data time: 9.82e+00, avg batch time: 10.6934, average train loss: 1.0410
[11/30 12:04:32 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.5219, average loss: 1.8635
[11/30 12:04:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.34	
[11/30 12:04:32 visual_prompt]: Training 17 / 100 epoch, with learning rate 4.945369001834514
[11/30 12:10:45 visual_prompt]: Epoch 17 / 100: avg data time: 9.79e+00, avg batch time: 10.6632, average train loss: 4.6222
[11/30 12:11:28 visual_prompt]: Inference (val):avg data time: 1.96e-05, avg batch time: 0.5218, average loss: 9.2348
[11/30 12:11:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.28	
[11/30 12:11:28 visual_prompt]: Training 18 / 100 epoch, with learning rate 4.925739315689991
[11/30 12:17:42 visual_prompt]: Epoch 18 / 100: avg data time: 9.81e+00, avg batch time: 10.6815, average train loss: 6.6472
[11/30 12:18:26 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.5274, average loss: 1.7886
[11/30 12:18:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.75	
[11/30 12:18:26 visual_prompt]: Stopping early.
[11/30 12:18:26 visual_prompt]: Rank of current process: 0. World size: 1
[11/30 12:18:26 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA TITAN Xp
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/30 12:18:26 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss', 'RECORD_GPU_SNAPSHOT', 'True'])
[11/30 12:18:26 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/30 12:18:26 visual_prompt]: Training with config:
[11/30 12:18:26 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr2.5_wd0.01/patience7/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 2.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True}), 'RECORD_GPU_SNAPSHOT': True})
[11/30 12:18:26 visual_prompt]: Loading training data...
[11/30 12:18:26 visual_prompt]: Constructing mammo-cbis dataset train...
[11/30 12:18:26 visual_prompt]: Loading validation data...
[11/30 12:18:26 visual_prompt]: Constructing mammo-cbis dataset val...
[11/30 12:18:26 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[11/30 12:18:32 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[11/30 12:18:32 visual_prompt]: tuned percent:0.536
[11/30 12:18:32 visual_prompt]: Device used for model: 0
[11/30 12:18:32 visual_prompt]: Setting up Evaluator...
[11/30 12:18:32 visual_prompt]: Setting up Trainer...
[11/30 12:18:32 visual_prompt]: 	Setting up the optimizer...
[11/30 12:18:32 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/30 12:24:46 visual_prompt]: Epoch 1 / 100: avg data time: 9.82e+00, avg batch time: 10.6907, average train loss: 1.4006
[11/30 12:25:29 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.5248, average loss: 1.2969
[11/30 12:25:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[11/30 12:25:29 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.25
[11/30 12:31:43 visual_prompt]: Epoch 2 / 100: avg data time: 9.81e+00, avg batch time: 10.6893, average train loss: 3.3699
[11/30 12:32:27 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.5242, average loss: 0.6860
[11/30 12:32:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.27	
[11/30 12:32:27 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.5
[11/30 12:38:41 visual_prompt]: Epoch 3 / 100: avg data time: 9.82e+00, avg batch time: 10.6953, average train loss: 0.7258
[11/30 12:39:24 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.5185, average loss: 0.7401
[11/30 12:39:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.34	
[11/30 12:39:24 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.75
[11/30 12:45:38 visual_prompt]: Epoch 4 / 100: avg data time: 9.81e+00, avg batch time: 10.6826, average train loss: 0.7616
[11/30 12:46:22 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.5250, average loss: 0.8856
[11/30 12:46:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.57	
[11/30 12:46:22 visual_prompt]: Training 5 / 100 epoch, with learning rate 1.0
[11/30 12:52:35 visual_prompt]: Epoch 5 / 100: avg data time: 9.80e+00, avg batch time: 10.6751, average train loss: 1.0729
[11/30 12:53:19 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.5236, average loss: 0.8617
[11/30 12:53:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.85	
[11/30 12:53:19 visual_prompt]: Training 6 / 100 epoch, with learning rate 1.25
[11/30 12:59:34 visual_prompt]: Epoch 6 / 100: avg data time: 9.84e+00, avg batch time: 10.7119, average train loss: 1.3040
[11/30 13:00:17 visual_prompt]: Inference (val):avg data time: 2.08e-05, avg batch time: 0.5201, average loss: 1.4463
[11/30 13:00:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.39	
[11/30 13:00:17 visual_prompt]: Training 7 / 100 epoch, with learning rate 1.5
[11/30 13:06:35 visual_prompt]: Epoch 7 / 100: avg data time: 9.94e+00, avg batch time: 10.8062, average train loss: 2.3479
[11/30 13:07:20 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.5203, average loss: 1.8607
[11/30 13:07:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.28	
[11/30 13:07:20 visual_prompt]: Training 8 / 100 epoch, with learning rate 1.75
[11/30 13:13:47 visual_prompt]: Epoch 8 / 100: avg data time: 1.02e+01, avg batch time: 11.0274, average train loss: 1.7663
[11/30 13:14:30 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.5236, average loss: 0.7228
[11/30 13:14:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.31	
[11/30 13:14:30 visual_prompt]: Training 9 / 100 epoch, with learning rate 2.0
[11/30 13:20:45 visual_prompt]: Epoch 9 / 100: avg data time: 9.84e+00, avg batch time: 10.7127, average train loss: 2.3725
[11/30 13:21:28 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.5248, average loss: 5.0524
[11/30 13:21:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.44	
[11/30 13:21:28 visual_prompt]: Training 10 / 100 epoch, with learning rate 2.25
[11/30 13:27:43 visual_prompt]: Epoch 10 / 100: avg data time: 9.83e+00, avg batch time: 10.6973, average train loss: 4.4172
[11/30 13:28:26 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.5230, average loss: 4.2301
[11/30 13:28:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 45.55	
[11/30 13:28:26 visual_prompt]: Training 11 / 100 epoch, with learning rate 2.5
[11/30 13:34:41 visual_prompt]: Epoch 11 / 100: avg data time: 9.83e+00, avg batch time: 10.6983, average train loss: 5.0814
[11/30 13:35:24 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.5172, average loss: 4.2661
[11/30 13:35:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.99	
[11/30 13:35:24 visual_prompt]: Training 12 / 100 epoch, with learning rate 2.4992385337738696
[11/30 13:41:38 visual_prompt]: Epoch 12 / 100: avg data time: 9.82e+00, avg batch time: 10.6914, average train loss: 5.1510
[11/30 13:42:22 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.5136, average loss: 9.4924
[11/30 13:42:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.58	
[11/30 13:42:22 visual_prompt]: Training 13 / 100 epoch, with learning rate 2.4969550628247803
[11/30 13:48:37 visual_prompt]: Epoch 13 / 100: avg data time: 9.85e+00, avg batch time: 10.7233, average train loss: 5.3912
[11/30 13:49:20 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.5170, average loss: 7.8631
[11/30 13:49:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 45.61	
[11/30 13:49:20 visual_prompt]: Training 14 / 100 epoch, with learning rate 2.4931523692103417
[11/30 13:55:35 visual_prompt]: Epoch 14 / 100: avg data time: 9.82e+00, avg batch time: 10.6883, average train loss: 3.8460
[11/30 13:56:18 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.5112, average loss: 5.5936
[11/30 13:56:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.52	
[11/30 13:56:18 visual_prompt]: Training 15 / 100 epoch, with learning rate 2.487835085926963
[11/30 14:02:33 visual_prompt]: Epoch 15 / 100: avg data time: 9.83e+00, avg batch time: 10.7037, average train loss: 4.7465
[11/30 14:03:16 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.5210, average loss: 4.3303
[11/30 14:03:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 43.00	
[11/30 14:03:16 visual_prompt]: Training 16 / 100 epoch, with learning rate 2.4810096912652604
[11/30 14:09:30 visual_prompt]: Epoch 16 / 100: avg data time: 9.81e+00, avg batch time: 10.6820, average train loss: 3.8909
[11/30 14:10:13 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.5241, average loss: 13.7328
[11/30 14:10:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.53	
[11/30 14:10:13 visual_prompt]: Training 17 / 100 epoch, with learning rate 2.472684500917257
[11/30 14:16:27 visual_prompt]: Epoch 17 / 100: avg data time: 9.80e+00, avg batch time: 10.6744, average train loss: 5.9041
[11/30 14:17:11 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.5186, average loss: 2.4741
[11/30 14:17:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.76	
[11/30 14:17:11 visual_prompt]: Best epoch 17: best metric: -2.474
[11/30 14:17:11 visual_prompt]: Training 18 / 100 epoch, with learning rate 2.4628696578449953
[11/30 14:23:25 visual_prompt]: Epoch 18 / 100: avg data time: 9.81e+00, avg batch time: 10.6850, average train loss: 3.4335
[11/30 14:24:08 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.5213, average loss: 6.1525
[11/30 14:24:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.15	
[11/30 14:24:08 visual_prompt]: Training 19 / 100 epoch, with learning rate 2.4515771199228986
[11/30 14:30:21 visual_prompt]: Epoch 19 / 100: avg data time: 9.80e+00, avg batch time: 10.6738, average train loss: 5.2571
[11/30 14:31:05 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.5164, average loss: 5.7841
[11/30 14:31:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.00	
[11/30 14:31:05 visual_prompt]: Training 20 / 100 epoch, with learning rate 2.438820645368942
[11/30 14:37:19 visual_prompt]: Epoch 20 / 100: avg data time: 9.81e+00, avg batch time: 10.6798, average train loss: 4.8364
[11/30 14:38:02 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.5248, average loss: 3.3507
[11/30 14:38:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.19	
[11/30 14:38:02 visual_prompt]: Training 21 / 100 epoch, with learning rate 2.4246157759823856
[11/30 14:44:46 visual_prompt]: Epoch 21 / 100: avg data time: 1.07e+01, avg batch time: 11.5386, average train loss: 2.7007
[11/30 14:45:34 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.5176, average loss: 0.7965
[11/30 14:45:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 46.75	rocauc: 47.35	
[11/30 14:45:34 visual_prompt]: Best epoch 21: best metric: -0.797
[11/30 14:45:34 visual_prompt]: Training 22 / 100 epoch, with learning rate 2.4089798182084845
[11/30 14:52:20 visual_prompt]: Epoch 22 / 100: avg data time: 1.07e+01, avg batch time: 11.5931, average train loss: 3.1721
[11/30 14:53:06 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.5159, average loss: 1.9093
[11/30 14:53:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.59	
[11/30 14:53:06 visual_prompt]: Training 23 / 100 epoch, with learning rate 2.391931822053251
[11/30 14:59:36 visual_prompt]: Epoch 23 / 100: avg data time: 1.03e+01, avg batch time: 11.1576, average train loss: 3.6573
[11/30 15:00:23 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.5199, average loss: 4.7770
[11/30 15:00:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.47	
[11/30 15:00:23 visual_prompt]: Training 24 / 100 epoch, with learning rate 2.3734925578739587
[11/30 15:07:03 visual_prompt]: Epoch 24 / 100: avg data time: 1.06e+01, avg batch time: 11.4435, average train loss: 4.7145
[11/30 15:07:48 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.5195, average loss: 34.9005
[11/30 15:07:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.20	
[11/30 15:07:48 visual_prompt]: Training 25 / 100 epoch, with learning rate 2.3536844910736585
[11/30 15:14:31 visual_prompt]: Epoch 25 / 100: avg data time: 1.06e+01, avg batch time: 11.5095, average train loss: 5.5821
[11/30 15:15:24 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.5212, average loss: 0.8313
[11/30 15:15:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.06	
[11/30 15:15:24 visual_prompt]: Training 26 / 100 epoch, with learning rate 2.3325317547305486
[11/30 15:22:13 visual_prompt]: Epoch 26 / 100: avg data time: 1.08e+01, avg batch time: 11.6722, average train loss: 2.7703
[11/30 15:23:01 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.5156, average loss: 1.6427
[11/30 15:23:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.00	
[11/30 15:23:01 visual_prompt]: Training 27 / 100 epoch, with learning rate 2.310060120195532
[11/30 15:29:43 visual_prompt]: Epoch 27 / 100: avg data time: 1.06e+01, avg batch time: 11.4762, average train loss: 3.6755
[11/30 15:30:28 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.5198, average loss: 6.1555
[11/30 15:30:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.32	
[11/30 15:30:28 visual_prompt]: Training 28 / 100 epoch, with learning rate 2.286296965693802
[11/30 15:37:10 visual_prompt]: Epoch 28 / 100: avg data time: 1.06e+01, avg batch time: 11.4647, average train loss: 6.8746
[11/30 15:37:58 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.5213, average loss: 9.4362
[11/30 15:37:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.49	
[11/30 15:37:58 visual_prompt]: Stopping early.
[11/30 15:37:58 visual_prompt]: Rank of current process: 0. World size: 1
[11/30 15:37:58 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA TITAN Xp
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/30 15:37:58 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss', 'RECORD_GPU_SNAPSHOT', 'True'])
[11/30 15:37:58 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/30 15:37:58 visual_prompt]: Training with config:
[11/30 15:37:58 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr2.5_wd0.001/patience7/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 2.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True}), 'RECORD_GPU_SNAPSHOT': True})
[11/30 15:37:58 visual_prompt]: Loading training data...
[11/30 15:37:58 visual_prompt]: Constructing mammo-cbis dataset train...
[11/30 15:37:58 visual_prompt]: Loading validation data...
[11/30 15:37:58 visual_prompt]: Constructing mammo-cbis dataset val...
[11/30 15:37:58 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[11/30 15:38:01 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[11/30 15:38:01 visual_prompt]: tuned percent:0.536
[11/30 15:38:02 visual_prompt]: Device used for model: 0
[11/30 15:38:02 visual_prompt]: Setting up Evaluator...
[11/30 15:38:02 visual_prompt]: Setting up Trainer...
[11/30 15:38:02 visual_prompt]: 	Setting up the optimizer...
[11/30 15:38:02 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/30 15:44:56 visual_prompt]: Epoch 1 / 100: avg data time: 1.10e+01, avg batch time: 11.8373, average train loss: 1.4006
[11/30 15:45:44 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.5252, average loss: 1.2969
[11/30 15:45:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[11/30 15:45:44 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.25
[11/30 15:52:39 visual_prompt]: Epoch 2 / 100: avg data time: 1.10e+01, avg batch time: 11.8570, average train loss: 3.4720
[11/30 15:53:27 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.5252, average loss: 0.7154
[11/30 15:53:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.18	
[11/30 15:53:27 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.5
[11/30 16:00:20 visual_prompt]: Epoch 3 / 100: avg data time: 1.09e+01, avg batch time: 11.8096, average train loss: 0.7399
[11/30 16:01:08 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.5296, average loss: 0.6848
[11/30 16:01:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.57	
[11/30 16:01:08 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.75
[11/30 16:07:59 visual_prompt]: Epoch 4 / 100: avg data time: 1.09e+01, avg batch time: 11.7620, average train loss: 0.8627
[11/30 16:08:48 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.5272, average loss: 0.7197
[11/30 16:08:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.39	
[11/30 16:08:48 visual_prompt]: Training 5 / 100 epoch, with learning rate 1.0
[11/30 16:15:41 visual_prompt]: Epoch 5 / 100: avg data time: 1.09e+01, avg batch time: 11.8064, average train loss: 1.0651
[11/30 16:16:29 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.5243, average loss: 0.8666
[11/30 16:16:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.11	
[11/30 16:16:29 visual_prompt]: Training 6 / 100 epoch, with learning rate 1.25
[11/30 16:23:21 visual_prompt]: Epoch 6 / 100: avg data time: 1.09e+01, avg batch time: 11.7790, average train loss: 1.6559
[11/30 16:24:09 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.5303, average loss: 1.0535
[11/30 16:24:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.80	
[11/30 16:24:09 visual_prompt]: Training 7 / 100 epoch, with learning rate 1.5
[11/30 16:31:01 visual_prompt]: Epoch 7 / 100: avg data time: 1.09e+01, avg batch time: 11.7701, average train loss: 0.9782
[11/30 16:31:49 visual_prompt]: Inference (val):avg data time: 3.56e-05, avg batch time: 0.5345, average loss: 1.9568
[11/30 16:31:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.12	
[11/30 16:31:49 visual_prompt]: Training 8 / 100 epoch, with learning rate 1.75
[11/30 16:38:48 visual_prompt]: Epoch 8 / 100: avg data time: 1.11e+01, avg batch time: 11.9551, average train loss: 1.3010
[11/30 16:39:36 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.5300, average loss: 1.1560
[11/30 16:39:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.75	
[11/30 16:39:36 visual_prompt]: Training 9 / 100 epoch, with learning rate 2.0
[11/30 16:46:34 visual_prompt]: Epoch 9 / 100: avg data time: 1.11e+01, avg batch time: 11.9434, average train loss: 1.5081
[11/30 16:47:23 visual_prompt]: Inference (val):avg data time: 3.46e-05, avg batch time: 0.5271, average loss: 0.7169
[11/30 16:47:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.15	
[11/30 16:47:23 visual_prompt]: Training 10 / 100 epoch, with learning rate 2.25
[11/30 16:54:21 visual_prompt]: Epoch 10 / 100: avg data time: 1.11e+01, avg batch time: 11.9505, average train loss: 1.0039
[11/30 16:55:10 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.5290, average loss: 0.9307
[11/30 16:55:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.61	
[11/30 16:55:10 visual_prompt]: Training 11 / 100 epoch, with learning rate 2.5
[11/30 17:02:03 visual_prompt]: Epoch 11 / 100: avg data time: 1.09e+01, avg batch time: 11.7989, average train loss: 0.9469
[11/30 17:02:51 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.5257, average loss: 0.6996
[11/30 17:02:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.62	
[11/30 17:02:51 visual_prompt]: Training 12 / 100 epoch, with learning rate 2.4992385337738696
[11/30 17:09:42 visual_prompt]: Epoch 12 / 100: avg data time: 1.09e+01, avg batch time: 11.7369, average train loss: 3.0795
[11/30 17:10:30 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.5322, average loss: 0.9356
[11/30 17:10:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.46	
[11/30 17:10:30 visual_prompt]: Training 13 / 100 epoch, with learning rate 2.4969550628247803
[11/30 17:17:21 visual_prompt]: Epoch 13 / 100: avg data time: 1.09e+01, avg batch time: 11.7391, average train loss: 3.7045
[11/30 17:18:07 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.5277, average loss: 0.6992
[11/30 17:18:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 45.26	
[11/30 17:18:07 visual_prompt]: Best epoch 13: best metric: -0.699
[11/30 17:18:07 visual_prompt]: Training 14 / 100 epoch, with learning rate 2.4931523692103417
[11/30 17:24:57 visual_prompt]: Epoch 14 / 100: avg data time: 1.08e+01, avg batch time: 11.7119, average train loss: 1.3648
[11/30 17:25:46 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.5265, average loss: 0.8836
[11/30 17:25:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.13	
[11/30 17:25:46 visual_prompt]: Training 15 / 100 epoch, with learning rate 2.487835085926963
[11/30 17:32:42 visual_prompt]: Epoch 15 / 100: avg data time: 1.10e+01, avg batch time: 11.8877, average train loss: 5.0260
[11/30 17:33:30 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.5230, average loss: 9.0985
[11/30 17:33:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.82	
[11/30 17:33:30 visual_prompt]: Training 16 / 100 epoch, with learning rate 2.4810096912652604
[11/30 17:40:24 visual_prompt]: Epoch 16 / 100: avg data time: 1.09e+01, avg batch time: 11.8193, average train loss: 4.1740
[11/30 17:41:12 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.5286, average loss: 0.6884
[11/30 17:41:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.10	
[11/30 17:41:12 visual_prompt]: Best epoch 16: best metric: -0.688
[11/30 17:41:12 visual_prompt]: Training 17 / 100 epoch, with learning rate 2.472684500917257
[11/30 17:48:00 visual_prompt]: Epoch 17 / 100: avg data time: 1.08e+01, avg batch time: 11.6545, average train loss: 1.7869
[11/30 17:48:47 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.5228, average loss: 1.2948
[11/30 17:48:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.79	
[11/30 17:48:47 visual_prompt]: Training 18 / 100 epoch, with learning rate 2.4628696578449953
[11/30 17:55:35 visual_prompt]: Epoch 18 / 100: avg data time: 1.08e+01, avg batch time: 11.6411, average train loss: 2.3638
[11/30 17:56:22 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.5233, average loss: 0.7903
[11/30 17:56:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.62	
[11/30 17:56:22 visual_prompt]: Training 19 / 100 epoch, with learning rate 2.4515771199228986
[11/30 18:02:55 visual_prompt]: Epoch 19 / 100: avg data time: 1.04e+01, avg batch time: 11.2275, average train loss: 5.3296
[11/30 18:03:40 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.5307, average loss: 2.8957
[11/30 18:03:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 44.48	
[11/30 18:03:40 visual_prompt]: Training 20 / 100 epoch, with learning rate 2.438820645368942
[11/30 18:10:08 visual_prompt]: Epoch 20 / 100: avg data time: 1.02e+01, avg batch time: 11.0877, average train loss: 3.3733
[11/30 18:10:52 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.5249, average loss: 2.3840
[11/30 18:10:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.43	
[11/30 18:10:52 visual_prompt]: Training 21 / 100 epoch, with learning rate 2.4246157759823856
[11/30 18:17:11 visual_prompt]: Epoch 21 / 100: avg data time: 9.95e+00, avg batch time: 10.8156, average train loss: 3.2587
[11/30 18:17:55 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.5294, average loss: 8.8746
[11/30 18:17:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 39.95	
[11/30 18:17:55 visual_prompt]: Training 22 / 100 epoch, with learning rate 2.4089798182084845
[11/30 18:24:19 visual_prompt]: Epoch 22 / 100: avg data time: 1.01e+01, avg batch time: 10.9612, average train loss: 2.9532
[11/30 18:25:05 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.5266, average loss: 1.5694
[11/30 18:25:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.39	
[11/30 18:25:05 visual_prompt]: Training 23 / 100 epoch, with learning rate 2.391931822053251
[11/30 18:31:36 visual_prompt]: Epoch 23 / 100: avg data time: 1.03e+01, avg batch time: 11.1867, average train loss: 3.0449
[11/30 18:32:20 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.5211, average loss: 2.6377
[11/30 18:32:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.57	
[11/30 18:32:20 visual_prompt]: Stopping early.
[11/30 18:32:21 visual_prompt]: Rank of current process: 0. World size: 1
[11/30 18:32:21 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA TITAN Xp
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/30 18:32:21 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss', 'RECORD_GPU_SNAPSHOT', 'True'])
[11/30 18:32:21 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/30 18:32:21 visual_prompt]: Training with config:
[11/30 18:32:21 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr2.5_wd0.0001/patience7/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 2.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True}), 'RECORD_GPU_SNAPSHOT': True})
[11/30 18:32:21 visual_prompt]: Loading training data...
[11/30 18:32:21 visual_prompt]: Constructing mammo-cbis dataset train...
[11/30 18:32:21 visual_prompt]: Loading validation data...
[11/30 18:32:21 visual_prompt]: Constructing mammo-cbis dataset val...
[11/30 18:32:21 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[11/30 18:32:26 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[11/30 18:32:26 visual_prompt]: tuned percent:0.536
[11/30 18:32:27 visual_prompt]: Device used for model: 0
[11/30 18:32:27 visual_prompt]: Setting up Evaluator...
[11/30 18:32:27 visual_prompt]: Setting up Trainer...
[11/30 18:32:27 visual_prompt]: 	Setting up the optimizer...
[11/30 18:32:27 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/30 18:38:47 visual_prompt]: Epoch 1 / 100: avg data time: 9.98e+00, avg batch time: 10.8541, average train loss: 1.4006
[11/30 18:39:30 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.5283, average loss: 1.2969
[11/30 18:39:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[11/30 18:39:30 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.25
[11/30 18:45:50 visual_prompt]: Epoch 2 / 100: avg data time: 9.95e+00, avg batch time: 10.8276, average train loss: 3.4462
[11/30 18:46:33 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.5300, average loss: 0.6881
[11/30 18:46:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.01	
[11/30 18:46:33 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.5
[11/30 18:52:53 visual_prompt]: Epoch 3 / 100: avg data time: 9.96e+00, avg batch time: 10.8369, average train loss: 0.7411
[11/30 18:53:37 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.5289, average loss: 0.6804
[11/30 18:53:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.18	
[11/30 18:53:37 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.75
[11/30 18:59:59 visual_prompt]: Epoch 4 / 100: avg data time: 1.01e+01, avg batch time: 10.9278, average train loss: 0.8913
[11/30 19:00:47 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.5241, average loss: 0.7379
[11/30 19:00:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.76	
[11/30 19:00:47 visual_prompt]: Training 5 / 100 epoch, with learning rate 1.0
[11/30 19:07:32 visual_prompt]: Epoch 5 / 100: avg data time: 1.07e+01, avg batch time: 11.5578, average train loss: 1.1565
[11/30 19:08:17 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.5301, average loss: 0.7966
[11/30 19:08:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.15	
[11/30 19:08:17 visual_prompt]: Training 6 / 100 epoch, with learning rate 1.25
[11/30 19:14:46 visual_prompt]: Epoch 6 / 100: avg data time: 1.03e+01, avg batch time: 11.1317, average train loss: 0.8104
[11/30 19:15:31 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.5234, average loss: 0.7666
[11/30 19:15:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.06	
[11/30 19:15:31 visual_prompt]: Training 7 / 100 epoch, with learning rate 1.5
[11/30 19:22:01 visual_prompt]: Epoch 7 / 100: avg data time: 1.02e+01, avg batch time: 11.1179, average train loss: 1.9810
[11/30 19:22:46 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.5247, average loss: 5.3661
[11/30 19:22:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.66	
[11/30 19:22:46 visual_prompt]: Training 8 / 100 epoch, with learning rate 1.75
[11/30 19:29:14 visual_prompt]: Epoch 8 / 100: avg data time: 1.02e+01, avg batch time: 11.0902, average train loss: 5.3285
[11/30 19:29:59 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.5288, average loss: 0.7372
[11/30 19:29:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.64	
[11/30 19:29:59 visual_prompt]: Training 9 / 100 epoch, with learning rate 2.0
[11/30 19:36:28 visual_prompt]: Epoch 9 / 100: avg data time: 1.02e+01, avg batch time: 11.1208, average train loss: 4.2134
[11/30 19:37:13 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.5307, average loss: 1.2099
[11/30 19:37:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.02	
[11/30 19:37:13 visual_prompt]: Training 10 / 100 epoch, with learning rate 2.25
[11/30 19:43:42 visual_prompt]: Epoch 10 / 100: avg data time: 1.02e+01, avg batch time: 11.1029, average train loss: 0.9462
[11/30 19:44:27 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.5259, average loss: 1.1169
[11/30 19:44:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.73	
[11/30 19:44:27 visual_prompt]: Training 11 / 100 epoch, with learning rate 2.5
[11/30 19:50:56 visual_prompt]: Epoch 11 / 100: avg data time: 1.02e+01, avg batch time: 11.1028, average train loss: 1.5373
[11/30 19:51:41 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.5278, average loss: 1.5131
[11/30 19:51:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.07	
[11/30 19:51:41 visual_prompt]: Training 12 / 100 epoch, with learning rate 2.4992385337738696
[11/30 19:58:09 visual_prompt]: Epoch 12 / 100: avg data time: 1.02e+01, avg batch time: 11.0891, average train loss: 1.3870
[11/30 19:58:54 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.5281, average loss: 0.9609
[11/30 19:58:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.79	
[11/30 19:58:54 visual_prompt]: Best epoch 12: best metric: -0.961
[11/30 19:58:54 visual_prompt]: Training 13 / 100 epoch, with learning rate 2.4969550628247803
[11/30 20:05:23 visual_prompt]: Epoch 13 / 100: avg data time: 1.02e+01, avg batch time: 11.1083, average train loss: 1.0989
[11/30 20:06:08 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.5228, average loss: 0.7132
[11/30 20:06:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.75	
[11/30 20:06:08 visual_prompt]: Best epoch 13: best metric: -0.713
[11/30 20:06:08 visual_prompt]: Training 14 / 100 epoch, with learning rate 2.4931523692103417
[11/30 20:12:36 visual_prompt]: Epoch 14 / 100: avg data time: 1.02e+01, avg batch time: 11.0814, average train loss: 1.0539
[11/30 20:13:21 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.5276, average loss: 0.7854
[11/30 20:13:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.54	
[11/30 20:13:21 visual_prompt]: Training 15 / 100 epoch, with learning rate 2.487835085926963
[11/30 20:19:50 visual_prompt]: Epoch 15 / 100: avg data time: 1.02e+01, avg batch time: 11.1092, average train loss: 0.8671
[11/30 20:20:35 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.5260, average loss: 0.8919
[11/30 20:20:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.59	
[11/30 20:20:35 visual_prompt]: Training 16 / 100 epoch, with learning rate 2.4810096912652604
[11/30 20:27:03 visual_prompt]: Epoch 16 / 100: avg data time: 1.02e+01, avg batch time: 11.0907, average train loss: 0.9253
[11/30 20:27:48 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.5269, average loss: 0.7166
[11/30 20:27:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.82	
[11/30 20:27:48 visual_prompt]: Training 17 / 100 epoch, with learning rate 2.472684500917257
[11/30 20:34:16 visual_prompt]: Epoch 17 / 100: avg data time: 1.02e+01, avg batch time: 11.0822, average train loss: 0.9034
[11/30 20:35:01 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.5238, average loss: 1.2001
[11/30 20:35:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.22	
[11/30 20:35:01 visual_prompt]: Training 18 / 100 epoch, with learning rate 2.4628696578449953
[11/30 20:41:29 visual_prompt]: Epoch 18 / 100: avg data time: 1.02e+01, avg batch time: 11.0949, average train loss: 0.8904
[11/30 20:42:14 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.5281, average loss: 0.7554
[11/30 20:42:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.17	
[11/30 20:42:14 visual_prompt]: Training 19 / 100 epoch, with learning rate 2.4515771199228986
[11/30 20:48:42 visual_prompt]: Epoch 19 / 100: avg data time: 1.02e+01, avg batch time: 11.0778, average train loss: 0.8317
[11/30 20:49:27 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.5199, average loss: 0.6986
[11/30 20:49:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.01	
[11/30 20:49:27 visual_prompt]: Best epoch 19: best metric: -0.699
[11/30 20:49:27 visual_prompt]: Training 20 / 100 epoch, with learning rate 2.438820645368942
[11/30 20:55:54 visual_prompt]: Epoch 20 / 100: avg data time: 1.02e+01, avg batch time: 11.0648, average train loss: 0.7180
[11/30 20:56:39 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.5283, average loss: 0.6836
[11/30 20:56:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 58.85	
[11/30 20:56:39 visual_prompt]: Best epoch 20: best metric: -0.684
[11/30 20:56:39 visual_prompt]: Training 21 / 100 epoch, with learning rate 2.4246157759823856
[11/30 21:02:58 visual_prompt]: Epoch 21 / 100: avg data time: 9.96e+00, avg batch time: 10.8365, average train loss: 0.7931
[11/30 21:03:42 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.5219, average loss: 0.6893
[11/30 21:03:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.64	
[11/30 21:03:42 visual_prompt]: Training 22 / 100 epoch, with learning rate 2.4089798182084845
[11/30 21:10:01 visual_prompt]: Epoch 22 / 100: avg data time: 9.95e+00, avg batch time: 10.8245, average train loss: 1.0000
[11/30 21:10:45 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.5225, average loss: 0.6869
[11/30 21:10:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.37	
[11/30 21:10:45 visual_prompt]: Training 23 / 100 epoch, with learning rate 2.391931822053251
[11/30 21:17:06 visual_prompt]: Epoch 23 / 100: avg data time: 1.00e+01, avg batch time: 10.8751, average train loss: 0.7470
[11/30 21:17:50 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.5231, average loss: 0.7234
[11/30 21:17:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.80	
[11/30 21:17:50 visual_prompt]: Training 24 / 100 epoch, with learning rate 2.3734925578739587
[11/30 21:24:11 visual_prompt]: Epoch 24 / 100: avg data time: 1.00e+01, avg batch time: 10.8746, average train loss: 0.7880
[11/30 21:24:55 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.5263, average loss: 0.7472
[11/30 21:24:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.34	
[11/30 21:24:55 visual_prompt]: Training 25 / 100 epoch, with learning rate 2.3536844910736585
[11/30 21:31:14 visual_prompt]: Epoch 25 / 100: avg data time: 9.95e+00, avg batch time: 10.8260, average train loss: 0.7322
[11/30 21:31:58 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.5278, average loss: 0.7025
[11/30 21:31:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 47.97	rocauc: 60.30	
[11/30 21:31:58 visual_prompt]: Training 26 / 100 epoch, with learning rate 2.3325317547305486
[11/30 21:38:18 visual_prompt]: Epoch 26 / 100: avg data time: 9.98e+00, avg batch time: 10.8539, average train loss: 0.8326
[11/30 21:39:02 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.5321, average loss: 0.8469
[11/30 21:39:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.88	
[11/30 21:39:02 visual_prompt]: Training 27 / 100 epoch, with learning rate 2.310060120195532
[11/30 21:45:23 visual_prompt]: Epoch 27 / 100: avg data time: 1.00e+01, avg batch time: 10.8787, average train loss: 0.7651
[11/30 21:46:07 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.5243, average loss: 1.0787
[11/30 21:46:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.83	
[11/30 21:46:07 visual_prompt]: Stopping early.
[11/30 21:46:07 visual_prompt]: Rank of current process: 0. World size: 1
[11/30 21:46:07 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA TITAN Xp
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/30 21:46:07 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss', 'RECORD_GPU_SNAPSHOT', 'True'])
[11/30 21:46:07 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/30 21:46:07 visual_prompt]: Training with config:
[11/30 21:46:07 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr2.5_wd0.0/patience7/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 2.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True}), 'RECORD_GPU_SNAPSHOT': True})
[11/30 21:46:07 visual_prompt]: Loading training data...
[11/30 21:46:07 visual_prompt]: Constructing mammo-cbis dataset train...
[11/30 21:46:07 visual_prompt]: Loading validation data...
[11/30 21:46:07 visual_prompt]: Constructing mammo-cbis dataset val...
[11/30 21:46:07 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[11/30 21:46:13 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[11/30 21:46:13 visual_prompt]: tuned percent:0.536
[11/30 21:46:13 visual_prompt]: Device used for model: 0
[11/30 21:46:13 visual_prompt]: Setting up Evaluator...
[11/30 21:46:13 visual_prompt]: Setting up Trainer...
[11/30 21:46:13 visual_prompt]: 	Setting up the optimizer...
[11/30 21:46:13 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/30 21:52:33 visual_prompt]: Epoch 1 / 100: avg data time: 9.98e+00, avg batch time: 10.8542, average train loss: 1.4006
[11/30 21:53:17 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.5262, average loss: 1.2969
[11/30 21:53:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[11/30 21:53:17 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.25
[11/30 21:59:38 visual_prompt]: Epoch 2 / 100: avg data time: 1.00e+01, avg batch time: 10.8774, average train loss: 3.4464
[11/30 22:00:22 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.5233, average loss: 0.6890
[11/30 22:00:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.14	
[11/30 22:00:22 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.5
[11/30 22:06:42 visual_prompt]: Epoch 3 / 100: avg data time: 9.98e+00, avg batch time: 10.8527, average train loss: 0.7411
[11/30 22:07:26 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.5293, average loss: 0.6804
[11/30 22:07:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 59.62	
[11/30 22:07:26 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.75
[11/30 22:13:46 visual_prompt]: Epoch 4 / 100: avg data time: 9.99e+00, avg batch time: 10.8613, average train loss: 0.8931
[11/30 22:14:30 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.5270, average loss: 0.7471
[11/30 22:14:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.48	
[11/30 22:14:30 visual_prompt]: Training 5 / 100 epoch, with learning rate 1.0
[11/30 22:20:50 visual_prompt]: Epoch 5 / 100: avg data time: 9.98e+00, avg batch time: 10.8502, average train loss: 1.1473
[11/30 22:21:34 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.5241, average loss: 0.8585
[11/30 22:21:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.56	
[11/30 22:21:34 visual_prompt]: Training 6 / 100 epoch, with learning rate 1.25
[11/30 22:27:55 visual_prompt]: Epoch 6 / 100: avg data time: 1.00e+01, avg batch time: 10.8695, average train loss: 0.8060
[11/30 22:28:39 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.5198, average loss: 0.7609
[11/30 22:28:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.26	
[11/30 22:28:39 visual_prompt]: Training 7 / 100 epoch, with learning rate 1.5
[11/30 22:34:59 visual_prompt]: Epoch 7 / 100: avg data time: 1.00e+01, avg batch time: 10.8648, average train loss: 2.0366
[11/30 22:35:43 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.5304, average loss: 2.9040
[11/30 22:35:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.12	
[11/30 22:35:43 visual_prompt]: Training 8 / 100 epoch, with learning rate 1.75
[11/30 22:42:03 visual_prompt]: Epoch 8 / 100: avg data time: 9.96e+00, avg batch time: 10.8293, average train loss: 1.6617
[11/30 22:42:47 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.5222, average loss: 1.0023
[11/30 22:42:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.83	
[11/30 22:42:47 visual_prompt]: Training 9 / 100 epoch, with learning rate 2.0
[11/30 22:49:08 visual_prompt]: Epoch 9 / 100: avg data time: 1.00e+01, avg batch time: 10.8867, average train loss: 3.0392
[11/30 22:49:52 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.5265, average loss: 2.4669
[11/30 22:49:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.87	
[11/30 22:49:52 visual_prompt]: Training 10 / 100 epoch, with learning rate 2.25
[11/30 22:56:12 visual_prompt]: Epoch 10 / 100: avg data time: 9.98e+00, avg batch time: 10.8453, average train loss: 4.4061
[11/30 22:56:55 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.5216, average loss: 0.9629
[11/30 22:56:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.74	
[11/30 22:56:55 visual_prompt]: Training 11 / 100 epoch, with learning rate 2.5
[11/30 23:03:16 visual_prompt]: Epoch 11 / 100: avg data time: 9.99e+00, avg batch time: 10.8581, average train loss: 2.4165
[11/30 23:04:00 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.5237, average loss: 1.9366
[11/30 23:04:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.12	
[11/30 23:04:00 visual_prompt]: Training 12 / 100 epoch, with learning rate 2.4992385337738696
[11/30 23:10:20 visual_prompt]: Epoch 12 / 100: avg data time: 9.99e+00, avg batch time: 10.8609, average train loss: 1.8818
[11/30 23:11:04 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.5226, average loss: 0.6832
[11/30 23:11:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 58.13	
[11/30 23:11:04 visual_prompt]: Best epoch 12: best metric: -0.683
[11/30 23:11:04 visual_prompt]: Training 13 / 100 epoch, with learning rate 2.4969550628247803
[11/30 23:17:40 visual_prompt]: Epoch 13 / 100: avg data time: 1.04e+01, avg batch time: 11.3110, average train loss: 1.1836
[11/30 23:18:26 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.5272, average loss: 0.7320
[11/30 23:18:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.62	
[11/30 23:18:26 visual_prompt]: Training 14 / 100 epoch, with learning rate 2.4931523692103417
[11/30 23:24:56 visual_prompt]: Epoch 14 / 100: avg data time: 1.03e+01, avg batch time: 11.1341, average train loss: 1.5084
[11/30 23:25:42 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.5179, average loss: 2.4211
[11/30 23:25:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.69	
[11/30 23:25:42 visual_prompt]: Training 15 / 100 epoch, with learning rate 2.487835085926963
[11/30 23:32:21 visual_prompt]: Epoch 15 / 100: avg data time: 1.05e+01, avg batch time: 11.3900, average train loss: 1.1882
[11/30 23:33:08 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.5231, average loss: 0.9154
[11/30 23:33:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.34	
[11/30 23:33:08 visual_prompt]: Training 16 / 100 epoch, with learning rate 2.4810096912652604
[11/30 23:39:42 visual_prompt]: Epoch 16 / 100: avg data time: 1.04e+01, avg batch time: 11.2718, average train loss: 0.7712
[11/30 23:40:28 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.5273, average loss: 0.6913
[11/30 23:40:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 60.56	
[11/30 23:40:28 visual_prompt]: Training 17 / 100 epoch, with learning rate 2.472684500917257
[11/30 23:47:02 visual_prompt]: Epoch 17 / 100: avg data time: 1.04e+01, avg batch time: 11.2662, average train loss: 0.9954
[11/30 23:47:46 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.5219, average loss: 0.8424
[11/30 23:47:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.74	
[11/30 23:47:46 visual_prompt]: Training 18 / 100 epoch, with learning rate 2.4628696578449953
[11/30 23:54:07 visual_prompt]: Epoch 18 / 100: avg data time: 1.00e+01, avg batch time: 10.8778, average train loss: 0.8370
[11/30 23:54:51 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.5253, average loss: 0.6988
[11/30 23:54:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.47	rocauc: 62.54	
[11/30 23:54:51 visual_prompt]: Training 19 / 100 epoch, with learning rate 2.4515771199228986
[12/01 00:01:27 visual_prompt]: Epoch 19 / 100: avg data time: 1.04e+01, avg batch time: 11.3006, average train loss: 0.8658
[12/01 00:02:13 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.5218, average loss: 0.6901
[12/01 00:02:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.98	
[12/01 00:02:13 visual_prompt]: Stopping early.
[12/01 00:02:13 visual_prompt]: Rank of current process: 0. World size: 1
[12/01 00:02:13 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA TITAN Xp
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[12/01 00:02:13 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss', 'RECORD_GPU_SNAPSHOT', 'True'])
[12/01 00:02:13 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[12/01 00:02:13 visual_prompt]: Training with config:
[12/01 00:02:13 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr1.0_wd0.01/patience7/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 1.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True}), 'RECORD_GPU_SNAPSHOT': True})
[12/01 00:02:13 visual_prompt]: Loading training data...
[12/01 00:02:13 visual_prompt]: Constructing mammo-cbis dataset train...
[12/01 00:02:13 visual_prompt]: Loading validation data...
[12/01 00:02:13 visual_prompt]: Constructing mammo-cbis dataset val...
[12/01 00:02:13 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[12/01 00:02:20 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[12/01 00:02:20 visual_prompt]: tuned percent:0.536
[12/01 00:02:20 visual_prompt]: Device used for model: 0
[12/01 00:02:20 visual_prompt]: Setting up Evaluator...
[12/01 00:02:20 visual_prompt]: Setting up Trainer...
[12/01 00:02:20 visual_prompt]: 	Setting up the optimizer...
[12/01 00:02:20 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[12/01 00:08:53 visual_prompt]: Epoch 1 / 100: avg data time: 1.04e+01, avg batch time: 11.2417, average train loss: 1.4006
[12/01 00:09:39 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.5114, average loss: 1.2969
[12/01 00:09:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[12/01 00:09:39 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.1
[12/01 00:16:11 visual_prompt]: Epoch 2 / 100: avg data time: 1.03e+01, avg batch time: 11.2046, average train loss: 2.1592
[12/01 00:16:57 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.5176, average loss: 0.6879
[12/01 00:16:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.30	
[12/01 00:16:57 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.2
[12/01 00:23:29 visual_prompt]: Epoch 3 / 100: avg data time: 1.03e+01, avg batch time: 11.2127, average train loss: 0.7533
[12/01 00:24:13 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.5219, average loss: 0.6938
[12/01 00:24:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.62	
[12/01 00:24:13 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.3
[12/01 00:30:38 visual_prompt]: Epoch 4 / 100: avg data time: 1.01e+01, avg batch time: 10.9863, average train loss: 0.7219
[12/01 00:31:22 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.5228, average loss: 0.7721
[12/01 00:31:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.03	
[12/01 00:31:22 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.4
[12/01 00:37:45 visual_prompt]: Epoch 5 / 100: avg data time: 1.01e+01, avg batch time: 10.9353, average train loss: 0.7179
[12/01 00:38:31 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.5196, average loss: 0.6924
[12/01 00:38:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.88	
[12/01 00:38:31 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.5
[12/01 00:45:11 visual_prompt]: Epoch 6 / 100: avg data time: 1.05e+01, avg batch time: 11.4221, average train loss: 0.7286
[12/01 00:45:58 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.5196, average loss: 0.6924
[12/01 00:45:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.36	
[12/01 00:45:58 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.6
[12/01 00:52:39 visual_prompt]: Epoch 7 / 100: avg data time: 1.06e+01, avg batch time: 11.4533, average train loss: 0.7507
[12/01 00:53:25 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.5210, average loss: 1.0640
[12/01 00:53:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 44.95	
[12/01 00:53:25 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.7
[12/01 01:00:07 visual_prompt]: Epoch 8 / 100: avg data time: 1.06e+01, avg batch time: 11.4556, average train loss: 0.7506
[12/01 01:00:53 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.5203, average loss: 0.6907
[12/01 01:00:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 39.41	
[12/01 01:00:53 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.8
[12/01 01:07:36 visual_prompt]: Epoch 9 / 100: avg data time: 1.06e+01, avg batch time: 11.5132, average train loss: 0.7703
[12/01 01:08:23 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.5205, average loss: 0.6890
[12/01 01:08:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.47	
[12/01 01:08:23 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.9
[12/01 01:15:00 visual_prompt]: Epoch 10 / 100: avg data time: 1.05e+01, avg batch time: 11.3460, average train loss: 0.7368
[12/01 01:15:46 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.5175, average loss: 0.7129
[12/01 01:15:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.22	
[12/01 01:15:46 visual_prompt]: Training 11 / 100 epoch, with learning rate 1.0
[12/01 01:22:28 visual_prompt]: Epoch 11 / 100: avg data time: 1.06e+01, avg batch time: 11.4844, average train loss: 1.1397
[12/01 01:23:15 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.5277, average loss: 1.7558
[12/01 01:23:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.55	
[12/01 01:23:15 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.9996954135095479
[12/01 01:29:44 visual_prompt]: Epoch 12 / 100: avg data time: 1.02e+01, avg batch time: 11.1092, average train loss: 1.1263
[12/01 01:30:28 visual_prompt]: Inference (val):avg data time: 3.35e-05, avg batch time: 0.5215, average loss: 1.1164
[12/01 01:30:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.13	
[12/01 01:30:28 visual_prompt]: Best epoch 12: best metric: -1.116
[12/01 01:30:28 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.9987820251299121
[12/01 01:36:55 visual_prompt]: Epoch 13 / 100: avg data time: 1.02e+01, avg batch time: 11.0521, average train loss: 1.2693
[12/01 01:37:40 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.5269, average loss: 0.9655
[12/01 01:37:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.01	
[12/01 01:37:40 visual_prompt]: Best epoch 13: best metric: -0.966
[12/01 01:37:40 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.9972609476841366
[12/01 01:44:04 visual_prompt]: Epoch 14 / 100: avg data time: 1.01e+01, avg batch time: 10.9764, average train loss: 2.3697
[12/01 01:44:49 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.5173, average loss: 1.1207
[12/01 01:44:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.71	
[12/01 01:44:49 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.9951340343707852
[12/01 01:51:15 visual_prompt]: Epoch 15 / 100: avg data time: 1.02e+01, avg batch time: 11.0472, average train loss: 1.9807
[12/01 01:52:00 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.5225, average loss: 0.7091
[12/01 01:52:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.69	
[12/01 01:52:00 visual_prompt]: Best epoch 15: best metric: -0.709
[12/01 01:52:00 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.9924038765061041
[12/01 01:58:25 visual_prompt]: Epoch 16 / 100: avg data time: 1.01e+01, avg batch time: 11.0082, average train loss: 0.9670
[12/01 01:59:10 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.5268, average loss: 0.9257
[12/01 01:59:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.42	
[12/01 01:59:10 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.9890738003669028
[12/01 02:05:34 visual_prompt]: Epoch 17 / 100: avg data time: 1.01e+01, avg batch time: 10.9748, average train loss: 0.8435
[12/01 02:06:19 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.5190, average loss: 0.8919
[12/01 02:06:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.93	
[12/01 02:06:19 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.9851478631379982
[12/01 02:12:47 visual_prompt]: Epoch 18 / 100: avg data time: 1.02e+01, avg batch time: 11.0761, average train loss: 0.7797
[12/01 02:13:31 visual_prompt]: Inference (val):avg data time: 2.08e-05, avg batch time: 0.5169, average loss: 0.6905
[12/01 02:13:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.45	
[12/01 02:13:31 visual_prompt]: Best epoch 18: best metric: -0.691
[12/01 02:13:31 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.9806308479691594
[12/01 02:19:57 visual_prompt]: Epoch 19 / 100: avg data time: 1.01e+01, avg batch time: 11.0193, average train loss: 0.8639
[12/01 02:20:42 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.5258, average loss: 1.5774
[12/01 02:20:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 44.51	
[12/01 02:20:42 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.9755282581475768
[12/01 02:27:08 visual_prompt]: Epoch 20 / 100: avg data time: 1.02e+01, avg batch time: 11.0381, average train loss: 0.8325
[12/01 02:27:53 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.5268, average loss: 0.6975
[12/01 02:27:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.40	
[12/01 02:27:53 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.9698463103929542
[12/01 02:34:18 visual_prompt]: Epoch 21 / 100: avg data time: 1.01e+01, avg batch time: 10.9904, average train loss: 0.8661
[12/01 02:35:02 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.5242, average loss: 1.3138
[12/01 02:35:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.75	
[12/01 02:35:02 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.9635919272833937
[12/01 02:41:25 visual_prompt]: Epoch 22 / 100: avg data time: 1.01e+01, avg batch time: 10.9409, average train loss: 0.8668
[12/01 02:42:10 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.5121, average loss: 0.8454
[12/01 02:42:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.63	
[12/01 02:42:10 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.9567727288213004
[12/01 02:48:34 visual_prompt]: Epoch 23 / 100: avg data time: 1.01e+01, avg batch time: 10.9641, average train loss: 0.7891
[12/01 02:49:18 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.5252, average loss: 0.6956
[12/01 02:49:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.95	
[12/01 02:49:18 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.9493970231495835
[12/01 02:56:01 visual_prompt]: Epoch 24 / 100: avg data time: 1.06e+01, avg batch time: 11.4999, average train loss: 0.8349
[12/01 02:56:47 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.5131, average loss: 0.7273
[12/01 02:56:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.58	
[12/01 02:56:47 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.9414737964294635
[12/01 03:03:09 visual_prompt]: Epoch 25 / 100: avg data time: 1.00e+01, avg batch time: 10.9089, average train loss: 1.2129
[12/01 03:03:52 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.5154, average loss: 0.8310
[12/01 03:03:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.29	
[12/01 03:03:52 visual_prompt]: Stopping early.
[12/01 03:03:53 visual_prompt]: Rank of current process: 0. World size: 1
[12/01 03:03:53 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA TITAN Xp
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[12/01 03:03:53 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss', 'RECORD_GPU_SNAPSHOT', 'True'])
[12/01 03:03:53 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[12/01 03:03:53 visual_prompt]: Training with config:
[12/01 03:03:53 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr1.0_wd0.001/patience7/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 1.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True}), 'RECORD_GPU_SNAPSHOT': True})
[12/01 03:03:53 visual_prompt]: Loading training data...
[12/01 03:03:53 visual_prompt]: Constructing mammo-cbis dataset train...
[12/01 03:03:53 visual_prompt]: Loading validation data...
[12/01 03:03:53 visual_prompt]: Constructing mammo-cbis dataset val...
[12/01 03:03:53 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[12/01 03:03:59 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[12/01 03:03:59 visual_prompt]: tuned percent:0.536
[12/01 03:03:59 visual_prompt]: Device used for model: 0
[12/01 03:03:59 visual_prompt]: Setting up Evaluator...
[12/01 03:03:59 visual_prompt]: Setting up Trainer...
[12/01 03:03:59 visual_prompt]: 	Setting up the optimizer...
[12/01 03:03:59 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[12/01 03:10:17 visual_prompt]: Epoch 1 / 100: avg data time: 9.91e+00, avg batch time: 10.7876, average train loss: 1.4006
[12/01 03:11:00 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.5193, average loss: 1.2969
[12/01 03:11:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[12/01 03:11:00 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.1
[12/01 03:17:17 visual_prompt]: Epoch 2 / 100: avg data time: 9.90e+00, avg batch time: 10.7714, average train loss: 2.2246
[12/01 03:18:01 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.5227, average loss: 0.6883
[12/01 03:18:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 53.66	rocauc: 51.57	
[12/01 03:18:01 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.2
[12/01 03:24:19 visual_prompt]: Epoch 3 / 100: avg data time: 9.91e+00, avg batch time: 10.7842, average train loss: 0.7838
[12/01 03:25:02 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.5235, average loss: 0.6890
[12/01 03:25:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.47	rocauc: 57.56	
[12/01 03:25:02 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.3
[12/01 03:31:23 visual_prompt]: Epoch 4 / 100: avg data time: 1.00e+01, avg batch time: 10.8685, average train loss: 0.7249
[12/01 03:32:07 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.5166, average loss: 0.7030
[12/01 03:32:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.23	
[12/01 03:32:07 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.4
[12/01 03:38:26 visual_prompt]: Epoch 5 / 100: avg data time: 9.95e+00, avg batch time: 10.8262, average train loss: 0.8061
[12/01 03:39:10 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.5181, average loss: 0.7331
[12/01 03:39:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.78	
[12/01 03:39:10 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.5
[12/01 03:45:31 visual_prompt]: Epoch 6 / 100: avg data time: 1.00e+01, avg batch time: 10.8828, average train loss: 0.8022
[12/01 03:46:15 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.5111, average loss: 0.6887
[12/01 03:46:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.37	
[12/01 03:46:15 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.6
[12/01 03:52:36 visual_prompt]: Epoch 7 / 100: avg data time: 1.00e+01, avg batch time: 10.8837, average train loss: 0.7032
[12/01 03:53:20 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.5244, average loss: 1.3003
[12/01 03:53:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.69	
[12/01 03:53:20 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.7
[12/01 03:59:39 visual_prompt]: Epoch 8 / 100: avg data time: 9.95e+00, avg batch time: 10.8226, average train loss: 0.8210
[12/01 04:00:23 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.5136, average loss: 0.6832
[12/01 04:00:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 60.55	
[12/01 04:00:23 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.8
[12/01 04:06:43 visual_prompt]: Epoch 9 / 100: avg data time: 1.00e+01, avg batch time: 10.8718, average train loss: 0.7957
[12/01 04:07:27 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.5194, average loss: 0.7088
[12/01 04:07:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.75	
[12/01 04:07:27 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.9
[12/01 04:13:46 visual_prompt]: Epoch 10 / 100: avg data time: 9.95e+00, avg batch time: 10.8218, average train loss: 0.7533
[12/01 04:14:30 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.5202, average loss: 0.7465
[12/01 04:14:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.65	
[12/01 04:14:30 visual_prompt]: Training 11 / 100 epoch, with learning rate 1.0
[12/01 04:20:50 visual_prompt]: Epoch 11 / 100: avg data time: 9.99e+00, avg batch time: 10.8609, average train loss: 0.7584
[12/01 04:21:34 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.5199, average loss: 0.7771
[12/01 04:21:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.46	
[12/01 04:21:34 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.9996954135095479
[12/01 04:27:54 visual_prompt]: Epoch 12 / 100: avg data time: 9.98e+00, avg batch time: 10.8510, average train loss: 0.7227
[12/01 04:28:38 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.5179, average loss: 0.6905
[12/01 04:28:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 59.32	
[12/01 04:28:38 visual_prompt]: Best epoch 12: best metric: -0.690
[12/01 04:28:38 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.9987820251299121
[12/01 04:34:58 visual_prompt]: Epoch 13 / 100: avg data time: 9.97e+00, avg batch time: 10.8436, average train loss: 0.7525
[12/01 04:35:42 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.5242, average loss: 0.6899
[12/01 04:35:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 59.98	
[12/01 04:35:42 visual_prompt]: Best epoch 13: best metric: -0.690
[12/01 04:35:42 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.9972609476841366
[12/01 04:42:02 visual_prompt]: Epoch 14 / 100: avg data time: 9.98e+00, avg batch time: 10.8584, average train loss: 0.7603
[12/01 04:42:46 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.5141, average loss: 0.7067
[12/01 04:42:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.87	
[12/01 04:42:46 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.9951340343707852
[12/01 04:49:06 visual_prompt]: Epoch 15 / 100: avg data time: 9.98e+00, avg batch time: 10.8524, average train loss: 0.7629
[12/01 04:49:50 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.5191, average loss: 0.7203
[12/01 04:49:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.67	
[12/01 04:49:50 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.9924038765061041
[12/01 04:56:10 visual_prompt]: Epoch 16 / 100: avg data time: 9.99e+00, avg batch time: 10.8637, average train loss: 0.7333
[12/01 04:56:54 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.5148, average loss: 0.9394
[12/01 04:56:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.81	
[12/01 04:56:54 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.9890738003669028
[12/01 05:03:14 visual_prompt]: Epoch 17 / 100: avg data time: 9.96e+00, avg batch time: 10.8351, average train loss: 0.7859
[12/01 05:03:57 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.5167, average loss: 0.8035
[12/01 05:03:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.30	
[12/01 05:03:57 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.9851478631379982
[12/01 05:10:17 visual_prompt]: Epoch 18 / 100: avg data time: 9.96e+00, avg batch time: 10.8300, average train loss: 0.7496
[12/01 05:11:00 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.5222, average loss: 0.9038
[12/01 05:11:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.23	
[12/01 05:11:00 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.9806308479691594
[12/01 05:17:21 visual_prompt]: Epoch 19 / 100: avg data time: 9.98e+00, avg batch time: 10.8595, average train loss: 0.7214
[12/01 05:18:05 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.5211, average loss: 0.7870
[12/01 05:18:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.91	
[12/01 05:18:05 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.9755282581475768
[12/01 05:24:25 visual_prompt]: Epoch 20 / 100: avg data time: 9.99e+00, avg batch time: 10.8632, average train loss: 0.7102
[12/01 05:25:09 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.5223, average loss: 0.7399
[12/01 05:25:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.18	
[12/01 05:25:09 visual_prompt]: Stopping early.
[12/01 05:25:09 visual_prompt]: Rank of current process: 0. World size: 1
[12/01 05:25:09 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA TITAN Xp
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[12/01 05:25:09 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss', 'RECORD_GPU_SNAPSHOT', 'True'])
[12/01 05:25:09 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[12/01 05:25:09 visual_prompt]: Training with config:
[12/01 05:25:09 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr1.0_wd0.0001/patience7/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 1.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True}), 'RECORD_GPU_SNAPSHOT': True})
[12/01 05:25:09 visual_prompt]: Loading training data...
[12/01 05:25:09 visual_prompt]: Constructing mammo-cbis dataset train...
[12/01 05:25:09 visual_prompt]: Loading validation data...
[12/01 05:25:09 visual_prompt]: Constructing mammo-cbis dataset val...
[12/01 05:25:09 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[12/01 05:25:12 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[12/01 05:25:12 visual_prompt]: tuned percent:0.536
[12/01 05:25:12 visual_prompt]: Device used for model: 0
[12/01 05:25:12 visual_prompt]: Setting up Evaluator...
[12/01 05:25:12 visual_prompt]: Setting up Trainer...
[12/01 05:25:12 visual_prompt]: 	Setting up the optimizer...
[12/01 05:25:12 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[12/01 05:31:31 visual_prompt]: Epoch 1 / 100: avg data time: 9.95e+00, avg batch time: 10.8241, average train loss: 1.4006
[12/01 05:32:14 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.5235, average loss: 1.2969
[12/01 05:32:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[12/01 05:32:14 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.1
[12/01 05:38:32 visual_prompt]: Epoch 2 / 100: avg data time: 9.89e+00, avg batch time: 10.7738, average train loss: 2.2323
[12/01 05:39:15 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.5143, average loss: 0.6883
[12/01 05:39:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.07	rocauc: 51.95	
[12/01 05:39:15 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.2
[12/01 05:45:33 visual_prompt]: Epoch 3 / 100: avg data time: 9.90e+00, avg batch time: 10.7808, average train loss: 0.7876
[12/01 05:46:17 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.5265, average loss: 0.6862
[12/01 05:46:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 58.19	
[12/01 05:46:17 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.3
[12/01 05:52:34 visual_prompt]: Epoch 4 / 100: avg data time: 9.92e+00, avg batch time: 10.7905, average train loss: 0.7290
[12/01 05:53:18 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.5199, average loss: 0.7010
[12/01 05:53:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.06	
[12/01 05:53:18 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.4
[12/01 05:59:38 visual_prompt]: Epoch 5 / 100: avg data time: 9.96e+00, avg batch time: 10.8411, average train loss: 0.8125
[12/01 06:00:22 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.5201, average loss: 0.7241
[12/01 06:00:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.94	
[12/01 06:00:22 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.5
[12/01 06:06:43 visual_prompt]: Epoch 6 / 100: avg data time: 1.00e+01, avg batch time: 10.8850, average train loss: 0.8284
[12/01 06:07:27 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.5210, average loss: 0.6762
[12/01 06:07:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 60.99	
[12/01 06:07:27 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.6
[12/01 06:13:46 visual_prompt]: Epoch 7 / 100: avg data time: 9.97e+00, avg batch time: 10.8457, average train loss: 0.7057
[12/01 06:14:30 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.5197, average loss: 1.4666
[12/01 06:14:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.31	
[12/01 06:14:30 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.7
[12/01 06:20:50 visual_prompt]: Epoch 8 / 100: avg data time: 9.96e+00, avg batch time: 10.8388, average train loss: 0.9079
[12/01 06:21:34 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.5202, average loss: 0.6768
[12/01 06:21:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 61.13	
[12/01 06:21:34 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.8
[12/01 06:27:56 visual_prompt]: Epoch 9 / 100: avg data time: 1.00e+01, avg batch time: 10.9035, average train loss: 0.8885
[12/01 06:28:40 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.5249, average loss: 0.6916
[12/01 06:28:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 52.44	rocauc: 60.59	
[12/01 06:28:40 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.9
[12/01 06:35:00 visual_prompt]: Epoch 10 / 100: avg data time: 9.98e+00, avg batch time: 10.8558, average train loss: 0.7908
[12/01 06:35:44 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.5189, average loss: 0.7353
[12/01 06:35:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 49.19	rocauc: 60.24	
[12/01 06:35:44 visual_prompt]: Training 11 / 100 epoch, with learning rate 1.0
[12/01 06:42:02 visual_prompt]: Epoch 11 / 100: avg data time: 9.93e+00, avg batch time: 10.8087, average train loss: 0.8163
[12/01 06:42:46 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.5307, average loss: 0.9303
[12/01 06:42:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.95	
[12/01 06:42:46 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.9996954135095479
[12/01 06:49:07 visual_prompt]: Epoch 12 / 100: avg data time: 1.00e+01, avg batch time: 10.8806, average train loss: 0.7214
[12/01 06:49:51 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.5302, average loss: 0.9696
[12/01 06:49:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 64.13	
[12/01 06:49:51 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.9987820251299121
[12/01 06:56:10 visual_prompt]: Epoch 13 / 100: avg data time: 9.94e+00, avg batch time: 10.8204, average train loss: 0.8989
[12/01 06:56:54 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.5183, average loss: 0.8084
[12/01 06:56:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 64.80	
[12/01 06:56:54 visual_prompt]: Best epoch 13: best metric: -0.808
[12/01 06:56:54 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.9972609476841366
[12/01 07:03:14 visual_prompt]: Epoch 14 / 100: avg data time: 9.99e+00, avg batch time: 10.8644, average train loss: 0.9532
[12/01 07:03:58 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.5317, average loss: 1.9877
[12/01 07:03:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 65.26	
[12/01 07:03:58 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.9951340343707852
[12/01 07:10:18 visual_prompt]: Epoch 15 / 100: avg data time: 9.98e+00, avg batch time: 10.8539, average train loss: 1.4786
[12/01 07:11:02 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.5218, average loss: 1.0999
[12/01 07:11:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 65.60	
[12/01 07:11:02 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.9924038765061041
[12/01 07:17:23 visual_prompt]: Epoch 16 / 100: avg data time: 9.99e+00, avg batch time: 10.8703, average train loss: 0.9565
[12/01 07:18:07 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.5214, average loss: 0.8753
[12/01 07:18:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.50	
[12/01 07:18:07 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.9890738003669028
[12/01 07:24:27 visual_prompt]: Epoch 17 / 100: avg data time: 9.96e+00, avg batch time: 10.8442, average train loss: 0.8613
[12/01 07:25:11 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.5192, average loss: 1.2170
[12/01 07:25:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 66.48	
[12/01 07:25:11 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.9851478631379982
[12/01 07:31:34 visual_prompt]: Epoch 18 / 100: avg data time: 1.01e+01, avg batch time: 10.9431, average train loss: 0.8424
[12/01 07:32:18 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.5268, average loss: 0.6535
[12/01 07:32:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 65.88	
[12/01 07:32:18 visual_prompt]: Best epoch 18: best metric: -0.653
[12/01 07:32:18 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.9806308479691594
[12/01 07:38:39 visual_prompt]: Epoch 19 / 100: avg data time: 1.00e+01, avg batch time: 10.8751, average train loss: 0.7048
[12/01 07:39:23 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.5296, average loss: 0.6751
[12/01 07:39:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.54	rocauc: 65.64	
[12/01 07:39:23 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.9755282581475768
[12/01 07:45:43 visual_prompt]: Epoch 20 / 100: avg data time: 9.96e+00, avg batch time: 10.8460, average train loss: 0.6753
[12/01 07:46:27 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.5199, average loss: 0.6346
[12/01 07:46:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 69.92	rocauc: 73.54	
[12/01 07:46:27 visual_prompt]: Best epoch 20: best metric: -0.635
[12/01 07:46:27 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.9698463103929542
[12/01 07:52:47 visual_prompt]: Epoch 21 / 100: avg data time: 9.98e+00, avg batch time: 10.8621, average train loss: 0.7380
[12/01 07:53:31 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.5287, average loss: 0.6622
[12/01 07:53:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 69.19	
[12/01 07:53:31 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.9635919272833937
[12/01 07:59:51 visual_prompt]: Epoch 22 / 100: avg data time: 9.99e+00, avg batch time: 10.8670, average train loss: 0.9098
[12/01 08:00:35 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.5165, average loss: 0.6395
[12/01 08:00:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 71.22	
[12/01 08:00:35 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.9567727288213004
[12/01 08:06:54 visual_prompt]: Epoch 23 / 100: avg data time: 9.93e+00, avg batch time: 10.8088, average train loss: 0.7086
[12/01 08:07:38 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.5225, average loss: 0.6266
[12/01 08:07:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 70.67	
[12/01 08:07:38 visual_prompt]: Best epoch 23: best metric: -0.627
[12/01 08:07:38 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.9493970231495835
[12/01 08:13:58 visual_prompt]: Epoch 24 / 100: avg data time: 1.00e+01, avg batch time: 10.8785, average train loss: 0.8221
[12/01 08:14:43 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.5201, average loss: 0.6440
[12/01 08:14:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.01	rocauc: 72.82	
[12/01 08:14:43 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.9414737964294635
[12/01 08:21:03 visual_prompt]: Epoch 25 / 100: avg data time: 9.99e+00, avg batch time: 10.8700, average train loss: 0.6570
[12/01 08:21:49 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.5269, average loss: 0.6079
[12/01 08:21:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.07	rocauc: 73.53	
[12/01 08:21:49 visual_prompt]: Best epoch 25: best metric: -0.608
[12/01 08:21:49 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.9330127018922194
[12/01 08:28:34 visual_prompt]: Epoch 26 / 100: avg data time: 1.07e+01, avg batch time: 11.5711, average train loss: 0.6918
[12/01 08:29:19 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.5179, average loss: 0.7877
[12/01 08:29:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 72.77	
[12/01 08:29:19 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.9240240480782129
[12/01 08:35:38 visual_prompt]: Epoch 27 / 100: avg data time: 9.94e+00, avg batch time: 10.8250, average train loss: 0.6656
[12/01 08:36:22 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.5202, average loss: 0.6794
[12/01 08:36:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 72.43	
[12/01 08:36:22 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.9145187862775208
[12/01 08:42:39 visual_prompt]: Epoch 28 / 100: avg data time: 9.88e+00, avg batch time: 10.7621, average train loss: 0.7083
[12/01 08:43:23 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.5196, average loss: 0.7694
[12/01 08:43:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 70.57	
[12/01 08:43:23 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.9045084971874737
[12/01 08:49:42 visual_prompt]: Epoch 29 / 100: avg data time: 9.95e+00, avg batch time: 10.8257, average train loss: 0.6656
[12/01 08:50:25 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.5167, average loss: 0.5942
[12/01 08:50:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 69.51	rocauc: 75.36	
[12/01 08:50:25 visual_prompt]: Best epoch 29: best metric: -0.594
[12/01 08:50:25 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.8940053768033609
[12/01 08:56:43 visual_prompt]: Epoch 30 / 100: avg data time: 9.92e+00, avg batch time: 10.7951, average train loss: 0.6202
[12/01 08:57:27 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.5177, average loss: 0.6069
[12/01 08:57:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 70.33	rocauc: 73.55	
[12/01 08:57:27 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.883022221559489
[12/01 09:03:47 visual_prompt]: Epoch 31 / 100: avg data time: 9.98e+00, avg batch time: 10.8592, average train loss: 0.6091
[12/01 09:04:32 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.5229, average loss: 0.6375
[12/01 09:04:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 74.70	
[12/01 09:04:32 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.8715724127386971
[12/01 09:10:53 visual_prompt]: Epoch 32 / 100: avg data time: 1.00e+01, avg batch time: 10.8927, average train loss: 0.6301
[12/01 09:11:37 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.5177, average loss: 0.6098
[12/01 09:11:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.67	rocauc: 75.68	
[12/01 09:11:37 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.8596699001693255
[12/01 09:17:58 visual_prompt]: Epoch 33 / 100: avg data time: 1.00e+01, avg batch time: 10.8731, average train loss: 0.6265
[12/01 09:18:42 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.5152, average loss: 0.6121
[12/01 09:18:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.67	rocauc: 73.58	
[12/01 09:18:42 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.8473291852294986
[12/01 09:25:02 visual_prompt]: Epoch 34 / 100: avg data time: 9.98e+00, avg batch time: 10.8522, average train loss: 0.6056
[12/01 09:25:46 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.5208, average loss: 0.6046
[12/01 09:25:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 70.73	rocauc: 73.73	
[12/01 09:25:46 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.8345653031794291
[12/01 09:32:06 visual_prompt]: Epoch 35 / 100: avg data time: 9.99e+00, avg batch time: 10.8686, average train loss: 0.6071
[12/01 09:32:50 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.5192, average loss: 0.6745
[12/01 09:32:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 73.35	
[12/01 09:32:50 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.8213938048432696
[12/01 09:39:08 visual_prompt]: Epoch 36 / 100: avg data time: 9.91e+00, avg batch time: 10.7830, average train loss: 0.6337
[12/01 09:39:51 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.5221, average loss: 0.6777
[12/01 09:39:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 73.10	
[12/01 09:39:51 visual_prompt]: Stopping early.
[12/01 09:39:51 visual_prompt]: Rank of current process: 0. World size: 1
[12/01 09:39:51 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA TITAN Xp
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[12/01 09:39:51 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss', 'RECORD_GPU_SNAPSHOT', 'True'])
[12/01 09:39:51 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[12/01 09:39:51 visual_prompt]: Training with config:
[12/01 09:39:51 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr1.0_wd0.0/patience7/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 1.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True}), 'RECORD_GPU_SNAPSHOT': True})
[12/01 09:39:51 visual_prompt]: Loading training data...
[12/01 09:39:51 visual_prompt]: Constructing mammo-cbis dataset train...
[12/01 09:39:51 visual_prompt]: Loading validation data...
[12/01 09:39:51 visual_prompt]: Constructing mammo-cbis dataset val...
[12/01 09:39:51 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[12/01 09:39:58 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[12/01 09:39:58 visual_prompt]: tuned percent:0.536
[12/01 09:39:58 visual_prompt]: Device used for model: 0
[12/01 09:39:58 visual_prompt]: Setting up Evaluator...
[12/01 09:39:58 visual_prompt]: Setting up Trainer...
[12/01 09:39:58 visual_prompt]: 	Setting up the optimizer...
[12/01 09:39:58 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[12/01 09:46:19 visual_prompt]: Epoch 1 / 100: avg data time: 1.00e+01, avg batch time: 10.8949, average train loss: 1.4006
[12/01 09:47:02 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.5234, average loss: 1.2969
[12/01 09:47:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[12/01 09:47:02 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.1
[12/01 09:53:32 visual_prompt]: Epoch 2 / 100: avg data time: 1.03e+01, avg batch time: 11.1378, average train loss: 2.2326
[12/01 09:54:18 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.5201, average loss: 0.6879
[12/01 09:54:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.07	rocauc: 52.27	
[12/01 09:54:18 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.2
[12/01 10:00:53 visual_prompt]: Epoch 3 / 100: avg data time: 1.04e+01, avg batch time: 11.2613, average train loss: 0.7887
[12/01 10:01:39 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.5191, average loss: 0.6878
[12/01 10:01:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.67	
[12/01 10:01:39 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.3
[12/01 10:08:08 visual_prompt]: Epoch 4 / 100: avg data time: 1.02e+01, avg batch time: 11.1093, average train loss: 0.7299
[12/01 10:08:53 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.5226, average loss: 0.7012
[12/01 10:08:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.51	
[12/01 10:08:53 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.4
[12/01 10:15:27 visual_prompt]: Epoch 5 / 100: avg data time: 1.04e+01, avg batch time: 11.2561, average train loss: 0.8018
[12/01 10:16:13 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.5266, average loss: 0.7035
[12/01 10:16:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 47.15	rocauc: 59.06	
[12/01 10:16:13 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.5
[12/01 10:22:45 visual_prompt]: Epoch 6 / 100: avg data time: 1.03e+01, avg batch time: 11.2130, average train loss: 0.8506
[12/01 10:23:31 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.5172, average loss: 0.6777
[12/01 10:23:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 58.51	
[12/01 10:23:31 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.6
[12/01 10:30:06 visual_prompt]: Epoch 7 / 100: avg data time: 1.04e+01, avg batch time: 11.2758, average train loss: 0.7054
[12/01 10:30:52 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.5201, average loss: 1.5080
[12/01 10:30:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.55	
[12/01 10:30:52 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.7
[12/01 10:37:29 visual_prompt]: Epoch 8 / 100: avg data time: 1.05e+01, avg batch time: 11.3447, average train loss: 0.9132
[12/01 10:38:15 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.5171, average loss: 0.6750
[12/01 10:38:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 59.91	
[12/01 10:38:15 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.8
[12/01 10:44:41 visual_prompt]: Epoch 9 / 100: avg data time: 1.02e+01, avg batch time: 11.0221, average train loss: 0.8940
[12/01 10:45:25 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.5201, average loss: 0.7035
[12/01 10:45:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 49.59	rocauc: 60.51	
[12/01 10:45:25 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.9
[12/01 10:51:44 visual_prompt]: Epoch 10 / 100: avg data time: 9.95e+00, avg batch time: 10.8221, average train loss: 0.8085
[12/01 10:52:27 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.5280, average loss: 0.7392
[12/01 10:52:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 47.56	rocauc: 60.27	
[12/01 10:52:27 visual_prompt]: Training 11 / 100 epoch, with learning rate 1.0
[12/01 10:58:45 visual_prompt]: Epoch 11 / 100: avg data time: 9.92e+00, avg batch time: 10.7941, average train loss: 0.8412
[12/01 10:59:29 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.5197, average loss: 0.9663
[12/01 10:59:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.34	
[12/01 10:59:29 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.9996954135095479
[12/01 11:05:47 visual_prompt]: Epoch 12 / 100: avg data time: 9.93e+00, avg batch time: 10.8051, average train loss: 0.7254
[12/01 11:06:31 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.5134, average loss: 1.0173
[12/01 11:06:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 64.52	
[12/01 11:06:31 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.9987820251299121
[12/01 11:12:48 visual_prompt]: Epoch 13 / 100: avg data time: 9.89e+00, avg batch time: 10.7582, average train loss: 0.9835
[12/01 11:13:31 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.5142, average loss: 0.6822
[12/01 11:13:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 63.78	
[12/01 11:13:31 visual_prompt]: Best epoch 13: best metric: -0.682
[12/01 11:13:31 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.9972609476841366
[12/01 11:19:47 visual_prompt]: Epoch 14 / 100: avg data time: 9.85e+00, avg batch time: 10.7213, average train loss: 0.8652
[12/01 11:20:30 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.5150, average loss: 1.1285
[12/01 11:20:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 64.57	
[12/01 11:20:30 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.9951340343707852
[12/01 11:26:46 visual_prompt]: Epoch 15 / 100: avg data time: 9.87e+00, avg batch time: 10.7394, average train loss: 0.8781
[12/01 11:27:30 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.5261, average loss: 0.8684
[12/01 11:27:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 65.73	
[12/01 11:27:30 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.9924038765061041
[12/01 11:33:46 visual_prompt]: Epoch 16 / 100: avg data time: 9.89e+00, avg batch time: 10.7612, average train loss: 0.8644
[12/01 11:34:30 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.5177, average loss: 0.8879
[12/01 11:34:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 66.32	
[12/01 11:34:30 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.9890738003669028
[12/01 11:40:45 visual_prompt]: Epoch 17 / 100: avg data time: 9.85e+00, avg batch time: 10.7253, average train loss: 0.8003
[12/01 11:41:29 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.5224, average loss: 1.4857
[12/01 11:41:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 68.15	
[12/01 11:41:29 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.9851478631379982
[12/01 11:47:47 visual_prompt]: Epoch 18 / 100: avg data time: 9.93e+00, avg batch time: 10.7977, average train loss: 0.8189
[12/01 11:48:31 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.5217, average loss: 0.6704
[12/01 11:48:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 67.79	
[12/01 11:48:31 visual_prompt]: Best epoch 18: best metric: -0.670
[12/01 11:48:31 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.9806308479691594
[12/01 11:54:49 visual_prompt]: Epoch 19 / 100: avg data time: 9.93e+00, avg batch time: 10.8013, average train loss: 0.7070
[12/01 11:55:32 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.5249, average loss: 0.6454
[12/01 11:55:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 68.80	
[12/01 11:55:32 visual_prompt]: Best epoch 19: best metric: -0.645
[12/01 11:55:32 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.9755282581475768
[12/01 12:01:56 visual_prompt]: Epoch 20 / 100: avg data time: 1.01e+01, avg batch time: 10.9450, average train loss: 0.6882
[12/01 12:02:42 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.5220, average loss: 0.6081
[12/01 12:02:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 68.70	rocauc: 74.72	
[12/01 12:02:42 visual_prompt]: Best epoch 20: best metric: -0.608
[12/01 12:02:42 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.9698463103929542
[12/01 12:09:25 visual_prompt]: Epoch 21 / 100: avg data time: 1.06e+01, avg batch time: 11.5130, average train loss: 0.7393
[12/01 12:10:09 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.5193, average loss: 0.6143
[12/01 12:10:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 69.92	rocauc: 72.58	
[12/01 12:10:09 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.9635919272833937
[12/01 12:16:29 visual_prompt]: Epoch 22 / 100: avg data time: 1.00e+01, avg batch time: 10.8728, average train loss: 0.9749
[12/01 12:17:17 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.5203, average loss: 0.6402
[12/01 12:17:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.01	rocauc: 71.45	
[12/01 12:17:17 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.9567727288213004
[12/01 12:23:54 visual_prompt]: Epoch 23 / 100: avg data time: 1.05e+01, avg batch time: 11.3552, average train loss: 0.7033
[12/01 12:24:41 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.5228, average loss: 0.6250
[12/01 12:24:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 71.63	
[12/01 12:24:41 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.9493970231495835
[12/01 12:31:17 visual_prompt]: Epoch 24 / 100: avg data time: 1.04e+01, avg batch time: 11.3105, average train loss: 0.8331
[12/01 12:32:00 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.5216, average loss: 0.7592
[12/01 12:32:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 73.34	
[12/01 12:32:00 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.9414737964294635
[12/01 12:38:35 visual_prompt]: Epoch 25 / 100: avg data time: 1.04e+01, avg batch time: 11.2634, average train loss: 0.6576
[12/01 12:39:21 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.5205, average loss: 0.6961
[12/01 12:39:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 73.69	
[12/01 12:39:21 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.9330127018922194
[12/01 12:45:57 visual_prompt]: Epoch 26 / 100: avg data time: 1.04e+01, avg batch time: 11.3131, average train loss: 0.8149
[12/01 12:46:44 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.5194, average loss: 0.6360
[12/01 12:46:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 74.93	
[12/01 12:46:44 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.9240240480782129
[12/01 12:53:19 visual_prompt]: Epoch 27 / 100: avg data time: 1.04e+01, avg batch time: 11.2960, average train loss: 0.6914
[12/01 12:54:05 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.5220, average loss: 0.6106
[12/01 12:54:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 68.70	rocauc: 73.21	
[12/01 12:54:05 visual_prompt]: Stopping early.
[12/01 12:54:06 visual_prompt]: Rank of current process: 0. World size: 1
[12/01 12:54:06 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA TITAN Xp
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[12/01 12:54:06 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss', 'RECORD_GPU_SNAPSHOT', 'True'])
[12/01 12:54:06 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[12/01 12:54:06 visual_prompt]: Training with config:
[12/01 12:54:06 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr0.5_wd0.01/patience7/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True}), 'RECORD_GPU_SNAPSHOT': True})
[12/01 12:54:06 visual_prompt]: Loading training data...
[12/01 12:54:06 visual_prompt]: Constructing mammo-cbis dataset train...
[12/01 12:54:06 visual_prompt]: Loading validation data...
[12/01 12:54:06 visual_prompt]: Constructing mammo-cbis dataset val...
[12/01 12:54:06 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[12/01 12:54:09 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[12/01 12:54:09 visual_prompt]: tuned percent:0.536
[12/01 12:54:09 visual_prompt]: Device used for model: 0
[12/01 12:54:09 visual_prompt]: Setting up Evaluator...
[12/01 12:54:09 visual_prompt]: Setting up Trainer...
[12/01 12:54:09 visual_prompt]: 	Setting up the optimizer...
[12/01 12:54:09 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[12/01 13:00:41 visual_prompt]: Epoch 1 / 100: avg data time: 1.03e+01, avg batch time: 11.2074, average train loss: 1.4006
[12/01 13:01:25 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.5286, average loss: 1.2969
[12/01 13:01:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[12/01 13:01:25 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.05
[12/01 13:07:41 visual_prompt]: Epoch 2 / 100: avg data time: 9.88e+00, avg batch time: 10.7533, average train loss: 1.8132
[12/01 13:08:25 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.5250, average loss: 0.6886
[12/01 13:08:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.48	
[12/01 13:08:25 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.1
[12/01 13:14:42 visual_prompt]: Epoch 3 / 100: avg data time: 9.89e+00, avg batch time: 10.7670, average train loss: 0.7056
[12/01 13:15:25 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.5282, average loss: 0.7022
[12/01 13:15:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.76	
[12/01 13:15:25 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.15
[12/01 13:21:44 visual_prompt]: Epoch 4 / 100: avg data time: 9.92e+00, avg batch time: 10.8004, average train loss: 0.6988
[12/01 13:22:27 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.5293, average loss: 0.6887
[12/01 13:22:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.71	
[12/01 13:22:27 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.2
[12/01 13:28:43 visual_prompt]: Epoch 5 / 100: avg data time: 9.87e+00, avg batch time: 10.7471, average train loss: 0.7294
[12/01 13:29:30 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.5266, average loss: 0.7277
[12/01 13:29:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.17	
[12/01 13:29:30 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.25
[12/01 13:36:12 visual_prompt]: Epoch 6 / 100: avg data time: 1.06e+01, avg batch time: 11.4780, average train loss: 0.7441
[12/01 13:36:59 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.5312, average loss: 0.6887
[12/01 13:36:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.35	
[12/01 13:36:59 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.3
[12/01 13:43:40 visual_prompt]: Epoch 7 / 100: avg data time: 1.06e+01, avg batch time: 11.4794, average train loss: 0.7370
[12/01 13:44:27 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.5265, average loss: 0.7550
[12/01 13:44:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.29	
[12/01 13:44:27 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.35
[12/01 13:51:07 visual_prompt]: Epoch 8 / 100: avg data time: 1.05e+01, avg batch time: 11.4237, average train loss: 0.7114
[12/01 13:51:53 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.5299, average loss: 0.6908
[12/01 13:51:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.25	
[12/01 13:51:53 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.4
[12/01 13:58:30 visual_prompt]: Epoch 9 / 100: avg data time: 1.04e+01, avg batch time: 11.3228, average train loss: 0.7088
[12/01 13:59:13 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.5303, average loss: 0.7090
[12/01 13:59:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.90	
[12/01 13:59:13 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.45
[12/01 14:05:32 visual_prompt]: Epoch 10 / 100: avg data time: 9.94e+00, avg batch time: 10.8209, average train loss: 0.8441
[12/01 14:06:16 visual_prompt]: Inference (val):avg data time: 2.05e-05, avg batch time: 0.5274, average loss: 0.7827
[12/01 14:06:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 61.82	
[12/01 14:06:16 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.5
[12/01 14:12:35 visual_prompt]: Epoch 11 / 100: avg data time: 9.95e+00, avg batch time: 10.8329, average train loss: 0.7514
[12/01 14:13:19 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.5307, average loss: 0.6911
[12/01 14:13:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.24	
[12/01 14:13:19 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.49984770675477397
[12/01 14:19:38 visual_prompt]: Epoch 12 / 100: avg data time: 9.93e+00, avg batch time: 10.8097, average train loss: 0.7088
[12/01 14:20:21 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.5286, average loss: 0.7275
[12/01 14:20:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.84	
[12/01 14:20:21 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.49939101256495605
[12/01 14:26:41 visual_prompt]: Epoch 13 / 100: avg data time: 9.97e+00, avg batch time: 10.8515, average train loss: 0.7274
[12/01 14:27:29 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.5284, average loss: 0.7023
[12/01 14:27:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.74	
[12/01 14:27:29 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.4986304738420683
[12/01 14:34:11 visual_prompt]: Epoch 14 / 100: avg data time: 1.06e+01, avg batch time: 11.4679, average train loss: 0.7393
[12/01 14:34:55 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.5367, average loss: 0.7596
[12/01 14:34:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.88	
[12/01 14:34:55 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.4975670171853926
[12/01 14:41:16 visual_prompt]: Epoch 15 / 100: avg data time: 1.00e+01, avg batch time: 10.8883, average train loss: 0.7481
[12/01 14:42:00 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.5331, average loss: 0.7060
[12/01 14:42:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.96	
[12/01 14:42:00 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.49620193825305203
[12/01 14:48:20 visual_prompt]: Epoch 16 / 100: avg data time: 9.96e+00, avg batch time: 10.8422, average train loss: 0.7025
[12/01 14:49:04 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.5261, average loss: 0.8708
[12/01 14:49:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.88	
[12/01 14:49:04 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.4945369001834514
[12/01 14:55:21 visual_prompt]: Epoch 17 / 100: avg data time: 9.90e+00, avg batch time: 10.7811, average train loss: 0.7429
[12/01 14:56:05 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.5303, average loss: 0.6952
[12/01 14:56:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.85	
[12/01 14:56:05 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.4925739315689991
[12/01 15:02:22 visual_prompt]: Epoch 18 / 100: avg data time: 9.89e+00, avg batch time: 10.7661, average train loss: 0.7264
[12/01 15:03:05 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.5307, average loss: 0.6891
[12/01 15:03:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.88	
[12/01 15:03:05 visual_prompt]: Best epoch 18: best metric: -0.689
[12/01 15:03:05 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.4903154239845797
[12/01 15:09:21 visual_prompt]: Epoch 19 / 100: avg data time: 9.86e+00, avg batch time: 10.7409, average train loss: 0.7082
[12/01 15:10:05 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.5288, average loss: 0.6977
[12/01 15:10:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.20	
[12/01 15:10:05 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.4877641290737884
[12/01 15:16:24 visual_prompt]: Epoch 20 / 100: avg data time: 9.96e+00, avg batch time: 10.8398, average train loss: 0.6969
[12/01 15:17:08 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.5340, average loss: 0.8146
[12/01 15:17:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.44	
[12/01 15:17:08 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.4849231551964771
[12/01 15:23:25 visual_prompt]: Epoch 21 / 100: avg data time: 9.89e+00, avg batch time: 10.7704, average train loss: 0.7062
[12/01 15:24:09 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.5285, average loss: 0.7045
[12/01 15:24:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.37	
[12/01 15:24:09 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.48179596364169686
[12/01 15:30:26 visual_prompt]: Epoch 22 / 100: avg data time: 9.88e+00, avg batch time: 10.7583, average train loss: 0.7440
[12/01 15:31:09 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.5353, average loss: 0.7014
[12/01 15:31:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.18	
[12/01 15:31:09 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.4783863644106502
[12/01 15:37:26 visual_prompt]: Epoch 23 / 100: avg data time: 9.88e+00, avg batch time: 10.7596, average train loss: 0.7189
[12/01 15:38:10 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.5374, average loss: 0.7331
[12/01 15:38:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.25	
[12/01 15:38:10 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.47469851157479176
[12/01 15:44:27 visual_prompt]: Epoch 24 / 100: avg data time: 9.89e+00, avg batch time: 10.7714, average train loss: 0.7421
[12/01 15:45:10 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.5296, average loss: 0.6885
[12/01 15:45:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.05	
[12/01 15:45:10 visual_prompt]: Best epoch 24: best metric: -0.688
[12/01 15:45:10 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.47073689821473175
[12/01 15:51:27 visual_prompt]: Epoch 25 / 100: avg data time: 9.88e+00, avg batch time: 10.7511, average train loss: 0.7102
[12/01 15:52:10 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.5393, average loss: 0.6929
[12/01 15:52:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 38.42	
[12/01 15:52:10 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.4665063509461097
[12/01 15:58:27 visual_prompt]: Epoch 26 / 100: avg data time: 9.88e+00, avg batch time: 10.7633, average train loss: 0.7204
[12/01 15:59:11 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.5227, average loss: 0.7149
[12/01 15:59:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.00	
[12/01 15:59:11 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.46201202403910646
[12/01 16:05:29 visual_prompt]: Epoch 27 / 100: avg data time: 9.92e+00, avg batch time: 10.7952, average train loss: 0.7196
[12/01 16:06:13 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.5281, average loss: 0.8172
[12/01 16:06:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 45.17	
[12/01 16:06:13 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.4572593931387604
[12/01 16:12:31 visual_prompt]: Epoch 28 / 100: avg data time: 9.93e+00, avg batch time: 10.8103, average train loss: 0.7321
[12/01 16:13:15 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.5306, average loss: 0.6883
[12/01 16:13:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.79	
[12/01 16:13:15 visual_prompt]: Best epoch 28: best metric: -0.688
[12/01 16:13:15 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.45225424859373686
[12/01 16:19:34 visual_prompt]: Epoch 29 / 100: avg data time: 9.95e+00, avg batch time: 10.8295, average train loss: 0.7004
[12/01 16:20:18 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.5305, average loss: 0.6886
[12/01 16:20:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 41.15	
[12/01 16:20:18 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.44700268840168045
[12/01 16:26:39 visual_prompt]: Epoch 30 / 100: avg data time: 1.00e+01, avg batch time: 10.8767, average train loss: 0.7130
[12/01 16:27:23 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.5287, average loss: 0.6936
[12/01 16:27:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.43	
[12/01 16:27:23 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.4415111107797445
[12/01 16:33:40 visual_prompt]: Epoch 31 / 100: avg data time: 9.87e+00, avg batch time: 10.7577, average train loss: 0.7045
[12/01 16:34:24 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.5341, average loss: 0.7386
[12/01 16:34:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.54	
[12/01 16:34:24 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.43578620636934856
[12/01 16:41:27 visual_prompt]: Epoch 32 / 100: avg data time: 1.12e+01, avg batch time: 12.0934, average train loss: 0.7272
[12/01 16:42:37 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.5226, average loss: 0.6996
[12/01 16:42:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.32	
[12/01 16:42:37 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.42983495008466277
[12/01 16:51:40 visual_prompt]: Epoch 33 / 100: avg data time: 1.46e+01, avg batch time: 15.5138, average train loss: 0.6971
[12/01 16:52:25 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.5326, average loss: 0.6938
[12/01 16:52:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.43	
[12/01 16:52:25 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.4236645926147493
[12/01 16:59:42 visual_prompt]: Epoch 34 / 100: avg data time: 1.16e+01, avg batch time: 12.4736, average train loss: 0.7066
[12/01 17:00:50 visual_prompt]: Inference (val):avg data time: 1.88e-05, avg batch time: 0.5257, average loss: 0.6884
[12/01 17:00:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.80	
[12/01 17:00:50 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.41728265158971456
[12/01 17:08:17 visual_prompt]: Epoch 35 / 100: avg data time: 1.19e+01, avg batch time: 12.7711, average train loss: 0.7117
[12/01 17:09:01 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.5276, average loss: 0.7209
[12/01 17:09:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.43	
[12/01 17:09:01 visual_prompt]: Stopping early.
[12/01 17:09:01 visual_prompt]: Rank of current process: 0. World size: 1
[12/01 17:09:01 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA TITAN Xp
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[12/01 17:09:01 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss', 'RECORD_GPU_SNAPSHOT', 'True'])
[12/01 17:09:01 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[12/01 17:09:01 visual_prompt]: Training with config:
[12/01 17:09:01 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr0.5_wd0.001/patience7/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True}), 'RECORD_GPU_SNAPSHOT': True})
[12/01 17:09:01 visual_prompt]: Loading training data...
[12/01 17:09:01 visual_prompt]: Constructing mammo-cbis dataset train...
[12/01 17:09:01 visual_prompt]: Loading validation data...
[12/01 17:09:01 visual_prompt]: Constructing mammo-cbis dataset val...
[12/01 17:09:01 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[12/01 17:09:16 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[12/01 17:09:16 visual_prompt]: tuned percent:0.536
[12/01 17:09:16 visual_prompt]: Device used for model: 0
[12/01 17:09:16 visual_prompt]: Setting up Evaluator...
[12/01 17:09:16 visual_prompt]: Setting up Trainer...
[12/01 17:09:16 visual_prompt]: 	Setting up the optimizer...
[12/01 17:09:16 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[12/01 17:15:36 visual_prompt]: Epoch 1 / 100: avg data time: 9.97e+00, avg batch time: 10.8543, average train loss: 1.4006
[12/01 17:16:20 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.5339, average loss: 1.2969
[12/01 17:16:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[12/01 17:16:20 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.05
[12/01 17:22:40 visual_prompt]: Epoch 2 / 100: avg data time: 9.97e+00, avg batch time: 10.8558, average train loss: 1.8299
[12/01 17:23:24 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.5367, average loss: 0.6888
[12/01 17:23:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.56	
[12/01 17:23:24 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.1
[12/01 17:29:42 visual_prompt]: Epoch 3 / 100: avg data time: 9.92e+00, avg batch time: 10.8060, average train loss: 0.7137
[12/01 17:30:26 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.5326, average loss: 0.7050
[12/01 17:30:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.78	
[12/01 17:30:26 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.15
[12/01 17:36:45 visual_prompt]: Epoch 4 / 100: avg data time: 9.93e+00, avg batch time: 10.8127, average train loss: 0.7117
[12/01 17:37:28 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.5340, average loss: 0.6869
[12/01 17:37:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.53	
[12/01 17:37:28 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.2
[12/01 17:43:46 visual_prompt]: Epoch 5 / 100: avg data time: 9.90e+00, avg batch time: 10.7761, average train loss: 0.7440
[12/01 17:44:30 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.5358, average loss: 0.8135
[12/01 17:44:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.53	
[12/01 17:44:30 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.25
[12/01 17:50:49 visual_prompt]: Epoch 6 / 100: avg data time: 9.95e+00, avg batch time: 10.8264, average train loss: 0.7520
[12/01 17:51:32 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.5340, average loss: 0.7138
[12/01 17:51:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.63	
[12/01 17:51:32 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.3
[12/01 17:57:50 visual_prompt]: Epoch 7 / 100: avg data time: 9.90e+00, avg batch time: 10.7759, average train loss: 0.7714
[12/01 17:58:33 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.5323, average loss: 0.7137
[12/01 17:58:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 44.72	rocauc: 57.41	
[12/01 17:58:33 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.35
[12/01 18:04:50 visual_prompt]: Epoch 8 / 100: avg data time: 9.87e+00, avg batch time: 10.7525, average train loss: 0.7598
[12/01 18:05:33 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.5289, average loss: 0.6865
[12/01 18:05:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 57.62	
[12/01 18:05:33 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.4
[12/01 18:11:51 visual_prompt]: Epoch 9 / 100: avg data time: 9.90e+00, avg batch time: 10.7781, average train loss: 0.7428
[12/01 18:12:35 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.5356, average loss: 0.7583
[12/01 18:12:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.99	
[12/01 18:12:35 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.45
[12/01 18:18:52 visual_prompt]: Epoch 10 / 100: avg data time: 9.89e+00, avg batch time: 10.7686, average train loss: 0.6970
[12/01 18:19:35 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.5298, average loss: 0.7928
[12/01 18:19:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.90	
[12/01 18:19:35 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.5
[12/01 18:25:52 visual_prompt]: Epoch 11 / 100: avg data time: 9.86e+00, avg batch time: 10.7485, average train loss: 0.7586
[12/01 18:26:35 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.5250, average loss: 0.7083
[12/01 18:26:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 48.78	rocauc: 61.30	
[12/01 18:26:35 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.49984770675477397
[12/01 18:32:52 visual_prompt]: Epoch 12 / 100: avg data time: 9.89e+00, avg batch time: 10.7718, average train loss: 0.7263
[12/01 18:33:36 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.5293, average loss: 0.7739
[12/01 18:33:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 63.86	
[12/01 18:33:36 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.49939101256495605
[12/01 18:39:53 visual_prompt]: Epoch 13 / 100: avg data time: 9.89e+00, avg batch time: 10.7706, average train loss: 0.7413
[12/01 18:40:37 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.5300, average loss: 0.6853
[12/01 18:40:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 64.12	
[12/01 18:40:37 visual_prompt]: Best epoch 13: best metric: -0.685
[12/01 18:40:37 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.4986304738420683
[12/01 18:46:53 visual_prompt]: Epoch 14 / 100: avg data time: 9.86e+00, avg batch time: 10.7452, average train loss: 0.7319
[12/01 18:47:37 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.5313, average loss: 0.7726
[12/01 18:47:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 66.92	
[12/01 18:47:37 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.4975670171853926
[12/01 18:53:54 visual_prompt]: Epoch 15 / 100: avg data time: 9.90e+00, avg batch time: 10.7902, average train loss: 0.7212
[12/01 18:54:38 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.5358, average loss: 0.7313
[12/01 18:54:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 65.10	
[12/01 18:54:38 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.49620193825305203
[12/01 19:00:55 visual_prompt]: Epoch 16 / 100: avg data time: 9.88e+00, avg batch time: 10.7633, average train loss: 0.6909
[12/01 19:01:39 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.5259, average loss: 0.8936
[12/01 19:01:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 64.56	
[12/01 19:01:39 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.4945369001834514
[12/01 19:07:54 visual_prompt]: Epoch 17 / 100: avg data time: 9.85e+00, avg batch time: 10.7321, average train loss: 0.7803
[12/01 19:08:38 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.5363, average loss: 0.6839
[12/01 19:08:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 67.10	
[12/01 19:08:38 visual_prompt]: Best epoch 17: best metric: -0.684
[12/01 19:08:38 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.4925739315689991
[12/01 19:14:56 visual_prompt]: Epoch 18 / 100: avg data time: 9.92e+00, avg batch time: 10.7989, average train loss: 0.7145
[12/01 19:15:40 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.5332, average loss: 0.7380
[12/01 19:15:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 65.76	
[12/01 19:15:40 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.4903154239845797
[12/01 19:22:00 visual_prompt]: Epoch 19 / 100: avg data time: 9.97e+00, avg batch time: 10.8520, average train loss: 0.6734
[12/01 19:22:44 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.5313, average loss: 0.6884
[12/01 19:22:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.54	
[12/01 19:22:44 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.4877641290737884
[12/01 19:29:04 visual_prompt]: Epoch 20 / 100: avg data time: 9.98e+00, avg batch time: 10.8606, average train loss: 0.7104
[12/01 19:29:49 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.5294, average loss: 0.7874
[12/01 19:29:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 62.95	
[12/01 19:29:49 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.4849231551964771
[12/01 19:36:09 visual_prompt]: Epoch 21 / 100: avg data time: 9.98e+00, avg batch time: 10.8609, average train loss: 0.7008
[12/01 19:36:52 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.5334, average loss: 0.6816
[12/01 19:36:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.23	
[12/01 19:36:53 visual_prompt]: Best epoch 21: best metric: -0.682
[12/01 19:36:53 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.48179596364169686
[12/01 19:43:09 visual_prompt]: Epoch 22 / 100: avg data time: 9.87e+00, avg batch time: 10.7512, average train loss: 0.7028
[12/01 19:43:53 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.5271, average loss: 0.6707
[12/01 19:43:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 62.88	
[12/01 19:43:53 visual_prompt]: Best epoch 22: best metric: -0.671
[12/01 19:43:53 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.4783863644106502
[12/01 19:50:09 visual_prompt]: Epoch 23 / 100: avg data time: 9.88e+00, avg batch time: 10.7589, average train loss: 0.7001
[12/01 19:50:53 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.5271, average loss: 0.6852
[12/01 19:50:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.49	
[12/01 19:50:53 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.47469851157479176
[12/01 19:57:10 visual_prompt]: Epoch 24 / 100: avg data time: 9.88e+00, avg batch time: 10.7666, average train loss: 0.7294
[12/01 19:57:54 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.5297, average loss: 0.6821
[12/01 19:57:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.46	
[12/01 19:57:54 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.47073689821473175
[12/01 20:04:11 visual_prompt]: Epoch 25 / 100: avg data time: 9.90e+00, avg batch time: 10.7815, average train loss: 0.6934
[12/01 20:04:55 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.5351, average loss: 0.6851
[12/01 20:04:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.54	rocauc: 64.00	
[12/01 20:04:55 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.4665063509461097
[12/01 20:11:11 visual_prompt]: Epoch 26 / 100: avg data time: 9.87e+00, avg batch time: 10.7508, average train loss: 0.7215
[12/01 20:11:55 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.5351, average loss: 0.7359
[12/01 20:11:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.72	
[12/01 20:11:55 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.46201202403910646
[12/01 20:18:12 visual_prompt]: Epoch 27 / 100: avg data time: 9.88e+00, avg batch time: 10.7604, average train loss: 0.7167
[12/01 20:18:55 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.5318, average loss: 0.7708
[12/01 20:18:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.77	
[12/01 20:18:55 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.4572593931387604
[12/01 20:25:12 visual_prompt]: Epoch 28 / 100: avg data time: 9.86e+00, avg batch time: 10.7481, average train loss: 0.7255
[12/01 20:25:55 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.5276, average loss: 0.7188
[12/01 20:25:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.05	
[12/01 20:25:55 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.45225424859373686
[12/01 20:32:13 visual_prompt]: Epoch 29 / 100: avg data time: 9.90e+00, avg batch time: 10.7791, average train loss: 0.7040
[12/01 20:32:57 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.5278, average loss: 0.6921
[12/01 20:32:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.63	
[12/01 20:32:57 visual_prompt]: Stopping early.
[12/01 20:32:57 visual_prompt]: Rank of current process: 0. World size: 1
[12/01 20:32:57 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA TITAN Xp
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[12/01 20:32:57 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss', 'RECORD_GPU_SNAPSHOT', 'True'])
[12/01 20:32:57 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[12/01 20:32:57 visual_prompt]: Training with config:
[12/01 20:32:57 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr0.5_wd0.0001/patience7/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True}), 'RECORD_GPU_SNAPSHOT': True})
[12/01 20:32:57 visual_prompt]: Loading training data...
[12/01 20:32:57 visual_prompt]: Constructing mammo-cbis dataset train...
[12/01 20:32:58 visual_prompt]: Loading validation data...
[12/01 20:32:58 visual_prompt]: Constructing mammo-cbis dataset val...
[12/01 20:32:58 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[12/01 20:33:00 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[12/01 20:33:00 visual_prompt]: tuned percent:0.536
[12/01 20:33:00 visual_prompt]: Device used for model: 0
[12/01 20:33:00 visual_prompt]: Setting up Evaluator...
[12/01 20:33:00 visual_prompt]: Setting up Trainer...
[12/01 20:33:00 visual_prompt]: 	Setting up the optimizer...
[12/01 20:33:00 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[12/01 20:39:18 visual_prompt]: Epoch 1 / 100: avg data time: 9.90e+00, avg batch time: 10.7881, average train loss: 1.4006
[12/01 20:40:02 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.5381, average loss: 1.2969
[12/01 20:40:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[12/01 20:40:02 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.05
[12/01 20:46:18 visual_prompt]: Epoch 2 / 100: avg data time: 9.88e+00, avg batch time: 10.7606, average train loss: 1.8312
[12/01 20:47:02 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.5224, average loss: 0.6890
[12/01 20:47:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.24	
[12/01 20:47:02 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.1
[12/01 20:53:19 visual_prompt]: Epoch 3 / 100: avg data time: 9.87e+00, avg batch time: 10.7569, average train loss: 0.7147
[12/01 20:54:02 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.5246, average loss: 0.7051
[12/01 20:54:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.28	
[12/01 20:54:02 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.15
[12/01 21:00:19 visual_prompt]: Epoch 4 / 100: avg data time: 9.88e+00, avg batch time: 10.7610, average train loss: 0.7134
[12/01 21:01:03 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.5335, average loss: 0.6865
[12/01 21:01:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.20	
[12/01 21:01:03 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.2
[12/01 21:07:19 visual_prompt]: Epoch 5 / 100: avg data time: 9.86e+00, avg batch time: 10.7421, average train loss: 0.7466
[12/01 21:08:02 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.5239, average loss: 0.8192
[12/01 21:08:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.44	
[12/01 21:08:02 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.25
[12/01 21:14:20 visual_prompt]: Epoch 6 / 100: avg data time: 9.90e+00, avg batch time: 10.7863, average train loss: 0.7552
[12/01 21:15:04 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.5430, average loss: 0.7114
[12/01 21:15:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.65	
[12/01 21:15:04 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.3
[12/01 21:21:21 visual_prompt]: Epoch 7 / 100: avg data time: 9.89e+00, avg batch time: 10.7726, average train loss: 0.7767
[12/01 21:22:05 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.5414, average loss: 0.7206
[12/01 21:22:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.38	
[12/01 21:22:05 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.35
[12/01 21:28:23 visual_prompt]: Epoch 8 / 100: avg data time: 9.91e+00, avg batch time: 10.7942, average train loss: 0.7780
[12/01 21:29:07 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.5337, average loss: 0.6876
[12/01 21:29:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 57.65	
[12/01 21:29:07 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.4
[12/01 21:35:25 visual_prompt]: Epoch 9 / 100: avg data time: 9.90e+00, avg batch time: 10.7839, average train loss: 0.7477
[12/01 21:36:09 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.5384, average loss: 0.7322
[12/01 21:36:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.70	
[12/01 21:36:09 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.45
[12/01 21:42:25 visual_prompt]: Epoch 10 / 100: avg data time: 9.88e+00, avg batch time: 10.7629, average train loss: 0.7048
[12/01 21:43:09 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.5276, average loss: 0.8743
[12/01 21:43:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.72	
[12/01 21:43:09 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.5
[12/01 21:49:26 visual_prompt]: Epoch 11 / 100: avg data time: 9.89e+00, avg batch time: 10.7772, average train loss: 0.8294
[12/01 21:50:10 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.5401, average loss: 0.6773
[12/01 21:50:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 60.51	
[12/01 21:50:10 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.49984770675477397
[12/01 21:56:27 visual_prompt]: Epoch 12 / 100: avg data time: 9.87e+00, avg batch time: 10.7543, average train loss: 0.7236
[12/01 21:57:10 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.5303, average loss: 0.6633
[12/01 21:57:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 63.70	
[12/01 21:57:10 visual_prompt]: Best epoch 12: best metric: -0.663
[12/01 21:57:10 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.49939101256495605
[12/01 22:03:28 visual_prompt]: Epoch 13 / 100: avg data time: 9.91e+00, avg batch time: 10.7958, average train loss: 0.7057
[12/01 22:04:12 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.5353, average loss: 0.6547
[12/01 22:04:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 66.29	
[12/01 22:04:12 visual_prompt]: Best epoch 13: best metric: -0.655
[12/01 22:04:12 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.4986304738420683
[12/01 22:10:28 visual_prompt]: Epoch 14 / 100: avg data time: 9.87e+00, avg batch time: 10.7500, average train loss: 0.7519
[12/01 22:11:12 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.5372, average loss: 0.7839
[12/01 22:11:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 66.72	
[12/01 22:11:12 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.4975670171853926
[12/01 22:17:30 visual_prompt]: Epoch 15 / 100: avg data time: 9.90e+00, avg batch time: 10.7795, average train loss: 0.7829
[12/01 22:18:13 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.5397, average loss: 0.8116
[12/01 22:18:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 65.56	
[12/01 22:18:13 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.49620193825305203
[12/01 22:24:30 visual_prompt]: Epoch 16 / 100: avg data time: 9.87e+00, avg batch time: 10.7542, average train loss: 0.6917
[12/01 22:25:13 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.5296, average loss: 1.0649
[12/01 22:25:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 69.55	
[12/01 22:25:13 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.4945369001834514
[12/01 22:31:30 visual_prompt]: Epoch 17 / 100: avg data time: 9.87e+00, avg batch time: 10.7558, average train loss: 0.7422
[12/01 22:32:14 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.5378, average loss: 0.7263
[12/01 22:32:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 71.17	
[12/01 22:32:14 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.4925739315689991
[12/01 22:38:30 visual_prompt]: Epoch 18 / 100: avg data time: 9.87e+00, avg batch time: 10.7493, average train loss: 0.6633
[12/01 22:39:14 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.5282, average loss: 0.7538
[12/01 22:39:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 73.10	
[12/01 22:39:14 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.4903154239845797
[12/01 22:45:30 visual_prompt]: Epoch 19 / 100: avg data time: 9.86e+00, avg batch time: 10.7439, average train loss: 0.6446
[12/01 22:46:14 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.5352, average loss: 0.6219
[12/01 22:46:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.07	rocauc: 71.92	
[12/01 22:46:14 visual_prompt]: Best epoch 19: best metric: -0.622
[12/01 22:46:14 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.4877641290737884
[12/01 22:52:33 visual_prompt]: Epoch 20 / 100: avg data time: 9.96e+00, avg batch time: 10.8432, average train loss: 0.6458
[12/01 22:53:18 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.5330, average loss: 0.6163
[12/01 22:53:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 69.51	rocauc: 74.16	
[12/01 22:53:18 visual_prompt]: Best epoch 20: best metric: -0.616
[12/01 22:53:18 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.4849231551964771
[12/01 22:59:34 visual_prompt]: Epoch 21 / 100: avg data time: 9.88e+00, avg batch time: 10.7545, average train loss: 0.6661
[12/01 23:00:18 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.5335, average loss: 0.6131
[12/01 23:00:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 70.33	rocauc: 73.20	
[12/01 23:00:18 visual_prompt]: Best epoch 21: best metric: -0.613
[12/01 23:00:18 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.48179596364169686
[12/01 23:06:34 visual_prompt]: Epoch 22 / 100: avg data time: 9.87e+00, avg batch time: 10.7469, average train loss: 0.7037
[12/01 23:07:18 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.5322, average loss: 0.6401
[12/01 23:07:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 73.18	
[12/01 23:07:18 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.4783863644106502
[12/01 23:13:34 visual_prompt]: Epoch 23 / 100: avg data time: 9.88e+00, avg batch time: 10.7638, average train loss: 0.6143
[12/01 23:14:18 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.5370, average loss: 0.6865
[12/01 23:14:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 71.75	
[12/01 23:14:18 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.47469851157479176
[12/01 23:20:35 visual_prompt]: Epoch 24 / 100: avg data time: 9.89e+00, avg batch time: 10.7678, average train loss: 0.6276
[12/01 23:21:19 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.5293, average loss: 0.6169
[12/01 23:21:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.89	rocauc: 73.87	
[12/01 23:21:19 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.47073689821473175
[12/01 23:27:35 visual_prompt]: Epoch 25 / 100: avg data time: 9.87e+00, avg batch time: 10.7511, average train loss: 0.5928
[12/01 23:28:19 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.5319, average loss: 0.6271
[12/01 23:28:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 73.84	
[12/01 23:28:19 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.4665063509461097
[12/01 23:34:35 visual_prompt]: Epoch 26 / 100: avg data time: 9.87e+00, avg batch time: 10.7506, average train loss: 0.6679
[12/01 23:35:19 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.5350, average loss: 0.6236
[12/01 23:35:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 73.87	
[12/01 23:35:19 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.46201202403910646
[12/01 23:41:36 visual_prompt]: Epoch 27 / 100: avg data time: 9.88e+00, avg batch time: 10.7634, average train loss: 0.5936
[12/01 23:42:20 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.5314, average loss: 0.6161
[12/01 23:42:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.89	rocauc: 71.83	
[12/01 23:42:20 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.4572593931387604
[12/01 23:48:36 visual_prompt]: Epoch 28 / 100: avg data time: 9.87e+00, avg batch time: 10.7538, average train loss: 0.6253
[12/01 23:49:20 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.5240, average loss: 0.6926
[12/01 23:49:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.54	rocauc: 70.85	
[12/01 23:49:20 visual_prompt]: Stopping early.
[12/01 23:49:20 visual_prompt]: Rank of current process: 0. World size: 1
[12/01 23:49:20 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA TITAN Xp
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[12/01 23:49:20 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss', 'RECORD_GPU_SNAPSHOT', 'True'])
[12/01 23:49:20 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[12/01 23:49:20 visual_prompt]: Training with config:
[12/01 23:49:20 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr0.5_wd0.0/patience7/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True}), 'RECORD_GPU_SNAPSHOT': True})
[12/01 23:49:20 visual_prompt]: Loading training data...
[12/01 23:49:20 visual_prompt]: Constructing mammo-cbis dataset train...
[12/01 23:49:20 visual_prompt]: Loading validation data...
[12/01 23:49:20 visual_prompt]: Constructing mammo-cbis dataset val...
[12/01 23:49:20 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[12/01 23:49:23 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[12/01 23:49:23 visual_prompt]: tuned percent:0.536
[12/01 23:49:23 visual_prompt]: Device used for model: 0
[12/01 23:49:23 visual_prompt]: Setting up Evaluator...
[12/01 23:49:23 visual_prompt]: Setting up Trainer...
[12/01 23:49:23 visual_prompt]: 	Setting up the optimizer...
[12/01 23:49:23 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[12/01 23:55:40 visual_prompt]: Epoch 1 / 100: avg data time: 9.89e+00, avg batch time: 10.7749, average train loss: 1.4006
[12/01 23:56:24 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.5307, average loss: 1.2969
[12/01 23:56:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[12/01 23:56:24 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.05
[12/02 00:02:41 visual_prompt]: Epoch 2 / 100: avg data time: 9.90e+00, avg batch time: 10.7830, average train loss: 1.8314
[12/02 00:03:25 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.5308, average loss: 0.6891
[12/02 00:03:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.31	
[12/02 00:03:25 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.1
[12/02 00:09:42 visual_prompt]: Epoch 3 / 100: avg data time: 9.88e+00, avg batch time: 10.7606, average train loss: 0.7148
[12/02 00:10:25 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.5316, average loss: 0.7044
[12/02 00:10:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.55	
[12/02 00:10:25 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.15
[12/02 00:16:44 visual_prompt]: Epoch 4 / 100: avg data time: 9.95e+00, avg batch time: 10.8259, average train loss: 0.7143
[12/02 00:17:28 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.5358, average loss: 0.6849
[12/02 00:17:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.77	
[12/02 00:17:28 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.2
[12/02 00:23:49 visual_prompt]: Epoch 5 / 100: avg data time: 9.98e+00, avg batch time: 10.8634, average train loss: 0.7509
[12/02 00:24:33 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.5386, average loss: 0.8104
[12/02 00:24:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.95	
[12/02 00:24:33 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.25
[12/02 00:30:52 visual_prompt]: Epoch 6 / 100: avg data time: 9.95e+00, avg batch time: 10.8354, average train loss: 0.7592
[12/02 00:31:36 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.5315, average loss: 0.7212
[12/02 00:31:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.64	
[12/02 00:31:36 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.3
[12/02 00:37:53 visual_prompt]: Epoch 7 / 100: avg data time: 9.88e+00, avg batch time: 10.7603, average train loss: 0.7817
[12/02 00:38:36 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.5315, average loss: 0.7184
[12/02 00:38:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.75	
[12/02 00:38:36 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.35
[12/02 00:44:52 visual_prompt]: Epoch 8 / 100: avg data time: 9.86e+00, avg batch time: 10.7393, average train loss: 0.7735
[12/02 00:45:36 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.5296, average loss: 0.6866
[12/02 00:45:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 58.42	
[12/02 00:45:36 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.4
[12/02 00:51:54 visual_prompt]: Epoch 9 / 100: avg data time: 9.90e+00, avg batch time: 10.7900, average train loss: 0.7449
[12/02 00:52:38 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.5285, average loss: 0.7455
[12/02 00:52:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.86	
[12/02 00:52:38 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.45
[12/02 00:58:55 visual_prompt]: Epoch 10 / 100: avg data time: 9.90e+00, avg batch time: 10.7736, average train loss: 0.7030
[12/02 00:59:39 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.5365, average loss: 0.7469
[12/02 00:59:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 49.59	rocauc: 59.97	
[12/02 00:59:39 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.5
[12/02 01:05:56 visual_prompt]: Epoch 11 / 100: avg data time: 9.89e+00, avg batch time: 10.7748, average train loss: 0.7902
[12/02 01:06:39 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.5273, average loss: 0.7339
[12/02 01:06:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 47.15	rocauc: 61.61	
[12/02 01:06:39 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.49984770675477397
[12/02 01:12:56 visual_prompt]: Epoch 12 / 100: avg data time: 9.88e+00, avg batch time: 10.7583, average train loss: 0.7502
[12/02 01:13:40 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.5378, average loss: 0.6653
[12/02 01:13:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 64.02	
[12/02 01:13:40 visual_prompt]: Best epoch 12: best metric: -0.665
[12/02 01:13:40 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.49939101256495605
[12/02 01:19:57 visual_prompt]: Epoch 13 / 100: avg data time: 9.89e+00, avg batch time: 10.7705, average train loss: 0.7030
[12/02 01:20:41 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.5420, average loss: 0.6529
[12/02 01:20:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 66.53	
[12/02 01:20:41 visual_prompt]: Best epoch 13: best metric: -0.653
[12/02 01:20:41 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.4986304738420683
[12/02 01:26:57 visual_prompt]: Epoch 14 / 100: avg data time: 9.86e+00, avg batch time: 10.7408, average train loss: 0.7449
[12/02 01:27:40 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.5310, average loss: 0.7182
[12/02 01:27:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 70.23	
[12/02 01:27:40 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.4975670171853926
[12/02 01:33:58 visual_prompt]: Epoch 15 / 100: avg data time: 9.90e+00, avg batch time: 10.7751, average train loss: 0.7914
[12/02 01:34:41 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.5285, average loss: 0.7617
[12/02 01:34:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 65.81	
[12/02 01:34:41 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.49620193825305203
[12/02 01:40:57 visual_prompt]: Epoch 16 / 100: avg data time: 9.87e+00, avg batch time: 10.7465, average train loss: 0.7061
[12/02 01:41:41 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.5291, average loss: 1.0598
[12/02 01:41:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 71.25	
[12/02 01:41:41 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.4945369001834514
[12/02 01:47:57 visual_prompt]: Epoch 17 / 100: avg data time: 9.87e+00, avg batch time: 10.7493, average train loss: 0.7755
[12/02 01:48:41 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.5238, average loss: 0.7725
[12/02 01:48:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 70.65	
[12/02 01:48:41 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.4925739315689991
[12/02 01:54:58 visual_prompt]: Epoch 18 / 100: avg data time: 9.88e+00, avg batch time: 10.7592, average train loss: 0.6831
[12/02 01:55:41 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.5301, average loss: 0.8806
[12/02 01:55:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 72.71	
[12/02 01:55:41 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.4903154239845797
[12/02 02:01:58 visual_prompt]: Epoch 19 / 100: avg data time: 9.87e+00, avg batch time: 10.7559, average train loss: 0.6573
[12/02 02:02:42 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.5189, average loss: 0.6150
[12/02 02:02:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.89	rocauc: 72.32	
[12/02 02:02:42 visual_prompt]: Best epoch 19: best metric: -0.615
[12/02 02:02:42 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.4877641290737884
[12/02 02:08:58 visual_prompt]: Epoch 20 / 100: avg data time: 9.86e+00, avg batch time: 10.7425, average train loss: 0.6488
[12/02 02:09:41 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.5302, average loss: 0.6179
[12/02 02:09:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 72.69	
[12/02 02:09:41 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.4849231551964771
[12/02 02:15:58 visual_prompt]: Epoch 21 / 100: avg data time: 9.88e+00, avg batch time: 10.7546, average train loss: 0.6757
[12/02 02:16:42 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.5326, average loss: 0.6259
[12/02 02:16:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.67	rocauc: 73.93	
[12/02 02:16:42 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.48179596364169686
[12/02 02:22:58 visual_prompt]: Epoch 22 / 100: avg data time: 9.86e+00, avg batch time: 10.7426, average train loss: 0.6916
[12/02 02:23:41 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.5228, average loss: 0.6390
[12/02 02:23:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 72.39	
[12/02 02:23:41 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.4783863644106502
[12/02 02:29:58 visual_prompt]: Epoch 23 / 100: avg data time: 9.87e+00, avg batch time: 10.7562, average train loss: 0.6134
[12/02 02:30:41 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.5311, average loss: 0.7332
[12/02 02:30:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 71.88	
[12/02 02:30:41 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.47469851157479176
[12/02 02:36:58 visual_prompt]: Epoch 24 / 100: avg data time: 9.87e+00, avg batch time: 10.7506, average train loss: 0.6315
[12/02 02:37:41 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.5342, average loss: 0.6292
[12/02 02:37:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 71.07	
[12/02 02:37:42 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.47073689821473175
[12/02 02:43:58 visual_prompt]: Epoch 25 / 100: avg data time: 9.87e+00, avg batch time: 10.7526, average train loss: 0.5940
[12/02 02:44:42 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.5383, average loss: 0.6308
[12/02 02:44:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.89	rocauc: 72.97	
[12/02 02:44:42 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.4665063509461097
[12/02 02:50:58 visual_prompt]: Epoch 26 / 100: avg data time: 9.87e+00, avg batch time: 10.7538, average train loss: 0.6377
[12/02 02:51:42 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.5322, average loss: 0.6442
[12/02 02:51:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 71.42	
[12/02 02:51:42 visual_prompt]: Stopping early.
[12/02 02:51:42 visual_prompt]: Rank of current process: 0. World size: 1
[12/02 02:51:42 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA TITAN Xp
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[12/02 02:51:42 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss', 'RECORD_GPU_SNAPSHOT', 'True'])
[12/02 02:51:42 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[12/02 02:51:42 visual_prompt]: Training with config:
[12/02 02:51:42 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr0.25_wd0.01/patience7/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.25, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True}), 'RECORD_GPU_SNAPSHOT': True})
[12/02 02:51:42 visual_prompt]: Loading training data...
[12/02 02:51:42 visual_prompt]: Constructing mammo-cbis dataset train...
[12/02 02:51:42 visual_prompt]: Loading validation data...
[12/02 02:51:42 visual_prompt]: Constructing mammo-cbis dataset val...
[12/02 02:51:42 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[12/02 02:51:45 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[12/02 02:51:45 visual_prompt]: tuned percent:0.536
[12/02 02:51:45 visual_prompt]: Device used for model: 0
[12/02 02:51:45 visual_prompt]: Setting up Evaluator...
[12/02 02:51:45 visual_prompt]: Setting up Trainer...
[12/02 02:51:45 visual_prompt]: 	Setting up the optimizer...
[12/02 02:51:45 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[12/02 02:58:03 visual_prompt]: Epoch 1 / 100: avg data time: 9.92e+00, avg batch time: 10.7934, average train loss: 1.4006
[12/02 02:58:47 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.5288, average loss: 1.2969
[12/02 02:58:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[12/02 02:58:47 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.025
[12/02 03:05:03 visual_prompt]: Epoch 2 / 100: avg data time: 9.88e+00, avg batch time: 10.7562, average train loss: 1.3950
[12/02 03:05:47 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.5305, average loss: 0.6916
[12/02 03:05:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 52.85	rocauc: 52.82	
[12/02 03:05:47 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.05
[12/02 03:12:03 visual_prompt]: Epoch 3 / 100: avg data time: 9.87e+00, avg batch time: 10.7505, average train loss: 0.7023
[12/02 03:12:47 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.5348, average loss: 0.6888
[12/02 03:12:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.36	
[12/02 03:12:47 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.075
[12/02 03:19:04 visual_prompt]: Epoch 4 / 100: avg data time: 9.88e+00, avg batch time: 10.7571, average train loss: 0.6965
[12/02 03:19:47 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.5309, average loss: 0.6799
[12/02 03:19:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 61.05	
[12/02 03:19:47 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.1
[12/02 03:26:03 visual_prompt]: Epoch 5 / 100: avg data time: 9.86e+00, avg batch time: 10.7386, average train loss: 0.7122
[12/02 03:26:47 visual_prompt]: Inference (val):avg data time: 2.00e-05, avg batch time: 0.5320, average loss: 0.6839
[12/02 03:26:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 59.14	
[12/02 03:26:47 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.125
[12/02 03:33:04 visual_prompt]: Epoch 6 / 100: avg data time: 9.89e+00, avg batch time: 10.7734, average train loss: 0.7140
[12/02 03:33:48 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.5317, average loss: 0.7077
[12/02 03:33:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.78	
[12/02 03:33:48 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.15
[12/02 03:40:05 visual_prompt]: Epoch 7 / 100: avg data time: 9.90e+00, avg batch time: 10.7728, average train loss: 0.7093
[12/02 03:40:49 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.5285, average loss: 0.6906
[12/02 03:40:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 59.33	
[12/02 03:40:49 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.175
[12/02 03:47:05 visual_prompt]: Epoch 8 / 100: avg data time: 9.86e+00, avg batch time: 10.7405, average train loss: 0.7054
[12/02 03:47:48 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.5328, average loss: 0.6858
[12/02 03:47:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.27	
[12/02 03:47:48 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.2
[12/02 03:54:06 visual_prompt]: Epoch 9 / 100: avg data time: 9.90e+00, avg batch time: 10.7781, average train loss: 0.7233
[12/02 03:54:50 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.5327, average loss: 0.6898
[12/02 03:54:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.69	
[12/02 03:54:50 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.225
[12/02 04:01:06 visual_prompt]: Epoch 10 / 100: avg data time: 9.88e+00, avg batch time: 10.7614, average train loss: 0.7047
[12/02 04:01:50 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.5396, average loss: 0.7100
[12/02 04:01:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.17	
[12/02 04:01:50 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.25
[12/02 04:08:07 visual_prompt]: Epoch 11 / 100: avg data time: 9.89e+00, avg batch time: 10.7693, average train loss: 0.6964
[12/02 04:08:51 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.5322, average loss: 0.6951
[12/02 04:08:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.74	
[12/02 04:08:51 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.24992385337738698
[12/02 04:15:07 visual_prompt]: Epoch 12 / 100: avg data time: 9.88e+00, avg batch time: 10.7568, average train loss: 0.7274
[12/02 04:15:51 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.5314, average loss: 0.7142
[12/02 04:15:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.60	
[12/02 04:15:51 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.24969550628247802
[12/02 04:22:08 visual_prompt]: Epoch 13 / 100: avg data time: 9.90e+00, avg batch time: 10.7761, average train loss: 0.7346
[12/02 04:22:52 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.5302, average loss: 0.6932
[12/02 04:22:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 42.68	rocauc: 50.18	
[12/02 04:22:52 visual_prompt]: Best epoch 13: best metric: -0.693
[12/02 04:22:52 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.24931523692103416
[12/02 04:29:08 visual_prompt]: Epoch 14 / 100: avg data time: 9.87e+00, avg batch time: 10.7409, average train loss: 0.7097
[12/02 04:29:51 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.5248, average loss: 0.7968
[12/02 04:29:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.53	
[12/02 04:29:51 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.2487835085926963
[12/02 04:36:09 visual_prompt]: Epoch 15 / 100: avg data time: 9.89e+00, avg batch time: 10.7715, average train loss: 0.7103
[12/02 04:36:52 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.5348, average loss: 0.6905
[12/02 04:36:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.84	
[12/02 04:36:52 visual_prompt]: Best epoch 15: best metric: -0.691
[12/02 04:36:52 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.24810096912652602
[12/02 04:43:09 visual_prompt]: Epoch 16 / 100: avg data time: 9.87e+00, avg batch time: 10.7515, average train loss: 0.7040
[12/02 04:43:53 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.5324, average loss: 0.7238
[12/02 04:43:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.89	
[12/02 04:43:53 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.2472684500917257
[12/02 04:50:09 visual_prompt]: Epoch 17 / 100: avg data time: 9.87e+00, avg batch time: 10.7445, average train loss: 0.7080
[12/02 04:50:52 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.5200, average loss: 0.6985
[12/02 04:50:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.46	
[12/02 04:50:52 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.24628696578449955
[12/02 04:57:09 visual_prompt]: Epoch 18 / 100: avg data time: 9.88e+00, avg batch time: 10.7563, average train loss: 0.7095
[12/02 04:57:53 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.5304, average loss: 0.7898
[12/02 04:57:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.35	
[12/02 04:57:53 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.24515771199228986
[12/02 05:04:09 visual_prompt]: Epoch 19 / 100: avg data time: 9.87e+00, avg batch time: 10.7474, average train loss: 0.7068
[12/02 05:04:53 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.5339, average loss: 0.7250
[12/02 05:04:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.12	
[12/02 05:04:53 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.2438820645368942
[12/02 05:11:09 visual_prompt]: Epoch 20 / 100: avg data time: 9.88e+00, avg batch time: 10.7584, average train loss: 0.7124
[12/02 05:11:53 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.5303, average loss: 0.7099
[12/02 05:11:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 45.30	
[12/02 05:11:53 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.24246157759823855
[12/02 05:18:12 visual_prompt]: Epoch 21 / 100: avg data time: 9.96e+00, avg batch time: 10.8382, average train loss: 0.7057
[12/02 05:18:57 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.5276, average loss: 0.6903
[12/02 05:18:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 41.54	
[12/02 05:18:57 visual_prompt]: Best epoch 21: best metric: -0.690
[12/02 05:18:57 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.24089798182084843
[12/02 05:25:15 visual_prompt]: Epoch 22 / 100: avg data time: 9.93e+00, avg batch time: 10.8114, average train loss: 0.7080
[12/02 05:25:59 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.5353, average loss: 0.7377
[12/02 05:25:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.15	
[12/02 05:25:59 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.2391931822053251
[12/02 05:32:15 visual_prompt]: Epoch 23 / 100: avg data time: 9.88e+00, avg batch time: 10.7561, average train loss: 0.7015
[12/02 05:32:59 visual_prompt]: Inference (val):avg data time: 2.11e-05, avg batch time: 0.5192, average loss: 0.6919
[12/02 05:32:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.61	
[12/02 05:32:59 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.23734925578739588
[12/02 05:39:15 visual_prompt]: Epoch 24 / 100: avg data time: 9.87e+00, avg batch time: 10.7512, average train loss: 0.6964
[12/02 05:39:59 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.5327, average loss: 0.6891
[12/02 05:39:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.02	
[12/02 05:39:59 visual_prompt]: Best epoch 24: best metric: -0.689
[12/02 05:39:59 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.23536844910736587
[12/02 05:46:15 visual_prompt]: Epoch 25 / 100: avg data time: 9.86e+00, avg batch time: 10.7433, average train loss: 0.7028
[12/02 05:46:59 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.5293, average loss: 0.6888
[12/02 05:46:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.10	
[12/02 05:46:59 visual_prompt]: Best epoch 25: best metric: -0.689
[12/02 05:46:59 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.23325317547305485
[12/02 05:53:15 visual_prompt]: Epoch 26 / 100: avg data time: 9.86e+00, avg batch time: 10.7435, average train loss: 0.7140
[12/02 05:53:59 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.5323, average loss: 0.7139
[12/02 05:53:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.80	
[12/02 05:53:59 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.23100601201955323
[12/02 06:00:15 visual_prompt]: Epoch 27 / 100: avg data time: 9.86e+00, avg batch time: 10.7356, average train loss: 0.7088
[12/02 06:00:58 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.5253, average loss: 0.6899
[12/02 06:00:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.07	
[12/02 06:00:58 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.2286296965693802
[12/02 06:07:14 visual_prompt]: Epoch 28 / 100: avg data time: 9.85e+00, avg batch time: 10.7317, average train loss: 0.7065
[12/02 06:07:58 visual_prompt]: Inference (val):avg data time: 2.11e-05, avg batch time: 0.5309, average loss: 0.7032
[12/02 06:07:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.33	
[12/02 06:07:58 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.22612712429686843
[12/02 06:14:15 visual_prompt]: Epoch 29 / 100: avg data time: 9.90e+00, avg batch time: 10.7793, average train loss: 0.6968
[12/02 06:14:59 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.5269, average loss: 0.6999
[12/02 06:14:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.46	
[12/02 06:14:59 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.22350134420084022
[12/02 06:21:17 visual_prompt]: Epoch 30 / 100: avg data time: 9.93e+00, avg batch time: 10.8056, average train loss: 0.6972
[12/02 06:22:01 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.5330, average loss: 0.7123
[12/02 06:22:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 42.78	
[12/02 06:22:01 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.22075555538987224
[12/02 06:28:17 visual_prompt]: Epoch 31 / 100: avg data time: 9.87e+00, avg batch time: 10.7468, average train loss: 0.6998
[12/02 06:29:01 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.5313, average loss: 0.7209
[12/02 06:29:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.52	
[12/02 06:29:01 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.21789310318467428
[12/02 06:35:18 visual_prompt]: Epoch 32 / 100: avg data time: 9.90e+00, avg batch time: 10.7705, average train loss: 0.7374
[12/02 06:36:02 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.5345, average loss: 0.7400
[12/02 06:36:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.09	
[12/02 06:36:02 visual_prompt]: Stopping early.
[12/02 06:36:02 visual_prompt]: Rank of current process: 0. World size: 1
[12/02 06:36:02 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA TITAN Xp
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[12/02 06:36:02 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss', 'RECORD_GPU_SNAPSHOT', 'True'])
[12/02 06:36:02 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[12/02 06:36:02 visual_prompt]: Training with config:
[12/02 06:36:02 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr0.25_wd0.001/patience7/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.25, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True}), 'RECORD_GPU_SNAPSHOT': True})
[12/02 06:36:02 visual_prompt]: Loading training data...
[12/02 06:36:02 visual_prompt]: Constructing mammo-cbis dataset train...
[12/02 06:36:02 visual_prompt]: Loading validation data...
[12/02 06:36:02 visual_prompt]: Constructing mammo-cbis dataset val...
[12/02 06:36:02 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[12/02 06:36:05 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[12/02 06:36:05 visual_prompt]: tuned percent:0.536
[12/02 06:36:05 visual_prompt]: Device used for model: 0
[12/02 06:36:05 visual_prompt]: Setting up Evaluator...
[12/02 06:36:05 visual_prompt]: Setting up Trainer...
[12/02 06:36:05 visual_prompt]: 	Setting up the optimizer...
[12/02 06:36:05 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[12/02 06:42:22 visual_prompt]: Epoch 1 / 100: avg data time: 9.89e+00, avg batch time: 10.7646, average train loss: 1.4006
[12/02 06:43:05 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.5336, average loss: 1.2969
[12/02 06:43:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[12/02 06:43:05 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.025
[12/02 06:49:22 visual_prompt]: Epoch 2 / 100: avg data time: 9.89e+00, avg batch time: 10.7677, average train loss: 1.3993
[12/02 06:50:06 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.5311, average loss: 0.6925
[12/02 06:50:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 52.44	rocauc: 52.70	
[12/02 06:50:06 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.05
[12/02 06:56:23 visual_prompt]: Epoch 3 / 100: avg data time: 9.89e+00, avg batch time: 10.7692, average train loss: 0.7063
[12/02 06:57:07 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.5334, average loss: 0.6898
[12/02 06:57:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.48	
[12/02 06:57:07 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.075
[12/02 07:03:24 visual_prompt]: Epoch 4 / 100: avg data time: 9.88e+00, avg batch time: 10.7648, average train loss: 0.6949
[12/02 07:04:07 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.5307, average loss: 0.6819
[12/02 07:04:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.47	rocauc: 61.33	
[12/02 07:04:07 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.1
[12/02 07:10:23 visual_prompt]: Epoch 5 / 100: avg data time: 9.85e+00, avg batch time: 10.7294, average train loss: 0.7281
[12/02 07:11:07 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.5284, average loss: 0.6772
[12/02 07:11:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 61.54	
[12/02 07:11:07 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.125
[12/02 07:17:23 visual_prompt]: Epoch 6 / 100: avg data time: 9.88e+00, avg batch time: 10.7594, average train loss: 0.7184
[12/02 07:18:07 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.5269, average loss: 0.6790
[12/02 07:18:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 61.11	
[12/02 07:18:07 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.15
[12/02 07:24:25 visual_prompt]: Epoch 7 / 100: avg data time: 9.91e+00, avg batch time: 10.7881, average train loss: 0.7048
[12/02 07:25:09 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.5313, average loss: 0.6735
[12/02 07:25:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 62.18	
[12/02 07:25:09 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.175
[12/02 07:31:27 visual_prompt]: Epoch 8 / 100: avg data time: 9.93e+00, avg batch time: 10.8056, average train loss: 0.7026
[12/02 07:32:11 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.5370, average loss: 0.6677
[12/02 07:32:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 61.55	
[12/02 07:32:11 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.2
[12/02 07:38:28 visual_prompt]: Epoch 9 / 100: avg data time: 9.89e+00, avg batch time: 10.7673, average train loss: 0.6946
[12/02 07:39:11 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.5357, average loss: 0.7027
[12/02 07:39:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 65.23	
[12/02 07:39:11 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.225
[12/02 07:45:28 visual_prompt]: Epoch 10 / 100: avg data time: 9.87e+00, avg batch time: 10.7557, average train loss: 0.7348
[12/02 07:46:12 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.5316, average loss: 0.6761
[12/02 07:46:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 63.45	
[12/02 07:46:12 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.25
[12/02 07:52:28 visual_prompt]: Epoch 11 / 100: avg data time: 9.87e+00, avg batch time: 10.7528, average train loss: 0.6997
[12/02 07:53:12 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.5308, average loss: 0.6715
[12/02 07:53:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 65.97	
[12/02 07:53:12 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.24992385337738698
[12/02 07:59:28 visual_prompt]: Epoch 12 / 100: avg data time: 9.87e+00, avg batch time: 10.7444, average train loss: 0.6965
[12/02 08:00:12 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.5227, average loss: 0.7356
[12/02 08:00:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 64.96	
[12/02 08:00:12 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.24969550628247802
[12/02 08:06:29 visual_prompt]: Epoch 13 / 100: avg data time: 9.90e+00, avg batch time: 10.7746, average train loss: 0.7295
[12/02 08:07:13 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.5312, average loss: 0.6857
[12/02 08:07:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 63.97	
[12/02 08:07:13 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.24931523692103416
[12/02 08:13:29 visual_prompt]: Epoch 14 / 100: avg data time: 9.87e+00, avg batch time: 10.7460, average train loss: 0.6884
[12/02 08:14:13 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.5307, average loss: 0.7068
[12/02 08:14:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 68.88	
[12/02 08:14:13 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.2487835085926963
[12/02 08:20:30 visual_prompt]: Epoch 15 / 100: avg data time: 9.90e+00, avg batch time: 10.7765, average train loss: 0.7107
[12/02 08:21:14 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.5401, average loss: 0.8164
[12/02 08:21:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 67.35	
[12/02 08:21:14 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.24810096912652602
[12/02 08:27:29 visual_prompt]: Epoch 16 / 100: avg data time: 9.86e+00, avg batch time: 10.7396, average train loss: 0.7402
[12/02 08:28:13 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.5290, average loss: 0.6585
[12/02 08:28:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 68.20	
[12/02 08:28:13 visual_prompt]: Best epoch 16: best metric: -0.658
[12/02 08:28:13 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.2472684500917257
[12/02 08:34:29 visual_prompt]: Epoch 17 / 100: avg data time: 9.85e+00, avg batch time: 10.7303, average train loss: 0.6993
[12/02 08:35:13 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.5250, average loss: 0.6697
[12/02 08:35:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 66.49	
[12/02 08:35:13 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.24628696578449955
[12/02 08:41:29 visual_prompt]: Epoch 18 / 100: avg data time: 9.87e+00, avg batch time: 10.7529, average train loss: 0.6679
[12/02 08:42:13 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.5316, average loss: 0.6516
[12/02 08:42:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 69.20	
[12/02 08:42:13 visual_prompt]: Best epoch 18: best metric: -0.652
[12/02 08:42:13 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.24515771199228986
[12/02 08:48:29 visual_prompt]: Epoch 19 / 100: avg data time: 9.86e+00, avg batch time: 10.7410, average train loss: 0.6398
[12/02 08:49:13 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.5296, average loss: 0.6772
[12/02 08:49:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 68.28	
[12/02 08:49:13 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.2438820645368942
[12/02 08:55:29 visual_prompt]: Epoch 20 / 100: avg data time: 9.88e+00, avg batch time: 10.7610, average train loss: 0.6531
[12/02 08:56:13 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.5307, average loss: 0.6964
[12/02 08:56:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 50.41	rocauc: 68.11	
[12/02 08:56:13 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.24246157759823855
[12/02 09:02:30 visual_prompt]: Epoch 21 / 100: avg data time: 9.88e+00, avg batch time: 10.7625, average train loss: 0.6666
[12/02 09:03:13 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.5305, average loss: 0.6906
[12/02 09:03:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 65.55	
[12/02 09:03:13 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.24089798182084843
[12/02 09:09:30 visual_prompt]: Epoch 22 / 100: avg data time: 9.88e+00, avg batch time: 10.7586, average train loss: 0.6735
[12/02 09:10:14 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.5345, average loss: 0.6341
[12/02 09:10:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 70.16	
[12/02 09:10:14 visual_prompt]: Best epoch 22: best metric: -0.634
[12/02 09:10:14 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.2391931822053251
[12/02 09:16:30 visual_prompt]: Epoch 23 / 100: avg data time: 9.88e+00, avg batch time: 10.7572, average train loss: 0.6506
[12/02 09:17:14 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.5266, average loss: 0.7318
[12/02 09:17:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 64.72	
[12/02 09:17:14 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.23734925578739588
[12/02 09:23:31 visual_prompt]: Epoch 24 / 100: avg data time: 9.88e+00, avg batch time: 10.7635, average train loss: 0.6983
[12/02 09:24:15 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.5314, average loss: 0.6478
[12/02 09:24:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 67.60	
[12/02 09:24:15 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.23536844910736587
[12/02 09:30:31 visual_prompt]: Epoch 25 / 100: avg data time: 9.87e+00, avg batch time: 10.7486, average train loss: 0.6335
[12/02 09:31:15 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.5356, average loss: 0.6325
[12/02 09:31:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 70.91	
[12/02 09:31:15 visual_prompt]: Best epoch 25: best metric: -0.632
[12/02 09:31:15 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.23325317547305485
[12/02 09:37:31 visual_prompt]: Epoch 26 / 100: avg data time: 9.86e+00, avg batch time: 10.7351, average train loss: 0.7118
[12/02 09:38:14 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.5327, average loss: 0.6665
[12/02 09:38:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 68.38	
[12/02 09:38:14 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.23100601201955323
[12/02 09:44:32 visual_prompt]: Epoch 27 / 100: avg data time: 9.90e+00, avg batch time: 10.7811, average train loss: 0.6563
[12/02 09:45:16 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.5347, average loss: 0.6319
[12/02 09:45:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 70.76	
[12/02 09:45:16 visual_prompt]: Best epoch 27: best metric: -0.632
[12/02 09:45:16 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.2286296965693802
[12/02 09:51:32 visual_prompt]: Epoch 28 / 100: avg data time: 9.87e+00, avg batch time: 10.7498, average train loss: 0.6762
[12/02 09:52:15 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.5270, average loss: 0.7221
[12/02 09:52:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 67.28	
[12/02 09:52:15 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.22612712429686843
[12/02 09:58:32 visual_prompt]: Epoch 29 / 100: avg data time: 9.89e+00, avg batch time: 10.7751, average train loss: 0.6358
[12/02 09:59:16 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.5324, average loss: 0.6440
[12/02 09:59:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.01	rocauc: 71.84	
[12/02 09:59:16 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.22350134420084022
[12/02 10:05:34 visual_prompt]: Epoch 30 / 100: avg data time: 9.90e+00, avg batch time: 10.7760, average train loss: 0.6330
[12/02 10:06:17 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.5246, average loss: 0.6835
[12/02 10:06:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.54	rocauc: 70.80	
[12/02 10:06:17 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.22075555538987224
[12/02 10:12:34 visual_prompt]: Epoch 31 / 100: avg data time: 9.89e+00, avg batch time: 10.7697, average train loss: 0.6208
[12/02 10:13:18 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.5341, average loss: 0.6708
[12/02 10:13:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.54	rocauc: 73.38	
[12/02 10:13:18 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.21789310318467428
[12/02 10:19:35 visual_prompt]: Epoch 32 / 100: avg data time: 9.89e+00, avg batch time: 10.7693, average train loss: 0.6322
[12/02 10:20:19 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.5335, average loss: 0.7142
[12/02 10:20:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 52.44	rocauc: 70.80	
[12/02 10:20:19 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.21491747504233139
[12/02 10:26:36 visual_prompt]: Epoch 33 / 100: avg data time: 9.89e+00, avg batch time: 10.7637, average train loss: 0.6137
[12/02 10:27:19 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.5325, average loss: 0.6594
[12/02 10:27:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 71.26	
[12/02 10:27:19 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.21183229630737466
[12/02 10:33:36 visual_prompt]: Epoch 34 / 100: avg data time: 9.87e+00, avg batch time: 10.7456, average train loss: 0.6065
[12/02 10:34:19 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.5296, average loss: 0.6241
[12/02 10:34:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 68.29	rocauc: 72.13	
[12/02 10:34:19 visual_prompt]: Best epoch 34: best metric: -0.624
[12/02 10:34:19 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.20864132579485728
[12/02 10:40:36 visual_prompt]: Epoch 35 / 100: avg data time: 9.87e+00, avg batch time: 10.7487, average train loss: 0.6196
[12/02 10:41:19 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.5333, average loss: 0.6649
[12/02 10:41:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 69.85	
[12/02 10:41:19 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.2053484512108174
[12/02 10:47:35 visual_prompt]: Epoch 36 / 100: avg data time: 9.86e+00, avg batch time: 10.7424, average train loss: 0.6399
[12/02 10:48:19 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.5350, average loss: 0.6727
[12/02 10:48:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 69.81	
[12/02 10:48:19 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.20195768441570727
[12/02 10:54:34 visual_prompt]: Epoch 37 / 100: avg data time: 9.85e+00, avg batch time: 10.7277, average train loss: 0.6208
[12/02 10:55:18 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.5314, average loss: 0.6427
[12/02 10:55:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 72.60	
[12/02 10:55:18 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.19847315653655914
[12/02 11:01:35 visual_prompt]: Epoch 38 / 100: avg data time: 9.88e+00, avg batch time: 10.7613, average train loss: 0.6195
[12/02 11:02:19 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.5340, average loss: 0.7439
[12/02 11:02:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 71.40	
[12/02 11:02:19 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.19489911293384335
[12/02 11:08:36 visual_prompt]: Epoch 39 / 100: avg data time: 9.90e+00, avg batch time: 10.7724, average train loss: 0.6485
[12/02 11:09:20 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.5297, average loss: 0.6567
[12/02 11:09:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 72.01	
[12/02 11:09:20 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.1912399080291506
[12/02 11:15:37 visual_prompt]: Epoch 40 / 100: avg data time: 9.90e+00, avg batch time: 10.7711, average train loss: 0.5941
[12/02 11:16:20 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.5383, average loss: 0.6156
[12/02 11:16:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 68.29	rocauc: 72.43	
[12/02 11:16:20 visual_prompt]: Best epoch 40: best metric: -0.616
[12/02 11:16:20 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.1875
[12/02 11:22:37 visual_prompt]: Epoch 41 / 100: avg data time: 9.89e+00, avg batch time: 10.7689, average train loss: 0.5910
[12/02 11:23:21 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.5293, average loss: 0.6493
[12/02 11:23:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.01	rocauc: 74.23	
[12/02 11:23:21 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.18368394534823634
[12/02 11:29:37 visual_prompt]: Epoch 42 / 100: avg data time: 9.87e+00, avg batch time: 10.7477, average train loss: 0.6130
[12/02 11:30:21 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.5381, average loss: 0.7341
[12/02 11:30:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 70.71	
[12/02 11:30:21 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.17979639334863468
[12/02 11:36:37 visual_prompt]: Epoch 43 / 100: avg data time: 9.87e+00, avg batch time: 10.7459, average train loss: 0.6101
[12/02 11:37:21 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.5315, average loss: 0.6082
[12/02 11:37:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 68.29	rocauc: 72.71	
[12/02 11:37:21 visual_prompt]: Best epoch 43: best metric: -0.608
[12/02 11:37:21 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.17584208038447505
[12/02 11:43:37 visual_prompt]: Epoch 44 / 100: avg data time: 9.88e+00, avg batch time: 10.7513, average train loss: 0.5916
[12/02 11:44:21 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.5335, average loss: 0.6761
[12/02 11:44:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 69.80	
[12/02 11:44:21 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.17182582417698902
[12/02 11:50:39 visual_prompt]: Epoch 45 / 100: avg data time: 9.91e+00, avg batch time: 10.7873, average train loss: 0.5913
[12/02 11:51:22 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.5333, average loss: 0.7287
[12/02 11:51:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 70.54	
[12/02 11:51:22 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.1677525179157086
[12/02 11:57:39 visual_prompt]: Epoch 46 / 100: avg data time: 9.87e+00, avg batch time: 10.7488, average train loss: 0.6081
[12/02 11:58:22 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.5271, average loss: 0.6281
[12/02 11:58:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 72.04	
[12/02 11:58:22 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.16362712429686843
[12/02 12:04:38 visual_prompt]: Epoch 47 / 100: avg data time: 9.85e+00, avg batch time: 10.7322, average train loss: 0.5875
[12/02 12:05:22 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.5246, average loss: 0.6367
[12/02 12:05:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 73.21	
[12/02 12:05:22 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.1594546694771249
[12/02 12:11:38 visual_prompt]: Epoch 48 / 100: avg data time: 9.87e+00, avg batch time: 10.7419, average train loss: 0.5802
[12/02 12:12:21 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.5232, average loss: 0.6177
[12/02 12:12:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.07	rocauc: 73.34	
[12/02 12:12:21 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.15524023694995845
[12/02 12:18:38 visual_prompt]: Epoch 49 / 100: avg data time: 9.87e+00, avg batch time: 10.7523, average train loss: 0.5778
[12/02 12:19:22 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.5309, average loss: 0.6693
[12/02 12:19:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 70.39	
[12/02 12:19:22 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.1509889613522199
[12/02 12:25:37 visual_prompt]: Epoch 50 / 100: avg data time: 9.84e+00, avg batch time: 10.7233, average train loss: 0.5822
[12/02 12:26:21 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.5304, average loss: 0.7985
[12/02 12:26:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 71.48	
[12/02 12:26:21 visual_prompt]: Stopping early.
[12/02 12:26:21 visual_prompt]: Rank of current process: 0. World size: 1
[12/02 12:26:21 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA TITAN Xp
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[12/02 12:26:21 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss', 'RECORD_GPU_SNAPSHOT', 'True'])
[12/02 12:26:21 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[12/02 12:26:21 visual_prompt]: Training with config:
[12/02 12:26:21 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr0.25_wd0.0001/patience7/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.25, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True}), 'RECORD_GPU_SNAPSHOT': True})
[12/02 12:26:21 visual_prompt]: Loading training data...
[12/02 12:26:21 visual_prompt]: Constructing mammo-cbis dataset train...
[12/02 12:26:21 visual_prompt]: Loading validation data...
[12/02 12:26:21 visual_prompt]: Constructing mammo-cbis dataset val...
[12/02 12:26:21 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[12/02 12:26:23 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[12/02 12:26:23 visual_prompt]: tuned percent:0.536
[12/02 12:26:23 visual_prompt]: Device used for model: 0
[12/02 12:26:23 visual_prompt]: Setting up Evaluator...
[12/02 12:26:23 visual_prompt]: Setting up Trainer...
[12/02 12:26:23 visual_prompt]: 	Setting up the optimizer...
[12/02 12:26:24 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[12/02 12:32:40 visual_prompt]: Epoch 1 / 100: avg data time: 9.87e+00, avg batch time: 10.7538, average train loss: 1.4006
[12/02 12:33:24 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.5396, average loss: 1.2969
[12/02 12:33:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[12/02 12:33:24 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.025
[12/02 12:39:39 visual_prompt]: Epoch 2 / 100: avg data time: 9.84e+00, avg batch time: 10.7215, average train loss: 1.3997
[12/02 12:40:23 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.5382, average loss: 0.6927
[12/02 12:40:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 52.85	rocauc: 52.59	
[12/02 12:40:23 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.05
[12/02 12:46:39 visual_prompt]: Epoch 3 / 100: avg data time: 9.87e+00, avg batch time: 10.7462, average train loss: 0.7068
[12/02 12:47:23 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.5359, average loss: 0.6900
[12/02 12:47:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.48	
[12/02 12:47:23 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.075
[12/02 12:53:39 visual_prompt]: Epoch 4 / 100: avg data time: 9.86e+00, avg batch time: 10.7401, average train loss: 0.6953
[12/02 12:54:23 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.5365, average loss: 0.6819
[12/02 12:54:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.47	rocauc: 61.07	
[12/02 12:54:23 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.1
[12/02 13:00:38 visual_prompt]: Epoch 5 / 100: avg data time: 9.85e+00, avg batch time: 10.7333, average train loss: 0.7295
[12/02 13:01:22 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.5359, average loss: 0.6766
[12/02 13:01:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 61.52	
[12/02 13:01:22 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.125
[12/02 13:07:39 visual_prompt]: Epoch 6 / 100: avg data time: 9.88e+00, avg batch time: 10.7580, average train loss: 0.7218
[12/02 13:08:22 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.5358, average loss: 0.6791
[12/02 13:08:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 60.86	
[12/02 13:08:22 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.15
[12/02 13:14:38 visual_prompt]: Epoch 7 / 100: avg data time: 9.86e+00, avg batch time: 10.7408, average train loss: 0.7050
[12/02 13:15:22 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.5368, average loss: 0.6715
[12/02 13:15:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 62.59	
[12/02 13:15:22 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.175
[12/02 13:21:38 visual_prompt]: Epoch 8 / 100: avg data time: 9.85e+00, avg batch time: 10.7327, average train loss: 0.7023
[12/02 13:22:21 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.5412, average loss: 0.6653
[12/02 13:22:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 62.81	
[12/02 13:22:21 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.2
[12/02 13:28:39 visual_prompt]: Epoch 9 / 100: avg data time: 9.89e+00, avg batch time: 10.7726, average train loss: 0.6876
[12/02 13:29:22 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.5369, average loss: 0.6832
[12/02 13:29:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 66.45	
[12/02 13:29:22 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.225
[12/02 13:35:38 visual_prompt]: Epoch 10 / 100: avg data time: 9.87e+00, avg batch time: 10.7415, average train loss: 0.6630
[12/02 13:36:22 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.5325, average loss: 0.6533
[12/02 13:36:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 68.79	
[12/02 13:36:22 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.25
[12/02 13:42:39 visual_prompt]: Epoch 11 / 100: avg data time: 9.88e+00, avg batch time: 10.7596, average train loss: 0.6718
[12/02 13:43:22 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.5285, average loss: 0.6493
[12/02 13:43:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 69.64	
[12/02 13:43:22 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.24992385337738698
[12/02 13:49:39 visual_prompt]: Epoch 12 / 100: avg data time: 9.87e+00, avg batch time: 10.7531, average train loss: 0.6747
[12/02 13:50:23 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.5381, average loss: 0.7218
[12/02 13:50:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 51.63	rocauc: 70.17	
[12/02 13:50:23 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.24969550628247802
[12/02 13:56:39 visual_prompt]: Epoch 13 / 100: avg data time: 9.87e+00, avg batch time: 10.7462, average train loss: 0.7069
[12/02 13:57:22 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.5257, average loss: 0.7664
[12/02 13:57:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 70.41	
[12/02 13:57:22 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.24931523692103416
[12/02 14:03:41 visual_prompt]: Epoch 14 / 100: avg data time: 9.93e+00, avg batch time: 10.8076, average train loss: 0.6847
[12/02 14:04:25 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.5342, average loss: 0.7257
[12/02 14:04:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 71.66	
[12/02 14:04:25 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.2487835085926963
[12/02 14:10:45 visual_prompt]: Epoch 15 / 100: avg data time: 9.98e+00, avg batch time: 10.8542, average train loss: 0.6745
[12/02 14:11:29 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.5305, average loss: 0.7695
[12/02 14:11:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 71.91	
[12/02 14:11:29 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.24810096912652602
[12/02 14:17:48 visual_prompt]: Epoch 16 / 100: avg data time: 9.95e+00, avg batch time: 10.8345, average train loss: 0.6537
[12/02 14:18:32 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.5400, average loss: 0.8376
[12/02 14:18:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 72.14	
[12/02 14:18:32 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.2472684500917257
[12/02 14:24:49 visual_prompt]: Epoch 17 / 100: avg data time: 9.87e+00, avg batch time: 10.7546, average train loss: 0.7246
[12/02 14:25:32 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.5338, average loss: 0.6525
[12/02 14:25:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 71.90	
[12/02 14:25:32 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.24628696578449955
[12/02 14:31:50 visual_prompt]: Epoch 18 / 100: avg data time: 9.92e+00, avg batch time: 10.7926, average train loss: 0.6477
[12/02 14:32:34 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.5373, average loss: 0.6257
[12/02 14:32:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 70.11	
[12/02 14:32:34 visual_prompt]: Best epoch 18: best metric: -0.626
[12/02 14:32:34 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.24515771199228986
[12/02 14:38:55 visual_prompt]: Epoch 19 / 100: avg data time: 9.98e+00, avg batch time: 10.8574, average train loss: 0.6427
[12/02 14:39:40 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.5351, average loss: 0.6277
[12/02 14:39:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 69.41	
[12/02 14:39:40 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.2438820645368942
[12/02 14:45:59 visual_prompt]: Epoch 20 / 100: avg data time: 9.96e+00, avg batch time: 10.8421, average train loss: 0.6106
[12/02 14:46:44 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.5365, average loss: 0.7843
[12/02 14:46:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 69.96	
[12/02 14:46:44 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.24246157759823855
[12/02 14:53:03 visual_prompt]: Epoch 21 / 100: avg data time: 9.96e+00, avg batch time: 10.8398, average train loss: 0.6224
[12/02 14:53:47 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.5319, average loss: 0.6733
[12/02 14:53:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 70.31	
[12/02 14:53:47 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.24089798182084843
[12/02 15:00:06 visual_prompt]: Epoch 22 / 100: avg data time: 9.94e+00, avg batch time: 10.8198, average train loss: 0.6176
[12/02 15:00:50 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.5396, average loss: 0.6181
[12/02 15:00:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 69.51	rocauc: 70.47	
[12/02 15:00:50 visual_prompt]: Best epoch 22: best metric: -0.618
[12/02 15:00:50 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.2391931822053251
[12/02 15:07:06 visual_prompt]: Epoch 23 / 100: avg data time: 9.88e+00, avg batch time: 10.7571, average train loss: 0.6171
[12/02 15:07:50 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.5315, average loss: 0.6332
[12/02 15:07:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 70.41	
[12/02 15:07:50 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.23734925578739588
[12/02 15:14:07 visual_prompt]: Epoch 24 / 100: avg data time: 9.88e+00, avg batch time: 10.7620, average train loss: 0.6464
[12/02 15:14:50 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.5361, average loss: 0.6277
[12/02 15:14:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 71.63	
[12/02 15:14:50 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.23536844910736587
[12/02 15:21:13 visual_prompt]: Epoch 25 / 100: avg data time: 1.00e+01, avg batch time: 10.9131, average train loss: 0.5836
[12/02 15:21:57 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.5364, average loss: 0.6340
[12/02 15:21:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.07	rocauc: 70.90	
[12/02 15:21:57 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.23325317547305485
[12/02 15:28:16 visual_prompt]: Epoch 26 / 100: avg data time: 9.93e+00, avg batch time: 10.8074, average train loss: 0.6073
[12/02 15:29:00 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.5335, average loss: 0.6358
[12/02 15:29:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 70.95	
[12/02 15:29:00 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.23100601201955323
[12/02 15:35:20 visual_prompt]: Epoch 27 / 100: avg data time: 9.98e+00, avg batch time: 10.8622, average train loss: 0.5680
[12/02 15:36:04 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.5306, average loss: 0.6384
[12/02 15:36:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 69.52	
[12/02 15:36:04 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.2286296965693802
[12/02 15:42:21 visual_prompt]: Epoch 28 / 100: avg data time: 9.88e+00, avg batch time: 10.7608, average train loss: 0.6004
[12/02 15:43:04 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.5375, average loss: 0.6263
[12/02 15:43:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 71.07	
[12/02 15:43:04 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.22612712429686843
[12/02 15:49:22 visual_prompt]: Epoch 29 / 100: avg data time: 9.92e+00, avg batch time: 10.7982, average train loss: 0.5459
[12/02 15:50:06 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.5363, average loss: 0.6508
[12/02 15:50:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 72.42	
[12/02 15:50:06 visual_prompt]: Stopping early.
[12/02 15:50:06 visual_prompt]: Rank of current process: 0. World size: 1
[12/02 15:50:06 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA TITAN Xp
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[12/02 15:50:06 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss', 'RECORD_GPU_SNAPSHOT', 'True'])
[12/02 15:50:06 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[12/02 15:50:06 visual_prompt]: Training with config:
[12/02 15:50:06 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr0.25_wd0.0/patience7/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.25, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True}), 'RECORD_GPU_SNAPSHOT': True})
[12/02 15:50:06 visual_prompt]: Loading training data...
[12/02 15:50:06 visual_prompt]: Constructing mammo-cbis dataset train...
[12/02 15:50:06 visual_prompt]: Loading validation data...
[12/02 15:50:06 visual_prompt]: Constructing mammo-cbis dataset val...
[12/02 15:50:06 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[12/02 15:50:09 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[12/02 15:50:09 visual_prompt]: tuned percent:0.536
[12/02 15:50:09 visual_prompt]: Device used for model: 0
[12/02 15:50:09 visual_prompt]: Setting up Evaluator...
[12/02 15:50:09 visual_prompt]: Setting up Trainer...
[12/02 15:50:09 visual_prompt]: 	Setting up the optimizer...
[12/02 15:50:09 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[12/02 15:56:26 visual_prompt]: Epoch 1 / 100: avg data time: 9.89e+00, avg batch time: 10.7736, average train loss: 1.4006
[12/02 15:57:10 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.5371, average loss: 1.2969
[12/02 15:57:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[12/02 15:57:10 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.025
[12/02 16:03:26 visual_prompt]: Epoch 2 / 100: avg data time: 9.87e+00, avg batch time: 10.7569, average train loss: 1.3998
[12/02 16:04:10 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.5356, average loss: 0.6927
[12/02 16:04:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 52.85	rocauc: 52.59	
[12/02 16:04:10 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.05
[12/02 16:10:27 visual_prompt]: Epoch 3 / 100: avg data time: 9.89e+00, avg batch time: 10.7691, average train loss: 0.7068
[12/02 16:11:11 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.5280, average loss: 0.6901
[12/02 16:11:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.44	
[12/02 16:11:11 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.075
[12/02 16:17:28 visual_prompt]: Epoch 4 / 100: avg data time: 9.87e+00, avg batch time: 10.7557, average train loss: 0.6954
[12/02 16:18:11 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.5404, average loss: 0.6818
[12/02 16:18:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.47	rocauc: 61.08	
[12/02 16:18:11 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.1
[12/02 16:24:30 visual_prompt]: Epoch 5 / 100: avg data time: 9.94e+00, avg batch time: 10.8197, average train loss: 0.7298
[12/02 16:25:14 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.5322, average loss: 0.6768
[12/02 16:25:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 61.16	
[12/02 16:25:14 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.125
[12/02 16:31:34 visual_prompt]: Epoch 6 / 100: avg data time: 9.95e+00, avg batch time: 10.8364, average train loss: 0.7235
[12/02 16:32:17 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.5309, average loss: 0.6786
[12/02 16:32:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 60.43	
[12/02 16:32:17 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.15
[12/02 16:38:35 visual_prompt]: Epoch 7 / 100: avg data time: 9.90e+00, avg batch time: 10.7852, average train loss: 0.7058
[12/02 16:39:19 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.5343, average loss: 0.6726
[12/02 16:39:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 62.07	
[12/02 16:39:19 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.175
[12/02 16:45:35 visual_prompt]: Epoch 8 / 100: avg data time: 9.87e+00, avg batch time: 10.7538, average train loss: 0.7028
[12/02 16:46:19 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.5335, average loss: 0.6627
[12/02 16:46:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 63.58	
[12/02 16:46:19 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.2
[12/02 16:52:36 visual_prompt]: Epoch 9 / 100: avg data time: 9.90e+00, avg batch time: 10.7805, average train loss: 0.6906
[12/02 16:53:20 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.5309, average loss: 0.6973
[12/02 16:53:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 65.32	
[12/02 16:53:20 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.225
[12/02 16:59:37 visual_prompt]: Epoch 10 / 100: avg data time: 9.88e+00, avg batch time: 10.7665, average train loss: 0.6615
[12/02 17:00:21 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.5257, average loss: 0.6605
[12/02 17:00:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 69.69	
[12/02 17:00:21 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.25
[12/02 17:06:38 visual_prompt]: Epoch 11 / 100: avg data time: 9.88e+00, avg batch time: 10.7642, average train loss: 0.7127
[12/02 17:07:21 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.5349, average loss: 0.6634
[12/02 17:07:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 66.87	
[12/02 17:07:21 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.24992385337738698
[12/02 17:13:38 visual_prompt]: Epoch 12 / 100: avg data time: 9.88e+00, avg batch time: 10.7582, average train loss: 0.7097
[12/02 17:14:22 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.5382, average loss: 0.7196
[12/02 17:14:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 48.78	rocauc: 70.13	
[12/02 17:14:22 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.24969550628247802
[12/02 17:20:39 visual_prompt]: Epoch 13 / 100: avg data time: 9.89e+00, avg batch time: 10.7677, average train loss: 0.7467
[12/02 17:21:22 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.5310, average loss: 0.7449
[12/02 17:21:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 67.55	
[12/02 17:21:22 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.24931523692103416
[12/02 17:27:39 visual_prompt]: Epoch 14 / 100: avg data time: 9.87e+00, avg batch time: 10.7476, average train loss: 0.6998
[12/02 17:28:22 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.5378, average loss: 0.7401
[12/02 17:28:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 68.37	
[12/02 17:28:22 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.2487835085926963
[12/02 17:34:39 visual_prompt]: Epoch 15 / 100: avg data time: 9.89e+00, avg batch time: 10.7714, average train loss: 0.7203
[12/02 17:35:23 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.5361, average loss: 0.8722
[12/02 17:35:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 68.12	
[12/02 17:35:23 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.24810096912652602
[12/02 17:41:40 visual_prompt]: Epoch 16 / 100: avg data time: 9.88e+00, avg batch time: 10.7600, average train loss: 0.7196
[12/02 17:42:24 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.5346, average loss: 0.7834
[12/02 17:42:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 69.53	
[12/02 17:42:24 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.2472684500917257
[12/02 17:48:39 visual_prompt]: Epoch 17 / 100: avg data time: 9.85e+00, avg batch time: 10.7312, average train loss: 0.7361
[12/02 17:49:23 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.5287, average loss: 0.6575
[12/02 17:49:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 71.51	
[12/02 17:49:23 visual_prompt]: Best epoch 17: best metric: -0.658
[12/02 17:49:23 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.24628696578449955
[12/02 17:55:40 visual_prompt]: Epoch 18 / 100: avg data time: 9.88e+00, avg batch time: 10.7615, average train loss: 0.6802
[12/02 17:56:23 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.5327, average loss: 0.6272
[12/02 17:56:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 72.27	
[12/02 17:56:23 visual_prompt]: Best epoch 18: best metric: -0.627
[12/02 17:56:23 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.24515771199228986
[12/02 18:02:40 visual_prompt]: Epoch 19 / 100: avg data time: 9.87e+00, avg batch time: 10.7587, average train loss: 0.6803
[12/02 18:03:24 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.5220, average loss: 0.6235
[12/02 18:03:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 71.73	
[12/02 18:03:24 visual_prompt]: Best epoch 19: best metric: -0.623
[12/02 18:03:24 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.2438820645368942
[12/02 18:09:41 visual_prompt]: Epoch 20 / 100: avg data time: 9.89e+00, avg batch time: 10.7664, average train loss: 0.6284
[12/02 18:10:24 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.5382, average loss: 0.6809
[12/02 18:10:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 74.51	
[12/02 18:10:24 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.24246157759823855
[12/02 18:16:41 visual_prompt]: Epoch 21 / 100: avg data time: 9.86e+00, avg batch time: 10.7425, average train loss: 0.6413
[12/02 18:17:24 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.5259, average loss: 0.6545
[12/02 18:17:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 73.76	
[12/02 18:17:24 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.24089798182084843
[12/02 18:23:40 visual_prompt]: Epoch 22 / 100: avg data time: 9.87e+00, avg batch time: 10.7497, average train loss: 0.6220
[12/02 18:24:24 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.5346, average loss: 0.6073
[12/02 18:24:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 74.94	
[12/02 18:24:24 visual_prompt]: Best epoch 22: best metric: -0.607
[12/02 18:24:24 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.2391931822053251
[12/02 18:30:41 visual_prompt]: Epoch 23 / 100: avg data time: 9.87e+00, avg batch time: 10.7594, average train loss: 0.6162
[12/02 18:31:25 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.5376, average loss: 0.6185
[12/02 18:31:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 72.48	
[12/02 18:31:25 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.23734925578739588
[12/02 18:37:42 visual_prompt]: Epoch 24 / 100: avg data time: 9.89e+00, avg batch time: 10.7738, average train loss: 0.6590
[12/02 18:38:26 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.5308, average loss: 0.6061
[12/02 18:38:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 74.38	
[12/02 18:38:26 visual_prompt]: Best epoch 24: best metric: -0.606
[12/02 18:38:26 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.23536844910736587
[12/02 18:44:42 visual_prompt]: Epoch 25 / 100: avg data time: 9.88e+00, avg batch time: 10.7592, average train loss: 0.6153
[12/02 18:45:26 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.5315, average loss: 0.6538
[12/02 18:45:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 72.74	
[12/02 18:45:26 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.23325317547305485
[12/02 18:51:42 visual_prompt]: Epoch 26 / 100: avg data time: 9.86e+00, avg batch time: 10.7413, average train loss: 0.6378
[12/02 18:52:26 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.5348, average loss: 0.6557
[12/02 18:52:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 73.42	
[12/02 18:52:26 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.23100601201955323
[12/02 18:58:43 visual_prompt]: Epoch 27 / 100: avg data time: 9.88e+00, avg batch time: 10.7624, average train loss: 0.6134
[12/02 18:59:26 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.5353, average loss: 0.6482
[12/02 18:59:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 71.51	
[12/02 18:59:26 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.2286296965693802
[12/02 19:05:43 visual_prompt]: Epoch 28 / 100: avg data time: 9.87e+00, avg batch time: 10.7575, average train loss: 0.6374
[12/02 19:06:27 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.5340, average loss: 0.6291
[12/02 19:06:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 73.46	
[12/02 19:06:27 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.22612712429686843
[12/02 19:12:44 visual_prompt]: Epoch 29 / 100: avg data time: 9.90e+00, avg batch time: 10.7817, average train loss: 0.5715
[12/02 19:13:28 visual_prompt]: Inference (val):avg data time: 1.99e-05, avg batch time: 0.5435, average loss: 0.6299
[12/02 19:13:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 73.37	
[12/02 19:13:28 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.22350134420084022
[12/02 19:19:44 visual_prompt]: Epoch 30 / 100: avg data time: 9.88e+00, avg batch time: 10.7567, average train loss: 0.5590
[12/02 19:20:28 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.5284, average loss: 0.6130
[12/02 19:20:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.67	rocauc: 73.56	
[12/02 19:20:28 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.22075555538987224
[12/02 19:26:44 visual_prompt]: Epoch 31 / 100: avg data time: 9.86e+00, avg batch time: 10.7347, average train loss: 0.5512
[12/02 19:27:28 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.5307, average loss: 0.6459
[12/02 19:27:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 70.54	
[12/02 19:27:28 visual_prompt]: Stopping early.
[12/02 19:27:28 visual_prompt]: Rank of current process: 0. World size: 1
[12/02 19:27:28 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA TITAN Xp
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[12/02 19:27:28 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss', 'RECORD_GPU_SNAPSHOT', 'True'])
[12/02 19:27:28 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[12/02 19:27:28 visual_prompt]: Training with config:
[12/02 19:27:28 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr0.1_wd0.01/patience7/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.1, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True}), 'RECORD_GPU_SNAPSHOT': True})
[12/02 19:27:28 visual_prompt]: Loading training data...
[12/02 19:27:28 visual_prompt]: Constructing mammo-cbis dataset train...
[12/02 19:27:28 visual_prompt]: Loading validation data...
[12/02 19:27:28 visual_prompt]: Constructing mammo-cbis dataset val...
[12/02 19:27:28 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[12/02 19:27:31 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[12/02 19:27:31 visual_prompt]: tuned percent:0.536
[12/02 19:27:31 visual_prompt]: Device used for model: 0
[12/02 19:27:31 visual_prompt]: Setting up Evaluator...
[12/02 19:27:31 visual_prompt]: Setting up Trainer...
[12/02 19:27:31 visual_prompt]: 	Setting up the optimizer...
[12/02 19:27:32 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[12/02 19:33:50 visual_prompt]: Epoch 1 / 100: avg data time: 9.92e+00, avg batch time: 10.7994, average train loss: 1.4006
[12/02 19:34:34 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.5297, average loss: 1.2969
[12/02 19:34:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[12/02 19:34:34 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.010000000000000002
[12/02 19:40:51 visual_prompt]: Epoch 2 / 100: avg data time: 9.89e+00, avg batch time: 10.7689, average train loss: 1.0630
[12/02 19:41:35 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.5288, average loss: 0.6922
[12/02 19:41:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 46.93	
[12/02 19:41:35 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.020000000000000004
[12/02 19:47:52 visual_prompt]: Epoch 3 / 100: avg data time: 9.89e+00, avg batch time: 10.7724, average train loss: 0.7026
[12/02 19:48:36 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.5274, average loss: 0.6902
[12/02 19:48:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.15	
[12/02 19:48:36 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.03
[12/02 19:54:53 visual_prompt]: Epoch 4 / 100: avg data time: 9.88e+00, avg batch time: 10.7600, average train loss: 0.6950
[12/02 19:55:36 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.5192, average loss: 0.6836
[12/02 19:55:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 58.20	
[12/02 19:55:36 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.04000000000000001
[12/02 20:01:52 visual_prompt]: Epoch 5 / 100: avg data time: 9.85e+00, avg batch time: 10.7303, average train loss: 0.7119
[12/02 20:02:36 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.5376, average loss: 0.6957
[12/02 20:02:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.91	
[12/02 20:02:36 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.05
[12/02 20:09:02 visual_prompt]: Epoch 6 / 100: avg data time: 1.02e+01, avg batch time: 11.0506, average train loss: 0.7170
[12/02 20:09:48 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.5256, average loss: 0.6921
[12/02 20:09:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 51.63	rocauc: 56.90	
[12/02 20:09:48 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.06
[12/02 20:16:17 visual_prompt]: Epoch 7 / 100: avg data time: 1.02e+01, avg batch time: 11.1187, average train loss: 0.6945
[12/02 20:17:01 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.5257, average loss: 0.6802
[12/02 20:17:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.03	
[12/02 20:17:01 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.06999999999999999
[12/02 20:23:17 visual_prompt]: Epoch 8 / 100: avg data time: 9.87e+00, avg batch time: 10.7517, average train loss: 0.6875
[12/02 20:24:01 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.5305, average loss: 0.6762
[12/02 20:24:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 63.08	
[12/02 20:24:01 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.08000000000000002
[12/02 20:30:19 visual_prompt]: Epoch 9 / 100: avg data time: 9.91e+00, avg batch time: 10.7902, average train loss: 0.7006
[12/02 20:31:02 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.5251, average loss: 0.6811
[12/02 20:31:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 61.79	
[12/02 20:31:02 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.09000000000000001
[12/02 20:37:19 visual_prompt]: Epoch 10 / 100: avg data time: 9.88e+00, avg batch time: 10.7637, average train loss: 0.6889
[12/02 20:38:03 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.5233, average loss: 0.6994
[12/02 20:38:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 51.63	rocauc: 64.16	
[12/02 20:38:03 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.1
[12/02 20:44:20 visual_prompt]: Epoch 11 / 100: avg data time: 9.88e+00, avg batch time: 10.7648, average train loss: 0.6863
[12/02 20:45:04 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.5239, average loss: 0.6666
[12/02 20:45:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 65.53	
[12/02 20:45:04 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0999695413509548
[12/02 20:51:20 visual_prompt]: Epoch 12 / 100: avg data time: 9.88e+00, avg batch time: 10.7596, average train loss: 0.7056
[12/02 20:52:04 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.5373, average loss: 0.7029
[12/02 20:52:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.88	
[12/02 20:52:04 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.09987820251299122
[12/02 20:58:21 visual_prompt]: Epoch 13 / 100: avg data time: 9.89e+00, avg batch time: 10.7658, average train loss: 0.7226
[12/02 20:59:05 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.5258, average loss: 0.7146
[12/02 20:59:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.38	
[12/02 20:59:05 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.09972609476841367
[12/02 21:05:20 visual_prompt]: Epoch 14 / 100: avg data time: 9.84e+00, avg batch time: 10.7279, average train loss: 0.7065
[12/02 21:06:04 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.5189, average loss: 0.6999
[12/02 21:06:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.49	
[12/02 21:06:04 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.09951340343707853
[12/02 21:12:21 visual_prompt]: Epoch 15 / 100: avg data time: 9.89e+00, avg batch time: 10.7725, average train loss: 0.6926
[12/02 21:13:05 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.5384, average loss: 0.6911
[12/02 21:13:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.53	
[12/02 21:13:05 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.09924038765061041
[12/02 21:19:21 visual_prompt]: Epoch 16 / 100: avg data time: 9.87e+00, avg batch time: 10.7517, average train loss: 0.6965
[12/02 21:20:05 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.5354, average loss: 0.6890
[12/02 21:20:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.76	
[12/02 21:20:05 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.09890738003669029
[12/02 21:26:22 visual_prompt]: Epoch 17 / 100: avg data time: 9.87e+00, avg batch time: 10.7571, average train loss: 0.6996
[12/02 21:27:06 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.5383, average loss: 0.6901
[12/02 21:27:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.14	
[12/02 21:27:06 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.09851478631379983
[12/02 21:33:22 visual_prompt]: Epoch 18 / 100: avg data time: 9.87e+00, avg batch time: 10.7541, average train loss: 0.6915
[12/02 21:34:06 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.5279, average loss: 0.6987
[12/02 21:34:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.98	
[12/02 21:34:06 visual_prompt]: Stopping early.
[12/02 21:34:06 visual_prompt]: Rank of current process: 0. World size: 1
[12/02 21:34:06 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA TITAN Xp
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[12/02 21:34:06 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss', 'RECORD_GPU_SNAPSHOT', 'True'])
[12/02 21:34:06 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[12/02 21:34:06 visual_prompt]: Training with config:
[12/02 21:34:06 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr0.1_wd0.001/patience7/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.1, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True}), 'RECORD_GPU_SNAPSHOT': True})
[12/02 21:34:06 visual_prompt]: Loading training data...
[12/02 21:34:06 visual_prompt]: Constructing mammo-cbis dataset train...
[12/02 21:34:06 visual_prompt]: Loading validation data...
[12/02 21:34:06 visual_prompt]: Constructing mammo-cbis dataset val...
[12/02 21:34:06 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[12/02 21:34:09 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[12/02 21:34:09 visual_prompt]: tuned percent:0.536
[12/02 21:34:09 visual_prompt]: Device used for model: 0
[12/02 21:34:09 visual_prompt]: Setting up Evaluator...
[12/02 21:34:09 visual_prompt]: Setting up Trainer...
[12/02 21:34:09 visual_prompt]: 	Setting up the optimizer...
[12/02 21:34:09 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[12/02 21:40:27 visual_prompt]: Epoch 1 / 100: avg data time: 9.91e+00, avg batch time: 10.7833, average train loss: 1.4006
[12/02 21:41:11 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.5289, average loss: 1.2969
[12/02 21:41:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[12/02 21:41:11 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.010000000000000002
[12/02 21:47:27 visual_prompt]: Epoch 2 / 100: avg data time: 9.89e+00, avg batch time: 10.7635, average train loss: 1.0646
[12/02 21:48:11 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.5282, average loss: 0.6923
[12/02 21:48:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 46.91	
[12/02 21:48:11 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.020000000000000004
[12/02 21:54:28 visual_prompt]: Epoch 3 / 100: avg data time: 9.89e+00, avg batch time: 10.7636, average train loss: 0.7040
[12/02 21:55:12 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.5293, average loss: 0.6901
[12/02 21:55:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.62	
[12/02 21:55:12 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.03
[12/02 22:01:29 visual_prompt]: Epoch 4 / 100: avg data time: 9.88e+00, avg batch time: 10.7611, average train loss: 0.6971
[12/02 22:02:12 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.5321, average loss: 0.6830
[12/02 22:02:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 57.59	
[12/02 22:02:12 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.04000000000000001
[12/02 22:08:29 visual_prompt]: Epoch 5 / 100: avg data time: 9.87e+00, avg batch time: 10.7512, average train loss: 0.7164
[12/02 22:09:13 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.5307, average loss: 0.6955
[12/02 22:09:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.97	
[12/02 22:09:13 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.05
[12/02 22:15:30 visual_prompt]: Epoch 6 / 100: avg data time: 9.91e+00, avg batch time: 10.7854, average train loss: 0.7295
[12/02 22:16:14 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.5322, average loss: 0.7194
[12/02 22:16:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.85	
[12/02 22:16:14 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.06
[12/02 22:22:31 visual_prompt]: Epoch 7 / 100: avg data time: 9.90e+00, avg batch time: 10.7721, average train loss: 0.7010
[12/02 22:23:15 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.5351, average loss: 0.6786
[12/02 22:23:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 60.29	
[12/02 22:23:15 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.06999999999999999
[12/02 22:29:31 visual_prompt]: Epoch 8 / 100: avg data time: 9.87e+00, avg batch time: 10.7467, average train loss: 0.6836
[12/02 22:30:15 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.5287, average loss: 0.6707
[12/02 22:30:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 65.26	
[12/02 22:30:15 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.08000000000000002
[12/02 22:36:32 visual_prompt]: Epoch 9 / 100: avg data time: 9.91e+00, avg batch time: 10.7818, average train loss: 0.7084
[12/02 22:37:16 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.5341, average loss: 0.7444
[12/02 22:37:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 65.52	
[12/02 22:37:16 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.09000000000000001
[12/02 22:43:33 visual_prompt]: Epoch 10 / 100: avg data time: 9.88e+00, avg batch time: 10.7574, average train loss: 0.7248
[12/02 22:44:16 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.5318, average loss: 0.6712
[12/02 22:44:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 63.61	
[12/02 22:44:16 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.1
[12/02 22:50:32 visual_prompt]: Epoch 11 / 100: avg data time: 9.87e+00, avg batch time: 10.7407, average train loss: 0.6899
[12/02 22:51:16 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.5310, average loss: 0.6614
[12/02 22:51:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 65.98	
[12/02 22:51:16 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0999695413509548
[12/02 22:57:33 visual_prompt]: Epoch 12 / 100: avg data time: 9.88e+00, avg batch time: 10.7541, average train loss: 0.6753
[12/02 22:58:16 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.5330, average loss: 0.6741
[12/02 22:58:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 68.37	
[12/02 22:58:16 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.09987820251299122
[12/02 23:04:33 visual_prompt]: Epoch 13 / 100: avg data time: 9.89e+00, avg batch time: 10.7682, average train loss: 0.6979
[12/02 23:05:17 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.5271, average loss: 0.6528
[12/02 23:05:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 68.03	
[12/02 23:05:17 visual_prompt]: Best epoch 13: best metric: -0.653
[12/02 23:05:17 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.09972609476841367
[12/02 23:11:33 visual_prompt]: Epoch 14 / 100: avg data time: 9.87e+00, avg batch time: 10.7455, average train loss: 0.6825
[12/02 23:12:17 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.5317, average loss: 0.6605
[12/02 23:12:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 69.33	
[12/02 23:12:17 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.09951340343707853
[12/02 23:18:34 visual_prompt]: Epoch 15 / 100: avg data time: 9.90e+00, avg batch time: 10.7669, average train loss: 0.6844
[12/02 23:19:18 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.5401, average loss: 0.6708
[12/02 23:19:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 69.04	
[12/02 23:19:18 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.09924038765061041
[12/02 23:25:35 visual_prompt]: Epoch 16 / 100: avg data time: 9.91e+00, avg batch time: 10.7827, average train loss: 0.6903
[12/02 23:26:19 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.5321, average loss: 0.7292
[12/02 23:26:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 68.88	
[12/02 23:26:19 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.09890738003669029
[12/02 23:32:35 visual_prompt]: Epoch 17 / 100: avg data time: 9.86e+00, avg batch time: 10.7418, average train loss: 0.6759
[12/02 23:33:19 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.5329, average loss: 0.6350
[12/02 23:33:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 69.06	
[12/02 23:33:19 visual_prompt]: Best epoch 17: best metric: -0.635
[12/02 23:33:19 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.09851478631379983
[12/02 23:39:35 visual_prompt]: Epoch 18 / 100: avg data time: 9.87e+00, avg batch time: 10.7468, average train loss: 0.6964
[12/02 23:40:19 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.5339, average loss: 0.7873
[12/02 23:40:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 68.92	
[12/02 23:40:19 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.09806308479691594
[12/02 23:46:35 visual_prompt]: Epoch 19 / 100: avg data time: 9.86e+00, avg batch time: 10.7364, average train loss: 0.6865
[12/02 23:47:19 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.5300, average loss: 0.8016
[12/02 23:47:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 68.89	
[12/02 23:47:19 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.09755282581475769
[12/02 23:53:35 visual_prompt]: Epoch 20 / 100: avg data time: 9.87e+00, avg batch time: 10.7469, average train loss: 0.6707
[12/02 23:54:18 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.5303, average loss: 0.7012
[12/02 23:54:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 70.50	
[12/02 23:54:18 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.09698463103929543
[12/03 00:00:34 visual_prompt]: Epoch 21 / 100: avg data time: 9.86e+00, avg batch time: 10.7411, average train loss: 0.6449
[12/03 00:01:18 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.5335, average loss: 0.6284
[12/03 00:01:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.89	rocauc: 69.80	
[12/03 00:01:18 visual_prompt]: Best epoch 21: best metric: -0.628
[12/03 00:01:18 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.09635919272833937
[12/03 00:07:34 visual_prompt]: Epoch 22 / 100: avg data time: 9.85e+00, avg batch time: 10.7325, average train loss: 0.6254
[12/03 00:08:18 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.5324, average loss: 0.6457
[12/03 00:08:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 72.54	
[12/03 00:08:18 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.09567727288213004
[12/03 00:14:35 visual_prompt]: Epoch 23 / 100: avg data time: 9.89e+00, avg batch time: 10.7667, average train loss: 0.6202
[12/03 00:15:19 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.5318, average loss: 0.6283
[12/03 00:15:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 70.45	
[12/03 00:15:19 visual_prompt]: Best epoch 23: best metric: -0.628
[12/03 00:15:19 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.09493970231495835
[12/03 00:21:37 visual_prompt]: Epoch 24 / 100: avg data time: 9.93e+00, avg batch time: 10.8017, average train loss: 0.6228
[12/03 00:22:21 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.5326, average loss: 0.6087
[12/03 00:22:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.67	rocauc: 72.85	
[12/03 00:22:21 visual_prompt]: Best epoch 24: best metric: -0.609
[12/03 00:22:21 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.09414737964294635
[12/03 00:28:36 visual_prompt]: Epoch 25 / 100: avg data time: 9.86e+00, avg batch time: 10.7341, average train loss: 0.6183
[12/03 00:29:20 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.5349, average loss: 0.6688
[12/03 00:29:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.01	rocauc: 71.23	
[12/03 00:29:20 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.09330127018922195
[12/03 00:35:37 visual_prompt]: Epoch 26 / 100: avg data time: 9.87e+00, avg batch time: 10.7481, average train loss: 0.6413
[12/03 00:36:20 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.5354, average loss: 0.6065
[12/03 00:36:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 73.20	
[12/03 00:36:20 visual_prompt]: Best epoch 26: best metric: -0.606
[12/03 00:36:20 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.0924024048078213
[12/03 00:42:37 visual_prompt]: Epoch 27 / 100: avg data time: 9.88e+00, avg batch time: 10.7582, average train loss: 0.6044
[12/03 00:43:21 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.5304, average loss: 0.6858
[12/03 00:43:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 69.11	
[12/03 00:43:21 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.09145187862775209
[12/03 00:49:37 visual_prompt]: Epoch 28 / 100: avg data time: 9.87e+00, avg batch time: 10.7473, average train loss: 0.6171
[12/03 00:50:21 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.5351, average loss: 0.6262
[12/03 00:50:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 70.50	
[12/03 00:50:21 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.09045084971874738
[12/03 00:56:38 visual_prompt]: Epoch 29 / 100: avg data time: 9.90e+00, avg batch time: 10.7749, average train loss: 0.5925
[12/03 00:57:21 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.5313, average loss: 0.6283
[12/03 00:57:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.89	rocauc: 71.59	
[12/03 00:57:21 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.0894005376803361
[12/03 01:03:38 visual_prompt]: Epoch 30 / 100: avg data time: 9.87e+00, avg batch time: 10.7508, average train loss: 0.5831
[12/03 01:04:22 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.5230, average loss: 0.6370
[12/03 01:04:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.67	rocauc: 69.32	
[12/03 01:04:22 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.0883022221559489
[12/03 01:10:38 visual_prompt]: Epoch 31 / 100: avg data time: 9.87e+00, avg batch time: 10.7425, average train loss: 0.6129
[12/03 01:11:21 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.5322, average loss: 0.6383
[12/03 01:11:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 68.93	
[12/03 01:11:21 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.08715724127386971
[12/03 01:17:38 visual_prompt]: Epoch 32 / 100: avg data time: 9.88e+00, avg batch time: 10.7569, average train loss: 0.6110
[12/03 01:18:22 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.5260, average loss: 0.6974
[12/03 01:18:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 69.41	
[12/03 01:18:22 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.08596699001693256
[12/03 01:24:38 visual_prompt]: Epoch 33 / 100: avg data time: 9.87e+00, avg batch time: 10.7485, average train loss: 0.5952
[12/03 01:25:22 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.5411, average loss: 0.6205
[12/03 01:25:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 72.10	
[12/03 01:25:22 visual_prompt]: Stopping early.
[12/03 01:25:22 visual_prompt]: Rank of current process: 0. World size: 1
[12/03 01:25:22 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA TITAN Xp
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[12/03 01:25:22 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss', 'RECORD_GPU_SNAPSHOT', 'True'])
[12/03 01:25:22 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[12/03 01:25:22 visual_prompt]: Training with config:
[12/03 01:25:22 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr0.1_wd0.0001/patience7/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.1, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True}), 'RECORD_GPU_SNAPSHOT': True})
[12/03 01:25:22 visual_prompt]: Loading training data...
[12/03 01:25:22 visual_prompt]: Constructing mammo-cbis dataset train...
[12/03 01:25:22 visual_prompt]: Loading validation data...
[12/03 01:25:22 visual_prompt]: Constructing mammo-cbis dataset val...
[12/03 01:25:22 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[12/03 01:25:24 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[12/03 01:25:24 visual_prompt]: tuned percent:0.536
[12/03 01:25:24 visual_prompt]: Device used for model: 0
[12/03 01:25:24 visual_prompt]: Setting up Evaluator...
[12/03 01:25:24 visual_prompt]: Setting up Trainer...
[12/03 01:25:24 visual_prompt]: 	Setting up the optimizer...
[12/03 01:25:24 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[12/03 01:31:41 visual_prompt]: Epoch 1 / 100: avg data time: 9.88e+00, avg batch time: 10.7574, average train loss: 1.4006
[12/03 01:32:25 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.5270, average loss: 1.2969
[12/03 01:32:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[12/03 01:32:25 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.010000000000000002
[12/03 01:38:41 visual_prompt]: Epoch 2 / 100: avg data time: 9.86e+00, avg batch time: 10.7403, average train loss: 1.0648
[12/03 01:39:24 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.5296, average loss: 0.6923
[12/03 01:39:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 46.91	
[12/03 01:39:24 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.020000000000000004
[12/03 01:45:41 visual_prompt]: Epoch 3 / 100: avg data time: 9.87e+00, avg batch time: 10.7496, average train loss: 0.7041
[12/03 01:46:24 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.5280, average loss: 0.6901
[12/03 01:46:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.55	
[12/03 01:46:24 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.03
[12/03 01:52:40 visual_prompt]: Epoch 4 / 100: avg data time: 9.86e+00, avg batch time: 10.7351, average train loss: 0.6973
[12/03 01:53:24 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.5307, average loss: 0.6827
[12/03 01:53:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 57.64	
[12/03 01:53:24 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.04000000000000001
[12/03 01:59:40 visual_prompt]: Epoch 5 / 100: avg data time: 9.88e+00, avg batch time: 10.7550, average train loss: 0.7166
[12/03 02:00:24 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.5312, average loss: 0.6965
[12/03 02:00:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.24	
[12/03 02:00:24 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.05
[12/03 02:06:41 visual_prompt]: Epoch 6 / 100: avg data time: 9.89e+00, avg batch time: 10.7636, average train loss: 0.7292
[12/03 02:07:25 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.5374, average loss: 0.7232
[12/03 02:07:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.00	
[12/03 02:07:25 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.06
[12/03 02:13:41 visual_prompt]: Epoch 7 / 100: avg data time: 9.87e+00, avg batch time: 10.7492, average train loss: 0.7056
[12/03 02:14:25 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.5336, average loss: 0.7081
[12/03 02:14:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.20	
[12/03 02:14:25 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.06999999999999999
[12/03 02:20:40 visual_prompt]: Epoch 8 / 100: avg data time: 9.85e+00, avg batch time: 10.7307, average train loss: 0.7094
[12/03 02:21:24 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.5284, average loss: 0.6814
[12/03 02:21:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 64.79	
[12/03 02:21:24 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.08000000000000002
[12/03 02:27:41 visual_prompt]: Epoch 9 / 100: avg data time: 9.88e+00, avg batch time: 10.7586, average train loss: 0.6930
[12/03 02:28:24 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.5325, average loss: 0.7383
[12/03 02:28:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 65.81	
[12/03 02:28:24 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.09000000000000001
[12/03 02:34:41 visual_prompt]: Epoch 10 / 100: avg data time: 9.88e+00, avg batch time: 10.7530, average train loss: 0.6798
[12/03 02:35:24 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.5311, average loss: 0.6565
[12/03 02:35:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 66.76	
[12/03 02:35:24 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.1
[12/03 02:41:41 visual_prompt]: Epoch 11 / 100: avg data time: 9.88e+00, avg batch time: 10.7547, average train loss: 0.6904
[12/03 02:42:25 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.5333, average loss: 0.6584
[12/03 02:42:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 67.31	
[12/03 02:42:25 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0999695413509548
[12/03 02:48:41 visual_prompt]: Epoch 12 / 100: avg data time: 9.88e+00, avg batch time: 10.7558, average train loss: 0.6776
[12/03 02:49:25 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.5311, average loss: 0.6660
[12/03 02:49:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 69.41	
[12/03 02:49:25 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.09987820251299122
[12/03 02:55:42 visual_prompt]: Epoch 13 / 100: avg data time: 9.88e+00, avg batch time: 10.7600, average train loss: 0.7074
[12/03 02:56:25 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.5325, average loss: 0.6549
[12/03 02:56:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 67.21	
[12/03 02:56:25 visual_prompt]: Best epoch 13: best metric: -0.655
[12/03 02:56:25 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.09972609476841367
[12/03 03:02:42 visual_prompt]: Epoch 14 / 100: avg data time: 9.89e+00, avg batch time: 10.7743, average train loss: 0.6919
[12/03 03:03:26 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.5277, average loss: 0.6548
[12/03 03:03:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 69.72	
[12/03 03:03:26 visual_prompt]: Best epoch 14: best metric: -0.655
[12/03 03:03:26 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.09951340343707853
[12/03 03:09:49 visual_prompt]: Epoch 15 / 100: avg data time: 1.00e+01, avg batch time: 10.9204, average train loss: 0.6924
[12/03 03:10:33 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.5309, average loss: 0.6543
[12/03 03:10:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 69.86	
[12/03 03:10:33 visual_prompt]: Best epoch 15: best metric: -0.654
[12/03 03:10:33 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.09924038765061041
[12/03 03:16:51 visual_prompt]: Epoch 16 / 100: avg data time: 9.91e+00, avg batch time: 10.7913, average train loss: 0.6812
[12/03 03:17:34 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.5306, average loss: 0.6672
[12/03 03:17:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.54	rocauc: 68.77	
[12/03 03:17:34 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.09890738003669029
[12/03 03:23:51 visual_prompt]: Epoch 17 / 100: avg data time: 9.87e+00, avg batch time: 10.7442, average train loss: 0.6736
[12/03 03:24:34 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.5260, average loss: 0.6371
[12/03 03:24:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 70.09	
[12/03 03:24:34 visual_prompt]: Best epoch 17: best metric: -0.637
[12/03 03:24:34 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.09851478631379983
[12/03 03:30:51 visual_prompt]: Epoch 18 / 100: avg data time: 9.88e+00, avg batch time: 10.7622, average train loss: 0.6999
[12/03 03:31:35 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.5216, average loss: 0.8801
[12/03 03:31:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 69.45	
[12/03 03:31:35 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.09806308479691594
[12/03 03:37:51 visual_prompt]: Epoch 19 / 100: avg data time: 9.85e+00, avg batch time: 10.7315, average train loss: 0.6889
[12/03 03:38:34 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.5316, average loss: 0.8524
[12/03 03:38:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 69.76	
[12/03 03:38:34 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.09755282581475769
[12/03 03:44:50 visual_prompt]: Epoch 20 / 100: avg data time: 9.85e+00, avg batch time: 10.7282, average train loss: 0.6992
[12/03 03:45:34 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.5276, average loss: 0.6865
[12/03 03:45:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.54	rocauc: 70.43	
[12/03 03:45:34 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.09698463103929543
[12/03 03:51:50 visual_prompt]: Epoch 21 / 100: avg data time: 9.86e+00, avg batch time: 10.7416, average train loss: 0.6562
[12/03 03:52:33 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.5283, average loss: 0.6242
[12/03 03:52:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.67	rocauc: 70.27	
[12/03 03:52:33 visual_prompt]: Best epoch 21: best metric: -0.624
[12/03 03:52:33 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.09635919272833937
[12/03 03:58:49 visual_prompt]: Epoch 22 / 100: avg data time: 9.86e+00, avg batch time: 10.7363, average train loss: 0.6281
[12/03 03:59:33 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.5269, average loss: 0.6283
[12/03 03:59:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 69.22	
[12/03 03:59:33 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.09567727288213004
[12/03 04:05:48 visual_prompt]: Epoch 23 / 100: avg data time: 9.84e+00, avg batch time: 10.7253, average train loss: 0.6210
[12/03 04:06:32 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.5234, average loss: 0.6302
[12/03 04:06:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.07	rocauc: 69.38	
[12/03 04:06:32 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.09493970231495835
[12/03 04:12:49 visual_prompt]: Epoch 24 / 100: avg data time: 9.87e+00, avg batch time: 10.7529, average train loss: 0.6281
[12/03 04:13:32 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.5321, average loss: 0.6145
[12/03 04:13:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 71.20	
[12/03 04:13:32 visual_prompt]: Best epoch 24: best metric: -0.614
[12/03 04:13:32 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.09414737964294635
[12/03 04:19:48 visual_prompt]: Epoch 25 / 100: avg data time: 9.86e+00, avg batch time: 10.7328, average train loss: 0.6163
[12/03 04:20:32 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.5250, average loss: 0.6706
[12/03 04:20:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 70.87	
[12/03 04:20:32 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.09330127018922195
[12/03 04:26:48 visual_prompt]: Epoch 26 / 100: avg data time: 9.85e+00, avg batch time: 10.7361, average train loss: 0.6184
[12/03 04:27:31 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.5276, average loss: 0.6379
[12/03 04:27:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 71.56	
[12/03 04:27:31 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.0924024048078213
[12/03 04:33:47 visual_prompt]: Epoch 27 / 100: avg data time: 9.86e+00, avg batch time: 10.7427, average train loss: 0.6041
[12/03 04:34:31 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.5296, average loss: 0.6473
[12/03 04:34:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 67.79	
[12/03 04:34:31 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.09145187862775209
[12/03 04:40:46 visual_prompt]: Epoch 28 / 100: avg data time: 9.85e+00, avg batch time: 10.7269, average train loss: 0.6275
[12/03 04:41:30 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.5292, average loss: 0.6745
[12/03 04:41:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 69.33	
[12/03 04:41:30 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.09045084971874738
[12/03 04:47:47 visual_prompt]: Epoch 29 / 100: avg data time: 9.89e+00, avg batch time: 10.7650, average train loss: 0.5989
[12/03 04:48:30 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.5299, average loss: 0.6556
[12/03 04:48:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 71.17	
[12/03 04:48:30 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.0894005376803361
[12/03 04:54:46 visual_prompt]: Epoch 30 / 100: avg data time: 9.86e+00, avg batch time: 10.7378, average train loss: 0.5874
[12/03 04:55:30 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.5251, average loss: 0.6797
[12/03 04:55:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 69.70	
[12/03 04:55:30 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.0883022221559489
[12/03 05:01:46 visual_prompt]: Epoch 31 / 100: avg data time: 9.87e+00, avg batch time: 10.7485, average train loss: 0.5654
[12/03 05:02:30 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.5277, average loss: 0.6841
[12/03 05:02:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 69.78	
[12/03 05:02:30 visual_prompt]: Stopping early.
[12/03 05:02:30 visual_prompt]: Rank of current process: 0. World size: 1
[12/03 05:02:30 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA TITAN Xp
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[12/03 05:02:30 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss', 'RECORD_GPU_SNAPSHOT', 'True'])
[12/03 05:02:30 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[12/03 05:02:30 visual_prompt]: Training with config:
[12/03 05:02:30 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr0.1_wd0.0/patience7/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.1, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True}), 'RECORD_GPU_SNAPSHOT': True})
[12/03 05:02:30 visual_prompt]: Loading training data...
[12/03 05:02:30 visual_prompt]: Constructing mammo-cbis dataset train...
[12/03 05:02:30 visual_prompt]: Loading validation data...
[12/03 05:02:30 visual_prompt]: Constructing mammo-cbis dataset val...
[12/03 05:02:30 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[12/03 05:02:33 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[12/03 05:02:33 visual_prompt]: tuned percent:0.536
[12/03 05:02:33 visual_prompt]: Device used for model: 0
[12/03 05:02:33 visual_prompt]: Setting up Evaluator...
[12/03 05:02:33 visual_prompt]: Setting up Trainer...
[12/03 05:02:33 visual_prompt]: 	Setting up the optimizer...
[12/03 05:02:33 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[12/03 05:08:50 visual_prompt]: Epoch 1 / 100: avg data time: 9.90e+00, avg batch time: 10.7794, average train loss: 1.4006
[12/03 05:09:34 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.5293, average loss: 1.2969
[12/03 05:09:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[12/03 05:09:34 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.010000000000000002
[12/03 05:15:51 visual_prompt]: Epoch 2 / 100: avg data time: 9.88e+00, avg batch time: 10.7567, average train loss: 1.0648
[12/03 05:16:34 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.5319, average loss: 0.6923
[12/03 05:16:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 46.91	
[12/03 05:16:34 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.020000000000000004
[12/03 05:22:52 visual_prompt]: Epoch 3 / 100: avg data time: 9.90e+00, avg batch time: 10.7818, average train loss: 0.7041
[12/03 05:23:36 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.5307, average loss: 0.6901
[12/03 05:23:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.56	
[12/03 05:23:36 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.03
[12/03 05:29:53 visual_prompt]: Epoch 4 / 100: avg data time: 9.90e+00, avg batch time: 10.7787, average train loss: 0.6973
[12/03 05:30:37 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.5290, average loss: 0.6826
[12/03 05:30:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 57.74	
[12/03 05:30:37 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.04000000000000001
[12/03 05:36:53 visual_prompt]: Epoch 5 / 100: avg data time: 9.87e+00, avg batch time: 10.7535, average train loss: 0.7168
[12/03 05:37:37 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.5268, average loss: 0.6961
[12/03 05:37:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.09	
[12/03 05:37:37 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.05
[12/03 05:43:54 visual_prompt]: Epoch 6 / 100: avg data time: 9.90e+00, avg batch time: 10.7851, average train loss: 0.7304
[12/03 05:44:38 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.5299, average loss: 0.7251
[12/03 05:44:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.72	
[12/03 05:44:38 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.06
[12/03 05:50:56 visual_prompt]: Epoch 7 / 100: avg data time: 9.90e+00, avg batch time: 10.7757, average train loss: 0.7062
[12/03 05:51:39 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.5312, average loss: 0.6822
[12/03 05:51:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 59.97	
[12/03 05:51:39 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.06999999999999999
[12/03 05:57:58 visual_prompt]: Epoch 8 / 100: avg data time: 9.93e+00, avg batch time: 10.8152, average train loss: 0.6860
[12/03 05:58:42 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.5308, average loss: 0.6780
[12/03 05:58:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 65.02	
[12/03 05:58:42 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.08000000000000002
[12/03 06:04:59 visual_prompt]: Epoch 9 / 100: avg data time: 9.90e+00, avg batch time: 10.7838, average train loss: 0.6877
[12/03 06:05:43 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.5337, average loss: 0.7273
[12/03 06:05:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 66.58	
[12/03 06:05:43 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.09000000000000001
[12/03 06:12:00 visual_prompt]: Epoch 10 / 100: avg data time: 9.88e+00, avg batch time: 10.7542, average train loss: 0.6693
[12/03 06:12:43 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.5283, average loss: 0.6518
[12/03 06:12:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 67.76	
[12/03 06:12:43 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.1
[12/03 06:19:00 visual_prompt]: Epoch 11 / 100: avg data time: 9.87e+00, avg batch time: 10.7492, average train loss: 0.6830
[12/03 06:19:43 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.5218, average loss: 0.6505
[12/03 06:19:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 68.91	
[12/03 06:19:43 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0999695413509548
[12/03 06:25:59 visual_prompt]: Epoch 12 / 100: avg data time: 9.87e+00, avg batch time: 10.7476, average train loss: 0.6791
[12/03 06:26:43 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.5301, average loss: 0.7141
[12/03 06:26:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 52.03	rocauc: 69.56	
[12/03 06:26:43 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.09987820251299122
[12/03 06:33:00 visual_prompt]: Epoch 13 / 100: avg data time: 9.87e+00, avg batch time: 10.7531, average train loss: 0.6893
[12/03 06:33:43 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.5266, average loss: 0.6392
[12/03 06:33:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 69.34	
[12/03 06:33:43 visual_prompt]: Best epoch 13: best metric: -0.639
[12/03 06:33:43 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.09972609476841367
[12/03 06:39:59 visual_prompt]: Epoch 14 / 100: avg data time: 9.85e+00, avg batch time: 10.7216, average train loss: 0.6826
[12/03 06:40:42 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.5293, average loss: 0.6497
[12/03 06:40:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 68.12	
[12/03 06:40:42 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.09951340343707853
[12/03 06:47:00 visual_prompt]: Epoch 15 / 100: avg data time: 9.90e+00, avg batch time: 10.7772, average train loss: 0.6701
[12/03 06:47:43 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.5378, average loss: 0.6588
[12/03 06:47:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 70.51	
[12/03 06:47:43 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.09924038765061041
[12/03 06:54:00 visual_prompt]: Epoch 16 / 100: avg data time: 9.89e+00, avg batch time: 10.7692, average train loss: 0.6611
[12/03 06:54:44 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.5248, average loss: 0.6768
[12/03 06:54:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.54	rocauc: 69.11	
[12/03 06:54:44 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.09890738003669029
[12/03 07:01:01 visual_prompt]: Epoch 17 / 100: avg data time: 9.87e+00, avg batch time: 10.7557, average train loss: 0.6479
[12/03 07:01:45 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.5316, average loss: 0.6292
[12/03 07:01:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 69.85	
[12/03 07:01:45 visual_prompt]: Best epoch 17: best metric: -0.629
[12/03 07:01:45 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.09851478631379983
[12/03 07:08:00 visual_prompt]: Epoch 18 / 100: avg data time: 9.86e+00, avg batch time: 10.7367, average train loss: 0.6680
[12/03 07:08:44 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.5295, average loss: 0.8906
[12/03 07:08:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 69.21	
[12/03 07:08:44 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.09806308479691594
[12/03 07:15:00 visual_prompt]: Epoch 19 / 100: avg data time: 9.86e+00, avg batch time: 10.7395, average train loss: 0.6674
[12/03 07:15:44 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.5287, average loss: 0.8598
[12/03 07:15:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 68.54	
[12/03 07:15:44 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.09755282581475769
[12/03 07:22:00 visual_prompt]: Epoch 20 / 100: avg data time: 9.88e+00, avg batch time: 10.7614, average train loss: 0.6531
[12/03 07:22:44 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.5296, average loss: 0.7821
[12/03 07:22:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 69.44	
[12/03 07:22:44 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.09698463103929543
[12/03 07:29:00 visual_prompt]: Epoch 21 / 100: avg data time: 9.87e+00, avg batch time: 10.7505, average train loss: 0.6095
[12/03 07:29:44 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.5259, average loss: 0.6456
[12/03 07:29:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.01	rocauc: 69.18	
[12/03 07:29:44 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.09635919272833937
[12/03 07:36:01 visual_prompt]: Epoch 22 / 100: avg data time: 9.89e+00, avg batch time: 10.7651, average train loss: 0.5946
[12/03 07:36:45 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.5365, average loss: 0.6390
[12/03 07:36:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 68.65	
[12/03 07:36:45 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.09567727288213004
[12/03 07:43:02 visual_prompt]: Epoch 23 / 100: avg data time: 9.89e+00, avg batch time: 10.7730, average train loss: 0.5800
[12/03 07:43:46 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.5310, average loss: 0.7015
[12/03 07:43:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 65.13	
[12/03 07:43:46 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.09493970231495835
[12/03 07:50:03 visual_prompt]: Epoch 24 / 100: avg data time: 9.89e+00, avg batch time: 10.7700, average train loss: 0.6020
[12/03 07:50:47 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.5321, average loss: 0.6366
[12/03 07:50:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 69.78	
[12/03 07:50:47 visual_prompt]: Stopping early.
[12/03 07:50:48 visual_prompt]: Rank of current process: 0. World size: 1
[12/03 07:50:48 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA TITAN Xp
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[12/03 07:50:48 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss', 'RECORD_GPU_SNAPSHOT', 'True'])
[12/03 07:50:48 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[12/03 07:50:48 visual_prompt]: Training with config:
[12/03 07:50:48 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr0.05_wd0.01/patience7/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.05, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True}), 'RECORD_GPU_SNAPSHOT': True})
[12/03 07:50:48 visual_prompt]: Loading training data...
[12/03 07:50:48 visual_prompt]: Constructing mammo-cbis dataset train...
[12/03 07:50:48 visual_prompt]: Loading validation data...
[12/03 07:50:48 visual_prompt]: Constructing mammo-cbis dataset val...
[12/03 07:50:48 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[12/03 07:50:50 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[12/03 07:50:50 visual_prompt]: tuned percent:0.536
[12/03 07:50:50 visual_prompt]: Device used for model: 0
[12/03 07:50:50 visual_prompt]: Setting up Evaluator...
[12/03 07:50:50 visual_prompt]: Setting up Trainer...
[12/03 07:50:50 visual_prompt]: 	Setting up the optimizer...
[12/03 07:50:50 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[12/03 07:57:07 visual_prompt]: Epoch 1 / 100: avg data time: 9.89e+00, avg batch time: 10.7668, average train loss: 1.4006
[12/03 07:57:51 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.5335, average loss: 1.2969
[12/03 07:57:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[12/03 07:57:51 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.005000000000000001
[12/03 08:04:07 visual_prompt]: Epoch 2 / 100: avg data time: 9.88e+00, avg batch time: 10.7599, average train loss: 1.0058
[12/03 08:04:51 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.5309, average loss: 0.6944
[12/03 08:04:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 49.19	rocauc: 48.38	
[12/03 08:04:51 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.010000000000000002
[12/03 08:11:08 visual_prompt]: Epoch 3 / 100: avg data time: 9.87e+00, avg batch time: 10.7522, average train loss: 0.7078
[12/03 08:11:51 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.5297, average loss: 0.6964
[12/03 08:11:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.21	
[12/03 08:11:51 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.015
[12/03 08:18:07 visual_prompt]: Epoch 4 / 100: avg data time: 9.87e+00, avg batch time: 10.7408, average train loss: 0.7088
[12/03 08:18:51 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.5308, average loss: 0.6984
[12/03 08:18:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.24	
[12/03 08:18:51 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.020000000000000004
[12/03 08:25:07 visual_prompt]: Epoch 5 / 100: avg data time: 9.86e+00, avg batch time: 10.7396, average train loss: 0.7233
[12/03 08:25:51 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.5301, average loss: 0.7059
[12/03 08:25:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.45	
[12/03 08:25:51 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.025
[12/03 08:32:09 visual_prompt]: Epoch 6 / 100: avg data time: 9.93e+00, avg batch time: 10.8141, average train loss: 0.7297
[12/03 08:32:54 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.5307, average loss: 0.6867
[12/03 08:32:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.52	
[12/03 08:32:54 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.03
[12/03 08:39:15 visual_prompt]: Epoch 7 / 100: avg data time: 1.00e+01, avg batch time: 10.8884, average train loss: 0.7071
[12/03 08:39:59 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.5287, average loss: 0.6848
[12/03 08:39:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.06	
[12/03 08:39:59 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.034999999999999996
[12/03 08:46:19 visual_prompt]: Epoch 8 / 100: avg data time: 9.99e+00, avg batch time: 10.8697, average train loss: 0.6951
[12/03 08:47:04 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.5341, average loss: 0.6801
[12/03 08:47:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 61.27	
[12/03 08:47:04 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.04000000000000001
[12/03 08:53:25 visual_prompt]: Epoch 9 / 100: avg data time: 1.00e+01, avg batch time: 10.8877, average train loss: 0.6924
[12/03 08:54:09 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.5275, average loss: 0.7261
[12/03 08:54:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.32	
[12/03 08:54:09 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.045000000000000005
[12/03 09:00:30 visual_prompt]: Epoch 10 / 100: avg data time: 1.00e+01, avg batch time: 10.8830, average train loss: 0.7054
[12/03 09:01:14 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.5307, average loss: 0.7026
[12/03 09:01:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.47	
[12/03 09:01:14 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.05
[12/03 09:07:34 visual_prompt]: Epoch 11 / 100: avg data time: 9.99e+00, avg batch time: 10.8591, average train loss: 0.6869
[12/03 09:08:18 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.5346, average loss: 0.6709
[12/03 09:08:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 63.19	
[12/03 09:08:18 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0499847706754774
[12/03 09:14:38 visual_prompt]: Epoch 12 / 100: avg data time: 9.98e+00, avg batch time: 10.8602, average train loss: 0.6922
[12/03 09:15:22 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.5331, average loss: 0.6842
[12/03 09:15:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 64.31	
[12/03 09:15:22 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.04993910125649561
[12/03 09:21:43 visual_prompt]: Epoch 13 / 100: avg data time: 1.00e+01, avg batch time: 10.8735, average train loss: 0.7057
[12/03 09:22:27 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.5295, average loss: 0.6840
[12/03 09:22:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.07	
[12/03 09:22:27 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.049863047384206834
[12/03 09:28:47 visual_prompt]: Epoch 14 / 100: avg data time: 9.97e+00, avg batch time: 10.8503, average train loss: 0.6992
[12/03 09:29:32 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.5304, average loss: 0.7959
[12/03 09:29:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 62.01	
[12/03 09:29:32 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.04975670171853926
[12/03 09:35:53 visual_prompt]: Epoch 15 / 100: avg data time: 1.00e+01, avg batch time: 10.8828, average train loss: 0.7055
[12/03 09:36:37 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.5313, average loss: 0.6898
[12/03 09:36:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.95	
[12/03 09:36:37 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.049620193825305206
[12/03 09:42:53 visual_prompt]: Epoch 16 / 100: avg data time: 9.88e+00, avg batch time: 10.7518, average train loss: 0.6895
[12/03 09:43:37 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.5285, average loss: 0.6940
[12/03 09:43:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.15	
[12/03 09:43:37 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.049453690018345146
[12/03 09:49:54 visual_prompt]: Epoch 17 / 100: avg data time: 9.89e+00, avg batch time: 10.7679, average train loss: 0.6856
[12/03 09:50:37 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.5281, average loss: 0.6862
[12/03 09:50:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 53.66	rocauc: 62.61	
[12/03 09:50:37 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.04925739315689991
[12/03 09:56:53 visual_prompt]: Epoch 18 / 100: avg data time: 9.87e+00, avg batch time: 10.7430, average train loss: 0.6865
[12/03 09:57:37 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.5414, average loss: 0.7773
[12/03 09:57:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.78	
[12/03 09:57:37 visual_prompt]: Stopping early.
[12/03 09:57:37 visual_prompt]: Rank of current process: 0. World size: 1
[12/03 09:57:37 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA TITAN Xp
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[12/03 09:57:37 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss', 'RECORD_GPU_SNAPSHOT', 'True'])
[12/03 09:57:37 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[12/03 09:57:37 visual_prompt]: Training with config:
[12/03 09:57:37 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr0.05_wd0.001/patience7/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.05, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True}), 'RECORD_GPU_SNAPSHOT': True})
[12/03 09:57:37 visual_prompt]: Loading training data...
[12/03 09:57:37 visual_prompt]: Constructing mammo-cbis dataset train...
[12/03 09:57:37 visual_prompt]: Loading validation data...
[12/03 09:57:37 visual_prompt]: Constructing mammo-cbis dataset val...
[12/03 09:57:37 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[12/03 09:57:40 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[12/03 09:57:40 visual_prompt]: tuned percent:0.536
[12/03 09:57:40 visual_prompt]: Device used for model: 0
[12/03 09:57:40 visual_prompt]: Setting up Evaluator...
[12/03 09:57:40 visual_prompt]: Setting up Trainer...
[12/03 09:57:40 visual_prompt]: 	Setting up the optimizer...
[12/03 09:57:40 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[12/03 10:03:57 visual_prompt]: Epoch 1 / 100: avg data time: 9.90e+00, avg batch time: 10.7740, average train loss: 1.4006
[12/03 10:04:41 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.5352, average loss: 1.2969
[12/03 10:04:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[12/03 10:04:41 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.005000000000000001
[12/03 10:10:57 visual_prompt]: Epoch 2 / 100: avg data time: 9.85e+00, avg batch time: 10.7251, average train loss: 1.0066
[12/03 10:11:40 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.5352, average loss: 0.6944
[12/03 10:11:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 49.19	rocauc: 48.28	
[12/03 10:11:40 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.010000000000000002
[12/03 10:17:57 visual_prompt]: Epoch 3 / 100: avg data time: 9.88e+00, avg batch time: 10.7668, average train loss: 0.7084
[12/03 10:18:41 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.5337, average loss: 0.6965
[12/03 10:18:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.96	
[12/03 10:18:41 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.015
[12/03 10:24:58 visual_prompt]: Epoch 4 / 100: avg data time: 9.88e+00, avg batch time: 10.7638, average train loss: 0.7098
[12/03 10:25:42 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.5317, average loss: 0.6970
[12/03 10:25:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.53	rocauc: 54.24	
[12/03 10:25:42 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.020000000000000004
[12/03 10:31:58 visual_prompt]: Epoch 5 / 100: avg data time: 9.88e+00, avg batch time: 10.7580, average train loss: 0.7230
[12/03 10:32:42 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.5292, average loss: 0.6912
[12/03 10:32:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 55.68	
[12/03 10:32:42 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.025
[12/03 10:39:00 visual_prompt]: Epoch 6 / 100: avg data time: 9.91e+00, avg batch time: 10.7919, average train loss: 0.7395
[12/03 10:39:44 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.5334, average loss: 0.6872
[12/03 10:39:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.42	
[12/03 10:39:44 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.03
[12/03 10:46:01 visual_prompt]: Epoch 7 / 100: avg data time: 9.90e+00, avg batch time: 10.7769, average train loss: 0.7080
[12/03 10:46:45 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.5299, average loss: 0.6824
[12/03 10:46:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 59.10	
[12/03 10:46:45 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.034999999999999996
[12/03 10:53:01 visual_prompt]: Epoch 8 / 100: avg data time: 9.88e+00, avg batch time: 10.7562, average train loss: 0.6967
[12/03 10:53:45 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.5308, average loss: 0.6784
[12/03 10:53:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 60.97	
[12/03 10:53:45 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.04000000000000001
[12/03 11:00:02 visual_prompt]: Epoch 9 / 100: avg data time: 9.89e+00, avg batch time: 10.7692, average train loss: 0.6953
[12/03 11:00:46 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.5360, average loss: 0.7484
[12/03 11:00:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.53	
[12/03 11:00:46 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.045000000000000005
[12/03 11:07:02 visual_prompt]: Epoch 10 / 100: avg data time: 9.87e+00, avg batch time: 10.7479, average train loss: 0.7171
[12/03 11:07:46 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.5310, average loss: 0.6993
[12/03 11:07:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.93	
[12/03 11:07:46 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.05
[12/03 11:14:03 visual_prompt]: Epoch 11 / 100: avg data time: 9.88e+00, avg batch time: 10.7621, average train loss: 0.6927
[12/03 11:14:47 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.5286, average loss: 0.6614
[12/03 11:14:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 64.59	
[12/03 11:14:47 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0499847706754774
[12/03 11:21:03 visual_prompt]: Epoch 12 / 100: avg data time: 9.87e+00, avg batch time: 10.7494, average train loss: 0.6921
[12/03 11:21:47 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.5338, average loss: 0.6685
[12/03 11:21:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 66.05	
[12/03 11:21:47 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.04993910125649561
[12/03 11:28:04 visual_prompt]: Epoch 13 / 100: avg data time: 9.89e+00, avg batch time: 10.7637, average train loss: 0.7112
[12/03 11:28:48 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.5355, average loss: 0.6734
[12/03 11:28:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 65.03	
[12/03 11:28:48 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.049863047384206834
[12/03 11:35:04 visual_prompt]: Epoch 14 / 100: avg data time: 9.87e+00, avg batch time: 10.7496, average train loss: 0.7100
[12/03 11:35:48 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.5309, average loss: 0.9093
[12/03 11:35:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 62.17	
[12/03 11:35:48 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.04975670171853926
[12/03 11:42:05 visual_prompt]: Epoch 15 / 100: avg data time: 9.90e+00, avg batch time: 10.7789, average train loss: 0.7120
[12/03 11:42:49 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.5339, average loss: 0.6577
[12/03 11:42:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 66.73	
[12/03 11:42:49 visual_prompt]: Best epoch 15: best metric: -0.658
[12/03 11:42:49 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.049620193825305206
[12/03 11:49:05 visual_prompt]: Epoch 16 / 100: avg data time: 9.88e+00, avg batch time: 10.7553, average train loss: 0.6928
[12/03 11:49:49 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.5272, average loss: 0.7673
[12/03 11:49:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 66.16	
[12/03 11:49:49 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.049453690018345146
[12/03 11:56:06 visual_prompt]: Epoch 17 / 100: avg data time: 9.88e+00, avg batch time: 10.7593, average train loss: 0.6859
[12/03 11:56:50 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.5308, average loss: 0.6518
[12/03 11:56:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 66.46	
[12/03 11:56:50 visual_prompt]: Best epoch 17: best metric: -0.652
[12/03 11:56:50 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.04925739315689991
[12/03 12:03:24 visual_prompt]: Epoch 18 / 100: avg data time: 1.04e+01, avg batch time: 11.2394, average train loss: 0.6975
[12/03 12:04:10 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.5390, average loss: 0.7233
[12/03 12:04:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.47	rocauc: 66.24	
[12/03 12:04:10 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.04903154239845797
[12/03 12:10:34 visual_prompt]: Epoch 19 / 100: avg data time: 1.01e+01, avg batch time: 10.9813, average train loss: 0.6802
[12/03 12:11:18 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.5237, average loss: 0.7383
[12/03 12:11:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 67.13	
[12/03 12:11:18 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.048776412907378844
[12/03 12:17:38 visual_prompt]: Epoch 20 / 100: avg data time: 9.98e+00, avg batch time: 10.8596, average train loss: 0.6706
[12/03 12:18:23 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.5340, average loss: 0.6893
[12/03 12:18:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 67.48	
[12/03 12:18:23 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.048492315519647715
[12/03 12:24:40 visual_prompt]: Epoch 21 / 100: avg data time: 9.88e+00, avg batch time: 10.7590, average train loss: 0.6789
[12/03 12:25:23 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.5303, average loss: 0.6589
[12/03 12:25:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 67.12	
[12/03 12:25:23 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.048179596364169686
[12/03 12:31:40 visual_prompt]: Epoch 22 / 100: avg data time: 9.87e+00, avg batch time: 10.7481, average train loss: 0.6511
[12/03 12:32:24 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.5413, average loss: 0.6802
[12/03 12:32:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 69.20	
[12/03 12:32:24 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.04783863644106502
[12/03 12:38:40 visual_prompt]: Epoch 23 / 100: avg data time: 9.88e+00, avg batch time: 10.7628, average train loss: 0.6537
[12/03 12:39:24 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.5343, average loss: 0.6432
[12/03 12:39:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 68.98	
[12/03 12:39:24 visual_prompt]: Best epoch 23: best metric: -0.643
[12/03 12:39:24 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.047469851157479176
[12/03 12:45:42 visual_prompt]: Epoch 24 / 100: avg data time: 9.90e+00, avg batch time: 10.7799, average train loss: 0.6523
[12/03 12:46:25 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.5292, average loss: 0.6989
[12/03 12:46:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 67.87	
[12/03 12:46:25 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.047073689821473176
[12/03 12:52:42 visual_prompt]: Epoch 25 / 100: avg data time: 9.87e+00, avg batch time: 10.7541, average train loss: 0.6637
[12/03 12:53:26 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.5350, average loss: 0.6486
[12/03 12:53:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 69.75	
[12/03 12:53:26 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.046650635094610975
[12/03 12:59:42 visual_prompt]: Epoch 26 / 100: avg data time: 9.86e+00, avg batch time: 10.7445, average train loss: 0.6516
[12/03 13:00:26 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.5391, average loss: 0.6294
[12/03 13:00:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 68.70	rocauc: 71.20	
[12/03 13:00:26 visual_prompt]: Best epoch 26: best metric: -0.629
[12/03 13:00:26 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.04620120240391065
[12/03 13:06:42 visual_prompt]: Epoch 27 / 100: avg data time: 9.87e+00, avg batch time: 10.7471, average train loss: 0.6333
[12/03 13:07:26 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.5336, average loss: 0.6358
[12/03 13:07:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 70.19	
[12/03 13:07:26 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.04572593931387604
[12/03 13:13:42 visual_prompt]: Epoch 28 / 100: avg data time: 9.88e+00, avg batch time: 10.7590, average train loss: 0.6315
[12/03 13:14:26 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.5411, average loss: 0.6654
[12/03 13:14:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 69.81	
[12/03 13:14:26 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.04522542485937369
[12/03 13:20:44 visual_prompt]: Epoch 29 / 100: avg data time: 9.91e+00, avg batch time: 10.7832, average train loss: 0.6231
[12/03 13:21:27 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.5310, average loss: 0.6289
[12/03 13:21:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 70.34	
[12/03 13:21:27 visual_prompt]: Best epoch 29: best metric: -0.629
[12/03 13:21:27 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.04470026884016805
[12/03 13:27:46 visual_prompt]: Epoch 30 / 100: avg data time: 9.91e+00, avg batch time: 10.7971, average train loss: 0.6175
[12/03 13:28:30 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.5312, average loss: 0.6279
[12/03 13:28:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.89	rocauc: 71.01	
[12/03 13:28:30 visual_prompt]: Best epoch 30: best metric: -0.628
[12/03 13:28:30 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.04415111107797445
[12/03 13:34:48 visual_prompt]: Epoch 31 / 100: avg data time: 9.91e+00, avg batch time: 10.7868, average train loss: 0.6090
[12/03 13:35:32 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.5301, average loss: 0.6657
[12/03 13:35:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 71.11	
[12/03 13:35:32 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.04357862063693486
[12/03 13:41:50 visual_prompt]: Epoch 32 / 100: avg data time: 9.93e+00, avg batch time: 10.8139, average train loss: 0.6549
[12/03 13:42:34 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.5318, average loss: 0.7008
[12/03 13:42:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 50.00	rocauc: 69.47	
[12/03 13:42:34 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.04298349500846628
[12/03 13:48:51 visual_prompt]: Epoch 33 / 100: avg data time: 9.90e+00, avg batch time: 10.7762, average train loss: 0.6291
[12/03 13:49:35 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.5362, average loss: 0.6241
[12/03 13:49:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 71.43	
[12/03 13:49:35 visual_prompt]: Best epoch 33: best metric: -0.624
[12/03 13:49:35 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.042366459261474934
[12/03 13:55:52 visual_prompt]: Epoch 34 / 100: avg data time: 9.87e+00, avg batch time: 10.7493, average train loss: 0.6166
[12/03 13:56:35 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.5335, average loss: 0.7300
[12/03 13:56:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 71.83	
[12/03 13:56:35 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.04172826515897146
[12/03 14:02:53 visual_prompt]: Epoch 35 / 100: avg data time: 9.89e+00, avg batch time: 10.7755, average train loss: 0.6107
[12/03 14:03:37 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.5271, average loss: 0.6191
[12/03 14:03:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 68.70	rocauc: 71.94	
[12/03 14:03:37 visual_prompt]: Best epoch 35: best metric: -0.619
[12/03 14:03:37 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.04106969024216348
[12/03 14:09:54 visual_prompt]: Epoch 36 / 100: avg data time: 9.89e+00, avg batch time: 10.7721, average train loss: 0.6040
[12/03 14:10:37 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.5278, average loss: 0.6252
[12/03 14:10:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 72.12	
[12/03 14:10:37 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.040391536883141455
[12/03 14:16:54 visual_prompt]: Epoch 37 / 100: avg data time: 9.88e+00, avg batch time: 10.7571, average train loss: 0.5887
[12/03 14:17:38 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.5301, average loss: 0.6344
[12/03 14:17:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 74.68	
[12/03 14:17:38 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.03969463130731183
[12/03 14:23:59 visual_prompt]: Epoch 38 / 100: avg data time: 1.00e+01, avg batch time: 10.8830, average train loss: 0.5801
[12/03 14:24:44 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.5392, average loss: 0.7247
[12/03 14:24:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 69.30	
[12/03 14:24:44 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.03897982258676867
[12/03 14:31:05 visual_prompt]: Epoch 39 / 100: avg data time: 1.00e+01, avg batch time: 10.9045, average train loss: 0.5913
[12/03 14:31:50 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.5380, average loss: 0.6274
[12/03 14:31:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 70.54	
[12/03 14:31:50 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.03824798160583012
[12/03 14:38:12 visual_prompt]: Epoch 40 / 100: avg data time: 1.00e+01, avg batch time: 10.8946, average train loss: 0.6007
[12/03 14:38:56 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.5389, average loss: 0.6294
[12/03 14:38:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 68.29	rocauc: 70.00	
[12/03 14:38:56 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.037500000000000006
[12/03 14:45:17 visual_prompt]: Epoch 41 / 100: avg data time: 1.00e+01, avg batch time: 10.8915, average train loss: 0.5772
[12/03 14:46:02 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.5317, average loss: 0.6154
[12/03 14:46:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 73.02	
[12/03 14:46:02 visual_prompt]: Best epoch 41: best metric: -0.615
[12/03 14:46:02 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.03673678906964727
[12/03 14:52:23 visual_prompt]: Epoch 42 / 100: avg data time: 1.00e+01, avg batch time: 10.8842, average train loss: 0.5810
[12/03 14:53:07 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.5328, average loss: 0.7061
[12/03 14:53:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 71.67	
[12/03 14:53:07 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.03595927866972694
[12/03 14:59:28 visual_prompt]: Epoch 43 / 100: avg data time: 1.00e+01, avg batch time: 10.8835, average train loss: 0.5685
[12/03 15:00:12 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.5382, average loss: 0.6326
[12/03 15:00:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 71.49	
[12/03 15:00:12 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.03516841607689501
[12/03 15:06:32 visual_prompt]: Epoch 44 / 100: avg data time: 9.99e+00, avg batch time: 10.8678, average train loss: 0.5707
[12/03 15:07:16 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.5311, average loss: 0.6639
[12/03 15:07:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 70.65	
[12/03 15:07:16 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.0343651648353978
[12/03 15:13:34 visual_prompt]: Epoch 45 / 100: avg data time: 9.91e+00, avg batch time: 10.7923, average train loss: 0.5739
[12/03 15:14:18 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.5358, average loss: 0.6165
[12/03 15:14:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 71.59	
[12/03 15:14:18 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.033550503583141725
[12/03 15:20:35 visual_prompt]: Epoch 46 / 100: avg data time: 9.88e+00, avg batch time: 10.7605, average train loss: 0.5321
[12/03 15:21:19 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.5341, average loss: 0.5925
[12/03 15:21:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 69.92	rocauc: 74.78	
[12/03 15:21:19 visual_prompt]: Best epoch 46: best metric: -0.592
[12/03 15:21:19 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.032725424859373686
[12/03 15:27:43 visual_prompt]: Epoch 47 / 100: avg data time: 1.01e+01, avg batch time: 10.9653, average train loss: 0.5370
[12/03 15:28:29 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.5335, average loss: 0.6142
[12/03 15:28:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 68.29	rocauc: 70.72	
[12/03 15:28:29 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.03189093389542498
[12/03 15:35:13 visual_prompt]: Epoch 48 / 100: avg data time: 1.06e+01, avg batch time: 11.5171, average train loss: 0.5344
[12/03 15:36:02 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.5277, average loss: 0.6190
[12/03 15:36:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 70.19	
[12/03 15:36:02 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.03104804738999169
[12/03 15:42:36 visual_prompt]: Epoch 49 / 100: avg data time: 1.04e+01, avg batch time: 11.2782, average train loss: 0.5087
[12/03 15:43:20 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.5332, average loss: 0.6413
[12/03 15:43:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.07	rocauc: 70.53	
[12/03 15:43:20 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.03019779227044398
[12/03 15:49:39 visual_prompt]: Epoch 50 / 100: avg data time: 9.93e+00, avg batch time: 10.8128, average train loss: 0.5270
[12/03 15:50:23 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.5287, average loss: 0.6468
[12/03 15:50:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 73.99	
[12/03 15:50:23 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.029341204441673263
[12/03 15:56:43 visual_prompt]: Epoch 51 / 100: avg data time: 9.98e+00, avg batch time: 10.8615, average train loss: 0.5240
[12/03 15:57:27 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.5283, average loss: 0.6253
[12/03 15:57:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 72.95	
[12/03 15:57:27 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.028479327524001636
[12/03 16:03:49 visual_prompt]: Epoch 52 / 100: avg data time: 1.00e+01, avg batch time: 10.8935, average train loss: 0.4941
[12/03 16:04:33 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.5258, average loss: 0.6744
[12/03 16:04:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 68.29	rocauc: 72.57	
[12/03 16:04:33 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.02761321158169134
[12/03 16:10:51 visual_prompt]: Epoch 53 / 100: avg data time: 9.93e+00, avg batch time: 10.8090, average train loss: 0.5065
[12/03 16:11:35 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.5294, average loss: 0.6373
[12/03 16:11:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.89	rocauc: 73.73	
[12/03 16:11:35 visual_prompt]: Stopping early.
[12/03 16:11:35 visual_prompt]: Rank of current process: 0. World size: 1
[12/03 16:11:35 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA TITAN Xp
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[12/03 16:11:35 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss', 'RECORD_GPU_SNAPSHOT', 'True'])
[12/03 16:11:35 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[12/03 16:11:35 visual_prompt]: Training with config:
[12/03 16:11:35 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr0.05_wd0.0001/patience7/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.05, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True}), 'RECORD_GPU_SNAPSHOT': True})
[12/03 16:11:35 visual_prompt]: Loading training data...
[12/03 16:11:35 visual_prompt]: Constructing mammo-cbis dataset train...
[12/03 16:11:35 visual_prompt]: Loading validation data...
[12/03 16:11:35 visual_prompt]: Constructing mammo-cbis dataset val...
[12/03 16:11:35 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[12/03 16:11:38 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[12/03 16:11:38 visual_prompt]: tuned percent:0.536
[12/03 16:11:38 visual_prompt]: Device used for model: 0
[12/03 16:11:38 visual_prompt]: Setting up Evaluator...
[12/03 16:11:38 visual_prompt]: Setting up Trainer...
[12/03 16:11:38 visual_prompt]: 	Setting up the optimizer...
[12/03 16:11:38 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[12/03 16:17:55 visual_prompt]: Epoch 1 / 100: avg data time: 9.90e+00, avg batch time: 10.7795, average train loss: 1.4006
[12/03 16:18:39 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.5431, average loss: 1.2969
[12/03 16:18:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[12/03 16:18:39 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.005000000000000001
[12/03 16:24:55 visual_prompt]: Epoch 2 / 100: avg data time: 9.86e+00, avg batch time: 10.7480, average train loss: 1.0067
[12/03 16:25:39 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.5338, average loss: 0.6944
[12/03 16:25:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 49.19	rocauc: 48.28	
[12/03 16:25:39 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.010000000000000002
[12/03 16:31:56 visual_prompt]: Epoch 3 / 100: avg data time: 9.90e+00, avg batch time: 10.7746, average train loss: 0.7085
[12/03 16:32:40 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.5345, average loss: 0.6965
[12/03 16:32:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.95	
[12/03 16:32:40 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.015
[12/03 16:38:57 visual_prompt]: Epoch 4 / 100: avg data time: 9.89e+00, avg batch time: 10.7682, average train loss: 0.7099
[12/03 16:39:41 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.5406, average loss: 0.6968
[12/03 16:39:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.24	
[12/03 16:39:41 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.020000000000000004
[12/03 16:45:57 visual_prompt]: Epoch 5 / 100: avg data time: 9.86e+00, avg batch time: 10.7415, average train loss: 0.7231
[12/03 16:46:41 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.5312, average loss: 0.6907
[12/03 16:46:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.47	rocauc: 55.60	
[12/03 16:46:41 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.025
[12/03 16:52:58 visual_prompt]: Epoch 6 / 100: avg data time: 9.90e+00, avg batch time: 10.7793, average train loss: 0.7404
[12/03 16:53:42 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.5337, average loss: 0.6871
[12/03 16:53:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.38	
[12/03 16:53:42 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.03
[12/03 16:59:59 visual_prompt]: Epoch 7 / 100: avg data time: 9.90e+00, avg batch time: 10.7801, average train loss: 0.7080
[12/03 17:00:43 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.5340, average loss: 0.6825
[12/03 17:00:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 59.21	
[12/03 17:00:43 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.034999999999999996
[12/03 17:06:59 visual_prompt]: Epoch 8 / 100: avg data time: 9.85e+00, avg batch time: 10.7351, average train loss: 0.6972
[12/03 17:07:42 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.5294, average loss: 0.6780
[12/03 17:07:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 61.11	
[12/03 17:07:42 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.04000000000000001
[12/03 17:14:00 visual_prompt]: Epoch 9 / 100: avg data time: 9.91e+00, avg batch time: 10.7821, average train loss: 0.6958
[12/03 17:14:43 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.5299, average loss: 0.7487
[12/03 17:14:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.20	
[12/03 17:14:43 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.045000000000000005
[12/03 17:21:01 visual_prompt]: Epoch 10 / 100: avg data time: 9.89e+00, avg batch time: 10.7714, average train loss: 0.7182
[12/03 17:21:44 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.5362, average loss: 0.6946
[12/03 17:21:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.13	
[12/03 17:21:44 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.05
[12/03 17:28:02 visual_prompt]: Epoch 11 / 100: avg data time: 9.89e+00, avg batch time: 10.7775, average train loss: 0.6930
[12/03 17:28:46 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.5374, average loss: 0.6630
[12/03 17:28:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 64.19	
[12/03 17:28:46 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0499847706754774
[12/03 17:35:02 visual_prompt]: Epoch 12 / 100: avg data time: 9.87e+00, avg batch time: 10.7526, average train loss: 0.6933
[12/03 17:35:46 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.5367, average loss: 0.6744
[12/03 17:35:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 65.44	
[12/03 17:35:46 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.04993910125649561
[12/03 17:42:04 visual_prompt]: Epoch 13 / 100: avg data time: 9.91e+00, avg batch time: 10.7919, average train loss: 0.7129
[12/03 17:42:47 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.5397, average loss: 0.6777
[12/03 17:42:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 65.42	
[12/03 17:42:47 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.049863047384206834
[12/03 17:49:04 visual_prompt]: Epoch 14 / 100: avg data time: 9.88e+00, avg batch time: 10.7532, average train loss: 0.7099
[12/03 17:49:48 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.5387, average loss: 0.8640
[12/03 17:49:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 65.12	
[12/03 17:49:48 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.04975670171853926
[12/03 17:56:05 visual_prompt]: Epoch 15 / 100: avg data time: 9.89e+00, avg batch time: 10.7677, average train loss: 0.7087
[12/03 17:56:48 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.5272, average loss: 0.6632
[12/03 17:56:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 65.21	
[12/03 17:56:48 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.049620193825305206
[12/03 18:03:06 visual_prompt]: Epoch 16 / 100: avg data time: 9.91e+00, avg batch time: 10.7928, average train loss: 0.6971
[12/03 18:03:50 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.5262, average loss: 0.7870
[12/03 18:03:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 65.52	
[12/03 18:03:50 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.049453690018345146
[12/03 18:10:11 visual_prompt]: Epoch 17 / 100: avg data time: 9.99e+00, avg batch time: 10.8662, average train loss: 0.6911
[12/03 18:10:55 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.5268, average loss: 0.6580
[12/03 18:10:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 66.50	
[12/03 18:10:55 visual_prompt]: Best epoch 17: best metric: -0.658
[12/03 18:10:55 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.04925739315689991
[12/03 18:17:12 visual_prompt]: Epoch 18 / 100: avg data time: 9.89e+00, avg batch time: 10.7743, average train loss: 0.7058
[12/03 18:17:56 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.5295, average loss: 0.7456
[12/03 18:17:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 66.08	
[12/03 18:17:56 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.04903154239845797
[12/03 18:24:12 visual_prompt]: Epoch 19 / 100: avg data time: 9.87e+00, avg batch time: 10.7464, average train loss: 0.6817
[12/03 18:24:56 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.5335, average loss: 0.7225
[12/03 18:24:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 67.00	
[12/03 18:24:56 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.048776412907378844
[12/03 18:31:16 visual_prompt]: Epoch 20 / 100: avg data time: 9.97e+00, avg batch time: 10.8479, average train loss: 0.6706
[12/03 18:32:00 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.5365, average loss: 0.6988
[12/03 18:32:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 66.73	
[12/03 18:32:00 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.048492315519647715
[12/03 18:38:18 visual_prompt]: Epoch 21 / 100: avg data time: 9.92e+00, avg batch time: 10.7958, average train loss: 0.6780
[12/03 18:39:02 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.5253, average loss: 0.6547
[12/03 18:39:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 67.32	
[12/03 18:39:02 visual_prompt]: Best epoch 21: best metric: -0.655
[12/03 18:39:02 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.048179596364169686
[12/03 18:45:20 visual_prompt]: Epoch 22 / 100: avg data time: 9.92e+00, avg batch time: 10.8055, average train loss: 0.6572
[12/03 18:46:04 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.5225, average loss: 0.7010
[12/03 18:46:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 68.19	
[12/03 18:46:04 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.04783863644106502
[12/03 18:52:21 visual_prompt]: Epoch 23 / 100: avg data time: 9.87e+00, avg batch time: 10.7525, average train loss: 0.6634
[12/03 18:53:04 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.5362, average loss: 0.6542
[12/03 18:53:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 68.28	
[12/03 18:53:04 visual_prompt]: Best epoch 23: best metric: -0.654
[12/03 18:53:04 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.047469851157479176
[12/03 18:59:21 visual_prompt]: Epoch 24 / 100: avg data time: 9.89e+00, avg batch time: 10.7654, average train loss: 0.6564
[12/03 19:00:05 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.5383, average loss: 0.6942
[12/03 19:00:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 68.87	
[12/03 19:00:05 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.047073689821473176
[12/03 19:06:22 visual_prompt]: Epoch 25 / 100: avg data time: 9.88e+00, avg batch time: 10.7601, average train loss: 0.6735
[12/03 19:07:05 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.5348, average loss: 0.6549
[12/03 19:07:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 68.64	
[12/03 19:07:05 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.046650635094610975
[12/03 19:13:22 visual_prompt]: Epoch 26 / 100: avg data time: 9.87e+00, avg batch time: 10.7508, average train loss: 0.6462
[12/03 19:14:06 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.5299, average loss: 0.6344
[12/03 19:14:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 70.51	
[12/03 19:14:06 visual_prompt]: Best epoch 26: best metric: -0.634
[12/03 19:14:06 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.04620120240391065
[12/03 19:20:23 visual_prompt]: Epoch 27 / 100: avg data time: 9.89e+00, avg batch time: 10.7656, average train loss: 0.6339
[12/03 19:21:06 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.5313, average loss: 0.6409
[12/03 19:21:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 68.91	
[12/03 19:21:06 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.04572593931387604
[12/03 19:27:23 visual_prompt]: Epoch 28 / 100: avg data time: 9.88e+00, avg batch time: 10.7599, average train loss: 0.6449
[12/03 19:28:06 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.5318, average loss: 0.6976
[12/03 19:28:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 68.43	
[12/03 19:28:06 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.04522542485937369
[12/03 19:34:24 visual_prompt]: Epoch 29 / 100: avg data time: 9.91e+00, avg batch time: 10.7856, average train loss: 0.6322
[12/03 19:35:08 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.5311, average loss: 0.6286
[12/03 19:35:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 70.90	
[12/03 19:35:08 visual_prompt]: Best epoch 29: best metric: -0.629
[12/03 19:35:08 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.04470026884016805
[12/03 19:41:24 visual_prompt]: Epoch 30 / 100: avg data time: 9.87e+00, avg batch time: 10.7474, average train loss: 0.6326
[12/03 19:42:08 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.5358, average loss: 0.6365
[12/03 19:42:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 70.01	
[12/03 19:42:08 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.04415111107797445
[12/03 19:48:24 visual_prompt]: Epoch 31 / 100: avg data time: 9.87e+00, avg batch time: 10.7478, average train loss: 0.6192
[12/03 19:49:08 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.5332, average loss: 0.6677
[12/03 19:49:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 68.67	
[12/03 19:49:08 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.04357862063693486
[12/03 19:55:25 visual_prompt]: Epoch 32 / 100: avg data time: 9.89e+00, avg batch time: 10.7700, average train loss: 0.6386
[12/03 19:56:08 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.5333, average loss: 0.6719
[12/03 19:56:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 69.11	
[12/03 19:56:08 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.04298349500846628
[12/03 20:02:25 visual_prompt]: Epoch 33 / 100: avg data time: 9.88e+00, avg batch time: 10.7539, average train loss: 0.6317
[12/03 20:03:09 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.5276, average loss: 0.6447
[12/03 20:03:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 69.32	
[12/03 20:03:09 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.042366459261474934
[12/03 20:09:26 visual_prompt]: Epoch 34 / 100: avg data time: 9.90e+00, avg batch time: 10.7770, average train loss: 0.6346
[12/03 20:10:10 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.5300, average loss: 0.7480
[12/03 20:10:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 69.99	
[12/03 20:10:10 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.04172826515897146
[12/03 20:16:27 visual_prompt]: Epoch 35 / 100: avg data time: 9.90e+00, avg batch time: 10.7747, average train loss: 0.6189
[12/03 20:17:11 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.5323, average loss: 0.6268
[12/03 20:17:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.07	rocauc: 70.31	
[12/03 20:17:11 visual_prompt]: Best epoch 35: best metric: -0.627
[12/03 20:17:11 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.04106969024216348
[12/03 20:23:28 visual_prompt]: Epoch 36 / 100: avg data time: 9.88e+00, avg batch time: 10.7595, average train loss: 0.6191
[12/03 20:24:11 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.5312, average loss: 0.6361
[12/03 20:24:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 70.45	
[12/03 20:24:11 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.040391536883141455
[12/03 20:30:29 visual_prompt]: Epoch 37 / 100: avg data time: 9.92e+00, avg batch time: 10.7955, average train loss: 0.6152
[12/03 20:31:13 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.5377, average loss: 0.6828
[12/03 20:31:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 70.60	
[12/03 20:31:13 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.03969463130731183
[12/03 20:37:31 visual_prompt]: Epoch 38 / 100: avg data time: 9.92e+00, avg batch time: 10.7923, average train loss: 0.6029
[12/03 20:38:15 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.5392, average loss: 0.6663
[12/03 20:38:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 68.80	
[12/03 20:38:15 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.03897982258676867
[12/03 20:44:32 visual_prompt]: Epoch 39 / 100: avg data time: 9.89e+00, avg batch time: 10.7678, average train loss: 0.6089
[12/03 20:45:15 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.5338, average loss: 0.6338
[12/03 20:45:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.67	rocauc: 69.59	
[12/03 20:45:15 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.03824798160583012
[12/03 20:51:31 visual_prompt]: Epoch 40 / 100: avg data time: 9.86e+00, avg batch time: 10.7419, average train loss: 0.5971
[12/03 20:52:15 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.5356, average loss: 0.6377
[12/03 20:52:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 68.81	
[12/03 20:52:15 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.037500000000000006
[12/03 20:58:32 visual_prompt]: Epoch 41 / 100: avg data time: 9.88e+00, avg batch time: 10.7553, average train loss: 0.5842
[12/03 20:59:15 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.5336, average loss: 0.6425
[12/03 20:59:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 67.92	
[12/03 20:59:15 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.03673678906964727
[12/03 21:05:33 visual_prompt]: Epoch 42 / 100: avg data time: 9.89e+00, avg batch time: 10.7735, average train loss: 0.6009
[12/03 21:06:16 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.5316, average loss: 0.7118
[12/03 21:06:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 70.61	
[12/03 21:06:16 visual_prompt]: Stopping early.
[12/03 21:06:17 visual_prompt]: Rank of current process: 0. World size: 1
[12/03 21:06:17 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA TITAN Xp
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[12/03 21:06:17 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss', 'RECORD_GPU_SNAPSHOT', 'True'])
[12/03 21:06:17 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[12/03 21:06:17 visual_prompt]: Training with config:
[12/03 21:06:17 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr0.05_wd0.0/patience7/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.05, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True}), 'RECORD_GPU_SNAPSHOT': True})
[12/03 21:06:17 visual_prompt]: Loading training data...
[12/03 21:06:17 visual_prompt]: Constructing mammo-cbis dataset train...
[12/03 21:06:17 visual_prompt]: Loading validation data...
[12/03 21:06:17 visual_prompt]: Constructing mammo-cbis dataset val...
[12/03 21:06:17 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[12/03 21:06:19 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[12/03 21:06:19 visual_prompt]: tuned percent:0.536
[12/03 21:06:19 visual_prompt]: Device used for model: 0
[12/03 21:06:19 visual_prompt]: Setting up Evaluator...
[12/03 21:06:19 visual_prompt]: Setting up Trainer...
[12/03 21:06:19 visual_prompt]: 	Setting up the optimizer...
[12/03 21:06:20 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[12/03 21:12:40 visual_prompt]: Epoch 1 / 100: avg data time: 9.97e+00, avg batch time: 10.8481, average train loss: 1.4006
[12/03 21:13:24 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.5341, average loss: 1.2969
[12/03 21:13:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[12/03 21:13:24 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.005000000000000001
[12/03 21:19:45 visual_prompt]: Epoch 2 / 100: avg data time: 1.00e+01, avg batch time: 10.8776, average train loss: 1.0067
[12/03 21:20:29 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.5382, average loss: 0.6944
[12/03 21:20:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 49.19	rocauc: 48.28	
[12/03 21:20:29 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.010000000000000002
[12/03 21:27:05 visual_prompt]: Epoch 3 / 100: avg data time: 1.04e+01, avg batch time: 11.2932, average train loss: 0.7085
[12/03 21:27:54 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.5294, average loss: 0.6965
[12/03 21:27:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.94	
[12/03 21:27:54 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.015
[12/03 21:34:50 visual_prompt]: Epoch 4 / 100: avg data time: 1.10e+01, avg batch time: 11.8789, average train loss: 0.7099
[12/03 21:35:37 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.5375, average loss: 0.6968
[12/03 21:35:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.24	
[12/03 21:35:37 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.020000000000000004
[12/03 21:42:08 visual_prompt]: Epoch 5 / 100: avg data time: 1.03e+01, avg batch time: 11.1508, average train loss: 0.7231
[12/03 21:42:52 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.5349, average loss: 0.6906
[12/03 21:42:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.47	rocauc: 55.60	
[12/03 21:42:52 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.025
[12/03 21:49:09 visual_prompt]: Epoch 6 / 100: avg data time: 9.89e+00, avg batch time: 10.7705, average train loss: 0.7404
[12/03 21:49:52 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.5302, average loss: 0.6871
[12/03 21:49:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.37	
[12/03 21:49:52 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.03
[12/03 21:56:09 visual_prompt]: Epoch 7 / 100: avg data time: 9.89e+00, avg batch time: 10.7696, average train loss: 0.7080
[12/03 21:56:53 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.5399, average loss: 0.6825
[12/03 21:56:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 59.23	
[12/03 21:56:53 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.034999999999999996
[12/03 22:03:10 visual_prompt]: Epoch 8 / 100: avg data time: 9.89e+00, avg batch time: 10.7695, average train loss: 0.6973
[12/03 22:03:54 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.5297, average loss: 0.6780
[12/03 22:03:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 61.08	
[12/03 22:03:54 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.04000000000000001
[12/03 22:10:11 visual_prompt]: Epoch 9 / 100: avg data time: 9.89e+00, avg batch time: 10.7702, average train loss: 0.6959
[12/03 22:10:54 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.5395, average loss: 0.7491
[12/03 22:10:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.38	
[12/03 22:10:54 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.045000000000000005
[12/03 22:17:18 visual_prompt]: Epoch 10 / 100: avg data time: 1.01e+01, avg batch time: 10.9593, average train loss: 0.7184
[12/03 22:18:03 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.5363, average loss: 0.6944
[12/03 22:18:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.79	
[12/03 22:18:03 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.05
[12/03 22:24:22 visual_prompt]: Epoch 11 / 100: avg data time: 9.94e+00, avg batch time: 10.8169, average train loss: 0.6932
[12/03 22:25:06 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.5367, average loss: 0.6630
[12/03 22:25:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.54	rocauc: 64.21	
[12/03 22:25:06 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0499847706754774
[12/03 22:31:23 visual_prompt]: Epoch 12 / 100: avg data time: 9.89e+00, avg batch time: 10.7739, average train loss: 0.6914
[12/03 22:32:07 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.5321, average loss: 0.6793
[12/03 22:32:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 65.66	
[12/03 22:32:07 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.04993910125649561
[12/03 22:38:23 visual_prompt]: Epoch 13 / 100: avg data time: 9.88e+00, avg batch time: 10.7590, average train loss: 0.7134
[12/03 22:39:08 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.5307, average loss: 0.6810
[12/03 22:39:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 65.33	
[12/03 22:39:08 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.049863047384206834
[12/03 22:45:25 visual_prompt]: Epoch 14 / 100: avg data time: 9.88e+00, avg batch time: 10.7662, average train loss: 0.7095
[12/03 22:46:09 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.5342, average loss: 0.8527
[12/03 22:46:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 63.11	
[12/03 22:46:09 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.04975670171853926
[12/03 22:52:26 visual_prompt]: Epoch 15 / 100: avg data time: 9.91e+00, avg batch time: 10.7886, average train loss: 0.7066
[12/03 22:53:10 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.5319, average loss: 0.6619
[12/03 22:53:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 65.91	
[12/03 22:53:10 visual_prompt]: Best epoch 15: best metric: -0.662
[12/03 22:53:10 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.049620193825305206
[12/03 22:59:27 visual_prompt]: Epoch 16 / 100: avg data time: 9.88e+00, avg batch time: 10.7606, average train loss: 0.6945
[12/03 23:00:11 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.5318, average loss: 0.7720
[12/03 23:00:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 65.86	
[12/03 23:00:11 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.049453690018345146
[12/03 23:06:30 visual_prompt]: Epoch 17 / 100: avg data time: 9.96e+00, avg batch time: 10.8364, average train loss: 0.6901
[12/03 23:07:14 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.5259, average loss: 0.6506
[12/03 23:07:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 66.97	
[12/03 23:07:14 visual_prompt]: Best epoch 17: best metric: -0.651
[12/03 23:07:14 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.04925739315689991
[12/03 23:13:35 visual_prompt]: Epoch 18 / 100: avg data time: 1.00e+01, avg batch time: 10.8770, average train loss: 0.7027
[12/03 23:14:19 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.5366, average loss: 0.7305
[12/03 23:14:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.47	rocauc: 66.57	
[12/03 23:14:19 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.04903154239845797
[12/03 23:20:39 visual_prompt]: Epoch 19 / 100: avg data time: 9.96e+00, avg batch time: 10.8339, average train loss: 0.6816
[12/03 23:21:23 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.5429, average loss: 0.7533
[12/03 23:21:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 66.79	
[12/03 23:21:23 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.048776412907378844
[12/03 23:27:43 visual_prompt]: Epoch 20 / 100: avg data time: 9.99e+00, avg batch time: 10.8742, average train loss: 0.6725
[12/03 23:28:28 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.5388, average loss: 0.6976
[12/03 23:28:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 66.66	
[12/03 23:28:28 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.048492315519647715
[12/03 23:34:52 visual_prompt]: Epoch 21 / 100: avg data time: 1.01e+01, avg batch time: 10.9917, average train loss: 0.6786
[12/03 23:35:36 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.5360, average loss: 0.6518
[12/03 23:35:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 66.89	
[12/03 23:35:36 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.048179596364169686
[12/03 23:41:57 visual_prompt]: Epoch 22 / 100: avg data time: 9.98e+00, avg batch time: 10.8592, average train loss: 0.6623
[12/03 23:42:41 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.5382, average loss: 0.7192
[12/03 23:42:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 53.66	rocauc: 67.50	
[12/03 23:42:41 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.04783863644106502
[12/03 23:49:02 visual_prompt]: Epoch 23 / 100: avg data time: 1.00e+01, avg batch time: 10.8771, average train loss: 0.6653
[12/03 23:49:46 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.5292, average loss: 0.6534
[12/03 23:49:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 67.24	
[12/03 23:49:46 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.047469851157479176
[12/03 23:56:04 visual_prompt]: Epoch 24 / 100: avg data time: 9.91e+00, avg batch time: 10.7939, average train loss: 0.6591
[12/03 23:56:47 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.5312, average loss: 0.6983
[12/03 23:56:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 68.67	
[12/03 23:56:47 visual_prompt]: Stopping early.
[12/03 23:56:55 visual_prompt]: Rank of current process: 0. World size: 1
[12/03 23:56:55 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA TITAN Xp
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[12/03 23:56:55 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss', 'RECORD_GPU_SNAPSHOT', 'True'])
[12/03 23:56:55 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[12/03 23:56:55 visual_prompt]: Training with config:
[12/03 23:56:55 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/test/seed9805/lr1.0_wd0.0/patience7/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 9805, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 1.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True}), 'RECORD_GPU_SNAPSHOT': True})
[12/03 23:56:55 visual_prompt]: Loading training data...
[12/03 23:56:55 visual_prompt]: Constructing mammo-cbis dataset train...
[12/03 23:56:55 visual_prompt]: Loading validation data...
[12/03 23:56:55 visual_prompt]: Constructing mammo-cbis dataset val...
[12/03 23:56:55 visual_prompt]: Loading test data...
[12/03 23:56:55 visual_prompt]: Constructing mammo-cbis dataset test...
[12/03 23:56:55 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[12/03 23:56:58 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[12/03 23:56:58 visual_prompt]: tuned percent:0.536
[12/03 23:56:58 visual_prompt]: Device used for model: 0
[12/03 23:56:58 visual_prompt]: Setting up Evaluator...
[12/03 23:56:58 visual_prompt]: Setting up Trainer...
[12/03 23:56:58 visual_prompt]: 	Setting up the optimizer...
[12/03 23:56:58 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[12/04 00:03:14 visual_prompt]: Epoch 1 / 100: avg data time: 9.87e+00, avg batch time: 10.7480, average train loss: 0.9016
[12/04 00:03:58 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.5352, average loss: 0.8574
[12/04 00:03:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 46.75	rocauc: 46.69	
[12/04 00:07:54 visual_prompt]: Inference (test):avg data time: 2.59e-05, avg batch time: 0.5404, average loss: 0.8635
[12/04 00:07:54 visual_prompt]: Classification results with test_mammo-cbis: top1: 41.55	rocauc: 48.05	
[12/04 00:07:54 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.1
[12/04 00:14:12 visual_prompt]: Epoch 2 / 100: avg data time: 9.92e+00, avg batch time: 10.7927, average train loss: 1.4435
[12/04 00:14:56 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.5385, average loss: 0.6906
[12/04 00:14:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.29	
[12/04 00:16:48 visual_prompt]: Inference (test):avg data time: 2.73e-05, avg batch time: 0.5238, average loss: 0.6781
[12/04 00:16:48 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 51.70	
[12/04 00:16:48 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.2
[12/04 00:23:04 visual_prompt]: Epoch 3 / 100: avg data time: 9.88e+00, avg batch time: 10.7560, average train loss: 0.7267
[12/04 00:23:48 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.5334, average loss: 0.6876
[12/04 00:23:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.96	
[12/04 00:25:39 visual_prompt]: Inference (test):avg data time: 3.08e-05, avg batch time: 0.5155, average loss: 0.6728
[12/04 00:25:39 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 56.48	
[12/04 00:25:39 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.3
[12/04 00:31:57 visual_prompt]: Epoch 4 / 100: avg data time: 9.90e+00, avg batch time: 10.7768, average train loss: 0.7399
[12/04 00:32:41 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.5320, average loss: 0.8091
[12/04 00:32:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.95	
[12/04 00:34:32 visual_prompt]: Inference (test):avg data time: 2.87e-05, avg batch time: 0.5181, average loss: 0.8509
[12/04 00:34:32 visual_prompt]: Classification results with test_mammo-cbis: top1: 40.93	rocauc: 58.77	
[12/04 00:34:32 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.4
[12/04 00:40:48 visual_prompt]: Epoch 5 / 100: avg data time: 9.87e+00, avg batch time: 10.7481, average train loss: 0.7120
[12/04 00:41:32 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.5461, average loss: 0.9663
[12/04 00:41:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 62.76	
[12/04 00:43:23 visual_prompt]: Inference (test):avg data time: 2.97e-05, avg batch time: 0.5156, average loss: 1.0378
[12/04 00:43:23 visual_prompt]: Classification results with test_mammo-cbis: top1: 40.93	rocauc: 61.30	
[12/04 00:43:23 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.5
[12/04 00:49:40 visual_prompt]: Epoch 6 / 100: avg data time: 9.91e+00, avg batch time: 10.7854, average train loss: 0.7236
[12/04 00:50:24 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.5370, average loss: 0.7332
[12/04 00:50:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.93	rocauc: 64.86	
[12/04 00:52:16 visual_prompt]: Inference (test):avg data time: 3.38e-05, avg batch time: 0.5187, average loss: 0.7703
[12/04 00:52:16 visual_prompt]: Classification results with test_mammo-cbis: top1: 41.24	rocauc: 63.39	
[12/04 00:52:16 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.6
[12/04 00:58:32 visual_prompt]: Epoch 7 / 100: avg data time: 9.87e+00, avg batch time: 10.7423, average train loss: 0.8474
[12/04 00:59:15 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.5401, average loss: 1.0900
[12/04 00:59:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 64.63	
[12/04 01:01:07 visual_prompt]: Inference (test):avg data time: 3.30e-05, avg batch time: 0.5210, average loss: 1.1787
[12/04 01:01:07 visual_prompt]: Classification results with test_mammo-cbis: top1: 40.93	rocauc: 64.25	
[12/04 01:01:07 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.7
[12/04 01:07:24 visual_prompt]: Epoch 8 / 100: avg data time: 9.89e+00, avg batch time: 10.7695, average train loss: 0.8246
[12/04 01:08:08 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.5378, average loss: 0.7456
[12/04 01:08:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 46.75	rocauc: 66.51	
[12/04 01:09:59 visual_prompt]: Inference (test):avg data time: 3.02e-05, avg batch time: 0.5167, average loss: 0.7873
[12/04 01:09:59 visual_prompt]: Classification results with test_mammo-cbis: top1: 41.40	rocauc: 65.58	
[12/04 01:09:59 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.8
[12/04 01:16:15 visual_prompt]: Epoch 9 / 100: avg data time: 9.88e+00, avg batch time: 10.7530, average train loss: 0.7247
[12/04 01:16:59 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.5314, average loss: 0.6936
[12/04 01:16:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 50.81	rocauc: 60.02	
[12/04 01:18:50 visual_prompt]: Inference (test):avg data time: 3.70e-05, avg batch time: 0.5148, average loss: 0.7046
[12/04 01:18:50 visual_prompt]: Classification results with test_mammo-cbis: top1: 45.74	rocauc: 56.50	
[12/04 01:18:50 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.9
[12/04 01:25:06 visual_prompt]: Epoch 10 / 100: avg data time: 9.86e+00, avg batch time: 10.7416, average train loss: 0.8326
[12/04 01:25:50 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.5373, average loss: 1.4204
[12/04 01:25:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.18	
[12/04 01:27:42 visual_prompt]: Inference (test):avg data time: 3.08e-05, avg batch time: 0.5173, average loss: 1.5263
[12/04 01:27:42 visual_prompt]: Classification results with test_mammo-cbis: top1: 40.93	rocauc: 56.91	
[12/04 01:27:42 visual_prompt]: Training 11 / 100 epoch, with learning rate 1.0
[12/04 01:34:00 visual_prompt]: Epoch 11 / 100: avg data time: 9.92e+00, avg batch time: 10.8043, average train loss: 0.9480
[12/04 01:34:44 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.5300, average loss: 0.6976
[12/04 01:34:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.84	
[12/04 01:36:35 visual_prompt]: Inference (test):avg data time: 2.80e-05, avg batch time: 0.5197, average loss: 0.6759
[12/04 01:36:35 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 58.66	
[12/04 01:36:35 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.9996954135095479
[12/04 01:42:56 visual_prompt]: Epoch 12 / 100: avg data time: 1.00e+01, avg batch time: 10.8877, average train loss: 0.8017
[12/04 01:43:40 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.5354, average loss: 0.9419
[12/04 01:43:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.81	
[12/04 01:45:31 visual_prompt]: Inference (test):avg data time: 2.70e-05, avg batch time: 0.5201, average loss: 0.8716
[12/04 01:45:31 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 60.00	
[12/04 01:45:31 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.9987820251299121
[12/04 01:51:48 visual_prompt]: Epoch 13 / 100: avg data time: 9.87e+00, avg batch time: 10.7465, average train loss: 1.2689
[12/04 01:52:31 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.5343, average loss: 0.6873
[12/04 01:52:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.47	rocauc: 63.05	
[12/04 01:54:23 visual_prompt]: Inference (test):avg data time: 3.20e-05, avg batch time: 0.5147, average loss: 0.6969
[12/04 01:54:23 visual_prompt]: Classification results with test_mammo-cbis: top1: 51.32	rocauc: 60.45	
[12/04 01:54:23 visual_prompt]: Best epoch 13: best metric: -0.687
[12/04 01:54:23 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.9972609476841366
[12/04 02:00:39 visual_prompt]: Epoch 14 / 100: avg data time: 9.87e+00, avg batch time: 10.7513, average train loss: 0.8564
[12/04 02:01:23 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.5335, average loss: 0.6913
[12/04 02:01:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 51.63	rocauc: 64.75	
[12/04 02:03:14 visual_prompt]: Inference (test):avg data time: 3.13e-05, avg batch time: 0.5159, average loss: 0.7168
[12/04 02:03:14 visual_prompt]: Classification results with test_mammo-cbis: top1: 49.77	rocauc: 61.02	
[12/04 02:03:14 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.9951340343707852
[12/04 02:09:31 visual_prompt]: Epoch 15 / 100: avg data time: 9.88e+00, avg batch time: 10.7607, average train loss: 0.7142
[12/04 02:10:15 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.5353, average loss: 0.7142
[12/04 02:10:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 66.29	
[12/04 02:12:06 visual_prompt]: Inference (test):avg data time: 2.90e-05, avg batch time: 0.5160, average loss: 0.6874
[12/04 02:12:06 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 63.13	
[12/04 02:12:06 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.9924038765061041
[12/04 02:18:23 visual_prompt]: Epoch 16 / 100: avg data time: 9.89e+00, avg batch time: 10.7736, average train loss: 0.7430
[12/04 02:19:07 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.5408, average loss: 0.6687
[12/04 02:19:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 66.01	
[12/04 02:20:59 visual_prompt]: Inference (test):avg data time: 3.04e-05, avg batch time: 0.5207, average loss: 0.6539
[12/04 02:20:59 visual_prompt]: Classification results with test_mammo-cbis: top1: 60.62	rocauc: 63.29	
[12/04 02:20:59 visual_prompt]: Best epoch 16: best metric: -0.669
[12/04 02:20:59 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.9890738003669028
[12/04 02:27:16 visual_prompt]: Epoch 17 / 100: avg data time: 9.90e+00, avg batch time: 10.7779, average train loss: 0.7226
[12/04 02:28:00 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.5348, average loss: 1.0077
[12/04 02:28:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 67.06	
[12/04 02:29:51 visual_prompt]: Inference (test):avg data time: 3.36e-05, avg batch time: 0.5194, average loss: 1.1116
[12/04 02:29:51 visual_prompt]: Classification results with test_mammo-cbis: top1: 40.93	rocauc: 62.86	
[12/04 02:29:51 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.9851478631379982
[12/04 02:36:08 visual_prompt]: Epoch 18 / 100: avg data time: 9.88e+00, avg batch time: 10.7599, average train loss: 0.8650
[12/04 02:36:52 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.5372, average loss: 0.7565
[12/04 02:36:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 48.37	rocauc: 64.63	
[12/04 02:38:43 visual_prompt]: Inference (test):avg data time: 2.64e-05, avg batch time: 0.5183, average loss: 0.8010
[12/04 02:38:43 visual_prompt]: Classification results with test_mammo-cbis: top1: 42.79	rocauc: 64.00	
[12/04 02:38:43 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.9806308479691594
[12/04 02:45:00 visual_prompt]: Epoch 19 / 100: avg data time: 9.90e+00, avg batch time: 10.7778, average train loss: 0.8113
[12/04 02:45:44 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.5319, average loss: 0.6365
[12/04 02:45:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.67	rocauc: 69.30	
[12/04 02:47:36 visual_prompt]: Inference (test):avg data time: 2.75e-05, avg batch time: 0.5186, average loss: 0.6501
[12/04 02:47:36 visual_prompt]: Classification results with test_mammo-cbis: top1: 62.17	rocauc: 63.62	
[12/04 02:47:36 visual_prompt]: Best epoch 19: best metric: -0.637
[12/04 02:47:36 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.9755282581475768
[12/04 02:53:52 visual_prompt]: Epoch 20 / 100: avg data time: 9.88e+00, avg batch time: 10.7543, average train loss: 0.6984
[12/04 02:54:36 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.5353, average loss: 0.6430
[12/04 02:54:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 69.87	
[12/04 02:56:27 visual_prompt]: Inference (test):avg data time: 3.01e-05, avg batch time: 0.5146, average loss: 0.6487
[12/04 02:56:27 visual_prompt]: Classification results with test_mammo-cbis: top1: 62.48	rocauc: 64.51	
[12/04 02:56:27 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.9698463103929542
[12/04 03:02:44 visual_prompt]: Epoch 21 / 100: avg data time: 9.88e+00, avg batch time: 10.7514, average train loss: 0.7533
[12/04 03:03:27 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.5341, average loss: 0.6989
[12/04 03:03:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 69.55	
[12/04 03:05:19 visual_prompt]: Inference (test):avg data time: 2.78e-05, avg batch time: 0.5193, average loss: 0.7702
[12/04 03:05:19 visual_prompt]: Classification results with test_mammo-cbis: top1: 53.80	rocauc: 64.61	
[12/04 03:05:19 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.9635919272833937
[12/04 03:11:36 visual_prompt]: Epoch 22 / 100: avg data time: 9.90e+00, avg batch time: 10.7748, average train loss: 0.6757
[12/04 03:12:20 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.5263, average loss: 1.0009
[12/04 03:12:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 69.82	
[12/04 03:14:12 visual_prompt]: Inference (test):avg data time: 3.18e-05, avg batch time: 0.5167, average loss: 0.8999
[12/04 03:14:12 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 65.99	
[12/04 03:14:12 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.9567727288213004
[12/04 03:20:28 visual_prompt]: Epoch 23 / 100: avg data time: 9.88e+00, avg batch time: 10.7606, average train loss: 0.7218
[12/04 03:21:12 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.5350, average loss: 0.6262
[12/04 03:21:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.89	rocauc: 70.62	
[12/04 03:23:04 visual_prompt]: Inference (test):avg data time: 3.17e-05, avg batch time: 0.5170, average loss: 0.6449
[12/04 03:23:04 visual_prompt]: Classification results with test_mammo-cbis: top1: 62.33	rocauc: 66.59	
[12/04 03:23:04 visual_prompt]: Best epoch 23: best metric: -0.626
[12/04 03:23:04 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.9493970231495835
[12/04 03:29:20 visual_prompt]: Epoch 24 / 100: avg data time: 9.89e+00, avg batch time: 10.7612, average train loss: 0.6648
[12/04 03:30:04 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.5267, average loss: 0.6393
[12/04 03:30:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 70.63	
[12/04 03:31:55 visual_prompt]: Inference (test):avg data time: 2.79e-05, avg batch time: 0.5180, average loss: 0.6492
[12/04 03:31:55 visual_prompt]: Classification results with test_mammo-cbis: top1: 63.88	rocauc: 65.53	
[12/04 03:31:55 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.9414737964294635
[12/04 03:38:12 visual_prompt]: Epoch 25 / 100: avg data time: 9.87e+00, avg batch time: 10.7512, average train loss: 0.7190
[12/04 03:38:55 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.5328, average loss: 0.8290
[12/04 03:38:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 49.59	rocauc: 70.89	
[12/04 03:40:47 visual_prompt]: Inference (test):avg data time: 3.05e-05, avg batch time: 0.5164, average loss: 0.9324
[12/04 03:40:47 visual_prompt]: Classification results with test_mammo-cbis: top1: 43.10	rocauc: 66.22	
[12/04 03:40:47 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.9330127018922194
[12/04 03:47:06 visual_prompt]: Epoch 26 / 100: avg data time: 9.96e+00, avg batch time: 10.8399, average train loss: 0.6869
[12/04 03:47:51 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.5302, average loss: 0.7940
[12/04 03:47:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 71.05	
[12/04 03:49:43 visual_prompt]: Inference (test):avg data time: 3.31e-05, avg batch time: 0.5225, average loss: 0.7399
[12/04 03:49:43 visual_prompt]: Classification results with test_mammo-cbis: top1: 62.64	rocauc: 65.62	
[12/04 03:49:43 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.9240240480782129
[12/04 03:56:04 visual_prompt]: Epoch 27 / 100: avg data time: 9.99e+00, avg batch time: 10.8764, average train loss: 0.8705
[12/04 03:56:48 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.5344, average loss: 1.3053
[12/04 03:56:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.73	
[12/04 03:58:41 visual_prompt]: Inference (test):avg data time: 3.19e-05, avg batch time: 0.5179, average loss: 1.3968
[12/04 03:58:41 visual_prompt]: Classification results with test_mammo-cbis: top1: 40.93	rocauc: 53.39	
[12/04 03:58:41 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.9145187862775208
[12/04 04:04:59 visual_prompt]: Epoch 28 / 100: avg data time: 9.92e+00, avg batch time: 10.7990, average train loss: 1.7518
[12/04 04:05:43 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.5335, average loss: 1.7998
[12/04 04:05:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.22	
[12/04 04:07:34 visual_prompt]: Inference (test):avg data time: 2.99e-05, avg batch time: 0.5180, average loss: 1.9360
[12/04 04:07:34 visual_prompt]: Classification results with test_mammo-cbis: top1: 40.93	rocauc: 51.86	
[12/04 04:07:34 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.9045084971874737
[12/04 04:13:52 visual_prompt]: Epoch 29 / 100: avg data time: 9.92e+00, avg batch time: 10.8069, average train loss: 1.3916
[12/04 04:14:36 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.5277, average loss: 1.1600
[12/04 04:14:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.40	
[12/04 04:16:27 visual_prompt]: Inference (test):avg data time: 3.24e-05, avg batch time: 0.5210, average loss: 1.2399
[12/04 04:16:27 visual_prompt]: Classification results with test_mammo-cbis: top1: 40.93	rocauc: 52.68	
[12/04 04:16:27 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.8940053768033609
[12/04 04:22:45 visual_prompt]: Epoch 30 / 100: avg data time: 9.90e+00, avg batch time: 10.7840, average train loss: 0.9289
[12/04 04:23:29 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.5349, average loss: 0.8969
[12/04 04:23:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.10	
[12/04 04:25:20 visual_prompt]: Inference (test):avg data time: 3.03e-05, avg batch time: 0.5179, average loss: 0.8297
[12/04 04:25:20 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 53.80	
[12/04 04:25:20 visual_prompt]: Stopping early.
[12/04 04:25:20 visual_prompt]: Rank of current process: 0. World size: 1
[12/04 04:25:20 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA TITAN Xp
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[12/04 04:25:20 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss', 'RECORD_GPU_SNAPSHOT', 'True'])
[12/04 04:25:20 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[12/04 04:25:20 visual_prompt]: Training with config:
[12/04 04:25:20 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/test/seed875/lr1.0_wd0.0/patience7/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 875, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 1.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True}), 'RECORD_GPU_SNAPSHOT': True})
[12/04 04:25:20 visual_prompt]: Loading training data...
[12/04 04:25:20 visual_prompt]: Constructing mammo-cbis dataset train...
[12/04 04:25:20 visual_prompt]: Loading validation data...
[12/04 04:25:20 visual_prompt]: Constructing mammo-cbis dataset val...
[12/04 04:25:20 visual_prompt]: Loading test data...
[12/04 04:25:20 visual_prompt]: Constructing mammo-cbis dataset test...
[12/04 04:25:20 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[12/04 04:25:23 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[12/04 04:25:23 visual_prompt]: tuned percent:0.536
[12/04 04:25:23 visual_prompt]: Device used for model: 0
[12/04 04:25:23 visual_prompt]: Setting up Evaluator...
[12/04 04:25:23 visual_prompt]: Setting up Trainer...
[12/04 04:25:23 visual_prompt]: 	Setting up the optimizer...
[12/04 04:25:23 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[12/04 04:31:40 visual_prompt]: Epoch 1 / 100: avg data time: 9.90e+00, avg batch time: 10.7698, average train loss: 0.9301
[12/04 04:32:23 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.5283, average loss: 0.8873
[12/04 04:32:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.43	
[12/04 04:34:15 visual_prompt]: Inference (test):avg data time: 3.16e-05, avg batch time: 0.5139, average loss: 0.8247
[12/04 04:34:15 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 50.82	
[12/04 04:34:15 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.1
[12/04 04:40:31 visual_prompt]: Epoch 2 / 100: avg data time: 9.88e+00, avg batch time: 10.7544, average train loss: 1.4762
[12/04 04:41:15 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.5297, average loss: 0.7062
[12/04 04:41:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.16	
[12/04 04:43:05 visual_prompt]: Inference (test):avg data time: 3.21e-05, avg batch time: 0.5091, average loss: 0.6781
[12/04 04:43:05 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 56.52	
[12/04 04:43:05 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.2
[12/04 04:49:20 visual_prompt]: Epoch 3 / 100: avg data time: 9.84e+00, avg batch time: 10.7200, average train loss: 0.7118
[12/04 04:50:04 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.5243, average loss: 0.7412
[12/04 04:50:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.90	
[12/04 04:51:54 visual_prompt]: Inference (test):avg data time: 2.95e-05, avg batch time: 0.5184, average loss: 0.6987
[12/04 04:51:54 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 60.87	
[12/04 04:51:54 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.3
[12/04 04:58:08 visual_prompt]: Epoch 4 / 100: avg data time: 9.80e+00, avg batch time: 10.6749, average train loss: 0.7228
[12/04 04:58:52 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.5272, average loss: 0.7271
[12/04 04:58:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.37	
[12/04 05:00:42 visual_prompt]: Inference (test):avg data time: 2.91e-05, avg batch time: 0.5150, average loss: 0.6870
[12/04 05:00:42 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 61.49	
[12/04 05:00:42 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.4
[12/04 05:06:57 visual_prompt]: Epoch 5 / 100: avg data time: 9.83e+00, avg batch time: 10.7144, average train loss: 0.8180
[12/04 05:07:41 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.5302, average loss: 0.6980
[12/04 05:07:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.46	
[12/04 05:09:32 visual_prompt]: Inference (test):avg data time: 3.33e-05, avg batch time: 0.5068, average loss: 0.6690
[12/04 05:09:32 visual_prompt]: Classification results with test_mammo-cbis: top1: 58.76	rocauc: 61.88	
[12/04 05:09:32 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.5
[12/04 05:15:46 visual_prompt]: Epoch 6 / 100: avg data time: 9.80e+00, avg batch time: 10.6796, average train loss: 0.9144
[12/04 05:16:29 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.5345, average loss: 0.6755
[12/04 05:16:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.54	rocauc: 59.99	
[12/04 05:18:20 visual_prompt]: Inference (test):avg data time: 2.88e-05, avg batch time: 0.5171, average loss: 0.6686
[12/04 05:18:20 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 61.88	
[12/04 05:18:20 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.6
[12/04 05:24:35 visual_prompt]: Epoch 7 / 100: avg data time: 9.84e+00, avg batch time: 10.7170, average train loss: 0.7028
[12/04 05:25:19 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.5311, average loss: 0.7136
[12/04 05:25:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.80	
[12/04 05:27:09 visual_prompt]: Inference (test):avg data time: 2.89e-05, avg batch time: 0.5119, average loss: 0.6743
[12/04 05:27:09 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.22	rocauc: 62.45	
[12/04 05:27:09 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.7
[12/04 05:33:24 visual_prompt]: Epoch 8 / 100: avg data time: 9.83e+00, avg batch time: 10.6981, average train loss: 0.7613
[12/04 05:34:07 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.5311, average loss: 1.2120
[12/04 05:34:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.84	
[12/04 05:35:58 visual_prompt]: Inference (test):avg data time: 2.87e-05, avg batch time: 0.5148, average loss: 1.0889
[12/04 05:35:58 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 63.39	
[12/04 05:35:58 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.8
[12/04 05:42:13 visual_prompt]: Epoch 9 / 100: avg data time: 9.84e+00, avg batch time: 10.7146, average train loss: 0.8716
[12/04 05:42:56 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.5304, average loss: 0.6704
[12/04 05:42:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.54	rocauc: 61.55	
[12/04 05:44:47 visual_prompt]: Inference (test):avg data time: 2.99e-05, avg batch time: 0.5106, average loss: 0.6498
[12/04 05:44:47 visual_prompt]: Classification results with test_mammo-cbis: top1: 61.55	rocauc: 64.01	
[12/04 05:44:47 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.9
[12/04 05:51:01 visual_prompt]: Epoch 10 / 100: avg data time: 9.81e+00, avg batch time: 10.6889, average train loss: 0.8855
[12/04 05:51:45 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.5359, average loss: 0.8355
[12/04 05:51:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 62.24	
[12/04 05:53:35 visual_prompt]: Inference (test):avg data time: 3.19e-05, avg batch time: 0.5105, average loss: 0.8817
[12/04 05:53:35 visual_prompt]: Classification results with test_mammo-cbis: top1: 40.93	rocauc: 64.04	
[12/04 05:53:35 visual_prompt]: Training 11 / 100 epoch, with learning rate 1.0
[12/04 05:59:50 visual_prompt]: Epoch 11 / 100: avg data time: 9.82e+00, avg batch time: 10.6977, average train loss: 0.8794
[12/04 06:00:33 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.5299, average loss: 0.9494
[12/04 06:00:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.61	
[12/04 06:02:24 visual_prompt]: Inference (test):avg data time: 3.35e-05, avg batch time: 0.5137, average loss: 0.8571
[12/04 06:02:24 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 64.38	
[12/04 06:02:24 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.9996954135095479
[12/04 06:08:38 visual_prompt]: Epoch 12 / 100: avg data time: 9.81e+00, avg batch time: 10.6902, average train loss: 0.7574
[12/04 06:09:22 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.5252, average loss: 0.6832
[12/04 06:09:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 67.09	
[12/04 06:11:12 visual_prompt]: Inference (test):avg data time: 3.02e-05, avg batch time: 0.5127, average loss: 0.6522
[12/04 06:11:12 visual_prompt]: Classification results with test_mammo-cbis: top1: 62.48	rocauc: 65.84	
[12/04 06:11:12 visual_prompt]: Best epoch 12: best metric: -0.683
[12/04 06:11:12 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.9987820251299121
[12/04 06:17:26 visual_prompt]: Epoch 13 / 100: avg data time: 9.80e+00, avg batch time: 10.6795, average train loss: 0.7975
[12/04 06:18:10 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.5299, average loss: 0.6428
[12/04 06:18:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 69.45	
[12/04 06:20:01 visual_prompt]: Inference (test):avg data time: 3.05e-05, avg batch time: 0.5168, average loss: 0.6539
[12/04 06:20:01 visual_prompt]: Classification results with test_mammo-cbis: top1: 62.48	rocauc: 66.33	
[12/04 06:20:01 visual_prompt]: Best epoch 13: best metric: -0.643
[12/04 06:20:01 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.9972609476841366
[12/04 06:26:15 visual_prompt]: Epoch 14 / 100: avg data time: 9.80e+00, avg batch time: 10.6809, average train loss: 0.7265
[12/04 06:26:58 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.5302, average loss: 0.9024
[12/04 06:26:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.47	rocauc: 70.35	
[12/04 06:28:49 visual_prompt]: Inference (test):avg data time: 3.02e-05, avg batch time: 0.5143, average loss: 0.8222
[12/04 06:28:49 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.69	rocauc: 67.00	
[12/04 06:28:49 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.9951340343707852
[12/04 06:35:03 visual_prompt]: Epoch 15 / 100: avg data time: 9.82e+00, avg batch time: 10.6915, average train loss: 0.7685
[12/04 06:35:47 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.5281, average loss: 0.7209
[12/04 06:35:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.54	rocauc: 69.76	
[12/04 06:37:37 visual_prompt]: Inference (test):avg data time: 3.04e-05, avg batch time: 0.5137, average loss: 0.7770
[12/04 06:37:37 visual_prompt]: Classification results with test_mammo-cbis: top1: 53.80	rocauc: 65.83	
[12/04 06:37:37 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.9924038765061041
[12/04 06:43:52 visual_prompt]: Epoch 16 / 100: avg data time: 9.82e+00, avg batch time: 10.6990, average train loss: 1.0498
[12/04 06:44:35 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.5310, average loss: 1.0019
[12/04 06:44:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 69.57	
[12/04 06:46:26 visual_prompt]: Inference (test):avg data time: 2.77e-05, avg batch time: 0.5157, average loss: 0.9024
[12/04 06:46:26 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.22	rocauc: 66.76	
[12/04 06:46:26 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.9890738003669028
[12/04 06:52:40 visual_prompt]: Epoch 17 / 100: avg data time: 9.81e+00, avg batch time: 10.6879, average train loss: 0.9096
[12/04 06:53:24 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.5306, average loss: 0.6279
[12/04 06:53:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 71.49	
[12/04 06:55:14 visual_prompt]: Inference (test):avg data time: 3.10e-05, avg batch time: 0.5153, average loss: 0.6467
[12/04 06:55:14 visual_prompt]: Classification results with test_mammo-cbis: top1: 62.33	rocauc: 66.66	
[12/04 06:55:14 visual_prompt]: Best epoch 17: best metric: -0.628
[12/04 06:55:14 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.9851478631379982
[12/04 07:01:29 visual_prompt]: Epoch 18 / 100: avg data time: 9.82e+00, avg batch time: 10.6917, average train loss: 0.6952
[12/04 07:02:12 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.5165, average loss: 0.7781
[12/04 07:02:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.54	rocauc: 71.82	
[12/04 07:04:03 visual_prompt]: Inference (test):avg data time: 3.15e-05, avg batch time: 0.5151, average loss: 0.7251
[12/04 07:04:03 visual_prompt]: Classification results with test_mammo-cbis: top1: 65.27	rocauc: 67.40	
[12/04 07:04:03 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.9806308479691594
[12/04 07:10:17 visual_prompt]: Epoch 19 / 100: avg data time: 9.81e+00, avg batch time: 10.6844, average train loss: 0.6580
[12/04 07:11:01 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.5367, average loss: 0.6249
[12/04 07:11:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 73.08	
[12/04 07:12:51 visual_prompt]: Inference (test):avg data time: 3.28e-05, avg batch time: 0.5104, average loss: 0.6432
[12/04 07:12:51 visual_prompt]: Classification results with test_mammo-cbis: top1: 62.79	rocauc: 66.73	
[12/04 07:12:51 visual_prompt]: Best epoch 19: best metric: -0.625
[12/04 07:12:51 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.9755282581475768
[12/04 07:19:06 visual_prompt]: Epoch 20 / 100: avg data time: 9.83e+00, avg batch time: 10.7074, average train loss: 0.7444
[12/04 07:19:50 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.5253, average loss: 0.6611
[12/04 07:19:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 72.75	
[12/04 07:21:40 visual_prompt]: Inference (test):avg data time: 3.23e-05, avg batch time: 0.5159, average loss: 0.6585
[12/04 07:21:40 visual_prompt]: Classification results with test_mammo-cbis: top1: 63.41	rocauc: 67.49	
[12/04 07:21:40 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.9698463103929542
[12/04 07:27:54 visual_prompt]: Epoch 21 / 100: avg data time: 9.81e+00, avg batch time: 10.6908, average train loss: 0.7184
[12/04 07:28:38 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.5271, average loss: 0.7900
[12/04 07:28:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 73.81	
[12/04 07:30:29 visual_prompt]: Inference (test):avg data time: 3.03e-05, avg batch time: 0.5107, average loss: 0.9494
[12/04 07:30:29 visual_prompt]: Classification results with test_mammo-cbis: top1: 49.15	rocauc: 65.56	
[12/04 07:30:29 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.9635919272833937
[12/04 07:36:43 visual_prompt]: Epoch 22 / 100: avg data time: 9.82e+00, avg batch time: 10.6933, average train loss: 0.7162
[12/04 07:37:26 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.5293, average loss: 0.6324
[12/04 07:37:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.67	rocauc: 71.07	
[12/04 07:39:17 visual_prompt]: Inference (test):avg data time: 3.36e-05, avg batch time: 0.5149, average loss: 0.6453
[12/04 07:39:17 visual_prompt]: Classification results with test_mammo-cbis: top1: 63.57	rocauc: 68.17	
[12/04 07:39:17 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.9567727288213004
[12/04 07:45:31 visual_prompt]: Epoch 23 / 100: avg data time: 9.82e+00, avg batch time: 10.6948, average train loss: 0.8983
[12/04 07:46:15 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.5330, average loss: 0.7623
[12/04 07:46:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 75.08	
[12/04 07:48:06 visual_prompt]: Inference (test):avg data time: 2.98e-05, avg batch time: 0.5147, average loss: 0.9028
[12/04 07:48:06 visual_prompt]: Classification results with test_mammo-cbis: top1: 49.15	rocauc: 66.67	
[12/04 07:48:06 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.9493970231495835
[12/04 07:54:20 visual_prompt]: Epoch 24 / 100: avg data time: 9.82e+00, avg batch time: 10.6970, average train loss: 0.7280
[12/04 07:55:04 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.5298, average loss: 0.5919
[12/04 07:55:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 68.70	rocauc: 75.43	
[12/04 07:56:54 visual_prompt]: Inference (test):avg data time: 2.87e-05, avg batch time: 0.5167, average loss: 0.6622
[12/04 07:56:54 visual_prompt]: Classification results with test_mammo-cbis: top1: 61.86	rocauc: 66.83	
[12/04 07:56:54 visual_prompt]: Best epoch 24: best metric: -0.592
[12/04 07:56:54 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.9414737964294635
[12/04 08:03:09 visual_prompt]: Epoch 25 / 100: avg data time: 9.81e+00, avg batch time: 10.6875, average train loss: 0.7918
[12/04 08:03:52 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.5208, average loss: 1.2675
[12/04 08:03:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 71.44	
[12/04 08:05:43 visual_prompt]: Inference (test):avg data time: 3.03e-05, avg batch time: 0.5141, average loss: 1.4847
[12/04 08:05:43 visual_prompt]: Classification results with test_mammo-cbis: top1: 40.93	rocauc: 68.01	
[12/04 08:05:43 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.9330127018922194
[12/04 08:11:58 visual_prompt]: Epoch 26 / 100: avg data time: 9.84e+00, avg batch time: 10.7169, average train loss: 0.6968
[12/04 08:12:42 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.5295, average loss: 0.6174
[12/04 08:12:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 72.86	
[12/04 08:14:32 visual_prompt]: Inference (test):avg data time: 3.24e-05, avg batch time: 0.5111, average loss: 0.6476
[12/04 08:14:32 visual_prompt]: Classification results with test_mammo-cbis: top1: 62.17	rocauc: 67.15	
[12/04 08:14:32 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.9240240480782129
[12/04 08:20:47 visual_prompt]: Epoch 27 / 100: avg data time: 9.82e+00, avg batch time: 10.6987, average train loss: 0.6160
[12/04 08:21:30 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.5282, average loss: 0.6310
[12/04 08:21:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 68.29	rocauc: 71.39	
[12/04 08:23:21 visual_prompt]: Inference (test):avg data time: 2.87e-05, avg batch time: 0.5183, average loss: 0.6652
[12/04 08:23:21 visual_prompt]: Classification results with test_mammo-cbis: top1: 62.02	rocauc: 68.32	
[12/04 08:23:21 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.9145187862775208
[12/04 08:29:35 visual_prompt]: Epoch 28 / 100: avg data time: 9.82e+00, avg batch time: 10.6946, average train loss: 0.6434
[12/04 08:30:19 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.5263, average loss: 0.6444
[12/04 08:30:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 72.28	
[12/04 08:32:09 visual_prompt]: Inference (test):avg data time: 2.93e-05, avg batch time: 0.5137, average loss: 0.6685
[12/04 08:32:09 visual_prompt]: Classification results with test_mammo-cbis: top1: 63.57	rocauc: 68.12	
[12/04 08:32:09 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.9045084971874737
[12/04 08:38:24 visual_prompt]: Epoch 29 / 100: avg data time: 9.82e+00, avg batch time: 10.6988, average train loss: 0.6335
[12/04 08:39:08 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.5360, average loss: 0.6694
[12/04 08:39:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 72.02	
[12/04 08:40:58 visual_prompt]: Inference (test):avg data time: 3.18e-05, avg batch time: 0.5154, average loss: 0.7385
[12/04 08:40:58 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 67.57	
[12/04 08:40:58 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.8940053768033609
[12/04 08:47:12 visual_prompt]: Epoch 30 / 100: avg data time: 9.82e+00, avg batch time: 10.6945, average train loss: 0.6460
[12/04 08:47:56 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.5283, average loss: 0.8131
[12/04 08:47:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.07	rocauc: 72.82	
[12/04 08:49:47 visual_prompt]: Inference (test):avg data time: 3.63e-05, avg batch time: 0.5152, average loss: 1.0228
[12/04 08:49:47 visual_prompt]: Classification results with test_mammo-cbis: top1: 57.98	rocauc: 67.69	
[12/04 08:49:47 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.883022221559489
[12/04 08:56:01 visual_prompt]: Epoch 31 / 100: avg data time: 9.80e+00, avg batch time: 10.6799, average train loss: 0.6672
[12/04 08:56:44 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.5253, average loss: 1.2256
[12/04 08:56:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 73.04	
[12/04 08:58:35 visual_prompt]: Inference (test):avg data time: 3.35e-05, avg batch time: 0.5155, average loss: 1.4575
[12/04 08:58:35 visual_prompt]: Classification results with test_mammo-cbis: top1: 40.78	rocauc: 66.90	
[12/04 08:58:35 visual_prompt]: Stopping early.
[12/04 08:58:35 visual_prompt]: Rank of current process: 0. World size: 1
[12/04 08:58:35 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA TITAN Xp
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[12/04 08:58:35 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss', 'RECORD_GPU_SNAPSHOT', 'True'])
[12/04 08:58:35 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[12/04 08:58:35 visual_prompt]: Training with config:
[12/04 08:58:35 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/test/seed4536/lr1.0_wd0.0/patience7/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 4536, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 1.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True}), 'RECORD_GPU_SNAPSHOT': True})
[12/04 08:58:35 visual_prompt]: Loading training data...
[12/04 08:58:35 visual_prompt]: Constructing mammo-cbis dataset train...
[12/04 08:58:35 visual_prompt]: Loading validation data...
[12/04 08:58:35 visual_prompt]: Constructing mammo-cbis dataset val...
[12/04 08:58:35 visual_prompt]: Loading test data...
[12/04 08:58:35 visual_prompt]: Constructing mammo-cbis dataset test...
[12/04 08:58:35 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[12/04 08:58:37 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[12/04 08:58:37 visual_prompt]: tuned percent:0.536
[12/04 08:58:37 visual_prompt]: Device used for model: 0
[12/04 08:58:37 visual_prompt]: Setting up Evaluator...
[12/04 08:58:37 visual_prompt]: Setting up Trainer...
[12/04 08:58:37 visual_prompt]: 	Setting up the optimizer...
[12/04 08:58:37 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[12/04 09:04:52 visual_prompt]: Epoch 1 / 100: avg data time: 9.83e+00, avg batch time: 10.7026, average train loss: 1.4576
[12/04 09:05:36 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.5235, average loss: 1.4668
[12/04 09:05:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.96	
[12/04 09:07:26 visual_prompt]: Inference (test):avg data time: 3.23e-05, avg batch time: 0.5111, average loss: 1.3289
[12/04 09:07:26 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 48.26	
[12/04 09:07:26 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.1
[12/04 09:13:40 visual_prompt]: Epoch 2 / 100: avg data time: 9.81e+00, avg batch time: 10.6902, average train loss: 2.0171
[12/04 09:14:24 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.5233, average loss: 0.6976
[12/04 09:14:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 44.63	
[12/04 09:16:14 visual_prompt]: Inference (test):avg data time: 2.92e-05, avg batch time: 0.5143, average loss: 0.6764
[12/04 09:16:14 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 50.87	
[12/04 09:16:14 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.2
[12/04 09:22:28 visual_prompt]: Epoch 3 / 100: avg data time: 9.79e+00, avg batch time: 10.6730, average train loss: 0.7429
[12/04 09:23:12 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.5301, average loss: 0.6968
[12/04 09:23:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.07	
[12/04 09:25:02 visual_prompt]: Inference (test):avg data time: 2.79e-05, avg batch time: 0.5145, average loss: 0.6741
[12/04 09:25:02 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 53.92	
[12/04 09:25:02 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.3
[12/04 09:34:20 visual_prompt]: Epoch 4 / 100: avg data time: 1.50e+01, avg batch time: 15.9203, average train loss: 0.7430
[12/04 09:36:04 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.5360, average loss: 0.7005
[12/04 09:36:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.93	rocauc: 52.90	
[12/04 09:41:41 visual_prompt]: Inference (test):avg data time: 2.89e-05, avg batch time: 0.5135, average loss: 0.7018
[12/04 09:41:41 visual_prompt]: Classification results with test_mammo-cbis: top1: 44.19	rocauc: 56.83	
[12/04 09:41:41 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.4
[12/04 09:47:59 visual_prompt]: Epoch 5 / 100: avg data time: 9.92e+00, avg batch time: 10.7945, average train loss: 0.7491
[12/04 09:48:43 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.5316, average loss: 0.8209
[12/04 09:48:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.01	
[12/04 09:50:34 visual_prompt]: Inference (test):avg data time: 2.84e-05, avg batch time: 0.5131, average loss: 0.7616
[12/04 09:50:34 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 58.64	
[12/04 09:50:34 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.5
[12/04 09:56:49 visual_prompt]: Epoch 6 / 100: avg data time: 9.85e+00, avg batch time: 10.7228, average train loss: 0.7674
[12/04 09:57:32 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.5321, average loss: 0.7503
[12/04 09:57:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.01	
[12/04 09:59:23 visual_prompt]: Inference (test):avg data time: 3.34e-05, avg batch time: 0.5161, average loss: 0.7055
[12/04 09:59:23 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 59.80	
[12/04 09:59:23 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.6
[12/04 10:05:38 visual_prompt]: Epoch 7 / 100: avg data time: 9.83e+00, avg batch time: 10.7040, average train loss: 0.7434
[12/04 10:06:22 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.5270, average loss: 0.6901
[12/04 10:06:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.07	rocauc: 58.27	
[12/04 10:08:12 visual_prompt]: Inference (test):avg data time: 2.88e-05, avg batch time: 0.5150, average loss: 0.6905
[12/04 10:08:12 visual_prompt]: Classification results with test_mammo-cbis: top1: 55.50	rocauc: 61.30	
[12/04 10:08:12 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.7
[12/04 10:14:27 visual_prompt]: Epoch 8 / 100: avg data time: 9.83e+00, avg batch time: 10.7113, average train loss: 0.7156
[12/04 10:15:11 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.5290, average loss: 0.6780
[12/04 10:15:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 61.52	
[12/04 10:17:01 visual_prompt]: Inference (test):avg data time: 2.83e-05, avg batch time: 0.5200, average loss: 0.6532
[12/04 10:17:01 visual_prompt]: Classification results with test_mammo-cbis: top1: 61.40	rocauc: 63.98	
[12/04 10:17:01 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.8
[12/04 10:23:16 visual_prompt]: Epoch 9 / 100: avg data time: 9.82e+00, avg batch time: 10.6963, average train loss: 0.7783
[12/04 10:23:59 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.5280, average loss: 0.7840
[12/04 10:23:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.17	
[12/04 10:25:50 visual_prompt]: Inference (test):avg data time: 3.05e-05, avg batch time: 0.5129, average loss: 0.7203
[12/04 10:25:50 visual_prompt]: Classification results with test_mammo-cbis: top1: 58.76	rocauc: 64.43	
[12/04 10:25:50 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.9
[12/04 10:32:04 visual_prompt]: Epoch 10 / 100: avg data time: 9.81e+00, avg batch time: 10.6861, average train loss: 0.8455
[12/04 10:32:47 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.5310, average loss: 0.6635
[12/04 10:32:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 64.15	
[12/04 10:34:38 visual_prompt]: Inference (test):avg data time: 3.23e-05, avg batch time: 0.5153, average loss: 0.6481
[12/04 10:34:38 visual_prompt]: Classification results with test_mammo-cbis: top1: 63.10	rocauc: 64.34	
[12/04 10:34:38 visual_prompt]: Training 11 / 100 epoch, with learning rate 1.0
[12/04 10:40:53 visual_prompt]: Epoch 11 / 100: avg data time: 9.83e+00, avg batch time: 10.7048, average train loss: 0.8327
[12/04 10:41:37 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.5306, average loss: 0.7445
[12/04 10:41:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 65.94	
[12/04 10:43:37 visual_prompt]: Inference (test):avg data time: 2.96e-05, avg batch time: 0.5135, average loss: 0.6922
[12/04 10:43:37 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 66.95	
[12/04 10:43:37 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.9996954135095479
[12/04 10:50:39 visual_prompt]: Epoch 12 / 100: avg data time: 1.12e+01, avg batch time: 12.0749, average train loss: 1.4255
[12/04 10:51:29 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.5281, average loss: 1.8546
[12/04 10:51:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 64.47	
[12/04 10:53:33 visual_prompt]: Inference (test):avg data time: 2.77e-05, avg batch time: 0.5165, average loss: 1.6671
[12/04 10:53:33 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 65.02	
[12/04 10:53:33 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.9987820251299121
[12/04 11:00:14 visual_prompt]: Epoch 13 / 100: avg data time: 1.06e+01, avg batch time: 11.4514, average train loss: 0.9406
[12/04 11:00:58 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.5283, average loss: 0.6469
[12/04 11:00:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 67.61	
[12/04 11:02:48 visual_prompt]: Inference (test):avg data time: 2.79e-05, avg batch time: 0.5133, average loss: 0.6376
[12/04 11:02:48 visual_prompt]: Classification results with test_mammo-cbis: top1: 63.41	rocauc: 66.60	
[12/04 11:02:48 visual_prompt]: Best epoch 13: best metric: -0.647
[12/04 11:02:48 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.9972609476841366
[12/04 11:09:03 visual_prompt]: Epoch 14 / 100: avg data time: 9.83e+00, avg batch time: 10.7073, average train loss: 0.7610
[12/04 11:09:47 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.5360, average loss: 0.7053
[12/04 11:09:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 69.07	
[12/04 11:11:44 visual_prompt]: Inference (test):avg data time: 3.25e-05, avg batch time: 0.5149, average loss: 0.6581
[12/04 11:11:44 visual_prompt]: Classification results with test_mammo-cbis: top1: 64.19	rocauc: 67.14	
[12/04 11:11:44 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.9951340343707852
[12/04 11:19:34 visual_prompt]: Epoch 15 / 100: avg data time: 1.26e+01, avg batch time: 13.4261, average train loss: 0.7366
[12/04 11:20:28 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.5286, average loss: 0.6473
[12/04 11:20:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 69.42	
[12/04 11:23:53 visual_prompt]: Inference (test):avg data time: 2.53e-05, avg batch time: 0.5211, average loss: 0.6343
[12/04 11:23:53 visual_prompt]: Classification results with test_mammo-cbis: top1: 64.03	rocauc: 67.82	
[12/04 11:23:53 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.9924038765061041
[12/04 11:31:58 visual_prompt]: Epoch 16 / 100: avg data time: 1.30e+01, avg batch time: 13.8610, average train loss: 0.6908
[12/04 11:32:43 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.5321, average loss: 0.6704
[12/04 11:32:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 69.63	
[12/04 11:34:46 visual_prompt]: Inference (test):avg data time: 2.95e-05, avg batch time: 0.5136, average loss: 0.6910
[12/04 11:34:46 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.53	rocauc: 69.02	
[12/04 11:34:46 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.9890738003669028
[12/04 11:43:08 visual_prompt]: Epoch 17 / 100: avg data time: 1.35e+01, avg batch time: 14.3392, average train loss: 0.8233
[12/04 11:44:10 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.5241, average loss: 0.9368
[12/04 11:44:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 69.76	
[12/04 11:47:21 visual_prompt]: Inference (test):avg data time: 2.53e-05, avg batch time: 0.5121, average loss: 0.8332
[12/04 11:47:21 visual_prompt]: Classification results with test_mammo-cbis: top1: 61.40	rocauc: 68.56	
[12/04 11:47:21 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.9851478631379982
[12/04 11:54:18 visual_prompt]: Epoch 18 / 100: avg data time: 1.10e+01, avg batch time: 11.9126, average train loss: 0.7430
[12/04 11:55:05 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.5295, average loss: 0.8036
[12/04 11:55:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.54	rocauc: 70.48	
[12/04 11:57:10 visual_prompt]: Inference (test):avg data time: 2.97e-05, avg batch time: 0.5162, average loss: 0.7344
[12/04 11:57:10 visual_prompt]: Classification results with test_mammo-cbis: top1: 64.81	rocauc: 67.51	
[12/04 11:57:10 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.9806308479691594
[12/04 12:06:02 visual_prompt]: Epoch 19 / 100: avg data time: 1.43e+01, avg batch time: 15.2030, average train loss: 0.7562
[12/04 12:07:02 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.5332, average loss: 0.9188
[12/04 12:07:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 72.35	
[12/04 12:10:45 visual_prompt]: Inference (test):avg data time: 3.10e-05, avg batch time: 0.5099, average loss: 0.8298
[12/04 12:10:45 visual_prompt]: Classification results with test_mammo-cbis: top1: 61.71	rocauc: 68.87	
[12/04 12:10:45 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.9755282581475768
[12/04 12:18:16 visual_prompt]: Epoch 20 / 100: avg data time: 1.20e+01, avg batch time: 12.8706, average train loss: 0.7762
[12/04 12:19:13 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.5252, average loss: 0.8009
[12/04 12:19:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 71.73	
[12/04 12:21:29 visual_prompt]: Inference (test):avg data time: 3.13e-05, avg batch time: 0.5119, average loss: 0.7273
[12/04 12:21:29 visual_prompt]: Classification results with test_mammo-cbis: top1: 65.58	rocauc: 69.20	
[12/04 12:21:29 visual_prompt]: Stopping early.
[12/04 12:21:30 visual_prompt]: Rank of current process: 0. World size: 1
[12/04 12:21:30 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA TITAN Xp
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[12/04 12:21:30 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss', 'RECORD_GPU_SNAPSHOT', 'True'])
[12/04 12:21:30 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[12/04 12:21:30 visual_prompt]: Training with config:
[12/04 12:21:30 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/test/seed3172/lr1.0_wd0.0/patience7/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 3172, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 1.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True}), 'RECORD_GPU_SNAPSHOT': True})
[12/04 12:21:30 visual_prompt]: Loading training data...
[12/04 12:21:30 visual_prompt]: Constructing mammo-cbis dataset train...
[12/04 12:21:30 visual_prompt]: Loading validation data...
[12/04 12:21:30 visual_prompt]: Constructing mammo-cbis dataset val...
[12/04 12:21:30 visual_prompt]: Loading test data...
[12/04 12:21:30 visual_prompt]: Constructing mammo-cbis dataset test...
[12/04 12:21:30 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[12/04 12:21:34 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[12/04 12:21:34 visual_prompt]: tuned percent:0.536
[12/04 12:21:34 visual_prompt]: Device used for model: 0
[12/04 12:21:34 visual_prompt]: Setting up Evaluator...
[12/04 12:21:34 visual_prompt]: Setting up Trainer...
[12/04 12:21:34 visual_prompt]: 	Setting up the optimizer...
[12/04 12:21:34 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[12/04 12:28:59 visual_prompt]: Epoch 1 / 100: avg data time: 1.18e+01, avg batch time: 12.7082, average train loss: 1.5261
[12/04 12:29:51 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.5295, average loss: 1.5037
[12/04 12:29:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.85	
[12/04 12:32:02 visual_prompt]: Inference (test):avg data time: 3.43e-05, avg batch time: 0.5177, average loss: 1.6174
[12/04 12:32:02 visual_prompt]: Classification results with test_mammo-cbis: top1: 40.93	rocauc: 50.41	
[12/04 12:32:02 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.1
[12/04 12:38:45 visual_prompt]: Epoch 2 / 100: avg data time: 1.06e+01, avg batch time: 11.5107, average train loss: 2.1762
[12/04 12:39:32 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.5298, average loss: 0.6948
[12/04 12:39:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 49.19	rocauc: 52.32	
[12/04 12:41:31 visual_prompt]: Inference (test):avg data time: 3.51e-05, avg batch time: 0.5146, average loss: 0.7000
[12/04 12:41:31 visual_prompt]: Classification results with test_mammo-cbis: top1: 44.96	rocauc: 51.33	
[12/04 12:41:31 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.2
[12/04 12:48:13 visual_prompt]: Epoch 3 / 100: avg data time: 1.06e+01, avg batch time: 11.4889, average train loss: 0.7252
[12/04 12:49:00 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.5240, average loss: 0.7079
[12/04 12:49:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.33	
[12/04 12:50:58 visual_prompt]: Inference (test):avg data time: 3.31e-05, avg batch time: 0.5119, average loss: 0.6822
[12/04 12:50:58 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 55.22	
[12/04 12:50:58 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.3
[12/04 12:57:41 visual_prompt]: Epoch 4 / 100: avg data time: 1.06e+01, avg batch time: 11.4953, average train loss: 0.7200
[12/04 12:58:27 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.5334, average loss: 0.6934
[12/04 12:58:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.29	
[12/04 13:00:26 visual_prompt]: Inference (test):avg data time: 3.76e-05, avg batch time: 0.5183, average loss: 0.6731
[12/04 13:00:26 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 57.99	
[12/04 13:00:26 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.4
[12/04 13:07:09 visual_prompt]: Epoch 5 / 100: avg data time: 1.06e+01, avg batch time: 11.5036, average train loss: 0.7501
[12/04 13:07:56 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.5317, average loss: 0.7198
[12/04 13:07:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.93	
[12/04 13:09:58 visual_prompt]: Inference (test):avg data time: 3.42e-05, avg batch time: 0.5143, average loss: 0.7393
[12/04 13:09:58 visual_prompt]: Classification results with test_mammo-cbis: top1: 40.93	rocauc: 59.20	
[12/04 13:09:58 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.5
[12/04 13:16:51 visual_prompt]: Epoch 6 / 100: avg data time: 1.09e+01, avg batch time: 11.8022, average train loss: 0.7733
[12/04 13:17:42 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.5297, average loss: 1.0334
[12/04 13:17:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.46	
[12/04 13:19:43 visual_prompt]: Inference (test):avg data time: 3.60e-05, avg batch time: 0.5135, average loss: 0.9456
[12/04 13:19:43 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 60.17	
[12/04 13:19:43 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.6
[12/04 13:26:28 visual_prompt]: Epoch 7 / 100: avg data time: 1.07e+01, avg batch time: 11.5429, average train loss: 0.8884
[12/04 13:27:14 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.5305, average loss: 0.6814
[12/04 13:27:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 59.61	
[12/04 13:29:13 visual_prompt]: Inference (test):avg data time: 3.83e-05, avg batch time: 0.5121, average loss: 0.6823
[12/04 13:29:13 visual_prompt]: Classification results with test_mammo-cbis: top1: 58.76	rocauc: 59.70	
[12/04 13:29:13 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.7
[12/04 13:35:54 visual_prompt]: Epoch 8 / 100: avg data time: 1.06e+01, avg batch time: 11.4585, average train loss: 1.1004
[12/04 13:36:41 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.5326, average loss: 0.8829
[12/04 13:36:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.42	
[12/04 13:38:39 visual_prompt]: Inference (test):avg data time: 3.60e-05, avg batch time: 0.5120, average loss: 0.8174
[12/04 13:38:39 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 59.80	
[12/04 13:38:39 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.8
[12/04 13:49:17 visual_prompt]: Epoch 9 / 100: avg data time: 1.74e+01, avg batch time: 18.2337, average train loss: 0.9100
[12/04 13:50:29 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.5261, average loss: 0.7230
[12/04 13:50:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 61.29	
[12/04 13:52:47 visual_prompt]: Inference (test):avg data time: 3.37e-05, avg batch time: 0.5155, average loss: 0.7461
[12/04 13:52:47 visual_prompt]: Classification results with test_mammo-cbis: top1: 41.40	rocauc: 60.64	
[12/04 13:52:47 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.9
[12/04 14:01:01 visual_prompt]: Epoch 10 / 100: avg data time: 1.32e+01, avg batch time: 14.1216, average train loss: 0.8246
[12/04 14:01:49 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.5325, average loss: 0.6688
[12/04 14:01:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 61.67	
[12/04 14:03:49 visual_prompt]: Inference (test):avg data time: 3.39e-05, avg batch time: 0.5113, average loss: 0.6630
[12/04 14:03:49 visual_prompt]: Classification results with test_mammo-cbis: top1: 62.48	rocauc: 62.21	
[12/04 14:03:49 visual_prompt]: Training 11 / 100 epoch, with learning rate 1.0
[12/04 14:10:33 visual_prompt]: Epoch 11 / 100: avg data time: 1.07e+01, avg batch time: 11.5279, average train loss: 1.2974
[12/04 14:11:20 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.5283, average loss: 0.9267
[12/04 14:11:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.62	
[12/04 14:13:18 visual_prompt]: Inference (test):avg data time: 3.50e-05, avg batch time: 0.5128, average loss: 0.8480
[12/04 14:13:18 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 60.63	
[12/04 14:13:18 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.9996954135095479
[12/04 14:20:01 visual_prompt]: Epoch 12 / 100: avg data time: 1.06e+01, avg batch time: 11.5039, average train loss: 1.1017
[12/04 14:20:47 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.5313, average loss: 1.2607
[12/04 14:20:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 61.25	
[12/04 14:22:45 visual_prompt]: Inference (test):avg data time: 3.78e-05, avg batch time: 0.5096, average loss: 1.3676
[12/04 14:22:45 visual_prompt]: Classification results with test_mammo-cbis: top1: 40.93	rocauc: 61.35	
[12/04 14:22:45 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.9987820251299121
[12/04 14:29:30 visual_prompt]: Epoch 13 / 100: avg data time: 1.07e+01, avg batch time: 11.5589, average train loss: 0.8946
[12/04 14:30:17 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.5332, average loss: 0.7911
[12/04 14:30:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.20	
[12/04 14:32:15 visual_prompt]: Inference (test):avg data time: 3.73e-05, avg batch time: 0.5168, average loss: 0.7302
[12/04 14:32:15 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 63.12	
[12/04 14:32:15 visual_prompt]: Best epoch 13: best metric: -0.791
[12/04 14:32:15 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.9972609476841366
[12/04 14:38:57 visual_prompt]: Epoch 14 / 100: avg data time: 1.06e+01, avg batch time: 11.4573, average train loss: 0.7483
[12/04 14:39:43 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.5308, average loss: 0.7666
[12/04 14:39:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.47	
[12/04 14:41:43 visual_prompt]: Inference (test):avg data time: 3.36e-05, avg batch time: 0.5146, average loss: 0.7126
[12/04 14:41:43 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.22	rocauc: 62.68	
[12/04 14:41:43 visual_prompt]: Best epoch 14: best metric: -0.767
[12/04 14:41:43 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.9951340343707852
[12/04 14:48:29 visual_prompt]: Epoch 15 / 100: avg data time: 1.07e+01, avg batch time: 11.5768, average train loss: 0.7891
[12/04 14:49:16 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.5356, average loss: 0.7304
[12/04 14:49:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 49.19	rocauc: 62.90	
[12/04 14:51:21 visual_prompt]: Inference (test):avg data time: 3.40e-05, avg batch time: 0.5068, average loss: 0.7684
[12/04 14:51:21 visual_prompt]: Classification results with test_mammo-cbis: top1: 45.58	rocauc: 62.70	
[12/04 14:51:21 visual_prompt]: Best epoch 15: best metric: -0.730
[12/04 14:51:21 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.9924038765061041
[12/04 15:01:16 visual_prompt]: Epoch 16 / 100: avg data time: 1.61e+01, avg batch time: 16.9964, average train loss: 0.9814
[12/04 15:02:35 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.5280, average loss: 0.6738
[12/04 15:02:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 62.78	
[12/04 15:05:55 visual_prompt]: Inference (test):avg data time: 4.01e-05, avg batch time: 0.5154, average loss: 0.6478
[12/04 15:05:55 visual_prompt]: Classification results with test_mammo-cbis: top1: 61.55	rocauc: 63.49	
[12/04 15:05:55 visual_prompt]: Best epoch 16: best metric: -0.674
[12/04 15:05:55 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.9890738003669028
[12/04 15:13:53 visual_prompt]: Epoch 17 / 100: avg data time: 1.28e+01, avg batch time: 13.6446, average train loss: 0.6748
[12/04 15:14:41 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.5363, average loss: 0.6965
[12/04 15:14:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 65.31	
[12/04 15:16:40 visual_prompt]: Inference (test):avg data time: 3.63e-05, avg batch time: 0.5133, average loss: 0.6606
[12/04 15:16:40 visual_prompt]: Classification results with test_mammo-cbis: top1: 62.48	rocauc: 63.69	
[12/04 15:16:40 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.9851478631379982
[12/04 15:23:24 visual_prompt]: Epoch 18 / 100: avg data time: 1.06e+01, avg batch time: 11.5218, average train loss: 0.7631
[12/04 15:24:10 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.5241, average loss: 1.0036
[12/04 15:24:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 67.00	
[12/04 15:26:09 visual_prompt]: Inference (test):avg data time: 4.64e-05, avg batch time: 0.5087, average loss: 1.1089
[12/04 15:26:09 visual_prompt]: Classification results with test_mammo-cbis: top1: 40.93	rocauc: 64.86	
[12/04 15:26:09 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.9806308479691594
[12/04 15:32:54 visual_prompt]: Epoch 19 / 100: avg data time: 1.07e+01, avg batch time: 11.5710, average train loss: 0.7925
[12/04 15:33:41 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.5260, average loss: 1.2793
[12/04 15:33:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 68.73	
[12/04 15:35:43 visual_prompt]: Inference (test):avg data time: 3.63e-05, avg batch time: 0.5138, average loss: 1.1394
[12/04 15:35:43 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 65.39	
[12/04 15:35:43 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.9755282581475768
[12/04 15:42:08 visual_prompt]: Epoch 20 / 100: avg data time: 1.01e+01, avg batch time: 10.9948, average train loss: 0.8615
[12/04 15:42:53 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.5272, average loss: 0.8123
[12/04 15:42:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 69.91	
[12/04 15:44:47 visual_prompt]: Inference (test):avg data time: 3.28e-05, avg batch time: 0.5132, average loss: 0.7423
[12/04 15:44:47 visual_prompt]: Classification results with test_mammo-cbis: top1: 61.24	rocauc: 66.20	
[12/04 15:44:47 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.9698463103929542
[12/04 15:55:24 visual_prompt]: Epoch 21 / 100: avg data time: 1.74e+01, avg batch time: 18.2185, average train loss: 0.6796
[12/04 15:56:46 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.5263, average loss: 0.7348
[12/04 15:56:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 71.48	
[12/04 16:00:06 visual_prompt]: Inference (test):avg data time: 4.06e-05, avg batch time: 0.5143, average loss: 0.6943
[12/04 16:00:06 visual_prompt]: Classification results with test_mammo-cbis: top1: 63.57	rocauc: 65.34	
[12/04 16:00:06 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.9635919272833937
[12/04 16:09:34 visual_prompt]: Epoch 22 / 100: avg data time: 1.54e+01, avg batch time: 16.2268, average train loss: 0.7697
[12/04 16:10:19 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.5251, average loss: 0.6336
[12/04 16:10:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 69.39	
[12/04 16:12:13 visual_prompt]: Inference (test):avg data time: 2.99e-05, avg batch time: 0.5141, average loss: 0.6339
[12/04 16:12:13 visual_prompt]: Classification results with test_mammo-cbis: top1: 64.96	rocauc: 66.59	
[12/04 16:12:13 visual_prompt]: Best epoch 22: best metric: -0.634
[12/04 16:12:13 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.9567727288213004
[12/04 16:19:25 visual_prompt]: Epoch 23 / 100: avg data time: 1.15e+01, avg batch time: 12.3515, average train loss: 0.7943
[12/04 16:20:25 visual_prompt]: Inference (val):avg data time: 3.45e-05, avg batch time: 0.5304, average loss: 0.6836
[12/04 16:20:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 71.68	
[12/04 16:22:56 visual_prompt]: Inference (test):avg data time: 3.30e-05, avg batch time: 0.5155, average loss: 0.7467
[12/04 16:22:56 visual_prompt]: Classification results with test_mammo-cbis: top1: 52.09	rocauc: 65.95	
[12/04 16:22:56 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.9493970231495835
[12/04 16:32:45 visual_prompt]: Epoch 24 / 100: avg data time: 1.60e+01, avg batch time: 16.8251, average train loss: 0.8839
[12/04 16:33:34 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.5306, average loss: 0.9678
[12/04 16:33:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 69.86	
[12/04 16:36:11 visual_prompt]: Inference (test):avg data time: 3.22e-05, avg batch time: 0.5131, average loss: 0.8691
[12/04 16:36:11 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.22	rocauc: 66.83	
[12/04 16:36:11 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.9414737964294635
[12/04 16:43:32 visual_prompt]: Epoch 25 / 100: avg data time: 1.17e+01, avg batch time: 12.5890, average train loss: 0.7432
[12/04 16:44:18 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.5287, average loss: 0.6797
[12/04 16:44:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 71.31	
[12/04 16:46:16 visual_prompt]: Inference (test):avg data time: 3.09e-05, avg batch time: 0.5109, average loss: 0.7377
[12/04 16:46:16 visual_prompt]: Classification results with test_mammo-cbis: top1: 57.05	rocauc: 68.71	
[12/04 16:46:16 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.9330127018922194
[12/04 16:52:52 visual_prompt]: Epoch 26 / 100: avg data time: 1.04e+01, avg batch time: 11.3172, average train loss: 0.6991
[12/04 16:53:38 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.5275, average loss: 0.6258
[12/04 16:53:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 69.51	rocauc: 72.99	
[12/04 16:55:32 visual_prompt]: Inference (test):avg data time: 3.43e-05, avg batch time: 0.5095, average loss: 0.6725
[12/04 16:55:32 visual_prompt]: Classification results with test_mammo-cbis: top1: 60.00	rocauc: 67.09	
[12/04 16:55:32 visual_prompt]: Best epoch 26: best metric: -0.626
[12/04 16:55:32 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.9240240480782129
[12/04 17:02:09 visual_prompt]: Epoch 27 / 100: avg data time: 1.05e+01, avg batch time: 11.3400, average train loss: 0.6682
[12/04 17:02:56 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.5263, average loss: 1.5028
[12/04 17:02:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 72.34	
[12/04 17:04:51 visual_prompt]: Inference (test):avg data time: 3.48e-05, avg batch time: 0.5191, average loss: 1.7268
[12/04 17:04:51 visual_prompt]: Classification results with test_mammo-cbis: top1: 40.93	rocauc: 69.49	
[12/04 17:04:51 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.9145187862775208
[12/04 17:11:18 visual_prompt]: Epoch 28 / 100: avg data time: 1.02e+01, avg batch time: 11.0549, average train loss: 0.7187
[12/04 17:12:05 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.5295, average loss: 0.6191
[12/04 17:12:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 73.05	
[12/04 17:14:00 visual_prompt]: Inference (test):avg data time: 3.26e-05, avg batch time: 0.5181, average loss: 0.6400
[12/04 17:14:00 visual_prompt]: Classification results with test_mammo-cbis: top1: 64.96	rocauc: 67.40	
[12/04 17:14:00 visual_prompt]: Best epoch 28: best metric: -0.619
[12/04 17:14:00 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.9045084971874737
[12/04 17:20:26 visual_prompt]: Epoch 29 / 100: avg data time: 1.01e+01, avg batch time: 11.0177, average train loss: 0.7238
[12/04 17:21:10 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.5268, average loss: 0.5984
[12/04 17:21:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 68.29	rocauc: 74.29	
[12/04 17:23:05 visual_prompt]: Inference (test):avg data time: 3.20e-05, avg batch time: 0.5104, average loss: 0.6197
[12/04 17:23:05 visual_prompt]: Classification results with test_mammo-cbis: top1: 65.89	rocauc: 69.23	
[12/04 17:23:05 visual_prompt]: Best epoch 29: best metric: -0.598
[12/04 17:23:05 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.8940053768033609
[12/04 17:29:29 visual_prompt]: Epoch 30 / 100: avg data time: 1.01e+01, avg batch time: 10.9930, average train loss: 0.6337
[12/04 17:30:16 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.5296, average loss: 0.6132
[12/04 17:30:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.07	rocauc: 74.32	
[12/04 17:32:13 visual_prompt]: Inference (test):avg data time: 3.01e-05, avg batch time: 0.5194, average loss: 0.6931
[12/04 17:32:13 visual_prompt]: Classification results with test_mammo-cbis: top1: 60.62	rocauc: 68.04	
[12/04 17:32:13 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.883022221559489
[12/04 17:38:37 visual_prompt]: Epoch 31 / 100: avg data time: 1.01e+01, avg batch time: 10.9877, average train loss: 0.6383
[12/04 17:39:22 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.5256, average loss: 0.9566
[12/04 17:39:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 47.97	rocauc: 73.45	
[12/04 17:41:20 visual_prompt]: Inference (test):avg data time: 2.93e-05, avg batch time: 0.5098, average loss: 1.1132
[12/04 17:41:20 visual_prompt]: Classification results with test_mammo-cbis: top1: 42.64	rocauc: 68.42	
[12/04 17:41:20 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.8715724127386971
[12/04 17:47:49 visual_prompt]: Epoch 32 / 100: avg data time: 1.03e+01, avg batch time: 11.1292, average train loss: 0.6379
[12/04 17:48:39 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.5257, average loss: 0.7484
[12/04 17:48:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 74.75	
[12/04 17:50:44 visual_prompt]: Inference (test):avg data time: 2.98e-05, avg batch time: 0.5142, average loss: 0.8925
[12/04 17:50:44 visual_prompt]: Classification results with test_mammo-cbis: top1: 48.22	rocauc: 68.65	
[12/04 17:50:44 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.8596699001693255
[12/04 17:58:09 visual_prompt]: Epoch 33 / 100: avg data time: 1.18e+01, avg batch time: 12.7150, average train loss: 0.6610
[12/04 17:58:54 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.5300, average loss: 0.7518
[12/04 17:58:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 72.17	
[12/04 18:00:57 visual_prompt]: Inference (test):avg data time: 3.22e-05, avg batch time: 0.5116, average loss: 0.7106
[12/04 18:00:57 visual_prompt]: Classification results with test_mammo-cbis: top1: 65.58	rocauc: 68.09	
[12/04 18:00:57 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.8473291852294986
[12/04 18:07:35 visual_prompt]: Epoch 34 / 100: avg data time: 1.05e+01, avg batch time: 11.3668, average train loss: 0.6463
[12/04 18:08:20 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.5309, average loss: 0.5960
[12/04 18:08:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 70.33	rocauc: 74.41	
[12/04 18:10:13 visual_prompt]: Inference (test):avg data time: 3.07e-05, avg batch time: 0.5093, average loss: 0.6537
[12/04 18:10:13 visual_prompt]: Classification results with test_mammo-cbis: top1: 64.19	rocauc: 69.50	
[12/04 18:10:13 visual_prompt]: Best epoch 34: best metric: -0.596
[12/04 18:10:13 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.8345653031794291
[12/04 18:16:35 visual_prompt]: Epoch 35 / 100: avg data time: 1.00e+01, avg batch time: 10.9008, average train loss: 0.5993
[12/04 18:17:19 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.5291, average loss: 0.6429
[12/04 18:17:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 72.57	
[12/04 18:19:12 visual_prompt]: Inference (test):avg data time: 3.18e-05, avg batch time: 0.5163, average loss: 0.7204
[12/04 18:19:12 visual_prompt]: Classification results with test_mammo-cbis: top1: 61.55	rocauc: 68.64	
[12/04 18:19:12 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.8213938048432696
[12/04 18:25:40 visual_prompt]: Epoch 36 / 100: avg data time: 1.02e+01, avg batch time: 11.0836, average train loss: 0.6188
[12/04 18:26:25 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.5332, average loss: 0.6746
[12/04 18:26:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.01	rocauc: 73.12	
[12/04 18:28:20 visual_prompt]: Inference (test):avg data time: 3.63e-05, avg batch time: 0.5082, average loss: 0.7910
[12/04 18:28:20 visual_prompt]: Classification results with test_mammo-cbis: top1: 55.81	rocauc: 67.40	
[12/04 18:28:20 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.8078307376628291
[12/04 18:34:46 visual_prompt]: Epoch 37 / 100: avg data time: 1.02e+01, avg batch time: 11.0425, average train loss: 0.5740
[12/04 18:35:31 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.5302, average loss: 0.7768
[12/04 18:35:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 74.18	
[12/04 18:37:24 visual_prompt]: Inference (test):avg data time: 3.76e-05, avg batch time: 0.5155, average loss: 0.9547
[12/04 18:37:24 visual_prompt]: Classification results with test_mammo-cbis: top1: 48.53	rocauc: 67.47	
[12/04 18:37:24 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.7938926261462366
[12/04 18:43:48 visual_prompt]: Epoch 38 / 100: avg data time: 1.01e+01, avg batch time: 10.9610, average train loss: 0.5363
[12/04 18:44:32 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.5294, average loss: 0.6812
[12/04 18:44:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 73.13	
[12/04 18:46:27 visual_prompt]: Inference (test):avg data time: 3.23e-05, avg batch time: 0.5153, average loss: 0.8123
[12/04 18:46:27 visual_prompt]: Classification results with test_mammo-cbis: top1: 55.81	rocauc: 68.07	
[12/04 18:46:27 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.7795964517353734
[12/04 18:57:36 visual_prompt]: Epoch 39 / 100: avg data time: 1.82e+01, avg batch time: 19.1225, average train loss: 0.5642
[12/04 18:58:54 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.5255, average loss: 0.6388
[12/04 18:58:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 72.44	
[12/04 19:02:36 visual_prompt]: Inference (test):avg data time: 3.45e-05, avg batch time: 0.5167, average loss: 0.6420
[12/04 19:02:36 visual_prompt]: Classification results with test_mammo-cbis: top1: 67.44	rocauc: 68.91	
[12/04 19:02:36 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.7649596321166025
[12/04 19:10:08 visual_prompt]: Epoch 40 / 100: avg data time: 1.20e+01, avg batch time: 12.9168, average train loss: 0.5893
[12/04 19:10:54 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.5379, average loss: 0.6605
[12/04 19:10:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 74.51	
[12/04 19:12:48 visual_prompt]: Inference (test):avg data time: 3.15e-05, avg batch time: 0.5133, average loss: 0.6728
[12/04 19:12:48 visual_prompt]: Classification results with test_mammo-cbis: top1: 65.74	rocauc: 67.39	
[12/04 19:12:48 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.75
[12/04 19:19:15 visual_prompt]: Epoch 41 / 100: avg data time: 1.02e+01, avg batch time: 11.0540, average train loss: 0.5897
[12/04 19:20:00 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.5376, average loss: 0.6343
[12/04 19:20:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.67	rocauc: 73.62	
[12/04 19:21:54 visual_prompt]: Inference (test):avg data time: 3.51e-05, avg batch time: 0.5111, average loss: 0.6597
[12/04 19:21:54 visual_prompt]: Classification results with test_mammo-cbis: top1: 65.58	rocauc: 68.48	
[12/04 19:21:54 visual_prompt]: Stopping early.
[12/04 19:21:54 visual_prompt]: Rank of current process: 0. World size: 1
[12/04 19:21:54 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA TITAN Xp
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[12/04 19:21:54 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss', 'RECORD_GPU_SNAPSHOT', 'True'])
[12/04 19:21:54 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[12/04 19:21:54 visual_prompt]: Training with config:
[12/04 19:21:54 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/test/seed8393/lr1.0_wd0.0/patience7/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 8393, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 1.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True}), 'RECORD_GPU_SNAPSHOT': True})
[12/04 19:21:54 visual_prompt]: Loading training data...
[12/04 19:21:54 visual_prompt]: Constructing mammo-cbis dataset train...
[12/04 19:21:55 visual_prompt]: Loading validation data...
[12/04 19:21:55 visual_prompt]: Constructing mammo-cbis dataset val...
[12/04 19:21:55 visual_prompt]: Loading test data...
[12/04 19:21:55 visual_prompt]: Constructing mammo-cbis dataset test...
[12/04 19:21:55 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[12/04 19:22:09 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[12/04 19:22:09 visual_prompt]: tuned percent:0.536
[12/04 19:22:09 visual_prompt]: Device used for model: 0
[12/04 19:22:09 visual_prompt]: Setting up Evaluator...
[12/04 19:22:09 visual_prompt]: Setting up Trainer...
[12/04 19:22:09 visual_prompt]: 	Setting up the optimizer...
[12/04 19:22:09 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[12/04 19:28:34 visual_prompt]: Epoch 1 / 100: avg data time: 1.01e+01, avg batch time: 10.9863, average train loss: 1.1729
[12/04 19:29:19 visual_prompt]: Inference (val):avg data time: 3.70e-05, avg batch time: 0.5311, average loss: 1.1029
[12/04 19:29:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.37	
[12/04 19:31:14 visual_prompt]: Inference (test):avg data time: 3.45e-05, avg batch time: 0.5129, average loss: 0.9873
[12/04 19:31:14 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 50.71	
[12/04 19:31:14 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.1
[12/04 19:37:39 visual_prompt]: Epoch 2 / 100: avg data time: 1.01e+01, avg batch time: 10.9953, average train loss: 2.2301
[12/04 19:38:24 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.5326, average loss: 0.6896
[12/04 19:38:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.27	
[12/04 19:40:18 visual_prompt]: Inference (test):avg data time: 3.24e-05, avg batch time: 0.5132, average loss: 0.6745
[12/04 19:40:18 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 54.73	
[12/04 19:40:18 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.2
[12/04 19:46:43 visual_prompt]: Epoch 3 / 100: avg data time: 1.01e+01, avg batch time: 10.9823, average train loss: 0.7726
[12/04 19:47:27 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.5341, average loss: 0.6862
[12/04 19:47:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 54.36	
[12/04 19:49:21 visual_prompt]: Inference (test):avg data time: 3.26e-05, avg batch time: 0.5177, average loss: 0.6851
[12/04 19:49:21 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.84	rocauc: 55.13	
[12/04 19:49:21 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.3
[12/04 19:55:45 visual_prompt]: Epoch 4 / 100: avg data time: 1.01e+01, avg batch time: 10.9487, average train loss: 0.7082
[12/04 19:56:29 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.5350, average loss: 0.7139
[12/04 19:56:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.34	
[12/04 19:58:23 visual_prompt]: Inference (test):avg data time: 3.21e-05, avg batch time: 0.5191, average loss: 0.6823
[12/04 19:58:23 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 59.32	
[12/04 19:58:23 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.4
[12/04 20:04:49 visual_prompt]: Epoch 5 / 100: avg data time: 1.02e+01, avg batch time: 11.0309, average train loss: 0.7439
[12/04 20:05:34 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.5314, average loss: 0.7303
[12/04 20:05:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.77	
[12/04 20:07:28 visual_prompt]: Inference (test):avg data time: 3.67e-05, avg batch time: 0.5138, average loss: 0.6940
[12/04 20:07:28 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 59.06	
[12/04 20:07:28 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.5
[12/04 20:13:54 visual_prompt]: Epoch 6 / 100: avg data time: 1.02e+01, avg batch time: 11.0297, average train loss: 0.7617
[12/04 20:14:39 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.5272, average loss: 0.8019
[12/04 20:14:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.87	
[12/04 20:16:33 visual_prompt]: Inference (test):avg data time: 3.11e-05, avg batch time: 0.5190, average loss: 0.7463
[12/04 20:16:33 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 60.02	
[12/04 20:16:33 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.6
[12/04 20:22:59 visual_prompt]: Epoch 7 / 100: avg data time: 1.01e+01, avg batch time: 11.0005, average train loss: 0.7348
[12/04 20:23:43 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.5357, average loss: 0.7217
[12/04 20:23:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 44.31	rocauc: 60.67	
[12/04 20:25:37 visual_prompt]: Inference (test):avg data time: 3.58e-05, avg batch time: 0.5166, average loss: 0.7435
[12/04 20:25:37 visual_prompt]: Classification results with test_mammo-cbis: top1: 42.79	rocauc: 62.18	
[12/04 20:25:37 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.7
[12/04 20:32:02 visual_prompt]: Epoch 8 / 100: avg data time: 1.01e+01, avg batch time: 10.9871, average train loss: 0.7625
[12/04 20:32:46 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.5358, average loss: 1.3133
[12/04 20:32:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.74	
[12/04 20:34:39 visual_prompt]: Inference (test):avg data time: 3.15e-05, avg batch time: 0.5172, average loss: 1.1791
[12/04 20:34:39 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 62.57	
[12/04 20:34:39 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.8
[12/04 20:41:03 visual_prompt]: Epoch 9 / 100: avg data time: 1.01e+01, avg batch time: 10.9673, average train loss: 0.8245
[12/04 20:41:48 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.5328, average loss: 0.9541
[12/04 20:41:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.53	
[12/04 20:43:41 visual_prompt]: Inference (test):avg data time: 3.32e-05, avg batch time: 0.5226, average loss: 0.8604
[12/04 20:43:41 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 62.73	
[12/04 20:43:41 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.9
[12/04 20:50:04 visual_prompt]: Epoch 10 / 100: avg data time: 1.01e+01, avg batch time: 10.9448, average train loss: 0.8154
[12/04 20:50:48 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.5291, average loss: 0.8122
[12/04 20:50:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.80	
[12/04 20:52:42 visual_prompt]: Inference (test):avg data time: 3.63e-05, avg batch time: 0.5111, average loss: 0.7440
[12/04 20:52:42 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 63.28	
[12/04 20:52:42 visual_prompt]: Training 11 / 100 epoch, with learning rate 1.0
[12/04 20:59:08 visual_prompt]: Epoch 11 / 100: avg data time: 1.01e+01, avg batch time: 11.0061, average train loss: 0.8138
[12/04 20:59:52 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.5253, average loss: 1.7573
[12/04 20:59:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.06	
[12/04 21:01:46 visual_prompt]: Inference (test):avg data time: 3.45e-05, avg batch time: 0.5168, average loss: 1.5685
[12/04 21:01:46 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 64.20	
[12/04 21:01:46 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.9996954135095479
[12/04 21:08:12 visual_prompt]: Epoch 12 / 100: avg data time: 1.01e+01, avg batch time: 11.0224, average train loss: 0.8570
[12/04 21:08:57 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.5288, average loss: 0.7472
[12/04 21:08:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 49.19	rocauc: 63.55	
[12/04 21:10:52 visual_prompt]: Inference (test):avg data time: 3.08e-05, avg batch time: 0.5146, average loss: 0.7836
[12/04 21:10:52 visual_prompt]: Classification results with test_mammo-cbis: top1: 46.36	rocauc: 65.26	
[12/04 21:10:52 visual_prompt]: Best epoch 12: best metric: -0.747
[12/04 21:10:52 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.9987820251299121
[12/04 21:17:17 visual_prompt]: Epoch 13 / 100: avg data time: 1.01e+01, avg batch time: 11.0050, average train loss: 0.7739
[12/04 21:18:02 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.5384, average loss: 0.7530
[12/04 21:18:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 47.15	rocauc: 63.94	
[12/04 21:19:55 visual_prompt]: Inference (test):avg data time: 3.30e-05, avg batch time: 0.5135, average loss: 0.7873
[12/04 21:19:55 visual_prompt]: Classification results with test_mammo-cbis: top1: 41.24	rocauc: 65.17	
[12/04 21:19:55 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.9972609476841366
[12/04 21:26:18 visual_prompt]: Epoch 14 / 100: avg data time: 1.01e+01, avg batch time: 10.9560, average train loss: 0.7280
[12/04 21:27:03 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.5401, average loss: 0.6490
[12/04 21:27:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 68.14	
[12/04 21:28:56 visual_prompt]: Inference (test):avg data time: 3.18e-05, avg batch time: 0.5187, average loss: 0.6577
[12/04 21:28:56 visual_prompt]: Classification results with test_mammo-cbis: top1: 62.33	rocauc: 66.93	
[12/04 21:28:56 visual_prompt]: Best epoch 14: best metric: -0.649
[12/04 21:28:56 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.9951340343707852
[12/04 21:35:22 visual_prompt]: Epoch 15 / 100: avg data time: 1.01e+01, avg batch time: 11.0035, average train loss: 0.8202
[12/04 21:36:07 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.5362, average loss: 0.7009
[12/04 21:36:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 67.96	
[12/04 21:38:01 visual_prompt]: Inference (test):avg data time: 3.11e-05, avg batch time: 0.5147, average loss: 0.6597
[12/04 21:38:01 visual_prompt]: Classification results with test_mammo-cbis: top1: 62.64	rocauc: 66.05	
[12/04 21:38:01 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.9924038765061041
[12/04 21:44:27 visual_prompt]: Epoch 16 / 100: avg data time: 1.02e+01, avg batch time: 11.0264, average train loss: 0.7875
[12/04 21:45:12 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.5287, average loss: 1.0633
[12/04 21:45:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 70.69	
[12/04 21:47:05 visual_prompt]: Inference (test):avg data time: 3.06e-05, avg batch time: 0.5153, average loss: 0.9521
[12/04 21:47:05 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 67.41	
[12/04 21:47:05 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.9890738003669028
[12/04 21:53:31 visual_prompt]: Epoch 17 / 100: avg data time: 1.01e+01, avg batch time: 11.0137, average train loss: 0.9663
[12/04 21:54:16 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.5413, average loss: 0.7215
[12/04 21:54:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.54	rocauc: 68.59	
[12/04 21:56:10 visual_prompt]: Inference (test):avg data time: 3.02e-05, avg batch time: 0.5136, average loss: 0.7587
[12/04 21:56:10 visual_prompt]: Classification results with test_mammo-cbis: top1: 55.50	rocauc: 68.52	
[12/04 21:56:10 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.9851478631379982
[12/04 22:02:33 visual_prompt]: Epoch 18 / 100: avg data time: 1.01e+01, avg batch time: 10.9418, average train loss: 0.7893
[12/04 22:03:18 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.5248, average loss: 0.6318
[12/04 22:03:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 72.71	
[12/04 22:05:12 visual_prompt]: Inference (test):avg data time: 3.26e-05, avg batch time: 0.5137, average loss: 0.6311
[12/04 22:05:12 visual_prompt]: Classification results with test_mammo-cbis: top1: 66.05	rocauc: 67.96	
[12/04 22:05:12 visual_prompt]: Best epoch 18: best metric: -0.632
[12/04 22:05:12 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.9806308479691594
[12/04 22:11:39 visual_prompt]: Epoch 19 / 100: avg data time: 1.02e+01, avg batch time: 11.0396, average train loss: 0.6943
[12/04 22:12:23 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.5351, average loss: 1.2279
[12/04 22:12:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 71.29	
[12/04 22:14:17 visual_prompt]: Inference (test):avg data time: 3.44e-05, avg batch time: 0.5164, average loss: 1.0880
[12/04 22:14:17 visual_prompt]: Classification results with test_mammo-cbis: top1: 59.07	rocauc: 69.08	
[12/04 22:14:17 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.9755282581475768
[12/04 22:20:42 visual_prompt]: Epoch 20 / 100: avg data time: 1.01e+01, avg batch time: 10.9931, average train loss: 0.6567
[12/04 22:21:27 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.5383, average loss: 0.8898
[12/04 22:21:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 73.68	
[12/04 22:23:21 visual_prompt]: Inference (test):avg data time: 3.20e-05, avg batch time: 0.5155, average loss: 0.8123
[12/04 22:23:21 visual_prompt]: Classification results with test_mammo-cbis: top1: 63.41	rocauc: 69.71	
[12/04 22:23:21 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.9698463103929542
[12/04 22:29:48 visual_prompt]: Epoch 21 / 100: avg data time: 1.02e+01, avg batch time: 11.0465, average train loss: 0.6762
[12/04 22:30:33 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.5341, average loss: 0.6229
[12/04 22:30:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 70.33	rocauc: 71.69	
[12/04 22:32:27 visual_prompt]: Inference (test):avg data time: 3.43e-05, avg batch time: 0.5119, average loss: 0.6321
[12/04 22:32:27 visual_prompt]: Classification results with test_mammo-cbis: top1: 63.41	rocauc: 68.39	
[12/04 22:32:27 visual_prompt]: Best epoch 21: best metric: -0.623
[12/04 22:32:27 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.9635919272833937
[12/04 22:38:51 visual_prompt]: Epoch 22 / 100: avg data time: 1.01e+01, avg batch time: 10.9792, average train loss: 0.7255
[12/04 22:39:36 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.5363, average loss: 0.6775
[12/04 22:39:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 69.82	
[12/04 22:41:30 visual_prompt]: Inference (test):avg data time: 3.42e-05, avg batch time: 0.5154, average loss: 0.7046
[12/04 22:41:30 visual_prompt]: Classification results with test_mammo-cbis: top1: 60.16	rocauc: 69.54	
[12/04 22:41:30 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.9567727288213004
[12/04 22:47:52 visual_prompt]: Epoch 23 / 100: avg data time: 1.00e+01, avg batch time: 10.9263, average train loss: 0.7240
[12/04 22:48:37 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.5215, average loss: 0.6348
[12/04 22:48:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 70.75	
[12/04 22:50:31 visual_prompt]: Inference (test):avg data time: 3.49e-05, avg batch time: 0.5123, average loss: 0.6134
[12/04 22:50:31 visual_prompt]: Classification results with test_mammo-cbis: top1: 66.20	rocauc: 70.50	
[12/04 22:50:31 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.9493970231495835
[12/04 22:56:57 visual_prompt]: Epoch 24 / 100: avg data time: 1.01e+01, avg batch time: 11.0175, average train loss: 0.6686
[12/04 22:57:41 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.5347, average loss: 0.6663
[12/04 22:57:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 72.47	
[12/04 22:59:35 visual_prompt]: Inference (test):avg data time: 3.25e-05, avg batch time: 0.5138, average loss: 0.6296
[12/04 22:59:35 visual_prompt]: Classification results with test_mammo-cbis: top1: 66.67	rocauc: 70.43	
[12/04 22:59:35 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.9414737964294635
[12/04 23:14:25 visual_prompt]: Epoch 25 / 100: avg data time: 2.45e+01, avg batch time: 25.4124, average train loss: 0.7026
[12/04 23:15:56 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.5264, average loss: 0.6499
[12/04 23:15:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.67	rocauc: 71.72	
[12/04 23:20:08 visual_prompt]: Inference (test):avg data time: 3.34e-05, avg batch time: 0.5177, average loss: 0.6258
[12/04 23:20:08 visual_prompt]: Classification results with test_mammo-cbis: top1: 64.81	rocauc: 70.02	
[12/04 23:20:08 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.9330127018922194
[12/04 23:27:11 visual_prompt]: Epoch 26 / 100: avg data time: 1.12e+01, avg batch time: 12.0963, average train loss: 0.6278
[12/04 23:27:56 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.5355, average loss: 0.6281
[12/04 23:27:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.67	rocauc: 73.39	
[12/04 23:29:52 visual_prompt]: Inference (test):avg data time: 3.00e-05, avg batch time: 0.5202, average loss: 0.6165
[12/04 23:29:52 visual_prompt]: Classification results with test_mammo-cbis: top1: 66.05	rocauc: 69.71	
[12/04 23:29:52 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.9240240480782129
[12/04 23:36:20 visual_prompt]: Epoch 27 / 100: avg data time: 1.02e+01, avg batch time: 11.0678, average train loss: 0.6838
[12/04 23:37:05 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.5359, average loss: 0.6600
[12/04 23:37:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 69.11	rocauc: 72.73	
[12/04 23:39:01 visual_prompt]: Inference (test):avg data time: 3.29e-05, avg batch time: 0.5164, average loss: 0.7116
[12/04 23:39:01 visual_prompt]: Classification results with test_mammo-cbis: top1: 60.93	rocauc: 69.46	
[12/04 23:39:01 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.9145187862775208
[12/04 23:45:30 visual_prompt]: Epoch 28 / 100: avg data time: 1.02e+01, avg batch time: 11.1108, average train loss: 0.6637
[12/04 23:46:15 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.5322, average loss: 0.6727
[12/04 23:46:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 70.71	
[12/04 23:48:13 visual_prompt]: Inference (test):avg data time: 3.24e-05, avg batch time: 0.5131, average loss: 0.6476
[12/04 23:48:13 visual_prompt]: Classification results with test_mammo-cbis: top1: 66.36	rocauc: 69.16	
[12/04 23:48:13 visual_prompt]: Stopping early.
/bin/bash: /home/s1952889/miniconda3/envs/prompt/lib/libtinfo.so.6: no version information available (required by /bin/bash)
