/bin/bash: /home/s1952889/miniconda3/envs/prompt/lib/libtinfo.so.6: no version information available (required by /bin/bash)
An exception occurred in telemetry logging.Disabling telemetry to prevent further exceptions.
Traceback (most recent call last):
  File "/home/s1952889/miniconda3/envs/prompt/lib/python3.11/site-packages/iopath/common/file_io.py", line 946, in __log_tmetry_keys
    handler.log_event()
  File "/home/s1952889/miniconda3/envs/prompt/lib/python3.11/site-packages/iopath/common/event_logger.py", line 97, in log_event
    del self._evt
        ^^^^^^^^^
AttributeError: 'NativePathHandler' object has no attribute '_evt'
Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss', 'RECORD_GPU_SNAPSHOT', 'True'])
[11/28 13:02:35 visual_prompt]: Rank of current process: 0. World size: 1
[11/28 13:02:37 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA TITAN Xp
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/28 13:02:37 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss', 'RECORD_GPU_SNAPSHOT', 'True'])
[11/28 13:02:37 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/28 13:02:37 visual_prompt]: Training with config:
[11/28 13:02:37 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr50.0_wd0.01/patience7/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 50.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True}), 'RECORD_GPU_SNAPSHOT': True})
[11/28 13:02:37 visual_prompt]: Loading training data...
[11/28 13:02:37 visual_prompt]: Constructing mammo-cbis dataset train...
[11/28 13:02:37 visual_prompt]: Loading validation data...
[11/28 13:02:37 visual_prompt]: Constructing mammo-cbis dataset val...
[11/28 13:02:37 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[11/28 13:02:42 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[11/28 13:02:42 visual_prompt]: tuned percent:0.536
[11/28 13:02:42 visual_prompt]: Device used for model: 0
[11/28 13:02:42 visual_prompt]: Setting up Evaluator...
[11/28 13:02:42 visual_prompt]: Setting up Trainer...
[11/28 13:02:42 visual_prompt]: 	Setting up the optimizer...
[11/28 13:02:42 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/28 13:10:28 visual_prompt]: Epoch 1 / 100: avg data time: 1.23e+01, avg batch time: 13.3108, average train loss: 1.4006
[11/28 13:11:21 visual_prompt]: Inference (val):avg data time: 4.32e-05, avg batch time: 0.5242, average loss: 1.2969
[11/28 13:11:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[11/28 13:11:21 visual_prompt]: Training 2 / 100 epoch, with learning rate 5.0
[11/28 13:18:58 visual_prompt]: Epoch 2 / 100: avg data time: 1.22e+01, avg batch time: 13.0800, average train loss: 47.2207
[11/28 13:19:52 visual_prompt]: Inference (val):avg data time: 6.48e-05, avg batch time: 0.5251, average loss: 21.1442
[11/28 13:19:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.51	
[11/28 13:19:52 visual_prompt]: Training 3 / 100 epoch, with learning rate 10.0
[11/28 13:27:29 visual_prompt]: Epoch 3 / 100: avg data time: 1.22e+01, avg batch time: 13.0468, average train loss: 21.4057
[11/28 13:28:21 visual_prompt]: Inference (val):avg data time: 4.68e-05, avg batch time: 0.5291, average loss: 7.6746
[11/28 13:28:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.11	
[11/28 13:28:21 visual_prompt]: Training 4 / 100 epoch, with learning rate 15.0
[11/28 13:35:57 visual_prompt]: Epoch 4 / 100: avg data time: 1.22e+01, avg batch time: 13.0292, average train loss: 25.2795
[11/28 13:36:48 visual_prompt]: Inference (val):avg data time: 4.09e-05, avg batch time: 0.5243, average loss: 29.5045
[11/28 13:36:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.18	
[11/28 13:36:48 visual_prompt]: Training 5 / 100 epoch, with learning rate 20.0
[11/28 13:44:09 visual_prompt]: Epoch 5 / 100: avg data time: 1.17e+01, avg batch time: 12.5918, average train loss: 35.3392
[11/28 13:45:00 visual_prompt]: Inference (val):avg data time: 3.53e-05, avg batch time: 0.5223, average loss: 40.5801
[11/28 13:45:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.15	
[11/28 13:45:00 visual_prompt]: Training 6 / 100 epoch, with learning rate 25.0
[11/28 13:52:32 visual_prompt]: Epoch 6 / 100: avg data time: 1.20e+01, avg batch time: 12.9069, average train loss: 75.6072
[11/28 13:53:25 visual_prompt]: Inference (val):avg data time: 3.82e-05, avg batch time: 0.5254, average loss: 46.1451
[11/28 13:53:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.12	
[11/28 13:53:25 visual_prompt]: Training 7 / 100 epoch, with learning rate 30.0
[11/28 14:01:05 visual_prompt]: Epoch 7 / 100: avg data time: 1.23e+01, avg batch time: 13.1256, average train loss: 64.3204
[11/28 14:01:57 visual_prompt]: Inference (val):avg data time: 3.90e-05, avg batch time: 0.5261, average loss: 126.3663
[11/28 14:01:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.34	
[11/28 14:01:57 visual_prompt]: Training 8 / 100 epoch, with learning rate 35.0
[11/28 14:09:33 visual_prompt]: Epoch 8 / 100: avg data time: 1.22e+01, avg batch time: 13.0153, average train loss: 84.2415
[11/28 14:10:26 visual_prompt]: Inference (val):avg data time: 3.67e-05, avg batch time: 0.5233, average loss: 21.1667
[11/28 14:10:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 44.31	rocauc: 48.56	
[11/28 14:10:26 visual_prompt]: Training 9 / 100 epoch, with learning rate 40.0
[11/28 14:18:04 visual_prompt]: Epoch 9 / 100: avg data time: 1.22e+01, avg batch time: 13.0813, average train loss: 122.1390
[11/28 14:18:57 visual_prompt]: Inference (val):avg data time: 5.14e-05, avg batch time: 0.5257, average loss: 82.8475
[11/28 14:18:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.13	
[11/28 14:18:57 visual_prompt]: Training 10 / 100 epoch, with learning rate 45.0
[11/28 14:26:36 visual_prompt]: Epoch 10 / 100: avg data time: 1.22e+01, avg batch time: 13.0973, average train loss: 89.4662
[11/28 14:27:28 visual_prompt]: Inference (val):avg data time: 4.85e-05, avg batch time: 0.5237, average loss: 129.9683
[11/28 14:27:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 42.94	
[11/28 14:27:28 visual_prompt]: Training 11 / 100 epoch, with learning rate 50.0
[11/28 14:35:05 visual_prompt]: Epoch 11 / 100: avg data time: 1.22e+01, avg batch time: 13.0445, average train loss: 121.1973
[11/28 14:35:58 visual_prompt]: Inference (val):avg data time: 4.36e-05, avg batch time: 0.5317, average loss: 28.3087
[11/28 14:35:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.33	
[11/28 14:35:58 visual_prompt]: Training 12 / 100 epoch, with learning rate 49.9847706754774
[11/28 14:43:36 visual_prompt]: Epoch 12 / 100: avg data time: 1.22e+01, avg batch time: 13.0813, average train loss: 118.6507
[11/28 14:44:29 visual_prompt]: Inference (val):avg data time: 5.65e-05, avg batch time: 0.5272, average loss: 4.7298
[11/28 14:44:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.62	
[11/28 14:44:29 visual_prompt]: Best epoch 12: best metric: -4.730
[11/28 14:44:29 visual_prompt]: Training 13 / 100 epoch, with learning rate 49.939101256495604
[11/28 14:51:55 visual_prompt]: Epoch 13 / 100: avg data time: 1.19e+01, avg batch time: 12.7233, average train loss: 99.8405
[11/28 14:52:46 visual_prompt]: Inference (val):avg data time: 5.61e-05, avg batch time: 0.5276, average loss: 268.0182
[11/28 14:52:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 41.27	
[11/28 14:52:46 visual_prompt]: Training 14 / 100 epoch, with learning rate 49.86304738420683
[11/28 15:00:08 visual_prompt]: Epoch 14 / 100: avg data time: 1.18e+01, avg batch time: 12.6203, average train loss: 128.8177
[11/28 15:00:59 visual_prompt]: Inference (val):avg data time: 4.91e-05, avg batch time: 0.5279, average loss: 32.0419
[11/28 15:00:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.65	
[11/28 15:00:59 visual_prompt]: Training 15 / 100 epoch, with learning rate 49.75670171853926
[11/28 15:08:22 visual_prompt]: Epoch 15 / 100: avg data time: 1.18e+01, avg batch time: 12.6469, average train loss: 143.5749
[11/28 15:09:13 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.5283, average loss: 5.4027
[11/28 15:09:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.66	
[11/28 15:09:13 visual_prompt]: Training 16 / 100 epoch, with learning rate 49.6201938253052
[11/28 15:16:35 visual_prompt]: Epoch 16 / 100: avg data time: 1.18e+01, avg batch time: 12.6235, average train loss: 153.1298
[11/28 15:17:29 visual_prompt]: Inference (val):avg data time: 4.33e-05, avg batch time: 0.5252, average loss: 64.2137
[11/28 15:17:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.48	
[11/28 15:17:29 visual_prompt]: Training 17 / 100 epoch, with learning rate 49.45369001834514
[11/28 15:25:20 visual_prompt]: Epoch 17 / 100: avg data time: 1.26e+01, avg batch time: 13.4737, average train loss: 122.3338
[11/28 15:26:14 visual_prompt]: Inference (val):avg data time: 5.26e-05, avg batch time: 0.5271, average loss: 93.1703
[11/28 15:26:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.70	
[11/28 15:26:14 visual_prompt]: Training 18 / 100 epoch, with learning rate 49.25739315689991
[11/28 15:33:54 visual_prompt]: Epoch 18 / 100: avg data time: 1.23e+01, avg batch time: 13.1486, average train loss: 141.9983
[11/28 15:34:47 visual_prompt]: Inference (val):avg data time: 5.05e-05, avg batch time: 0.5298, average loss: 13.3476
[11/28 15:34:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.66	
[11/28 15:34:47 visual_prompt]: Training 19 / 100 epoch, with learning rate 49.03154239845797
[11/28 15:42:23 visual_prompt]: Epoch 19 / 100: avg data time: 1.22e+01, avg batch time: 13.0358, average train loss: 107.0472
[11/28 15:43:16 visual_prompt]: Inference (val):avg data time: 4.91e-05, avg batch time: 0.5259, average loss: 40.1287
[11/28 15:43:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.11	
[11/28 15:43:16 visual_prompt]: Stopping early.
[11/28 15:43:17 visual_prompt]: Rank of current process: 0. World size: 1
[11/28 15:43:17 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA TITAN Xp
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/28 15:43:17 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss', 'RECORD_GPU_SNAPSHOT', 'True'])
[11/28 15:43:17 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/28 15:43:17 visual_prompt]: Training with config:
[11/28 15:43:17 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr50.0_wd0.001/patience7/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 50.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True}), 'RECORD_GPU_SNAPSHOT': True})
[11/28 15:43:17 visual_prompt]: Loading training data...
[11/28 15:43:17 visual_prompt]: Constructing mammo-cbis dataset train...
[11/28 15:43:17 visual_prompt]: Loading validation data...
[11/28 15:43:17 visual_prompt]: Constructing mammo-cbis dataset val...
[11/28 15:43:17 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[11/28 15:43:24 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[11/28 15:43:24 visual_prompt]: tuned percent:0.536
[11/28 15:43:24 visual_prompt]: Device used for model: 0
[11/28 15:43:24 visual_prompt]: Setting up Evaluator...
[11/28 15:43:24 visual_prompt]: Setting up Trainer...
[11/28 15:43:24 visual_prompt]: 	Setting up the optimizer...
[11/28 15:43:24 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/28 15:51:03 visual_prompt]: Epoch 1 / 100: avg data time: 1.22e+01, avg batch time: 13.0873, average train loss: 1.4006
[11/28 15:51:56 visual_prompt]: Inference (val):avg data time: 5.67e-05, avg batch time: 0.5190, average loss: 1.2969
[11/28 15:51:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[11/28 15:51:56 visual_prompt]: Training 2 / 100 epoch, with learning rate 5.0
[11/28 15:59:33 visual_prompt]: Epoch 2 / 100: avg data time: 1.22e+01, avg batch time: 13.0687, average train loss: 27.0155
[11/28 16:00:26 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.5263, average loss: 10.3730
[11/28 16:00:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.98	
[11/28 16:00:26 visual_prompt]: Training 3 / 100 epoch, with learning rate 10.0
[11/28 16:08:04 visual_prompt]: Epoch 3 / 100: avg data time: 1.22e+01, avg batch time: 13.0786, average train loss: 24.1599
[11/28 16:08:57 visual_prompt]: Inference (val):avg data time: 4.05e-05, avg batch time: 0.5213, average loss: 43.2925
[11/28 16:08:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.26	
[11/28 16:08:57 visual_prompt]: Training 4 / 100 epoch, with learning rate 15.0
[11/28 16:16:35 visual_prompt]: Epoch 4 / 100: avg data time: 1.22e+01, avg batch time: 13.0830, average train loss: 28.1329
[11/28 16:17:29 visual_prompt]: Inference (val):avg data time: 5.29e-05, avg batch time: 0.5211, average loss: 34.0368
[11/28 16:17:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.94	
[11/28 16:17:29 visual_prompt]: Training 5 / 100 epoch, with learning rate 20.0
[11/28 16:24:52 visual_prompt]: Epoch 5 / 100: avg data time: 1.18e+01, avg batch time: 12.6551, average train loss: 38.8075
[11/28 16:25:43 visual_prompt]: Inference (val):avg data time: 3.93e-05, avg batch time: 0.5248, average loss: 24.0847
[11/28 16:25:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.62	
[11/28 16:25:43 visual_prompt]: Training 6 / 100 epoch, with learning rate 25.0
[11/28 16:33:06 visual_prompt]: Epoch 6 / 100: avg data time: 1.18e+01, avg batch time: 12.6612, average train loss: 68.2230
[11/28 16:33:58 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.5216, average loss: 4.7247
[11/28 16:33:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.24	
[11/28 16:33:58 visual_prompt]: Training 7 / 100 epoch, with learning rate 30.0
[11/28 16:41:21 visual_prompt]: Epoch 7 / 100: avg data time: 1.18e+01, avg batch time: 12.6686, average train loss: 68.6292
[11/28 16:42:13 visual_prompt]: Inference (val):avg data time: 5.39e-05, avg batch time: 0.5296, average loss: 267.1232
[11/28 16:42:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 45.87	
[11/28 16:42:13 visual_prompt]: Training 8 / 100 epoch, with learning rate 35.0
[11/28 16:49:36 visual_prompt]: Epoch 8 / 100: avg data time: 1.18e+01, avg batch time: 12.6435, average train loss: 117.2350
[11/28 16:50:27 visual_prompt]: Inference (val):avg data time: 4.01e-05, avg batch time: 0.5250, average loss: 28.0913
[11/28 16:50:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.17	
[11/28 16:50:27 visual_prompt]: Training 9 / 100 epoch, with learning rate 40.0
[11/28 16:57:51 visual_prompt]: Epoch 9 / 100: avg data time: 1.18e+01, avg batch time: 12.6781, average train loss: 78.8698
[11/28 16:58:42 visual_prompt]: Inference (val):avg data time: 4.56e-05, avg batch time: 0.5278, average loss: 38.8818
[11/28 16:58:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.94	
[11/28 16:58:42 visual_prompt]: Training 10 / 100 epoch, with learning rate 45.0
[11/28 17:06:05 visual_prompt]: Epoch 10 / 100: avg data time: 1.18e+01, avg batch time: 12.6438, average train loss: 74.8236
[11/28 17:06:56 visual_prompt]: Inference (val):avg data time: 3.58e-05, avg batch time: 0.5228, average loss: 67.9963
[11/28 17:06:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 42.31	
[11/28 17:06:56 visual_prompt]: Training 11 / 100 epoch, with learning rate 50.0
[11/28 17:14:35 visual_prompt]: Epoch 11 / 100: avg data time: 1.23e+01, avg batch time: 13.1247, average train loss: 79.9933
[11/28 17:15:34 visual_prompt]: Inference (val):avg data time: 4.92e-05, avg batch time: 0.5217, average loss: 158.3058
[11/28 17:15:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.29	
[11/28 17:15:34 visual_prompt]: Training 12 / 100 epoch, with learning rate 49.9847706754774
[11/28 17:23:30 visual_prompt]: Epoch 12 / 100: avg data time: 1.27e+01, avg batch time: 13.5888, average train loss: 107.5670
[11/28 17:24:23 visual_prompt]: Inference (val):avg data time: 3.78e-05, avg batch time: 0.5200, average loss: 46.9732
[11/28 17:24:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.28	
[11/28 17:24:23 visual_prompt]: Best epoch 12: best metric: -46.973
[11/28 17:24:23 visual_prompt]: Training 13 / 100 epoch, with learning rate 49.939101256495604
[11/28 17:32:05 visual_prompt]: Epoch 13 / 100: avg data time: 1.23e+01, avg batch time: 13.1909, average train loss: 183.5818
[11/28 17:33:02 visual_prompt]: Inference (val):avg data time: 5.29e-05, avg batch time: 0.5189, average loss: 55.5075
[11/28 17:33:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.34	
[11/28 17:33:02 visual_prompt]: Training 14 / 100 epoch, with learning rate 49.86304738420683
[11/28 17:40:44 visual_prompt]: Epoch 14 / 100: avg data time: 1.23e+01, avg batch time: 13.2149, average train loss: 126.3127
[11/28 17:41:37 visual_prompt]: Inference (val):avg data time: 5.20e-05, avg batch time: 0.5253, average loss: 63.5713
[11/28 17:41:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.71	
[11/28 17:41:37 visual_prompt]: Training 15 / 100 epoch, with learning rate 49.75670171853926
[11/28 17:49:28 visual_prompt]: Epoch 15 / 100: avg data time: 1.26e+01, avg batch time: 13.4370, average train loss: 131.3694
[11/28 17:50:22 visual_prompt]: Inference (val):avg data time: 5.95e-05, avg batch time: 0.5237, average loss: 136.1798
[11/28 17:50:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.79	
[11/28 17:50:22 visual_prompt]: Training 16 / 100 epoch, with learning rate 49.6201938253052
[11/28 17:58:12 visual_prompt]: Epoch 16 / 100: avg data time: 1.26e+01, avg batch time: 13.4231, average train loss: 105.8246
[11/28 17:59:06 visual_prompt]: Inference (val):avg data time: 6.04e-05, avg batch time: 0.5205, average loss: 209.0344
[11/28 17:59:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.94	
[11/28 17:59:06 visual_prompt]: Training 17 / 100 epoch, with learning rate 49.45369001834514
[11/28 18:06:46 visual_prompt]: Epoch 17 / 100: avg data time: 1.23e+01, avg batch time: 13.1359, average train loss: 186.2917
[11/28 18:07:39 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.5223, average loss: 115.1705
[11/28 18:07:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 41.51	
[11/28 18:07:39 visual_prompt]: Training 18 / 100 epoch, with learning rate 49.25739315689991
[11/28 18:15:19 visual_prompt]: Epoch 18 / 100: avg data time: 1.23e+01, avg batch time: 13.1232, average train loss: 120.0132
[11/28 18:16:12 visual_prompt]: Inference (val):avg data time: 4.80e-05, avg batch time: 0.5297, average loss: 433.3973
[11/28 18:16:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.83	
[11/28 18:16:12 visual_prompt]: Training 19 / 100 epoch, with learning rate 49.03154239845797
[11/28 18:23:50 visual_prompt]: Epoch 19 / 100: avg data time: 1.22e+01, avg batch time: 13.0752, average train loss: 168.5670
[11/28 18:24:43 visual_prompt]: Inference (val):avg data time: 4.05e-05, avg batch time: 0.5180, average loss: 122.0169
[11/28 18:24:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.69	
[11/28 18:24:43 visual_prompt]: Stopping early.
[11/28 18:24:44 visual_prompt]: Rank of current process: 0. World size: 1
[11/28 18:24:44 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA TITAN Xp
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/28 18:24:44 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss', 'RECORD_GPU_SNAPSHOT', 'True'])
[11/28 18:24:44 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/28 18:24:44 visual_prompt]: Training with config:
[11/28 18:24:44 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr50.0_wd0.0001/patience7/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 50.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True}), 'RECORD_GPU_SNAPSHOT': True})
[11/28 18:24:44 visual_prompt]: Loading training data...
[11/28 18:24:44 visual_prompt]: Constructing mammo-cbis dataset train...
[11/28 18:24:44 visual_prompt]: Loading validation data...
[11/28 18:24:44 visual_prompt]: Constructing mammo-cbis dataset val...
[11/28 18:24:44 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[11/28 18:24:52 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[11/28 18:24:52 visual_prompt]: tuned percent:0.536
[11/28 18:24:52 visual_prompt]: Device used for model: 0
[11/28 18:24:52 visual_prompt]: Setting up Evaluator...
[11/28 18:24:52 visual_prompt]: Setting up Trainer...
[11/28 18:24:52 visual_prompt]: 	Setting up the optimizer...
[11/28 18:24:52 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/28 18:32:32 visual_prompt]: Epoch 1 / 100: avg data time: 1.23e+01, avg batch time: 13.1347, average train loss: 1.4006
[11/28 18:33:25 visual_prompt]: Inference (val):avg data time: 5.54e-05, avg batch time: 0.5266, average loss: 1.2969
[11/28 18:33:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[11/28 18:33:25 visual_prompt]: Training 2 / 100 epoch, with learning rate 5.0
[11/28 18:41:01 visual_prompt]: Epoch 2 / 100: avg data time: 1.21e+01, avg batch time: 13.0241, average train loss: 21.6884
[11/28 18:41:53 visual_prompt]: Inference (val):avg data time: 4.69e-05, avg batch time: 0.5245, average loss: 1.0083
[11/28 18:41:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 49.59	rocauc: 57.03	
[11/28 18:41:53 visual_prompt]: Training 3 / 100 epoch, with learning rate 10.0
[11/28 18:49:17 visual_prompt]: Epoch 3 / 100: avg data time: 1.18e+01, avg batch time: 12.6746, average train loss: 38.6201
[11/28 18:50:08 visual_prompt]: Inference (val):avg data time: 3.73e-05, avg batch time: 0.5262, average loss: 0.7869
[11/28 18:50:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 50.00	rocauc: 57.16	
[11/28 18:50:08 visual_prompt]: Training 4 / 100 epoch, with learning rate 15.0
[11/28 18:57:31 visual_prompt]: Epoch 4 / 100: avg data time: 1.18e+01, avg batch time: 12.6495, average train loss: 16.9552
[11/28 18:58:22 visual_prompt]: Inference (val):avg data time: 5.10e-05, avg batch time: 0.5294, average loss: 5.0919
[11/28 18:58:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.75	
[11/28 18:58:22 visual_prompt]: Training 5 / 100 epoch, with learning rate 20.0
[11/28 19:05:45 visual_prompt]: Epoch 5 / 100: avg data time: 1.18e+01, avg batch time: 12.6359, average train loss: 19.9032
[11/28 19:06:37 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.5256, average loss: 45.1114
[11/28 19:06:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.01	
[11/28 19:06:37 visual_prompt]: Training 6 / 100 epoch, with learning rate 25.0
[11/28 19:14:00 visual_prompt]: Epoch 6 / 100: avg data time: 1.18e+01, avg batch time: 12.6673, average train loss: 35.5889
[11/28 19:14:52 visual_prompt]: Inference (val):avg data time: 4.69e-05, avg batch time: 0.5245, average loss: 26.3993
[11/28 19:14:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.96	
[11/28 19:14:52 visual_prompt]: Training 7 / 100 epoch, with learning rate 30.0
[11/28 19:22:15 visual_prompt]: Epoch 7 / 100: avg data time: 1.18e+01, avg batch time: 12.6575, average train loss: 31.7600
[11/28 19:23:06 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.5281, average loss: 42.0422
[11/28 19:23:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 40.99	
[11/28 19:23:06 visual_prompt]: Training 8 / 100 epoch, with learning rate 35.0
[11/28 19:30:29 visual_prompt]: Epoch 8 / 100: avg data time: 1.18e+01, avg batch time: 12.6394, average train loss: 91.7362
[11/28 19:31:20 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.5254, average loss: 71.1311
[11/28 19:31:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.15	
[11/28 19:31:20 visual_prompt]: Training 9 / 100 epoch, with learning rate 40.0
[11/28 19:38:44 visual_prompt]: Epoch 9 / 100: avg data time: 1.18e+01, avg batch time: 12.6765, average train loss: 88.7644
[11/28 19:39:36 visual_prompt]: Inference (val):avg data time: 4.53e-05, avg batch time: 0.5286, average loss: 27.8329
[11/28 19:39:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.10	
[11/28 19:39:36 visual_prompt]: Training 10 / 100 epoch, with learning rate 45.0
[11/28 19:46:59 visual_prompt]: Epoch 10 / 100: avg data time: 1.18e+01, avg batch time: 12.6570, average train loss: 91.6330
[11/28 19:47:51 visual_prompt]: Inference (val):avg data time: 4.36e-05, avg batch time: 0.5357, average loss: 92.8379
[11/28 19:47:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.37	
[11/28 19:47:51 visual_prompt]: Training 11 / 100 epoch, with learning rate 50.0
[11/28 19:55:13 visual_prompt]: Epoch 11 / 100: avg data time: 1.18e+01, avg batch time: 12.6410, average train loss: 123.4984
[11/28 19:56:05 visual_prompt]: Inference (val):avg data time: 3.58e-05, avg batch time: 0.5290, average loss: 14.5397
[11/28 19:56:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.09	
[11/28 19:56:05 visual_prompt]: Training 12 / 100 epoch, with learning rate 49.9847706754774
[11/28 20:03:28 visual_prompt]: Epoch 12 / 100: avg data time: 1.18e+01, avg batch time: 12.6427, average train loss: 93.7713
[11/28 20:04:19 visual_prompt]: Inference (val):avg data time: 3.76e-05, avg batch time: 0.5266, average loss: 33.3844
[11/28 20:04:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.21	
[11/28 20:04:19 visual_prompt]: Training 13 / 100 epoch, with learning rate 49.939101256495604
[11/28 20:11:42 visual_prompt]: Epoch 13 / 100: avg data time: 1.18e+01, avg batch time: 12.6512, average train loss: 204.6375
[11/28 20:12:33 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.5221, average loss: 87.7408
[11/28 20:12:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.99	
[11/28 20:12:33 visual_prompt]: Training 14 / 100 epoch, with learning rate 49.86304738420683
[11/28 20:19:56 visual_prompt]: Epoch 14 / 100: avg data time: 1.18e+01, avg batch time: 12.6374, average train loss: 86.7965
[11/28 20:20:47 visual_prompt]: Inference (val):avg data time: 5.54e-05, avg batch time: 0.5251, average loss: 96.9401
[11/28 20:20:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 39.79	
[11/28 20:20:47 visual_prompt]: Training 15 / 100 epoch, with learning rate 49.75670171853926
[11/28 20:28:12 visual_prompt]: Epoch 15 / 100: avg data time: 1.18e+01, avg batch time: 12.6895, average train loss: 101.9606
[11/28 20:29:03 visual_prompt]: Inference (val):avg data time: 4.65e-05, avg batch time: 0.5222, average loss: 15.5796
[11/28 20:29:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.35	
[11/28 20:29:04 visual_prompt]: Training 16 / 100 epoch, with learning rate 49.6201938253052
[11/28 20:36:27 visual_prompt]: Epoch 16 / 100: avg data time: 1.18e+01, avg batch time: 12.6629, average train loss: 108.8948
[11/28 20:37:18 visual_prompt]: Inference (val):avg data time: 4.99e-05, avg batch time: 0.5302, average loss: 10.1484
[11/28 20:37:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.41	
[11/28 20:37:18 visual_prompt]: Best epoch 16: best metric: -10.148
[11/28 20:37:18 visual_prompt]: Training 17 / 100 epoch, with learning rate 49.45369001834514
[11/28 20:44:41 visual_prompt]: Epoch 17 / 100: avg data time: 1.18e+01, avg batch time: 12.6468, average train loss: 140.4017
[11/28 20:45:33 visual_prompt]: Inference (val):avg data time: 4.47e-05, avg batch time: 0.5317, average loss: 28.2596
[11/28 20:45:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.51	
[11/28 20:45:33 visual_prompt]: Training 18 / 100 epoch, with learning rate 49.25739315689991
[11/28 20:52:56 visual_prompt]: Epoch 18 / 100: avg data time: 1.18e+01, avg batch time: 12.6516, average train loss: 76.1672
[11/28 20:53:47 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.5318, average loss: 94.7159
[11/28 20:53:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.16	
[11/28 20:53:47 visual_prompt]: Training 19 / 100 epoch, with learning rate 49.03154239845797
[11/28 21:01:10 visual_prompt]: Epoch 19 / 100: avg data time: 1.18e+01, avg batch time: 12.6417, average train loss: 77.4839
[11/28 21:02:01 visual_prompt]: Inference (val):avg data time: 6.13e-05, avg batch time: 0.5278, average loss: 48.5832
[11/28 21:02:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.16	
[11/28 21:02:01 visual_prompt]: Training 20 / 100 epoch, with learning rate 48.77641290737884
[11/28 21:09:24 visual_prompt]: Epoch 20 / 100: avg data time: 1.18e+01, avg batch time: 12.6449, average train loss: 74.0089
[11/28 21:10:16 visual_prompt]: Inference (val):avg data time: 5.84e-05, avg batch time: 0.5299, average loss: 73.6098
[11/28 21:10:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.86	
[11/28 21:10:16 visual_prompt]: Training 21 / 100 epoch, with learning rate 48.49231551964771
[11/28 21:17:39 visual_prompt]: Epoch 21 / 100: avg data time: 1.18e+01, avg batch time: 12.6562, average train loss: 46.9716
[11/28 21:18:30 visual_prompt]: Inference (val):avg data time: 4.36e-05, avg batch time: 0.5234, average loss: 68.4389
[11/28 21:18:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.13	
[11/28 21:18:30 visual_prompt]: Training 22 / 100 epoch, with learning rate 48.17959636416968
[11/28 21:25:52 visual_prompt]: Epoch 22 / 100: avg data time: 1.17e+01, avg batch time: 12.6188, average train loss: 53.8320
[11/28 21:26:44 visual_prompt]: Inference (val):avg data time: 4.13e-05, avg batch time: 0.5307, average loss: 103.9562
[11/28 21:26:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.67	
[11/28 21:26:44 visual_prompt]: Training 23 / 100 epoch, with learning rate 47.83863644106502
[11/28 21:34:06 visual_prompt]: Epoch 23 / 100: avg data time: 1.18e+01, avg batch time: 12.6425, average train loss: 64.1752
[11/28 21:34:58 visual_prompt]: Inference (val):avg data time: 4.15e-05, avg batch time: 0.5319, average loss: 8.6518
[11/28 21:34:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.81	
[11/28 21:34:58 visual_prompt]: Best epoch 23: best metric: -8.652
[11/28 21:34:58 visual_prompt]: Training 24 / 100 epoch, with learning rate 47.46985115747918
[11/28 21:42:22 visual_prompt]: Epoch 24 / 100: avg data time: 1.18e+01, avg batch time: 12.6975, average train loss: 53.3917
[11/28 21:43:15 visual_prompt]: Inference (val):avg data time: 5.03e-05, avg batch time: 0.5282, average loss: 79.1550
[11/28 21:43:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.53	
[11/28 21:43:15 visual_prompt]: Training 25 / 100 epoch, with learning rate 47.073689821473174
[11/28 21:50:45 visual_prompt]: Epoch 25 / 100: avg data time: 1.20e+01, avg batch time: 12.8454, average train loss: 83.9509
[11/28 21:51:36 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.5291, average loss: 121.5777
[11/28 21:51:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 45.93	
[11/28 21:51:36 visual_prompt]: Training 26 / 100 epoch, with learning rate 46.65063509461097
[11/28 21:58:59 visual_prompt]: Epoch 26 / 100: avg data time: 1.18e+01, avg batch time: 12.6600, average train loss: 100.4154
[11/28 21:59:51 visual_prompt]: Inference (val):avg data time: 5.59e-05, avg batch time: 0.5236, average loss: 50.2287
[11/28 21:59:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.91	
[11/28 21:59:51 visual_prompt]: Training 27 / 100 epoch, with learning rate 46.20120240391065
[11/28 22:07:14 visual_prompt]: Epoch 27 / 100: avg data time: 1.18e+01, avg batch time: 12.6487, average train loss: 56.2868
[11/28 22:08:05 visual_prompt]: Inference (val):avg data time: 3.89e-05, avg batch time: 0.5284, average loss: 45.5013
[11/28 22:08:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.50	
[11/28 22:08:05 visual_prompt]: Training 28 / 100 epoch, with learning rate 45.72593931387604
[11/28 22:15:29 visual_prompt]: Epoch 28 / 100: avg data time: 1.18e+01, avg batch time: 12.6819, average train loss: 67.3416
[11/28 22:16:21 visual_prompt]: Inference (val):avg data time: 5.13e-05, avg batch time: 0.5257, average loss: 4.4116
[11/28 22:16:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 45.03	
[11/28 22:16:21 visual_prompt]: Best epoch 28: best metric: -4.412
[11/28 22:16:21 visual_prompt]: Training 29 / 100 epoch, with learning rate 45.22542485937369
[11/28 22:23:49 visual_prompt]: Epoch 29 / 100: avg data time: 1.19e+01, avg batch time: 12.8135, average train loss: 67.4864
[11/28 22:24:41 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.5193, average loss: 11.7534
[11/28 22:24:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.43	
[11/28 22:24:41 visual_prompt]: Training 30 / 100 epoch, with learning rate 44.70026884016804
[11/28 22:32:03 visual_prompt]: Epoch 30 / 100: avg data time: 1.18e+01, avg batch time: 12.6260, average train loss: 118.5525
[11/28 22:32:54 visual_prompt]: Inference (val):avg data time: 3.96e-05, avg batch time: 0.5307, average loss: 26.2126
[11/28 22:32:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 45.01	
[11/28 22:32:54 visual_prompt]: Training 31 / 100 epoch, with learning rate 44.15111107797445
[11/28 22:40:16 visual_prompt]: Epoch 31 / 100: avg data time: 1.18e+01, avg batch time: 12.6351, average train loss: 127.2978
[11/28 22:41:08 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.5264, average loss: 29.5896
[11/28 22:41:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.84	
[11/28 22:41:08 visual_prompt]: Training 32 / 100 epoch, with learning rate 43.57862063693486
[11/28 22:48:31 visual_prompt]: Epoch 32 / 100: avg data time: 1.18e+01, avg batch time: 12.6624, average train loss: 82.8848
[11/28 22:49:23 visual_prompt]: Inference (val):avg data time: 4.23e-05, avg batch time: 0.5272, average loss: 126.7155
[11/28 22:49:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.09	
[11/28 22:49:23 visual_prompt]: Training 33 / 100 epoch, with learning rate 42.98349500846628
[11/28 22:56:45 visual_prompt]: Epoch 33 / 100: avg data time: 1.18e+01, avg batch time: 12.6334, average train loss: 78.9427
[11/28 22:57:36 visual_prompt]: Inference (val):avg data time: 4.69e-05, avg batch time: 0.5315, average loss: 105.0000
[11/28 22:57:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.73	
[11/28 22:57:36 visual_prompt]: Training 34 / 100 epoch, with learning rate 42.36645926147493
[11/28 23:04:58 visual_prompt]: Epoch 34 / 100: avg data time: 1.17e+01, avg batch time: 12.6061, average train loss: 55.3709
[11/28 23:05:50 visual_prompt]: Inference (val):avg data time: 4.43e-05, avg batch time: 0.5259, average loss: 73.8822
[11/28 23:05:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.97	
[11/28 23:05:50 visual_prompt]: Training 35 / 100 epoch, with learning rate 41.72826515897145
[11/28 23:13:12 visual_prompt]: Epoch 35 / 100: avg data time: 1.18e+01, avg batch time: 12.6483, average train loss: 65.2232
[11/28 23:14:04 visual_prompt]: Inference (val):avg data time: 4.51e-05, avg batch time: 0.5229, average loss: 634.3558
[11/28 23:14:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.99	
[11/28 23:14:04 visual_prompt]: Stopping early.
[11/28 23:14:04 visual_prompt]: Rank of current process: 0. World size: 1
[11/28 23:14:04 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA TITAN Xp
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/28 23:14:04 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss', 'RECORD_GPU_SNAPSHOT', 'True'])
[11/28 23:14:04 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/28 23:14:04 visual_prompt]: Training with config:
[11/28 23:14:04 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr50.0_wd0.0/patience7/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 50.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True}), 'RECORD_GPU_SNAPSHOT': True})
[11/28 23:14:04 visual_prompt]: Loading training data...
[11/28 23:14:04 visual_prompt]: Constructing mammo-cbis dataset train...
[11/28 23:14:04 visual_prompt]: Loading validation data...
[11/28 23:14:04 visual_prompt]: Constructing mammo-cbis dataset val...
[11/28 23:14:04 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[11/28 23:14:13 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[11/28 23:14:13 visual_prompt]: tuned percent:0.536
[11/28 23:14:13 visual_prompt]: Device used for model: 0
[11/28 23:14:13 visual_prompt]: Setting up Evaluator...
[11/28 23:14:13 visual_prompt]: Setting up Trainer...
[11/28 23:14:13 visual_prompt]: 	Setting up the optimizer...
[11/28 23:14:13 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/28 23:21:36 visual_prompt]: Epoch 1 / 100: avg data time: 1.18e+01, avg batch time: 12.6418, average train loss: 1.4006
[11/28 23:22:28 visual_prompt]: Inference (val):avg data time: 4.04e-05, avg batch time: 0.5247, average loss: 1.2969
[11/28 23:22:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[11/28 23:22:28 visual_prompt]: Training 2 / 100 epoch, with learning rate 5.0
[11/28 23:29:49 visual_prompt]: Epoch 2 / 100: avg data time: 1.17e+01, avg batch time: 12.6107, average train loss: 22.2948
[11/28 23:30:40 visual_prompt]: Inference (val):avg data time: 3.80e-05, avg batch time: 0.5210, average loss: 17.1110
[11/28 23:30:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.22	
[11/28 23:30:40 visual_prompt]: Training 3 / 100 epoch, with learning rate 10.0
[11/28 23:38:03 visual_prompt]: Epoch 3 / 100: avg data time: 1.18e+01, avg batch time: 12.6407, average train loss: 22.4783
[11/28 23:38:54 visual_prompt]: Inference (val):avg data time: 5.19e-05, avg batch time: 0.5273, average loss: 22.4050
[11/28 23:38:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.81	
[11/28 23:38:54 visual_prompt]: Training 4 / 100 epoch, with learning rate 15.0
[11/28 23:46:15 visual_prompt]: Epoch 4 / 100: avg data time: 1.17e+01, avg batch time: 12.6135, average train loss: 41.8588
[11/28 23:47:07 visual_prompt]: Inference (val):avg data time: 4.37e-05, avg batch time: 0.5291, average loss: 27.7860
[11/28 23:47:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.88	
[11/28 23:47:07 visual_prompt]: Training 5 / 100 epoch, with learning rate 20.0
[11/28 23:54:29 visual_prompt]: Epoch 5 / 100: avg data time: 1.17e+01, avg batch time: 12.6151, average train loss: 54.8232
[11/28 23:55:20 visual_prompt]: Inference (val):avg data time: 3.46e-05, avg batch time: 0.5252, average loss: 24.0043
[11/28 23:55:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.88	
[11/28 23:55:20 visual_prompt]: Training 6 / 100 epoch, with learning rate 25.0
[11/29 00:02:43 visual_prompt]: Epoch 6 / 100: avg data time: 1.18e+01, avg batch time: 12.6451, average train loss: 54.2931
[11/29 00:03:34 visual_prompt]: Inference (val):avg data time: 4.18e-05, avg batch time: 0.5301, average loss: 55.2725
[11/29 00:03:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.53	
[11/29 00:03:34 visual_prompt]: Training 7 / 100 epoch, with learning rate 30.0
[11/29 00:10:57 visual_prompt]: Epoch 7 / 100: avg data time: 1.18e+01, avg batch time: 12.6530, average train loss: 27.7218
[11/29 00:11:49 visual_prompt]: Inference (val):avg data time: 4.11e-05, avg batch time: 0.5260, average loss: 7.0102
[11/29 00:11:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.49	
[11/29 00:11:49 visual_prompt]: Training 8 / 100 epoch, with learning rate 35.0
[11/29 00:19:10 visual_prompt]: Epoch 8 / 100: avg data time: 1.17e+01, avg batch time: 12.6081, average train loss: 81.4585
[11/29 00:20:02 visual_prompt]: Inference (val):avg data time: 4.88e-05, avg batch time: 0.5250, average loss: 160.3830
[11/29 00:20:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.04	
[11/29 00:20:02 visual_prompt]: Training 9 / 100 epoch, with learning rate 40.0
[11/29 00:27:25 visual_prompt]: Epoch 9 / 100: avg data time: 1.18e+01, avg batch time: 12.6555, average train loss: 39.7723
[11/29 00:28:16 visual_prompt]: Inference (val):avg data time: 6.26e-05, avg batch time: 0.5227, average loss: 20.0599
[11/29 00:28:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.98	
[11/29 00:28:16 visual_prompt]: Training 10 / 100 epoch, with learning rate 45.0
[11/29 00:35:38 visual_prompt]: Epoch 10 / 100: avg data time: 1.18e+01, avg batch time: 12.6314, average train loss: 53.7560
[11/29 00:36:29 visual_prompt]: Inference (val):avg data time: 4.99e-05, avg batch time: 0.5259, average loss: 55.4346
[11/29 00:36:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.93	
[11/29 00:36:29 visual_prompt]: Training 11 / 100 epoch, with learning rate 50.0
[11/29 00:43:52 visual_prompt]: Epoch 11 / 100: avg data time: 1.18e+01, avg batch time: 12.6273, average train loss: 38.6414
[11/29 00:44:43 visual_prompt]: Inference (val):avg data time: 4.52e-05, avg batch time: 0.5239, average loss: 56.3611
[11/29 00:44:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.28	
[11/29 00:44:43 visual_prompt]: Training 12 / 100 epoch, with learning rate 49.9847706754774
[11/29 00:52:05 visual_prompt]: Epoch 12 / 100: avg data time: 1.18e+01, avg batch time: 12.6309, average train loss: 45.0364
[11/29 00:52:57 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.5242, average loss: 43.5440
[11/29 00:52:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.31	
[11/29 00:52:57 visual_prompt]: Best epoch 12: best metric: -43.544
[11/29 00:52:57 visual_prompt]: Training 13 / 100 epoch, with learning rate 49.939101256495604
[11/29 01:00:20 visual_prompt]: Epoch 13 / 100: avg data time: 1.18e+01, avg batch time: 12.6571, average train loss: 30.3548
[11/29 01:01:11 visual_prompt]: Inference (val):avg data time: 4.07e-05, avg batch time: 0.5239, average loss: 18.9613
[11/29 01:01:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.15	
[11/29 01:01:11 visual_prompt]: Best epoch 13: best metric: -18.961
[11/29 01:01:11 visual_prompt]: Training 14 / 100 epoch, with learning rate 49.86304738420683
[11/29 01:08:33 visual_prompt]: Epoch 14 / 100: avg data time: 1.18e+01, avg batch time: 12.6293, average train loss: 53.3074
[11/29 01:09:24 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.5285, average loss: 0.7582
[11/29 01:09:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.52	
[11/29 01:09:24 visual_prompt]: Best epoch 14: best metric: -0.758
[11/29 01:09:24 visual_prompt]: Training 15 / 100 epoch, with learning rate 49.75670171853926
[11/29 01:16:47 visual_prompt]: Epoch 15 / 100: avg data time: 1.18e+01, avg batch time: 12.6508, average train loss: 32.6008
[11/29 01:17:39 visual_prompt]: Inference (val):avg data time: 5.20e-05, avg batch time: 0.5300, average loss: 55.0331
[11/29 01:17:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.51	
[11/29 01:17:39 visual_prompt]: Training 16 / 100 epoch, with learning rate 49.6201938253052
[11/29 01:25:01 visual_prompt]: Epoch 16 / 100: avg data time: 1.17e+01, avg batch time: 12.6176, average train loss: 23.8085
[11/29 01:25:52 visual_prompt]: Inference (val):avg data time: 5.33e-05, avg batch time: 0.5282, average loss: 25.0575
[11/29 01:25:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.27	
[11/29 01:25:52 visual_prompt]: Training 17 / 100 epoch, with learning rate 49.45369001834514
[11/29 01:33:14 visual_prompt]: Epoch 17 / 100: avg data time: 1.17e+01, avg batch time: 12.6211, average train loss: 21.4958
[11/29 01:34:06 visual_prompt]: Inference (val):avg data time: 4.82e-05, avg batch time: 0.5307, average loss: 54.8485
[11/29 01:34:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.94	
[11/29 01:34:06 visual_prompt]: Training 18 / 100 epoch, with learning rate 49.25739315689991
[11/29 01:41:28 visual_prompt]: Epoch 18 / 100: avg data time: 1.18e+01, avg batch time: 12.6414, average train loss: 76.7608
[11/29 01:42:20 visual_prompt]: Inference (val):avg data time: 4.33e-05, avg batch time: 0.5222, average loss: 93.1804
[11/29 01:42:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.08	
[11/29 01:42:20 visual_prompt]: Training 19 / 100 epoch, with learning rate 49.03154239845797
[11/29 01:49:41 visual_prompt]: Epoch 19 / 100: avg data time: 1.17e+01, avg batch time: 12.6115, average train loss: 28.2852
[11/29 01:50:32 visual_prompt]: Inference (val):avg data time: 4.83e-05, avg batch time: 0.5224, average loss: 19.4200
[11/29 01:50:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.33	
[11/29 01:50:32 visual_prompt]: Training 20 / 100 epoch, with learning rate 48.77641290737884
[11/29 01:57:54 visual_prompt]: Epoch 20 / 100: avg data time: 1.18e+01, avg batch time: 12.6205, average train loss: 39.3531
[11/29 01:58:45 visual_prompt]: Inference (val):avg data time: 5.61e-05, avg batch time: 0.5188, average loss: 93.7001
[11/29 01:58:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.31	
[11/29 01:58:46 visual_prompt]: Training 21 / 100 epoch, with learning rate 48.49231551964771
[11/29 02:06:09 visual_prompt]: Epoch 21 / 100: avg data time: 1.18e+01, avg batch time: 12.6738, average train loss: 24.9626
[11/29 02:07:00 visual_prompt]: Inference (val):avg data time: 5.13e-05, avg batch time: 0.5228, average loss: 30.7846
[11/29 02:07:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.94	
[11/29 02:07:00 visual_prompt]: Stopping early.
[11/29 02:07:01 visual_prompt]: Rank of current process: 0. World size: 1
[11/29 02:07:01 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA TITAN Xp
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/29 02:07:01 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss', 'RECORD_GPU_SNAPSHOT', 'True'])
[11/29 02:07:01 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/29 02:07:01 visual_prompt]: Training with config:
[11/29 02:07:01 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr25.0_wd0.01/patience7/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 25.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True}), 'RECORD_GPU_SNAPSHOT': True})
[11/29 02:07:01 visual_prompt]: Loading training data...
[11/29 02:07:01 visual_prompt]: Constructing mammo-cbis dataset train...
[11/29 02:07:01 visual_prompt]: Loading validation data...
[11/29 02:07:01 visual_prompt]: Constructing mammo-cbis dataset val...
[11/29 02:07:01 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[11/29 02:07:04 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[11/29 02:07:04 visual_prompt]: tuned percent:0.536
[11/29 02:07:05 visual_prompt]: Device used for model: 0
[11/29 02:07:05 visual_prompt]: Setting up Evaluator...
[11/29 02:07:05 visual_prompt]: Setting up Trainer...
[11/29 02:07:05 visual_prompt]: 	Setting up the optimizer...
[11/29 02:07:05 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/29 02:14:28 visual_prompt]: Epoch 1 / 100: avg data time: 1.18e+01, avg batch time: 12.6676, average train loss: 1.4006
[11/29 02:15:20 visual_prompt]: Inference (val):avg data time: 4.76e-05, avg batch time: 0.5354, average loss: 1.2969
[11/29 02:15:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[11/29 02:15:20 visual_prompt]: Training 2 / 100 epoch, with learning rate 2.5
[11/29 02:22:43 visual_prompt]: Epoch 2 / 100: avg data time: 1.18e+01, avg batch time: 12.6595, average train loss: 15.7918
[11/29 02:23:35 visual_prompt]: Inference (val):avg data time: 3.87e-05, avg batch time: 0.5202, average loss: 6.8894
[11/29 02:23:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.72	
[11/29 02:23:35 visual_prompt]: Training 3 / 100 epoch, with learning rate 5.0
[11/29 02:30:59 visual_prompt]: Epoch 3 / 100: avg data time: 1.18e+01, avg batch time: 12.6717, average train loss: 10.7627
[11/29 02:31:50 visual_prompt]: Inference (val):avg data time: 5.12e-05, avg batch time: 0.5276, average loss: 7.5916
[11/29 02:31:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 45.39	
[11/29 02:31:50 visual_prompt]: Training 4 / 100 epoch, with learning rate 7.5
[11/29 02:39:12 visual_prompt]: Epoch 4 / 100: avg data time: 1.17e+01, avg batch time: 12.6128, average train loss: 16.2732
[11/29 02:40:03 visual_prompt]: Inference (val):avg data time: 4.04e-05, avg batch time: 0.5238, average loss: 4.7213
[11/29 02:40:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.61	
[11/29 02:40:03 visual_prompt]: Training 5 / 100 epoch, with learning rate 10.0
[11/29 02:47:26 visual_prompt]: Epoch 5 / 100: avg data time: 1.18e+01, avg batch time: 12.6385, average train loss: 37.4550
[11/29 02:48:17 visual_prompt]: Inference (val):avg data time: 4.85e-05, avg batch time: 0.5270, average loss: 19.0919
[11/29 02:48:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.24	
[11/29 02:48:17 visual_prompt]: Training 6 / 100 epoch, with learning rate 12.5
[11/29 02:55:41 visual_prompt]: Epoch 6 / 100: avg data time: 1.18e+01, avg batch time: 12.6629, average train loss: 39.3881
[11/29 02:56:31 visual_prompt]: Inference (val):avg data time: 3.95e-05, avg batch time: 0.5191, average loss: 102.4557
[11/29 02:56:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.86	
[11/29 02:56:31 visual_prompt]: Training 7 / 100 epoch, with learning rate 15.0
[11/29 03:03:51 visual_prompt]: Epoch 7 / 100: avg data time: 1.17e+01, avg batch time: 12.5690, average train loss: 39.6249
[11/29 03:04:42 visual_prompt]: Inference (val):avg data time: 4.06e-05, avg batch time: 0.5279, average loss: 64.6401
[11/29 03:04:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.81	
[11/29 03:04:42 visual_prompt]: Training 8 / 100 epoch, with learning rate 17.5
[11/29 03:12:05 visual_prompt]: Epoch 8 / 100: avg data time: 1.18e+01, avg batch time: 12.6335, average train loss: 49.9475
[11/29 03:12:56 visual_prompt]: Inference (val):avg data time: 3.60e-05, avg batch time: 0.5241, average loss: 160.6079
[11/29 03:12:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.92	
[11/29 03:12:56 visual_prompt]: Training 9 / 100 epoch, with learning rate 20.0
[11/29 03:20:18 visual_prompt]: Epoch 9 / 100: avg data time: 1.17e+01, avg batch time: 12.6159, average train loss: 45.3639
[11/29 03:21:09 visual_prompt]: Inference (val):avg data time: 3.73e-05, avg batch time: 0.5340, average loss: 67.4572
[11/29 03:21:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 42.20	
[11/29 03:21:09 visual_prompt]: Training 10 / 100 epoch, with learning rate 22.5
[11/29 03:28:29 visual_prompt]: Epoch 10 / 100: avg data time: 1.17e+01, avg batch time: 12.5704, average train loss: 65.7773
[11/29 03:29:20 visual_prompt]: Inference (val):avg data time: 4.14e-05, avg batch time: 0.5241, average loss: 56.5179
[11/29 03:29:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.09	
[11/29 03:29:20 visual_prompt]: Training 11 / 100 epoch, with learning rate 25.0
[11/29 03:36:41 visual_prompt]: Epoch 11 / 100: avg data time: 1.17e+01, avg batch time: 12.5800, average train loss: 45.6347
[11/29 03:37:31 visual_prompt]: Inference (val):avg data time: 4.54e-05, avg batch time: 0.5296, average loss: 54.4974
[11/29 03:37:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.88	
[11/29 03:37:31 visual_prompt]: Training 12 / 100 epoch, with learning rate 24.9923853377387
[11/29 03:44:51 visual_prompt]: Epoch 12 / 100: avg data time: 1.17e+01, avg batch time: 12.5632, average train loss: 49.6809
[11/29 03:45:43 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.5232, average loss: 17.6987
[11/29 03:45:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 41.14	
[11/29 03:45:43 visual_prompt]: Best epoch 12: best metric: -17.699
[11/29 03:45:43 visual_prompt]: Training 13 / 100 epoch, with learning rate 24.969550628247802
[11/29 03:53:01 visual_prompt]: Epoch 13 / 100: avg data time: 1.17e+01, avg batch time: 12.5253, average train loss: 66.5660
[11/29 03:53:52 visual_prompt]: Inference (val):avg data time: 4.58e-05, avg batch time: 0.5206, average loss: 68.4455
[11/29 03:53:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.13	
[11/29 03:53:52 visual_prompt]: Training 14 / 100 epoch, with learning rate 24.931523692103415
[11/29 04:01:08 visual_prompt]: Epoch 14 / 100: avg data time: 1.16e+01, avg batch time: 12.4577, average train loss: 83.4128
[11/29 04:01:59 visual_prompt]: Inference (val):avg data time: 4.85e-05, avg batch time: 0.5264, average loss: 299.3634
[11/29 04:01:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.00	
[11/29 04:01:59 visual_prompt]: Training 15 / 100 epoch, with learning rate 24.87835085926963
[11/29 04:09:17 visual_prompt]: Epoch 15 / 100: avg data time: 1.16e+01, avg batch time: 12.4961, average train loss: 130.0345
[11/29 04:10:08 visual_prompt]: Inference (val):avg data time: 3.71e-05, avg batch time: 0.5326, average loss: 2.0601
[11/29 04:10:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 61.65	
[11/29 04:10:08 visual_prompt]: Best epoch 15: best metric: -2.060
[11/29 04:10:08 visual_prompt]: Training 16 / 100 epoch, with learning rate 24.8100969126526
[11/29 04:17:26 visual_prompt]: Epoch 16 / 100: avg data time: 1.16e+01, avg batch time: 12.5047, average train loss: 74.8319
[11/29 04:18:17 visual_prompt]: Inference (val):avg data time: 3.71e-05, avg batch time: 0.5250, average loss: 105.7599
[11/29 04:18:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.21	
[11/29 04:18:17 visual_prompt]: Training 17 / 100 epoch, with learning rate 24.72684500917257
[11/29 04:25:35 visual_prompt]: Epoch 17 / 100: avg data time: 1.16e+01, avg batch time: 12.5055, average train loss: 63.3187
[11/29 04:26:26 visual_prompt]: Inference (val):avg data time: 4.67e-05, avg batch time: 0.5227, average loss: 30.9655
[11/29 04:26:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.98	
[11/29 04:26:26 visual_prompt]: Training 18 / 100 epoch, with learning rate 24.628696578449954
[11/29 04:33:44 visual_prompt]: Epoch 18 / 100: avg data time: 1.17e+01, avg batch time: 12.5262, average train loss: 82.0289
[11/29 04:34:35 visual_prompt]: Inference (val):avg data time: 4.73e-05, avg batch time: 0.5350, average loss: 174.5963
[11/29 04:34:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.96	
[11/29 04:34:35 visual_prompt]: Training 19 / 100 epoch, with learning rate 24.515771199228986
[11/29 04:41:54 visual_prompt]: Epoch 19 / 100: avg data time: 1.16e+01, avg batch time: 12.5134, average train loss: 71.7941
[11/29 04:42:45 visual_prompt]: Inference (val):avg data time: 5.32e-05, avg batch time: 0.5229, average loss: 134.8451
[11/29 04:42:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.59	
[11/29 04:42:45 visual_prompt]: Training 20 / 100 epoch, with learning rate 24.38820645368942
[11/29 04:50:04 visual_prompt]: Epoch 20 / 100: avg data time: 1.17e+01, avg batch time: 12.5494, average train loss: 62.4867
[11/29 04:50:55 visual_prompt]: Inference (val):avg data time: 4.39e-05, avg batch time: 0.5299, average loss: 30.6840
[11/29 04:50:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.36	
[11/29 04:50:55 visual_prompt]: Training 21 / 100 epoch, with learning rate 24.246157759823856
[11/29 04:58:15 visual_prompt]: Epoch 21 / 100: avg data time: 1.17e+01, avg batch time: 12.5609, average train loss: 95.0501
[11/29 04:59:06 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.5276, average loss: 190.0296
[11/29 04:59:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.43	
[11/29 04:59:06 visual_prompt]: Training 22 / 100 epoch, with learning rate 24.08979818208484
[11/29 05:06:25 visual_prompt]: Epoch 22 / 100: avg data time: 1.16e+01, avg batch time: 12.5195, average train loss: 80.5103
[11/29 05:07:15 visual_prompt]: Inference (val):avg data time: 4.65e-05, avg batch time: 0.5226, average loss: 122.3092
[11/29 05:07:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.20	
[11/29 05:07:15 visual_prompt]: Stopping early.
[11/29 05:07:16 visual_prompt]: Rank of current process: 0. World size: 1
[11/29 05:07:16 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA TITAN Xp
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/29 05:07:16 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss', 'RECORD_GPU_SNAPSHOT', 'True'])
[11/29 05:07:16 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/29 05:07:16 visual_prompt]: Training with config:
[11/29 05:07:16 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr25.0_wd0.001/patience7/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 25.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True}), 'RECORD_GPU_SNAPSHOT': True})
[11/29 05:07:16 visual_prompt]: Loading training data...
[11/29 05:07:16 visual_prompt]: Constructing mammo-cbis dataset train...
[11/29 05:07:16 visual_prompt]: Loading validation data...
[11/29 05:07:16 visual_prompt]: Constructing mammo-cbis dataset val...
[11/29 05:07:16 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[11/29 05:07:19 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[11/29 05:07:19 visual_prompt]: tuned percent:0.536
[11/29 05:07:19 visual_prompt]: Device used for model: 0
[11/29 05:07:19 visual_prompt]: Setting up Evaluator...
[11/29 05:07:19 visual_prompt]: Setting up Trainer...
[11/29 05:07:19 visual_prompt]: 	Setting up the optimizer...
[11/29 05:07:19 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/29 05:14:39 visual_prompt]: Epoch 1 / 100: avg data time: 1.17e+01, avg batch time: 12.5570, average train loss: 1.4006
[11/29 05:15:30 visual_prompt]: Inference (val):avg data time: 4.81e-05, avg batch time: 0.5305, average loss: 1.2969
[11/29 05:15:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[11/29 05:15:30 visual_prompt]: Training 2 / 100 epoch, with learning rate 2.5
[11/29 05:22:49 visual_prompt]: Epoch 2 / 100: avg data time: 1.17e+01, avg batch time: 12.5434, average train loss: 23.9563
[11/29 05:23:40 visual_prompt]: Inference (val):avg data time: 4.20e-05, avg batch time: 0.5306, average loss: 2.2611
[11/29 05:23:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.94	
[11/29 05:23:40 visual_prompt]: Training 3 / 100 epoch, with learning rate 5.0
[11/29 05:30:58 visual_prompt]: Epoch 3 / 100: avg data time: 1.16e+01, avg batch time: 12.5208, average train loss: 12.5572
[11/29 05:31:49 visual_prompt]: Inference (val):avg data time: 4.37e-05, avg batch time: 0.5254, average loss: 5.1162
[11/29 05:31:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.45	
[11/29 05:31:49 visual_prompt]: Training 4 / 100 epoch, with learning rate 7.5
[11/29 05:39:09 visual_prompt]: Epoch 4 / 100: avg data time: 1.17e+01, avg batch time: 12.5702, average train loss: 11.6014
[11/29 05:40:00 visual_prompt]: Inference (val):avg data time: 5.29e-05, avg batch time: 0.5273, average loss: 5.2183
[11/29 05:40:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.73	
[11/29 05:40:00 visual_prompt]: Training 5 / 100 epoch, with learning rate 10.0
[11/29 05:47:17 visual_prompt]: Epoch 5 / 100: avg data time: 1.16e+01, avg batch time: 12.4840, average train loss: 28.7568
[11/29 05:48:08 visual_prompt]: Inference (val):avg data time: 4.64e-05, avg batch time: 0.5182, average loss: 15.6132
[11/29 05:48:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.37	
[11/29 05:48:08 visual_prompt]: Training 6 / 100 epoch, with learning rate 12.5
[11/29 05:55:26 visual_prompt]: Epoch 6 / 100: avg data time: 1.17e+01, avg batch time: 12.5275, average train loss: 17.9456
[11/29 05:56:18 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.5312, average loss: 11.7070
[11/29 05:56:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.61	
[11/29 05:56:18 visual_prompt]: Training 7 / 100 epoch, with learning rate 15.0
[11/29 06:03:36 visual_prompt]: Epoch 7 / 100: avg data time: 1.17e+01, avg batch time: 12.5343, average train loss: 25.2146
[11/29 06:04:28 visual_prompt]: Inference (val):avg data time: 3.93e-05, avg batch time: 0.5256, average loss: 8.6318
[11/29 06:04:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.34	
[11/29 06:04:28 visual_prompt]: Training 8 / 100 epoch, with learning rate 17.5
[11/29 06:11:45 visual_prompt]: Epoch 8 / 100: avg data time: 1.16e+01, avg batch time: 12.4902, average train loss: 33.6537
[11/29 06:12:36 visual_prompt]: Inference (val):avg data time: 3.76e-05, avg batch time: 0.5240, average loss: 3.5247
[11/29 06:12:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.36	
[11/29 06:12:36 visual_prompt]: Training 9 / 100 epoch, with learning rate 20.0
[11/29 06:19:54 visual_prompt]: Epoch 9 / 100: avg data time: 1.16e+01, avg batch time: 12.5091, average train loss: 46.5278
[11/29 06:20:46 visual_prompt]: Inference (val):avg data time: 3.85e-05, avg batch time: 0.5220, average loss: 21.3520
[11/29 06:20:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.28	
[11/29 06:20:46 visual_prompt]: Training 10 / 100 epoch, with learning rate 22.5
[11/29 06:28:04 visual_prompt]: Epoch 10 / 100: avg data time: 1.16e+01, avg batch time: 12.5131, average train loss: 53.4978
[11/29 06:28:54 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.5176, average loss: 34.7211
[11/29 06:28:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.19	
[11/29 06:28:54 visual_prompt]: Training 11 / 100 epoch, with learning rate 25.0
[11/29 06:36:12 visual_prompt]: Epoch 11 / 100: avg data time: 1.16e+01, avg batch time: 12.4886, average train loss: 39.1158
[11/29 06:37:02 visual_prompt]: Inference (val):avg data time: 3.94e-05, avg batch time: 0.5268, average loss: 85.8978
[11/29 06:37:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.06	
[11/29 06:37:02 visual_prompt]: Training 12 / 100 epoch, with learning rate 24.9923853377387
[11/29 06:44:18 visual_prompt]: Epoch 12 / 100: avg data time: 1.16e+01, avg batch time: 12.4667, average train loss: 89.5430
[11/29 06:45:08 visual_prompt]: Inference (val):avg data time: 4.58e-05, avg batch time: 0.5280, average loss: 4.1313
[11/29 06:45:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.58	
[11/29 06:45:08 visual_prompt]: Best epoch 12: best metric: -4.131
[11/29 06:45:08 visual_prompt]: Training 13 / 100 epoch, with learning rate 24.969550628247802
[11/29 06:52:26 visual_prompt]: Epoch 13 / 100: avg data time: 1.16e+01, avg batch time: 12.4956, average train loss: 71.3667
[11/29 06:53:16 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.5168, average loss: 4.0069
[11/29 06:53:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.74	
[11/29 06:53:16 visual_prompt]: Best epoch 13: best metric: -4.007
[11/29 06:53:16 visual_prompt]: Training 14 / 100 epoch, with learning rate 24.931523692103415
[11/29 07:00:31 visual_prompt]: Epoch 14 / 100: avg data time: 1.16e+01, avg batch time: 12.4426, average train loss: 54.6791
[11/29 07:01:22 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.5186, average loss: 50.7133
[11/29 07:01:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.42	
[11/29 07:01:22 visual_prompt]: Training 15 / 100 epoch, with learning rate 24.87835085926963
[11/29 07:08:39 visual_prompt]: Epoch 15 / 100: avg data time: 1.16e+01, avg batch time: 12.4738, average train loss: 46.9962
[11/29 07:09:30 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.5244, average loss: 33.4857
[11/29 07:09:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.11	
[11/29 07:09:30 visual_prompt]: Training 16 / 100 epoch, with learning rate 24.8100969126526
[11/29 07:16:47 visual_prompt]: Epoch 16 / 100: avg data time: 1.16e+01, avg batch time: 12.4965, average train loss: 53.9086
[11/29 07:17:38 visual_prompt]: Inference (val):avg data time: 4.39e-05, avg batch time: 0.5220, average loss: 64.7179
[11/29 07:17:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.62	
[11/29 07:17:38 visual_prompt]: Training 17 / 100 epoch, with learning rate 24.72684500917257
[11/29 07:24:56 visual_prompt]: Epoch 17 / 100: avg data time: 1.16e+01, avg batch time: 12.4918, average train loss: 38.0387
[11/29 07:25:47 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.5240, average loss: 39.6790
[11/29 07:25:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.57	
[11/29 07:25:47 visual_prompt]: Training 18 / 100 epoch, with learning rate 24.628696578449954
[11/29 07:33:04 visual_prompt]: Epoch 18 / 100: avg data time: 1.16e+01, avg batch time: 12.4962, average train loss: 53.2982
[11/29 07:33:55 visual_prompt]: Inference (val):avg data time: 4.57e-05, avg batch time: 0.5232, average loss: 64.1893
[11/29 07:33:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 45.51	
[11/29 07:33:55 visual_prompt]: Training 19 / 100 epoch, with learning rate 24.515771199228986
[11/29 07:41:13 visual_prompt]: Epoch 19 / 100: avg data time: 1.16e+01, avg batch time: 12.4901, average train loss: 67.6427
[11/29 07:42:04 visual_prompt]: Inference (val):avg data time: 5.82e-05, avg batch time: 0.5217, average loss: 32.7374
[11/29 07:42:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.62	
[11/29 07:42:04 visual_prompt]: Training 20 / 100 epoch, with learning rate 24.38820645368942
[11/29 07:49:21 visual_prompt]: Epoch 20 / 100: avg data time: 1.16e+01, avg batch time: 12.4981, average train loss: 65.8348
[11/29 07:50:12 visual_prompt]: Inference (val):avg data time: 4.50e-05, avg batch time: 0.5229, average loss: 170.4924
[11/29 07:50:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.49	
[11/29 07:50:12 visual_prompt]: Stopping early.
[11/29 07:50:13 visual_prompt]: Rank of current process: 0. World size: 1
[11/29 07:50:13 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA TITAN Xp
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/29 07:50:13 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss', 'RECORD_GPU_SNAPSHOT', 'True'])
[11/29 07:50:13 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/29 07:50:13 visual_prompt]: Training with config:
[11/29 07:50:13 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr25.0_wd0.0001/patience7/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 25.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True}), 'RECORD_GPU_SNAPSHOT': True})
[11/29 07:50:13 visual_prompt]: Loading training data...
[11/29 07:50:13 visual_prompt]: Constructing mammo-cbis dataset train...
[11/29 07:50:13 visual_prompt]: Loading validation data...
[11/29 07:50:13 visual_prompt]: Constructing mammo-cbis dataset val...
[11/29 07:50:13 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[11/29 07:50:16 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[11/29 07:50:16 visual_prompt]: tuned percent:0.536
[11/29 07:50:16 visual_prompt]: Device used for model: 0
[11/29 07:50:16 visual_prompt]: Setting up Evaluator...
[11/29 07:50:16 visual_prompt]: Setting up Trainer...
[11/29 07:50:16 visual_prompt]: 	Setting up the optimizer...
[11/29 07:50:16 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/29 07:57:34 visual_prompt]: Epoch 1 / 100: avg data time: 1.16e+01, avg batch time: 12.5150, average train loss: 1.4006
[11/29 07:58:25 visual_prompt]: Inference (val):avg data time: 4.22e-05, avg batch time: 0.5196, average loss: 1.2969
[11/29 07:58:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[11/29 07:58:25 visual_prompt]: Training 2 / 100 epoch, with learning rate 2.5
[11/29 08:05:42 visual_prompt]: Epoch 2 / 100: avg data time: 1.16e+01, avg batch time: 12.5013, average train loss: 23.3420
[11/29 08:06:33 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.5159, average loss: 1.6945
[11/29 08:06:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.77	
[11/29 08:06:33 visual_prompt]: Training 3 / 100 epoch, with learning rate 5.0
[11/29 08:13:49 visual_prompt]: Epoch 3 / 100: avg data time: 1.16e+01, avg batch time: 12.4536, average train loss: 6.8467
[11/29 08:14:40 visual_prompt]: Inference (val):avg data time: 4.33e-05, avg batch time: 0.5222, average loss: 3.2745
[11/29 08:14:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.98	
[11/29 08:14:40 visual_prompt]: Training 4 / 100 epoch, with learning rate 7.5
[11/29 08:21:57 visual_prompt]: Epoch 4 / 100: avg data time: 1.16e+01, avg batch time: 12.4859, average train loss: 13.5289
[11/29 08:22:48 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.5183, average loss: 31.5207
[11/29 08:22:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.00	
[11/29 08:22:48 visual_prompt]: Training 5 / 100 epoch, with learning rate 10.0
[11/29 08:30:05 visual_prompt]: Epoch 5 / 100: avg data time: 1.16e+01, avg batch time: 12.4936, average train loss: 17.9638
[11/29 08:30:56 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.5256, average loss: 4.0814
[11/29 08:30:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.27	
[11/29 08:30:56 visual_prompt]: Training 6 / 100 epoch, with learning rate 12.5
[11/29 08:38:14 visual_prompt]: Epoch 6 / 100: avg data time: 1.16e+01, avg batch time: 12.5038, average train loss: 23.6279
[11/29 08:39:05 visual_prompt]: Inference (val):avg data time: 3.74e-05, avg batch time: 0.5238, average loss: 16.5253
[11/29 08:39:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.50	
[11/29 08:39:05 visual_prompt]: Training 7 / 100 epoch, with learning rate 15.0
[11/29 08:46:22 visual_prompt]: Epoch 7 / 100: avg data time: 1.16e+01, avg batch time: 12.4753, average train loss: 42.5847
[11/29 08:47:13 visual_prompt]: Inference (val):avg data time: 4.49e-05, avg batch time: 0.5223, average loss: 28.9656
[11/29 08:47:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.21	
[11/29 08:47:13 visual_prompt]: Training 8 / 100 epoch, with learning rate 17.5
[11/29 08:54:28 visual_prompt]: Epoch 8 / 100: avg data time: 1.16e+01, avg batch time: 12.4401, average train loss: 34.4184
[11/29 08:55:19 visual_prompt]: Inference (val):avg data time: 3.71e-05, avg batch time: 0.5193, average loss: 25.3895
[11/29 08:55:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.06	
[11/29 08:55:19 visual_prompt]: Training 9 / 100 epoch, with learning rate 20.0
[11/29 09:02:36 visual_prompt]: Epoch 9 / 100: avg data time: 1.16e+01, avg batch time: 12.4858, average train loss: 10.9663
[11/29 09:03:27 visual_prompt]: Inference (val):avg data time: 3.62e-05, avg batch time: 0.5220, average loss: 6.2567
[11/29 09:03:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 61.19	
[11/29 09:03:27 visual_prompt]: Training 10 / 100 epoch, with learning rate 22.5
[11/29 09:10:45 visual_prompt]: Epoch 10 / 100: avg data time: 1.16e+01, avg batch time: 12.5097, average train loss: 29.6243
[11/29 09:11:36 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.5161, average loss: 50.6515
[11/29 09:11:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 62.30	
[11/29 09:11:36 visual_prompt]: Training 11 / 100 epoch, with learning rate 25.0
[11/29 09:18:56 visual_prompt]: Epoch 11 / 100: avg data time: 1.17e+01, avg batch time: 12.5815, average train loss: 36.6971
[11/29 09:19:48 visual_prompt]: Inference (val):avg data time: 3.38e-05, avg batch time: 0.5234, average loss: 67.0725
[11/29 09:19:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.37	
[11/29 09:19:48 visual_prompt]: Training 12 / 100 epoch, with learning rate 24.9923853377387
[11/29 09:27:11 visual_prompt]: Epoch 12 / 100: avg data time: 1.18e+01, avg batch time: 12.6471, average train loss: 43.5188
[11/29 09:28:02 visual_prompt]: Inference (val):avg data time: 5.15e-05, avg batch time: 0.5182, average loss: 47.8986
[11/29 09:28:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.15	
[11/29 09:28:02 visual_prompt]: Best epoch 12: best metric: -47.899
[11/29 09:28:02 visual_prompt]: Training 13 / 100 epoch, with learning rate 24.969550628247802
[11/29 09:35:23 visual_prompt]: Epoch 13 / 100: avg data time: 1.17e+01, avg batch time: 12.5759, average train loss: 27.3156
[11/29 09:36:14 visual_prompt]: Inference (val):avg data time: 5.16e-05, avg batch time: 0.5172, average loss: 10.5741
[11/29 09:36:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.03	
[11/29 09:36:14 visual_prompt]: Best epoch 13: best metric: -10.574
[11/29 09:36:14 visual_prompt]: Training 14 / 100 epoch, with learning rate 24.931523692103415
[11/29 09:43:32 visual_prompt]: Epoch 14 / 100: avg data time: 1.16e+01, avg batch time: 12.5195, average train loss: 31.3186
[11/29 09:44:23 visual_prompt]: Inference (val):avg data time: 5.01e-05, avg batch time: 0.5149, average loss: 1.0008
[11/29 09:44:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 48.37	rocauc: 57.16	
[11/29 09:44:23 visual_prompt]: Best epoch 14: best metric: -1.001
[11/29 09:44:23 visual_prompt]: Training 15 / 100 epoch, with learning rate 24.87835085926963
[11/29 09:51:43 visual_prompt]: Epoch 15 / 100: avg data time: 1.17e+01, avg batch time: 12.5605, average train loss: 32.5071
[11/29 09:52:34 visual_prompt]: Inference (val):avg data time: 4.85e-05, avg batch time: 0.5211, average loss: 13.2455
[11/29 09:52:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.11	
[11/29 09:52:34 visual_prompt]: Training 16 / 100 epoch, with learning rate 24.8100969126526
[11/29 09:59:56 visual_prompt]: Epoch 16 / 100: avg data time: 1.18e+01, avg batch time: 12.6214, average train loss: 80.8210
[11/29 10:00:47 visual_prompt]: Inference (val):avg data time: 3.71e-05, avg batch time: 0.5227, average loss: 134.5552
[11/29 10:00:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.44	
[11/29 10:00:47 visual_prompt]: Training 17 / 100 epoch, with learning rate 24.72684500917257
[11/29 10:08:05 visual_prompt]: Epoch 17 / 100: avg data time: 1.17e+01, avg batch time: 12.5202, average train loss: 55.7091
[11/29 10:08:56 visual_prompt]: Inference (val):avg data time: 5.48e-05, avg batch time: 0.5312, average loss: 29.5391
[11/29 10:08:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.83	
[11/29 10:08:56 visual_prompt]: Training 18 / 100 epoch, with learning rate 24.628696578449954
[11/29 10:16:17 visual_prompt]: Epoch 18 / 100: avg data time: 1.17e+01, avg batch time: 12.5853, average train loss: 27.6651
[11/29 10:17:08 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.5185, average loss: 17.4893
[11/29 10:17:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.62	
[11/29 10:17:08 visual_prompt]: Training 19 / 100 epoch, with learning rate 24.515771199228986
[11/29 10:24:29 visual_prompt]: Epoch 19 / 100: avg data time: 1.17e+01, avg batch time: 12.5705, average train loss: 30.7046
[11/29 10:25:19 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.5139, average loss: 41.1395
[11/29 10:25:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.63	
[11/29 10:25:19 visual_prompt]: Training 20 / 100 epoch, with learning rate 24.38820645368942
[11/29 10:32:38 visual_prompt]: Epoch 20 / 100: avg data time: 1.16e+01, avg batch time: 12.5254, average train loss: 19.0451
[11/29 10:33:29 visual_prompt]: Inference (val):avg data time: 3.95e-05, avg batch time: 0.5155, average loss: 8.2098
[11/29 10:33:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.27	
[11/29 10:33:29 visual_prompt]: Training 21 / 100 epoch, with learning rate 24.246157759823856
[11/29 10:40:47 visual_prompt]: Epoch 21 / 100: avg data time: 1.16e+01, avg batch time: 12.5033, average train loss: 38.2065
[11/29 10:41:38 visual_prompt]: Inference (val):avg data time: 3.70e-05, avg batch time: 0.5223, average loss: 87.9089
[11/29 10:41:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 44.20	
[11/29 10:41:38 visual_prompt]: Stopping early.
[11/29 10:41:38 visual_prompt]: Rank of current process: 0. World size: 1
[11/29 10:41:38 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA TITAN Xp
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/29 10:41:38 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '7', 'SOLVER.CRITERION', 'loss', 'RECORD_GPU_SNAPSHOT', 'True'])
[11/29 10:41:38 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/29 10:41:38 visual_prompt]: Training with config:
[11/29 10:41:38 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr25.0_wd0.0/patience7/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 7, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 25.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True}), 'RECORD_GPU_SNAPSHOT': True})
[11/29 10:41:38 visual_prompt]: Loading training data...
[11/29 10:41:38 visual_prompt]: Constructing mammo-cbis dataset train...
[11/29 10:41:38 visual_prompt]: Loading validation data...
[11/29 10:41:38 visual_prompt]: Constructing mammo-cbis dataset val...
[11/29 10:41:38 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[11/29 10:41:41 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[11/29 10:41:41 visual_prompt]: tuned percent:0.536
[11/29 10:41:42 visual_prompt]: Device used for model: 0
[11/29 10:41:42 visual_prompt]: Setting up Evaluator...
[11/29 10:41:42 visual_prompt]: Setting up Trainer...
[11/29 10:41:42 visual_prompt]: 	Setting up the optimizer...
[11/29 10:41:42 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/29 10:49:02 visual_prompt]: Epoch 1 / 100: avg data time: 1.17e+01, avg batch time: 12.5703, average train loss: 1.4006
[11/29 10:49:52 visual_prompt]: Inference (val):avg data time: 4.43e-05, avg batch time: 0.5276, average loss: 1.2969
[11/29 10:49:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[11/29 10:49:52 visual_prompt]: Training 2 / 100 epoch, with learning rate 2.5
[11/29 10:57:19 visual_prompt]: Epoch 2 / 100: avg data time: 1.19e+01, avg batch time: 12.7563, average train loss: 23.2444
[11/29 10:58:11 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.5190, average loss: 0.7595
[11/29 10:58:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 47.15	rocauc: 56.32	
[11/29 10:58:11 visual_prompt]: Training 3 / 100 epoch, with learning rate 5.0
[11/29 11:05:29 visual_prompt]: Epoch 3 / 100: avg data time: 1.17e+01, avg batch time: 12.5360, average train loss: 12.6302
[11/29 11:06:20 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.5161, average loss: 5.1407
[11/29 11:06:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.78	
[11/29 11:06:20 visual_prompt]: Training 4 / 100 epoch, with learning rate 7.5
[11/29 11:13:36 visual_prompt]: Epoch 4 / 100: avg data time: 1.16e+01, avg batch time: 12.4632, average train loss: 12.7690
[11/29 11:14:27 visual_prompt]: Inference (val):avg data time: 4.61e-05, avg batch time: 0.5216, average loss: 22.4596
[11/29 11:14:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.25	
[11/29 11:14:27 visual_prompt]: Training 5 / 100 epoch, with learning rate 10.0
[11/29 11:21:46 visual_prompt]: Epoch 5 / 100: avg data time: 1.17e+01, avg batch time: 12.5404, average train loss: 14.5014
[11/29 11:22:37 visual_prompt]: Inference (val):avg data time: 4.17e-05, avg batch time: 0.5178, average loss: 8.8947
[11/29 11:22:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.46	
[11/29 11:22:37 visual_prompt]: Training 6 / 100 epoch, with learning rate 12.5
[11/29 11:29:56 visual_prompt]: Epoch 6 / 100: avg data time: 1.17e+01, avg batch time: 12.5443, average train loss: 19.9883
[11/29 11:30:47 visual_prompt]: Inference (val):avg data time: 3.86e-05, avg batch time: 0.5167, average loss: 49.3884
[11/29 11:30:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.02	
[11/29 11:30:47 visual_prompt]: Training 7 / 100 epoch, with learning rate 15.0
[11/29 11:38:07 visual_prompt]: Epoch 7 / 100: avg data time: 1.17e+01, avg batch time: 12.5721, average train loss: 37.1695
[11/29 11:38:59 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.5262, average loss: 18.4642
[11/29 11:38:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.75	
[11/29 11:38:59 visual_prompt]: Training 8 / 100 epoch, with learning rate 17.5
[11/29 11:46:16 visual_prompt]: Epoch 8 / 100: avg data time: 1.16e+01, avg batch time: 12.4806, average train loss: 10.4049
[11/29 11:47:06 visual_prompt]: Inference (val):avg data time: 4.59e-05, avg batch time: 0.5180, average loss: 2.4897
[11/29 11:47:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.40	
[11/29 11:47:06 visual_prompt]: Training 9 / 100 epoch, with learning rate 20.0
[11/29 11:54:33 visual_prompt]: Epoch 9 / 100: avg data time: 1.19e+01, avg batch time: 12.7703, average train loss: 23.1159
[11/29 11:55:24 visual_prompt]: Inference (val):avg data time: 3.68e-05, avg batch time: 0.5237, average loss: 1.9623
[11/29 11:55:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.83	
[11/29 11:55:24 visual_prompt]: Training 10 / 100 epoch, with learning rate 22.5
[11/29 12:02:42 visual_prompt]: Epoch 10 / 100: avg data time: 1.16e+01, avg batch time: 12.4969, average train loss: 40.3583
[11/29 12:03:32 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.5181, average loss: 94.7424
[11/29 12:03:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 45.32	
[11/29 12:03:32 visual_prompt]: Training 11 / 100 epoch, with learning rate 25.0
[11/29 12:10:52 visual_prompt]: Epoch 11 / 100: avg data time: 1.17e+01, avg batch time: 12.5619, average train loss: 55.4712
[11/29 12:11:43 visual_prompt]: Inference (val):avg data time: 4.98e-05, avg batch time: 0.5215, average loss: 162.2737
[11/29 12:11:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.03	
[11/29 12:11:43 visual_prompt]: Training 12 / 100 epoch, with learning rate 24.9923853377387
[11/29 12:19:03 visual_prompt]: Epoch 12 / 100: avg data time: 1.17e+01, avg batch time: 12.5791, average train loss: 35.7930
[11/29 12:19:54 visual_prompt]: Inference (val):avg data time: 3.62e-05, avg batch time: 0.5179, average loss: 1.2686
[11/29 12:19:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.94	
[11/29 12:19:54 visual_prompt]: Best epoch 12: best metric: -1.269
[11/29 12:19:54 visual_prompt]: Training 13 / 100 epoch, with learning rate 24.969550628247802
[11/29 12:27:14 visual_prompt]: Epoch 13 / 100: avg data time: 1.17e+01, avg batch time: 12.5502, average train loss: 44.0898
[11/29 12:28:04 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.5192, average loss: 38.4840
[11/29 12:28:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.53	
[11/29 12:28:04 visual_prompt]: Training 14 / 100 epoch, with learning rate 24.931523692103415
[11/29 12:35:21 visual_prompt]: Epoch 14 / 100: avg data time: 1.16e+01, avg batch time: 12.4626, average train loss: 59.5598
[11/29 12:36:12 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.5221, average loss: 82.5873
[11/29 12:36:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.52	
[11/29 12:36:12 visual_prompt]: Training 15 / 100 epoch, with learning rate 24.87835085926963
[11/29 12:43:30 visual_prompt]: Epoch 15 / 100: avg data time: 1.16e+01, avg batch time: 12.5220, average train loss: 38.4200
[11/29 12:44:21 visual_prompt]: Inference (val):avg data time: 4.86e-05, avg batch time: 0.5275, average loss: 45.0434
[11/29 12:44:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.27	
[11/29 12:44:21 visual_prompt]: Training 16 / 100 epoch, with learning rate 24.8100969126526
