/bin/bash: /home/s1952889/miniconda3/envs/prompt/lib/libtinfo.so.6: no version information available (required by /bin/bash)
An exception occurred in telemetry logging.Disabling telemetry to prevent further exceptions.
Traceback (most recent call last):
  File "/home/s1952889/miniconda3/envs/prompt/lib/python3.11/site-packages/iopath/common/file_io.py", line 946, in __log_tmetry_keys
    handler.log_event()
  File "/home/s1952889/miniconda3/envs/prompt/lib/python3.11/site-packages/iopath/common/event_logger.py", line 97, in log_event
    del self._evt
        ^^^^^^^^^
AttributeError: 'NativePathHandler' object has no attribute '_evt'
Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/13 18:48:35 visual_prompt]: Rank of current process: 0. World size: 1
[11/13 18:48:37 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/13 18:48:37 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/13 18:48:37 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/13 18:48:37 visual_prompt]: Training with config:
[11/13 18:48:37 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr2.5_wd0.0/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 2.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/13 18:48:37 visual_prompt]: Loading training data...
[11/13 18:48:37 visual_prompt]: Constructing mammo-cbis dataset train...
[11/13 18:48:38 visual_prompt]: Loading validation data...
[11/13 18:48:38 visual_prompt]: Constructing mammo-cbis dataset val...
[11/13 18:48:38 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[11/13 18:48:44 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[11/13 18:48:44 visual_prompt]: tuned percent:0.536
[11/13 18:48:45 visual_prompt]: Device used for model: 0
[11/13 18:48:45 visual_prompt]: Setting up Evaluator...
[11/13 18:48:45 visual_prompt]: Setting up Trainer...
[11/13 18:48:45 visual_prompt]: 	Setting up the optimizer...
[11/13 18:48:45 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/13 18:55:14 visual_prompt]: Epoch 1 / 100: avg data time: 1.07e+01, avg batch time: 11.1343, average train loss: 1.4017
[11/13 18:55:57 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1538, average loss: 1.2969
[11/13 18:55:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[11/13 18:55:57 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.25
[11/13 19:02:10 visual_prompt]: Epoch 2 / 100: avg data time: 1.03e+01, avg batch time: 10.6634, average train loss: 3.6468
[11/13 19:02:53 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1537, average loss: 0.6812
[11/13 19:02:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 56.78	
[11/13 19:02:53 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.5
[11/13 19:09:06 visual_prompt]: Epoch 3 / 100: avg data time: 1.03e+01, avg batch time: 10.6611, average train loss: 0.7277
[11/13 19:09:48 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1538, average loss: 0.6949
[11/13 19:09:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 48.78	rocauc: 59.53	
[11/13 19:09:48 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.75
[11/13 19:16:02 visual_prompt]: Epoch 4 / 100: avg data time: 1.03e+01, avg batch time: 10.6788, average train loss: 0.9364
[11/13 19:16:44 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1568, average loss: 0.6894
[11/13 19:16:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.26	
[11/13 19:16:44 visual_prompt]: Training 5 / 100 epoch, with learning rate 1.0
[11/13 19:22:57 visual_prompt]: Epoch 5 / 100: avg data time: 1.03e+01, avg batch time: 10.6505, average train loss: 1.1632
[11/13 19:23:40 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1539, average loss: 0.7970
[11/13 19:23:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.89	
[11/13 19:23:40 visual_prompt]: Training 6 / 100 epoch, with learning rate 1.25
[11/13 19:29:53 visual_prompt]: Epoch 6 / 100: avg data time: 1.03e+01, avg batch time: 10.6804, average train loss: 1.6444
[11/13 19:30:36 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1539, average loss: 1.4777
[11/13 19:30:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.03	
[11/13 19:30:36 visual_prompt]: Training 7 / 100 epoch, with learning rate 1.5
[11/13 19:36:49 visual_prompt]: Epoch 7 / 100: avg data time: 1.03e+01, avg batch time: 10.6717, average train loss: 2.5634
[11/13 19:37:32 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1544, average loss: 1.7295
[11/13 19:37:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.24	
[11/13 19:37:32 visual_prompt]: Training 8 / 100 epoch, with learning rate 1.75
[11/13 19:43:44 visual_prompt]: Epoch 8 / 100: avg data time: 1.03e+01, avg batch time: 10.6465, average train loss: 1.3294
[11/13 19:44:27 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1538, average loss: 1.5858
[11/13 19:44:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.43	
[11/13 19:44:27 visual_prompt]: Training 9 / 100 epoch, with learning rate 2.0
[11/13 19:50:42 visual_prompt]: Epoch 9 / 100: avg data time: 1.04e+01, avg batch time: 10.7068, average train loss: 1.0449
[11/13 19:51:24 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1540, average loss: 1.5837
[11/13 19:51:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.59	
[11/13 19:51:24 visual_prompt]: Training 10 / 100 epoch, with learning rate 2.25
[11/13 19:57:52 visual_prompt]: Epoch 10 / 100: avg data time: 1.07e+01, avg batch time: 11.0830, average train loss: 0.9955
[11/13 19:58:39 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1559, average loss: 1.4498
[11/13 19:58:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.75	
[11/13 19:58:39 visual_prompt]: Training 11 / 100 epoch, with learning rate 2.5
[11/13 20:05:19 visual_prompt]: Epoch 11 / 100: avg data time: 1.11e+01, avg batch time: 11.4105, average train loss: 2.7400
[11/13 20:06:05 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1543, average loss: 0.6725
[11/13 20:06:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 60.86	
[11/13 20:06:05 visual_prompt]: Training 12 / 100 epoch, with learning rate 2.4992385337738696
[11/13 20:12:54 visual_prompt]: Epoch 12 / 100: avg data time: 1.13e+01, avg batch time: 11.6750, average train loss: 1.7798
[11/13 20:13:41 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1546, average loss: 1.5732
[11/13 20:13:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.55	
[11/13 20:13:41 visual_prompt]: Training 13 / 100 epoch, with learning rate 2.4969550628247803
[11/13 20:20:30 visual_prompt]: Epoch 13 / 100: avg data time: 1.13e+01, avg batch time: 11.6917, average train loss: 3.1057
[11/13 20:21:16 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1545, average loss: 2.8106
[11/13 20:21:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.71	
[11/13 20:21:16 visual_prompt]: Training 14 / 100 epoch, with learning rate 2.4931523692103417
[11/13 20:27:56 visual_prompt]: Epoch 14 / 100: avg data time: 1.11e+01, avg batch time: 11.4150, average train loss: 1.8764
[11/13 20:28:39 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1573, average loss: 1.8100
[11/13 20:28:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.51	
[11/13 20:28:39 visual_prompt]: Training 15 / 100 epoch, with learning rate 2.487835085926963
[11/13 20:34:52 visual_prompt]: Epoch 15 / 100: avg data time: 1.03e+01, avg batch time: 10.6519, average train loss: 1.4916
[11/13 20:35:34 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1542, average loss: 0.6773
[11/13 20:35:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 61.61	
[11/13 20:35:34 visual_prompt]: Training 16 / 100 epoch, with learning rate 2.4810096912652604
[11/13 20:41:47 visual_prompt]: Epoch 16 / 100: avg data time: 1.03e+01, avg batch time: 10.6616, average train loss: 0.9782
[11/13 20:42:30 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1540, average loss: 0.7296
[11/13 20:42:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.93	
[11/13 20:42:30 visual_prompt]: Training 17 / 100 epoch, with learning rate 2.472684500917257
[11/13 20:48:46 visual_prompt]: Epoch 17 / 100: avg data time: 1.04e+01, avg batch time: 10.7540, average train loss: 2.6419
[11/13 20:49:29 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1545, average loss: 3.1785
[11/13 20:49:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 64.29	
[11/13 20:49:29 visual_prompt]: Training 18 / 100 epoch, with learning rate 2.4628696578449953
[11/13 20:55:47 visual_prompt]: Epoch 18 / 100: avg data time: 1.04e+01, avg batch time: 10.7986, average train loss: 2.1624
[11/13 20:56:30 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1541, average loss: 2.9060
[11/13 20:56:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.04	
[11/13 20:56:30 visual_prompt]: Training 19 / 100 epoch, with learning rate 2.4515771199228986
[11/13 21:02:47 visual_prompt]: Epoch 19 / 100: avg data time: 1.04e+01, avg batch time: 10.7729, average train loss: 0.9419
[11/13 21:03:30 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1543, average loss: 0.8211
[11/13 21:03:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 63.41	
[11/13 21:03:30 visual_prompt]: Training 20 / 100 epoch, with learning rate 2.438820645368942
[11/13 21:09:47 visual_prompt]: Epoch 20 / 100: avg data time: 1.04e+01, avg batch time: 10.7807, average train loss: 0.8630
[11/13 21:10:30 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1543, average loss: 0.6662
[11/13 21:10:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 65.07	
[11/13 21:10:30 visual_prompt]: Best epoch 20: best metric: -0.666
[11/13 21:10:30 visual_prompt]: Training 21 / 100 epoch, with learning rate 2.4246157759823856
[11/13 21:16:46 visual_prompt]: Epoch 21 / 100: avg data time: 1.04e+01, avg batch time: 10.7393, average train loss: 0.8961
[11/13 21:17:28 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1557, average loss: 1.0804
[11/13 21:17:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 67.77	
[11/13 21:17:28 visual_prompt]: Training 22 / 100 epoch, with learning rate 2.4089798182084845
[11/13 21:23:46 visual_prompt]: Epoch 22 / 100: avg data time: 1.04e+01, avg batch time: 10.7727, average train loss: 0.8104
[11/13 21:24:28 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1566, average loss: 0.6743
[11/13 21:24:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 65.22	
[11/13 21:24:28 visual_prompt]: Training 23 / 100 epoch, with learning rate 2.391931822053251
[11/13 21:30:46 visual_prompt]: Epoch 23 / 100: avg data time: 1.04e+01, avg batch time: 10.7856, average train loss: 0.7085
[11/13 21:31:29 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1568, average loss: 0.6581
[11/13 21:31:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 65.25	
[11/13 21:31:29 visual_prompt]: Best epoch 23: best metric: -0.658
[11/13 21:31:29 visual_prompt]: Training 24 / 100 epoch, with learning rate 2.3734925578739587
[11/13 21:37:46 visual_prompt]: Epoch 24 / 100: avg data time: 1.04e+01, avg batch time: 10.7833, average train loss: 0.8079
[11/13 21:38:29 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1542, average loss: 0.8420
[11/13 21:38:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 67.83	
[11/13 21:38:29 visual_prompt]: Training 25 / 100 epoch, with learning rate 2.3536844910736585
[11/13 21:44:46 visual_prompt]: Epoch 25 / 100: avg data time: 1.04e+01, avg batch time: 10.7763, average train loss: 0.7110
[11/13 21:45:29 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1542, average loss: 0.8505
[11/13 21:45:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 47.56	rocauc: 67.69	
[11/13 21:45:29 visual_prompt]: Training 26 / 100 epoch, with learning rate 2.3325317547305486
[11/13 21:51:46 visual_prompt]: Epoch 26 / 100: avg data time: 1.04e+01, avg batch time: 10.7700, average train loss: 0.8778
[11/13 21:52:29 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1540, average loss: 1.1769
[11/13 21:52:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 68.04	
[11/13 21:52:29 visual_prompt]: Training 27 / 100 epoch, with learning rate 2.310060120195532
[11/13 21:58:47 visual_prompt]: Epoch 27 / 100: avg data time: 1.04e+01, avg batch time: 10.7807, average train loss: 0.7844
[11/13 21:59:29 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1561, average loss: 0.9773
[11/13 21:59:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 67.95	
[11/13 21:59:29 visual_prompt]: Training 28 / 100 epoch, with learning rate 2.286296965693802
[11/13 22:05:47 visual_prompt]: Epoch 28 / 100: avg data time: 1.04e+01, avg batch time: 10.7756, average train loss: 0.7772
[11/13 22:06:29 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1583, average loss: 1.0207
[11/13 22:06:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 67.99	
[11/13 22:06:29 visual_prompt]: Training 29 / 100 epoch, with learning rate 2.261271242968684
[11/13 22:12:47 visual_prompt]: Epoch 29 / 100: avg data time: 1.04e+01, avg batch time: 10.7879, average train loss: 0.8490
[11/13 22:13:30 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1562, average loss: 0.7324
[11/13 22:13:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 68.43	
[11/13 22:13:30 visual_prompt]: Training 30 / 100 epoch, with learning rate 2.2350134420084022
[11/13 22:19:47 visual_prompt]: Epoch 30 / 100: avg data time: 1.04e+01, avg batch time: 10.7818, average train loss: 0.7285
[11/13 22:20:30 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1541, average loss: 0.6607
[11/13 22:20:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 67.56	
[11/13 22:20:30 visual_prompt]: Training 31 / 100 epoch, with learning rate 2.2075555538987226
[11/13 22:26:47 visual_prompt]: Epoch 31 / 100: avg data time: 1.04e+01, avg batch time: 10.7684, average train loss: 0.6971
[11/13 22:27:30 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1541, average loss: 0.8402
[11/13 22:27:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 68.14	
[11/13 22:27:30 visual_prompt]: Training 32 / 100 epoch, with learning rate 2.178931031846743
[11/13 22:33:48 visual_prompt]: Epoch 32 / 100: avg data time: 1.04e+01, avg batch time: 10.7940, average train loss: 0.7193
[11/13 22:34:31 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1554, average loss: 0.7239
[11/13 22:34:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 68.56	
[11/13 22:34:31 visual_prompt]: Training 33 / 100 epoch, with learning rate 2.149174750423314
[11/13 22:40:48 visual_prompt]: Epoch 33 / 100: avg data time: 1.04e+01, avg batch time: 10.7854, average train loss: 0.7723
[11/13 22:41:31 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1545, average loss: 0.6594
[11/13 22:41:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 68.62	
[11/13 22:41:31 visual_prompt]: Training 34 / 100 epoch, with learning rate 2.1183229630737466
[11/13 22:47:48 visual_prompt]: Epoch 34 / 100: avg data time: 1.04e+01, avg batch time: 10.7625, average train loss: 0.7258
[11/13 22:48:31 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1541, average loss: 0.6461
[11/13 22:48:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 67.85	
[11/13 22:48:31 visual_prompt]: Best epoch 34: best metric: -0.646
[11/13 22:48:31 visual_prompt]: Training 35 / 100 epoch, with learning rate 2.086413257948573
[11/13 22:54:47 visual_prompt]: Epoch 35 / 100: avg data time: 1.04e+01, avg batch time: 10.7638, average train loss: 0.6361
[11/13 22:55:30 visual_prompt]: Inference (val):avg data time: 4.49e-05, avg batch time: 0.1553, average loss: 0.6906
[11/13 22:55:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.54	rocauc: 67.63	
[11/13 22:55:30 visual_prompt]: Training 36 / 100 epoch, with learning rate 2.053484512108174
[11/13 23:01:48 visual_prompt]: Epoch 36 / 100: avg data time: 1.04e+01, avg batch time: 10.7753, average train loss: 0.7138
[11/13 23:02:30 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1540, average loss: 0.6873
[11/13 23:02:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 67.64	
[11/13 23:02:30 visual_prompt]: Training 37 / 100 epoch, with learning rate 2.019576844157073
[11/13 23:08:47 visual_prompt]: Epoch 37 / 100: avg data time: 1.04e+01, avg batch time: 10.7630, average train loss: 0.6374
[11/13 23:09:30 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1541, average loss: 0.6362
[11/13 23:09:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 71.18	
[11/13 23:09:30 visual_prompt]: Best epoch 37: best metric: -0.636
[11/13 23:09:30 visual_prompt]: Training 38 / 100 epoch, with learning rate 1.9847315653655915
[11/13 23:15:47 visual_prompt]: Epoch 38 / 100: avg data time: 1.04e+01, avg batch time: 10.7816, average train loss: 0.7790
[11/13 23:16:30 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1560, average loss: 0.8786
[11/13 23:16:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.47	rocauc: 69.30	
[11/13 23:16:30 visual_prompt]: Training 39 / 100 epoch, with learning rate 1.9489911293384334
[11/13 23:22:46 visual_prompt]: Epoch 39 / 100: avg data time: 1.04e+01, avg batch time: 10.7380, average train loss: 0.7525
[11/13 23:23:28 visual_prompt]: Inference (val):avg data time: 3.68e-05, avg batch time: 0.1573, average loss: 0.7565
[11/13 23:23:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 68.93	
[11/13 23:23:28 visual_prompt]: Training 40 / 100 epoch, with learning rate 1.912399080291506
[11/13 23:29:42 visual_prompt]: Epoch 40 / 100: avg data time: 1.03e+01, avg batch time: 10.6730, average train loss: 0.6242
[11/13 23:30:25 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1582, average loss: 0.6305
[11/13 23:30:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 72.28	
[11/13 23:30:25 visual_prompt]: Best epoch 40: best metric: -0.630
[11/13 23:30:25 visual_prompt]: Training 41 / 100 epoch, with learning rate 1.875
[11/13 23:36:42 visual_prompt]: Epoch 41 / 100: avg data time: 1.04e+01, avg batch time: 10.7682, average train loss: 0.6404
[11/13 23:37:25 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1553, average loss: 0.9358
[11/13 23:37:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.47	rocauc: 69.39	
[11/13 23:37:25 visual_prompt]: Training 42 / 100 epoch, with learning rate 1.8368394534823635
[11/13 23:43:42 visual_prompt]: Epoch 42 / 100: avg data time: 1.04e+01, avg batch time: 10.7850, average train loss: 0.6842
[11/13 23:44:25 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1573, average loss: 0.6362
[11/13 23:44:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 70.26	
[11/13 23:44:25 visual_prompt]: Training 43 / 100 epoch, with learning rate 1.7979639334863466
[11/13 23:50:41 visual_prompt]: Epoch 43 / 100: avg data time: 1.04e+01, avg batch time: 10.7559, average train loss: 0.6795
[11/13 23:51:24 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1541, average loss: 0.6904
[11/13 23:51:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 69.62	
[11/13 23:51:24 visual_prompt]: Training 44 / 100 epoch, with learning rate 1.7584208038447504
[11/13 23:57:39 visual_prompt]: Epoch 44 / 100: avg data time: 1.04e+01, avg batch time: 10.7223, average train loss: 0.6264
[11/13 23:58:22 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1549, average loss: 0.7529
[11/13 23:58:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 68.95	
[11/13 23:58:22 visual_prompt]: Training 45 / 100 epoch, with learning rate 1.7182582417698902
[11/14 00:04:38 visual_prompt]: Epoch 45 / 100: avg data time: 1.04e+01, avg batch time: 10.7224, average train loss: 0.7099
[11/14 00:05:20 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1567, average loss: 0.7904
[11/14 00:05:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.54	rocauc: 71.21	
[11/14 00:05:20 visual_prompt]: Training 46 / 100 epoch, with learning rate 1.6775251791570862
[11/14 00:11:36 visual_prompt]: Epoch 46 / 100: avg data time: 1.04e+01, avg batch time: 10.7527, average train loss: 0.7437
[11/14 00:12:19 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1542, average loss: 0.7652
[11/14 00:12:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 68.93	
[11/14 00:12:19 visual_prompt]: Training 47 / 100 epoch, with learning rate 1.6362712429686843
[11/14 00:18:36 visual_prompt]: Epoch 47 / 100: avg data time: 1.04e+01, avg batch time: 10.7646, average train loss: 0.6902
[11/14 00:19:19 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1558, average loss: 0.6896
[11/14 00:19:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.54	rocauc: 71.59	
[11/14 00:19:19 visual_prompt]: Training 48 / 100 epoch, with learning rate 1.5945466947712488
[11/14 00:25:36 visual_prompt]: Epoch 48 / 100: avg data time: 1.04e+01, avg batch time: 10.7675, average train loss: 0.6369
[11/14 00:26:19 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1548, average loss: 0.6545
[11/14 00:26:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 70.86	
[11/14 00:26:19 visual_prompt]: Training 49 / 100 epoch, with learning rate 1.5524023694995845
[11/14 00:32:36 visual_prompt]: Epoch 49 / 100: avg data time: 1.04e+01, avg batch time: 10.7780, average train loss: 0.5890
[11/14 00:33:19 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1559, average loss: 0.6912
[11/14 00:33:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 70.31	
[11/14 00:33:19 visual_prompt]: Training 50 / 100 epoch, with learning rate 1.509889613522199
[11/14 00:39:36 visual_prompt]: Epoch 50 / 100: avg data time: 1.04e+01, avg batch time: 10.7647, average train loss: 0.7762
[11/14 00:40:19 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1546, average loss: 1.1414
[11/14 00:40:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 71.38	
[11/14 00:40:19 visual_prompt]: Training 51 / 100 epoch, with learning rate 1.467060222083663
[11/14 00:46:36 visual_prompt]: Epoch 51 / 100: avg data time: 1.04e+01, avg batch time: 10.7738, average train loss: 0.6500
[11/14 00:47:19 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1546, average loss: 0.6584
[11/14 00:47:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 70.82	
[11/14 00:47:19 visual_prompt]: Training 52 / 100 epoch, with learning rate 1.4239663762000818
[11/14 00:53:36 visual_prompt]: Epoch 52 / 100: avg data time: 1.04e+01, avg batch time: 10.7696, average train loss: 0.5731
[11/14 00:54:18 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1546, average loss: 0.6643
[11/14 00:54:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 71.75	
[11/14 00:54:18 visual_prompt]: Training 53 / 100 epoch, with learning rate 1.380660579084567
[11/14 01:00:36 visual_prompt]: Epoch 53 / 100: avg data time: 1.04e+01, avg batch time: 10.7839, average train loss: 0.6001
[11/14 01:01:19 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1554, average loss: 0.6949
[11/14 01:01:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 71.73	
[11/14 01:01:19 visual_prompt]: Training 54 / 100 epoch, with learning rate 1.3371955921801564
[11/14 01:07:33 visual_prompt]: Epoch 54 / 100: avg data time: 1.03e+01, avg batch time: 10.6957, average train loss: 0.5802
[11/14 01:08:15 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1541, average loss: 0.6884
[11/14 01:08:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 72.43	
[11/14 01:08:15 visual_prompt]: Training 55 / 100 epoch, with learning rate 1.2936243708781263
[11/14 01:14:29 visual_prompt]: Epoch 55 / 100: avg data time: 1.03e+01, avg batch time: 10.6648, average train loss: 0.6285
[11/14 01:15:11 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1542, average loss: 0.6837
[11/14 01:15:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 73.25	
[11/14 01:15:11 visual_prompt]: Training 56 / 100 epoch, with learning rate 1.25
[11/14 01:21:28 visual_prompt]: Epoch 56 / 100: avg data time: 1.04e+01, avg batch time: 10.7570, average train loss: 0.5768
[11/14 01:22:11 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.1543, average loss: 0.7735
[11/14 01:22:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 70.63	
[11/14 01:22:11 visual_prompt]: Training 57 / 100 epoch, with learning rate 1.2063756291218741
[11/14 01:28:27 visual_prompt]: Epoch 57 / 100: avg data time: 1.04e+01, avg batch time: 10.7535, average train loss: 0.5705
[11/14 01:29:10 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1543, average loss: 0.7076
[11/14 01:29:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 70.64	
[11/14 01:29:10 visual_prompt]: Training 58 / 100 epoch, with learning rate 1.1628044078198434
[11/14 01:35:25 visual_prompt]: Epoch 58 / 100: avg data time: 1.04e+01, avg batch time: 10.7184, average train loss: 0.5493
[11/14 01:36:07 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1541, average loss: 0.6549
[11/14 01:36:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 69.88	
[11/14 01:36:08 visual_prompt]: Training 59 / 100 epoch, with learning rate 1.1193394209154333
[11/14 01:42:20 visual_prompt]: Epoch 59 / 100: avg data time: 1.03e+01, avg batch time: 10.6472, average train loss: 0.5612
[11/14 01:43:03 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1546, average loss: 0.6639
[11/14 01:43:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 72.95	
[11/14 01:43:03 visual_prompt]: Training 60 / 100 epoch, with learning rate 1.0760336237999186
[11/14 01:49:18 visual_prompt]: Epoch 60 / 100: avg data time: 1.04e+01, avg batch time: 10.7283, average train loss: 0.5395
[11/14 01:50:01 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1571, average loss: 0.6354
[11/14 01:50:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 70.07	
[11/14 01:50:01 visual_prompt]: Training 61 / 100 epoch, with learning rate 1.0329397779163372
[11/14 01:56:18 visual_prompt]: Epoch 61 / 100: avg data time: 1.04e+01, avg batch time: 10.7567, average train loss: 0.5650
[11/14 01:57:00 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1542, average loss: 0.6564
[11/14 01:57:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 70.61	
[11/14 01:57:00 visual_prompt]: Stopping early.
[11/14 01:57:00 visual_prompt]: Rank of current process: 0. World size: 1
[11/14 01:57:00 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/14 01:57:00 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/14 01:57:00 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/14 01:57:00 visual_prompt]: Training with config:
[11/14 01:57:00 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr1.0_wd0.01/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 1.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/14 01:57:00 visual_prompt]: Loading training data...
[11/14 01:57:00 visual_prompt]: Constructing mammo-cbis dataset train...
[11/14 01:57:00 visual_prompt]: Loading validation data...
[11/14 01:57:00 visual_prompt]: Constructing mammo-cbis dataset val...
[11/14 01:57:00 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[11/14 01:57:03 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[11/14 01:57:03 visual_prompt]: tuned percent:0.536
[11/14 01:57:03 visual_prompt]: Device used for model: 0
[11/14 01:57:03 visual_prompt]: Setting up Evaluator...
[11/14 01:57:03 visual_prompt]: Setting up Trainer...
[11/14 01:57:03 visual_prompt]: 	Setting up the optimizer...
[11/14 01:57:03 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/14 02:03:21 visual_prompt]: Epoch 1 / 100: avg data time: 1.04e+01, avg batch time: 10.7989, average train loss: 1.4017
[11/14 02:04:04 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1541, average loss: 1.2969
[11/14 02:04:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[11/14 02:04:04 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.1
[11/14 02:10:22 visual_prompt]: Epoch 2 / 100: avg data time: 1.04e+01, avg batch time: 10.7856, average train loss: 2.3252
[11/14 02:11:05 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1540, average loss: 0.6886
[11/14 02:11:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.47	rocauc: 51.43	
[11/14 02:11:05 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.2
[11/14 02:17:22 visual_prompt]: Epoch 3 / 100: avg data time: 1.04e+01, avg batch time: 10.7825, average train loss: 0.7411
[11/14 02:18:05 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1575, average loss: 0.6876
[11/14 02:18:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.54	
[11/14 02:18:05 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.3
[11/14 02:24:23 visual_prompt]: Epoch 4 / 100: avg data time: 1.04e+01, avg batch time: 10.8020, average train loss: 0.7144
[11/14 02:25:06 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1541, average loss: 0.7505
[11/14 02:25:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.94	
[11/14 02:25:06 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.4
[11/14 02:31:24 visual_prompt]: Epoch 5 / 100: avg data time: 1.04e+01, avg batch time: 10.7798, average train loss: 0.7138
[11/14 02:32:06 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1544, average loss: 0.6898
[11/14 02:32:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.08	
[11/14 02:32:06 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.5
[11/14 02:38:20 visual_prompt]: Epoch 6 / 100: avg data time: 1.03e+01, avg batch time: 10.6807, average train loss: 0.7073
[11/14 02:39:03 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1540, average loss: 0.7206
[11/14 02:39:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.18	
[11/14 02:39:03 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.6
[11/14 02:45:19 visual_prompt]: Epoch 7 / 100: avg data time: 1.04e+01, avg batch time: 10.7460, average train loss: 0.7291
[11/14 02:46:02 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1563, average loss: 1.0410
[11/14 02:46:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.60	
[11/14 02:46:02 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.7
[11/14 02:52:19 visual_prompt]: Epoch 8 / 100: avg data time: 1.04e+01, avg batch time: 10.7812, average train loss: 0.7992
[11/14 02:53:02 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1542, average loss: 0.7395
[11/14 02:53:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.76	
[11/14 02:53:02 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.8
[11/14 02:59:21 visual_prompt]: Epoch 9 / 100: avg data time: 1.05e+01, avg batch time: 10.8196, average train loss: 0.8031
[11/14 03:00:04 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1537, average loss: 0.6885
[11/14 03:00:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.07	
[11/14 03:00:04 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.9
[11/14 03:06:21 visual_prompt]: Epoch 10 / 100: avg data time: 1.04e+01, avg batch time: 10.7685, average train loss: 0.7939
[11/14 03:07:04 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1543, average loss: 1.0083
[11/14 03:07:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.16	
[11/14 03:07:04 visual_prompt]: Training 11 / 100 epoch, with learning rate 1.0
[11/14 03:13:21 visual_prompt]: Epoch 11 / 100: avg data time: 1.04e+01, avg batch time: 10.7663, average train loss: 0.8696
[11/14 03:14:04 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1541, average loss: 0.7229
[11/14 03:14:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.56	
[11/14 03:14:04 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.9996954135095479
[11/14 03:20:20 visual_prompt]: Epoch 12 / 100: avg data time: 1.04e+01, avg batch time: 10.7658, average train loss: 0.7553
[11/14 03:21:03 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1554, average loss: 1.1101
[11/14 03:21:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.71	
[11/14 03:21:03 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.9987820251299121
[11/14 03:27:16 visual_prompt]: Epoch 13 / 100: avg data time: 1.03e+01, avg batch time: 10.6538, average train loss: 1.3041
[11/14 03:27:59 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1545, average loss: 0.8014
[11/14 03:27:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.66	
[11/14 03:27:59 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.9972609476841366
[11/14 03:34:12 visual_prompt]: Epoch 14 / 100: avg data time: 1.03e+01, avg batch time: 10.6587, average train loss: 0.8819
[11/14 03:34:55 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1542, average loss: 3.4008
[11/14 03:34:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.93	
[11/14 03:34:55 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.9951340343707852
[11/14 03:41:09 visual_prompt]: Epoch 15 / 100: avg data time: 1.03e+01, avg batch time: 10.6919, average train loss: 1.0585
[11/14 03:41:52 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1539, average loss: 0.7373
[11/14 03:41:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.04	
[11/14 03:41:52 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.9924038765061041
[11/14 03:48:05 visual_prompt]: Epoch 16 / 100: avg data time: 1.03e+01, avg batch time: 10.6667, average train loss: 1.1577
[11/14 03:48:48 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1566, average loss: 0.9042
[11/14 03:48:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.19	
[11/14 03:48:48 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.9890738003669028
[11/14 03:55:03 visual_prompt]: Epoch 17 / 100: avg data time: 1.04e+01, avg batch time: 10.7300, average train loss: 1.8154
[11/14 03:55:46 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1540, average loss: 0.9966
[11/14 03:55:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.62	
[11/14 03:55:46 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.9851478631379982
[11/14 04:02:02 visual_prompt]: Epoch 18 / 100: avg data time: 1.04e+01, avg batch time: 10.7207, average train loss: 1.0424
[11/14 04:02:44 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1541, average loss: 0.8716
[11/14 04:02:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.05	
[11/14 04:02:44 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.9806308479691594
[11/14 04:09:02 visual_prompt]: Epoch 19 / 100: avg data time: 1.04e+01, avg batch time: 10.7811, average train loss: 1.5314
[11/14 04:09:45 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1542, average loss: 0.8393
[11/14 04:09:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.02	
[11/14 04:09:45 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.9755282581475768
[11/14 04:16:03 visual_prompt]: Epoch 20 / 100: avg data time: 1.04e+01, avg batch time: 10.7961, average train loss: 1.0486
[11/14 04:16:46 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1543, average loss: 0.8317
[11/14 04:16:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.66	
[11/14 04:16:46 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.9698463103929542
[11/14 04:23:03 visual_prompt]: Epoch 21 / 100: avg data time: 1.04e+01, avg batch time: 10.7813, average train loss: 0.9939
[11/14 04:23:46 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1544, average loss: 0.6884
[11/14 04:23:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.61	
[11/14 04:23:46 visual_prompt]: Best epoch 21: best metric: -0.688
[11/14 04:23:46 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.9635919272833937
[11/14 04:30:04 visual_prompt]: Epoch 22 / 100: avg data time: 1.04e+01, avg batch time: 10.7827, average train loss: 0.9601
[11/14 04:30:46 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1542, average loss: 0.6919
[11/14 04:30:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 44.91	
[11/14 04:30:46 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.9567727288213004
[11/14 04:37:04 visual_prompt]: Epoch 23 / 100: avg data time: 1.04e+01, avg batch time: 10.7724, average train loss: 0.8454
[11/14 04:37:46 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1545, average loss: 0.8342
[11/14 04:37:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 40.58	
[11/14 04:37:47 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.9493970231495835
[11/14 04:44:04 visual_prompt]: Epoch 24 / 100: avg data time: 1.04e+01, avg batch time: 10.7855, average train loss: 0.8642
[11/14 04:44:47 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1541, average loss: 0.9819
[11/14 04:44:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.92	
[11/14 04:44:47 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.9414737964294635
[11/14 04:51:03 visual_prompt]: Epoch 25 / 100: avg data time: 1.04e+01, avg batch time: 10.7294, average train loss: 0.8508
[11/14 04:51:45 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1565, average loss: 0.9971
[11/14 04:51:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.66	
[11/14 04:51:45 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.9330127018922194
[11/14 04:57:59 visual_prompt]: Epoch 26 / 100: avg data time: 1.03e+01, avg batch time: 10.6654, average train loss: 0.9577
[11/14 04:58:41 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1542, average loss: 1.6606
[11/14 04:58:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 44.49	
[11/14 04:58:41 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.9240240480782129
[11/14 05:04:54 visual_prompt]: Epoch 27 / 100: avg data time: 1.03e+01, avg batch time: 10.6519, average train loss: 0.9529
[11/14 05:05:37 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1539, average loss: 0.9675
[11/14 05:05:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.47	
[11/14 05:05:37 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.9145187862775208
[11/14 05:11:50 visual_prompt]: Epoch 28 / 100: avg data time: 1.03e+01, avg batch time: 10.6611, average train loss: 0.9223
[11/14 05:12:32 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1576, average loss: 0.6977
[11/14 05:12:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.47	
[11/14 05:12:32 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.9045084971874737
[11/14 05:18:47 visual_prompt]: Epoch 29 / 100: avg data time: 1.04e+01, avg batch time: 10.7100, average train loss: 0.9115
[11/14 05:19:30 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1540, average loss: 0.7078
[11/14 05:19:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 44.24	
[11/14 05:19:30 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.8940053768033609
[11/14 05:25:43 visual_prompt]: Epoch 30 / 100: avg data time: 1.03e+01, avg batch time: 10.6572, average train loss: 0.7795
[11/14 05:26:26 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1539, average loss: 0.6884
[11/14 05:26:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.24	
[11/14 05:26:26 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.883022221559489
[11/14 05:32:42 visual_prompt]: Epoch 31 / 100: avg data time: 1.04e+01, avg batch time: 10.7528, average train loss: 1.0520
[11/14 05:33:25 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1539, average loss: 0.6895
[11/14 05:33:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 52.16	
[11/14 05:33:25 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.8715724127386971
[11/14 05:39:40 visual_prompt]: Epoch 32 / 100: avg data time: 1.04e+01, avg batch time: 10.7249, average train loss: 0.8002
[11/14 05:40:23 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1553, average loss: 0.7751
[11/14 05:40:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 42.68	rocauc: 50.24	
[11/14 05:40:23 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.8596699001693255
[11/14 05:46:40 visual_prompt]: Epoch 33 / 100: avg data time: 1.04e+01, avg batch time: 10.7623, average train loss: 0.7942
[11/14 05:47:23 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1552, average loss: 0.6897
[11/14 05:47:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.79	
[11/14 05:47:23 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.8473291852294986
[11/14 05:53:39 visual_prompt]: Epoch 34 / 100: avg data time: 1.04e+01, avg batch time: 10.7592, average train loss: 1.1053
[11/14 05:54:22 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1545, average loss: 0.7024
[11/14 05:54:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.43	
[11/14 05:54:22 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.8345653031794291
[11/14 06:00:40 visual_prompt]: Epoch 35 / 100: avg data time: 1.04e+01, avg batch time: 10.7944, average train loss: 0.8295
[11/14 06:01:23 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1541, average loss: 0.7010
[11/14 06:01:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.93	
[11/14 06:01:23 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.8213938048432696
[11/14 06:07:40 visual_prompt]: Epoch 36 / 100: avg data time: 1.04e+01, avg batch time: 10.7703, average train loss: 1.1439
[11/14 06:08:23 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1538, average loss: 0.6933
[11/14 06:08:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.32	
[11/14 06:08:23 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.8078307376628291
[11/14 06:14:40 visual_prompt]: Epoch 37 / 100: avg data time: 1.04e+01, avg batch time: 10.7688, average train loss: 0.7649
[11/14 06:15:23 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1539, average loss: 0.6965
[11/14 06:15:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.66	
[11/14 06:15:23 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.7938926261462366
[11/14 06:21:41 visual_prompt]: Epoch 38 / 100: avg data time: 1.04e+01, avg batch time: 10.7924, average train loss: 0.7542
[11/14 06:22:24 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1539, average loss: 0.8411
[11/14 06:22:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.74	
[11/14 06:22:24 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.7795964517353734
[11/14 06:28:42 visual_prompt]: Epoch 39 / 100: avg data time: 1.04e+01, avg batch time: 10.8035, average train loss: 0.7935
[11/14 06:29:25 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1578, average loss: 0.8180
[11/14 06:29:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.73	
[11/14 06:29:25 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.7649596321166025
[11/14 06:35:43 visual_prompt]: Epoch 40 / 100: avg data time: 1.04e+01, avg batch time: 10.7960, average train loss: 0.7695
[11/14 06:36:26 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1544, average loss: 0.6969
[11/14 06:36:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 43.10	
[11/14 06:36:26 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.75
[11/14 06:42:44 visual_prompt]: Epoch 41 / 100: avg data time: 1.04e+01, avg batch time: 10.7752, average train loss: 0.8443
[11/14 06:43:26 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1575, average loss: 1.0501
[11/14 06:43:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.75	
[11/14 06:43:27 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.7347357813929454
[11/14 06:49:41 visual_prompt]: Epoch 42 / 100: avg data time: 1.04e+01, avg batch time: 10.7087, average train loss: 0.8060
[11/14 06:50:24 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1566, average loss: 0.7146
[11/14 06:50:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.33	
[11/14 06:50:24 visual_prompt]: Stopping early.
[11/14 06:50:24 visual_prompt]: Rank of current process: 0. World size: 1
[11/14 06:50:24 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/14 06:50:24 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/14 06:50:24 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/14 06:50:24 visual_prompt]: Training with config:
[11/14 06:50:24 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr1.0_wd0.001/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 1.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/14 06:50:24 visual_prompt]: Loading training data...
[11/14 06:50:24 visual_prompt]: Constructing mammo-cbis dataset train...
[11/14 06:50:24 visual_prompt]: Loading validation data...
[11/14 06:50:24 visual_prompt]: Constructing mammo-cbis dataset val...
[11/14 06:50:24 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[11/14 06:50:27 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[11/14 06:50:27 visual_prompt]: tuned percent:0.536
[11/14 06:50:27 visual_prompt]: Device used for model: 0
[11/14 06:50:27 visual_prompt]: Setting up Evaluator...
[11/14 06:50:27 visual_prompt]: Setting up Trainer...
[11/14 06:50:27 visual_prompt]: 	Setting up the optimizer...
[11/14 06:50:27 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/14 06:56:45 visual_prompt]: Epoch 1 / 100: avg data time: 1.04e+01, avg batch time: 10.7929, average train loss: 1.4017
[11/14 06:57:28 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1546, average loss: 1.2969
[11/14 06:57:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[11/14 06:57:28 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.1
[11/14 07:03:45 visual_prompt]: Epoch 2 / 100: avg data time: 1.04e+01, avg batch time: 10.7741, average train loss: 2.3839
[11/14 07:04:28 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1544, average loss: 0.6869
[11/14 07:04:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.61	
[11/14 07:04:28 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.2
[11/14 07:10:46 visual_prompt]: Epoch 3 / 100: avg data time: 1.04e+01, avg batch time: 10.7869, average train loss: 0.7623
[11/14 07:11:29 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1542, average loss: 0.6867
[11/14 07:11:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 57.20	
[11/14 07:11:29 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.3
[11/14 07:17:47 visual_prompt]: Epoch 4 / 100: avg data time: 1.04e+01, avg batch time: 10.7953, average train loss: 0.7195
[11/14 07:18:30 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1543, average loss: 0.6913
[11/14 07:18:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.58	
[11/14 07:18:30 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.4
[11/14 07:24:47 visual_prompt]: Epoch 5 / 100: avg data time: 1.04e+01, avg batch time: 10.7846, average train loss: 0.7861
[11/14 07:25:30 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1571, average loss: 0.6954
[11/14 07:25:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 49.19	rocauc: 59.88	
[11/14 07:25:30 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.5
[11/14 07:31:49 visual_prompt]: Epoch 6 / 100: avg data time: 1.04e+01, avg batch time: 10.8059, average train loss: 0.7758
[11/14 07:32:32 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1543, average loss: 0.6790
[11/14 07:32:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 58.89	
[11/14 07:32:32 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.6
[11/14 07:38:50 visual_prompt]: Epoch 7 / 100: avg data time: 1.05e+01, avg batch time: 10.8097, average train loss: 0.7122
[11/14 07:39:33 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1544, average loss: 1.4528
[11/14 07:39:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.64	
[11/14 07:39:33 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.7
[11/14 07:45:51 visual_prompt]: Epoch 8 / 100: avg data time: 1.04e+01, avg batch time: 10.7885, average train loss: 0.8635
[11/14 07:46:34 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.1544, average loss: 0.6842
[11/14 07:46:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 58.75	
[11/14 07:46:34 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.8
[11/14 07:52:52 visual_prompt]: Epoch 9 / 100: avg data time: 1.05e+01, avg batch time: 10.8116, average train loss: 0.8505
[11/14 07:53:35 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1545, average loss: 0.7907
[11/14 07:53:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.55	
[11/14 07:53:35 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.9
[11/14 07:59:51 visual_prompt]: Epoch 10 / 100: avg data time: 1.04e+01, avg batch time: 10.7295, average train loss: 0.7273
[11/14 08:00:33 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1541, average loss: 0.7180
[11/14 08:00:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.24	
[11/14 08:00:33 visual_prompt]: Training 11 / 100 epoch, with learning rate 1.0
[11/14 08:06:48 visual_prompt]: Epoch 11 / 100: avg data time: 1.04e+01, avg batch time: 10.7045, average train loss: 0.7782
[11/14 08:07:31 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1545, average loss: 0.8833
[11/14 08:07:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.68	
[11/14 08:07:31 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.9996954135095479
[11/14 08:13:46 visual_prompt]: Epoch 12 / 100: avg data time: 1.04e+01, avg batch time: 10.7224, average train loss: 0.7381
[11/14 08:14:29 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1540, average loss: 0.6908
[11/14 08:14:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.47	rocauc: 57.60	
[11/14 08:14:29 visual_prompt]: Best epoch 12: best metric: -0.691
[11/14 08:14:29 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.9987820251299121
[11/14 08:20:43 visual_prompt]: Epoch 13 / 100: avg data time: 1.03e+01, avg batch time: 10.6786, average train loss: 0.7580
[11/14 08:21:26 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1541, average loss: 0.6869
[11/14 08:21:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.67	
[11/14 08:21:26 visual_prompt]: Best epoch 13: best metric: -0.687
[11/14 08:21:26 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.9972609476841366
[11/14 08:27:39 visual_prompt]: Epoch 14 / 100: avg data time: 1.03e+01, avg batch time: 10.6650, average train loss: 0.7634
[11/14 08:28:22 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1546, average loss: 0.7071
[11/14 08:28:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.69	
[11/14 08:28:22 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.9951340343707852
[11/14 08:34:40 visual_prompt]: Epoch 15 / 100: avg data time: 1.05e+01, avg batch time: 10.8080, average train loss: 0.7538
[11/14 08:35:23 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1543, average loss: 0.6997
[11/14 08:35:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.43	
[11/14 08:35:23 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.9924038765061041
[11/14 08:41:41 visual_prompt]: Epoch 16 / 100: avg data time: 1.04e+01, avg batch time: 10.7792, average train loss: 0.7532
[11/14 08:42:23 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1542, average loss: 1.0249
[11/14 08:42:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.33	
[11/14 08:42:23 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.9890738003669028
[11/14 08:48:37 visual_prompt]: Epoch 17 / 100: avg data time: 1.03e+01, avg batch time: 10.6646, average train loss: 0.7676
[11/14 08:49:19 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1542, average loss: 0.9649
[11/14 08:49:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.19	
[11/14 08:49:19 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.9851478631379982
[11/14 08:55:33 visual_prompt]: Epoch 18 / 100: avg data time: 1.03e+01, avg batch time: 10.6832, average train loss: 0.7477
[11/14 08:56:16 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1541, average loss: 0.8711
[11/14 08:56:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.90	
[11/14 08:56:16 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.9806308479691594
[11/14 09:02:29 visual_prompt]: Epoch 19 / 100: avg data time: 1.03e+01, avg batch time: 10.6648, average train loss: 0.7134
[11/14 09:03:12 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1538, average loss: 0.7062
[11/14 09:03:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.07	
[11/14 09:03:12 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.9755282581475768
[11/14 09:09:26 visual_prompt]: Epoch 20 / 100: avg data time: 1.03e+01, avg batch time: 10.6867, average train loss: 0.6941
[11/14 09:10:09 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1544, average loss: 0.8264
[11/14 09:10:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.28	
[11/14 09:10:09 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.9698463103929542
[11/14 09:16:26 visual_prompt]: Epoch 21 / 100: avg data time: 1.04e+01, avg batch time: 10.7848, average train loss: 0.7186
[11/14 09:17:09 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1538, average loss: 0.7168
[11/14 09:17:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.33	
[11/14 09:17:09 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.9635919272833937
[11/14 09:23:27 visual_prompt]: Epoch 22 / 100: avg data time: 1.04e+01, avg batch time: 10.7899, average train loss: 0.7132
[11/14 09:24:10 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1557, average loss: 0.6985
[11/14 09:24:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.17	
[11/14 09:24:10 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.9567727288213004
[11/14 09:30:28 visual_prompt]: Epoch 23 / 100: avg data time: 1.04e+01, avg batch time: 10.7880, average train loss: 0.7190
[11/14 09:31:11 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1539, average loss: 0.7996
[11/14 09:31:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 45.59	
[11/14 09:31:11 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.9493970231495835
[11/14 09:37:29 visual_prompt]: Epoch 24 / 100: avg data time: 1.04e+01, avg batch time: 10.8050, average train loss: 0.7689
[11/14 09:38:12 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1542, average loss: 0.7190
[11/14 09:38:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.92	
[11/14 09:38:12 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.9414737964294635
[11/14 09:44:30 visual_prompt]: Epoch 25 / 100: avg data time: 1.04e+01, avg batch time: 10.7880, average train loss: 0.7421
[11/14 09:45:13 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1543, average loss: 0.8644
[11/14 09:45:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.95	
[11/14 09:45:13 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.9330127018922194
[11/14 09:51:31 visual_prompt]: Epoch 26 / 100: avg data time: 1.04e+01, avg batch time: 10.7923, average train loss: 0.8509
[11/14 09:52:13 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1545, average loss: 0.7059
[11/14 09:52:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.74	
[11/14 09:52:13 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.9240240480782129
[11/14 09:58:27 visual_prompt]: Epoch 27 / 100: avg data time: 1.03e+01, avg batch time: 10.6789, average train loss: 0.7652
[11/14 09:59:10 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1592, average loss: 0.8495
[11/14 09:59:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.78	
[11/14 09:59:10 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.9145187862775208
[11/14 10:05:23 visual_prompt]: Epoch 28 / 100: avg data time: 1.03e+01, avg batch time: 10.6624, average train loss: 0.7276
[11/14 10:06:05 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1544, average loss: 0.7104
[11/14 10:06:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.36	
[11/14 10:06:05 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.9045084971874737
[11/14 10:12:20 visual_prompt]: Epoch 29 / 100: avg data time: 1.04e+01, avg batch time: 10.7077, average train loss: 0.7087
[11/14 10:13:03 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1540, average loss: 0.6877
[11/14 10:13:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.77	
[11/14 10:13:03 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.8940053768033609
[11/14 10:19:17 visual_prompt]: Epoch 30 / 100: avg data time: 1.03e+01, avg batch time: 10.6753, average train loss: 0.7028
[11/14 10:19:59 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1545, average loss: 0.7007
[11/14 10:19:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.15	
[11/14 10:19:59 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.883022221559489
[11/14 10:26:13 visual_prompt]: Epoch 31 / 100: avg data time: 1.03e+01, avg batch time: 10.6686, average train loss: 0.7064
[11/14 10:26:56 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1571, average loss: 0.7225
[11/14 10:26:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.00	
[11/14 10:26:56 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.8715724127386971
[11/14 10:33:14 visual_prompt]: Epoch 32 / 100: avg data time: 1.05e+01, avg batch time: 10.8038, average train loss: 0.7323
[11/14 10:33:57 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1539, average loss: 0.6889
[11/14 10:33:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.40	
[11/14 10:33:57 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.8596699001693255
[11/14 10:40:15 visual_prompt]: Epoch 33 / 100: avg data time: 1.04e+01, avg batch time: 10.7819, average train loss: 0.6994
[11/14 10:40:58 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1541, average loss: 0.6883
[11/14 10:40:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.60	
[11/14 10:40:58 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.8473291852294986
[11/14 10:47:15 visual_prompt]: Epoch 34 / 100: avg data time: 1.04e+01, avg batch time: 10.7863, average train loss: 0.7048
[11/14 10:47:58 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1544, average loss: 0.6896
[11/14 10:47:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.84	
[11/14 10:47:58 visual_prompt]: Stopping early.
[11/14 10:47:58 visual_prompt]: Rank of current process: 0. World size: 1
[11/14 10:47:58 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/14 10:47:58 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/14 10:47:58 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/14 10:47:58 visual_prompt]: Training with config:
[11/14 10:47:58 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr1.0_wd0.0001/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 1.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/14 10:47:58 visual_prompt]: Loading training data...
[11/14 10:47:58 visual_prompt]: Constructing mammo-cbis dataset train...
[11/14 10:47:58 visual_prompt]: Loading validation data...
[11/14 10:47:58 visual_prompt]: Constructing mammo-cbis dataset val...
[11/14 10:47:58 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[11/14 10:48:01 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[11/14 10:48:01 visual_prompt]: tuned percent:0.536
[11/14 10:48:01 visual_prompt]: Device used for model: 0
[11/14 10:48:01 visual_prompt]: Setting up Evaluator...
[11/14 10:48:01 visual_prompt]: Setting up Trainer...
[11/14 10:48:01 visual_prompt]: 	Setting up the optimizer...
[11/14 10:48:01 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/14 10:54:19 visual_prompt]: Epoch 1 / 100: avg data time: 1.04e+01, avg batch time: 10.7933, average train loss: 1.4017
[11/14 10:55:02 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1567, average loss: 1.2969
[11/14 10:55:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[11/14 10:55:02 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.1
[11/14 11:01:20 visual_prompt]: Epoch 2 / 100: avg data time: 1.04e+01, avg batch time: 10.7933, average train loss: 2.3838
[11/14 11:02:03 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1542, average loss: 0.6868
[11/14 11:02:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.68	
[11/14 11:02:03 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.2
[11/14 11:09:05 visual_prompt]: Epoch 3 / 100: avg data time: 1.17e+01, avg batch time: 12.0647, average train loss: 0.7630
[11/14 11:10:00 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1539, average loss: 0.6921
[11/14 11:10:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 49.19	rocauc: 56.57	
[11/14 11:10:00 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.3
[11/14 11:16:31 visual_prompt]: Epoch 4 / 100: avg data time: 1.08e+01, avg batch time: 11.1702, average train loss: 0.7209
[11/14 11:17:14 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1540, average loss: 0.6886
[11/14 11:17:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.51	
[11/14 11:17:14 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.4
[11/14 11:23:29 visual_prompt]: Epoch 5 / 100: avg data time: 1.04e+01, avg batch time: 10.7252, average train loss: 0.7916
[11/14 11:24:14 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.1546, average loss: 0.7003
[11/14 11:24:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 47.56	rocauc: 57.28	
[11/14 11:24:14 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.5
[11/14 11:30:56 visual_prompt]: Epoch 6 / 100: avg data time: 1.12e+01, avg batch time: 11.5043, average train loss: 0.7844
[11/14 11:31:39 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1537, average loss: 0.6790
[11/14 11:31:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 58.11	
[11/14 11:31:39 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.6
[11/14 11:37:53 visual_prompt]: Epoch 7 / 100: avg data time: 1.03e+01, avg batch time: 10.6940, average train loss: 0.7213
[11/14 11:38:36 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1537, average loss: 1.5615
[11/14 11:38:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.46	
[11/14 11:38:36 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.7
[11/14 11:45:00 visual_prompt]: Epoch 8 / 100: avg data time: 1.06e+01, avg batch time: 10.9755, average train loss: 0.9059
[11/14 11:45:48 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1530, average loss: 0.6771
[11/14 11:45:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 59.84	
[11/14 11:45:48 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.8
[11/14 11:52:51 visual_prompt]: Epoch 9 / 100: avg data time: 1.17e+01, avg batch time: 12.0913, average train loss: 0.9008
[11/14 11:53:35 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1539, average loss: 0.7714
[11/14 11:53:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.90	
[11/14 11:53:35 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.9
[11/14 12:00:09 visual_prompt]: Epoch 10 / 100: avg data time: 1.09e+01, avg batch time: 11.2352, average train loss: 0.8158
[11/14 12:00:52 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1540, average loss: 0.8030
[11/14 12:00:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.84	
[11/14 12:00:52 visual_prompt]: Training 11 / 100 epoch, with learning rate 1.0
[11/14 12:07:24 visual_prompt]: Epoch 11 / 100: avg data time: 1.08e+01, avg batch time: 11.1970, average train loss: 0.7922
[11/14 12:08:07 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1558, average loss: 0.7035
[11/14 12:08:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 63.11	
[11/14 12:08:07 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.9996954135095479
[11/14 12:14:26 visual_prompt]: Epoch 12 / 100: avg data time: 1.05e+01, avg batch time: 10.8182, average train loss: 0.7841
[11/14 12:15:09 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1538, average loss: 1.2673
[11/14 12:15:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 63.03	
[11/14 12:15:09 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.9987820251299121
[11/14 12:21:27 visual_prompt]: Epoch 13 / 100: avg data time: 1.05e+01, avg batch time: 10.8104, average train loss: 0.9815
[11/14 12:22:11 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.1541, average loss: 0.6713
[11/14 12:22:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 61.95	
[11/14 12:22:11 visual_prompt]: Best epoch 13: best metric: -0.671
[11/14 12:22:11 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.9972609476841366
[11/14 12:28:30 visual_prompt]: Epoch 14 / 100: avg data time: 1.05e+01, avg batch time: 10.8345, average train loss: 0.8481
[11/14 12:29:13 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1538, average loss: 1.1224
[11/14 12:29:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 65.18	
[11/14 12:29:13 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.9951340343707852
[11/14 12:35:36 visual_prompt]: Epoch 15 / 100: avg data time: 1.06e+01, avg batch time: 10.9424, average train loss: 0.8763
[11/14 12:36:20 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1557, average loss: 0.7881
[11/14 12:36:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 65.86	
[11/14 12:36:20 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.9924038765061041
[11/14 12:42:35 visual_prompt]: Epoch 16 / 100: avg data time: 1.03e+01, avg batch time: 10.7015, average train loss: 0.8560
[11/14 12:43:17 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.1539, average loss: 0.8235
[11/14 12:43:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 66.43	
[11/14 12:43:17 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.9890738003669028
[11/14 12:49:35 visual_prompt]: Epoch 17 / 100: avg data time: 1.04e+01, avg batch time: 10.7792, average train loss: 0.7877
[11/14 12:50:18 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1542, average loss: 1.2729
[11/14 12:50:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 66.00	
[11/14 12:50:18 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.9851478631379982
[11/14 12:56:33 visual_prompt]: Epoch 18 / 100: avg data time: 1.04e+01, avg batch time: 10.7078, average train loss: 0.8015
[11/14 12:57:16 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.1545, average loss: 0.6836
[11/14 12:57:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 68.99	
[11/14 12:57:16 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.9806308479691594
[11/14 13:03:34 visual_prompt]: Epoch 19 / 100: avg data time: 1.04e+01, avg batch time: 10.7895, average train loss: 0.7269
[11/14 13:04:17 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1539, average loss: 0.6563
[11/14 13:04:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 67.62	
[11/14 13:04:17 visual_prompt]: Best epoch 19: best metric: -0.656
[11/14 13:04:17 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.9755282581475768
[11/14 13:10:33 visual_prompt]: Epoch 20 / 100: avg data time: 1.04e+01, avg batch time: 10.7569, average train loss: 0.6895
[11/14 13:11:16 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1543, average loss: 0.6313
[11/14 13:11:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.07	rocauc: 74.00	
[11/14 13:11:16 visual_prompt]: Best epoch 20: best metric: -0.631
[11/14 13:11:16 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.9698463103929542
[11/14 13:17:34 visual_prompt]: Epoch 21 / 100: avg data time: 1.04e+01, avg batch time: 10.8001, average train loss: 0.7534
[11/14 13:18:18 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1541, average loss: 0.6307
[11/14 13:18:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 71.39	
[11/14 13:18:18 visual_prompt]: Best epoch 21: best metric: -0.631
[11/14 13:18:18 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.9635919272833937
[11/14 13:24:36 visual_prompt]: Epoch 22 / 100: avg data time: 1.05e+01, avg batch time: 10.8068, average train loss: 1.0107
[11/14 13:25:19 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1540, average loss: 0.8245
[11/14 13:25:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.40	
[11/14 13:25:19 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.9567727288213004
[11/14 13:31:37 visual_prompt]: Epoch 23 / 100: avg data time: 1.04e+01, avg batch time: 10.7986, average train loss: 0.7548
[11/14 13:32:20 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1564, average loss: 0.6719
[11/14 13:32:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.47	rocauc: 68.89	
[11/14 13:32:20 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.9493970231495835
[11/14 13:38:40 visual_prompt]: Epoch 24 / 100: avg data time: 1.05e+01, avg batch time: 10.8406, average train loss: 0.7281
[11/14 13:39:23 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1547, average loss: 0.6827
[11/14 13:39:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 67.11	
[11/14 13:39:23 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.9414737964294635
[11/14 13:45:45 visual_prompt]: Epoch 25 / 100: avg data time: 1.05e+01, avg batch time: 10.9040, average train loss: 0.6765
[11/14 13:46:28 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.1543, average loss: 0.7280
[11/14 13:46:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 50.41	rocauc: 70.97	
[11/14 13:46:28 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.9330127018922194
[11/14 13:52:46 visual_prompt]: Epoch 26 / 100: avg data time: 1.05e+01, avg batch time: 10.8082, average train loss: 0.7592
[11/14 13:53:29 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1544, average loss: 0.8253
[11/14 13:53:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 70.08	
[11/14 13:53:29 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.9240240480782129
[11/14 13:59:48 visual_prompt]: Epoch 27 / 100: avg data time: 1.05e+01, avg batch time: 10.8164, average train loss: 0.7015
[11/14 14:00:31 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1571, average loss: 0.8911
[11/14 14:00:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.53	rocauc: 66.46	
[11/14 14:00:31 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.9145187862775208
[11/14 14:06:47 visual_prompt]: Epoch 28 / 100: avg data time: 1.04e+01, avg batch time: 10.7365, average train loss: 0.7425
[11/14 14:07:30 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1543, average loss: 0.7833
[11/14 14:07:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 68.45	
[11/14 14:07:30 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.9045084971874737
[11/14 14:13:46 visual_prompt]: Epoch 29 / 100: avg data time: 1.04e+01, avg batch time: 10.7341, average train loss: 0.7365
[11/14 14:14:28 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1566, average loss: 0.6650
[11/14 14:14:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 71.61	
[11/14 14:14:28 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.8940053768033609
[11/14 14:20:47 visual_prompt]: Epoch 30 / 100: avg data time: 1.04e+01, avg batch time: 10.8019, average train loss: 0.6650
[11/14 14:21:32 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.1541, average loss: 0.6152
[11/14 14:21:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.67	rocauc: 72.52	
[11/14 14:21:32 visual_prompt]: Best epoch 30: best metric: -0.615
[11/14 14:21:32 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.883022221559489
[11/14 14:28:06 visual_prompt]: Epoch 31 / 100: avg data time: 1.09e+01, avg batch time: 11.2496, average train loss: 0.6711
[11/14 14:28:49 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1546, average loss: 0.6374
[11/14 14:28:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 71.24	
[11/14 14:28:49 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.8715724127386971
[11/14 14:35:04 visual_prompt]: Epoch 32 / 100: avg data time: 1.04e+01, avg batch time: 10.7356, average train loss: 0.7042
[11/14 14:35:47 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1573, average loss: 0.6896
[11/14 14:35:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 69.52	
[11/14 14:35:47 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.8596699001693255
[11/14 14:42:00 visual_prompt]: Epoch 33 / 100: avg data time: 1.03e+01, avg batch time: 10.6576, average train loss: 0.7151
[11/14 14:42:43 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1555, average loss: 0.6131
[11/14 14:42:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.89	rocauc: 72.80	
[11/14 14:42:43 visual_prompt]: Best epoch 33: best metric: -0.613
[11/14 14:42:43 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.8473291852294986
[11/14 14:49:19 visual_prompt]: Epoch 34 / 100: avg data time: 1.10e+01, avg batch time: 11.3305, average train loss: 0.6883
[11/14 14:50:05 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.1582, average loss: 0.6913
[11/14 14:50:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 68.55	
[11/14 14:50:05 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.8345653031794291
[11/14 14:56:27 visual_prompt]: Epoch 35 / 100: avg data time: 1.05e+01, avg batch time: 10.8874, average train loss: 0.6318
[11/14 14:57:10 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1559, average loss: 0.6609
[11/14 14:57:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 71.17	
[11/14 14:57:10 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.8213938048432696
[11/14 15:03:30 visual_prompt]: Epoch 36 / 100: avg data time: 1.05e+01, avg batch time: 10.8458, average train loss: 0.6853
[11/14 15:04:13 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1542, average loss: 0.6976
[11/14 15:04:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 72.11	
[11/14 15:04:13 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.8078307376628291
[11/14 15:10:37 visual_prompt]: Epoch 37 / 100: avg data time: 1.06e+01, avg batch time: 10.9651, average train loss: 0.6850
[11/14 15:11:23 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1543, average loss: 0.7541
[11/14 15:11:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 73.90	
[11/14 15:11:23 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.7938926261462366
[11/14 15:18:00 visual_prompt]: Epoch 38 / 100: avg data time: 1.10e+01, avg batch time: 11.3424, average train loss: 0.6619
[11/14 15:18:46 visual_prompt]: Inference (val):avg data time: 3.38e-05, avg batch time: 0.1544, average loss: 0.6805
[11/14 15:18:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 70.96	
[11/14 15:18:46 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.7795964517353734
[11/14 15:25:29 visual_prompt]: Epoch 39 / 100: avg data time: 1.12e+01, avg batch time: 11.5221, average train loss: 0.7488
[11/14 15:26:15 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1543, average loss: 0.6527
[11/14 15:26:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 70.85	
[11/14 15:26:15 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.7649596321166025
[11/14 15:32:48 visual_prompt]: Epoch 40 / 100: avg data time: 1.09e+01, avg batch time: 11.2149, average train loss: 0.6265
[11/14 15:33:30 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.1544, average loss: 0.6484
[11/14 15:33:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 68.70	rocauc: 72.19	
[11/14 15:33:30 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.75
[11/14 15:39:58 visual_prompt]: Epoch 41 / 100: avg data time: 1.07e+01, avg batch time: 11.0723, average train loss: 0.6342
[11/14 15:40:43 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1546, average loss: 0.9573
[11/14 15:40:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 72.19	
[11/14 15:40:43 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.7347357813929454
[11/14 15:47:02 visual_prompt]: Epoch 42 / 100: avg data time: 1.05e+01, avg batch time: 10.8325, average train loss: 0.6262
[11/14 15:47:45 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1560, average loss: 0.6375
[11/14 15:47:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 72.79	
[11/14 15:47:45 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.7191855733945387
[11/14 15:54:03 visual_prompt]: Epoch 43 / 100: avg data time: 1.04e+01, avg batch time: 10.7884, average train loss: 0.6646
[11/14 15:54:46 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1545, average loss: 0.6265
[11/14 15:54:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 69.51	rocauc: 73.68	
[11/14 15:54:46 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.7033683215379002
[11/14 16:01:03 visual_prompt]: Epoch 44 / 100: avg data time: 1.04e+01, avg batch time: 10.7796, average train loss: 0.6363
[11/14 16:01:46 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.1540, average loss: 0.6235
[11/14 16:01:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.67	rocauc: 73.53	
[11/14 16:01:46 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.6873032967079561
[11/14 16:08:05 visual_prompt]: Epoch 45 / 100: avg data time: 1.05e+01, avg batch time: 10.8109, average train loss: 0.6214
[11/14 16:08:48 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1545, average loss: 0.6358
[11/14 16:08:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 73.09	
[11/14 16:08:48 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.6710100716628344
[11/14 16:15:05 visual_prompt]: Epoch 46 / 100: avg data time: 1.04e+01, avg batch time: 10.7841, average train loss: 0.6146
[11/14 16:15:48 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1540, average loss: 0.7738
[11/14 16:15:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 72.32	
[11/14 16:15:48 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.6545084971874737
[11/14 16:22:06 visual_prompt]: Epoch 47 / 100: avg data time: 1.04e+01, avg batch time: 10.7790, average train loss: 0.6490
[11/14 16:22:49 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1549, average loss: 0.6798
[11/14 16:22:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 72.77	
[11/14 16:22:49 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.6378186779084996
[11/14 16:29:07 visual_prompt]: Epoch 48 / 100: avg data time: 1.04e+01, avg batch time: 10.7949, average train loss: 0.6222
[11/14 16:29:50 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1542, average loss: 0.7581
[11/14 16:29:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 72.78	
[11/14 16:29:50 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.6209609477998338
[11/14 16:36:11 visual_prompt]: Epoch 49 / 100: avg data time: 1.05e+01, avg batch time: 10.8863, average train loss: 0.5989
[11/14 16:37:01 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1550, average loss: 0.6166
[11/14 16:37:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 69.92	rocauc: 73.41	
[11/14 16:37:01 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.6039558454088796
[11/14 16:43:23 visual_prompt]: Epoch 50 / 100: avg data time: 1.06e+01, avg batch time: 10.9218, average train loss: 0.6101
[11/14 16:44:06 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1550, average loss: 0.9439
[11/14 16:44:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.54	rocauc: 73.93	
[11/14 16:44:06 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.5868240888334653
[11/14 16:50:42 visual_prompt]: Epoch 51 / 100: avg data time: 1.09e+01, avg batch time: 11.2960, average train loss: 0.5759
[11/14 16:51:27 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.1542, average loss: 0.6346
[11/14 16:51:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 68.29	rocauc: 74.34	
[11/14 16:51:27 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.5695865504800327
[11/14 16:58:02 visual_prompt]: Epoch 52 / 100: avg data time: 1.09e+01, avg batch time: 11.2720, average train loss: 0.5615
[11/14 16:58:48 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1541, average loss: 0.6901
[11/14 16:58:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 69.51	
[11/14 16:58:48 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.5522642316338268
[11/14 17:05:05 visual_prompt]: Epoch 53 / 100: avg data time: 1.04e+01, avg batch time: 10.7810, average train loss: 0.5931
[11/14 17:05:48 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1543, average loss: 0.6246
[11/14 17:05:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 73.60	
[11/14 17:05:48 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.5348782368720626
[11/14 17:12:10 visual_prompt]: Epoch 54 / 100: avg data time: 1.05e+01, avg batch time: 10.8987, average train loss: 0.5731
[11/14 17:12:56 visual_prompt]: Inference (val):avg data time: 3.61e-05, avg batch time: 0.1541, average loss: 0.7166
[11/14 17:12:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.07	rocauc: 71.96	
[11/14 17:12:56 visual_prompt]: Stopping early.
[11/14 17:12:56 visual_prompt]: Rank of current process: 0. World size: 1
[11/14 17:12:56 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/14 17:12:56 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/14 17:12:56 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/14 17:12:56 visual_prompt]: Training with config:
[11/14 17:12:56 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr1.0_wd0.0/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 1.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/14 17:12:56 visual_prompt]: Loading training data...
[11/14 17:12:56 visual_prompt]: Constructing mammo-cbis dataset train...
[11/14 17:12:56 visual_prompt]: Loading validation data...
[11/14 17:12:56 visual_prompt]: Constructing mammo-cbis dataset val...
[11/14 17:12:56 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[11/14 17:12:59 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[11/14 17:12:59 visual_prompt]: tuned percent:0.536
[11/14 17:12:59 visual_prompt]: Device used for model: 0
[11/14 17:12:59 visual_prompt]: Setting up Evaluator...
[11/14 17:12:59 visual_prompt]: Setting up Trainer...
[11/14 17:12:59 visual_prompt]: 	Setting up the optimizer...
[11/14 17:12:59 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/14 17:19:26 visual_prompt]: Epoch 1 / 100: avg data time: 1.07e+01, avg batch time: 11.0654, average train loss: 1.4017
[11/14 17:20:09 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1544, average loss: 1.2969
[11/14 17:20:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[11/14 17:20:09 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.1
[11/14 17:26:22 visual_prompt]: Epoch 2 / 100: avg data time: 1.03e+01, avg batch time: 10.6592, average train loss: 2.3837
[11/14 17:27:05 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1541, average loss: 0.6870
[11/14 17:27:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.31	
[11/14 17:27:05 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.2
[11/14 17:33:19 visual_prompt]: Epoch 3 / 100: avg data time: 1.03e+01, avg batch time: 10.6873, average train loss: 0.7638
[11/14 17:34:01 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1540, average loss: 0.6927
[11/14 17:34:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 48.78	rocauc: 56.68	
[11/14 17:34:01 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.3
[11/14 17:40:15 visual_prompt]: Epoch 4 / 100: avg data time: 1.03e+01, avg batch time: 10.6741, average train loss: 0.7212
[11/14 17:40:58 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1540, average loss: 0.6890
[11/14 17:40:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.52	
[11/14 17:40:58 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.4
[11/14 17:47:12 visual_prompt]: Epoch 5 / 100: avg data time: 1.03e+01, avg batch time: 10.6822, average train loss: 0.7934
[11/14 17:47:54 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1563, average loss: 0.7004
[11/14 17:47:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 47.56	rocauc: 57.28	
[11/14 17:47:54 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.5
[11/14 17:54:09 visual_prompt]: Epoch 6 / 100: avg data time: 1.04e+01, avg batch time: 10.7160, average train loss: 0.7839
[11/14 17:54:53 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1542, average loss: 0.6782
[11/14 17:54:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 57.76	
[11/14 17:54:53 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.6
[11/14 18:01:11 visual_prompt]: Epoch 7 / 100: avg data time: 1.04e+01, avg batch time: 10.7960, average train loss: 0.7145
[11/14 18:01:54 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1550, average loss: 1.5308
[11/14 18:01:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.15	
[11/14 18:01:54 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.7
[11/14 18:08:11 visual_prompt]: Epoch 8 / 100: avg data time: 1.04e+01, avg batch time: 10.7783, average train loss: 0.9186
[11/14 18:08:54 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1546, average loss: 0.6984
[11/14 18:08:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 50.00	rocauc: 58.64	
[11/14 18:08:54 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.8
[11/14 18:15:13 visual_prompt]: Epoch 9 / 100: avg data time: 1.05e+01, avg batch time: 10.8171, average train loss: 0.9092
[11/14 18:15:56 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1541, average loss: 0.7654
[11/14 18:15:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.11	
[11/14 18:15:56 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.9
[11/14 18:22:13 visual_prompt]: Epoch 10 / 100: avg data time: 1.04e+01, avg batch time: 10.7799, average train loss: 0.8134
[11/14 18:22:56 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1540, average loss: 0.7783
[11/14 18:22:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.21	
[11/14 18:22:56 visual_prompt]: Training 11 / 100 epoch, with learning rate 1.0
[11/14 18:29:14 visual_prompt]: Epoch 11 / 100: avg data time: 1.04e+01, avg batch time: 10.7902, average train loss: 0.8128
[11/14 18:29:57 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1543, average loss: 0.6920
[11/14 18:29:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 59.77	
[11/14 18:29:57 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.9996954135095479
[11/14 18:36:15 visual_prompt]: Epoch 12 / 100: avg data time: 1.04e+01, avg batch time: 10.7855, average train loss: 0.8227
[11/14 18:36:58 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1541, average loss: 1.2181
[11/14 18:36:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 63.21	
[11/14 18:36:58 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.9987820251299121
[11/14 18:43:15 visual_prompt]: Epoch 13 / 100: avg data time: 1.04e+01, avg batch time: 10.7881, average train loss: 0.9879
[11/14 18:43:58 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1543, average loss: 0.6647
[11/14 18:43:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 63.97	
[11/14 18:43:58 visual_prompt]: Best epoch 13: best metric: -0.665
[11/14 18:43:58 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.9972609476841366
[11/14 18:50:25 visual_prompt]: Epoch 14 / 100: avg data time: 1.07e+01, avg batch time: 11.0503, average train loss: 0.9055
[11/14 18:51:13 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1536, average loss: 0.7470
[11/14 18:51:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 64.10	
[11/14 18:51:13 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.9951340343707852
[11/14 18:58:17 visual_prompt]: Epoch 15 / 100: avg data time: 1.18e+01, avg batch time: 12.1049, average train loss: 0.9364
[11/14 18:59:09 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1542, average loss: 0.7376
[11/14 18:59:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 51.63	rocauc: 64.47	
[11/14 18:59:09 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.9924038765061041
[11/14 19:06:29 visual_prompt]: Epoch 16 / 100: avg data time: 1.22e+01, avg batch time: 12.5890, average train loss: 0.8586
[11/14 19:07:17 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1539, average loss: 0.8393
[11/14 19:07:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 66.10	
[11/14 19:07:17 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.9890738003669028
[11/14 19:14:31 visual_prompt]: Epoch 17 / 100: avg data time: 1.20e+01, avg batch time: 12.3856, average train loss: 0.9024
[11/14 19:15:22 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1541, average loss: 1.4949
[11/14 19:15:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 66.81	
[11/14 19:15:22 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.9851478631379982
[11/14 19:22:34 visual_prompt]: Epoch 18 / 100: avg data time: 1.20e+01, avg batch time: 12.3604, average train loss: 0.9396
[11/14 19:23:22 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1539, average loss: 0.6471
[11/14 19:23:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 67.72	
[11/14 19:23:22 visual_prompt]: Best epoch 18: best metric: -0.647
[11/14 19:23:22 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.9806308479691594
[11/14 19:30:37 visual_prompt]: Epoch 19 / 100: avg data time: 1.21e+01, avg batch time: 12.4331, average train loss: 0.7226
[11/14 19:31:24 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1575, average loss: 0.6440
[11/14 19:31:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 68.51	
[11/14 19:31:24 visual_prompt]: Best epoch 19: best metric: -0.644
[11/14 19:31:24 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.9755282581475768
[11/14 19:38:34 visual_prompt]: Epoch 20 / 100: avg data time: 1.19e+01, avg batch time: 12.2628, average train loss: 0.6846
[11/14 19:39:24 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1538, average loss: 0.6398
[11/14 19:39:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 69.21	
[11/14 19:39:24 visual_prompt]: Best epoch 20: best metric: -0.640
[11/14 19:39:24 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.9698463103929542
[11/14 19:46:32 visual_prompt]: Epoch 21 / 100: avg data time: 1.19e+01, avg batch time: 12.2391, average train loss: 0.7334
[11/14 19:47:20 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1543, average loss: 0.6257
[11/14 19:47:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.67	rocauc: 72.01	
[11/14 19:47:20 visual_prompt]: Best epoch 21: best metric: -0.626
[11/14 19:47:20 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.9635919272833937
[11/14 19:54:13 visual_prompt]: Epoch 22 / 100: avg data time: 1.15e+01, avg batch time: 11.8037, average train loss: 0.8954
[11/14 19:55:03 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1540, average loss: 0.8054
[11/14 19:55:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 53.25	rocauc: 71.37	
[11/14 19:55:03 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.9567727288213004
[11/14 20:01:59 visual_prompt]: Epoch 23 / 100: avg data time: 1.15e+01, avg batch time: 11.8822, average train loss: 0.7275
[11/14 20:02:49 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1540, average loss: 0.6562
[11/14 20:02:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 70.01	
[11/14 20:02:49 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.9493970231495835
[11/14 20:09:53 visual_prompt]: Epoch 24 / 100: avg data time: 1.18e+01, avg batch time: 12.1138, average train loss: 0.7949
[11/14 20:10:42 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1533, average loss: 0.8498
[11/14 20:10:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 70.71	
[11/14 20:10:42 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.9414737964294635
[11/14 20:17:25 visual_prompt]: Epoch 25 / 100: avg data time: 1.12e+01, avg batch time: 11.5386, average train loss: 0.6597
[11/14 20:18:09 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1544, average loss: 0.6262
[11/14 20:18:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.67	rocauc: 72.23	
[11/14 20:18:09 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.9330127018922194
[11/14 20:24:23 visual_prompt]: Epoch 26 / 100: avg data time: 1.04e+01, avg batch time: 10.7055, average train loss: 0.6893
[11/14 20:25:06 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1540, average loss: 0.7597
[11/14 20:25:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 73.77	
[11/14 20:25:06 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.9240240480782129
[11/14 20:31:20 visual_prompt]: Epoch 27 / 100: avg data time: 1.03e+01, avg batch time: 10.6819, average train loss: 0.6735
[11/14 20:32:03 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1542, average loss: 0.6484
[11/14 20:32:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 70.90	
[11/14 20:32:03 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.9145187862775208
[11/14 20:38:16 visual_prompt]: Epoch 28 / 100: avg data time: 1.03e+01, avg batch time: 10.6684, average train loss: 0.7117
[11/14 20:38:59 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.1569, average loss: 0.8069
[11/14 20:38:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 71.71	
[11/14 20:38:59 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.9045084971874737
[11/14 20:45:14 visual_prompt]: Epoch 29 / 100: avg data time: 1.04e+01, avg batch time: 10.7102, average train loss: 0.6974
[11/14 20:45:56 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1542, average loss: 0.6343
[11/14 20:45:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 73.49	
[11/14 20:45:56 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.8940053768033609
[11/14 20:52:10 visual_prompt]: Epoch 30 / 100: avg data time: 1.03e+01, avg batch time: 10.6750, average train loss: 0.6181
[11/14 20:52:53 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1556, average loss: 0.6059
[11/14 20:52:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 74.02	
[11/14 20:52:53 visual_prompt]: Best epoch 30: best metric: -0.606
[11/14 20:52:53 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.883022221559489
[11/14 20:59:07 visual_prompt]: Epoch 31 / 100: avg data time: 1.03e+01, avg batch time: 10.6796, average train loss: 0.6141
[11/14 20:59:49 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1540, average loss: 0.6445
[11/14 20:59:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 71.74	
[11/14 20:59:49 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.8715724127386971
[11/14 21:06:04 visual_prompt]: Epoch 32 / 100: avg data time: 1.03e+01, avg batch time: 10.6899, average train loss: 0.6365
[11/14 21:06:46 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1538, average loss: 0.6059
[11/14 21:06:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.67	rocauc: 73.53	
[11/14 21:06:46 visual_prompt]: Best epoch 32: best metric: -0.606
[11/14 21:06:46 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.8596699001693255
[11/14 21:13:00 visual_prompt]: Epoch 33 / 100: avg data time: 1.03e+01, avg batch time: 10.6825, average train loss: 0.6069
[11/14 21:13:43 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1585, average loss: 0.6453
[11/14 21:13:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 71.56	
[11/14 21:13:43 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.8473291852294986
[11/14 21:19:56 visual_prompt]: Epoch 34 / 100: avg data time: 1.03e+01, avg batch time: 10.6598, average train loss: 0.6032
[11/14 21:20:38 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1545, average loss: 0.6399
[11/14 21:20:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 71.07	
[11/14 21:20:39 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.8345653031794291
[11/14 21:26:54 visual_prompt]: Epoch 35 / 100: avg data time: 1.04e+01, avg batch time: 10.7238, average train loss: 0.5863
[11/14 21:27:37 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1545, average loss: 0.6498
[11/14 21:27:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 70.12	
[11/14 21:27:37 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.8213938048432696
[11/14 21:33:55 visual_prompt]: Epoch 36 / 100: avg data time: 1.04e+01, avg batch time: 10.7939, average train loss: 0.6224
[11/14 21:34:38 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1542, average loss: 0.7823
[11/14 21:34:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 68.09	
[11/14 21:34:38 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.8078307376628291
[11/14 21:40:55 visual_prompt]: Epoch 37 / 100: avg data time: 1.04e+01, avg batch time: 10.7772, average train loss: 0.6550
[11/14 21:41:39 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1543, average loss: 0.6746
[11/14 21:41:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 70.05	
[11/14 21:41:39 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.7938926261462366
[11/14 21:47:57 visual_prompt]: Epoch 38 / 100: avg data time: 1.05e+01, avg batch time: 10.8066, average train loss: 0.5704
[11/14 21:48:40 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1543, average loss: 0.7443
[11/14 21:48:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.01	rocauc: 70.57	
[11/14 21:48:40 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.7795964517353734
[11/14 21:54:59 visual_prompt]: Epoch 39 / 100: avg data time: 1.05e+01, avg batch time: 10.8137, average train loss: 0.6368
[11/14 21:55:42 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1542, average loss: 0.8699
[11/14 21:55:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 70.91	
[11/14 21:55:42 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.7649596321166025
[11/14 22:02:00 visual_prompt]: Epoch 40 / 100: avg data time: 1.04e+01, avg batch time: 10.8032, average train loss: 0.5646
[11/14 22:02:43 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1553, average loss: 0.6517
[11/14 22:02:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 70.71	
[11/14 22:02:43 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.75
[11/14 22:09:17 visual_prompt]: Epoch 41 / 100: avg data time: 1.09e+01, avg batch time: 11.2456, average train loss: 0.5479
[11/14 22:10:06 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1543, average loss: 1.0372
[11/14 22:10:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 70.30	
[11/14 22:10:06 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.7347357813929454
[11/14 22:16:50 visual_prompt]: Epoch 42 / 100: avg data time: 1.12e+01, avg batch time: 11.5163, average train loss: 0.5487
[11/14 22:17:36 visual_prompt]: Inference (val):avg data time: 3.43e-05, avg batch time: 0.1537, average loss: 0.6927
[11/14 22:17:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 70.09	
[11/14 22:17:36 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.7191855733945387
[11/14 22:24:24 visual_prompt]: Epoch 43 / 100: avg data time: 1.13e+01, avg batch time: 11.6440, average train loss: 0.6197
[11/14 22:25:09 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1544, average loss: 0.7484
[11/14 22:25:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 72.30	
[11/14 22:25:09 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.7033683215379002
[11/14 22:31:56 visual_prompt]: Epoch 44 / 100: avg data time: 1.13e+01, avg batch time: 11.6186, average train loss: 0.5463
[11/14 22:32:44 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.1542, average loss: 0.6594
[11/14 22:32:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 72.18	
[11/14 22:32:44 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.6873032967079561
[11/14 22:39:34 visual_prompt]: Epoch 45 / 100: avg data time: 1.14e+01, avg batch time: 11.7238, average train loss: 0.5169
[11/14 22:40:30 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1538, average loss: 0.7180
[11/14 22:40:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 73.28	
[11/14 22:40:30 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.6710100716628344
[11/14 22:48:56 visual_prompt]: Epoch 46 / 100: avg data time: 1.41e+01, avg batch time: 14.4453, average train loss: 0.5621
[11/14 22:49:44 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.1540, average loss: 0.9338
[11/14 22:49:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 72.21	
[11/14 22:49:44 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.6545084971874737
[11/14 22:56:59 visual_prompt]: Epoch 47 / 100: avg data time: 1.21e+01, avg batch time: 12.4174, average train loss: 0.5909
[11/14 22:57:49 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1541, average loss: 0.6749
[11/14 22:57:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.67	rocauc: 71.30	
[11/14 22:57:49 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.6378186779084996
[11/14 23:04:50 visual_prompt]: Epoch 48 / 100: avg data time: 1.17e+01, avg batch time: 12.0113, average train loss: 0.5193
[11/14 23:05:34 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1545, average loss: 0.7210
[11/14 23:05:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 72.00	
[11/14 23:05:34 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.6209609477998338
[11/14 23:12:49 visual_prompt]: Epoch 49 / 100: avg data time: 1.21e+01, avg batch time: 12.4203, average train loss: 0.4586
[11/14 23:13:41 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.1551, average loss: 0.8323
[11/14 23:13:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 68.03	
[11/14 23:13:41 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.6039558454088796
[11/14 23:20:45 visual_prompt]: Epoch 50 / 100: avg data time: 1.17e+01, avg batch time: 12.0886, average train loss: 0.5122
[11/14 23:21:35 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1552, average loss: 0.9505
[11/14 23:21:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 70.41	
[11/14 23:21:35 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.5868240888334653
[11/14 23:29:51 visual_prompt]: Epoch 51 / 100: avg data time: 1.38e+01, avg batch time: 14.1801, average train loss: 0.4728
[11/14 23:30:35 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1579, average loss: 0.7770
[11/14 23:30:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.67	rocauc: 70.07	
[11/14 23:30:35 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.5695865504800327
[11/14 23:37:03 visual_prompt]: Epoch 52 / 100: avg data time: 1.07e+01, avg batch time: 11.0917, average train loss: 0.4409
[11/14 23:37:46 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1546, average loss: 0.7205
[11/14 23:37:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.67	rocauc: 72.49	
[11/14 23:37:46 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.5522642316338268
[11/14 23:44:15 visual_prompt]: Epoch 53 / 100: avg data time: 1.08e+01, avg batch time: 11.1123, average train loss: 0.4248
[11/14 23:45:00 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1539, average loss: 0.7735
[11/14 23:45:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.01	rocauc: 70.13	
[11/14 23:45:00 visual_prompt]: Stopping early.
[11/14 23:45:00 visual_prompt]: Rank of current process: 0. World size: 1
[11/14 23:45:00 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/14 23:45:00 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/14 23:45:00 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/14 23:45:00 visual_prompt]: Training with config:
[11/14 23:45:00 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr0.5_wd0.01/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/14 23:45:00 visual_prompt]: Loading training data...
[11/14 23:45:00 visual_prompt]: Constructing mammo-cbis dataset train...
[11/14 23:45:00 visual_prompt]: Loading validation data...
[11/14 23:45:00 visual_prompt]: Constructing mammo-cbis dataset val...
[11/14 23:45:00 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[11/14 23:45:03 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[11/14 23:45:03 visual_prompt]: tuned percent:0.536
[11/14 23:45:03 visual_prompt]: Device used for model: 0
[11/14 23:45:03 visual_prompt]: Setting up Evaluator...
[11/14 23:45:03 visual_prompt]: Setting up Trainer...
[11/14 23:45:03 visual_prompt]: 	Setting up the optimizer...
[11/14 23:45:03 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/14 23:51:30 visual_prompt]: Epoch 1 / 100: avg data time: 1.07e+01, avg batch time: 11.0709, average train loss: 1.4017
[11/14 23:52:15 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1578, average loss: 1.2969
[11/14 23:52:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[11/14 23:52:15 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.05
[11/14 23:58:47 visual_prompt]: Epoch 2 / 100: avg data time: 1.08e+01, avg batch time: 11.1988, average train loss: 1.8262
[11/14 23:59:33 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1542, average loss: 0.6901
[11/14 23:59:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.31	
[11/14 23:59:33 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.1
[11/15 00:05:58 visual_prompt]: Epoch 3 / 100: avg data time: 1.06e+01, avg batch time: 10.9956, average train loss: 0.7022
[11/15 00:06:41 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1544, average loss: 0.6911
[11/15 00:06:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.45	
[11/15 00:06:41 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.15
[11/15 00:12:59 visual_prompt]: Epoch 4 / 100: avg data time: 1.04e+01, avg batch time: 10.8031, average train loss: 0.6931
[11/15 00:13:42 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1534, average loss: 0.7120
[11/15 00:13:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.97	
[11/15 00:13:42 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.2
[11/15 00:19:59 visual_prompt]: Epoch 5 / 100: avg data time: 1.04e+01, avg batch time: 10.7656, average train loss: 0.7299
[11/15 00:20:42 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1556, average loss: 0.7271
[11/15 00:20:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.46	
[11/15 00:20:42 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.25
[11/15 00:27:01 visual_prompt]: Epoch 6 / 100: avg data time: 1.05e+01, avg batch time: 10.8070, average train loss: 0.7423
[11/15 00:27:44 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1534, average loss: 0.7055
[11/15 00:27:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.62	
[11/15 00:27:44 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.3
[11/15 00:34:05 visual_prompt]: Epoch 7 / 100: avg data time: 1.05e+01, avg batch time: 10.8760, average train loss: 0.7393
[11/15 00:34:48 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1536, average loss: 0.7034
[11/15 00:34:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 45.71	
[11/15 00:34:48 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.35
[11/15 00:41:07 visual_prompt]: Epoch 8 / 100: avg data time: 1.05e+01, avg batch time: 10.8215, average train loss: 0.7093
[11/15 00:41:50 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1536, average loss: 0.6898
[11/15 00:41:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.58	
[11/15 00:41:50 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.4
[11/15 00:48:13 visual_prompt]: Epoch 9 / 100: avg data time: 1.06e+01, avg batch time: 10.9189, average train loss: 0.7092
[11/15 00:48:56 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1546, average loss: 0.7333
[11/15 00:48:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.82	
[11/15 00:48:56 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.45
[11/15 00:55:16 visual_prompt]: Epoch 10 / 100: avg data time: 1.05e+01, avg batch time: 10.8489, average train loss: 0.7067
[11/15 00:55:59 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1553, average loss: 0.7526
[11/15 00:55:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.47	
[11/15 00:55:59 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.5
[11/15 01:02:20 visual_prompt]: Epoch 11 / 100: avg data time: 1.05e+01, avg batch time: 10.8689, average train loss: 0.7159
[11/15 01:03:03 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1533, average loss: 0.6911
[11/15 01:03:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.18	
[11/15 01:03:03 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.49984770675477397
[11/15 01:09:23 visual_prompt]: Epoch 12 / 100: avg data time: 1.05e+01, avg batch time: 10.8532, average train loss: 0.7329
[11/15 01:10:07 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1536, average loss: 0.7096
[11/15 01:10:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 38.71	
[11/15 01:10:07 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.49939101256495605
[11/15 01:16:28 visual_prompt]: Epoch 13 / 100: avg data time: 1.05e+01, avg batch time: 10.8871, average train loss: 0.7421
[11/15 01:17:11 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1535, average loss: 0.7032
[11/15 01:17:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.23	
[11/15 01:17:11 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.4986304738420683
[11/15 01:23:30 visual_prompt]: Epoch 14 / 100: avg data time: 1.05e+01, avg batch time: 10.8211, average train loss: 0.7345
[11/15 01:24:13 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1534, average loss: 0.7341
[11/15 01:24:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.53	
[11/15 01:24:13 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.4975670171853926
[11/15 01:30:33 visual_prompt]: Epoch 15 / 100: avg data time: 1.05e+01, avg batch time: 10.8627, average train loss: 0.7460
[11/15 01:31:17 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1540, average loss: 0.7016
[11/15 01:31:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.98	
[11/15 01:31:17 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.49620193825305203
[11/15 01:37:35 visual_prompt]: Epoch 16 / 100: avg data time: 1.05e+01, avg batch time: 10.8134, average train loss: 0.7029
[11/15 01:38:19 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1542, average loss: 0.8806
[11/15 01:38:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.29	
[11/15 01:38:19 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.4945369001834514
[11/15 01:44:38 visual_prompt]: Epoch 17 / 100: avg data time: 1.05e+01, avg batch time: 10.8443, average train loss: 0.7797
[11/15 01:45:22 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.1561, average loss: 0.7726
[11/15 01:45:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.10	
[11/15 01:45:22 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.4925739315689991
[11/15 01:51:41 visual_prompt]: Epoch 18 / 100: avg data time: 1.05e+01, avg batch time: 10.8476, average train loss: 0.7318
[11/15 01:52:24 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1535, average loss: 0.7669
[11/15 01:52:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.56	
[11/15 01:52:25 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.4903154239845797
[11/15 01:58:46 visual_prompt]: Epoch 19 / 100: avg data time: 1.05e+01, avg batch time: 10.8915, average train loss: 0.7136
[11/15 01:59:29 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1533, average loss: 0.7828
[11/15 01:59:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.46	
[11/15 01:59:29 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.4877641290737884
[11/15 02:05:50 visual_prompt]: Epoch 20 / 100: avg data time: 1.05e+01, avg batch time: 10.8645, average train loss: 0.7135
[11/15 02:06:33 visual_prompt]: Inference (val):avg data time: 3.43e-05, avg batch time: 0.1550, average loss: 0.7291
[11/15 02:06:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.91	
[11/15 02:06:33 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.4849231551964771
[11/15 02:12:52 visual_prompt]: Epoch 21 / 100: avg data time: 1.05e+01, avg batch time: 10.8110, average train loss: 0.7235
[11/15 02:13:35 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1555, average loss: 0.7152
[11/15 02:13:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.00	
[11/15 02:13:35 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.48179596364169686
[11/15 02:19:56 visual_prompt]: Epoch 22 / 100: avg data time: 1.05e+01, avg batch time: 10.8739, average train loss: 0.7275
[11/15 02:20:39 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1548, average loss: 0.7115
[11/15 02:20:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.77	
[11/15 02:20:39 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.4783863644106502
[11/15 02:26:59 visual_prompt]: Epoch 23 / 100: avg data time: 1.05e+01, avg batch time: 10.8582, average train loss: 0.7317
[11/15 02:27:43 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1559, average loss: 0.6996
[11/15 02:27:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.07	
[11/15 02:27:43 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.47469851157479176
[11/15 02:34:04 visual_prompt]: Epoch 24 / 100: avg data time: 1.05e+01, avg batch time: 10.8851, average train loss: 0.7430
[11/15 02:34:47 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1535, average loss: 0.7402
[11/15 02:34:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.95	
[11/15 02:34:47 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.47073689821473175
[11/15 02:41:07 visual_prompt]: Epoch 25 / 100: avg data time: 1.05e+01, avg batch time: 10.8433, average train loss: 0.7182
[11/15 02:41:50 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1534, average loss: 0.7036
[11/15 02:41:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.71	
[11/15 02:41:50 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.4665063509461097
[11/15 02:48:10 visual_prompt]: Epoch 26 / 100: avg data time: 1.05e+01, avg batch time: 10.8629, average train loss: 0.7233
[11/15 02:48:54 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1537, average loss: 0.7107
[11/15 02:48:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.78	
[11/15 02:48:54 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.46201202403910646
[11/15 02:55:15 visual_prompt]: Epoch 27 / 100: avg data time: 1.05e+01, avg batch time: 10.8740, average train loss: 0.7112
[11/15 02:55:58 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1536, average loss: 0.7513
[11/15 02:55:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.06	
[11/15 02:55:58 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.4572593931387604
[11/15 03:02:18 visual_prompt]: Epoch 28 / 100: avg data time: 1.05e+01, avg batch time: 10.8658, average train loss: 0.7203
[11/15 03:03:02 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1537, average loss: 0.6914
[11/15 03:03:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.15	
[11/15 03:03:02 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.45225424859373686
[11/15 03:09:23 visual_prompt]: Epoch 29 / 100: avg data time: 1.05e+01, avg batch time: 10.8910, average train loss: 0.7022
[11/15 03:10:06 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1558, average loss: 0.6888
[11/15 03:10:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.60	
[11/15 03:10:06 visual_prompt]: Best epoch 29: best metric: -0.689
[11/15 03:10:06 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.44700268840168045
[11/15 03:16:27 visual_prompt]: Epoch 30 / 100: avg data time: 1.05e+01, avg batch time: 10.8577, average train loss: 0.7003
[11/15 03:17:10 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1527, average loss: 0.6941
[11/15 03:17:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.81	
[11/15 03:17:10 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.4415111107797445
[11/15 03:23:30 visual_prompt]: Epoch 31 / 100: avg data time: 1.05e+01, avg batch time: 10.8596, average train loss: 0.7127
[11/15 03:24:13 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1575, average loss: 0.7171
[11/15 03:24:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.75	
[11/15 03:24:14 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.43578620636934856
[11/15 03:30:35 visual_prompt]: Epoch 32 / 100: avg data time: 1.05e+01, avg batch time: 10.8889, average train loss: 0.7172
[11/15 03:31:18 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1535, average loss: 0.7009
[11/15 03:31:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.14	
[11/15 03:31:18 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.42983495008466277
[11/15 03:37:38 visual_prompt]: Epoch 33 / 100: avg data time: 1.05e+01, avg batch time: 10.8466, average train loss: 0.7004
[11/15 03:38:21 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1535, average loss: 0.6886
[11/15 03:38:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.78	
[11/15 03:38:21 visual_prompt]: Best epoch 33: best metric: -0.689
[11/15 03:38:21 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.4236645926147493
[11/15 03:44:40 visual_prompt]: Epoch 34 / 100: avg data time: 1.05e+01, avg batch time: 10.8248, average train loss: 0.7039
[11/15 03:45:24 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1537, average loss: 0.6908
[11/15 03:45:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.12	
[11/15 03:45:24 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.41728265158971456
[11/15 03:51:44 visual_prompt]: Epoch 35 / 100: avg data time: 1.05e+01, avg batch time: 10.8568, average train loss: 0.7075
[11/15 03:52:27 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1559, average loss: 0.7352
[11/15 03:52:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 44.85	
[11/15 03:52:27 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.4106969024216348
[11/15 03:58:48 visual_prompt]: Epoch 36 / 100: avg data time: 1.05e+01, avg batch time: 10.8729, average train loss: 0.7084
[11/15 03:59:31 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1535, average loss: 0.7190
[11/15 03:59:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.35	
[11/15 03:59:31 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.40391536883141455
[11/15 04:05:51 visual_prompt]: Epoch 37 / 100: avg data time: 1.05e+01, avg batch time: 10.8518, average train loss: 0.7100
[11/15 04:06:34 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1530, average loss: 0.8127
[11/15 04:06:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.66	
[11/15 04:06:34 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.3969463130731183
[11/15 04:12:50 visual_prompt]: Epoch 38 / 100: avg data time: 1.04e+01, avg batch time: 10.7309, average train loss: 0.7042
[11/15 04:13:33 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1536, average loss: 0.7360
[11/15 04:13:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.28	
[11/15 04:13:33 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.3897982258676867
[11/15 04:19:49 visual_prompt]: Epoch 39 / 100: avg data time: 1.04e+01, avg batch time: 10.7372, average train loss: 0.7158
[11/15 04:20:32 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1557, average loss: 0.7242
[11/15 04:20:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 44.00	
[11/15 04:20:32 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.3824798160583012
[11/15 04:26:46 visual_prompt]: Epoch 40 / 100: avg data time: 1.03e+01, avg batch time: 10.7022, average train loss: 0.7006
[11/15 04:27:29 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1572, average loss: 0.6884
[11/15 04:27:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.86	
[11/15 04:27:29 visual_prompt]: Best epoch 40: best metric: -0.688
[11/15 04:27:29 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.375
[11/15 04:33:44 visual_prompt]: Epoch 41 / 100: avg data time: 1.04e+01, avg batch time: 10.7137, average train loss: 0.7102
[11/15 04:34:27 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1532, average loss: 0.7405
[11/15 04:34:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.91	
[11/15 04:34:27 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.3673678906964727
[11/15 04:40:43 visual_prompt]: Epoch 42 / 100: avg data time: 1.04e+01, avg batch time: 10.7331, average train loss: 0.7155
[11/15 04:41:25 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1535, average loss: 0.7672
[11/15 04:41:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.24	
[11/15 04:41:25 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.35959278669726935
[11/15 04:47:40 visual_prompt]: Epoch 43 / 100: avg data time: 1.04e+01, avg batch time: 10.7167, average train loss: 0.7450
[11/15 04:48:23 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1535, average loss: 0.7062
[11/15 04:48:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.63	
[11/15 04:48:23 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.3516841607689501
[11/15 04:54:38 visual_prompt]: Epoch 44 / 100: avg data time: 1.04e+01, avg batch time: 10.7141, average train loss: 0.7083
[11/15 04:55:21 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1533, average loss: 0.7198
[11/15 04:55:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.76	
[11/15 04:55:21 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.34365164835397805
[11/15 05:01:37 visual_prompt]: Epoch 45 / 100: avg data time: 1.04e+01, avg batch time: 10.7475, average train loss: 0.7016
[11/15 05:02:20 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1568, average loss: 0.7566
[11/15 05:02:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.34	
[11/15 05:02:20 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.3355050358314172
[11/15 05:08:35 visual_prompt]: Epoch 46 / 100: avg data time: 1.04e+01, avg batch time: 10.7068, average train loss: 0.7570
[11/15 05:09:18 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.1536, average loss: 0.7251
[11/15 05:09:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.08	
[11/15 05:09:18 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.32725424859373686
[11/15 05:15:32 visual_prompt]: Epoch 47 / 100: avg data time: 1.03e+01, avg batch time: 10.6880, average train loss: 0.7272
[11/15 05:16:15 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1535, average loss: 0.7533
[11/15 05:16:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.31	
[11/15 05:16:15 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.3189093389542498
[11/15 05:22:29 visual_prompt]: Epoch 48 / 100: avg data time: 1.03e+01, avg batch time: 10.6749, average train loss: 0.7282
[11/15 05:23:11 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1533, average loss: 0.6945
[11/15 05:23:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.32	
[11/15 05:23:11 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.3104804738999169
[11/15 05:29:25 visual_prompt]: Epoch 49 / 100: avg data time: 1.03e+01, avg batch time: 10.6941, average train loss: 0.7052
[11/15 05:30:08 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1536, average loss: 0.6888
[11/15 05:30:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.20	
[11/15 05:30:08 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.3019779227044398
[11/15 05:36:22 visual_prompt]: Epoch 50 / 100: avg data time: 1.03e+01, avg batch time: 10.6797, average train loss: 0.7013
[11/15 05:37:04 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1534, average loss: 0.6892
[11/15 05:37:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 44.15	
[11/15 05:37:04 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.29341204441673263
[11/15 05:43:19 visual_prompt]: Epoch 51 / 100: avg data time: 1.04e+01, avg batch time: 10.7109, average train loss: 0.7020
[11/15 05:44:02 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1536, average loss: 0.6983
[11/15 05:44:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.01	
[11/15 05:44:02 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.28479327524001635
[11/15 05:50:17 visual_prompt]: Epoch 52 / 100: avg data time: 1.04e+01, avg batch time: 10.7027, average train loss: 0.7202
[11/15 05:51:00 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1531, average loss: 0.6919
[11/15 05:51:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.29	
[11/15 05:51:00 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.2761321158169134
[11/15 05:57:14 visual_prompt]: Epoch 53 / 100: avg data time: 1.04e+01, avg batch time: 10.7026, average train loss: 0.6958
[11/15 05:57:57 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1536, average loss: 0.6887
[11/15 05:57:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.77	
[11/15 05:57:57 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.2674391184360313
[11/15 06:04:11 visual_prompt]: Epoch 54 / 100: avg data time: 1.03e+01, avg batch time: 10.6619, average train loss: 0.6984
[11/15 06:04:53 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1536, average loss: 0.6936
[11/15 06:04:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.60	
[11/15 06:04:53 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.2587248741756253
[11/15 06:11:08 visual_prompt]: Epoch 55 / 100: avg data time: 1.04e+01, avg batch time: 10.7019, average train loss: 0.7082
[11/15 06:11:50 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1559, average loss: 0.6921
[11/15 06:11:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.05	
[11/15 06:11:50 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.25
[11/15 06:18:04 visual_prompt]: Epoch 56 / 100: avg data time: 1.03e+01, avg batch time: 10.6838, average train loss: 0.7028
[11/15 06:18:47 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1539, average loss: 0.6929
[11/15 06:18:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.44	
[11/15 06:18:47 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.24127512582437483
[11/15 06:25:01 visual_prompt]: Epoch 57 / 100: avg data time: 1.03e+01, avg batch time: 10.6676, average train loss: 0.7105
[11/15 06:25:43 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1531, average loss: 0.7120
[11/15 06:25:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 40.69	
[11/15 06:25:43 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.23256088156396867
[11/15 06:31:59 visual_prompt]: Epoch 58 / 100: avg data time: 1.04e+01, avg batch time: 10.7392, average train loss: 0.7085
[11/15 06:32:42 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1532, average loss: 0.7202
[11/15 06:32:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.54	
[11/15 06:32:42 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.22386788418308667
[11/15 06:38:57 visual_prompt]: Epoch 59 / 100: avg data time: 1.04e+01, avg batch time: 10.7114, average train loss: 0.7045
[11/15 06:39:40 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1543, average loss: 0.6884
[11/15 06:39:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.89	
[11/15 06:39:40 visual_prompt]: Best epoch 59: best metric: -0.688
[11/15 06:39:40 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.2152067247599837
[11/15 06:45:54 visual_prompt]: Epoch 60 / 100: avg data time: 1.03e+01, avg batch time: 10.6795, average train loss: 0.7066
[11/15 06:46:36 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1580, average loss: 0.7677
[11/15 06:46:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.61	
[11/15 06:46:36 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.20658795558326742
[11/15 06:52:51 visual_prompt]: Epoch 61 / 100: avg data time: 1.03e+01, avg batch time: 10.6989, average train loss: 0.7072
[11/15 06:53:34 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1533, average loss: 0.7008
[11/15 06:53:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.03	
[11/15 06:53:34 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.1980220772955602
[11/15 06:59:49 visual_prompt]: Epoch 62 / 100: avg data time: 1.04e+01, avg batch time: 10.7181, average train loss: 0.6969
[11/15 07:00:32 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1531, average loss: 0.6883
[11/15 07:00:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.55	
[11/15 07:00:32 visual_prompt]: Best epoch 62: best metric: -0.688
[11/15 07:00:32 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.1895195261000831
[11/15 07:06:47 visual_prompt]: Epoch 63 / 100: avg data time: 1.04e+01, avg batch time: 10.7217, average train loss: 0.6949
[11/15 07:07:30 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1533, average loss: 0.6899
[11/15 07:07:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 44.08	
[11/15 07:07:30 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.18109066104575022
[11/15 07:13:44 visual_prompt]: Epoch 64 / 100: avg data time: 1.03e+01, avg batch time: 10.6920, average train loss: 0.6963
[11/15 07:14:27 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1560, average loss: 0.7012
[11/15 07:14:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.04	
[11/15 07:14:27 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.17274575140626316
[11/15 07:20:42 visual_prompt]: Epoch 65 / 100: avg data time: 1.04e+01, avg batch time: 10.7093, average train loss: 0.7071
[11/15 07:21:25 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1531, average loss: 0.6883
[11/15 07:21:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.24	
[11/15 07:21:25 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.16449496416858284
[11/15 07:27:40 visual_prompt]: Epoch 66 / 100: avg data time: 1.04e+01, avg batch time: 10.6996, average train loss: 0.6949
[11/15 07:28:23 visual_prompt]: Inference (val):avg data time: 3.44e-05, avg batch time: 0.1533, average loss: 0.6882
[11/15 07:28:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.68	
[11/15 07:28:23 visual_prompt]: Best epoch 66: best metric: -0.688
[11/15 07:28:23 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.15634835164602198
[11/15 07:34:37 visual_prompt]: Epoch 67 / 100: avg data time: 1.03e+01, avg batch time: 10.6970, average train loss: 0.7008
[11/15 07:35:20 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1534, average loss: 0.7018
[11/15 07:35:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.74	
[11/15 07:35:20 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.14831583923105
[11/15 07:41:36 visual_prompt]: Epoch 68 / 100: avg data time: 1.04e+01, avg batch time: 10.7410, average train loss: 0.6926
[11/15 07:42:19 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1552, average loss: 0.6926
[11/15 07:42:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.18	
[11/15 07:42:19 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.14040721330273062
[11/15 07:48:34 visual_prompt]: Epoch 69 / 100: avg data time: 1.04e+01, avg batch time: 10.7048, average train loss: 0.6953
[11/15 07:49:17 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1533, average loss: 0.7034
[11/15 07:49:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 62.98	
[11/15 07:49:17 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.13263210930352737
[11/15 07:55:32 visual_prompt]: Epoch 70 / 100: avg data time: 1.04e+01, avg batch time: 10.7129, average train loss: 0.6957
[11/15 07:56:14 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1571, average loss: 0.6884
[11/15 07:56:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.99	
[11/15 07:56:14 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.12500000000000006
[11/15 08:02:29 visual_prompt]: Epoch 71 / 100: avg data time: 1.03e+01, avg batch time: 10.6947, average train loss: 0.6932
[11/15 08:03:11 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1532, average loss: 0.6926
[11/15 08:03:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.47	rocauc: 52.23	
[11/15 08:03:11 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.1175201839416988
[11/15 08:09:27 visual_prompt]: Epoch 72 / 100: avg data time: 1.04e+01, avg batch time: 10.7224, average train loss: 0.6987
[11/15 08:10:10 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1552, average loss: 0.6891
[11/15 08:10:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.98	
[11/15 08:10:10 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.11020177413231333
[11/15 08:16:25 visual_prompt]: Epoch 73 / 100: avg data time: 1.04e+01, avg batch time: 10.7154, average train loss: 0.6989
[11/15 08:17:08 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1532, average loss: 0.6948
[11/15 08:17:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.18	
[11/15 08:17:08 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.10305368692688174
[11/15 08:23:23 visual_prompt]: Epoch 74 / 100: avg data time: 1.04e+01, avg batch time: 10.7178, average train loss: 0.6921
[11/15 08:24:06 visual_prompt]: Inference (val):avg data time: 3.43e-05, avg batch time: 0.1537, average loss: 0.7189
[11/15 08:24:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.34	
[11/15 08:24:06 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.09608463116858543
[11/15 08:30:21 visual_prompt]: Epoch 75 / 100: avg data time: 1.04e+01, avg batch time: 10.7141, average train loss: 0.6924
[11/15 08:31:04 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1535, average loss: 0.7010
[11/15 08:31:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.33	
[11/15 08:31:04 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.08930309757836516
[11/15 08:37:18 visual_prompt]: Epoch 76 / 100: avg data time: 1.03e+01, avg batch time: 10.6839, average train loss: 0.6945
[11/15 08:38:01 visual_prompt]: Inference (val):avg data time: 3.46e-05, avg batch time: 0.1535, average loss: 0.7319
[11/15 08:38:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.87	
[11/15 08:38:01 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.08271734841028552
[11/15 08:44:16 visual_prompt]: Epoch 77 / 100: avg data time: 1.04e+01, avg batch time: 10.7276, average train loss: 0.6996
[11/15 08:44:59 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1530, average loss: 0.6890
[11/15 08:44:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.55	
[11/15 08:44:59 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.07633540738525066
[11/15 08:51:13 visual_prompt]: Epoch 78 / 100: avg data time: 1.03e+01, avg batch time: 10.6842, average train loss: 0.6908
[11/15 08:51:55 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1545, average loss: 0.6883
[11/15 08:51:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.05	
[11/15 08:51:55 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.07016504991533726
[11/15 08:58:09 visual_prompt]: Epoch 79 / 100: avg data time: 1.03e+01, avg batch time: 10.6801, average train loss: 0.6956
[11/15 08:58:52 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1543, average loss: 0.7034
[11/15 08:58:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.56	
[11/15 08:58:52 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.06421379363065141
[11/15 09:05:08 visual_prompt]: Epoch 80 / 100: avg data time: 1.04e+01, avg batch time: 10.7323, average train loss: 0.7069
[11/15 09:05:50 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1535, average loss: 0.6901
[11/15 09:05:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.64	
[11/15 09:05:50 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.058488889220255524
[11/15 09:12:06 visual_prompt]: Epoch 81 / 100: avg data time: 1.04e+01, avg batch time: 10.7254, average train loss: 0.7002
[11/15 09:12:49 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1570, average loss: 0.6958
[11/15 09:12:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.89	
[11/15 09:12:49 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.052997311598319524
[11/15 09:19:05 visual_prompt]: Epoch 82 / 100: avg data time: 1.04e+01, avg batch time: 10.7439, average train loss: 0.6945
[11/15 09:19:48 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1535, average loss: 0.6901
[11/15 09:19:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.80	
[11/15 09:19:48 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.047745751406263165
[11/15 09:26:03 visual_prompt]: Epoch 83 / 100: avg data time: 1.04e+01, avg batch time: 10.7183, average train loss: 0.6925
[11/15 09:26:46 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1545, average loss: 0.6934
[11/15 09:26:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.64	
[11/15 09:26:46 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.042740606861239594
[11/15 09:33:02 visual_prompt]: Epoch 84 / 100: avg data time: 1.04e+01, avg batch time: 10.7366, average train loss: 0.6917
[11/15 09:33:45 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1569, average loss: 0.6893
[11/15 09:33:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.63	
[11/15 09:33:45 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.03798797596089351
[11/15 09:40:24 visual_prompt]: Epoch 85 / 100: avg data time: 1.11e+01, avg batch time: 11.4117, average train loss: 0.6914
[11/15 09:41:09 visual_prompt]: Inference (val):avg data time: 3.93e-05, avg batch time: 0.1543, average loss: 0.6924
[11/15 09:41:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.69	
[11/15 09:41:09 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.03349364905389032
[11/15 09:48:08 visual_prompt]: Epoch 86 / 100: avg data time: 1.16e+01, avg batch time: 11.9670, average train loss: 0.6895
[11/15 09:49:01 visual_prompt]: Inference (val):avg data time: 4.23e-05, avg batch time: 0.1556, average loss: 0.6902
[11/15 09:49:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.46	
[11/15 09:49:01 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.029263101785268253
[11/15 09:56:38 visual_prompt]: Epoch 87 / 100: avg data time: 1.27e+01, avg batch time: 13.0486, average train loss: 0.6897
[11/15 09:57:28 visual_prompt]: Inference (val):avg data time: 4.28e-05, avg batch time: 0.1553, average loss: 0.6883
[11/15 09:57:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.64	
[11/15 09:57:28 visual_prompt]: Stopping early.
[11/15 09:57:29 visual_prompt]: Rank of current process: 0. World size: 1
[11/15 09:57:29 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/15 09:57:29 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/15 09:57:29 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/15 09:57:29 visual_prompt]: Training with config:
[11/15 09:57:29 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr0.5_wd0.001/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/15 09:57:29 visual_prompt]: Loading training data...
[11/15 09:57:29 visual_prompt]: Constructing mammo-cbis dataset train...
[11/15 09:57:29 visual_prompt]: Loading validation data...
[11/15 09:57:29 visual_prompt]: Constructing mammo-cbis dataset val...
[11/15 09:57:29 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[11/15 09:57:32 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[11/15 09:57:32 visual_prompt]: tuned percent:0.536
[11/15 09:57:32 visual_prompt]: Device used for model: 0
[11/15 09:57:32 visual_prompt]: Setting up Evaluator...
[11/15 09:57:32 visual_prompt]: Setting up Trainer...
[11/15 09:57:32 visual_prompt]: 	Setting up the optimizer...
[11/15 09:57:32 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/15 10:04:24 visual_prompt]: Epoch 1 / 100: avg data time: 1.14e+01, avg batch time: 11.7765, average train loss: 1.4017
[11/15 10:05:07 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1554, average loss: 1.2969
[11/15 10:05:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[11/15 10:05:07 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.05
[11/15 10:12:10 visual_prompt]: Epoch 2 / 100: avg data time: 1.17e+01, avg batch time: 12.0577, average train loss: 1.8435
[11/15 10:13:02 visual_prompt]: Inference (val):avg data time: 3.67e-05, avg batch time: 0.1556, average loss: 0.6906
[11/15 10:13:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.44	
[11/15 10:13:02 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.1
[11/15 10:20:41 visual_prompt]: Epoch 3 / 100: avg data time: 1.28e+01, avg batch time: 13.1187, average train loss: 0.7094
[11/15 10:21:31 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.1564, average loss: 0.6943
[11/15 10:21:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.27	
[11/15 10:21:31 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.15
[11/15 10:28:11 visual_prompt]: Epoch 4 / 100: avg data time: 1.11e+01, avg batch time: 11.4255, average train loss: 0.7023
[11/15 10:28:57 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1553, average loss: 0.6986
[11/15 10:28:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.85	
[11/15 10:28:57 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.2
[11/15 10:35:49 visual_prompt]: Epoch 5 / 100: avg data time: 1.14e+01, avg batch time: 11.7691, average train loss: 0.7469
[11/15 10:36:35 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1557, average loss: 0.8048
[11/15 10:36:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.50	
[11/15 10:36:35 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.25
[11/15 10:44:03 visual_prompt]: Epoch 6 / 100: avg data time: 1.24e+01, avg batch time: 12.7942, average train loss: 0.7441
[11/15 10:44:56 visual_prompt]: Inference (val):avg data time: 4.07e-05, avg batch time: 0.1578, average loss: 0.7027
[11/15 10:44:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.57	
[11/15 10:44:56 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.3
[11/15 10:52:34 visual_prompt]: Epoch 7 / 100: avg data time: 1.27e+01, avg batch time: 13.1004, average train loss: 0.7830
[11/15 10:53:24 visual_prompt]: Inference (val):avg data time: 3.67e-05, avg batch time: 0.1557, average loss: 0.7193
[11/15 10:53:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.11	
[11/15 10:53:24 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.35
[11/15 11:00:04 visual_prompt]: Epoch 8 / 100: avg data time: 1.11e+01, avg batch time: 11.4094, average train loss: 0.7786
[11/15 11:00:48 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1549, average loss: 0.6903
[11/15 11:00:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.47	rocauc: 58.96	
[11/15 11:00:48 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.4
[11/15 11:08:20 visual_prompt]: Epoch 9 / 100: avg data time: 1.25e+01, avg batch time: 12.9097, average train loss: 0.7408
[11/15 11:09:14 visual_prompt]: Inference (val):avg data time: 3.84e-05, avg batch time: 0.1584, average loss: 0.7273
[11/15 11:09:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.79	
[11/15 11:09:14 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.45
[11/15 11:16:52 visual_prompt]: Epoch 10 / 100: avg data time: 1.28e+01, avg batch time: 13.1083, average train loss: 0.6953
[11/15 11:17:40 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1588, average loss: 0.7790
[11/15 11:17:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 63.19	
[11/15 11:17:40 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.5
[11/15 11:24:21 visual_prompt]: Epoch 11 / 100: avg data time: 1.11e+01, avg batch time: 11.4476, average train loss: 0.7582
[11/15 11:25:09 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.1555, average loss: 0.7374
[11/15 11:25:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.75	
[11/15 11:25:09 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.49984770675477397
[11/15 11:32:02 visual_prompt]: Epoch 12 / 100: avg data time: 1.15e+01, avg batch time: 11.8145, average train loss: 0.7390
[11/15 11:32:51 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.1559, average loss: 0.6723
[11/15 11:32:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 64.70	
[11/15 11:32:51 visual_prompt]: Best epoch 12: best metric: -0.672
[11/15 11:32:51 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.49939101256495605
[11/15 11:40:36 visual_prompt]: Epoch 13 / 100: avg data time: 1.29e+01, avg batch time: 13.2764, average train loss: 0.7260
[11/15 11:41:29 visual_prompt]: Inference (val):avg data time: 3.99e-05, avg batch time: 0.1575, average loss: 0.7644
[11/15 11:41:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.44	
[11/15 11:41:29 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.4986304738420683
[11/15 11:48:55 visual_prompt]: Epoch 14 / 100: avg data time: 1.24e+01, avg batch time: 12.7421, average train loss: 0.7721
[11/15 11:49:42 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.1557, average loss: 0.7254
[11/15 11:49:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.20	
[11/15 11:49:42 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.4975670171853926
[11/15 11:56:38 visual_prompt]: Epoch 15 / 100: avg data time: 1.15e+01, avg batch time: 11.8918, average train loss: 0.7794
[11/15 11:57:23 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.1558, average loss: 0.7724
[11/15 11:57:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.70	
[11/15 11:57:23 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.49620193825305203
[11/15 12:05:09 visual_prompt]: Epoch 16 / 100: avg data time: 1.30e+01, avg batch time: 13.3156, average train loss: 0.7152
[11/15 12:06:04 visual_prompt]: Inference (val):avg data time: 4.01e-05, avg batch time: 0.1560, average loss: 0.9232
[11/15 12:06:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.07	
[11/15 12:06:04 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.4945369001834514
[11/15 12:13:32 visual_prompt]: Epoch 17 / 100: avg data time: 1.24e+01, avg batch time: 12.7916, average train loss: 0.8351
[11/15 12:14:18 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1556, average loss: 0.7152
[11/15 12:14:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.95	
[11/15 12:14:18 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.4925739315689991
[11/15 12:20:58 visual_prompt]: Epoch 18 / 100: avg data time: 1.11e+01, avg batch time: 11.4189, average train loss: 0.7349
[11/15 12:21:47 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1562, average loss: 0.6877
[11/15 12:21:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 65.39	
[11/15 12:21:47 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.4903154239845797
[11/15 12:28:34 visual_prompt]: Epoch 19 / 100: avg data time: 1.12e+01, avg batch time: 11.6022, average train loss: 0.6876
[11/15 12:29:26 visual_prompt]: Inference (val):avg data time: 3.66e-05, avg batch time: 0.1559, average loss: 0.7146
[11/15 12:29:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.99	
[11/15 12:29:26 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.4877641290737884
[11/15 12:37:17 visual_prompt]: Epoch 20 / 100: avg data time: 1.31e+01, avg batch time: 13.4546, average train loss: 0.6929
[11/15 12:38:09 visual_prompt]: Inference (val):avg data time: 3.55e-05, avg batch time: 0.1557, average loss: 0.7547
[11/15 12:38:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 62.23	
[11/15 12:38:09 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.4849231551964771
[11/15 12:45:22 visual_prompt]: Epoch 21 / 100: avg data time: 1.20e+01, avg batch time: 12.3487, average train loss: 0.6971
[11/15 12:46:08 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1558, average loss: 0.6779
[11/15 12:46:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.22	
[11/15 12:46:08 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.48179596364169686
[11/15 12:53:08 visual_prompt]: Epoch 22 / 100: avg data time: 1.16e+01, avg batch time: 12.0055, average train loss: 0.7026
[11/15 12:54:03 visual_prompt]: Inference (val):avg data time: 4.21e-05, avg batch time: 0.1554, average loss: 0.6707
[11/15 12:54:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 64.15	
[11/15 12:54:03 visual_prompt]: Best epoch 22: best metric: -0.671
[11/15 12:54:03 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.4783863644106502
[11/15 13:01:53 visual_prompt]: Epoch 23 / 100: avg data time: 1.31e+01, avg batch time: 13.4350, average train loss: 0.7059
[11/15 13:02:45 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.1560, average loss: 0.6878
[11/15 13:02:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.88	
[11/15 13:02:45 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.47469851157479176
[11/15 13:09:34 visual_prompt]: Epoch 24 / 100: avg data time: 1.13e+01, avg batch time: 11.7037, average train loss: 0.7378
[11/15 13:10:18 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1551, average loss: 0.6878
[11/15 13:10:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.27	
[11/15 13:10:18 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.47073689821473175
[11/15 13:17:07 visual_prompt]: Epoch 25 / 100: avg data time: 1.13e+01, avg batch time: 11.6788, average train loss: 0.6947
[11/15 13:17:53 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1554, average loss: 0.6856
[11/15 13:17:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.60	
[11/15 13:17:53 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.4665063509461097
[11/15 13:25:35 visual_prompt]: Epoch 26 / 100: avg data time: 1.28e+01, avg batch time: 13.2035, average train loss: 0.7003
[11/15 13:26:30 visual_prompt]: Inference (val):avg data time: 3.49e-05, avg batch time: 0.1591, average loss: 0.7054
[11/15 13:26:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.73	
[11/15 13:26:30 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.46201202403910646
[11/15 13:33:55 visual_prompt]: Epoch 27 / 100: avg data time: 1.24e+01, avg batch time: 12.7169, average train loss: 0.7031
[11/15 13:34:43 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1561, average loss: 0.6845
[11/15 13:34:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.58	
[11/15 13:34:44 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.4572593931387604
[11/15 13:41:18 visual_prompt]: Epoch 28 / 100: avg data time: 1.09e+01, avg batch time: 11.2747, average train loss: 0.7061
[11/15 13:42:09 visual_prompt]: Inference (val):avg data time: 3.64e-05, avg batch time: 0.1589, average loss: 0.6957
[11/15 13:42:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.01	
[11/15 13:42:09 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.45225424859373686
[11/15 13:50:02 visual_prompt]: Epoch 29 / 100: avg data time: 1.32e+01, avg batch time: 13.5085, average train loss: 0.6989
[11/15 13:50:55 visual_prompt]: Inference (val):avg data time: 3.93e-05, avg batch time: 0.1552, average loss: 0.6873
[11/15 13:50:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.01	
[11/15 13:50:55 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.44700268840168045
[11/15 13:58:07 visual_prompt]: Epoch 30 / 100: avg data time: 1.20e+01, avg batch time: 12.3465, average train loss: 0.6990
[11/15 13:58:54 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1575, average loss: 0.7120
[11/15 13:58:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.52	
[11/15 13:58:54 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.4415111107797445
[11/15 14:05:33 visual_prompt]: Epoch 31 / 100: avg data time: 1.10e+01, avg batch time: 11.4044, average train loss: 0.6939
[11/15 14:06:24 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.1564, average loss: 0.7452
[11/15 14:06:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.77	
[11/15 14:06:24 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.43578620636934856
[11/15 14:13:12 visual_prompt]: Epoch 32 / 100: avg data time: 1.13e+01, avg batch time: 11.6426, average train loss: 0.7034
[11/15 14:14:03 visual_prompt]: Inference (val):avg data time: 3.62e-05, avg batch time: 0.1569, average loss: 0.7120
[11/15 14:14:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.90	
[11/15 14:14:03 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.42983495008466277
[11/15 14:21:51 visual_prompt]: Epoch 33 / 100: avg data time: 1.30e+01, avg batch time: 13.3528, average train loss: 0.6922
[11/15 14:22:43 visual_prompt]: Inference (val):avg data time: 3.84e-05, avg batch time: 0.1561, average loss: 0.6834
[11/15 14:22:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 57.22	
[11/15 14:22:43 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.4236645926147493
[11/15 14:29:45 visual_prompt]: Epoch 34 / 100: avg data time: 1.17e+01, avg batch time: 12.0565, average train loss: 0.6974
[11/15 14:30:29 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1562, average loss: 0.6864
[11/15 14:30:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.89	
[11/15 14:30:29 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.41728265158971456
[11/15 14:37:38 visual_prompt]: Epoch 35 / 100: avg data time: 1.19e+01, avg batch time: 12.2372, average train loss: 0.7109
[11/15 14:38:33 visual_prompt]: Inference (val):avg data time: 5.20e-05, avg batch time: 0.1551, average loss: 0.6969
[11/15 14:38:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.60	
[11/15 14:38:33 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.4106969024216348
[11/15 14:46:20 visual_prompt]: Epoch 36 / 100: avg data time: 1.30e+01, avg batch time: 13.3553, average train loss: 0.6991
[11/15 14:47:11 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1596, average loss: 0.6849
[11/15 14:47:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.47	
[11/15 14:47:11 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.40391536883141455
[11/15 14:53:56 visual_prompt]: Epoch 37 / 100: avg data time: 1.12e+01, avg batch time: 11.5715, average train loss: 0.6925
[11/15 14:54:39 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1556, average loss: 0.7312
[11/15 14:54:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.89	
[11/15 14:54:39 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.3969463130731183
[11/15 15:01:29 visual_prompt]: Epoch 38 / 100: avg data time: 1.14e+01, avg batch time: 11.7170, average train loss: 0.6939
[11/15 15:02:16 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1563, average loss: 0.7198
[11/15 15:02:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.59	
[11/15 15:02:16 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.3897982258676867
[11/15 15:09:59 visual_prompt]: Epoch 39 / 100: avg data time: 1.29e+01, avg batch time: 13.2113, average train loss: 0.7153
[11/15 15:10:52 visual_prompt]: Inference (val):avg data time: 4.34e-05, avg batch time: 0.1583, average loss: 0.6967
[11/15 15:10:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.74	
[11/15 15:10:52 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.3824798160583012
[11/15 15:18:06 visual_prompt]: Epoch 40 / 100: avg data time: 1.21e+01, avg batch time: 12.4110, average train loss: 0.6975
[11/15 15:18:52 visual_prompt]: Inference (val):avg data time: 3.56e-05, avg batch time: 0.1551, average loss: 0.6774
[11/15 15:18:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 59.06	
[11/15 15:18:52 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.375
[11/15 15:25:14 visual_prompt]: Epoch 41 / 100: avg data time: 1.05e+01, avg batch time: 10.9020, average train loss: 0.7112
[11/15 15:25:57 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1589, average loss: 0.7017
[11/15 15:25:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.43	
[11/15 15:25:57 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.3673678906964727
[11/15 15:33:39 visual_prompt]: Epoch 42 / 100: avg data time: 1.28e+01, avg batch time: 13.1811, average train loss: 0.7149
[11/15 15:34:31 visual_prompt]: Inference (val):avg data time: 4.00e-05, avg batch time: 0.1552, average loss: 0.7027
[11/15 15:34:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.92	
[11/15 15:34:31 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.35959278669726935
[11/15 15:41:57 visual_prompt]: Epoch 43 / 100: avg data time: 1.24e+01, avg batch time: 12.7198, average train loss: 0.7753
[11/15 15:42:43 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.1550, average loss: 0.7030
[11/15 15:42:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.01	
[11/15 15:42:43 visual_prompt]: Stopping early.
[11/15 15:42:44 visual_prompt]: Rank of current process: 0. World size: 1
[11/15 15:42:44 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/15 15:42:44 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/15 15:42:44 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/15 15:42:44 visual_prompt]: Training with config:
[11/15 15:42:44 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr0.5_wd0.0001/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/15 15:42:44 visual_prompt]: Loading training data...
[11/15 15:42:44 visual_prompt]: Constructing mammo-cbis dataset train...
[11/15 15:42:44 visual_prompt]: Loading validation data...
[11/15 15:42:44 visual_prompt]: Constructing mammo-cbis dataset val...
[11/15 15:42:44 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[11/15 15:42:50 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[11/15 15:42:50 visual_prompt]: tuned percent:0.536
[11/15 15:42:50 visual_prompt]: Device used for model: 0
[11/15 15:42:50 visual_prompt]: Setting up Evaluator...
[11/15 15:42:50 visual_prompt]: Setting up Trainer...
[11/15 15:42:50 visual_prompt]: 	Setting up the optimizer...
[11/15 15:42:50 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/15 15:49:31 visual_prompt]: Epoch 1 / 100: avg data time: 1.11e+01, avg batch time: 11.4550, average train loss: 1.4017
[11/15 15:50:17 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1558, average loss: 1.2969
[11/15 15:50:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[11/15 15:50:17 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.05
[11/15 15:57:17 visual_prompt]: Epoch 2 / 100: avg data time: 1.16e+01, avg batch time: 11.9779, average train loss: 1.8453
[11/15 15:58:08 visual_prompt]: Inference (val):avg data time: 4.13e-05, avg batch time: 0.1556, average loss: 0.6906
[11/15 15:58:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.38	
[11/15 15:58:08 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.1
[11/15 16:05:55 visual_prompt]: Epoch 3 / 100: avg data time: 1.30e+01, avg batch time: 13.3274, average train loss: 0.7104
[11/15 16:06:46 visual_prompt]: Inference (val):avg data time: 3.47e-05, avg batch time: 0.1565, average loss: 0.6945
[11/15 16:06:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.29	
[11/15 16:06:46 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.15
[11/15 16:13:58 visual_prompt]: Epoch 4 / 100: avg data time: 1.20e+01, avg batch time: 12.3197, average train loss: 0.7037
[11/15 16:14:43 visual_prompt]: Inference (val):avg data time: 3.75e-05, avg batch time: 0.1553, average loss: 0.6968
[11/15 16:14:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.67	
[11/15 16:14:43 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.2
[11/15 16:21:11 visual_prompt]: Epoch 5 / 100: avg data time: 1.07e+01, avg batch time: 11.0720, average train loss: 0.7500
[11/15 16:22:01 visual_prompt]: Inference (val):avg data time: 4.28e-05, avg batch time: 0.1554, average loss: 0.8080
[11/15 16:22:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.01	
[11/15 16:22:01 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.25
[11/15 16:29:43 visual_prompt]: Epoch 6 / 100: avg data time: 1.28e+01, avg batch time: 13.2034, average train loss: 0.7462
[11/15 16:30:36 visual_prompt]: Inference (val):avg data time: 3.98e-05, avg batch time: 0.1556, average loss: 0.7135
[11/15 16:30:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.93	
[11/15 16:30:36 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.3
[11/15 16:37:58 visual_prompt]: Epoch 7 / 100: avg data time: 1.23e+01, avg batch time: 12.6273, average train loss: 0.7995
[11/15 16:38:46 visual_prompt]: Inference (val):avg data time: 3.73e-05, avg batch time: 0.1546, average loss: 0.7164
[11/15 16:38:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.53	rocauc: 59.40	
[11/15 16:38:46 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.35
[11/15 16:45:24 visual_prompt]: Epoch 8 / 100: avg data time: 1.10e+01, avg batch time: 11.3769, average train loss: 0.7933
[11/15 16:46:10 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1555, average loss: 0.7115
[11/15 16:46:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 48.37	rocauc: 59.75	
[11/15 16:46:10 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.4
[11/15 16:52:50 visual_prompt]: Epoch 9 / 100: avg data time: 1.11e+01, avg batch time: 11.4173, average train loss: 0.7332
[11/15 16:53:40 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.1556, average loss: 0.6741
[11/15 16:53:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 61.36	
[11/15 16:53:40 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.45
[11/15 17:01:18 visual_prompt]: Epoch 10 / 100: avg data time: 1.27e+01, avg batch time: 13.0855, average train loss: 0.7151
[11/15 17:02:09 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.1555, average loss: 0.6899
[11/15 17:02:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 60.15	
[11/15 17:02:09 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.5
[11/15 17:09:13 visual_prompt]: Epoch 11 / 100: avg data time: 1.18e+01, avg batch time: 12.1130, average train loss: 0.7315
[11/15 17:09:59 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1597, average loss: 0.7185
[11/15 17:09:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 47.15	rocauc: 62.13	
[11/15 17:09:59 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.49984770675477397
[11/15 17:16:33 visual_prompt]: Epoch 12 / 100: avg data time: 1.09e+01, avg batch time: 11.2762, average train loss: 0.7214
[11/15 17:17:28 visual_prompt]: Inference (val):avg data time: 3.54e-05, avg batch time: 0.1556, average loss: 0.6694
[11/15 17:17:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 64.88	
[11/15 17:17:28 visual_prompt]: Best epoch 12: best metric: -0.669
[11/15 17:17:28 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.49939101256495605
[11/15 17:25:08 visual_prompt]: Epoch 13 / 100: avg data time: 1.28e+01, avg batch time: 13.1524, average train loss: 0.7061
[11/15 17:26:00 visual_prompt]: Inference (val):avg data time: 3.48e-05, avg batch time: 0.1560, average loss: 0.6514
[11/15 17:26:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 66.07	
[11/15 17:26:00 visual_prompt]: Best epoch 13: best metric: -0.651
[11/15 17:26:00 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.4986304738420683
[11/15 17:33:22 visual_prompt]: Epoch 14 / 100: avg data time: 1.23e+01, avg batch time: 12.6262, average train loss: 0.7379
[11/15 17:34:11 visual_prompt]: Inference (val):avg data time: 3.50e-05, avg batch time: 0.1589, average loss: 0.6531
[11/15 17:34:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 67.36	
[11/15 17:34:11 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.4975670171853926
[11/15 17:40:59 visual_prompt]: Epoch 15 / 100: avg data time: 1.13e+01, avg batch time: 11.6592, average train loss: 0.7558
[11/15 17:41:43 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.1555, average loss: 0.8857
[11/15 17:41:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 66.32	
[11/15 17:41:43 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.49620193825305203
[11/15 17:48:57 visual_prompt]: Epoch 16 / 100: avg data time: 1.20e+01, avg batch time: 12.4033, average train loss: 0.6961
[11/15 17:49:51 visual_prompt]: Inference (val):avg data time: 4.27e-05, avg batch time: 0.1560, average loss: 1.1060
[11/15 17:49:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 68.64	
[11/15 17:49:51 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.4945369001834514
[11/15 17:57:32 visual_prompt]: Epoch 17 / 100: avg data time: 1.28e+01, avg batch time: 13.1601, average train loss: 0.7790
[11/15 17:58:23 visual_prompt]: Inference (val):avg data time: 3.84e-05, avg batch time: 0.1561, average loss: 0.8006
[11/15 17:58:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 68.61	
[11/15 17:58:23 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.4925739315689991
[11/15 18:05:13 visual_prompt]: Epoch 18 / 100: avg data time: 1.14e+01, avg batch time: 11.7080, average train loss: 0.6780
[11/15 18:05:57 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.1560, average loss: 0.7981
[11/15 18:05:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 71.70	
[11/15 18:05:57 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.4903154239845797
[11/15 18:13:05 visual_prompt]: Epoch 19 / 100: avg data time: 1.19e+01, avg batch time: 12.2373, average train loss: 0.6478
[11/15 18:14:05 visual_prompt]: Inference (val):avg data time: 3.90e-05, avg batch time: 0.1549, average loss: 0.6321
[11/15 18:14:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 70.75	
[11/15 18:14:05 visual_prompt]: Best epoch 19: best metric: -0.632
[11/15 18:14:05 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.4877641290737884
[11/15 18:22:20 visual_prompt]: Epoch 20 / 100: avg data time: 1.38e+01, avg batch time: 14.1374, average train loss: 0.6462
[11/15 18:23:15 visual_prompt]: Inference (val):avg data time: 3.83e-05, avg batch time: 0.1548, average loss: 0.6470
[11/15 18:23:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 71.01	
[11/15 18:23:15 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.4849231551964771
[11/15 18:30:37 visual_prompt]: Epoch 21 / 100: avg data time: 1.23e+01, avg batch time: 12.6064, average train loss: 0.6687
[11/15 18:31:25 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1548, average loss: 0.6271
[11/15 18:31:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.89	rocauc: 71.64	
[11/15 18:31:25 visual_prompt]: Best epoch 21: best metric: -0.627
[11/15 18:31:25 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.48179596364169686
[11/15 18:38:43 visual_prompt]: Epoch 22 / 100: avg data time: 1.21e+01, avg batch time: 12.5035, average train loss: 0.7108
[11/15 18:39:34 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1551, average loss: 0.6187
[11/15 18:39:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 73.52	
[11/15 18:39:34 visual_prompt]: Best epoch 22: best metric: -0.619
[11/15 18:39:34 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.4783863644106502
[11/15 18:46:52 visual_prompt]: Epoch 23 / 100: avg data time: 1.21e+01, avg batch time: 12.5046, average train loss: 0.6203
[11/15 18:47:45 visual_prompt]: Inference (val):avg data time: 4.06e-05, avg batch time: 0.1546, average loss: 0.6928
[11/15 18:47:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 71.00	
[11/15 18:47:45 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.47469851157479176
[11/15 18:55:38 visual_prompt]: Epoch 24 / 100: avg data time: 1.31e+01, avg batch time: 13.5029, average train loss: 0.6369
[11/15 18:56:33 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1551, average loss: 0.6413
[11/15 18:56:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.89	rocauc: 71.59	
[11/15 18:56:33 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.47073689821473175
[11/15 19:03:46 visual_prompt]: Epoch 25 / 100: avg data time: 1.20e+01, avg batch time: 12.3848, average train loss: 0.6043
[11/15 19:04:35 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1583, average loss: 0.6300
[11/15 19:04:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.89	rocauc: 72.91	
[11/15 19:04:35 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.4665063509461097
[11/15 19:11:51 visual_prompt]: Epoch 26 / 100: avg data time: 1.21e+01, avg batch time: 12.4513, average train loss: 0.6790
[11/15 19:12:48 visual_prompt]: Inference (val):avg data time: 4.54e-05, avg batch time: 0.1579, average loss: 0.6311
[11/15 19:12:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 73.61	
[11/15 19:12:48 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.46201202403910646
[11/15 19:21:17 visual_prompt]: Epoch 27 / 100: avg data time: 1.42e+01, avg batch time: 14.5289, average train loss: 0.6128
[11/15 19:22:11 visual_prompt]: Inference (val):avg data time: 4.51e-05, avg batch time: 0.1574, average loss: 0.6411
[11/15 19:22:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 68.70	rocauc: 69.82	
[11/15 19:22:11 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.4572593931387604
[11/15 19:29:41 visual_prompt]: Epoch 28 / 100: avg data time: 1.25e+01, avg batch time: 12.8480, average train loss: 0.6404
[11/15 19:30:29 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.1584, average loss: 0.6662
[11/15 19:30:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 69.54	
[11/15 19:30:29 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.45225424859373686
[11/15 19:37:38 visual_prompt]: Epoch 29 / 100: avg data time: 1.19e+01, avg batch time: 12.2547, average train loss: 0.6202
[11/15 19:38:27 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.1549, average loss: 0.6265
[11/15 19:38:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.67	rocauc: 73.33	
[11/15 19:38:27 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.44700268840168045
[11/15 19:45:40 visual_prompt]: Epoch 30 / 100: avg data time: 1.20e+01, avg batch time: 12.3706, average train loss: 0.6009
[11/15 19:46:34 visual_prompt]: Inference (val):avg data time: 3.65e-05, avg batch time: 0.1568, average loss: 0.6312
[11/15 19:46:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.67	rocauc: 72.96	
[11/15 19:46:34 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.4415111107797445
[11/15 19:55:00 visual_prompt]: Epoch 31 / 100: avg data time: 1.41e+01, avg batch time: 14.4779, average train loss: 0.5962
[11/15 19:55:56 visual_prompt]: Inference (val):avg data time: 3.99e-05, avg batch time: 0.1552, average loss: 0.6883
[11/15 19:55:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.01	rocauc: 70.57	
[11/15 19:55:56 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.43578620636934856
[11/15 20:03:28 visual_prompt]: Epoch 32 / 100: avg data time: 1.26e+01, avg batch time: 12.9361, average train loss: 0.6577
[11/15 20:04:16 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.1546, average loss: 0.6057
[11/15 20:04:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 68.29	rocauc: 73.78	
[11/15 20:04:16 visual_prompt]: Best epoch 32: best metric: -0.606
[11/15 20:04:16 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.42983495008466277
[11/15 20:11:55 visual_prompt]: Epoch 33 / 100: avg data time: 1.27e+01, avg batch time: 13.0951, average train loss: 0.5876
[11/15 20:12:55 visual_prompt]: Inference (val):avg data time: 4.43e-05, avg batch time: 0.1542, average loss: 0.6279
[11/15 20:12:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 71.00	
[11/15 20:12:55 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.4236645926147493
[11/15 20:21:16 visual_prompt]: Epoch 34 / 100: avg data time: 1.39e+01, avg batch time: 14.2972, average train loss: 0.5687
[11/15 20:22:11 visual_prompt]: Inference (val):avg data time: 4.20e-05, avg batch time: 0.1540, average loss: 0.6274
[11/15 20:22:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 71.56	
[11/15 20:22:11 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.41728265158971456
[11/15 20:29:55 visual_prompt]: Epoch 35 / 100: avg data time: 1.29e+01, avg batch time: 13.2443, average train loss: 0.6282
[11/15 20:30:44 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1535, average loss: 0.9541
[11/15 20:30:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.93	rocauc: 70.70	
[11/15 20:30:44 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.4106969024216348
[11/15 20:38:15 visual_prompt]: Epoch 36 / 100: avg data time: 1.25e+01, avg batch time: 12.8931, average train loss: 0.6098
[11/15 20:39:04 visual_prompt]: Inference (val):avg data time: 3.47e-05, avg batch time: 0.1534, average loss: 0.7584
[11/15 20:39:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 68.23	
[11/15 20:39:04 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.40391536883141455
[11/15 20:46:43 visual_prompt]: Epoch 37 / 100: avg data time: 1.28e+01, avg batch time: 13.1092, average train loss: 0.5591
[11/15 20:47:36 visual_prompt]: Inference (val):avg data time: 4.43e-05, avg batch time: 0.1558, average loss: 0.6463
[11/15 20:47:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 70.33	rocauc: 72.83	
[11/15 20:47:36 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.3969463130731183
[11/15 20:55:36 visual_prompt]: Epoch 38 / 100: avg data time: 1.33e+01, avg batch time: 13.7035, average train loss: 0.5436
[11/15 20:56:27 visual_prompt]: Inference (val):avg data time: 3.67e-05, avg batch time: 0.1544, average loss: 0.6902
[11/15 20:56:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 66.57	
[11/15 20:56:27 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.3897982258676867
[11/15 21:03:50 visual_prompt]: Epoch 39 / 100: avg data time: 1.23e+01, avg batch time: 12.6532, average train loss: 0.5976
[11/15 21:04:38 visual_prompt]: Inference (val):avg data time: 3.76e-05, avg batch time: 0.1536, average loss: 0.6310
[11/15 21:04:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 68.29	rocauc: 71.32	
[11/15 21:04:38 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.3824798160583012
[11/15 21:12:29 visual_prompt]: Epoch 40 / 100: avg data time: 1.31e+01, avg batch time: 13.4708, average train loss: 0.5354
[11/15 21:13:25 visual_prompt]: Inference (val):avg data time: 4.96e-05, avg batch time: 0.1547, average loss: 0.7088
[11/15 21:13:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 71.61	
[11/15 21:13:25 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.375
[11/15 21:21:35 visual_prompt]: Epoch 41 / 100: avg data time: 1.37e+01, avg batch time: 14.0178, average train loss: 0.5344
[11/15 21:22:28 visual_prompt]: Inference (val):avg data time: 3.65e-05, avg batch time: 0.1539, average loss: 0.6715
[11/15 21:22:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 69.46	
[11/15 21:22:28 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.3673678906964727
[11/15 21:29:32 visual_prompt]: Epoch 42 / 100: avg data time: 1.17e+01, avg batch time: 12.0917, average train loss: 0.5389
[11/15 21:30:23 visual_prompt]: Inference (val):avg data time: 4.15e-05, avg batch time: 0.1542, average loss: 0.7421
[11/15 21:30:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.01	rocauc: 68.82	
[11/15 21:30:23 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.35959278669726935
[11/15 21:37:31 visual_prompt]: Epoch 43 / 100: avg data time: 1.19e+01, avg batch time: 12.2337, average train loss: 0.5825
[11/15 21:38:23 visual_prompt]: Inference (val):avg data time: 3.73e-05, avg batch time: 0.1540, average loss: 0.6578
[11/15 21:38:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 72.19	
[11/15 21:38:23 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.3516841607689501
[11/15 21:46:27 visual_prompt]: Epoch 44 / 100: avg data time: 1.35e+01, avg batch time: 13.8349, average train loss: 0.4990
[11/15 21:47:19 visual_prompt]: Inference (val):avg data time: 3.86e-05, avg batch time: 0.1537, average loss: 0.7739
[11/15 21:47:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.01	rocauc: 66.75	
[11/15 21:47:19 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.34365164835397805
[11/15 21:54:56 visual_prompt]: Epoch 45 / 100: avg data time: 1.27e+01, avg batch time: 13.0660, average train loss: 0.5031
[11/15 21:55:43 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.1540, average loss: 0.6776
[11/15 21:55:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 70.67	
[11/15 21:55:43 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.3355050358314172
[11/15 22:02:49 visual_prompt]: Epoch 46 / 100: avg data time: 1.18e+01, avg batch time: 12.1779, average train loss: 0.4840
[11/15 22:03:44 visual_prompt]: Inference (val):avg data time: 4.83e-05, avg batch time: 0.1542, average loss: 0.7482
[11/15 22:03:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 68.62	
[11/15 22:03:44 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.32725424859373686
[11/15 22:11:35 visual_prompt]: Epoch 47 / 100: avg data time: 1.31e+01, avg batch time: 13.4633, average train loss: 0.4917
[11/15 22:12:29 visual_prompt]: Inference (val):avg data time: 4.80e-05, avg batch time: 0.1542, average loss: 0.7499
[11/15 22:12:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 69.76	
[11/15 22:12:29 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.3189093389542498
[11/15 22:19:42 visual_prompt]: Epoch 48 / 100: avg data time: 1.20e+01, avg batch time: 12.3406, average train loss: 0.4815
[11/15 22:20:27 visual_prompt]: Inference (val):avg data time: 4.39e-05, avg batch time: 0.1534, average loss: 0.6951
[11/15 22:20:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 70.95	
[11/15 22:20:27 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.3104804738999169
[11/15 22:27:25 visual_prompt]: Epoch 49 / 100: avg data time: 1.16e+01, avg batch time: 11.9336, average train loss: 0.4496
[11/15 22:28:15 visual_prompt]: Inference (val):avg data time: 3.76e-05, avg batch time: 0.1553, average loss: 0.7907
[11/15 22:28:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 67.37	
[11/15 22:28:15 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.3019779227044398
[11/15 22:36:02 visual_prompt]: Epoch 50 / 100: avg data time: 1.30e+01, avg batch time: 13.3550, average train loss: 0.4801
[11/15 22:36:57 visual_prompt]: Inference (val):avg data time: 4.15e-05, avg batch time: 0.1540, average loss: 0.7508
[11/15 22:36:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 71.26	
[11/15 22:36:57 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.29341204441673263
[11/15 22:44:39 visual_prompt]: Epoch 51 / 100: avg data time: 1.29e+01, avg batch time: 13.2110, average train loss: 0.4521
[11/15 22:45:29 visual_prompt]: Inference (val):avg data time: 4.01e-05, avg batch time: 0.1537, average loss: 1.0014
[11/15 22:45:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 70.08	
[11/15 22:45:29 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.28479327524001635
[11/15 22:52:17 visual_prompt]: Epoch 52 / 100: avg data time: 1.13e+01, avg batch time: 11.6384, average train loss: 0.4526
[11/15 22:53:02 visual_prompt]: Inference (val):avg data time: 3.52e-05, avg batch time: 0.1537, average loss: 0.8328
[11/15 22:53:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 70.13	
[11/15 22:53:02 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.2761321158169134
[11/15 23:00:48 visual_prompt]: Epoch 53 / 100: avg data time: 1.29e+01, avg batch time: 13.2874, average train loss: 0.4216
[11/15 23:01:41 visual_prompt]: Inference (val):avg data time: 4.11e-05, avg batch time: 0.1538, average loss: 0.7859
[11/15 23:01:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 69.36	
[11/15 23:01:41 visual_prompt]: Stopping early.
[11/15 23:01:42 visual_prompt]: Rank of current process: 0. World size: 1
[11/15 23:01:42 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/15 23:01:42 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/15 23:01:42 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/15 23:01:42 visual_prompt]: Training with config:
[11/15 23:01:42 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr0.5_wd0.0/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/15 23:01:42 visual_prompt]: Loading training data...
[11/15 23:01:42 visual_prompt]: Constructing mammo-cbis dataset train...
[11/15 23:01:43 visual_prompt]: Loading validation data...
[11/15 23:01:43 visual_prompt]: Constructing mammo-cbis dataset val...
[11/15 23:01:43 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[11/15 23:01:53 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[11/15 23:01:53 visual_prompt]: tuned percent:0.536
[11/15 23:01:53 visual_prompt]: Device used for model: 0
[11/15 23:01:53 visual_prompt]: Setting up Evaluator...
[11/15 23:01:53 visual_prompt]: Setting up Trainer...
[11/15 23:01:53 visual_prompt]: 	Setting up the optimizer...
[11/15 23:01:53 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/15 23:09:32 visual_prompt]: Epoch 1 / 100: avg data time: 1.28e+01, avg batch time: 13.1010, average train loss: 1.4017
[11/15 23:10:22 visual_prompt]: Inference (val):avg data time: 3.32e-05, avg batch time: 0.1538, average loss: 1.2969
[11/15 23:10:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[11/15 23:10:22 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.05
[11/15 23:17:21 visual_prompt]: Epoch 2 / 100: avg data time: 1.16e+01, avg batch time: 11.9626, average train loss: 1.8455
[11/15 23:18:06 visual_prompt]: Inference (val):avg data time: 3.35e-05, avg batch time: 0.1535, average loss: 0.6907
[11/15 23:18:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.20	
[11/15 23:18:06 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.1
[11/15 23:25:29 visual_prompt]: Epoch 3 / 100: avg data time: 1.23e+01, avg batch time: 12.6481, average train loss: 0.7105
[11/15 23:26:23 visual_prompt]: Inference (val):avg data time: 4.54e-05, avg batch time: 0.1538, average loss: 0.6949
[11/15 23:26:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.20	
[11/15 23:26:23 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.15
[11/15 23:34:09 visual_prompt]: Epoch 4 / 100: avg data time: 1.30e+01, avg batch time: 13.3235, average train loss: 0.7042
[11/15 23:35:01 visual_prompt]: Inference (val):avg data time: 3.67e-05, avg batch time: 0.1537, average loss: 0.6947
[11/15 23:35:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.88	
[11/15 23:35:01 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.2
[11/15 23:42:05 visual_prompt]: Epoch 5 / 100: avg data time: 1.17e+01, avg batch time: 12.0960, average train loss: 0.7514
[11/15 23:42:50 visual_prompt]: Inference (val):avg data time: 3.92e-05, avg batch time: 0.1539, average loss: 0.8103
[11/15 23:42:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.07	
[11/15 23:42:50 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.25
[11/15 23:50:12 visual_prompt]: Epoch 6 / 100: avg data time: 1.23e+01, avg batch time: 12.6260, average train loss: 0.7477
[11/15 23:51:06 visual_prompt]: Inference (val):avg data time: 4.04e-05, avg batch time: 0.1536, average loss: 0.7125
[11/15 23:51:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.89	
[11/15 23:51:06 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.3
[11/15 23:58:51 visual_prompt]: Epoch 7 / 100: avg data time: 1.29e+01, avg batch time: 13.2690, average train loss: 0.8003
[11/15 23:59:42 visual_prompt]: Inference (val):avg data time: 4.05e-05, avg batch time: 0.1535, average loss: 0.7195
[11/15 23:59:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 44.72	rocauc: 59.23	
[11/15 23:59:42 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.35
[11/16 00:06:38 visual_prompt]: Epoch 8 / 100: avg data time: 1.15e+01, avg batch time: 11.8710, average train loss: 0.7903
[11/16 00:07:30 visual_prompt]: Inference (val):avg data time: 3.93e-05, avg batch time: 0.1577, average loss: 0.7154
[11/16 00:07:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 47.56	rocauc: 59.36	
[11/16 00:07:30 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.4
[11/16 00:14:30 visual_prompt]: Epoch 9 / 100: avg data time: 1.16e+01, avg batch time: 11.9973, average train loss: 0.7305
[11/16 00:15:21 visual_prompt]: Inference (val):avg data time: 4.42e-05, avg batch time: 0.1569, average loss: 0.6735
[11/16 00:15:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 60.91	
[11/16 00:15:21 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.45
[11/16 00:23:08 visual_prompt]: Epoch 10 / 100: avg data time: 1.30e+01, avg batch time: 13.3281, average train loss: 0.7154
[11/16 00:24:01 visual_prompt]: Inference (val):avg data time: 4.00e-05, avg batch time: 0.1571, average loss: 0.6920
[11/16 00:24:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 61.12	
[11/16 00:24:01 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.5
[11/16 00:31:19 visual_prompt]: Epoch 11 / 100: avg data time: 1.22e+01, avg batch time: 12.5313, average train loss: 0.7353
[11/16 00:32:05 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.1538, average loss: 0.7143
[11/16 00:32:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 53.25	rocauc: 61.93	
[11/16 00:32:05 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.49984770675477397
[11/16 00:39:18 visual_prompt]: Epoch 12 / 100: avg data time: 1.20e+01, avg batch time: 12.3596, average train loss: 0.7209
[11/16 00:40:12 visual_prompt]: Inference (val):avg data time: 4.45e-05, avg batch time: 0.1538, average loss: 0.6675
[11/16 00:40:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 64.67	
[11/16 00:40:12 visual_prompt]: Best epoch 12: best metric: -0.668
[11/16 00:40:12 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.49939101256495605
[11/16 00:47:59 visual_prompt]: Epoch 13 / 100: avg data time: 1.30e+01, avg batch time: 13.3447, average train loss: 0.7065
[11/16 00:48:50 visual_prompt]: Inference (val):avg data time: 3.70e-05, avg batch time: 0.1560, average loss: 0.6548
[11/16 00:48:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.54	rocauc: 66.39	
[11/16 00:48:50 visual_prompt]: Best epoch 13: best metric: -0.655
[11/16 00:48:50 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.4986304738420683
[11/16 00:55:36 visual_prompt]: Epoch 14 / 100: avg data time: 1.13e+01, avg batch time: 11.6055, average train loss: 0.7370
[11/16 00:56:25 visual_prompt]: Inference (val):avg data time: 3.91e-05, avg batch time: 0.1541, average loss: 0.6551
[11/16 00:56:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 67.85	
[11/16 00:56:25 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.4975670171853926
[11/16 01:03:25 visual_prompt]: Epoch 15 / 100: avg data time: 1.16e+01, avg batch time: 12.0020, average train loss: 0.7552
[11/16 01:04:16 visual_prompt]: Inference (val):avg data time: 3.90e-05, avg batch time: 0.1575, average loss: 0.8812
[11/16 01:04:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 67.71	
[11/16 01:04:16 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.49620193825305203
[11/16 01:11:58 visual_prompt]: Epoch 16 / 100: avg data time: 1.28e+01, avg batch time: 13.1958, average train loss: 0.6956
[11/16 01:12:50 visual_prompt]: Inference (val):avg data time: 4.08e-05, avg batch time: 0.1538, average loss: 1.0518
[11/16 01:12:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 68.12	
[11/16 01:12:50 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.4945369001834514
[11/16 01:20:10 visual_prompt]: Epoch 17 / 100: avg data time: 1.22e+01, avg batch time: 12.5746, average train loss: 0.7537
[11/16 01:20:57 visual_prompt]: Inference (val):avg data time: 3.45e-05, avg batch time: 0.1538, average loss: 0.7634
[11/16 01:20:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 70.23	
[11/16 01:20:57 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.4925739315689991
[11/16 01:27:49 visual_prompt]: Epoch 18 / 100: avg data time: 1.14e+01, avg batch time: 11.7762, average train loss: 0.6820
[11/16 01:28:43 visual_prompt]: Inference (val):avg data time: 4.22e-05, avg batch time: 0.1538, average loss: 0.8015
[11/16 01:28:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 71.46	
[11/16 01:28:43 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.4903154239845797
[11/16 01:36:31 visual_prompt]: Epoch 19 / 100: avg data time: 1.30e+01, avg batch time: 13.3632, average train loss: 0.6552
[11/16 01:37:23 visual_prompt]: Inference (val):avg data time: 4.18e-05, avg batch time: 0.1539, average loss: 0.6303
[11/16 01:37:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 71.41	
[11/16 01:37:23 visual_prompt]: Best epoch 19: best metric: -0.630
[11/16 01:37:23 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.4877641290737884
[11/16 01:44:31 visual_prompt]: Epoch 20 / 100: avg data time: 1.19e+01, avg batch time: 12.2153, average train loss: 0.6614
[11/16 01:45:16 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1539, average loss: 0.6415
[11/16 01:45:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.07	rocauc: 72.59	
[11/16 01:45:16 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.4849231551964771
[11/16 01:52:12 visual_prompt]: Epoch 21 / 100: avg data time: 1.15e+01, avg batch time: 11.8606, average train loss: 0.6946
[11/16 01:52:59 visual_prompt]: Inference (val):avg data time: 3.63e-05, avg batch time: 0.1570, average loss: 0.6676
[11/16 01:52:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 72.62	
[11/16 01:52:59 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.48179596364169686
[11/16 02:00:35 visual_prompt]: Epoch 22 / 100: avg data time: 1.27e+01, avg batch time: 13.0273, average train loss: 0.7177
[11/16 02:01:27 visual_prompt]: Inference (val):avg data time: 5.72e-05, avg batch time: 0.1565, average loss: 0.6442
[11/16 02:01:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 72.62	
[11/16 02:01:27 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.4783863644106502
[11/16 02:08:59 visual_prompt]: Epoch 23 / 100: avg data time: 1.25e+01, avg batch time: 12.8931, average train loss: 0.6219
[11/16 02:09:49 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1536, average loss: 0.7250
[11/16 02:09:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 71.95	
[11/16 02:09:49 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.47469851157479176
[11/16 02:16:35 visual_prompt]: Epoch 24 / 100: avg data time: 1.13e+01, avg batch time: 11.6064, average train loss: 0.6376
[11/16 02:17:21 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1537, average loss: 0.6360
[11/16 02:17:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 71.78	
[11/16 02:17:21 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.47073689821473175
[11/16 02:25:03 visual_prompt]: Epoch 25 / 100: avg data time: 1.28e+01, avg batch time: 13.1958, average train loss: 0.6107
[11/16 02:25:56 visual_prompt]: Inference (val):avg data time: 4.51e-05, avg batch time: 0.1580, average loss: 0.6201
[11/16 02:25:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.07	rocauc: 73.01	
[11/16 02:25:56 visual_prompt]: Best epoch 25: best metric: -0.620
[11/16 02:25:56 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.4665063509461097
[11/16 02:33:32 visual_prompt]: Epoch 26 / 100: avg data time: 1.27e+01, avg batch time: 13.0225, average train loss: 0.6503
[11/16 02:34:22 visual_prompt]: Inference (val):avg data time: 3.75e-05, avg batch time: 0.1537, average loss: 0.6205
[11/16 02:34:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 72.64	
[11/16 02:34:22 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.46201202403910646
[11/16 02:41:22 visual_prompt]: Epoch 27 / 100: avg data time: 1.17e+01, avg batch time: 12.0076, average train loss: 0.6140
[11/16 02:42:08 visual_prompt]: Inference (val):avg data time: 3.45e-05, avg batch time: 0.1537, average loss: 0.6396
[11/16 02:42:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.89	rocauc: 70.72	
[11/16 02:42:08 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.4572593931387604
[11/16 02:49:18 visual_prompt]: Epoch 28 / 100: avg data time: 1.19e+01, avg batch time: 12.2888, average train loss: 0.6413
[11/16 02:50:11 visual_prompt]: Inference (val):avg data time: 4.60e-05, avg batch time: 0.1573, average loss: 0.6288
[11/16 02:50:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 71.39	
[11/16 02:50:11 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.45225424859373686
[11/16 02:58:06 visual_prompt]: Epoch 29 / 100: avg data time: 1.32e+01, avg batch time: 13.5652, average train loss: 0.5975
[11/16 02:58:59 visual_prompt]: Inference (val):avg data time: 4.30e-05, avg batch time: 0.1539, average loss: 0.6219
[11/16 02:58:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.07	rocauc: 72.24	
[11/16 02:58:59 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.44700268840168045
[11/16 03:06:03 visual_prompt]: Epoch 30 / 100: avg data time: 1.18e+01, avg batch time: 12.1190, average train loss: 0.6137
[11/16 03:06:49 visual_prompt]: Inference (val):avg data time: 3.59e-05, avg batch time: 0.1533, average loss: 0.6492
[11/16 03:06:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 71.88	
[11/16 03:06:49 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.4415111107797445
[11/16 03:14:13 visual_prompt]: Epoch 31 / 100: avg data time: 1.23e+01, avg batch time: 12.6979, average train loss: 0.5935
[11/16 03:15:07 visual_prompt]: Inference (val):avg data time: 4.61e-05, avg batch time: 0.1539, average loss: 0.6954
[11/16 03:15:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 70.43	
[11/16 03:15:07 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.43578620636934856
[11/16 03:22:45 visual_prompt]: Epoch 32 / 100: avg data time: 1.27e+01, avg batch time: 13.0844, average train loss: 0.6072
[11/16 03:23:35 visual_prompt]: Inference (val):avg data time: 3.61e-05, avg batch time: 0.1564, average loss: 0.6059
[11/16 03:23:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 70.73	rocauc: 73.58	
[11/16 03:23:35 visual_prompt]: Best epoch 32: best metric: -0.606
[11/16 03:23:35 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.42983495008466277
[11/16 03:30:36 visual_prompt]: Epoch 33 / 100: avg data time: 1.16e+01, avg batch time: 12.0011, average train loss: 0.5505
[11/16 03:31:27 visual_prompt]: Inference (val):avg data time: 4.11e-05, avg batch time: 0.1552, average loss: 0.6391
[11/16 03:31:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 70.53	
[11/16 03:31:27 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.4236645926147493
[11/16 03:38:26 visual_prompt]: Epoch 34 / 100: avg data time: 1.16e+01, avg batch time: 11.9448, average train loss: 0.5644
[11/16 03:39:18 visual_prompt]: Inference (val):avg data time: 3.98e-05, avg batch time: 0.1537, average loss: 0.6228
[11/16 03:39:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.67	rocauc: 72.14	
[11/16 03:39:18 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.41728265158971456
[11/16 03:47:09 visual_prompt]: Epoch 35 / 100: avg data time: 1.31e+01, avg batch time: 13.4514, average train loss: 0.6069
[11/16 03:48:01 visual_prompt]: Inference (val):avg data time: 3.93e-05, avg batch time: 0.1575, average loss: 0.9533
[11/16 03:48:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 53.25	rocauc: 71.73	
[11/16 03:48:01 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.4106969024216348
[11/16 03:55:19 visual_prompt]: Epoch 36 / 100: avg data time: 1.21e+01, avg batch time: 12.4842, average train loss: 0.6015
[11/16 03:56:05 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1562, average loss: 0.7839
[11/16 03:56:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 70.70	
[11/16 03:56:05 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.40391536883141455
[11/16 04:03:09 visual_prompt]: Epoch 37 / 100: avg data time: 1.18e+01, avg batch time: 12.1187, average train loss: 0.5496
[11/16 04:04:04 visual_prompt]: Inference (val):avg data time: 4.68e-05, avg batch time: 0.1562, average loss: 0.6397
[11/16 04:04:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 68.70	rocauc: 72.72	
[11/16 04:04:04 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.3969463130731183
[11/16 04:11:53 visual_prompt]: Epoch 38 / 100: avg data time: 1.30e+01, avg batch time: 13.3881, average train loss: 0.5286
[11/16 04:12:45 visual_prompt]: Inference (val):avg data time: 4.28e-05, avg batch time: 0.1572, average loss: 0.6540
[11/16 04:12:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 69.63	
[11/16 04:12:45 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.3897982258676867
[11/16 04:19:37 visual_prompt]: Epoch 39 / 100: avg data time: 1.14e+01, avg batch time: 11.7781, average train loss: 0.5423
[11/16 04:20:23 visual_prompt]: Inference (val):avg data time: 3.58e-05, avg batch time: 0.1564, average loss: 0.8090
[11/16 04:20:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 70.83	
[11/16 04:20:23 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.3824798160583012
[11/16 04:27:26 visual_prompt]: Epoch 40 / 100: avg data time: 1.17e+01, avg batch time: 12.0982, average train loss: 0.5124
[11/16 04:28:17 visual_prompt]: Inference (val):avg data time: 3.77e-05, avg batch time: 0.1541, average loss: 0.6311
[11/16 04:28:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 71.31	
[11/16 04:28:17 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.375
[11/16 04:36:01 visual_prompt]: Epoch 41 / 100: avg data time: 1.29e+01, avg batch time: 13.2529, average train loss: 0.4963
[11/16 04:36:55 visual_prompt]: Inference (val):avg data time: 4.28e-05, avg batch time: 0.1541, average loss: 0.8958
[11/16 04:36:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 70.51	
[11/16 04:36:55 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.3673678906964727
[11/16 04:44:29 visual_prompt]: Epoch 42 / 100: avg data time: 1.26e+01, avg batch time: 12.9650, average train loss: 0.5496
[11/16 04:45:16 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.1537, average loss: 0.8696
[11/16 04:45:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 69.30	
[11/16 04:45:16 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.35959278669726935
[11/16 04:52:02 visual_prompt]: Epoch 43 / 100: avg data time: 1.12e+01, avg batch time: 11.5854, average train loss: 0.5255
[11/16 04:52:55 visual_prompt]: Inference (val):avg data time: 4.21e-05, avg batch time: 0.1561, average loss: 0.6923
[11/16 04:52:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 70.66	
[11/16 04:52:55 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.3516841607689501
[11/16 05:00:47 visual_prompt]: Epoch 44 / 100: avg data time: 1.31e+01, avg batch time: 13.4760, average train loss: 0.4817
[11/16 05:01:40 visual_prompt]: Inference (val):avg data time: 4.33e-05, avg batch time: 0.1543, average loss: 0.8459
[11/16 05:01:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 66.66	
[11/16 05:01:40 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.34365164835397805
[11/16 05:09:05 visual_prompt]: Epoch 45 / 100: avg data time: 1.24e+01, avg batch time: 12.7062, average train loss: 0.4827
[11/16 05:09:51 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1537, average loss: 0.7454
[11/16 05:09:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 70.27	
[11/16 05:09:51 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.3355050358314172
[11/16 05:16:47 visual_prompt]: Epoch 46 / 100: avg data time: 1.15e+01, avg batch time: 11.8682, average train loss: 0.4155
[11/16 05:17:33 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.1537, average loss: 0.8390
[11/16 05:17:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.01	rocauc: 69.54	
[11/16 05:17:33 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.32725424859373686
[11/16 05:25:02 visual_prompt]: Epoch 47 / 100: avg data time: 1.25e+01, avg batch time: 12.8242, average train loss: 0.4756
[11/16 05:25:57 visual_prompt]: Inference (val):avg data time: 4.25e-05, avg batch time: 0.1540, average loss: 0.8228
[11/16 05:25:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 68.26	
[11/16 05:25:57 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.3189093389542498
[11/16 05:33:44 visual_prompt]: Epoch 48 / 100: avg data time: 1.30e+01, avg batch time: 13.3466, average train loss: 0.4419
[11/16 05:34:35 visual_prompt]: Inference (val):avg data time: 3.45e-05, avg batch time: 0.1539, average loss: 0.7234
[11/16 05:34:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 69.27	
[11/16 05:34:35 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.3104804738999169
[11/16 05:41:33 visual_prompt]: Epoch 49 / 100: avg data time: 1.16e+01, avg batch time: 11.9390, average train loss: 0.4048
[11/16 05:42:19 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1537, average loss: 0.7738
[11/16 05:42:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 69.01	
[11/16 05:42:19 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.3019779227044398
[11/16 05:49:54 visual_prompt]: Epoch 50 / 100: avg data time: 1.27e+01, avg batch time: 13.0091, average train loss: 0.4431
[11/16 05:50:48 visual_prompt]: Inference (val):avg data time: 5.09e-05, avg batch time: 0.1539, average loss: 0.7699
[11/16 05:50:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.67	rocauc: 71.02	
[11/16 05:50:48 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.29341204441673263
[11/16 05:58:28 visual_prompt]: Epoch 51 / 100: avg data time: 1.28e+01, avg batch time: 13.1384, average train loss: 0.4268
[11/16 05:59:18 visual_prompt]: Inference (val):avg data time: 3.62e-05, avg batch time: 0.1569, average loss: 0.7997
[11/16 05:59:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.01	rocauc: 69.53	
[11/16 05:59:18 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.28479327524001635
[11/16 06:06:16 visual_prompt]: Epoch 52 / 100: avg data time: 1.16e+01, avg batch time: 11.9387, average train loss: 0.3962
[11/16 06:07:06 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1549, average loss: 0.9634
[11/16 06:07:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 68.29	
[11/16 06:07:06 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.2761321158169134
[11/16 06:14:10 visual_prompt]: Epoch 53 / 100: avg data time: 1.18e+01, avg batch time: 12.1138, average train loss: 0.3593
[11/16 06:15:03 visual_prompt]: Inference (val):avg data time: 4.14e-05, avg batch time: 0.1542, average loss: 0.8505
[11/16 06:15:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.01	rocauc: 71.09	
[11/16 06:15:03 visual_prompt]: Stopping early.
[11/16 06:15:03 visual_prompt]: Rank of current process: 0. World size: 1
[11/16 06:15:03 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/16 06:15:03 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/16 06:15:03 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/16 06:15:03 visual_prompt]: Training with config:
[11/16 06:15:03 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr0.25_wd0.01/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.25, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/16 06:15:03 visual_prompt]: Loading training data...
[11/16 06:15:03 visual_prompt]: Constructing mammo-cbis dataset train...
[11/16 06:15:03 visual_prompt]: Loading validation data...
[11/16 06:15:03 visual_prompt]: Constructing mammo-cbis dataset val...
[11/16 06:15:03 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[11/16 06:15:08 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[11/16 06:15:08 visual_prompt]: tuned percent:0.536
[11/16 06:15:08 visual_prompt]: Device used for model: 0
[11/16 06:15:08 visual_prompt]: Setting up Evaluator...
[11/16 06:15:08 visual_prompt]: Setting up Trainer...
[11/16 06:15:08 visual_prompt]: 	Setting up the optimizer...
[11/16 06:15:08 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/16 06:22:54 visual_prompt]: Epoch 1 / 100: avg data time: 1.30e+01, avg batch time: 13.3072, average train loss: 1.4017
[11/16 06:23:47 visual_prompt]: Inference (val):avg data time: 4.28e-05, avg batch time: 0.1538, average loss: 1.2969
[11/16 06:23:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[11/16 06:23:47 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.025
[11/16 06:31:05 visual_prompt]: Epoch 2 / 100: avg data time: 1.22e+01, avg batch time: 12.5103, average train loss: 1.4183
[11/16 06:31:51 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.1534, average loss: 0.6912
[11/16 06:31:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 52.08	
[11/16 06:31:51 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.05
[11/16 06:38:58 visual_prompt]: Epoch 3 / 100: avg data time: 1.19e+01, avg batch time: 12.2074, average train loss: 0.7009
[11/16 06:39:52 visual_prompt]: Inference (val):avg data time: 4.70e-05, avg batch time: 0.1540, average loss: 0.6877
[11/16 06:39:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.22	
[11/16 06:39:52 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.075
[11/16 06:47:43 visual_prompt]: Epoch 4 / 100: avg data time: 1.31e+01, avg batch time: 13.4669, average train loss: 0.6893
[11/16 06:48:36 visual_prompt]: Inference (val):avg data time: 3.90e-05, avg batch time: 0.1538, average loss: 0.6925
[11/16 06:48:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.51	
[11/16 06:48:36 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.1
[11/16 06:55:42 visual_prompt]: Epoch 5 / 100: avg data time: 1.18e+01, avg batch time: 12.1666, average train loss: 0.7201
[11/16 06:56:27 visual_prompt]: Inference (val):avg data time: 3.60e-05, avg batch time: 0.1535, average loss: 0.6930
[11/16 06:56:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.40	
[11/16 06:56:27 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.125
[11/16 07:03:31 visual_prompt]: Epoch 6 / 100: avg data time: 1.17e+01, avg batch time: 12.1004, average train loss: 0.7055
[11/16 07:04:22 visual_prompt]: Inference (val):avg data time: 3.68e-05, avg batch time: 0.1537, average loss: 0.6884
[11/16 07:04:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.22	
[11/16 07:04:22 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.15
[11/16 07:12:05 visual_prompt]: Epoch 7 / 100: avg data time: 1.29e+01, avg batch time: 13.2484, average train loss: 0.7063
[11/16 07:12:58 visual_prompt]: Inference (val):avg data time: 4.42e-05, avg batch time: 0.1542, average loss: 0.6932
[11/16 07:12:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 48.78	rocauc: 58.12	
[11/16 07:12:58 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.175
[11/16 07:20:19 visual_prompt]: Epoch 8 / 100: avg data time: 1.22e+01, avg batch time: 12.5897, average train loss: 0.7053
[11/16 07:21:05 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1536, average loss: 0.6867
[11/16 07:21:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.77	
[11/16 07:21:05 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.2
[11/16 07:27:57 visual_prompt]: Epoch 9 / 100: avg data time: 1.14e+01, avg batch time: 11.7551, average train loss: 0.7017
[11/16 07:28:51 visual_prompt]: Inference (val):avg data time: 4.50e-05, avg batch time: 0.1541, average loss: 0.6942
[11/16 07:28:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.14	
[11/16 07:28:51 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.225
[11/16 07:36:40 visual_prompt]: Epoch 10 / 100: avg data time: 1.30e+01, avg batch time: 13.4021, average train loss: 0.7012
[11/16 07:37:32 visual_prompt]: Inference (val):avg data time: 4.32e-05, avg batch time: 0.1549, average loss: 0.7062
[11/16 07:37:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.14	
[11/16 07:37:32 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.25
[11/16 07:44:46 visual_prompt]: Epoch 11 / 100: avg data time: 1.20e+01, avg batch time: 12.3841, average train loss: 0.6958
[11/16 07:45:31 visual_prompt]: Inference (val):avg data time: 3.93e-05, avg batch time: 0.1533, average loss: 0.6900
[11/16 07:45:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.25	
[11/16 07:45:31 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.24992385337738698
[11/16 07:51:56 visual_prompt]: Epoch 12 / 100: avg data time: 1.06e+01, avg batch time: 10.9933, average train loss: 0.7014
[11/16 07:52:40 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1539, average loss: 0.6881
[11/16 07:52:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.57	
[11/16 07:52:40 visual_prompt]: Best epoch 12: best metric: -0.688
[11/16 07:52:40 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.24969550628247802
[11/16 07:59:02 visual_prompt]: Epoch 13 / 100: avg data time: 1.06e+01, avg batch time: 10.9274, average train loss: 0.7115
[11/16 07:59:46 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1535, average loss: 0.6885
[11/16 07:59:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.89	
[11/16 07:59:46 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.24931523692103416
[11/16 08:06:07 visual_prompt]: Epoch 14 / 100: avg data time: 1.05e+01, avg batch time: 10.8962, average train loss: 0.7062
[11/16 08:06:51 visual_prompt]: Inference (val):avg data time: 3.82e-05, avg batch time: 0.1560, average loss: 0.8048
[11/16 08:06:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.71	
[11/16 08:06:51 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.2487835085926963
[11/16 08:13:14 visual_prompt]: Epoch 15 / 100: avg data time: 1.06e+01, avg batch time: 10.9302, average train loss: 0.7092
[11/16 08:13:57 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1537, average loss: 0.6886
[11/16 08:13:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.49	
[11/16 08:13:57 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.24810096912652602
[11/16 08:20:20 visual_prompt]: Epoch 16 / 100: avg data time: 1.06e+01, avg batch time: 10.9151, average train loss: 0.7068
[11/16 08:21:03 visual_prompt]: Inference (val):avg data time: 3.95e-05, avg batch time: 0.1538, average loss: 0.6885
[11/16 08:21:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 41.77	
[11/16 08:21:03 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.2472684500917257
[11/16 08:27:25 visual_prompt]: Epoch 17 / 100: avg data time: 1.06e+01, avg batch time: 10.9150, average train loss: 0.7087
[11/16 08:28:09 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1538, average loss: 0.6925
[11/16 08:28:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.84	
[11/16 08:28:09 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.24628696578449955
[11/16 08:34:32 visual_prompt]: Epoch 18 / 100: avg data time: 1.06e+01, avg batch time: 10.9277, average train loss: 0.7181
[11/16 08:35:16 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.1533, average loss: 0.7962
[11/16 08:35:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.20	
[11/16 08:35:16 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.24515771199228986
[11/16 08:41:38 visual_prompt]: Epoch 19 / 100: avg data time: 1.06e+01, avg batch time: 10.9144, average train loss: 0.7125
[11/16 08:42:21 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.1535, average loss: 0.7443
[11/16 08:42:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.07	
[11/16 08:42:21 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.2438820645368942
[11/16 08:48:44 visual_prompt]: Epoch 20 / 100: avg data time: 1.06e+01, avg batch time: 10.9295, average train loss: 0.7017
[11/16 08:49:27 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.1539, average loss: 0.6905
[11/16 08:49:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.20	
[11/16 08:49:27 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.24246157759823855
[11/16 08:55:50 visual_prompt]: Epoch 21 / 100: avg data time: 1.06e+01, avg batch time: 10.9218, average train loss: 0.7040
[11/16 08:56:34 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1541, average loss: 0.6884
[11/16 08:56:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.45	
[11/16 08:56:34 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.24089798182084843
[11/16 09:02:56 visual_prompt]: Epoch 22 / 100: avg data time: 1.06e+01, avg batch time: 10.9328, average train loss: 0.7021
[11/16 09:03:40 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1553, average loss: 0.7165
[11/16 09:03:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.80	
[11/16 09:03:40 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.2391931822053251
[11/16 09:10:01 visual_prompt]: Epoch 23 / 100: avg data time: 1.05e+01, avg batch time: 10.9008, average train loss: 0.6970
[11/16 09:10:45 visual_prompt]: Inference (val):avg data time: 3.43e-05, avg batch time: 0.1536, average loss: 0.6935
[11/16 09:10:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.91	
[11/16 09:10:45 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.23734925578739588
[11/16 09:17:08 visual_prompt]: Epoch 24 / 100: avg data time: 1.06e+01, avg batch time: 10.9359, average train loss: 0.6948
[11/16 09:17:52 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.1536, average loss: 0.6968
[11/16 09:17:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.43	
[11/16 09:17:52 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.23536844910736587
[11/16 09:24:14 visual_prompt]: Epoch 25 / 100: avg data time: 1.06e+01, avg batch time: 10.9182, average train loss: 0.6939
[11/16 09:24:58 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.1537, average loss: 0.6938
[11/16 09:24:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 61.14	
[11/16 09:24:58 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.23325317547305485
[11/16 09:31:21 visual_prompt]: Epoch 26 / 100: avg data time: 1.06e+01, avg batch time: 10.9392, average train loss: 0.6950
[11/16 09:32:04 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.1534, average loss: 0.6911
[11/16 09:32:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.24	
[11/16 09:32:04 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.23100601201955323
[11/16 09:38:28 visual_prompt]: Epoch 27 / 100: avg data time: 1.06e+01, avg batch time: 10.9488, average train loss: 0.7057
[11/16 09:39:12 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1586, average loss: 0.6911
[11/16 09:39:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.98	
[11/16 09:39:12 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.2286296965693802
[11/16 09:45:35 visual_prompt]: Epoch 28 / 100: avg data time: 1.06e+01, avg batch time: 10.9162, average train loss: 0.7093
[11/16 09:46:18 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1535, average loss: 0.7100
[11/16 09:46:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.40	
[11/16 09:46:18 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.22612712429686843
[11/16 09:52:42 visual_prompt]: Epoch 29 / 100: avg data time: 1.06e+01, avg batch time: 10.9517, average train loss: 0.7186
[11/16 09:53:25 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.1578, average loss: 0.7396
[11/16 09:53:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.22	
[11/16 09:53:25 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.22350134420084022
[11/16 09:59:48 visual_prompt]: Epoch 30 / 100: avg data time: 1.06e+01, avg batch time: 10.9317, average train loss: 0.7031
[11/16 10:00:31 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.1538, average loss: 0.6924
[11/16 10:00:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.89	
[11/16 10:00:31 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.22075555538987224
[11/16 10:06:54 visual_prompt]: Epoch 31 / 100: avg data time: 1.06e+01, avg batch time: 10.9141, average train loss: 0.7015
[11/16 10:07:37 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.1537, average loss: 0.6940
[11/16 10:07:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 42.57	
[11/16 10:07:37 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.21789310318467428
[11/16 10:14:00 visual_prompt]: Epoch 32 / 100: avg data time: 1.06e+01, avg batch time: 10.9247, average train loss: 0.7038
[11/16 10:14:43 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.1576, average loss: 0.7157
[11/16 10:14:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.52	
[11/16 10:14:43 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.21491747504233139
[11/16 10:21:05 visual_prompt]: Epoch 33 / 100: avg data time: 1.06e+01, avg batch time: 10.9026, average train loss: 0.7008
[11/16 10:21:49 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1535, average loss: 0.6905
[11/16 10:21:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.23	
[11/16 10:21:49 visual_prompt]: Stopping early.
[11/16 10:21:49 visual_prompt]: Rank of current process: 0. World size: 1
[11/16 10:21:49 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/16 10:21:49 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/16 10:21:49 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/16 10:21:49 visual_prompt]: Training with config:
[11/16 10:21:49 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr0.25_wd0.001/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.25, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/16 10:21:49 visual_prompt]: Loading training data...
[11/16 10:21:49 visual_prompt]: Constructing mammo-cbis dataset train...
[11/16 10:21:49 visual_prompt]: Loading validation data...
[11/16 10:21:49 visual_prompt]: Constructing mammo-cbis dataset val...
[11/16 10:21:49 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[11/16 10:21:51 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[11/16 10:21:51 visual_prompt]: tuned percent:0.536
[11/16 10:21:52 visual_prompt]: Device used for model: 0
[11/16 10:21:52 visual_prompt]: Setting up Evaluator...
[11/16 10:21:52 visual_prompt]: Setting up Trainer...
[11/16 10:21:52 visual_prompt]: 	Setting up the optimizer...
[11/16 10:21:52 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/16 10:28:14 visual_prompt]: Epoch 1 / 100: avg data time: 1.06e+01, avg batch time: 10.9117, average train loss: 1.4017
[11/16 10:28:57 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1537, average loss: 1.2969
[11/16 10:28:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[11/16 10:28:57 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.025
[11/16 10:35:20 visual_prompt]: Epoch 2 / 100: avg data time: 1.06e+01, avg batch time: 10.9233, average train loss: 1.4235
[11/16 10:36:03 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1540, average loss: 0.6898
[11/16 10:36:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 52.09	
[11/16 10:36:03 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.05
[11/16 10:42:25 visual_prompt]: Epoch 3 / 100: avg data time: 1.06e+01, avg batch time: 10.9161, average train loss: 0.7048
[11/16 10:43:09 visual_prompt]: Inference (val):avg data time: 3.45e-05, avg batch time: 0.1551, average loss: 0.6906
[11/16 10:43:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.99	
[11/16 10:43:09 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.075
[11/16 10:49:32 visual_prompt]: Epoch 4 / 100: avg data time: 1.06e+01, avg batch time: 10.9306, average train loss: 0.6935
[11/16 10:50:15 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1537, average loss: 0.6935
[11/16 10:50:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.71	
[11/16 10:50:15 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.1
[11/16 10:56:37 visual_prompt]: Epoch 5 / 100: avg data time: 1.06e+01, avg batch time: 10.9058, average train loss: 0.7290
[11/16 10:57:21 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.1550, average loss: 0.7004
[11/16 10:57:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.93	rocauc: 60.60	
[11/16 10:57:21 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.125
[11/16 11:03:43 visual_prompt]: Epoch 6 / 100: avg data time: 1.06e+01, avg batch time: 10.9349, average train loss: 0.7546
[11/16 11:04:27 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1536, average loss: 0.6821
[11/16 11:04:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 60.84	
[11/16 11:04:27 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.15
[11/16 11:10:51 visual_prompt]: Epoch 7 / 100: avg data time: 1.06e+01, avg batch time: 10.9547, average train loss: 0.7174
[11/16 11:11:34 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1548, average loss: 0.6708
[11/16 11:11:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 61.88	
[11/16 11:11:34 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.175
[11/16 11:17:57 visual_prompt]: Epoch 8 / 100: avg data time: 1.06e+01, avg batch time: 10.9305, average train loss: 0.7078
[11/16 11:18:41 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.1535, average loss: 0.6659
[11/16 11:18:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.54	rocauc: 62.19	
[11/16 11:18:41 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.2
[11/16 11:25:04 visual_prompt]: Epoch 9 / 100: avg data time: 1.06e+01, avg batch time: 10.9584, average train loss: 0.6920
[11/16 11:25:50 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.1556, average loss: 0.7073
[11/16 11:25:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 64.51	
[11/16 11:25:50 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.225
[11/16 11:32:12 visual_prompt]: Epoch 10 / 100: avg data time: 1.06e+01, avg batch time: 10.9359, average train loss: 0.6650
[11/16 11:32:56 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1576, average loss: 0.6646
[11/16 11:32:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 66.38	
[11/16 11:32:56 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.25
[11/16 11:39:25 visual_prompt]: Epoch 11 / 100: avg data time: 1.08e+01, avg batch time: 11.1065, average train loss: 0.6847
[11/16 11:40:09 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1545, average loss: 0.6636
[11/16 11:40:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 65.98	
[11/16 11:40:09 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.24992385337738698
[11/16 11:46:31 visual_prompt]: Epoch 12 / 100: avg data time: 1.06e+01, avg batch time: 10.9066, average train loss: 0.6734
[11/16 11:47:14 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.1571, average loss: 0.6851
[11/16 11:47:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 70.45	
[11/16 11:47:14 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.24969550628247802
[11/16 11:53:37 visual_prompt]: Epoch 13 / 100: avg data time: 1.06e+01, avg batch time: 10.9384, average train loss: 0.7218
[11/16 11:54:21 visual_prompt]: Inference (val):avg data time: 3.47e-05, avg batch time: 0.1533, average loss: 0.6889
[11/16 11:54:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 68.50	
[11/16 11:54:21 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.24931523692103416
[11/16 12:00:43 visual_prompt]: Epoch 14 / 100: avg data time: 1.06e+01, avg batch time: 10.9201, average train loss: 0.6693
[11/16 12:01:27 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.1574, average loss: 0.6953
[11/16 12:01:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 70.00	
[11/16 12:01:27 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.2487835085926963
[11/16 12:07:50 visual_prompt]: Epoch 15 / 100: avg data time: 1.06e+01, avg batch time: 10.9439, average train loss: 0.6743
[11/16 12:08:33 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.1543, average loss: 0.7851
[11/16 12:08:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 69.01	
[11/16 12:08:33 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.24810096912652602
[11/16 12:14:55 visual_prompt]: Epoch 16 / 100: avg data time: 1.06e+01, avg batch time: 10.9157, average train loss: 0.6836
[11/16 12:15:39 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1538, average loss: 0.7908
[11/16 12:15:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 72.90	
[11/16 12:15:39 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.2472684500917257
[11/16 12:22:01 visual_prompt]: Epoch 17 / 100: avg data time: 1.06e+01, avg batch time: 10.9075, average train loss: 0.7032
[11/16 12:22:45 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1538, average loss: 0.6382
[11/16 12:22:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 70.62	
[11/16 12:22:45 visual_prompt]: Best epoch 17: best metric: -0.638
[11/16 12:22:45 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.24628696578449955
[11/16 12:29:07 visual_prompt]: Epoch 18 / 100: avg data time: 1.06e+01, avg batch time: 10.9364, average train loss: 0.6304
[11/16 12:29:51 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.1535, average loss: 0.7878
[11/16 12:29:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 72.66	
[11/16 12:29:51 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.24515771199228986
[11/16 12:36:13 visual_prompt]: Epoch 19 / 100: avg data time: 1.06e+01, avg batch time: 10.9100, average train loss: 0.6323
[11/16 12:36:57 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1537, average loss: 0.6691
[11/16 12:36:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 71.86	
[11/16 12:36:57 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.2438820645368942
[11/16 12:43:20 visual_prompt]: Epoch 20 / 100: avg data time: 1.06e+01, avg batch time: 10.9339, average train loss: 0.6399
[11/16 12:44:03 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1562, average loss: 0.6589
[11/16 12:44:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 70.17	
[11/16 12:44:03 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.24246157759823855
[11/16 12:50:26 visual_prompt]: Epoch 21 / 100: avg data time: 1.06e+01, avg batch time: 10.9245, average train loss: 0.6507
[11/16 12:51:09 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1539, average loss: 0.6301
[11/16 12:51:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.07	rocauc: 71.47	
[11/16 12:51:09 visual_prompt]: Best epoch 21: best metric: -0.630
[11/16 12:51:09 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.24089798182084843
[11/16 12:57:32 visual_prompt]: Epoch 22 / 100: avg data time: 1.06e+01, avg batch time: 10.9159, average train loss: 0.6614
[11/16 12:58:15 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.1536, average loss: 0.6326
[11/16 12:58:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 72.04	
[11/16 12:58:15 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.2391931822053251
[11/16 13:04:37 visual_prompt]: Epoch 23 / 100: avg data time: 1.06e+01, avg batch time: 10.9104, average train loss: 0.6358
[11/16 13:05:21 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.1534, average loss: 0.6755
[11/16 13:05:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 68.23	
[11/16 13:05:21 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.23734925578739588
[11/16 13:11:44 visual_prompt]: Epoch 24 / 100: avg data time: 1.06e+01, avg batch time: 10.9349, average train loss: 0.6579
[11/16 13:12:27 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1538, average loss: 0.6712
[11/16 13:12:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 70.73	
[11/16 13:12:27 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.23536844910736587
[11/16 13:18:50 visual_prompt]: Epoch 25 / 100: avg data time: 1.06e+01, avg batch time: 10.9241, average train loss: 0.6274
[11/16 13:19:33 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1540, average loss: 0.6264
[11/16 13:19:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.67	rocauc: 71.60	
[11/16 13:19:33 visual_prompt]: Best epoch 25: best metric: -0.626
[11/16 13:19:33 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.23325317547305485
[11/16 13:25:55 visual_prompt]: Epoch 26 / 100: avg data time: 1.06e+01, avg batch time: 10.9064, average train loss: 0.6534
[11/16 13:26:39 visual_prompt]: Inference (val):avg data time: 3.35e-05, avg batch time: 0.1544, average loss: 0.6683
[11/16 13:26:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 69.08	
[11/16 13:26:39 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.23100601201955323
[11/16 13:33:02 visual_prompt]: Epoch 27 / 100: avg data time: 1.06e+01, avg batch time: 10.9512, average train loss: 0.6346
[11/16 13:33:46 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1539, average loss: 0.6668
[11/16 13:33:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.01	rocauc: 70.03	
[11/16 13:33:46 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.2286296965693802
[11/16 13:40:08 visual_prompt]: Epoch 28 / 100: avg data time: 1.06e+01, avg batch time: 10.9114, average train loss: 0.6432
[11/16 13:40:52 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1539, average loss: 0.6234
[11/16 13:40:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.67	rocauc: 70.75	
[11/16 13:40:52 visual_prompt]: Best epoch 28: best metric: -0.623
[11/16 13:40:52 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.22612712429686843
[11/16 13:47:15 visual_prompt]: Epoch 29 / 100: avg data time: 1.06e+01, avg batch time: 10.9488, average train loss: 0.6084
[11/16 13:47:59 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.1554, average loss: 0.6089
[11/16 13:47:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 73.06	
[11/16 13:47:59 visual_prompt]: Best epoch 29: best metric: -0.609
[11/16 13:47:59 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.22350134420084022
[11/16 13:54:33 visual_prompt]: Epoch 30 / 100: avg data time: 1.09e+01, avg batch time: 11.2672, average train loss: 0.6443
[11/16 13:55:17 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1544, average loss: 0.7532
[11/16 13:55:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 72.17	
[11/16 13:55:17 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.22075555538987224
[11/16 14:01:37 visual_prompt]: Epoch 31 / 100: avg data time: 1.05e+01, avg batch time: 10.8560, average train loss: 0.6261
[11/16 14:02:20 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1561, average loss: 0.6395
[11/16 14:02:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.01	rocauc: 74.16	
[11/16 14:02:20 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.21789310318467428
[11/16 14:08:41 visual_prompt]: Epoch 32 / 100: avg data time: 1.05e+01, avg batch time: 10.8832, average train loss: 0.6122
[11/16 14:09:25 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1561, average loss: 0.6150
[11/16 14:09:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 68.70	rocauc: 73.71	
[11/16 14:09:25 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.21491747504233139
[11/16 14:15:46 visual_prompt]: Epoch 33 / 100: avg data time: 1.05e+01, avg batch time: 10.8976, average train loss: 0.6088
[11/16 14:16:30 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1554, average loss: 0.6055
[11/16 14:16:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 68.70	rocauc: 73.65	
[11/16 14:16:30 visual_prompt]: Best epoch 33: best metric: -0.605
[11/16 14:16:30 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.21183229630737466
[11/16 14:22:50 visual_prompt]: Epoch 34 / 100: avg data time: 1.05e+01, avg batch time: 10.8762, average train loss: 0.5969
[11/16 14:23:34 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1580, average loss: 0.6675
[11/16 14:23:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 71.05	
[11/16 14:23:34 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.20864132579485728
[11/16 14:29:54 visual_prompt]: Epoch 35 / 100: avg data time: 1.05e+01, avg batch time: 10.8698, average train loss: 0.6063
[11/16 14:30:38 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1557, average loss: 0.6949
[11/16 14:30:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 72.10	
[11/16 14:30:38 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.2053484512108174
[11/16 14:36:57 visual_prompt]: Epoch 36 / 100: avg data time: 1.05e+01, avg batch time: 10.8456, average train loss: 0.6131
[11/16 14:37:41 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1550, average loss: 0.6433
[11/16 14:37:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 71.85	
[11/16 14:37:41 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.20195768441570727
[11/16 14:44:00 visual_prompt]: Epoch 37 / 100: avg data time: 1.05e+01, avg batch time: 10.8212, average train loss: 0.5746
[11/16 14:44:45 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1577, average loss: 0.6824
[11/16 14:44:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.01	rocauc: 70.59	
[11/16 14:44:45 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.19847315653655914
[11/16 14:51:05 visual_prompt]: Epoch 38 / 100: avg data time: 1.05e+01, avg batch time: 10.8477, average train loss: 0.5860
[11/16 14:51:48 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1561, average loss: 0.6254
[11/16 14:51:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 70.98	
[11/16 14:51:48 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.19489911293384335
[11/16 14:58:07 visual_prompt]: Epoch 39 / 100: avg data time: 1.05e+01, avg batch time: 10.8323, average train loss: 0.6084
[11/16 14:58:51 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1556, average loss: 0.6735
[11/16 14:58:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 72.70	
[11/16 14:58:51 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.1912399080291506
[11/16 15:05:12 visual_prompt]: Epoch 40 / 100: avg data time: 1.05e+01, avg batch time: 10.9004, average train loss: 0.5740
[11/16 15:05:56 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1575, average loss: 0.6229
[11/16 15:05:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.07	rocauc: 71.57	
[11/16 15:05:56 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.1875
[11/16 15:12:17 visual_prompt]: Epoch 41 / 100: avg data time: 1.05e+01, avg batch time: 10.9001, average train loss: 0.5896
[11/16 15:13:01 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.1570, average loss: 0.6358
[11/16 15:13:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 73.02	
[11/16 15:13:01 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.18368394534823634
[11/16 15:19:21 visual_prompt]: Epoch 42 / 100: avg data time: 1.05e+01, avg batch time: 10.8503, average train loss: 0.6004
[11/16 15:20:04 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1582, average loss: 0.7482
[11/16 15:20:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 74.06	
[11/16 15:20:04 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.17979639334863468
[11/16 15:26:23 visual_prompt]: Epoch 43 / 100: avg data time: 1.05e+01, avg batch time: 10.8314, average train loss: 0.6015
[11/16 15:27:06 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1559, average loss: 0.6526
[11/16 15:27:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 71.86	
[11/16 15:27:06 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.17584208038447505
[11/16 15:33:26 visual_prompt]: Epoch 44 / 100: avg data time: 1.05e+01, avg batch time: 10.8499, average train loss: 0.5843
[11/16 15:34:09 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.1554, average loss: 0.6471
[11/16 15:34:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 71.64	
[11/16 15:34:09 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.17182582417698902
[11/16 15:40:34 visual_prompt]: Epoch 45 / 100: avg data time: 1.06e+01, avg batch time: 10.9699, average train loss: 0.5812
[11/16 15:41:17 visual_prompt]: Inference (val):avg data time: 3.54e-05, avg batch time: 0.1584, average loss: 0.5962
[11/16 15:41:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 68.70	rocauc: 76.28	
[11/16 15:41:17 visual_prompt]: Best epoch 45: best metric: -0.596
[11/16 15:41:17 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.1677525179157086
[11/16 15:47:39 visual_prompt]: Epoch 46 / 100: avg data time: 1.06e+01, avg batch time: 10.9187, average train loss: 0.5813
[11/16 15:48:23 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1570, average loss: 0.6101
[11/16 15:48:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 71.54	rocauc: 75.31	
[11/16 15:48:23 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.16362712429686843
[11/16 15:54:46 visual_prompt]: Epoch 47 / 100: avg data time: 1.06e+01, avg batch time: 10.9402, average train loss: 0.5849
[11/16 15:55:29 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1554, average loss: 0.6384
[11/16 15:55:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.01	rocauc: 69.11	
[11/16 15:55:29 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.1594546694771249
[11/16 16:02:08 visual_prompt]: Epoch 48 / 100: avg data time: 1.10e+01, avg batch time: 11.4021, average train loss: 0.5794
[11/16 16:02:52 visual_prompt]: Inference (val):avg data time: 3.56e-05, avg batch time: 0.1562, average loss: 0.6190
[11/16 16:02:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 73.25	
[11/16 16:02:52 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.15524023694995845
[11/16 16:09:11 visual_prompt]: Epoch 49 / 100: avg data time: 1.05e+01, avg batch time: 10.8396, average train loss: 0.5658
[11/16 16:09:54 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1601, average loss: 0.6281
[11/16 16:09:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 72.10	
[11/16 16:09:54 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.1509889613522199
[11/16 16:16:22 visual_prompt]: Epoch 50 / 100: avg data time: 1.07e+01, avg batch time: 11.0835, average train loss: 0.5564
[11/16 16:17:06 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.1615, average loss: 0.7421
[11/16 16:17:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 72.51	
[11/16 16:17:06 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.14670602220836632
[11/16 16:23:36 visual_prompt]: Epoch 51 / 100: avg data time: 1.08e+01, avg batch time: 11.1389, average train loss: 0.5582
[11/16 16:24:20 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1542, average loss: 0.6127
[11/16 16:24:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 72.92	
[11/16 16:24:20 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.14239663762000818
[11/16 16:30:49 visual_prompt]: Epoch 52 / 100: avg data time: 1.07e+01, avg batch time: 11.0957, average train loss: 0.5312
[11/16 16:31:32 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1538, average loss: 0.7145
[11/16 16:31:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 68.27	
[11/16 16:31:32 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.1380660579084567
[11/16 16:38:01 visual_prompt]: Epoch 53 / 100: avg data time: 1.07e+01, avg batch time: 11.1010, average train loss: 0.5395
[11/16 16:38:44 visual_prompt]: Inference (val):avg data time: 4.03e-05, avg batch time: 0.1539, average loss: 0.6169
[11/16 16:38:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 70.33	rocauc: 73.19	
[11/16 16:38:44 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.13371955921801565
[11/16 16:45:11 visual_prompt]: Epoch 54 / 100: avg data time: 1.07e+01, avg batch time: 11.0491, average train loss: 0.5451
[11/16 16:45:58 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.1534, average loss: 0.6507
[11/16 16:45:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 70.42	
[11/16 16:45:58 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.12936243708781264
[11/16 16:52:22 visual_prompt]: Epoch 55 / 100: avg data time: 1.06e+01, avg batch time: 10.9778, average train loss: 0.5852
[11/16 16:53:06 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1536, average loss: 0.6276
[11/16 16:53:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 72.16	
[11/16 16:53:06 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.125
[11/16 16:59:42 visual_prompt]: Epoch 56 / 100: avg data time: 1.10e+01, avg batch time: 11.3279, average train loss: 0.5335
[11/16 17:00:37 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1538, average loss: 0.6648
[11/16 17:00:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.67	rocauc: 70.13	
[11/16 17:00:37 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.12063756291218741
[11/16 17:07:26 visual_prompt]: Epoch 57 / 100: avg data time: 1.13e+01, avg batch time: 11.6670, average train loss: 0.4999
[11/16 17:08:14 visual_prompt]: Inference (val):avg data time: 3.50e-05, avg batch time: 0.1559, average loss: 0.7652
[11/16 17:08:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.67	rocauc: 70.13	
[11/16 17:08:14 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.11628044078198434
[11/16 17:15:03 visual_prompt]: Epoch 58 / 100: avg data time: 1.13e+01, avg batch time: 11.6860, average train loss: 0.4936
[11/16 17:15:49 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1551, average loss: 0.6505
[11/16 17:15:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.89	rocauc: 71.67	
[11/16 17:15:49 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.11193394209154334
[11/16 17:22:24 visual_prompt]: Epoch 59 / 100: avg data time: 1.09e+01, avg batch time: 11.2919, average train loss: 0.5012
[11/16 17:23:08 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1555, average loss: 0.6637
[11/16 17:23:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 69.51	rocauc: 73.57	
[11/16 17:23:08 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.10760336237999185
[11/16 17:29:52 visual_prompt]: Epoch 60 / 100: avg data time: 1.12e+01, avg batch time: 11.5400, average train loss: 0.4897
[11/16 17:30:38 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1557, average loss: 0.6376
[11/16 17:30:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 69.92	rocauc: 73.46	
[11/16 17:30:38 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.10329397779163371
[11/16 17:37:23 visual_prompt]: Epoch 61 / 100: avg data time: 1.12e+01, avg batch time: 11.5780, average train loss: 0.5044
[11/16 17:38:08 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1552, average loss: 0.6946
[11/16 17:38:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.07	rocauc: 73.16	
[11/16 17:38:08 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.0990110386477801
[11/16 17:44:42 visual_prompt]: Epoch 62 / 100: avg data time: 1.09e+01, avg batch time: 11.2670, average train loss: 0.4868
[11/16 17:45:27 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1560, average loss: 0.6522
[11/16 17:45:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 69.92	rocauc: 72.58	
[11/16 17:45:27 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.09475976305004155
[11/16 17:52:02 visual_prompt]: Epoch 63 / 100: avg data time: 1.09e+01, avg batch time: 11.2827, average train loss: 0.4501
[11/16 17:52:47 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1580, average loss: 0.7490
[11/16 17:52:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.07	rocauc: 70.05	
[11/16 17:52:47 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.09054533052287511
[11/16 17:59:23 visual_prompt]: Epoch 64 / 100: avg data time: 1.10e+01, avg batch time: 11.3295, average train loss: 0.4760
[11/16 18:00:08 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.1557, average loss: 0.7315
[11/16 18:00:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.07	rocauc: 71.32	
[11/16 18:00:08 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.08637287570313158
[11/16 18:06:45 visual_prompt]: Epoch 65 / 100: avg data time: 1.10e+01, avg batch time: 11.3440, average train loss: 0.4402
[11/16 18:07:31 visual_prompt]: Inference (val):avg data time: 3.59e-05, avg batch time: 0.1590, average loss: 0.6703
[11/16 18:07:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 72.10	
[11/16 18:07:31 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.08224748208429142
[11/16 18:14:07 visual_prompt]: Epoch 66 / 100: avg data time: 1.10e+01, avg batch time: 11.3277, average train loss: 0.4435
[11/16 18:14:52 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1560, average loss: 0.6487
[11/16 18:14:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.89	rocauc: 74.22	
[11/16 18:14:52 visual_prompt]: Stopping early.
[11/16 18:14:52 visual_prompt]: Rank of current process: 0. World size: 1
[11/16 18:14:52 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/16 18:14:52 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/16 18:14:52 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/16 18:14:52 visual_prompt]: Training with config:
[11/16 18:14:52 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr0.25_wd0.0001/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.25, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/16 18:14:52 visual_prompt]: Loading training data...
[11/16 18:14:52 visual_prompt]: Constructing mammo-cbis dataset train...
[11/16 18:14:52 visual_prompt]: Loading validation data...
[11/16 18:14:52 visual_prompt]: Constructing mammo-cbis dataset val...
[11/16 18:14:52 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[11/16 18:14:58 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[11/16 18:14:58 visual_prompt]: tuned percent:0.536
[11/16 18:14:58 visual_prompt]: Device used for model: 0
[11/16 18:14:58 visual_prompt]: Setting up Evaluator...
[11/16 18:14:58 visual_prompt]: Setting up Trainer...
[11/16 18:14:58 visual_prompt]: 	Setting up the optimizer...
[11/16 18:14:58 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/16 18:21:33 visual_prompt]: Epoch 1 / 100: avg data time: 1.09e+01, avg batch time: 11.2820, average train loss: 1.4017
[11/16 18:22:18 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1557, average loss: 1.2969
[11/16 18:22:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[11/16 18:22:18 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.025
[11/16 18:28:52 visual_prompt]: Epoch 2 / 100: avg data time: 1.09e+01, avg batch time: 11.2776, average train loss: 1.4240
[11/16 18:29:37 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1552, average loss: 0.6896
[11/16 18:29:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 52.12	
[11/16 18:29:37 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.05
[11/16 18:36:12 visual_prompt]: Epoch 3 / 100: avg data time: 1.09e+01, avg batch time: 11.2734, average train loss: 0.7053
[11/16 18:36:57 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1561, average loss: 0.6911
[11/16 18:36:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.93	
[11/16 18:36:57 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.075
[11/16 18:43:33 visual_prompt]: Epoch 4 / 100: avg data time: 1.10e+01, avg batch time: 11.3033, average train loss: 0.6941
[11/16 18:44:18 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1538, average loss: 0.6937
[11/16 18:44:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.80	
[11/16 18:44:18 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.1
[11/16 18:50:52 visual_prompt]: Epoch 5 / 100: avg data time: 1.09e+01, avg batch time: 11.2667, average train loss: 0.7293
[11/16 18:51:37 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1541, average loss: 0.7034
[11/16 18:51:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 46.34	rocauc: 58.65	
[11/16 18:51:37 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.125
[11/16 18:57:57 visual_prompt]: Epoch 6 / 100: avg data time: 1.05e+01, avg batch time: 10.8446, average train loss: 0.7478
[11/16 18:58:40 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1545, average loss: 0.6728
[11/16 18:58:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 61.69	
[11/16 18:58:40 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.15
[11/16 19:04:53 visual_prompt]: Epoch 7 / 100: avg data time: 1.03e+01, avg batch time: 10.6686, average train loss: 0.7139
[11/16 19:05:36 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1542, average loss: 0.6679
[11/16 19:05:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 62.05	
[11/16 19:05:36 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.175
[11/16 19:11:49 visual_prompt]: Epoch 8 / 100: avg data time: 1.03e+01, avg batch time: 10.6720, average train loss: 0.7062
[11/16 19:12:32 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1539, average loss: 0.6654
[11/16 19:12:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 61.99	
[11/16 19:12:32 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.2
[11/16 19:18:47 visual_prompt]: Epoch 9 / 100: avg data time: 1.03e+01, avg batch time: 10.7003, average train loss: 0.6886
[11/16 19:19:29 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1556, average loss: 0.6923
[11/16 19:19:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 64.92	
[11/16 19:19:29 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.225
[11/16 19:25:43 visual_prompt]: Epoch 10 / 100: avg data time: 1.03e+01, avg batch time: 10.6779, average train loss: 0.6645
[11/16 19:26:26 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1558, average loss: 0.6487
[11/16 19:26:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 66.76	
[11/16 19:26:26 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.25
[11/16 19:32:40 visual_prompt]: Epoch 11 / 100: avg data time: 1.03e+01, avg batch time: 10.6876, average train loss: 0.6771
[11/16 19:33:22 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1542, average loss: 0.6599
[11/16 19:33:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.54	rocauc: 69.56	
[11/16 19:33:22 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.24992385337738698
[11/16 19:39:36 visual_prompt]: Epoch 12 / 100: avg data time: 1.03e+01, avg batch time: 10.6773, average train loss: 0.6733
[11/16 19:40:19 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1586, average loss: 0.7517
[11/16 19:40:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 48.78	rocauc: 70.07	
[11/16 19:40:19 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.24969550628247802
[11/16 19:46:33 visual_prompt]: Epoch 13 / 100: avg data time: 1.03e+01, avg batch time: 10.6971, average train loss: 0.7598
[11/16 19:47:16 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1557, average loss: 0.6845
[11/16 19:47:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 67.20	
[11/16 19:47:16 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.24931523692103416
[11/16 19:53:29 visual_prompt]: Epoch 14 / 100: avg data time: 1.03e+01, avg batch time: 10.6542, average train loss: 0.6848
[11/16 19:54:11 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1554, average loss: 0.7344
[11/16 19:54:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 70.05	
[11/16 19:54:11 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.2487835085926963
[11/16 20:00:26 visual_prompt]: Epoch 15 / 100: avg data time: 1.03e+01, avg batch time: 10.7036, average train loss: 0.6973
[11/16 20:01:09 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1537, average loss: 0.8251
[11/16 20:01:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 69.00	
[11/16 20:01:09 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.24810096912652602
[11/16 20:07:24 visual_prompt]: Epoch 16 / 100: avg data time: 1.04e+01, avg batch time: 10.7122, average train loss: 0.7038
[11/16 20:08:07 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1537, average loss: 0.7210
[11/16 20:08:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.54	rocauc: 70.83	
[11/16 20:08:07 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.2472684500917257
[11/16 20:14:22 visual_prompt]: Epoch 17 / 100: avg data time: 1.04e+01, avg batch time: 10.7140, average train loss: 0.6889
[11/16 20:15:04 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1537, average loss: 0.6296
[11/16 20:15:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 71.48	
[11/16 20:15:04 visual_prompt]: Best epoch 17: best metric: -0.630
[11/16 20:15:04 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.24628696578449955
[11/16 20:21:22 visual_prompt]: Epoch 18 / 100: avg data time: 1.04e+01, avg batch time: 10.7928, average train loss: 0.6597
[11/16 20:22:05 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1538, average loss: 0.6428
[11/16 20:22:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 69.73	
[11/16 20:22:05 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.24515771199228986
[11/16 20:28:20 visual_prompt]: Epoch 19 / 100: avg data time: 1.04e+01, avg batch time: 10.7114, average train loss: 0.6638
[11/16 20:29:03 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1537, average loss: 0.6310
[11/16 20:29:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.07	rocauc: 70.41	
[11/16 20:29:03 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.2438820645368942
[11/16 20:35:20 visual_prompt]: Epoch 20 / 100: avg data time: 1.04e+01, avg batch time: 10.7699, average train loss: 0.6083
[11/16 20:36:03 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1538, average loss: 0.6869
[11/16 20:36:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 70.59	
[11/16 20:36:03 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.24246157759823855
[11/16 20:42:19 visual_prompt]: Epoch 21 / 100: avg data time: 1.04e+01, avg batch time: 10.7315, average train loss: 0.6039
[11/16 20:43:02 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1534, average loss: 0.6265
[11/16 20:43:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 69.92	rocauc: 71.36	
[11/16 20:43:02 visual_prompt]: Best epoch 21: best metric: -0.627
[11/16 20:43:02 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.24089798182084843
[11/16 20:49:16 visual_prompt]: Epoch 22 / 100: avg data time: 1.03e+01, avg batch time: 10.6963, average train loss: 0.5869
[11/16 20:49:59 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1535, average loss: 0.6334
[11/16 20:49:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 69.79	
[11/16 20:49:59 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.2391931822053251
[11/16 20:56:15 visual_prompt]: Epoch 23 / 100: avg data time: 1.04e+01, avg batch time: 10.7242, average train loss: 0.5979
[11/16 20:56:58 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1550, average loss: 0.6341
[11/16 20:56:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 70.16	
[11/16 20:56:58 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.23734925578739588
[11/16 21:03:13 visual_prompt]: Epoch 24 / 100: avg data time: 1.04e+01, avg batch time: 10.7160, average train loss: 0.6274
[11/16 21:03:56 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1537, average loss: 0.7203
[11/16 21:03:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 70.25	
[11/16 21:03:56 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.23536844910736587
[11/16 21:10:11 visual_prompt]: Epoch 25 / 100: avg data time: 1.04e+01, avg batch time: 10.7316, average train loss: 0.5901
[11/16 21:10:54 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1536, average loss: 0.6145
[11/16 21:10:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 72.58	
[11/16 21:10:54 visual_prompt]: Best epoch 25: best metric: -0.615
[11/16 21:10:54 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.23325317547305485
[11/16 21:17:11 visual_prompt]: Epoch 26 / 100: avg data time: 1.04e+01, avg batch time: 10.7472, average train loss: 0.6197
[11/16 21:17:54 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1536, average loss: 0.6446
[11/16 21:17:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 72.05	
[11/16 21:17:54 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.23100601201955323
[11/16 21:24:09 visual_prompt]: Epoch 27 / 100: avg data time: 1.04e+01, avg batch time: 10.7260, average train loss: 0.5683
[11/16 21:24:52 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1538, average loss: 0.6487
[11/16 21:24:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 67.55	
[11/16 21:24:52 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.2286296965693802
[11/16 21:31:07 visual_prompt]: Epoch 28 / 100: avg data time: 1.04e+01, avg batch time: 10.7274, average train loss: 0.5906
[11/16 21:31:50 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1536, average loss: 0.6432
[11/16 21:31:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 70.02	
[11/16 21:31:50 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.22612712429686843
[11/16 21:38:06 visual_prompt]: Epoch 29 / 100: avg data time: 1.04e+01, avg batch time: 10.7397, average train loss: 0.5563
[11/16 21:38:49 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1537, average loss: 0.6407
[11/16 21:38:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 72.64	
[11/16 21:38:49 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.22350134420084022
[11/16 21:45:04 visual_prompt]: Epoch 30 / 100: avg data time: 1.04e+01, avg batch time: 10.7275, average train loss: 0.5335
[11/16 21:45:47 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1534, average loss: 0.6586
[11/16 21:45:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 73.16	
[11/16 21:45:47 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.22075555538987224
[11/16 21:52:03 visual_prompt]: Epoch 31 / 100: avg data time: 1.04e+01, avg batch time: 10.7190, average train loss: 0.5178
[11/16 21:52:45 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1567, average loss: 0.6539
[11/16 21:52:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 70.83	
[11/16 21:52:45 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.21789310318467428
[11/16 21:59:02 visual_prompt]: Epoch 32 / 100: avg data time: 1.04e+01, avg batch time: 10.7501, average train loss: 0.5555
[11/16 21:59:45 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1536, average loss: 0.6706
[11/16 21:59:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 70.54	
[11/16 21:59:45 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.21491747504233139
[11/16 22:06:00 visual_prompt]: Epoch 33 / 100: avg data time: 1.04e+01, avg batch time: 10.7304, average train loss: 0.5453
[11/16 22:06:43 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1547, average loss: 0.6352
[11/16 22:06:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.07	rocauc: 71.97	
[11/16 22:06:43 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.21183229630737466
[11/16 22:12:58 visual_prompt]: Epoch 34 / 100: avg data time: 1.04e+01, avg batch time: 10.7180, average train loss: 0.5173
[11/16 22:13:41 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1535, average loss: 0.6278
[11/16 22:13:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.07	rocauc: 71.38	
[11/16 22:13:41 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.20864132579485728
[11/16 22:19:57 visual_prompt]: Epoch 35 / 100: avg data time: 1.04e+01, avg batch time: 10.7248, average train loss: 0.5068
[11/16 22:20:40 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1534, average loss: 0.8937
[11/16 22:20:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 65.80	
[11/16 22:20:40 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.2053484512108174
[11/16 22:26:55 visual_prompt]: Epoch 36 / 100: avg data time: 1.04e+01, avg batch time: 10.7170, average train loss: 0.5282
[11/16 22:27:37 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1535, average loss: 0.6701
[11/16 22:27:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 69.08	
[11/16 22:27:37 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.20195768441570727
[11/16 22:33:51 visual_prompt]: Epoch 37 / 100: avg data time: 1.03e+01, avg batch time: 10.6879, average train loss: 0.4958
[11/16 22:34:34 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1535, average loss: 0.7004
[11/16 22:34:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.89	rocauc: 72.07	
[11/16 22:34:34 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.19847315653655914
[11/16 22:40:52 visual_prompt]: Epoch 38 / 100: avg data time: 1.04e+01, avg batch time: 10.7879, average train loss: 0.4781
[11/16 22:41:35 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1556, average loss: 0.6514
[11/16 22:41:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.89	rocauc: 72.74	
[11/16 22:41:35 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.19489911293384335
[11/16 22:47:52 visual_prompt]: Epoch 39 / 100: avg data time: 1.04e+01, avg batch time: 10.7626, average train loss: 0.5021
[11/16 22:48:35 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1535, average loss: 0.6596
[11/16 22:48:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 72.05	
[11/16 22:48:35 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.1912399080291506
[11/16 22:54:50 visual_prompt]: Epoch 40 / 100: avg data time: 1.04e+01, avg batch time: 10.7316, average train loss: 0.5110
[11/16 22:55:33 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1556, average loss: 0.7078
[11/16 22:55:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 70.36	
[11/16 22:55:33 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.1875
[11/16 23:01:49 visual_prompt]: Epoch 41 / 100: avg data time: 1.04e+01, avg batch time: 10.7414, average train loss: 0.5362
[11/16 23:02:32 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1534, average loss: 0.6709
[11/16 23:02:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 68.82	
[11/16 23:02:32 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.18368394534823634
[11/16 23:08:48 visual_prompt]: Epoch 42 / 100: avg data time: 1.04e+01, avg batch time: 10.7332, average train loss: 0.4808
[11/16 23:09:31 visual_prompt]: Inference (val):avg data time: 3.47e-05, avg batch time: 0.1537, average loss: 0.7463
[11/16 23:09:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 72.57	
[11/16 23:09:31 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.17979639334863468
[11/16 23:15:46 visual_prompt]: Epoch 43 / 100: avg data time: 1.04e+01, avg batch time: 10.7267, average train loss: 0.4993
[11/16 23:16:29 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1535, average loss: 0.6697
[11/16 23:16:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 71.73	
[11/16 23:16:29 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.17584208038447505
[11/16 23:22:44 visual_prompt]: Epoch 44 / 100: avg data time: 1.04e+01, avg batch time: 10.7079, average train loss: 0.4370
[11/16 23:23:27 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1556, average loss: 0.8222
[11/16 23:23:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 69.03	
[11/16 23:23:27 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.17182582417698902
[11/16 23:29:43 visual_prompt]: Epoch 45 / 100: avg data time: 1.04e+01, avg batch time: 10.7459, average train loss: 0.4197
[11/16 23:30:26 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1533, average loss: 0.8237
[11/16 23:30:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 69.09	
[11/16 23:30:26 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.1677525179157086
[11/16 23:36:41 visual_prompt]: Epoch 46 / 100: avg data time: 1.04e+01, avg batch time: 10.7147, average train loss: 0.4359
[11/16 23:37:24 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1536, average loss: 0.7773
[11/16 23:37:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 69.25	
[11/16 23:37:24 visual_prompt]: Stopping early.
[11/16 23:37:24 visual_prompt]: Rank of current process: 0. World size: 1
[11/16 23:37:24 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/16 23:37:24 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/16 23:37:24 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/16 23:37:24 visual_prompt]: Training with config:
[11/16 23:37:24 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr0.25_wd0.0/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.25, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/16 23:37:24 visual_prompt]: Loading training data...
[11/16 23:37:24 visual_prompt]: Constructing mammo-cbis dataset train...
[11/16 23:37:24 visual_prompt]: Loading validation data...
[11/16 23:37:24 visual_prompt]: Constructing mammo-cbis dataset val...
[11/16 23:37:24 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[11/16 23:37:27 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[11/16 23:37:27 visual_prompt]: tuned percent:0.536
[11/16 23:37:27 visual_prompt]: Device used for model: 0
[11/16 23:37:27 visual_prompt]: Setting up Evaluator...
[11/16 23:37:27 visual_prompt]: Setting up Trainer...
[11/16 23:37:27 visual_prompt]: 	Setting up the optimizer...
[11/16 23:37:27 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/16 23:43:43 visual_prompt]: Epoch 1 / 100: avg data time: 1.04e+01, avg batch time: 10.7346, average train loss: 1.4017
[11/16 23:44:26 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.1548, average loss: 1.2969
[11/16 23:44:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[11/16 23:44:26 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.025
[11/16 23:50:41 visual_prompt]: Epoch 2 / 100: avg data time: 1.04e+01, avg batch time: 10.7137, average train loss: 1.4240
[11/16 23:51:24 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1535, average loss: 0.6896
[11/16 23:51:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 52.10	
[11/16 23:51:24 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.05
[11/16 23:57:41 visual_prompt]: Epoch 3 / 100: avg data time: 1.04e+01, avg batch time: 10.7804, average train loss: 0.7053
[11/16 23:58:26 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1534, average loss: 0.6910
[11/16 23:58:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.86	
[11/16 23:58:26 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.075
[11/17 00:04:53 visual_prompt]: Epoch 4 / 100: avg data time: 1.07e+01, avg batch time: 11.0672, average train loss: 0.6941
[11/17 00:05:36 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1590, average loss: 0.6943
[11/17 00:05:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.92	
[11/17 00:05:36 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.1
[11/17 00:11:53 visual_prompt]: Epoch 5 / 100: avg data time: 1.04e+01, avg batch time: 10.7557, average train loss: 0.7331
[11/17 00:12:35 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1555, average loss: 0.6873
[11/17 00:12:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 59.26	
[11/17 00:12:35 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.125
[11/17 00:18:55 visual_prompt]: Epoch 6 / 100: avg data time: 1.05e+01, avg batch time: 10.8390, average train loss: 0.7440
[11/17 00:19:38 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.1552, average loss: 0.6740
[11/17 00:19:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 61.84	
[11/17 00:19:38 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.15
[11/17 00:25:56 visual_prompt]: Epoch 7 / 100: avg data time: 1.04e+01, avg batch time: 10.7863, average train loss: 0.7171
[11/17 00:26:39 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1572, average loss: 0.6689
[11/17 00:26:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 61.83	
[11/17 00:26:39 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.175
[11/17 00:32:55 visual_prompt]: Epoch 8 / 100: avg data time: 1.04e+01, avg batch time: 10.7621, average train loss: 0.7066
[11/17 00:33:38 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1578, average loss: 0.6648
[11/17 00:33:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 62.47	
[11/17 00:33:38 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.2
[11/17 00:39:56 visual_prompt]: Epoch 9 / 100: avg data time: 1.04e+01, avg batch time: 10.7869, average train loss: 0.6864
[11/17 00:40:39 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1549, average loss: 0.6958
[11/17 00:40:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 66.03	
[11/17 00:40:39 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.225
[11/17 00:46:55 visual_prompt]: Epoch 10 / 100: avg data time: 1.04e+01, avg batch time: 10.7504, average train loss: 0.6628
[11/17 00:47:38 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1561, average loss: 0.6445
[11/17 00:47:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 67.86	
[11/17 00:47:38 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.25
[11/17 00:53:56 visual_prompt]: Epoch 11 / 100: avg data time: 1.04e+01, avg batch time: 10.7777, average train loss: 0.6792
[11/17 00:54:39 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1561, average loss: 0.6552
[11/17 00:54:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 68.42	
[11/17 00:54:39 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.24992385337738698
[11/17 01:00:56 visual_prompt]: Epoch 12 / 100: avg data time: 1.04e+01, avg batch time: 10.7900, average train loss: 0.6736
[11/17 01:01:39 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1556, average loss: 0.7371
[11/17 01:01:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 51.22	rocauc: 69.09	
[11/17 01:01:39 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.24969550628247802
[11/17 01:07:56 visual_prompt]: Epoch 13 / 100: avg data time: 1.04e+01, avg batch time: 10.7554, average train loss: 0.7443
[11/17 01:08:39 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.1574, average loss: 0.7039
[11/17 01:08:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 69.02	
[11/17 01:08:39 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.24931523692103416
[11/17 01:14:55 visual_prompt]: Epoch 14 / 100: avg data time: 1.04e+01, avg batch time: 10.7443, average train loss: 0.6801
[11/17 01:15:38 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1552, average loss: 0.7292
[11/17 01:15:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 71.78	
[11/17 01:15:38 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.2487835085926963
[11/17 01:21:55 visual_prompt]: Epoch 15 / 100: avg data time: 1.04e+01, avg batch time: 10.7767, average train loss: 0.6873
[11/17 01:22:38 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1558, average loss: 0.8067
[11/17 01:22:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 70.88	
[11/17 01:22:38 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.24810096912652602
[11/17 01:28:54 visual_prompt]: Epoch 16 / 100: avg data time: 1.04e+01, avg batch time: 10.7498, average train loss: 0.6775
[11/17 01:29:37 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1551, average loss: 0.8387
[11/17 01:29:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 70.67	
[11/17 01:29:37 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.2472684500917257
[11/17 01:35:53 visual_prompt]: Epoch 17 / 100: avg data time: 1.04e+01, avg batch time: 10.7404, average train loss: 0.7107
[11/17 01:36:36 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.1594, average loss: 0.6252
[11/17 01:36:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 71.39	
[11/17 01:36:36 visual_prompt]: Best epoch 17: best metric: -0.625
[11/17 01:36:36 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.24628696578449955
[11/17 01:42:52 visual_prompt]: Epoch 18 / 100: avg data time: 1.04e+01, avg batch time: 10.7419, average train loss: 0.6610
[11/17 01:43:35 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1557, average loss: 0.6284
[11/17 01:43:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 70.66	
[11/17 01:43:35 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.24515771199228986
[11/17 01:49:53 visual_prompt]: Epoch 19 / 100: avg data time: 1.04e+01, avg batch time: 10.8023, average train loss: 0.6644
[11/17 01:50:36 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1557, average loss: 0.6291
[11/17 01:50:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 69.97	
[11/17 01:50:36 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.2438820645368942
[11/17 01:56:53 visual_prompt]: Epoch 20 / 100: avg data time: 1.04e+01, avg batch time: 10.7507, average train loss: 0.6069
[11/17 01:57:36 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.1561, average loss: 0.6020
[11/17 01:57:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 72.82	
[11/17 01:57:36 visual_prompt]: Best epoch 20: best metric: -0.602
[11/17 01:57:36 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.24246157759823855
[11/17 02:03:52 visual_prompt]: Epoch 21 / 100: avg data time: 1.04e+01, avg batch time: 10.7663, average train loss: 0.6149
[11/17 02:04:35 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1587, average loss: 0.6033
[11/17 02:04:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 73.15	
[11/17 02:04:35 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.24089798182084843
[11/17 02:10:52 visual_prompt]: Epoch 22 / 100: avg data time: 1.04e+01, avg batch time: 10.7497, average train loss: 0.6226
[11/17 02:11:35 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1557, average loss: 0.6335
[11/17 02:11:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 72.48	
[11/17 02:11:35 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.2391931822053251
[11/17 02:17:51 visual_prompt]: Epoch 23 / 100: avg data time: 1.04e+01, avg batch time: 10.7462, average train loss: 0.6043
[11/17 02:18:34 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1548, average loss: 0.6338
[11/17 02:18:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 70.27	
[11/17 02:18:34 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.23734925578739588
[11/17 02:24:54 visual_prompt]: Epoch 24 / 100: avg data time: 1.05e+01, avg batch time: 10.8525, average train loss: 0.6458
[11/17 02:25:37 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1544, average loss: 0.6417
[11/17 02:25:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 72.02	
[11/17 02:25:37 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.23536844910736587
[11/17 02:31:59 visual_prompt]: Epoch 25 / 100: avg data time: 1.05e+01, avg batch time: 10.8908, average train loss: 0.5915
[11/17 02:32:42 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1540, average loss: 0.6203
[11/17 02:32:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 72.26	
[11/17 02:32:42 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.23325317547305485
[11/17 02:39:03 visual_prompt]: Epoch 26 / 100: avg data time: 1.05e+01, avg batch time: 10.8803, average train loss: 0.6273
[11/17 02:39:46 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1539, average loss: 0.5987
[11/17 02:39:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 71.14	rocauc: 74.00	
[11/17 02:39:46 visual_prompt]: Best epoch 26: best metric: -0.599
[11/17 02:39:46 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.23100601201955323
[11/17 02:46:06 visual_prompt]: Epoch 27 / 100: avg data time: 1.05e+01, avg batch time: 10.8517, average train loss: 0.5716
[11/17 02:46:50 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.1539, average loss: 0.6553
[11/17 02:46:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 68.53	
[11/17 02:46:50 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.2286296965693802
[11/17 02:53:11 visual_prompt]: Epoch 28 / 100: avg data time: 1.05e+01, avg batch time: 10.8750, average train loss: 0.6112
[11/17 02:53:54 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.1575, average loss: 0.6402
[11/17 02:53:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 71.70	
[11/17 02:53:54 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.22612712429686843
[11/17 03:00:17 visual_prompt]: Epoch 29 / 100: avg data time: 1.06e+01, avg batch time: 10.9313, average train loss: 0.5532
[11/17 03:01:00 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1538, average loss: 0.6537
[11/17 03:01:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 70.34	
[11/17 03:01:00 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.22350134420084022
[11/17 03:07:22 visual_prompt]: Epoch 30 / 100: avg data time: 1.05e+01, avg batch time: 10.8939, average train loss: 0.5478
[11/17 03:08:05 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.1537, average loss: 0.6180
[11/17 03:08:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 68.29	rocauc: 72.00	
[11/17 03:08:05 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.22075555538987224
[11/17 03:14:26 visual_prompt]: Epoch 31 / 100: avg data time: 1.05e+01, avg batch time: 10.8877, average train loss: 0.5215
[11/17 03:15:10 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1535, average loss: 0.6603
[11/17 03:15:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.07	rocauc: 71.18	
[11/17 03:15:10 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.21789310318467428
[11/17 03:21:32 visual_prompt]: Epoch 32 / 100: avg data time: 1.06e+01, avg batch time: 10.9192, average train loss: 0.5315
[11/17 03:22:16 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.1535, average loss: 0.6632
[11/17 03:22:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 70.74	
[11/17 03:22:16 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.21491747504233139
[11/17 03:28:37 visual_prompt]: Epoch 33 / 100: avg data time: 1.05e+01, avg batch time: 10.9052, average train loss: 0.5278
[11/17 03:29:21 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1554, average loss: 0.6460
[11/17 03:29:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 72.37	
[11/17 03:29:21 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.21183229630737466
[11/17 03:35:42 visual_prompt]: Epoch 34 / 100: avg data time: 1.05e+01, avg batch time: 10.8711, average train loss: 0.4912
[11/17 03:36:25 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1537, average loss: 0.6754
[11/17 03:36:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 71.71	
[11/17 03:36:25 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.20864132579485728
[11/17 03:42:46 visual_prompt]: Epoch 35 / 100: avg data time: 1.05e+01, avg batch time: 10.8842, average train loss: 0.5140
[11/17 03:43:30 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1535, average loss: 0.7196
[11/17 03:43:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 66.69	
[11/17 03:43:30 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.2053484512108174
[11/17 03:49:51 visual_prompt]: Epoch 36 / 100: avg data time: 1.05e+01, avg batch time: 10.8942, average train loss: 0.5279
[11/17 03:50:35 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1538, average loss: 0.6947
[11/17 03:50:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 70.56	
[11/17 03:50:35 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.20195768441570727
[11/17 03:56:56 visual_prompt]: Epoch 37 / 100: avg data time: 1.05e+01, avg batch time: 10.8848, average train loss: 0.5511
[11/17 03:57:39 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1538, average loss: 0.9179
[11/17 03:57:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 71.52	
[11/17 03:57:39 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.19847315653655914
[11/17 04:04:01 visual_prompt]: Epoch 38 / 100: avg data time: 1.06e+01, avg batch time: 10.9086, average train loss: 0.5312
[11/17 04:04:45 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1538, average loss: 0.7600
[11/17 04:04:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 70.42	
[11/17 04:04:45 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.19489911293384335
[11/17 04:11:07 visual_prompt]: Epoch 39 / 100: avg data time: 1.06e+01, avg batch time: 10.9091, average train loss: 0.5952
[11/17 04:11:50 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1543, average loss: 0.6483
[11/17 04:11:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 72.46	
[11/17 04:11:50 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.1912399080291506
[11/17 04:18:11 visual_prompt]: Epoch 40 / 100: avg data time: 1.05e+01, avg batch time: 10.8849, average train loss: 0.5115
[11/17 04:18:55 visual_prompt]: Inference (val):avg data time: 3.26e-05, avg batch time: 0.1537, average loss: 0.6356
[11/17 04:18:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 71.14	
[11/17 04:18:55 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.1875
[11/17 04:25:17 visual_prompt]: Epoch 41 / 100: avg data time: 1.05e+01, avg batch time: 10.9009, average train loss: 0.4952
[11/17 04:26:00 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.1547, average loss: 0.6979
[11/17 04:26:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 70.94	
[11/17 04:26:00 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.18368394534823634
[11/17 04:32:22 visual_prompt]: Epoch 42 / 100: avg data time: 1.05e+01, avg batch time: 10.9002, average train loss: 0.4819
[11/17 04:33:05 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.1533, average loss: 0.8223
[11/17 04:33:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 66.61	
[11/17 04:33:05 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.17979639334863468
[11/17 04:39:27 visual_prompt]: Epoch 43 / 100: avg data time: 1.06e+01, avg batch time: 10.9057, average train loss: 0.4643
[11/17 04:40:11 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1537, average loss: 0.6768
[11/17 04:40:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.07	rocauc: 72.31	
[11/17 04:40:11 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.17584208038447505
[11/17 04:46:32 visual_prompt]: Epoch 44 / 100: avg data time: 1.05e+01, avg batch time: 10.8916, average train loss: 0.4361
[11/17 04:47:15 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1536, average loss: 0.7540
[11/17 04:47:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 70.16	
[11/17 04:47:15 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.17182582417698902
[11/17 04:53:37 visual_prompt]: Epoch 45 / 100: avg data time: 1.06e+01, avg batch time: 10.9081, average train loss: 0.4342
[11/17 04:54:21 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1540, average loss: 0.6642
[11/17 04:54:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 68.29	rocauc: 74.81	
[11/17 04:54:21 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.1677525179157086
[11/17 05:00:42 visual_prompt]: Epoch 46 / 100: avg data time: 1.05e+01, avg batch time: 10.8945, average train loss: 0.4135
[11/17 05:01:26 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.1541, average loss: 0.8597
[11/17 05:01:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 69.31	
[11/17 05:01:26 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.16362712429686843
[11/17 05:07:47 visual_prompt]: Epoch 47 / 100: avg data time: 1.05e+01, avg batch time: 10.8843, average train loss: 0.4439
[11/17 05:08:30 visual_prompt]: Inference (val):avg data time: 3.46e-05, avg batch time: 0.1545, average loss: 0.7673
[11/17 05:08:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 66.40	
[11/17 05:08:30 visual_prompt]: Stopping early.
[11/17 05:08:31 visual_prompt]: Rank of current process: 0. World size: 1
[11/17 05:08:31 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/17 05:08:31 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/17 05:08:31 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/17 05:08:31 visual_prompt]: Training with config:
[11/17 05:08:31 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr0.1_wd0.01/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.1, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/17 05:08:31 visual_prompt]: Loading training data...
[11/17 05:08:31 visual_prompt]: Constructing mammo-cbis dataset train...
[11/17 05:08:31 visual_prompt]: Loading validation data...
[11/17 05:08:31 visual_prompt]: Constructing mammo-cbis dataset val...
[11/17 05:08:31 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[11/17 05:08:33 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[11/17 05:08:33 visual_prompt]: tuned percent:0.536
[11/17 05:08:33 visual_prompt]: Device used for model: 0
[11/17 05:08:33 visual_prompt]: Setting up Evaluator...
[11/17 05:08:33 visual_prompt]: Setting up Trainer...
[11/17 05:08:33 visual_prompt]: 	Setting up the optimizer...
[11/17 05:08:33 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/17 05:14:55 visual_prompt]: Epoch 1 / 100: avg data time: 1.06e+01, avg batch time: 10.9105, average train loss: 1.4017
[11/17 05:15:39 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.1557, average loss: 1.2969
[11/17 05:15:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[11/17 05:15:39 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.010000000000000002
[11/17 05:22:00 visual_prompt]: Epoch 2 / 100: avg data time: 1.05e+01, avg batch time: 10.8798, average train loss: 1.0705
[11/17 05:22:43 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1541, average loss: 0.6907
[11/17 05:22:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 47.90	
[11/17 05:22:43 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.020000000000000004
[11/17 05:29:05 visual_prompt]: Epoch 3 / 100: avg data time: 1.05e+01, avg batch time: 10.8994, average train loss: 0.7019
[11/17 05:29:48 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1566, average loss: 0.6936
[11/17 05:29:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.38	
[11/17 05:29:48 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.03
[11/17 05:36:10 visual_prompt]: Epoch 4 / 100: avg data time: 1.06e+01, avg batch time: 10.9132, average train loss: 0.6916
[11/17 05:36:54 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.1540, average loss: 0.6810
[11/17 05:36:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 59.06	
[11/17 05:36:54 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.04000000000000001
[11/17 05:43:15 visual_prompt]: Epoch 5 / 100: avg data time: 1.05e+01, avg batch time: 10.8807, average train loss: 0.7094
[11/17 05:43:58 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.1539, average loss: 0.6902
[11/17 05:43:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.81	
[11/17 05:43:58 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.05
[11/17 05:50:21 visual_prompt]: Epoch 6 / 100: avg data time: 1.06e+01, avg batch time: 10.9134, average train loss: 0.7276
[11/17 05:51:04 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1548, average loss: 0.6840
[11/17 05:51:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 57.69	
[11/17 05:51:04 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.06
[11/17 05:57:26 visual_prompt]: Epoch 7 / 100: avg data time: 1.06e+01, avg batch time: 10.9192, average train loss: 0.6935
[11/17 05:58:10 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.1574, average loss: 0.7299
[11/17 05:58:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.42	
[11/17 05:58:10 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.06999999999999999
[11/17 06:04:32 visual_prompt]: Epoch 8 / 100: avg data time: 1.05e+01, avg batch time: 10.8938, average train loss: 0.7299
[11/17 06:05:15 visual_prompt]: Inference (val):avg data time: 4.11e-05, avg batch time: 0.1537, average loss: 0.6855
[11/17 06:05:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.34	
[11/17 06:05:15 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.08000000000000002
[11/17 06:11:38 visual_prompt]: Epoch 9 / 100: avg data time: 1.06e+01, avg batch time: 10.9264, average train loss: 0.6886
[11/17 06:12:21 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1542, average loss: 0.7100
[11/17 06:12:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.02	
[11/17 06:12:21 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.09000000000000001
[11/17 06:18:42 visual_prompt]: Epoch 10 / 100: avg data time: 1.05e+01, avg batch time: 10.8884, average train loss: 0.6977
[11/17 06:19:26 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1563, average loss: 0.6916
[11/17 06:19:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.20	
[11/17 06:19:26 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.1
[11/17 06:25:47 visual_prompt]: Epoch 11 / 100: avg data time: 1.05e+01, avg batch time: 10.8928, average train loss: 0.6889
[11/17 06:26:31 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1551, average loss: 0.6854
[11/17 06:26:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 59.79	
[11/17 06:26:31 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0999695413509548
[11/17 06:32:52 visual_prompt]: Epoch 12 / 100: avg data time: 1.05e+01, avg batch time: 10.8938, average train loss: 0.7003
[11/17 06:33:36 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.1556, average loss: 0.6877
[11/17 06:33:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.50	
[11/17 06:33:36 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.09987820251299122
[11/17 06:39:58 visual_prompt]: Epoch 13 / 100: avg data time: 1.05e+01, avg batch time: 10.9011, average train loss: 0.7056
[11/17 06:40:41 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.1537, average loss: 0.7145
[11/17 06:40:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.20	
[11/17 06:40:41 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.09972609476841367
[11/17 06:47:03 visual_prompt]: Epoch 14 / 100: avg data time: 1.05e+01, avg batch time: 10.8925, average train loss: 0.7051
[11/17 06:47:46 visual_prompt]: Inference (val):avg data time: 3.65e-05, avg batch time: 0.1536, average loss: 0.6982
[11/17 06:47:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.38	
[11/17 06:47:46 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.09951340343707853
[11/17 06:54:08 visual_prompt]: Epoch 15 / 100: avg data time: 1.06e+01, avg batch time: 10.9152, average train loss: 0.7057
[11/17 06:54:52 visual_prompt]: Inference (val):avg data time: 3.81e-05, avg batch time: 0.1537, average loss: 0.6937
[11/17 06:54:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.71	
[11/17 06:54:52 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.09924038765061041
[11/17 07:01:13 visual_prompt]: Epoch 16 / 100: avg data time: 1.05e+01, avg batch time: 10.8892, average train loss: 0.6993
[11/17 07:01:56 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.1558, average loss: 0.6912
[11/17 07:01:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.71	
[11/17 07:01:56 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.09890738003669029
[11/17 07:08:17 visual_prompt]: Epoch 17 / 100: avg data time: 1.05e+01, avg batch time: 10.8818, average train loss: 0.6922
[11/17 07:09:01 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1546, average loss: 0.6905
[11/17 07:09:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.27	
[11/17 07:09:01 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.09851478631379983
[11/17 07:15:22 visual_prompt]: Epoch 18 / 100: avg data time: 1.05e+01, avg batch time: 10.8878, average train loss: 0.6950
[11/17 07:16:06 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1574, average loss: 0.6953
[11/17 07:16:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.82	
[11/17 07:16:06 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.09806308479691594
[11/17 07:22:27 visual_prompt]: Epoch 19 / 100: avg data time: 1.05e+01, avg batch time: 10.8929, average train loss: 0.6928
[11/17 07:23:11 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1535, average loss: 0.6963
[11/17 07:23:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.40	
[11/17 07:23:11 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.09755282581475769
[11/17 07:29:33 visual_prompt]: Epoch 20 / 100: avg data time: 1.06e+01, avg batch time: 10.9098, average train loss: 0.6907
[11/17 07:30:16 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.1537, average loss: 0.7014
[11/17 07:30:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.82	
[11/17 07:30:16 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.09698463103929543
[11/17 07:36:38 visual_prompt]: Epoch 21 / 100: avg data time: 1.05e+01, avg batch time: 10.9014, average train loss: 0.6969
[11/17 07:37:22 visual_prompt]: Inference (val):avg data time: 3.45e-05, avg batch time: 0.1536, average loss: 0.6928
[11/17 07:37:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.90	
[11/17 07:37:22 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.09635919272833937
[11/17 07:43:43 visual_prompt]: Epoch 22 / 100: avg data time: 1.05e+01, avg batch time: 10.8863, average train loss: 0.6965
[11/17 07:44:27 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1549, average loss: 0.6878
[11/17 07:44:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.16	
[11/17 07:44:27 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.09567727288213004
[11/17 07:50:48 visual_prompt]: Epoch 23 / 100: avg data time: 1.05e+01, avg batch time: 10.8931, average train loss: 0.6860
[11/17 07:51:31 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1537, average loss: 0.6994
[11/17 07:51:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.66	
[11/17 07:51:31 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.09493970231495835
[11/17 07:57:53 visual_prompt]: Epoch 24 / 100: avg data time: 1.05e+01, avg batch time: 10.8956, average train loss: 0.6959
[11/17 07:58:37 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.1536, average loss: 0.6884
[11/17 07:58:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.95	
[11/17 07:58:37 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.09414737964294635
[11/17 08:04:57 visual_prompt]: Epoch 25 / 100: avg data time: 1.05e+01, avg batch time: 10.8619, average train loss: 0.6903
[11/17 08:05:41 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.1576, average loss: 0.6907
[11/17 08:05:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.15	
[11/17 08:05:41 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.09330127018922195
[11/17 08:12:02 visual_prompt]: Epoch 26 / 100: avg data time: 1.06e+01, avg batch time: 10.9058, average train loss: 0.6913
[11/17 08:12:46 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.1535, average loss: 0.6938
[11/17 08:12:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.67	
[11/17 08:12:46 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.0924024048078213
[11/17 08:19:07 visual_prompt]: Epoch 27 / 100: avg data time: 1.06e+01, avg batch time: 10.8998, average train loss: 0.6922
[11/17 08:19:51 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.1538, average loss: 0.6886
[11/17 08:19:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.58	
[11/17 08:19:51 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.09145187862775209
[11/17 08:26:12 visual_prompt]: Epoch 28 / 100: avg data time: 1.05e+01, avg batch time: 10.8882, average train loss: 0.6910
[11/17 08:26:56 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.1537, average loss: 0.6899
[11/17 08:26:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.36	
[11/17 08:26:56 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.09045084971874738
[11/17 08:33:18 visual_prompt]: Epoch 29 / 100: avg data time: 1.06e+01, avg batch time: 10.9212, average train loss: 0.6924
[11/17 08:34:02 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.1566, average loss: 0.6891
[11/17 08:34:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.35	
[11/17 08:34:02 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.0894005376803361
[11/17 08:40:23 visual_prompt]: Epoch 30 / 100: avg data time: 1.05e+01, avg batch time: 10.8945, average train loss: 0.6962
[11/17 08:41:07 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1538, average loss: 0.6880
[11/17 08:41:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.97	
[11/17 08:41:07 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.0883022221559489
[11/17 08:47:28 visual_prompt]: Epoch 31 / 100: avg data time: 1.05e+01, avg batch time: 10.8930, average train loss: 0.6915
[11/17 08:48:12 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1537, average loss: 0.6888
[11/17 08:48:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.94	
[11/17 08:48:12 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.08715724127386971
[11/17 08:54:34 visual_prompt]: Epoch 32 / 100: avg data time: 1.06e+01, avg batch time: 10.9058, average train loss: 0.6937
[11/17 08:55:17 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.1538, average loss: 0.6884
[11/17 08:55:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.20	
[11/17 08:55:17 visual_prompt]: Stopping early.
[11/17 08:55:17 visual_prompt]: Rank of current process: 0. World size: 1
[11/17 08:55:17 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/17 08:55:17 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/17 08:55:17 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/17 08:55:17 visual_prompt]: Training with config:
[11/17 08:55:17 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr0.1_wd0.001/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.1, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/17 08:55:17 visual_prompt]: Loading training data...
[11/17 08:55:17 visual_prompt]: Constructing mammo-cbis dataset train...
[11/17 08:55:17 visual_prompt]: Loading validation data...
[11/17 08:55:17 visual_prompt]: Constructing mammo-cbis dataset val...
[11/17 08:55:17 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[11/17 08:55:20 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[11/17 08:55:20 visual_prompt]: tuned percent:0.536
[11/17 08:55:20 visual_prompt]: Device used for model: 0
[11/17 08:55:20 visual_prompt]: Setting up Evaluator...
[11/17 08:55:20 visual_prompt]: Setting up Trainer...
[11/17 08:55:20 visual_prompt]: 	Setting up the optimizer...
[11/17 08:55:20 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/17 09:01:42 visual_prompt]: Epoch 1 / 100: avg data time: 1.05e+01, avg batch time: 10.9033, average train loss: 1.4017
[11/17 09:02:25 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1537, average loss: 1.2969
[11/17 09:02:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[11/17 09:02:25 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.010000000000000002
[11/17 09:08:48 visual_prompt]: Epoch 2 / 100: avg data time: 1.06e+01, avg batch time: 10.9271, average train loss: 1.0723
[11/17 09:09:31 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1585, average loss: 0.6909
[11/17 09:09:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 47.75	
[11/17 09:09:31 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.020000000000000004
[11/17 09:15:53 visual_prompt]: Epoch 3 / 100: avg data time: 1.06e+01, avg batch time: 10.9089, average train loss: 0.7033
[11/17 09:16:37 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.1536, average loss: 0.6938
[11/17 09:16:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.75	
[11/17 09:16:37 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.03
[11/17 09:22:59 visual_prompt]: Epoch 4 / 100: avg data time: 1.06e+01, avg batch time: 10.9082, average train loss: 0.6929
[11/17 09:23:42 visual_prompt]: Inference (val):avg data time: 3.76e-05, avg batch time: 0.1561, average loss: 0.6804
[11/17 09:23:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 58.78	
[11/17 09:23:42 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.04000000000000001
[11/17 09:30:04 visual_prompt]: Epoch 5 / 100: avg data time: 1.05e+01, avg batch time: 10.8938, average train loss: 0.7148
[11/17 09:30:47 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1547, average loss: 0.6962
[11/17 09:30:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.88	
[11/17 09:30:47 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.05
[11/17 09:37:10 visual_prompt]: Epoch 6 / 100: avg data time: 1.06e+01, avg batch time: 10.9185, average train loss: 0.7385
[11/17 09:37:53 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.1537, average loss: 0.6915
[11/17 09:37:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 52.03	rocauc: 55.36	
[11/17 09:37:53 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.06
[11/17 09:44:15 visual_prompt]: Epoch 7 / 100: avg data time: 1.06e+01, avg batch time: 10.9213, average train loss: 0.6963
[11/17 09:45:00 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.1539, average loss: 0.6782
[11/17 09:45:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 59.73	
[11/17 09:45:00 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.06999999999999999
[11/17 09:51:23 visual_prompt]: Epoch 8 / 100: avg data time: 1.06e+01, avg batch time: 10.9226, average train loss: 0.6892
[11/17 09:52:06 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.1573, average loss: 0.6818
[11/17 09:52:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 62.62	
[11/17 09:52:06 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.08000000000000002
[11/17 09:58:29 visual_prompt]: Epoch 9 / 100: avg data time: 1.06e+01, avg batch time: 10.9348, average train loss: 0.6901
[11/17 09:59:13 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1555, average loss: 0.7419
[11/17 09:59:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 65.10	
[11/17 09:59:13 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.09000000000000001
[11/17 10:05:34 visual_prompt]: Epoch 10 / 100: avg data time: 1.05e+01, avg batch time: 10.9036, average train loss: 0.6824
[11/17 10:06:18 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1539, average loss: 0.6651
[11/17 10:06:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 64.44	
[11/17 10:06:18 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.1
[11/17 10:12:40 visual_prompt]: Epoch 11 / 100: avg data time: 1.06e+01, avg batch time: 10.9210, average train loss: 0.6695
[11/17 10:13:23 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1546, average loss: 0.6550
[11/17 10:13:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 66.46	
[11/17 10:13:23 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0999695413509548
[11/17 10:19:42 visual_prompt]: Epoch 12 / 100: avg data time: 1.04e+01, avg batch time: 10.8065, average train loss: 0.6575
[11/17 10:20:25 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1548, average loss: 0.6604
[11/17 10:20:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 69.08	
[11/17 10:20:25 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.09987820251299122
[11/17 10:26:54 visual_prompt]: Epoch 13 / 100: avg data time: 1.08e+01, avg batch time: 11.1205, average train loss: 0.6852
[11/17 10:27:47 visual_prompt]: Inference (val):avg data time: 3.23e-05, avg batch time: 0.1575, average loss: 0.6496
[11/17 10:27:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 67.13	
[11/17 10:27:47 visual_prompt]: Best epoch 13: best metric: -0.650
[11/17 10:27:47 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.09972609476841367
[11/17 10:34:15 visual_prompt]: Epoch 14 / 100: avg data time: 1.07e+01, avg batch time: 11.0904, average train loss: 0.6885
[11/17 10:34:58 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.1546, average loss: 0.7683
[11/17 10:34:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 66.52	
[11/17 10:34:58 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.09951340343707853
[11/17 10:41:21 visual_prompt]: Epoch 15 / 100: avg data time: 1.06e+01, avg batch time: 10.9357, average train loss: 0.6791
[11/17 10:42:05 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1538, average loss: 0.6587
[11/17 10:42:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 68.92	
[11/17 10:42:05 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.09924038765061041
[11/17 10:48:24 visual_prompt]: Epoch 16 / 100: avg data time: 1.05e+01, avg batch time: 10.8306, average train loss: 0.6772
[11/17 10:49:07 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.1537, average loss: 0.7687
[11/17 10:49:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 68.35	
[11/17 10:49:07 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.09890738003669029
[11/17 10:55:28 visual_prompt]: Epoch 17 / 100: avg data time: 1.05e+01, avg batch time: 10.8667, average train loss: 0.6523
[11/17 10:56:11 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.1539, average loss: 0.6259
[11/17 10:56:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.67	rocauc: 70.15	
[11/17 10:56:11 visual_prompt]: Best epoch 17: best metric: -0.626
[11/17 10:56:11 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.09851478631379983
[11/17 11:02:32 visual_prompt]: Epoch 18 / 100: avg data time: 1.05e+01, avg batch time: 10.8840, average train loss: 0.6554
[11/17 11:03:15 visual_prompt]: Inference (val):avg data time: 3.47e-05, avg batch time: 0.1540, average loss: 0.7966
[11/17 11:03:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 70.19	
[11/17 11:03:15 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.09806308479691594
[11/17 11:09:35 visual_prompt]: Epoch 19 / 100: avg data time: 1.05e+01, avg batch time: 10.8453, average train loss: 0.6649
[11/17 11:10:18 visual_prompt]: Inference (val):avg data time: 3.26e-05, avg batch time: 0.1537, average loss: 0.8159
[11/17 11:10:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 68.88	
[11/17 11:10:18 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.09755282581475769
[11/17 11:16:37 visual_prompt]: Epoch 20 / 100: avg data time: 1.05e+01, avg batch time: 10.8067, average train loss: 0.6487
[11/17 11:17:20 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.1539, average loss: 0.7228
[11/17 11:17:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 68.19	
[11/17 11:17:20 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.09698463103929543
[11/17 11:23:41 visual_prompt]: Epoch 21 / 100: avg data time: 1.05e+01, avg batch time: 10.8736, average train loss: 0.6133
[11/17 11:24:24 visual_prompt]: Inference (val):avg data time: 3.58e-05, avg batch time: 0.1536, average loss: 0.6511
[11/17 11:24:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 70.17	
[11/17 11:24:24 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.09635919272833937
[11/17 11:30:46 visual_prompt]: Epoch 22 / 100: avg data time: 1.06e+01, avg batch time: 10.9049, average train loss: 0.6008
[11/17 11:31:34 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1566, average loss: 0.6419
[11/17 11:31:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.01	rocauc: 69.47	
[11/17 11:31:34 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.09567727288213004
[11/17 11:38:09 visual_prompt]: Epoch 23 / 100: avg data time: 1.09e+01, avg batch time: 11.2732, average train loss: 0.6125
[11/17 11:38:51 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1576, average loss: 0.7167
[11/17 11:38:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 66.31	
[11/17 11:38:51 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.09493970231495835
[11/17 11:45:08 visual_prompt]: Epoch 24 / 100: avg data time: 1.04e+01, avg batch time: 10.7474, average train loss: 0.6196
[11/17 11:45:51 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1550, average loss: 0.6156
[11/17 11:45:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 72.17	
[11/17 11:45:51 visual_prompt]: Best epoch 24: best metric: -0.616
[11/17 11:45:51 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.09414737964294635
[11/17 11:52:06 visual_prompt]: Epoch 25 / 100: avg data time: 1.04e+01, avg batch time: 10.7374, average train loss: 0.5970
[11/17 11:52:49 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1571, average loss: 0.6255
[11/17 11:52:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 68.70	rocauc: 70.11	
[11/17 11:52:49 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.09330127018922195
[11/17 11:59:05 visual_prompt]: Epoch 26 / 100: avg data time: 1.04e+01, avg batch time: 10.7209, average train loss: 0.6580
[11/17 11:59:47 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.1551, average loss: 0.6410
[11/17 11:59:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 68.98	
[11/17 11:59:47 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.0924024048078213
[11/17 12:06:05 visual_prompt]: Epoch 27 / 100: avg data time: 1.04e+01, avg batch time: 10.7790, average train loss: 0.6072
[11/17 12:06:47 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1576, average loss: 0.6497
[11/17 12:06:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 67.42	
[11/17 12:06:47 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.09145187862775209
[11/17 12:13:03 visual_prompt]: Epoch 28 / 100: avg data time: 1.04e+01, avg batch time: 10.7360, average train loss: 0.6254
[11/17 12:13:46 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1555, average loss: 0.6641
[11/17 12:13:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 66.57	
[11/17 12:13:46 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.09045084971874738
[11/17 12:20:02 visual_prompt]: Epoch 29 / 100: avg data time: 1.04e+01, avg batch time: 10.7443, average train loss: 0.5999
[11/17 12:20:45 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1580, average loss: 0.6243
[11/17 12:20:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 73.07	
[11/17 12:20:45 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.0894005376803361
[11/17 12:27:02 visual_prompt]: Epoch 30 / 100: avg data time: 1.04e+01, avg batch time: 10.7601, average train loss: 0.5994
[11/17 12:27:45 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1557, average loss: 0.7013
[11/17 12:27:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 71.31	
[11/17 12:27:45 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.0883022221559489
[11/17 12:34:00 visual_prompt]: Epoch 31 / 100: avg data time: 1.04e+01, avg batch time: 10.7122, average train loss: 0.5889
[11/17 12:34:43 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1557, average loss: 0.6347
[11/17 12:34:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 71.46	
[11/17 12:34:43 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.08715724127386971
[11/17 12:40:57 visual_prompt]: Epoch 32 / 100: avg data time: 1.03e+01, avg batch time: 10.7006, average train loss: 0.5848
[11/17 12:41:40 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1560, average loss: 0.6698
[11/17 12:41:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 68.09	
[11/17 12:41:40 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.08596699001693256
[11/17 12:47:55 visual_prompt]: Epoch 33 / 100: avg data time: 1.04e+01, avg batch time: 10.7117, average train loss: 0.5733
[11/17 12:48:38 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1559, average loss: 0.6526
[11/17 12:48:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 68.39	
[11/17 12:48:38 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.08473291852294987
[11/17 12:54:52 visual_prompt]: Epoch 34 / 100: avg data time: 1.03e+01, avg batch time: 10.6949, average train loss: 0.5752
[11/17 12:55:35 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1552, average loss: 0.6379
[11/17 12:55:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 69.42	
[11/17 12:55:35 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.08345653031794292
[11/17 13:01:49 visual_prompt]: Epoch 35 / 100: avg data time: 1.03e+01, avg batch time: 10.7016, average train loss: 0.5710
[11/17 13:02:32 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.1552, average loss: 0.6738
[11/17 13:02:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 67.95	
[11/17 13:02:32 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.08213938048432697
[11/17 13:08:47 visual_prompt]: Epoch 36 / 100: avg data time: 1.03e+01, avg batch time: 10.7031, average train loss: 0.5626
[11/17 13:09:30 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1553, average loss: 0.6303
[11/17 13:09:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.07	rocauc: 71.31	
[11/17 13:09:30 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.08078307376628291
[11/17 13:15:44 visual_prompt]: Epoch 37 / 100: avg data time: 1.03e+01, avg batch time: 10.6985, average train loss: 0.5539
[11/17 13:16:27 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1580, average loss: 0.7025
[11/17 13:16:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 71.42	
[11/17 13:16:27 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.07938926261462366
[11/17 13:22:42 visual_prompt]: Epoch 38 / 100: avg data time: 1.04e+01, avg batch time: 10.7097, average train loss: 0.5348
[11/17 13:23:25 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1548, average loss: 0.6442
[11/17 13:23:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 69.19	
[11/17 13:23:25 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.07795964517353735
[11/17 13:29:40 visual_prompt]: Epoch 39 / 100: avg data time: 1.04e+01, avg batch time: 10.7227, average train loss: 0.6152
[11/17 13:30:23 visual_prompt]: Inference (val):avg data time: 3.81e-05, avg batch time: 0.1550, average loss: 0.6638
[11/17 13:30:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 66.87	
[11/17 13:30:23 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.07649596321166025
[11/17 13:36:38 visual_prompt]: Epoch 40 / 100: avg data time: 1.04e+01, avg batch time: 10.7267, average train loss: 0.5628
[11/17 13:37:21 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.1585, average loss: 0.6416
[11/17 13:37:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 71.26	
[11/17 13:37:21 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.07500000000000001
[11/17 13:43:36 visual_prompt]: Epoch 41 / 100: avg data time: 1.03e+01, avg batch time: 10.7060, average train loss: 0.6500
[11/17 13:44:19 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.1576, average loss: 0.6452
[11/17 13:44:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 70.54	
[11/17 13:44:19 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.07347357813929455
[11/17 13:50:33 visual_prompt]: Epoch 42 / 100: avg data time: 1.04e+01, avg batch time: 10.7055, average train loss: 0.6189
[11/17 13:51:16 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1548, average loss: 0.7577
[11/17 13:51:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 69.83	
[11/17 13:51:16 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.07191855733945388
[11/17 13:57:31 visual_prompt]: Epoch 43 / 100: avg data time: 1.03e+01, avg batch time: 10.6998, average train loss: 0.6039
[11/17 13:58:14 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1556, average loss: 0.6127
[11/17 13:58:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 72.89	
[11/17 13:58:14 visual_prompt]: Best epoch 43: best metric: -0.613
[11/17 13:58:14 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.07033683215379002
[11/17 14:04:28 visual_prompt]: Epoch 44 / 100: avg data time: 1.03e+01, avg batch time: 10.6924, average train loss: 0.5919
[11/17 14:05:11 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1586, average loss: 0.7087
[11/17 14:05:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 67.54	
[11/17 14:05:11 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.0687303296707956
[11/17 14:11:26 visual_prompt]: Epoch 45 / 100: avg data time: 1.04e+01, avg batch time: 10.7273, average train loss: 0.5797
[11/17 14:12:09 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1549, average loss: 0.6572
[11/17 14:12:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 70.98	
[11/17 14:12:09 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.06710100716628345
[11/17 14:18:24 visual_prompt]: Epoch 46 / 100: avg data time: 1.04e+01, avg batch time: 10.7063, average train loss: 0.5581
[11/17 14:19:06 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.1556, average loss: 0.6329
[11/17 14:19:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 72.31	
[11/17 14:19:06 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.06545084971874737
[11/17 14:25:21 visual_prompt]: Epoch 47 / 100: avg data time: 1.03e+01, avg batch time: 10.6904, average train loss: 0.5491
[11/17 14:26:03 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.1596, average loss: 0.6397
[11/17 14:26:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 69.10	
[11/17 14:26:03 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.06378186779084996
[11/17 14:32:18 visual_prompt]: Epoch 48 / 100: avg data time: 1.03e+01, avg batch time: 10.6899, average train loss: 0.5540
[11/17 14:33:01 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1555, average loss: 0.6655
[11/17 14:33:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 67.10	
[11/17 14:33:01 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.06209609477998338
[11/17 14:39:15 visual_prompt]: Epoch 49 / 100: avg data time: 1.03e+01, avg batch time: 10.6969, average train loss: 0.5545
[11/17 14:39:59 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1559, average loss: 0.6520
[11/17 14:39:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.07	rocauc: 69.11	
[11/17 14:39:59 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.06039558454088796
[11/17 14:46:18 visual_prompt]: Epoch 50 / 100: avg data time: 1.05e+01, avg batch time: 10.8194, average train loss: 0.5361
[11/17 14:47:01 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1583, average loss: 0.8103
[11/17 14:47:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 71.41	
[11/17 14:47:01 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.058682408883346526
[11/17 14:53:19 visual_prompt]: Epoch 51 / 100: avg data time: 1.04e+01, avg batch time: 10.7954, average train loss: 0.5363
[11/17 14:54:02 visual_prompt]: Inference (val):avg data time: 3.59e-05, avg batch time: 0.1556, average loss: 0.6681
[11/17 14:54:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 68.80	
[11/17 14:54:02 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.05695865504800327
[11/17 15:00:21 visual_prompt]: Epoch 52 / 100: avg data time: 1.04e+01, avg batch time: 10.7986, average train loss: 0.5473
[11/17 15:01:03 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1554, average loss: 0.6893
[11/17 15:01:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 68.45	
[11/17 15:01:03 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.05522642316338268
[11/17 15:07:23 visual_prompt]: Epoch 53 / 100: avg data time: 1.05e+01, avg batch time: 10.8477, average train loss: 0.5074
[11/17 15:08:12 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1552, average loss: 0.7021
[11/17 15:08:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 70.18	
[11/17 15:08:12 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.05348782368720626
[11/17 15:14:54 visual_prompt]: Epoch 54 / 100: avg data time: 1.11e+01, avg batch time: 11.4821, average train loss: 0.5254
[11/17 15:15:37 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1591, average loss: 0.6747
[11/17 15:15:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 68.62	
[11/17 15:15:37 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.05174497483512506
[11/17 15:21:54 visual_prompt]: Epoch 55 / 100: avg data time: 1.04e+01, avg batch time: 10.7636, average train loss: 0.4964
[11/17 15:22:37 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.1553, average loss: 0.6351
[11/17 15:22:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 72.10	
[11/17 15:22:37 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.05
[11/17 15:28:54 visual_prompt]: Epoch 56 / 100: avg data time: 1.04e+01, avg batch time: 10.7795, average train loss: 0.4813
[11/17 15:29:37 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1551, average loss: 0.6934
[11/17 15:29:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.01	rocauc: 67.62	
[11/17 15:29:37 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.04825502516487497
[11/17 15:35:55 visual_prompt]: Epoch 57 / 100: avg data time: 1.04e+01, avg batch time: 10.7878, average train loss: 0.4861
[11/17 15:36:41 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.1556, average loss: 0.7123
[11/17 15:36:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 67.73	
[11/17 15:36:41 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.04651217631279374
[11/17 15:43:19 visual_prompt]: Epoch 58 / 100: avg data time: 1.10e+01, avg batch time: 11.3817, average train loss: 0.5151
[11/17 15:44:11 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.1571, average loss: 0.7118
[11/17 15:44:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 66.89	
[11/17 15:44:11 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.04477357683661734
[11/17 15:50:57 visual_prompt]: Epoch 59 / 100: avg data time: 1.12e+01, avg batch time: 11.5984, average train loss: 0.4794
[11/17 15:51:41 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1578, average loss: 0.6928
[11/17 15:51:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 69.09	
[11/17 15:51:41 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.04304134495199674
[11/17 15:58:07 visual_prompt]: Epoch 60 / 100: avg data time: 1.07e+01, avg batch time: 11.0246, average train loss: 0.4678
[11/17 15:58:51 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1597, average loss: 0.7051
[11/17 15:58:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.01	rocauc: 71.52	
[11/17 15:58:51 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.041317591116653486
[11/17 16:05:15 visual_prompt]: Epoch 61 / 100: avg data time: 1.06e+01, avg batch time: 10.9833, average train loss: 0.4691
[11/17 16:05:59 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1607, average loss: 0.7850
[11/17 16:05:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 69.54	
[11/17 16:05:59 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.039604415459112044
[11/17 16:12:24 visual_prompt]: Epoch 62 / 100: avg data time: 1.06e+01, avg batch time: 11.0029, average train loss: 0.4632
[11/17 16:13:08 visual_prompt]: Inference (val):avg data time: 3.54e-05, avg batch time: 0.1573, average loss: 0.6887
[11/17 16:13:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 70.67	
[11/17 16:13:08 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.037903905220016625
[11/17 16:19:34 visual_prompt]: Epoch 63 / 100: avg data time: 1.06e+01, avg batch time: 11.0072, average train loss: 0.4062
[11/17 16:20:17 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1571, average loss: 0.7214
[11/17 16:20:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 70.40	
[11/17 16:20:17 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.036218132209150045
[11/17 16:26:42 visual_prompt]: Epoch 64 / 100: avg data time: 1.06e+01, avg batch time: 10.9902, average train loss: 0.4030
[11/17 16:27:28 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1572, average loss: 0.6874
[11/17 16:27:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.67	rocauc: 72.05	
[11/17 16:27:28 visual_prompt]: Stopping early.
[11/17 16:27:28 visual_prompt]: Rank of current process: 0. World size: 1
[11/17 16:27:28 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/17 16:27:28 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/17 16:27:28 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/17 16:27:28 visual_prompt]: Training with config:
[11/17 16:27:28 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr0.1_wd0.0001/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.1, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/17 16:27:28 visual_prompt]: Loading training data...
[11/17 16:27:28 visual_prompt]: Constructing mammo-cbis dataset train...
[11/17 16:27:28 visual_prompt]: Loading validation data...
[11/17 16:27:28 visual_prompt]: Constructing mammo-cbis dataset val...
[11/17 16:27:28 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[11/17 16:27:37 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[11/17 16:27:37 visual_prompt]: tuned percent:0.536
[11/17 16:27:38 visual_prompt]: Device used for model: 0
[11/17 16:27:38 visual_prompt]: Setting up Evaluator...
[11/17 16:27:38 visual_prompt]: Setting up Trainer...
[11/17 16:27:38 visual_prompt]: 	Setting up the optimizer...
[11/17 16:27:38 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/17 16:34:13 visual_prompt]: Epoch 1 / 100: avg data time: 1.09e+01, avg batch time: 11.3010, average train loss: 1.4017
[11/17 16:34:58 visual_prompt]: Inference (val):avg data time: 3.60e-05, avg batch time: 0.1592, average loss: 1.2969
[11/17 16:34:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[11/17 16:34:58 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.010000000000000002
[11/17 16:41:32 visual_prompt]: Epoch 2 / 100: avg data time: 1.09e+01, avg batch time: 11.2540, average train loss: 1.0725
[11/17 16:42:17 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1572, average loss: 0.6909
[11/17 16:42:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 47.75	
[11/17 16:42:17 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.020000000000000004
[11/17 16:48:44 visual_prompt]: Epoch 3 / 100: avg data time: 1.07e+01, avg batch time: 11.0551, average train loss: 0.7035
[11/17 16:49:28 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.1574, average loss: 0.6938
[11/17 16:49:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.70	
[11/17 16:49:28 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.03
[11/17 16:55:55 visual_prompt]: Epoch 4 / 100: avg data time: 1.07e+01, avg batch time: 11.0479, average train loss: 0.6930
[11/17 16:56:39 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.1572, average loss: 0.6801
[11/17 16:56:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 58.87	
[11/17 16:56:39 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.04000000000000001
[11/17 17:03:01 visual_prompt]: Epoch 5 / 100: avg data time: 1.06e+01, avg batch time: 10.9345, average train loss: 0.7154
[11/17 17:03:45 visual_prompt]: Inference (val):avg data time: 3.66e-05, avg batch time: 0.1572, average loss: 0.6998
[11/17 17:03:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.40	
[11/17 17:03:45 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.05
[11/17 17:10:09 visual_prompt]: Epoch 6 / 100: avg data time: 1.06e+01, avg batch time: 10.9682, average train loss: 0.7346
[11/17 17:10:53 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1571, average loss: 0.7218
[11/17 17:10:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.89	
[11/17 17:10:53 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.06
[11/17 17:17:17 visual_prompt]: Epoch 7 / 100: avg data time: 1.06e+01, avg batch time: 10.9668, average train loss: 0.7038
[11/17 17:18:00 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1575, average loss: 0.6830
[11/17 17:18:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.47	rocauc: 59.02	
[11/17 17:18:00 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.06999999999999999
[11/17 17:24:22 visual_prompt]: Epoch 8 / 100: avg data time: 1.06e+01, avg batch time: 10.9175, average train loss: 0.6961
[11/17 17:25:06 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1571, average loss: 0.6761
[11/17 17:25:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 62.57	
[11/17 17:25:06 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.08000000000000002
[11/17 17:31:32 visual_prompt]: Epoch 9 / 100: avg data time: 1.07e+01, avg batch time: 11.0316, average train loss: 0.6812
[11/17 17:32:16 visual_prompt]: Inference (val):avg data time: 3.67e-05, avg batch time: 0.1572, average loss: 0.7409
[11/17 17:32:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 65.29	
[11/17 17:32:16 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.09000000000000001
[11/17 17:38:40 visual_prompt]: Epoch 10 / 100: avg data time: 1.06e+01, avg batch time: 10.9744, average train loss: 0.6646
[11/17 17:39:24 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1579, average loss: 0.6509
[11/17 17:39:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 67.11	
[11/17 17:39:24 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.1
[11/17 17:45:45 visual_prompt]: Epoch 11 / 100: avg data time: 1.05e+01, avg batch time: 10.9097, average train loss: 0.6738
[11/17 17:46:29 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1573, average loss: 0.6655
[11/17 17:46:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 68.55	
[11/17 17:46:29 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0999695413509548
[11/17 17:52:51 visual_prompt]: Epoch 12 / 100: avg data time: 1.06e+01, avg batch time: 10.9122, average train loss: 0.6587
[11/17 17:53:35 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.1590, average loss: 0.6666
[11/17 17:53:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 68.93	
[11/17 17:53:35 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.09987820251299122
[11/17 17:59:57 visual_prompt]: Epoch 13 / 100: avg data time: 1.06e+01, avg batch time: 10.9219, average train loss: 0.6894
[11/17 18:00:42 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1591, average loss: 0.6548
[11/17 18:00:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 67.85	
[11/17 18:00:42 visual_prompt]: Best epoch 13: best metric: -0.655
[11/17 18:00:42 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.09972609476841367
[11/17 18:07:03 visual_prompt]: Epoch 14 / 100: avg data time: 1.06e+01, avg batch time: 10.9075, average train loss: 0.6878
[11/17 18:07:47 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1571, average loss: 0.6694
[11/17 18:07:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 66.10	
[11/17 18:07:47 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.09951340343707853
[11/17 18:14:10 visual_prompt]: Epoch 15 / 100: avg data time: 1.06e+01, avg batch time: 10.9401, average train loss: 0.6835
[11/17 18:14:54 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1571, average loss: 0.6506
[11/17 18:14:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 68.01	
[11/17 18:14:54 visual_prompt]: Best epoch 15: best metric: -0.651
[11/17 18:14:54 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.09924038765061041
[11/17 18:21:15 visual_prompt]: Epoch 16 / 100: avg data time: 1.05e+01, avg batch time: 10.8982, average train loss: 0.6733
[11/17 18:21:59 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1574, average loss: 0.6882
[11/17 18:21:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.54	rocauc: 65.52	
[11/17 18:21:59 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.09890738003669029
[11/17 18:28:27 visual_prompt]: Epoch 17 / 100: avg data time: 1.07e+01, avg batch time: 11.1009, average train loss: 0.6547
[11/17 18:29:11 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.1566, average loss: 0.6373
[11/17 18:29:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 68.19	
[11/17 18:29:11 visual_prompt]: Best epoch 17: best metric: -0.637
[11/17 18:29:11 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.09851478631379983
[11/17 18:35:38 visual_prompt]: Epoch 18 / 100: avg data time: 1.07e+01, avg batch time: 11.0512, average train loss: 0.6536
[11/17 18:36:21 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1571, average loss: 0.8856
[11/17 18:36:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 68.59	
[11/17 18:36:21 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.09806308479691594
[11/17 18:42:43 visual_prompt]: Epoch 19 / 100: avg data time: 1.05e+01, avg batch time: 10.9017, average train loss: 0.6741
[11/17 18:43:26 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1571, average loss: 0.8656
[11/17 18:43:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 68.64	
[11/17 18:43:26 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.09755282581475769
[11/17 18:49:48 visual_prompt]: Epoch 20 / 100: avg data time: 1.05e+01, avg batch time: 10.8891, average train loss: 0.6525
[11/17 18:50:31 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1573, average loss: 0.7656
[11/17 18:50:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 53.25	rocauc: 68.59	
[11/17 18:50:31 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.09698463103929543
[11/17 18:56:52 visual_prompt]: Epoch 21 / 100: avg data time: 1.05e+01, avg batch time: 10.8852, average train loss: 0.6191
[11/17 18:57:35 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.1569, average loss: 0.6496
[11/17 18:57:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 68.86	
[11/17 18:57:35 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.09635919272833937
[11/17 19:03:56 visual_prompt]: Epoch 22 / 100: avg data time: 1.05e+01, avg batch time: 10.8707, average train loss: 0.6023
[11/17 19:04:39 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1599, average loss: 0.6382
[11/17 19:04:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.67	rocauc: 68.94	
[11/17 19:04:39 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.09567727288213004
[11/17 19:11:00 visual_prompt]: Epoch 23 / 100: avg data time: 1.05e+01, avg batch time: 10.8670, average train loss: 0.5954
[11/17 19:11:43 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1573, average loss: 0.6280
[11/17 19:11:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 69.39	
[11/17 19:11:43 visual_prompt]: Best epoch 23: best metric: -0.628
[11/17 19:11:43 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.09493970231495835
[11/17 19:18:03 visual_prompt]: Epoch 24 / 100: avg data time: 1.05e+01, avg batch time: 10.8648, average train loss: 0.5988
[11/17 19:18:46 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1612, average loss: 0.6278
[11/17 19:18:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 68.48	
[11/17 19:18:46 visual_prompt]: Best epoch 24: best metric: -0.628
[11/17 19:18:46 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.09414737964294635
[11/17 19:25:07 visual_prompt]: Epoch 25 / 100: avg data time: 1.05e+01, avg batch time: 10.8842, average train loss: 0.5862
[11/17 19:25:50 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.1571, average loss: 0.6796
[11/17 19:25:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 66.38	
[11/17 19:25:50 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.09330127018922195
[11/17 19:32:11 visual_prompt]: Epoch 26 / 100: avg data time: 1.05e+01, avg batch time: 10.8631, average train loss: 0.6070
[11/17 19:32:54 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1570, average loss: 0.6501
[11/17 19:32:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 67.96	
[11/17 19:32:54 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.0924024048078213
[11/17 19:39:15 visual_prompt]: Epoch 27 / 100: avg data time: 1.05e+01, avg batch time: 10.8785, average train loss: 0.5635
[11/17 19:39:58 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1569, average loss: 0.6744
[11/17 19:39:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 65.58	
[11/17 19:39:58 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.09145187862775209
[11/17 19:46:18 visual_prompt]: Epoch 28 / 100: avg data time: 1.05e+01, avg batch time: 10.8626, average train loss: 0.6041
[11/17 19:47:02 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1569, average loss: 0.6869
[11/17 19:47:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 67.53	
[11/17 19:47:02 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.09045084971874738
[11/17 19:53:23 visual_prompt]: Epoch 29 / 100: avg data time: 1.05e+01, avg batch time: 10.8935, average train loss: 0.5578
[11/17 19:54:06 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1597, average loss: 0.6818
[11/17 19:54:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.01	rocauc: 67.82	
[11/17 19:54:06 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.0894005376803361
[11/17 20:00:26 visual_prompt]: Epoch 30 / 100: avg data time: 1.05e+01, avg batch time: 10.8524, average train loss: 0.5610
[11/17 20:01:09 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1569, average loss: 0.7042
[11/17 20:01:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 71.69	
[11/17 20:01:10 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.0883022221559489
[11/17 20:07:29 visual_prompt]: Epoch 31 / 100: avg data time: 1.05e+01, avg batch time: 10.8392, average train loss: 0.5311
[11/17 20:08:12 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1569, average loss: 0.7157
[11/17 20:08:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 65.79	
[11/17 20:08:12 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.08715724127386971
[11/17 20:14:33 visual_prompt]: Epoch 32 / 100: avg data time: 1.05e+01, avg batch time: 10.8666, average train loss: 0.5580
[11/17 20:15:16 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1601, average loss: 0.6906
[11/17 20:15:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 68.94	
[11/17 20:15:16 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.08596699001693256
[11/17 20:21:35 visual_prompt]: Epoch 33 / 100: avg data time: 1.05e+01, avg batch time: 10.8322, average train loss: 0.5323
[11/17 20:22:18 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1567, average loss: 0.6420
[11/17 20:22:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.67	rocauc: 68.53	
[11/17 20:22:18 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.08473291852294987
[11/17 20:28:37 visual_prompt]: Epoch 34 / 100: avg data time: 1.05e+01, avg batch time: 10.8220, average train loss: 0.5270
[11/17 20:29:20 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.1587, average loss: 0.6587
[11/17 20:29:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 65.91	
[11/17 20:29:20 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.08345653031794292
[11/17 20:35:40 visual_prompt]: Epoch 35 / 100: avg data time: 1.05e+01, avg batch time: 10.8372, average train loss: 0.5063
[11/17 20:36:23 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1571, average loss: 0.7180
[11/17 20:36:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.01	rocauc: 64.48	
[11/17 20:36:23 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.08213938048432697
[11/17 20:42:42 visual_prompt]: Epoch 36 / 100: avg data time: 1.05e+01, avg batch time: 10.8247, average train loss: 0.5004
[11/17 20:43:26 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1573, average loss: 0.7563
[11/17 20:43:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 64.99	
[11/17 20:43:26 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.08078307376628291
[11/17 20:49:46 visual_prompt]: Epoch 37 / 100: avg data time: 1.05e+01, avg batch time: 10.8504, average train loss: 0.4916
[11/17 20:50:29 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.1571, average loss: 0.7571
[11/17 20:50:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 68.49	
[11/17 20:50:29 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.07938926261462366
[11/17 20:56:49 visual_prompt]: Epoch 38 / 100: avg data time: 1.05e+01, avg batch time: 10.8472, average train loss: 0.4944
[11/17 20:57:32 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1571, average loss: 0.8297
[11/17 20:57:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 66.92	
[11/17 20:57:32 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.07795964517353735
[11/17 21:03:53 visual_prompt]: Epoch 39 / 100: avg data time: 1.05e+01, avg batch time: 10.8880, average train loss: 0.4772
[11/17 21:04:36 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1602, average loss: 0.7733
[11/17 21:04:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 64.02	
[11/17 21:04:36 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.07649596321166025
[11/17 21:10:56 visual_prompt]: Epoch 40 / 100: avg data time: 1.05e+01, avg batch time: 10.8398, average train loss: 0.4575
[11/17 21:11:39 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1594, average loss: 0.7801
[11/17 21:11:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 64.70	
[11/17 21:11:39 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.07500000000000001
[11/17 21:17:58 visual_prompt]: Epoch 41 / 100: avg data time: 1.05e+01, avg batch time: 10.8340, average train loss: 0.4472
[11/17 21:18:41 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.1569, average loss: 0.7500
[11/17 21:18:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 64.86	
[11/17 21:18:41 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.07347357813929455
[11/17 21:25:01 visual_prompt]: Epoch 42 / 100: avg data time: 1.05e+01, avg batch time: 10.8330, average train loss: 0.4574
[11/17 21:25:44 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1577, average loss: 0.7204
[11/17 21:25:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 63.46	
[11/17 21:25:44 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.07191855733945388
[11/17 21:32:04 visual_prompt]: Epoch 43 / 100: avg data time: 1.05e+01, avg batch time: 10.8502, average train loss: 0.4309
[11/17 21:32:47 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1573, average loss: 0.7359
[11/17 21:32:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 64.72	
[11/17 21:32:47 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.07033683215379002
[11/17 21:39:05 visual_prompt]: Epoch 44 / 100: avg data time: 1.05e+01, avg batch time: 10.8141, average train loss: 0.3984
[11/17 21:39:48 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1572, average loss: 0.7553
[11/17 21:39:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 67.17	
[11/17 21:39:48 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.0687303296707956
[11/17 21:46:08 visual_prompt]: Epoch 45 / 100: avg data time: 1.05e+01, avg batch time: 10.8415, average train loss: 0.3821
[11/17 21:46:51 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1572, average loss: 0.8477
[11/17 21:46:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 65.59	
[11/17 21:46:51 visual_prompt]: Stopping early.
[11/17 21:46:51 visual_prompt]: Rank of current process: 0. World size: 1
[11/17 21:46:51 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/17 21:46:51 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/17 21:46:51 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/17 21:46:51 visual_prompt]: Training with config:
[11/17 21:46:51 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr0.1_wd0.0/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.1, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/17 21:46:51 visual_prompt]: Loading training data...
[11/17 21:46:51 visual_prompt]: Constructing mammo-cbis dataset train...
[11/17 21:46:51 visual_prompt]: Loading validation data...
[11/17 21:46:51 visual_prompt]: Constructing mammo-cbis dataset val...
[11/17 21:46:51 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[11/17 21:46:54 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[11/17 21:46:54 visual_prompt]: tuned percent:0.536
[11/17 21:46:54 visual_prompt]: Device used for model: 0
[11/17 21:46:54 visual_prompt]: Setting up Evaluator...
[11/17 21:46:54 visual_prompt]: Setting up Trainer...
[11/17 21:46:54 visual_prompt]: 	Setting up the optimizer...
[11/17 21:46:54 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/17 21:53:13 visual_prompt]: Epoch 1 / 100: avg data time: 1.05e+01, avg batch time: 10.8244, average train loss: 1.4017
[11/17 21:53:56 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.1588, average loss: 1.2969
[11/17 21:53:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[11/17 21:53:56 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.010000000000000002
[11/17 22:00:15 visual_prompt]: Epoch 2 / 100: avg data time: 1.05e+01, avg batch time: 10.8220, average train loss: 1.0725
[11/17 22:00:58 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1567, average loss: 0.6909
[11/17 22:00:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 47.76	
[11/17 22:00:58 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.020000000000000004
[11/17 22:07:19 visual_prompt]: Epoch 3 / 100: avg data time: 1.05e+01, avg batch time: 10.8729, average train loss: 0.7035
[11/17 22:08:02 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1576, average loss: 0.6938
[11/17 22:08:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.66	
[11/17 22:08:02 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.03
[11/17 22:14:22 visual_prompt]: Epoch 4 / 100: avg data time: 1.05e+01, avg batch time: 10.8390, average train loss: 0.6931
[11/17 22:15:05 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1570, average loss: 0.6804
[11/17 22:15:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 58.76	
[11/17 22:15:05 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.04000000000000001
[11/17 22:21:23 visual_prompt]: Epoch 5 / 100: avg data time: 1.04e+01, avg batch time: 10.8072, average train loss: 0.7155
[11/17 22:22:06 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1604, average loss: 0.6984
[11/17 22:22:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.54	
[11/17 22:22:06 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.05
[11/17 22:28:25 visual_prompt]: Epoch 6 / 100: avg data time: 1.05e+01, avg batch time: 10.8255, average train loss: 0.7364
[11/17 22:29:09 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1597, average loss: 0.7177
[11/17 22:29:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.55	
[11/17 22:29:09 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.06
[11/17 22:35:27 visual_prompt]: Epoch 7 / 100: avg data time: 1.04e+01, avg batch time: 10.8014, average train loss: 0.7035
[11/17 22:36:10 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1565, average loss: 0.6818
[11/17 22:36:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 58.90	
[11/17 22:36:10 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.06999999999999999
[11/17 22:42:28 visual_prompt]: Epoch 8 / 100: avg data time: 1.04e+01, avg batch time: 10.8013, average train loss: 0.6942
[11/17 22:43:11 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1572, average loss: 0.6765
[11/17 22:43:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 62.25	
[11/17 22:43:11 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.08000000000000002
[11/17 22:49:30 visual_prompt]: Epoch 9 / 100: avg data time: 1.05e+01, avg batch time: 10.8259, average train loss: 0.6780
[11/17 22:50:14 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1565, average loss: 0.7291
[11/17 22:50:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 65.97	
[11/17 22:50:14 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.09000000000000001
[11/17 22:56:34 visual_prompt]: Epoch 10 / 100: avg data time: 1.05e+01, avg batch time: 10.8316, average train loss: 0.6636
[11/17 22:57:17 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.1578, average loss: 0.6480
[11/17 22:57:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 67.50	
[11/17 22:57:17 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.1
[11/17 23:03:36 visual_prompt]: Epoch 11 / 100: avg data time: 1.05e+01, avg batch time: 10.8279, average train loss: 0.6750
[11/17 23:04:19 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1572, average loss: 0.6768
[11/17 23:04:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 68.24	
[11/17 23:04:19 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0999695413509548
[11/17 23:10:37 visual_prompt]: Epoch 12 / 100: avg data time: 1.04e+01, avg batch time: 10.8061, average train loss: 0.6563
[11/17 23:11:20 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.1564, average loss: 0.6717
[11/17 23:11:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 69.11	
[11/17 23:11:20 visual_prompt]: Best epoch 12: best metric: -0.672
[11/17 23:11:20 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.09987820251299122
[11/17 23:17:39 visual_prompt]: Epoch 13 / 100: avg data time: 1.05e+01, avg batch time: 10.8240, average train loss: 0.6982
[11/17 23:18:22 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.1606, average loss: 0.6465
[11/17 23:18:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 67.19	
[11/17 23:18:22 visual_prompt]: Best epoch 13: best metric: -0.646
[11/17 23:18:22 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.09972609476841367
[11/17 23:24:41 visual_prompt]: Epoch 14 / 100: avg data time: 1.04e+01, avg batch time: 10.8036, average train loss: 0.6822
[11/17 23:25:24 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1573, average loss: 0.6681
[11/17 23:25:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 66.74	
[11/17 23:25:24 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.09951340343707853
[11/17 23:31:43 visual_prompt]: Epoch 15 / 100: avg data time: 1.05e+01, avg batch time: 10.8315, average train loss: 0.6672
[11/17 23:32:26 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1566, average loss: 0.6460
[11/17 23:32:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 68.44	
[11/17 23:32:26 visual_prompt]: Best epoch 15: best metric: -0.646
[11/17 23:32:26 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.09924038765061041
[11/17 23:38:44 visual_prompt]: Epoch 16 / 100: avg data time: 1.04e+01, avg batch time: 10.8075, average train loss: 0.6628
[11/17 23:39:27 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1567, average loss: 0.6860
[11/17 23:39:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 67.65	
[11/17 23:39:27 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.09890738003669029
[11/17 23:45:45 visual_prompt]: Epoch 17 / 100: avg data time: 1.04e+01, avg batch time: 10.7853, average train loss: 0.6485
[11/17 23:46:28 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1570, average loss: 0.6349
[11/17 23:46:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.67	rocauc: 68.37	
[11/17 23:46:28 visual_prompt]: Best epoch 17: best metric: -0.635
[11/17 23:46:28 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.09851478631379983
[11/17 23:52:47 visual_prompt]: Epoch 18 / 100: avg data time: 1.04e+01, avg batch time: 10.8095, average train loss: 0.6506
[11/17 23:53:30 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1568, average loss: 0.8987
[11/17 23:53:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 66.55	
[11/17 23:53:30 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.09806308479691594
[11/17 23:59:48 visual_prompt]: Epoch 19 / 100: avg data time: 1.04e+01, avg batch time: 10.7944, average train loss: 0.6536
[11/18 00:00:31 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1593, average loss: 0.8199
[11/18 00:00:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 69.12	
[11/18 00:00:31 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.09755282581475769
[11/18 00:06:49 visual_prompt]: Epoch 20 / 100: avg data time: 1.04e+01, avg batch time: 10.7969, average train loss: 0.6521
[11/18 00:07:32 visual_prompt]: Inference (val):avg data time: 3.46e-05, avg batch time: 0.1567, average loss: 0.8552
[11/18 00:07:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 48.78	rocauc: 65.82	
[11/18 00:07:32 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.09698463103929543
[11/18 00:13:50 visual_prompt]: Epoch 21 / 100: avg data time: 1.04e+01, avg batch time: 10.8081, average train loss: 0.6300
[11/18 00:14:33 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1570, average loss: 0.6533
[11/18 00:14:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 67.25	
[11/18 00:14:33 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.09635919272833937
[11/18 00:20:53 visual_prompt]: Epoch 22 / 100: avg data time: 1.05e+01, avg batch time: 10.8369, average train loss: 0.5831
[11/18 00:21:36 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1569, average loss: 0.6557
[11/18 00:21:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.01	rocauc: 66.71	
[11/18 00:21:36 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.09567727288213004
[11/18 00:27:54 visual_prompt]: Epoch 23 / 100: avg data time: 1.04e+01, avg batch time: 10.8014, average train loss: 0.5873
[11/18 00:28:37 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1568, average loss: 0.6637
[11/18 00:28:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 66.43	
[11/18 00:28:37 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.09493970231495835
[11/18 00:34:59 visual_prompt]: Epoch 24 / 100: avg data time: 1.05e+01, avg batch time: 10.9051, average train loss: 0.5907
[11/18 00:35:42 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1569, average loss: 0.6852
[11/18 00:35:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 64.31	
[11/18 00:35:42 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.09414737964294635
[11/18 00:42:02 visual_prompt]: Epoch 25 / 100: avg data time: 1.05e+01, avg batch time: 10.8539, average train loss: 0.5772
[11/18 00:42:46 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1592, average loss: 0.6986
[11/18 00:42:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 66.80	
[11/18 00:42:46 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.09330127018922195
[11/18 00:49:06 visual_prompt]: Epoch 26 / 100: avg data time: 1.05e+01, avg batch time: 10.8591, average train loss: 0.6101
[11/18 00:49:49 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1570, average loss: 0.6556
[11/18 00:49:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 66.61	
[11/18 00:49:49 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.0924024048078213
[11/18 00:56:12 visual_prompt]: Epoch 27 / 100: avg data time: 1.06e+01, avg batch time: 10.9169, average train loss: 0.5715
[11/18 00:56:55 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.1569, average loss: 0.6731
[11/18 00:56:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 64.78	
[11/18 00:56:55 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.09145187862775209
[11/18 01:03:17 visual_prompt]: Epoch 28 / 100: avg data time: 1.05e+01, avg batch time: 10.8984, average train loss: 0.5767
[11/18 01:04:00 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.1570, average loss: 0.7598
[11/18 01:04:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 67.54	
[11/18 01:04:00 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.09045084971874738
[11/18 01:10:23 visual_prompt]: Epoch 29 / 100: avg data time: 1.06e+01, avg batch time: 10.9333, average train loss: 0.5634
[11/18 01:11:06 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1568, average loss: 0.6520
[11/18 01:11:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 66.40	
[11/18 01:11:06 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.0894005376803361
[11/18 01:17:26 visual_prompt]: Epoch 30 / 100: avg data time: 1.05e+01, avg batch time: 10.8482, average train loss: 0.5466
[11/18 01:18:09 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.1568, average loss: 0.7726
[11/18 01:18:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 65.25	
[11/18 01:18:09 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.0883022221559489
[11/18 01:24:27 visual_prompt]: Epoch 31 / 100: avg data time: 1.04e+01, avg batch time: 10.7992, average train loss: 0.5028
[11/18 01:25:10 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1570, average loss: 0.7586
[11/18 01:25:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 66.13	
[11/18 01:25:10 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.08715724127386971
[11/18 01:31:29 visual_prompt]: Epoch 32 / 100: avg data time: 1.05e+01, avg batch time: 10.8121, average train loss: 0.5169
[11/18 01:32:12 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1570, average loss: 0.7249
[11/18 01:32:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.01	rocauc: 66.39	
[11/18 01:32:12 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.08596699001693256
[11/18 01:38:30 visual_prompt]: Epoch 33 / 100: avg data time: 1.04e+01, avg batch time: 10.7945, average train loss: 0.5230
[11/18 01:39:13 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1570, average loss: 0.6490
[11/18 01:39:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 68.29	
[11/18 01:39:13 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.08473291852294987
[11/18 01:45:31 visual_prompt]: Epoch 34 / 100: avg data time: 1.04e+01, avg batch time: 10.7923, average train loss: 0.5219
[11/18 01:46:14 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1595, average loss: 0.7788
[11/18 01:46:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 67.08	
[11/18 01:46:14 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.08345653031794292
[11/18 01:52:31 visual_prompt]: Epoch 35 / 100: avg data time: 1.04e+01, avg batch time: 10.7820, average train loss: 0.4814
[11/18 01:53:14 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.1586, average loss: 0.7552
[11/18 01:53:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 64.88	
[11/18 01:53:14 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.08213938048432697
[11/18 01:59:32 visual_prompt]: Epoch 36 / 100: avg data time: 1.04e+01, avg batch time: 10.7982, average train loss: 0.4765
[11/18 02:00:16 visual_prompt]: Inference (val):avg data time: 3.47e-05, avg batch time: 0.1575, average loss: 0.7382
[11/18 02:00:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.01	rocauc: 64.58	
[11/18 02:00:16 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.08078307376628291
[11/18 02:06:33 visual_prompt]: Epoch 37 / 100: avg data time: 1.04e+01, avg batch time: 10.7900, average train loss: 0.4512
[11/18 02:07:16 visual_prompt]: Inference (val):avg data time: 3.90e-05, avg batch time: 0.1590, average loss: 0.7747
[11/18 02:07:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 68.95	
[11/18 02:07:16 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.07938926261462366
[11/18 02:13:35 visual_prompt]: Epoch 38 / 100: avg data time: 1.04e+01, avg batch time: 10.8107, average train loss: 0.4634
[11/18 02:14:18 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.1606, average loss: 0.8845
[11/18 02:14:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 66.50	
[11/18 02:14:18 visual_prompt]: Stopping early.
[11/18 02:14:18 visual_prompt]: Rank of current process: 0. World size: 1
[11/18 02:14:18 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/18 02:14:18 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/18 02:14:18 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/18 02:14:18 visual_prompt]: Training with config:
[11/18 02:14:18 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr0.05_wd0.01/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.05, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/18 02:14:18 visual_prompt]: Loading training data...
[11/18 02:14:18 visual_prompt]: Constructing mammo-cbis dataset train...
[11/18 02:14:18 visual_prompt]: Loading validation data...
[11/18 02:14:18 visual_prompt]: Constructing mammo-cbis dataset val...
[11/18 02:14:18 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[11/18 02:14:21 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[11/18 02:14:21 visual_prompt]: tuned percent:0.536
[11/18 02:14:21 visual_prompt]: Device used for model: 0
[11/18 02:14:21 visual_prompt]: Setting up Evaluator...
[11/18 02:14:21 visual_prompt]: Setting up Trainer...
[11/18 02:14:21 visual_prompt]: 	Setting up the optimizer...
[11/18 02:14:21 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/18 02:20:39 visual_prompt]: Epoch 1 / 100: avg data time: 1.04e+01, avg batch time: 10.8010, average train loss: 1.4017
[11/18 02:21:22 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1567, average loss: 1.2969
[11/18 02:21:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[11/18 02:21:22 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.005000000000000001
[11/18 02:27:41 visual_prompt]: Epoch 2 / 100: avg data time: 1.05e+01, avg batch time: 10.8248, average train loss: 0.9963
[11/18 02:28:24 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.1574, average loss: 0.6960
[11/18 02:28:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.93	rocauc: 46.43	
[11/18 02:28:24 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.010000000000000002
[11/18 02:34:43 visual_prompt]: Epoch 3 / 100: avg data time: 1.04e+01, avg batch time: 10.8043, average train loss: 0.7067
[11/18 02:35:26 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1567, average loss: 0.6914
[11/18 02:35:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.16	
[11/18 02:35:26 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.015
[11/18 02:41:44 visual_prompt]: Epoch 4 / 100: avg data time: 1.05e+01, avg batch time: 10.8096, average train loss: 0.6950
[11/18 02:42:27 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1567, average loss: 0.6846
[11/18 02:42:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.14	
[11/18 02:42:27 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.020000000000000004
[11/18 02:48:45 visual_prompt]: Epoch 5 / 100: avg data time: 1.04e+01, avg batch time: 10.7936, average train loss: 0.7228
[11/18 02:49:28 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.1570, average loss: 0.7047
[11/18 02:49:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.50	
[11/18 02:49:28 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.025
[11/18 02:55:47 visual_prompt]: Epoch 6 / 100: avg data time: 1.04e+01, avg batch time: 10.8065, average train loss: 0.7257
[11/18 02:56:30 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.1575, average loss: 0.7285
[11/18 02:56:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.29	
[11/18 02:56:30 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.03
[11/18 03:02:50 visual_prompt]: Epoch 7 / 100: avg data time: 1.05e+01, avg batch time: 10.8628, average train loss: 0.7121
[11/18 03:03:33 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1570, average loss: 0.6850
[11/18 03:03:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 61.29	
[11/18 03:03:33 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.034999999999999996
[11/18 03:09:51 visual_prompt]: Epoch 8 / 100: avg data time: 1.04e+01, avg batch time: 10.8000, average train loss: 0.7077
[11/18 03:10:34 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1577, average loss: 0.6910
[11/18 03:10:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.30	
[11/18 03:10:34 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.04000000000000001
[11/18 03:16:53 visual_prompt]: Epoch 9 / 100: avg data time: 1.05e+01, avg batch time: 10.8280, average train loss: 0.6956
[11/18 03:17:37 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1600, average loss: 0.7079
[11/18 03:17:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.13	
[11/18 03:17:37 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.045000000000000005
[11/18 03:23:55 visual_prompt]: Epoch 10 / 100: avg data time: 1.04e+01, avg batch time: 10.7980, average train loss: 0.7094
[11/18 03:24:38 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1566, average loss: 0.7066
[11/18 03:24:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.42	
[11/18 03:24:38 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.05
[11/18 03:30:56 visual_prompt]: Epoch 11 / 100: avg data time: 1.04e+01, avg batch time: 10.8010, average train loss: 0.6881
[11/18 03:31:39 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1572, average loss: 0.6668
[11/18 03:31:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 63.45	
[11/18 03:31:39 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0499847706754774
[11/18 03:37:57 visual_prompt]: Epoch 12 / 100: avg data time: 1.04e+01, avg batch time: 10.7970, average train loss: 0.6773
[11/18 03:38:40 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1573, average loss: 0.6955
[11/18 03:38:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 48.37	rocauc: 64.64	
[11/18 03:38:40 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.04993910125649561
[11/18 03:44:58 visual_prompt]: Epoch 13 / 100: avg data time: 1.04e+01, avg batch time: 10.8052, average train loss: 0.6948
[11/18 03:45:42 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1591, average loss: 0.6748
[11/18 03:45:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 63.77	
[11/18 03:45:42 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.049863047384206834
[11/18 03:51:59 visual_prompt]: Epoch 14 / 100: avg data time: 1.04e+01, avg batch time: 10.7921, average train loss: 0.6903
[11/18 03:52:42 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.1568, average loss: 0.8157
[11/18 03:52:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.37	
[11/18 03:52:42 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.04975670171853926
[11/18 03:59:01 visual_prompt]: Epoch 15 / 100: avg data time: 1.05e+01, avg batch time: 10.8179, average train loss: 0.7070
[11/18 03:59:45 visual_prompt]: Inference (val):avg data time: 3.67e-05, avg batch time: 0.1568, average loss: 0.6795
[11/18 03:59:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 64.03	
[11/18 03:59:45 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.049620193825305206
[11/18 04:06:05 visual_prompt]: Epoch 16 / 100: avg data time: 1.05e+01, avg batch time: 10.8711, average train loss: 0.6916
[11/18 04:06:48 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1572, average loss: 0.6782
[11/18 04:06:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 63.08	
[11/18 04:06:48 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.049453690018345146
[11/18 04:13:01 visual_prompt]: Epoch 17 / 100: avg data time: 1.03e+01, avg batch time: 10.6599, average train loss: 0.6827
[11/18 04:13:44 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1568, average loss: 0.6761
[11/18 04:13:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 64.74	
[11/18 04:13:44 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.04925739315689991
[11/18 04:19:57 visual_prompt]: Epoch 18 / 100: avg data time: 1.03e+01, avg batch time: 10.6705, average train loss: 0.6973
[11/18 04:20:40 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1566, average loss: 0.7200
[11/18 04:20:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.06	
[11/18 04:20:40 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.04903154239845797
[11/18 04:26:53 visual_prompt]: Epoch 19 / 100: avg data time: 1.03e+01, avg batch time: 10.6556, average train loss: 0.6949
[11/18 04:27:35 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1572, average loss: 0.6973
[11/18 04:27:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.11	
[11/18 04:27:35 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.048776412907378844
[11/18 04:33:49 visual_prompt]: Epoch 20 / 100: avg data time: 1.03e+01, avg batch time: 10.6733, average train loss: 0.6862
[11/18 04:34:32 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1567, average loss: 0.6916
[11/18 04:34:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 49.59	rocauc: 61.37	
[11/18 04:34:32 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.048492315519647715
[11/18 04:40:45 visual_prompt]: Epoch 21 / 100: avg data time: 1.03e+01, avg batch time: 10.6691, average train loss: 0.6943
[11/18 04:41:28 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1568, average loss: 0.6889
[11/18 04:41:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.74	
[11/18 04:41:28 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.048179596364169686
[11/18 04:47:41 visual_prompt]: Epoch 22 / 100: avg data time: 1.03e+01, avg batch time: 10.6534, average train loss: 0.6876
[11/18 04:48:23 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.1571, average loss: 0.6961
[11/18 04:48:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 46.34	rocauc: 62.75	
[11/18 04:48:23 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.04783863644106502
[11/18 04:54:37 visual_prompt]: Epoch 23 / 100: avg data time: 1.03e+01, avg batch time: 10.6809, average train loss: 0.6779
[11/18 04:55:20 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1573, average loss: 0.7122
[11/18 04:55:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 61.84	
[11/18 04:55:20 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.047469851157479176
[11/18 05:01:34 visual_prompt]: Epoch 24 / 100: avg data time: 1.03e+01, avg batch time: 10.6960, average train loss: 0.6882
[11/18 05:02:17 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1568, average loss: 0.6783
[11/18 05:02:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 65.48	
[11/18 05:02:17 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.047073689821473176
[11/18 05:08:30 visual_prompt]: Epoch 25 / 100: avg data time: 1.03e+01, avg batch time: 10.6700, average train loss: 0.6854
[11/18 05:09:13 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1573, average loss: 0.6894
[11/18 05:09:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.16	
[11/18 05:09:13 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.046650635094610975
[11/18 05:15:27 visual_prompt]: Epoch 26 / 100: avg data time: 1.03e+01, avg batch time: 10.6701, average train loss: 0.6903
[11/18 05:16:09 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1562, average loss: 0.6892
[11/18 05:16:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 64.87	
[11/18 05:16:09 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.04620120240391065
[11/18 05:22:23 visual_prompt]: Epoch 27 / 100: avg data time: 1.03e+01, avg batch time: 10.6675, average train loss: 0.6883
[11/18 05:23:05 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1568, average loss: 0.6921
[11/18 05:23:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 46.75	rocauc: 61.37	
[11/18 05:23:05 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.04572593931387604
[11/18 05:29:19 visual_prompt]: Epoch 28 / 100: avg data time: 1.03e+01, avg batch time: 10.6644, average train loss: 0.6893
[11/18 05:30:01 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1586, average loss: 0.6877
[11/18 05:30:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.19	
[11/18 05:30:01 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.04522542485937369
[11/18 05:36:17 visual_prompt]: Epoch 29 / 100: avg data time: 1.04e+01, avg batch time: 10.7178, average train loss: 0.6838
[11/18 05:36:59 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1568, average loss: 0.6808
[11/18 05:36:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 59.39	
[11/18 05:36:59 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.04470026884016805
[11/18 05:43:14 visual_prompt]: Epoch 30 / 100: avg data time: 1.03e+01, avg batch time: 10.6927, average train loss: 0.6908
[11/18 05:43:56 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1567, average loss: 0.6850
[11/18 05:43:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.99	
[11/18 05:43:56 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.04415111107797445
[11/18 05:50:11 visual_prompt]: Epoch 31 / 100: avg data time: 1.03e+01, avg batch time: 10.6887, average train loss: 0.6881
[11/18 05:50:53 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1568, average loss: 0.6917
[11/18 05:50:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.47	rocauc: 52.98	
[11/18 05:50:53 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.04357862063693486
[11/18 05:57:08 visual_prompt]: Epoch 32 / 100: avg data time: 1.03e+01, avg batch time: 10.6954, average train loss: 0.6903
[11/18 05:57:50 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1581, average loss: 0.6861
[11/18 05:57:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.32	
[11/18 05:57:50 visual_prompt]: Stopping early.
[11/18 05:57:50 visual_prompt]: Rank of current process: 0. World size: 1
[11/18 05:57:50 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/18 05:57:50 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/18 05:57:50 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/18 05:57:50 visual_prompt]: Training with config:
[11/18 05:57:50 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr0.05_wd0.001/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.05, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/18 05:57:50 visual_prompt]: Loading training data...
[11/18 05:57:50 visual_prompt]: Constructing mammo-cbis dataset train...
[11/18 05:57:50 visual_prompt]: Loading validation data...
[11/18 05:57:50 visual_prompt]: Constructing mammo-cbis dataset val...
[11/18 05:57:50 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[11/18 05:57:53 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[11/18 05:57:53 visual_prompt]: tuned percent:0.536
[11/18 05:57:53 visual_prompt]: Device used for model: 0
[11/18 05:57:53 visual_prompt]: Setting up Evaluator...
[11/18 05:57:53 visual_prompt]: Setting up Trainer...
[11/18 05:57:53 visual_prompt]: 	Setting up the optimizer...
[11/18 05:57:53 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/18 06:04:08 visual_prompt]: Epoch 1 / 100: avg data time: 1.03e+01, avg batch time: 10.7092, average train loss: 1.4017
[11/18 06:04:51 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1568, average loss: 1.2969
[11/18 06:04:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[11/18 06:04:51 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.005000000000000001
[11/18 06:11:04 visual_prompt]: Epoch 2 / 100: avg data time: 1.03e+01, avg batch time: 10.6685, average train loss: 0.9972
[11/18 06:11:47 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1564, average loss: 0.6963
[11/18 06:11:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.93	rocauc: 46.34	
[11/18 06:11:47 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.010000000000000002
[11/18 06:18:01 visual_prompt]: Epoch 3 / 100: avg data time: 1.03e+01, avg batch time: 10.6780, average train loss: 0.7074
[11/18 06:18:43 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1595, average loss: 0.6913
[11/18 06:18:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.00	
[11/18 06:18:43 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.015
[11/18 06:24:57 visual_prompt]: Epoch 4 / 100: avg data time: 1.03e+01, avg batch time: 10.6779, average train loss: 0.6961
[11/18 06:25:39 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1568, average loss: 0.6843
[11/18 06:25:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.82	
[11/18 06:25:39 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.020000000000000004
[11/18 06:31:53 visual_prompt]: Epoch 5 / 100: avg data time: 1.03e+01, avg batch time: 10.6656, average train loss: 0.7246
[11/18 06:32:35 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1566, average loss: 0.6985
[11/18 06:32:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.95	
[11/18 06:32:35 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.025
[11/18 06:38:49 visual_prompt]: Epoch 6 / 100: avg data time: 1.03e+01, avg batch time: 10.6802, average train loss: 0.7290
[11/18 06:39:32 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1599, average loss: 0.6959
[11/18 06:39:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 44.72	rocauc: 59.49	
[11/18 06:39:32 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.03
[11/18 06:45:46 visual_prompt]: Epoch 7 / 100: avg data time: 1.03e+01, avg batch time: 10.6816, average train loss: 0.6991
[11/18 06:46:28 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1566, average loss: 0.6808
[11/18 06:46:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 61.92	
[11/18 06:46:28 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.034999999999999996
[11/18 06:52:43 visual_prompt]: Epoch 8 / 100: avg data time: 1.03e+01, avg batch time: 10.6880, average train loss: 0.6972
[11/18 06:53:25 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1597, average loss: 0.6726
[11/18 06:53:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 62.88	
[11/18 06:53:25 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.04000000000000001
[11/18 06:59:41 visual_prompt]: Epoch 9 / 100: avg data time: 1.04e+01, avg batch time: 10.7189, average train loss: 0.6853
[11/18 07:00:23 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1567, average loss: 0.7307
[11/18 07:00:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 65.64	
[11/18 07:00:23 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.045000000000000005
[11/18 07:06:37 visual_prompt]: Epoch 10 / 100: avg data time: 1.03e+01, avg batch time: 10.6888, average train loss: 0.6805
[11/18 07:07:20 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1572, average loss: 0.6662
[11/18 07:07:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 63.90	
[11/18 07:07:20 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.05
[11/18 07:13:34 visual_prompt]: Epoch 11 / 100: avg data time: 1.03e+01, avg batch time: 10.6763, average train loss: 0.6860
[11/18 07:14:16 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.1569, average loss: 0.6591
[11/18 07:14:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 66.56	
[11/18 07:14:16 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0499847706754774
[11/18 07:20:30 visual_prompt]: Epoch 12 / 100: avg data time: 1.03e+01, avg batch time: 10.6719, average train loss: 0.6924
[11/18 07:21:12 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1564, average loss: 0.6662
[11/18 07:21:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 65.06	
[11/18 07:21:12 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.04993910125649561
[11/18 07:27:27 visual_prompt]: Epoch 13 / 100: avg data time: 1.03e+01, avg batch time: 10.6957, average train loss: 0.6988
[11/18 07:28:10 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1596, average loss: 0.6767
[11/18 07:28:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 65.99	
[11/18 07:28:10 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.049863047384206834
[11/18 07:34:23 visual_prompt]: Epoch 14 / 100: avg data time: 1.03e+01, avg batch time: 10.6793, average train loss: 0.6837
[11/18 07:35:06 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1567, average loss: 0.7999
[11/18 07:35:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 64.93	
[11/18 07:35:06 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.04975670171853926
[11/18 07:41:21 visual_prompt]: Epoch 15 / 100: avg data time: 1.04e+01, avg batch time: 10.7088, average train loss: 0.7022
[11/18 07:42:04 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1569, average loss: 0.6705
[11/18 07:42:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 64.80	
[11/18 07:42:04 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.049620193825305206
[11/18 07:48:17 visual_prompt]: Epoch 16 / 100: avg data time: 1.03e+01, avg batch time: 10.6656, average train loss: 0.6883
[11/18 07:48:59 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1567, average loss: 0.7709
[11/18 07:48:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 66.31	
[11/18 07:48:59 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.049453690018345146
[11/18 07:55:12 visual_prompt]: Epoch 17 / 100: avg data time: 1.03e+01, avg batch time: 10.6528, average train loss: 0.6848
[11/18 07:55:55 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1567, average loss: 0.6528
[11/18 07:55:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 66.95	
[11/18 07:55:55 visual_prompt]: Best epoch 17: best metric: -0.653
[11/18 07:55:55 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.04925739315689991
[11/18 08:02:09 visual_prompt]: Epoch 18 / 100: avg data time: 1.03e+01, avg batch time: 10.6809, average train loss: 0.6804
[11/18 08:02:52 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1568, average loss: 0.6983
[11/18 08:02:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 68.38	
[11/18 08:02:52 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.04903154239845797
[11/18 08:09:05 visual_prompt]: Epoch 19 / 100: avg data time: 1.03e+01, avg batch time: 10.6558, average train loss: 0.6901
[11/18 08:09:47 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1568, average loss: 0.7053
[11/18 08:09:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 68.86	
[11/18 08:09:47 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.048776412907378844
[11/18 08:16:00 visual_prompt]: Epoch 20 / 100: avg data time: 1.03e+01, avg batch time: 10.6616, average train loss: 0.6648
[11/18 08:16:43 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1566, average loss: 0.6887
[11/18 08:16:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 68.31	
[11/18 08:16:43 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.048492315519647715
[11/18 08:22:56 visual_prompt]: Epoch 21 / 100: avg data time: 1.03e+01, avg batch time: 10.6635, average train loss: 0.6618
[11/18 08:23:39 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1570, average loss: 0.6413
[11/18 08:23:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 68.41	
[11/18 08:23:39 visual_prompt]: Best epoch 21: best metric: -0.641
[11/18 08:23:39 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.048179596364169686
[11/18 08:29:52 visual_prompt]: Epoch 22 / 100: avg data time: 1.03e+01, avg batch time: 10.6637, average train loss: 0.6560
[11/18 08:30:35 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1566, average loss: 0.7079
[11/18 08:30:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 52.85	rocauc: 70.18	
[11/18 08:30:35 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.04783863644106502
[11/18 08:36:48 visual_prompt]: Epoch 23 / 100: avg data time: 1.03e+01, avg batch time: 10.6675, average train loss: 0.6578
[11/18 08:37:31 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1570, average loss: 0.6596
[11/18 08:37:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.54	rocauc: 68.46	
[11/18 08:37:31 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.047469851157479176
[11/18 08:43:45 visual_prompt]: Epoch 24 / 100: avg data time: 1.03e+01, avg batch time: 10.6926, average train loss: 0.6430
[11/18 08:44:28 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1569, average loss: 0.6839
[11/18 08:44:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 68.78	
[11/18 08:44:28 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.047073689821473176
[11/18 08:50:42 visual_prompt]: Epoch 25 / 100: avg data time: 1.03e+01, avg batch time: 10.6813, average train loss: 0.6532
[11/18 08:51:24 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.1607, average loss: 0.6401
[11/18 08:51:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 70.57	
[11/18 08:51:24 visual_prompt]: Best epoch 25: best metric: -0.640
[11/18 08:51:24 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.046650635094610975
[11/18 08:57:38 visual_prompt]: Epoch 26 / 100: avg data time: 1.03e+01, avg batch time: 10.6728, average train loss: 0.6305
[11/18 08:58:20 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1574, average loss: 0.6215
[11/18 08:58:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.89	rocauc: 71.17	
[11/18 08:58:20 visual_prompt]: Best epoch 26: best metric: -0.621
[11/18 08:58:20 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.04620120240391065
[11/18 09:04:34 visual_prompt]: Epoch 27 / 100: avg data time: 1.03e+01, avg batch time: 10.6751, average train loss: 0.6230
[11/18 09:05:16 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1563, average loss: 0.6323
[11/18 09:05:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 69.73	
[11/18 09:05:16 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.04572593931387604
[11/18 09:11:30 visual_prompt]: Epoch 28 / 100: avg data time: 1.03e+01, avg batch time: 10.6568, average train loss: 0.6312
[11/18 09:12:12 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1571, average loss: 0.6664
[11/18 09:12:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 70.91	
[11/18 09:12:12 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.04522542485937369
[11/18 09:18:27 visual_prompt]: Epoch 29 / 100: avg data time: 1.03e+01, avg batch time: 10.6991, average train loss: 0.6129
[11/18 09:19:09 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1607, average loss: 0.6346
[11/18 09:19:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 71.26	
[11/18 09:19:09 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.04470026884016805
[11/18 09:25:23 visual_prompt]: Epoch 30 / 100: avg data time: 1.03e+01, avg batch time: 10.6670, average train loss: 0.6134
[11/18 09:26:05 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1570, average loss: 0.6274
[11/18 09:26:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 71.66	
[11/18 09:26:05 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.04415111107797445
[11/18 09:32:19 visual_prompt]: Epoch 31 / 100: avg data time: 1.03e+01, avg batch time: 10.6630, average train loss: 0.5958
[11/18 09:33:01 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1564, average loss: 0.6279
[11/18 09:33:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 72.14	
[11/18 09:33:01 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.04357862063693486
[11/18 09:39:15 visual_prompt]: Epoch 32 / 100: avg data time: 1.03e+01, avg batch time: 10.6831, average train loss: 0.6147
[11/18 09:39:58 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1581, average loss: 0.6330
[11/18 09:39:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 69.91	
[11/18 09:39:58 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.04298349500846628
[11/18 09:46:11 visual_prompt]: Epoch 33 / 100: avg data time: 1.03e+01, avg batch time: 10.6785, average train loss: 0.5860
[11/18 09:46:54 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1577, average loss: 0.6258
[11/18 09:46:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 71.20	
[11/18 09:46:54 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.042366459261474934
[11/18 09:53:07 visual_prompt]: Epoch 34 / 100: avg data time: 1.03e+01, avg batch time: 10.6676, average train loss: 0.6002
[11/18 09:53:50 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1568, average loss: 0.7330
[11/18 09:53:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 69.87	
[11/18 09:53:50 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.04172826515897146
[11/18 10:00:03 visual_prompt]: Epoch 35 / 100: avg data time: 1.03e+01, avg batch time: 10.6665, average train loss: 0.5978
[11/18 10:00:46 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1568, average loss: 0.6412
[11/18 10:00:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 69.63	
[11/18 10:00:46 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.04106969024216348
[11/18 10:07:00 visual_prompt]: Epoch 36 / 100: avg data time: 1.03e+01, avg batch time: 10.6796, average train loss: 0.5801
[11/18 10:07:42 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1566, average loss: 0.6651
[11/18 10:07:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 70.75	
[11/18 10:07:42 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.040391536883141455
[11/18 10:13:56 visual_prompt]: Epoch 37 / 100: avg data time: 1.03e+01, avg batch time: 10.6855, average train loss: 0.5674
[11/18 10:14:39 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1563, average loss: 0.7261
[11/18 10:14:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.01	rocauc: 66.98	
[11/18 10:14:39 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.03969463130731183
[11/18 10:20:54 visual_prompt]: Epoch 38 / 100: avg data time: 1.03e+01, avg batch time: 10.6967, average train loss: 0.5632
[11/18 10:21:36 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1569, average loss: 0.6685
[11/18 10:21:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 69.61	
[11/18 10:21:36 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.03897982258676867
[11/18 10:27:50 visual_prompt]: Epoch 39 / 100: avg data time: 1.03e+01, avg batch time: 10.7036, average train loss: 0.6019
[11/18 10:28:33 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1569, average loss: 0.6897
[11/18 10:28:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 68.00	
[11/18 10:28:33 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.03824798160583012
[11/18 10:34:48 visual_prompt]: Epoch 40 / 100: avg data time: 1.03e+01, avg batch time: 10.7099, average train loss: 0.5495
[11/18 10:35:31 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1582, average loss: 0.6529
[11/18 10:35:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 68.53	
[11/18 10:35:31 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.037500000000000006
[11/18 10:41:44 visual_prompt]: Epoch 41 / 100: avg data time: 1.03e+01, avg batch time: 10.6691, average train loss: 0.5404
[11/18 10:42:27 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1570, average loss: 0.6762
[11/18 10:42:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 67.51	
[11/18 10:42:27 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.03673678906964727
[11/18 10:48:40 visual_prompt]: Epoch 42 / 100: avg data time: 1.03e+01, avg batch time: 10.6709, average train loss: 0.5348
[11/18 10:49:23 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1569, average loss: 0.7038
[11/18 10:49:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 67.32	
[11/18 10:49:23 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.03595927866972694
[11/18 10:55:37 visual_prompt]: Epoch 43 / 100: avg data time: 1.03e+01, avg batch time: 10.6737, average train loss: 0.5433
[11/18 10:56:19 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1567, average loss: 0.6532
[11/18 10:56:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 69.25	
[11/18 10:56:19 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.03516841607689501
[11/18 11:02:32 visual_prompt]: Epoch 44 / 100: avg data time: 1.03e+01, avg batch time: 10.6593, average train loss: 0.5342
[11/18 11:03:15 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1580, average loss: 0.7443
[11/18 11:03:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.54	rocauc: 67.61	
[11/18 11:03:15 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.0343651648353978
[11/18 11:09:29 visual_prompt]: Epoch 45 / 100: avg data time: 1.03e+01, avg batch time: 10.6924, average train loss: 0.5524
[11/18 11:10:12 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1570, average loss: 0.7264
[11/18 11:10:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 68.98	
[11/18 11:10:12 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.033550503583141725
[11/18 11:16:25 visual_prompt]: Epoch 46 / 100: avg data time: 1.03e+01, avg batch time: 10.6644, average train loss: 0.5066
[11/18 11:17:08 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1564, average loss: 0.7224
[11/18 11:17:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 69.86	
[11/18 11:17:08 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.032725424859373686
[11/18 11:23:21 visual_prompt]: Epoch 47 / 100: avg data time: 1.03e+01, avg batch time: 10.6544, average train loss: 0.5386
[11/18 11:24:03 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1595, average loss: 0.7048
[11/18 11:24:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 68.87	
[11/18 11:24:03 visual_prompt]: Stopping early.
[11/18 11:24:03 visual_prompt]: Rank of current process: 0. World size: 1
[11/18 11:24:03 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/18 11:24:03 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/18 11:24:03 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/18 11:24:03 visual_prompt]: Training with config:
[11/18 11:24:03 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr0.05_wd0.0001/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.05, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/18 11:24:03 visual_prompt]: Loading training data...
[11/18 11:24:03 visual_prompt]: Constructing mammo-cbis dataset train...
[11/18 11:24:03 visual_prompt]: Loading validation data...
[11/18 11:24:03 visual_prompt]: Constructing mammo-cbis dataset val...
[11/18 11:24:03 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[11/18 11:24:06 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[11/18 11:24:06 visual_prompt]: tuned percent:0.536
[11/18 11:24:06 visual_prompt]: Device used for model: 0
[11/18 11:24:06 visual_prompt]: Setting up Evaluator...
[11/18 11:24:06 visual_prompt]: Setting up Trainer...
[11/18 11:24:06 visual_prompt]: 	Setting up the optimizer...
[11/18 11:24:06 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/18 11:30:19 visual_prompt]: Epoch 1 / 100: avg data time: 1.03e+01, avg batch time: 10.6687, average train loss: 1.4017
[11/18 11:31:02 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1612, average loss: 1.2969
[11/18 11:31:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[11/18 11:31:02 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.005000000000000001
[11/18 11:37:15 visual_prompt]: Epoch 2 / 100: avg data time: 1.03e+01, avg batch time: 10.6611, average train loss: 0.9973
[11/18 11:37:57 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1588, average loss: 0.6963
[11/18 11:37:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.93	rocauc: 46.32	
[11/18 11:37:57 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.010000000000000002
[11/18 11:44:11 visual_prompt]: Epoch 3 / 100: avg data time: 1.03e+01, avg batch time: 10.6619, average train loss: 0.7075
[11/18 11:44:53 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1569, average loss: 0.6913
[11/18 11:44:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.01	
[11/18 11:44:53 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.015
[11/18 11:51:08 visual_prompt]: Epoch 4 / 100: avg data time: 1.03e+01, avg batch time: 10.6941, average train loss: 0.6962
[11/18 11:51:54 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1578, average loss: 0.6843
[11/18 11:51:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.76	
[11/18 11:51:54 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.020000000000000004
[11/18 11:58:40 visual_prompt]: Epoch 5 / 100: avg data time: 1.12e+01, avg batch time: 11.6013, average train loss: 0.7240
[11/18 11:59:24 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1543, average loss: 0.6927
[11/18 11:59:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.74	
[11/18 11:59:24 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.025
[11/18 12:05:48 visual_prompt]: Epoch 6 / 100: avg data time: 1.06e+01, avg batch time: 10.9670, average train loss: 0.7304
[11/18 12:06:31 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1553, average loss: 0.6991
[11/18 12:06:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.27	
[11/18 12:06:31 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.03
[11/18 12:12:55 visual_prompt]: Epoch 7 / 100: avg data time: 1.06e+01, avg batch time: 10.9582, average train loss: 0.7007
[11/18 12:13:39 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1540, average loss: 0.6809
[11/18 12:13:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 61.41	
[11/18 12:13:39 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.034999999999999996
[11/18 12:20:01 visual_prompt]: Epoch 8 / 100: avg data time: 1.06e+01, avg batch time: 10.9295, average train loss: 0.6972
[11/18 12:20:45 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1544, average loss: 0.6738
[11/18 12:20:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 62.36	
[11/18 12:20:45 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.04000000000000001
[11/18 12:27:08 visual_prompt]: Epoch 9 / 100: avg data time: 1.06e+01, avg batch time: 10.9499, average train loss: 0.6855
[11/18 12:27:52 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1549, average loss: 0.7340
[11/18 12:27:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 65.24	
[11/18 12:27:52 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.045000000000000005
[11/18 12:34:13 visual_prompt]: Epoch 10 / 100: avg data time: 1.05e+01, avg batch time: 10.8868, average train loss: 0.6823
[11/18 12:34:57 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1541, average loss: 0.6665
[11/18 12:34:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 63.85	
[11/18 12:34:57 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.05
[11/18 12:41:19 visual_prompt]: Epoch 11 / 100: avg data time: 1.06e+01, avg batch time: 10.9231, average train loss: 0.6869
[11/18 12:42:03 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1542, average loss: 0.6609
[11/18 12:42:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 65.98	
[11/18 12:42:03 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0499847706754774
[11/18 12:48:24 visual_prompt]: Epoch 12 / 100: avg data time: 1.06e+01, avg batch time: 10.9067, average train loss: 0.6928
[11/18 12:49:08 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1538, average loss: 0.6676
[11/18 12:49:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 64.21	
[11/18 12:49:08 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.04993910125649561
[11/18 12:55:30 visual_prompt]: Epoch 13 / 100: avg data time: 1.06e+01, avg batch time: 10.9208, average train loss: 0.7019
[11/18 12:56:14 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1540, average loss: 0.6691
[11/18 12:56:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 64.45	
[11/18 12:56:14 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.049863047384206834
[11/18 13:02:36 visual_prompt]: Epoch 14 / 100: avg data time: 1.06e+01, avg batch time: 10.9128, average train loss: 0.6917
[11/18 13:03:19 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1542, average loss: 0.7862
[11/18 13:03:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 64.03	
[11/18 13:03:19 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.04975670171853926
[11/18 13:09:42 visual_prompt]: Epoch 15 / 100: avg data time: 1.06e+01, avg batch time: 10.9135, average train loss: 0.6980
[11/18 13:10:25 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1541, average loss: 0.6564
[11/18 13:10:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 65.82	
[11/18 13:10:25 visual_prompt]: Best epoch 15: best metric: -0.656
[11/18 13:10:25 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.049620193825305206
[11/18 13:16:46 visual_prompt]: Epoch 16 / 100: avg data time: 1.05e+01, avg batch time: 10.8840, average train loss: 0.6968
[11/18 13:17:30 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1540, average loss: 0.7931
[11/18 13:17:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 66.61	
[11/18 13:17:30 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.049453690018345146
[11/18 13:23:50 visual_prompt]: Epoch 17 / 100: avg data time: 1.05e+01, avg batch time: 10.8780, average train loss: 0.6897
[11/18 13:24:34 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1545, average loss: 0.6517
[11/18 13:24:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 66.83	
[11/18 13:24:34 visual_prompt]: Best epoch 17: best metric: -0.652
[11/18 13:24:34 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.04925739315689991
[11/18 13:30:56 visual_prompt]: Epoch 18 / 100: avg data time: 1.06e+01, avg batch time: 10.9150, average train loss: 0.6841
[11/18 13:31:40 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1547, average loss: 0.6975
[11/18 13:31:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 67.30	
[11/18 13:31:40 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.04903154239845797
[11/18 13:38:00 visual_prompt]: Epoch 19 / 100: avg data time: 1.05e+01, avg batch time: 10.8677, average train loss: 0.6897
[11/18 13:38:43 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.1536, average loss: 0.7390
[11/18 13:38:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 67.32	
[11/18 13:38:43 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.048776412907378844
[11/18 13:45:04 visual_prompt]: Epoch 20 / 100: avg data time: 1.05e+01, avg batch time: 10.8606, average train loss: 0.6652
[11/18 13:45:47 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.1542, average loss: 0.7308
[11/18 13:45:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 50.41	rocauc: 66.88	
[11/18 13:45:47 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.048492315519647715
[11/18 13:52:08 visual_prompt]: Epoch 21 / 100: avg data time: 1.05e+01, avg batch time: 10.8707, average train loss: 0.6596
[11/18 13:52:51 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1540, average loss: 0.6446
[11/18 13:52:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 68.70	
[11/18 13:52:51 visual_prompt]: Best epoch 21: best metric: -0.645
[11/18 13:52:51 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.048179596364169686
[11/18 13:59:11 visual_prompt]: Epoch 22 / 100: avg data time: 1.05e+01, avg batch time: 10.8610, average train loss: 0.6508
[11/18 13:59:55 visual_prompt]: Inference (val):avg data time: 3.62e-05, avg batch time: 0.1542, average loss: 0.6764
[11/18 13:59:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 69.17	
[11/18 13:59:55 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.04783863644106502
[11/18 14:06:15 visual_prompt]: Epoch 23 / 100: avg data time: 1.05e+01, avg batch time: 10.8636, average train loss: 0.6519
[11/18 14:06:58 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1576, average loss: 0.6581
[11/18 14:06:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 68.23	
[11/18 14:06:58 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.047469851157479176
[11/18 14:13:19 visual_prompt]: Epoch 24 / 100: avg data time: 1.05e+01, avg batch time: 10.8661, average train loss: 0.6448
[11/18 14:14:02 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1541, average loss: 0.6868
[11/18 14:14:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 68.03	
[11/18 14:14:02 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.047073689821473176
[11/18 14:20:22 visual_prompt]: Epoch 25 / 100: avg data time: 1.05e+01, avg batch time: 10.8445, average train loss: 0.6553
[11/18 14:21:05 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1542, average loss: 0.6543
[11/18 14:21:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 69.61	
[11/18 14:21:05 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.046650635094610975
[11/18 14:27:25 visual_prompt]: Epoch 26 / 100: avg data time: 1.05e+01, avg batch time: 10.8692, average train loss: 0.6365
[11/18 14:28:09 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1574, average loss: 0.6373
[11/18 14:28:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.67	rocauc: 70.11	
[11/18 14:28:09 visual_prompt]: Best epoch 26: best metric: -0.637
[11/18 14:28:09 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.04620120240391065
[11/18 14:34:31 visual_prompt]: Epoch 27 / 100: avg data time: 1.06e+01, avg batch time: 10.9225, average train loss: 0.6287
[11/18 14:35:15 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1541, average loss: 0.6406
[11/18 14:35:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.67	rocauc: 68.88	
[11/18 14:35:15 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.04572593931387604
[11/18 14:41:34 visual_prompt]: Epoch 28 / 100: avg data time: 1.05e+01, avg batch time: 10.8168, average train loss: 0.6356
[11/18 14:42:17 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1552, average loss: 0.6742
[11/18 14:42:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 67.13	
[11/18 14:42:17 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.04522542485937369
[11/18 14:48:37 visual_prompt]: Epoch 29 / 100: avg data time: 1.05e+01, avg batch time: 10.8562, average train loss: 0.6263
[11/18 14:49:20 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1540, average loss: 0.6511
[11/18 14:49:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 67.09	
[11/18 14:49:20 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.04470026884016805
[11/18 14:55:39 visual_prompt]: Epoch 30 / 100: avg data time: 1.05e+01, avg batch time: 10.8190, average train loss: 0.6270
[11/18 14:56:22 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1547, average loss: 0.6525
[11/18 14:56:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 66.57	
[11/18 14:56:22 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.04415111107797445
[11/18 15:02:41 visual_prompt]: Epoch 31 / 100: avg data time: 1.05e+01, avg batch time: 10.8232, average train loss: 0.6137
[11/18 15:03:24 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1542, average loss: 0.6712
[11/18 15:03:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 68.75	
[11/18 15:03:24 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.04357862063693486
[11/18 15:09:43 visual_prompt]: Epoch 32 / 100: avg data time: 1.05e+01, avg batch time: 10.8237, average train loss: 0.6407
[11/18 15:10:26 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.1541, average loss: 0.6787
[11/18 15:10:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 67.28	
[11/18 15:10:26 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.04298349500846628
[11/18 15:16:45 visual_prompt]: Epoch 33 / 100: avg data time: 1.05e+01, avg batch time: 10.8242, average train loss: 0.6240
[11/18 15:17:29 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1541, average loss: 0.6309
[11/18 15:17:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 69.92	rocauc: 70.29	
[11/18 15:17:29 visual_prompt]: Best epoch 33: best metric: -0.631
[11/18 15:17:29 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.042366459261474934
[11/18 15:23:47 visual_prompt]: Epoch 34 / 100: avg data time: 1.05e+01, avg batch time: 10.8043, average train loss: 0.6196
[11/18 15:24:30 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1541, average loss: 0.7583
[11/18 15:24:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 67.68	
[11/18 15:24:30 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.04172826515897146
[11/18 15:30:49 visual_prompt]: Epoch 35 / 100: avg data time: 1.05e+01, avg batch time: 10.8228, average train loss: 0.6116
[11/18 15:31:32 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1544, average loss: 0.6350
[11/18 15:31:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 69.03	
[11/18 15:31:32 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.04106969024216348
[11/18 15:37:51 visual_prompt]: Epoch 36 / 100: avg data time: 1.05e+01, avg batch time: 10.8344, average train loss: 0.5937
[11/18 15:38:35 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1544, average loss: 0.6709
[11/18 15:38:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.01	rocauc: 68.66	
[11/18 15:38:35 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.040391536883141455
[11/18 15:44:53 visual_prompt]: Epoch 37 / 100: avg data time: 1.05e+01, avg batch time: 10.8128, average train loss: 0.5911
[11/18 15:45:36 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1568, average loss: 0.7702
[11/18 15:45:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 69.30	
[11/18 15:45:36 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.03969463130731183
[11/18 15:51:54 visual_prompt]: Epoch 38 / 100: avg data time: 1.05e+01, avg batch time: 10.8096, average train loss: 0.5773
[11/18 15:52:37 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1539, average loss: 0.7292
[11/18 15:52:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 69.35	
[11/18 15:52:37 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.03897982258676867
[11/18 15:58:56 visual_prompt]: Epoch 39 / 100: avg data time: 1.05e+01, avg batch time: 10.8160, average train loss: 0.5825
[11/18 15:59:39 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1570, average loss: 0.6312
[11/18 15:59:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 70.38	
[11/18 15:59:39 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.03824798160583012
[11/18 16:05:58 visual_prompt]: Epoch 40 / 100: avg data time: 1.05e+01, avg batch time: 10.8210, average train loss: 0.5812
[11/18 16:06:41 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1541, average loss: 0.6562
[11/18 16:06:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 68.93	
[11/18 16:06:41 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.037500000000000006
[11/18 16:12:59 visual_prompt]: Epoch 41 / 100: avg data time: 1.04e+01, avg batch time: 10.7925, average train loss: 0.5521
[11/18 16:13:42 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1542, average loss: 0.6975
[11/18 16:13:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 67.18	
[11/18 16:13:42 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.03673678906964727
[11/18 16:20:00 visual_prompt]: Epoch 42 / 100: avg data time: 1.05e+01, avg batch time: 10.8073, average train loss: 0.5843
[11/18 16:20:43 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1608, average loss: 0.6947
[11/18 16:20:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 66.98	
[11/18 16:20:43 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.03595927866972694
[11/18 16:27:02 visual_prompt]: Epoch 43 / 100: avg data time: 1.04e+01, avg batch time: 10.7990, average train loss: 0.5627
[11/18 16:27:45 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1555, average loss: 0.6641
[11/18 16:27:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.07	rocauc: 69.74	
[11/18 16:27:45 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.03516841607689501
[11/18 16:34:02 visual_prompt]: Epoch 44 / 100: avg data time: 1.04e+01, avg batch time: 10.7845, average train loss: 0.5504
[11/18 16:34:45 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1580, average loss: 0.7929
[11/18 16:34:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 66.91	
[11/18 16:34:45 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.0343651648353978
[11/18 16:41:04 visual_prompt]: Epoch 45 / 100: avg data time: 1.05e+01, avg batch time: 10.8268, average train loss: 0.5629
[11/18 16:41:48 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1571, average loss: 0.6827
[11/18 16:41:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 69.36	
[11/18 16:41:48 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.033550503583141725
[11/18 16:48:09 visual_prompt]: Epoch 46 / 100: avg data time: 1.05e+01, avg batch time: 10.8792, average train loss: 0.5305
[11/18 16:48:52 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1540, average loss: 0.6558
[11/18 16:48:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 68.29	rocauc: 70.65	
[11/18 16:48:52 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.032725424859373686
[11/18 16:55:13 visual_prompt]: Epoch 47 / 100: avg data time: 1.05e+01, avg batch time: 10.8662, average train loss: 0.5297
[11/18 16:55:56 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1540, average loss: 0.7338
[11/18 16:55:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 67.00	
[11/18 16:55:56 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.03189093389542498
[11/18 17:02:18 visual_prompt]: Epoch 48 / 100: avg data time: 1.05e+01, avg batch time: 10.9021, average train loss: 0.5671
[11/18 17:03:01 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1541, average loss: 0.6975
[11/18 17:03:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 70.40	
[11/18 17:03:01 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.03104804738999169
[11/18 17:09:18 visual_prompt]: Epoch 49 / 100: avg data time: 1.04e+01, avg batch time: 10.7734, average train loss: 0.5407
[11/18 17:10:01 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1543, average loss: 0.6526
[11/18 17:10:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 69.06	
[11/18 17:10:01 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.03019779227044398
[11/18 17:16:19 visual_prompt]: Epoch 50 / 100: avg data time: 1.04e+01, avg batch time: 10.7714, average train loss: 0.5055
[11/18 17:17:02 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1540, average loss: 0.7148
[11/18 17:17:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 69.53	
[11/18 17:17:02 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.029341204441673263
[11/18 17:23:19 visual_prompt]: Epoch 51 / 100: avg data time: 1.04e+01, avg batch time: 10.7834, average train loss: 0.4976
[11/18 17:24:02 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.1541, average loss: 0.6869
[11/18 17:24:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 67.55	
[11/18 17:24:02 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.028479327524001636
[11/18 17:30:22 visual_prompt]: Epoch 52 / 100: avg data time: 1.05e+01, avg batch time: 10.8513, average train loss: 0.4930
[11/18 17:31:05 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1561, average loss: 0.7580
[11/18 17:31:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 66.79	
[11/18 17:31:05 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.02761321158169134
[11/18 17:37:23 visual_prompt]: Epoch 53 / 100: avg data time: 1.04e+01, avg batch time: 10.7855, average train loss: 0.4746
[11/18 17:38:06 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1539, average loss: 0.7014
[11/18 17:38:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 67.34	
[11/18 17:38:06 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.02674391184360313
[11/18 17:44:25 visual_prompt]: Epoch 54 / 100: avg data time: 1.05e+01, avg batch time: 10.8371, average train loss: 0.4627
[11/18 17:45:09 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.1541, average loss: 0.7584
[11/18 17:45:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 66.01	
[11/18 17:45:09 visual_prompt]: Stopping early.
[11/18 17:45:09 visual_prompt]: Rank of current process: 0. World size: 1
[11/18 17:45:09 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/18 17:45:09 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/18 17:45:09 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/18 17:45:09 visual_prompt]: Training with config:
[11/18 17:45:09 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr0.05_wd0.0/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.05, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/18 17:45:09 visual_prompt]: Loading training data...
[11/18 17:45:09 visual_prompt]: Constructing mammo-cbis dataset train...
[11/18 17:45:09 visual_prompt]: Loading validation data...
[11/18 17:45:09 visual_prompt]: Constructing mammo-cbis dataset val...
[11/18 17:45:09 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[11/18 17:45:14 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[11/18 17:45:14 visual_prompt]: tuned percent:0.536
[11/18 17:45:14 visual_prompt]: Device used for model: 0
[11/18 17:45:14 visual_prompt]: Setting up Evaluator...
[11/18 17:45:14 visual_prompt]: Setting up Trainer...
[11/18 17:45:14 visual_prompt]: 	Setting up the optimizer...
[11/18 17:45:14 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/18 17:51:35 visual_prompt]: Epoch 1 / 100: avg data time: 1.05e+01, avg batch time: 10.8798, average train loss: 1.4017
[11/18 17:52:18 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1541, average loss: 1.2969
[11/18 17:52:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[11/18 17:52:18 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.005000000000000001
[11/18 17:58:36 visual_prompt]: Epoch 2 / 100: avg data time: 1.05e+01, avg batch time: 10.8050, average train loss: 0.9974
[11/18 17:59:19 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1568, average loss: 0.6963
[11/18 17:59:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.93	rocauc: 46.32	
[11/18 17:59:19 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.010000000000000002
[11/18 18:05:37 visual_prompt]: Epoch 3 / 100: avg data time: 1.04e+01, avg batch time: 10.8011, average train loss: 0.7075
[11/18 18:06:20 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1543, average loss: 0.6913
[11/18 18:06:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.00	
[11/18 18:06:20 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.015
[11/18 18:12:38 visual_prompt]: Epoch 4 / 100: avg data time: 1.04e+01, avg batch time: 10.7910, average train loss: 0.6962
[11/18 18:13:21 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1557, average loss: 0.6843
[11/18 18:13:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.76	
[11/18 18:13:21 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.020000000000000004
[11/18 18:19:38 visual_prompt]: Epoch 5 / 100: avg data time: 1.04e+01, avg batch time: 10.7762, average train loss: 0.7239
[11/18 18:20:21 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.1539, average loss: 0.6920
[11/18 18:20:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.86	
[11/18 18:20:21 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.025
[11/18 18:26:40 visual_prompt]: Epoch 6 / 100: avg data time: 1.05e+01, avg batch time: 10.8138, average train loss: 0.7310
[11/18 18:27:23 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1542, average loss: 0.6997
[11/18 18:27:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 44.72	rocauc: 59.25	
[11/18 18:27:23 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.03
[11/18 18:33:41 visual_prompt]: Epoch 7 / 100: avg data time: 1.05e+01, avg batch time: 10.8066, average train loss: 0.7009
[11/18 18:34:24 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1546, average loss: 0.6808
[11/18 18:34:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 61.51	
[11/18 18:34:24 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.034999999999999996
[11/18 18:40:42 visual_prompt]: Epoch 8 / 100: avg data time: 1.04e+01, avg batch time: 10.7823, average train loss: 0.6974
[11/18 18:41:25 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1564, average loss: 0.6738
[11/18 18:41:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 62.30	
[11/18 18:41:25 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.04000000000000001
[11/18 18:47:43 visual_prompt]: Epoch 9 / 100: avg data time: 1.04e+01, avg batch time: 10.7944, average train loss: 0.6856
[11/18 18:48:26 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1540, average loss: 0.7333
[11/18 18:48:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 65.32	
[11/18 18:48:26 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.045000000000000005
[11/18 18:54:43 visual_prompt]: Epoch 10 / 100: avg data time: 1.04e+01, avg batch time: 10.7712, average train loss: 0.6829
[11/18 18:55:26 visual_prompt]: Inference (val):avg data time: 3.61e-05, avg batch time: 0.1542, average loss: 0.6664
[11/18 18:55:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 63.91	
[11/18 18:55:26 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.05
[11/18 19:01:43 visual_prompt]: Epoch 11 / 100: avg data time: 1.04e+01, avg batch time: 10.7802, average train loss: 0.6868
[11/18 19:02:26 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.1543, average loss: 0.6614
[11/18 19:02:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 66.02	
[11/18 19:02:26 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0499847706754774
[11/18 19:08:43 visual_prompt]: Epoch 12 / 100: avg data time: 1.04e+01, avg batch time: 10.7682, average train loss: 0.6933
[11/18 19:09:26 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1540, average loss: 0.6682
[11/18 19:09:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 64.27	
[11/18 19:09:26 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.04993910125649561
[11/18 19:15:44 visual_prompt]: Epoch 13 / 100: avg data time: 1.04e+01, avg batch time: 10.7853, average train loss: 0.7000
[11/18 19:16:27 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1544, average loss: 0.6803
[11/18 19:16:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 64.63	
[11/18 19:16:27 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.049863047384206834
[11/18 19:22:43 visual_prompt]: Epoch 14 / 100: avg data time: 1.04e+01, avg batch time: 10.7596, average train loss: 0.6895
[11/18 19:23:26 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1589, average loss: 0.7511
[11/18 19:23:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 65.04	
[11/18 19:23:26 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.04975670171853926
[11/18 19:29:44 visual_prompt]: Epoch 15 / 100: avg data time: 1.04e+01, avg batch time: 10.7952, average train loss: 0.6965
[11/18 19:30:27 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1540, average loss: 0.6573
[11/18 19:30:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 65.48	
[11/18 19:30:27 visual_prompt]: Best epoch 15: best metric: -0.657
[11/18 19:30:27 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.049620193825305206
[11/18 19:36:44 visual_prompt]: Epoch 16 / 100: avg data time: 1.04e+01, avg batch time: 10.7710, average train loss: 0.7084
[11/18 19:37:27 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1546, average loss: 0.8042
[11/18 19:37:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 66.67	
[11/18 19:37:27 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.049453690018345146
[11/18 19:43:44 visual_prompt]: Epoch 17 / 100: avg data time: 1.04e+01, avg batch time: 10.7690, average train loss: 0.6934
[11/18 19:44:27 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1590, average loss: 0.6495
[11/18 19:44:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 67.05	
[11/18 19:44:27 visual_prompt]: Best epoch 17: best metric: -0.650
[11/18 19:44:27 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.04925739315689991
[11/18 19:50:44 visual_prompt]: Epoch 18 / 100: avg data time: 1.04e+01, avg batch time: 10.7769, average train loss: 0.6880
[11/18 19:51:27 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1548, average loss: 0.6940
[11/18 19:51:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 66.80	
[11/18 19:51:27 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.04903154239845797
[11/18 19:57:44 visual_prompt]: Epoch 19 / 100: avg data time: 1.04e+01, avg batch time: 10.7529, average train loss: 0.6829
[11/18 19:58:27 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1553, average loss: 0.7317
[11/18 19:58:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 67.37	
[11/18 19:58:27 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.048776412907378844
[11/18 20:04:44 visual_prompt]: Epoch 20 / 100: avg data time: 1.04e+01, avg batch time: 10.7730, average train loss: 0.6659
[11/18 20:05:27 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1584, average loss: 0.7027
[11/18 20:05:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 67.52	
[11/18 20:05:27 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.048492315519647715
[11/18 20:11:44 visual_prompt]: Epoch 21 / 100: avg data time: 1.04e+01, avg batch time: 10.7689, average train loss: 0.6639
[11/18 20:12:27 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1542, average loss: 0.6485
[11/18 20:12:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 68.45	
[11/18 20:12:27 visual_prompt]: Best epoch 21: best metric: -0.648
[11/18 20:12:27 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.048179596364169686
[11/18 20:18:44 visual_prompt]: Epoch 22 / 100: avg data time: 1.04e+01, avg batch time: 10.7635, average train loss: 0.6540
[11/18 20:19:27 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1540, average loss: 0.7051
[11/18 20:19:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 68.93	
[11/18 20:19:27 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.04783863644106502
[11/18 20:25:43 visual_prompt]: Epoch 23 / 100: avg data time: 1.04e+01, avg batch time: 10.7494, average train loss: 0.6552
[11/18 20:26:26 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1542, average loss: 0.6613
[11/18 20:26:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 69.06	
[11/18 20:26:26 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.047469851157479176
[11/18 20:32:43 visual_prompt]: Epoch 24 / 100: avg data time: 1.04e+01, avg batch time: 10.7834, average train loss: 0.6498
[11/18 20:33:27 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1539, average loss: 0.7112
[11/18 20:33:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 68.80	
[11/18 20:33:27 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.047073689821473176
[11/18 20:39:43 visual_prompt]: Epoch 25 / 100: avg data time: 1.04e+01, avg batch time: 10.7636, average train loss: 0.6704
[11/18 20:40:26 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1543, average loss: 0.6595
[11/18 20:40:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 69.14	
[11/18 20:40:26 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.046650635094610975
[11/18 20:46:44 visual_prompt]: Epoch 26 / 100: avg data time: 1.04e+01, avg batch time: 10.7818, average train loss: 0.6401
[11/18 20:47:27 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1542, average loss: 0.6395
[11/18 20:47:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 69.20	
[11/18 20:47:27 visual_prompt]: Best epoch 26: best metric: -0.640
[11/18 20:47:27 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.04620120240391065
[11/18 20:53:44 visual_prompt]: Epoch 27 / 100: avg data time: 1.04e+01, avg batch time: 10.7821, average train loss: 0.6310
[11/18 20:54:27 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.1566, average loss: 0.6427
[11/18 20:54:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 69.20	
[11/18 20:54:27 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.04572593931387604
[11/18 21:00:44 visual_prompt]: Epoch 28 / 100: avg data time: 1.04e+01, avg batch time: 10.7668, average train loss: 0.6367
[11/18 21:01:27 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1567, average loss: 0.7055
[11/18 21:01:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 68.85	
[11/18 21:01:27 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.04522542485937369
[11/18 21:07:45 visual_prompt]: Epoch 29 / 100: avg data time: 1.04e+01, avg batch time: 10.7933, average train loss: 0.6280
[11/18 21:08:28 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1548, average loss: 0.6443
[11/18 21:08:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.67	rocauc: 69.68	
[11/18 21:08:28 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.04470026884016805
[11/18 21:14:45 visual_prompt]: Epoch 30 / 100: avg data time: 1.04e+01, avg batch time: 10.7727, average train loss: 0.6308
[11/18 21:15:28 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1538, average loss: 0.6383
[11/18 21:15:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 68.82	
[11/18 21:15:28 visual_prompt]: Best epoch 30: best metric: -0.638
[11/18 21:15:28 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.04415111107797445
[11/18 21:21:45 visual_prompt]: Epoch 31 / 100: avg data time: 1.04e+01, avg batch time: 10.7766, average train loss: 0.6132
[11/18 21:22:28 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1542, average loss: 0.6730
[11/18 21:22:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 69.05	
[11/18 21:22:28 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.04357862063693486
[11/18 21:28:46 visual_prompt]: Epoch 32 / 100: avg data time: 1.04e+01, avg batch time: 10.7802, average train loss: 0.6313
[11/18 21:29:29 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1542, average loss: 0.6801
[11/18 21:29:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 68.18	
[11/18 21:29:29 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.04298349500846628
[11/18 21:35:45 visual_prompt]: Epoch 33 / 100: avg data time: 1.04e+01, avg batch time: 10.7606, average train loss: 0.6232
[11/18 21:36:28 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1582, average loss: 0.6271
[11/18 21:36:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.67	rocauc: 70.20	
[11/18 21:36:28 visual_prompt]: Best epoch 33: best metric: -0.627
[11/18 21:36:28 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.042366459261474934
[11/18 21:42:45 visual_prompt]: Epoch 34 / 100: avg data time: 1.04e+01, avg batch time: 10.7557, average train loss: 0.6143
[11/18 21:43:28 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1541, average loss: 0.7344
[11/18 21:43:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.54	rocauc: 69.22	
[11/18 21:43:28 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.04172826515897146
[11/18 21:49:45 visual_prompt]: Epoch 35 / 100: avg data time: 1.04e+01, avg batch time: 10.7664, average train loss: 0.6080
[11/18 21:50:28 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1543, average loss: 0.6371
[11/18 21:50:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 69.91	
[11/18 21:50:28 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.04106969024216348
[11/18 21:56:44 visual_prompt]: Epoch 36 / 100: avg data time: 1.04e+01, avg batch time: 10.7562, average train loss: 0.6018
[11/18 21:57:27 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.1544, average loss: 0.6572
[11/18 21:57:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 68.40	
[11/18 21:57:27 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.040391536883141455
[11/18 22:03:44 visual_prompt]: Epoch 37 / 100: avg data time: 1.04e+01, avg batch time: 10.7692, average train loss: 0.5982
[11/18 22:04:27 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1542, average loss: 0.6882
[11/18 22:04:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 69.17	
[11/18 22:04:27 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.03969463130731183
[11/18 22:10:45 visual_prompt]: Epoch 38 / 100: avg data time: 1.04e+01, avg batch time: 10.7817, average train loss: 0.5736
[11/18 22:11:28 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1552, average loss: 0.7073
[11/18 22:11:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 69.56	
[11/18 22:11:28 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.03897982258676867
[11/18 22:17:44 visual_prompt]: Epoch 39 / 100: avg data time: 1.04e+01, avg batch time: 10.7658, average train loss: 0.5889
[11/18 22:18:27 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1541, average loss: 0.6344
[11/18 22:18:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 69.92	
[11/18 22:18:27 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.03824798160583012
[11/18 22:24:45 visual_prompt]: Epoch 40 / 100: avg data time: 1.04e+01, avg batch time: 10.7816, average train loss: 0.5774
[11/18 22:25:28 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1550, average loss: 0.6468
[11/18 22:25:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 69.80	
[11/18 22:25:28 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.037500000000000006
[11/18 22:31:45 visual_prompt]: Epoch 41 / 100: avg data time: 1.04e+01, avg batch time: 10.7751, average train loss: 0.5587
[11/18 22:32:28 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1543, average loss: 0.6470
[11/18 22:32:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 68.87	
[11/18 22:32:28 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.03673678906964727
[11/18 22:38:45 visual_prompt]: Epoch 42 / 100: avg data time: 1.04e+01, avg batch time: 10.7654, average train loss: 0.5749
[11/18 22:39:28 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.1571, average loss: 0.7001
[11/18 22:39:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.01	rocauc: 68.40	
[11/18 22:39:28 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.03595927866972694
[11/18 22:45:45 visual_prompt]: Epoch 43 / 100: avg data time: 1.04e+01, avg batch time: 10.7600, average train loss: 0.5594
[11/18 22:46:28 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1540, average loss: 0.6554
[11/18 22:46:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 69.89	
[11/18 22:46:28 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.03516841607689501
[11/18 22:52:45 visual_prompt]: Epoch 44 / 100: avg data time: 1.04e+01, avg batch time: 10.7703, average train loss: 0.5615
[11/18 22:53:28 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1567, average loss: 0.7721
[11/18 22:53:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 66.98	
[11/18 22:53:28 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.0343651648353978
[11/18 22:59:46 visual_prompt]: Epoch 45 / 100: avg data time: 1.04e+01, avg batch time: 10.7972, average train loss: 0.5813
[11/18 23:00:29 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1542, average loss: 0.6535
[11/18 23:00:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.07	rocauc: 69.54	
[11/18 23:00:29 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.033550503583141725
[11/18 23:06:45 visual_prompt]: Epoch 46 / 100: avg data time: 1.04e+01, avg batch time: 10.7520, average train loss: 0.5278
[11/18 23:07:28 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1539, average loss: 0.6951
[11/18 23:07:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 70.23	
[11/18 23:07:28 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.032725424859373686
[11/18 23:13:44 visual_prompt]: Epoch 47 / 100: avg data time: 1.04e+01, avg batch time: 10.7487, average train loss: 0.5300
[11/18 23:14:27 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1544, average loss: 0.6891
[11/18 23:14:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 69.75	
[11/18 23:14:27 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.03189093389542498
[11/18 23:20:44 visual_prompt]: Epoch 48 / 100: avg data time: 1.04e+01, avg batch time: 10.7644, average train loss: 0.5350
[11/18 23:21:27 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1571, average loss: 0.6339
[11/18 23:21:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 69.09	
[11/18 23:21:27 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.03104804738999169
[11/18 23:27:43 visual_prompt]: Epoch 49 / 100: avg data time: 1.04e+01, avg batch time: 10.7516, average train loss: 0.5298
[11/18 23:28:26 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1539, average loss: 0.6846
[11/18 23:28:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.01	rocauc: 68.69	
[11/18 23:28:26 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.03019779227044398
[11/18 23:34:43 visual_prompt]: Epoch 50 / 100: avg data time: 1.04e+01, avg batch time: 10.7463, average train loss: 0.5162
[11/18 23:35:26 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.1540, average loss: 0.7173
[11/18 23:35:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.07	rocauc: 69.16	
[11/18 23:35:26 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.029341204441673263
[11/18 23:41:43 visual_prompt]: Epoch 51 / 100: avg data time: 1.04e+01, avg batch time: 10.7762, average train loss: 0.5063
[11/18 23:42:26 visual_prompt]: Inference (val):avg data time: 3.46e-05, avg batch time: 0.1540, average loss: 0.6813
[11/18 23:42:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 68.67	
[11/18 23:42:26 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.028479327524001636
[11/18 23:48:43 visual_prompt]: Epoch 52 / 100: avg data time: 1.04e+01, avg batch time: 10.7713, average train loss: 0.4955
[11/18 23:49:26 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1543, average loss: 0.7950
[11/18 23:49:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 66.74	
[11/18 23:49:26 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.02761321158169134
[11/18 23:55:43 visual_prompt]: Epoch 53 / 100: avg data time: 1.04e+01, avg batch time: 10.7640, average train loss: 0.4851
[11/18 23:56:26 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1546, average loss: 0.6680
[11/18 23:56:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 67.69	
[11/18 23:56:26 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.02674391184360313
[11/19 00:02:43 visual_prompt]: Epoch 54 / 100: avg data time: 1.04e+01, avg batch time: 10.7783, average train loss: 0.4650
[11/19 00:03:26 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1541, average loss: 0.7164
[11/19 00:03:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 67.06	
[11/19 00:03:26 visual_prompt]: Stopping early.
[11/19 00:03:27 visual_prompt]: Rank of current process: 0. World size: 1
[11/19 00:03:27 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/19 00:03:27 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/19 00:03:27 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/19 00:03:27 visual_prompt]: Training with config:
[11/19 00:03:27 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/test/seed9805/lrNone_wdNone/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 9805, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': None, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': None, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/19 00:03:27 visual_prompt]: Loading training data...
[11/19 00:03:27 visual_prompt]: Constructing mammo-cbis dataset train...
[11/19 00:03:27 visual_prompt]: Loading validation data...
[11/19 00:03:27 visual_prompt]: Constructing mammo-cbis dataset val...
[11/19 00:03:27 visual_prompt]: Loading test data...
[11/19 00:03:27 visual_prompt]: Constructing mammo-cbis dataset test...
[11/19 00:03:27 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[11/19 00:03:29 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[11/19 00:03:29 visual_prompt]: tuned percent:0.536
[11/19 00:03:29 visual_prompt]: Device used for model: 0
[11/19 00:03:29 visual_prompt]: Setting up Evaluator...
[11/19 00:03:29 visual_prompt]: Setting up Trainer...
[11/19 00:03:29 visual_prompt]: 	Setting up the optimizer...
Traceback (most recent call last):
  File "/home/s1952889/final-project/implementation/visual_prompt_tuning/tune_cbis.py", line 99, in <module>
    main(args)
  File "/home/s1952889/final-project/implementation/visual_prompt_tuning/tune_cbis.py", line 94, in main
    train(cfg, args)
  File "/home/s1952889/final-project/implementation/visual_prompt_tuning/tune_cbis.py", line 43, in train
    trainer = Trainer(cfg, model, evaluator, cur_device)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/s1952889/final-project/implementation/visual_prompt_tuning/src/engine/trainer.py", line 46, in __init__
    self.optimizer = make_optimizer([self.model], cfg.SOLVER)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/s1952889/final-project/implementation/visual_prompt_tuning/src/solver/optimizer.py", line 36, in make_optimizer
    if train_params.WEIGHT_DECAY > 0:
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: '>' not supported between instances of 'NoneType' and 'int'
/bin/bash: /home/s1952889/miniconda3/envs/prompt/lib/libtinfo.so.6: no version information available (required by /bin/bash)
