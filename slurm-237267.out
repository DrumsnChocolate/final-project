/bin/bash: /home/s1952889/miniconda3/envs/prompt/lib/libtinfo.so.6: no version information available (required by /bin/bash)
An exception occurred in telemetry logging.Disabling telemetry to prevent further exceptions.
Traceback (most recent call last):
  File "/home/s1952889/miniconda3/envs/prompt/lib/python3.11/site-packages/iopath/common/file_io.py", line 946, in __log_tmetry_keys
    handler.log_event()
  File "/home/s1952889/miniconda3/envs/prompt/lib/python3.11/site-packages/iopath/common/event_logger.py", line 97, in log_event
    del self._evt
        ^^^^^^^^^
AttributeError: 'NativePathHandler' object has no attribute '_evt'
Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-sun397', 'DATA.NUMBER_CLASSES', '397', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 00:48:48 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 00:48:48 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              0
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 00:48:48 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-sun397', 'DATA.NUMBER_CLASSES', '397', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 00:48:48 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 00:48:48 visual_prompt]: Training with config:
[09/26 00:48:48 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-sun397/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr50.0_wd0.01/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 50.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-sun397', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 397, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 00:48:48 visual_prompt]: Loading training data...
2023-09-26 00:48:49.236567: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-09-26 00:48:49.284526: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-09-26 00:48:51.446254: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[09/26 00:48:54 visual_prompt]: Constructing vtab-sun397 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split train[:800], from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/26 00:48:56 visual_prompt]: Number of images: 800
[09/26 00:48:56 visual_prompt]: Number of classes: 309 / 397
[09/26 00:48:56 visual_prompt]: Loading validation data...
[09/26 00:48:56 visual_prompt]: Constructing vtab-sun397 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split validation[:200], from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/26 00:48:56 visual_prompt]: Number of images: 200
[09/26 00:48:56 visual_prompt]: Number of classes: 136 / 397
[09/26 00:48:56 visual_prompt]: Constructing models...
[09/26 00:48:59 visual_prompt]: Total Parameters: 86564749	 Gradient Parameters: 766093
[09/26 00:48:59 visual_prompt]: tuned percent:0.885
[09/26 00:49:01 visual_prompt]: Device used for model: 0
[09/26 00:49:01 visual_prompt]: Setting up Evaluator...
[09/26 00:49:01 visual_prompt]: Setting up Trainer...
[09/26 00:49:01 visual_prompt]: 	Setting up the optimizer...
[09/26 00:49:01 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 00:49:12 visual_prompt]: Epoch 1 / 100: avg data time: 1.92e-01, avg batch time: 0.8162, average train loss: 5.9895
[09/26 00:49:13 visual_prompt]: Inference (val):avg data time: 1.99e-05, avg batch time: 0.1659, average loss: 6.0097
[09/26 00:49:13 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/26 00:49:13 visual_prompt]: Training 2 / 100 epoch, with learning rate 5.0
[09/26 00:49:20 visual_prompt]: Epoch 2 / 100: avg data time: 4.95e-02, avg batch time: 0.4882, average train loss: 5.8865
[09/26 00:49:21 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1653, average loss: 6.0077
[09/26 00:49:21 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.50	
[09/26 00:49:21 visual_prompt]: Best epoch 2: best metric: 0.010
[09/26 00:49:21 visual_prompt]: Training 3 / 100 epoch, with learning rate 10.0
[09/26 00:49:28 visual_prompt]: Epoch 3 / 100: avg data time: 5.12e-02, avg batch time: 0.4888, average train loss: 6.3268
[09/26 00:49:29 visual_prompt]: Inference (val):avg data time: 1.94e-05, avg batch time: 0.1653, average loss: 6.4125
[09/26 00:49:29 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.00	
[09/26 00:49:29 visual_prompt]: Training 4 / 100 epoch, with learning rate 15.0
[09/26 00:49:36 visual_prompt]: Epoch 4 / 100: avg data time: 5.21e-02, avg batch time: 0.4918, average train loss: 7.0514
[09/26 00:49:37 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1655, average loss: 8.4359
[09/26 00:49:37 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/26 00:49:37 visual_prompt]: Training 5 / 100 epoch, with learning rate 20.0
[09/26 00:49:44 visual_prompt]: Epoch 5 / 100: avg data time: 5.06e-02, avg batch time: 0.4920, average train loss: 10.7117
[09/26 00:49:45 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1661, average loss: 15.0783
[09/26 00:49:45 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.50	
[09/26 00:49:45 visual_prompt]: Training 6 / 100 epoch, with learning rate 25.0
[09/26 00:49:52 visual_prompt]: Epoch 6 / 100: avg data time: 5.28e-02, avg batch time: 0.4942, average train loss: 16.6807
[09/26 00:49:53 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1666, average loss: 18.6660
[09/26 00:49:53 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 2.00	
[09/26 00:49:53 visual_prompt]: Training 7 / 100 epoch, with learning rate 30.0
[09/26 00:50:00 visual_prompt]: Epoch 7 / 100: avg data time: 5.05e-02, avg batch time: 0.4920, average train loss: 25.4152
[09/26 00:50:01 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1667, average loss: 26.9592
[09/26 00:50:01 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.00	
[09/26 00:50:01 visual_prompt]: Training 8 / 100 epoch, with learning rate 35.0
[09/26 00:50:08 visual_prompt]: Epoch 8 / 100: avg data time: 4.81e-02, avg batch time: 0.4895, average train loss: 42.9979
[09/26 00:50:09 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1671, average loss: 39.9062
[09/26 00:50:09 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 0.00	
[09/26 00:50:09 visual_prompt]: Training 9 / 100 epoch, with learning rate 40.0
[09/26 00:50:16 visual_prompt]: Epoch 9 / 100: avg data time: 4.98e-02, avg batch time: 0.4930, average train loss: 62.6595
[09/26 00:50:17 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1667, average loss: 45.9765
[09/26 00:50:17 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.00	
[09/26 00:50:17 visual_prompt]: Training 10 / 100 epoch, with learning rate 45.0
[09/26 00:50:24 visual_prompt]: Epoch 10 / 100: avg data time: 5.07e-02, avg batch time: 0.4942, average train loss: 77.4281
[09/26 00:50:25 visual_prompt]: Inference (val):avg data time: 1.68e-05, avg batch time: 0.1673, average loss: 64.7547
[09/26 00:50:25 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 2.50	
[09/26 00:50:25 visual_prompt]: Training 11 / 100 epoch, with learning rate 50.0
[09/26 00:50:32 visual_prompt]: Epoch 11 / 100: avg data time: 5.09e-02, avg batch time: 0.4943, average train loss: 97.5453
[09/26 00:50:33 visual_prompt]: Inference (val):avg data time: 1.65e-05, avg batch time: 0.1667, average loss: 90.7736
[09/26 00:50:33 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.50	
[09/26 00:50:33 visual_prompt]: Training 12 / 100 epoch, with learning rate 49.9847706754774
[09/26 00:50:40 visual_prompt]: Epoch 12 / 100: avg data time: 5.25e-02, avg batch time: 0.4942, average train loss: 108.3080
[09/26 00:50:41 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1668, average loss: 96.6575
[09/26 00:50:41 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 3.00	
[09/26 00:50:41 visual_prompt]: Training 13 / 100 epoch, with learning rate 49.939101256495604
[09/26 00:50:48 visual_prompt]: Epoch 13 / 100: avg data time: 4.98e-02, avg batch time: 0.4921, average train loss: 134.3469
[09/26 00:50:49 visual_prompt]: Inference (val):avg data time: 1.87e-05, avg batch time: 0.1669, average loss: 119.9822
[09/26 00:50:49 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.00	
[09/26 00:50:49 visual_prompt]: Training 14 / 100 epoch, with learning rate 49.86304738420683
[09/26 00:50:56 visual_prompt]: Epoch 14 / 100: avg data time: 5.10e-02, avg batch time: 0.4939, average train loss: 144.2347
[09/26 00:50:57 visual_prompt]: Inference (val):avg data time: 1.72e-05, avg batch time: 0.1672, average loss: 127.5582
[09/26 00:50:57 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 0.50	
[09/26 00:50:57 visual_prompt]: Training 15 / 100 epoch, with learning rate 49.75670171853926
[09/26 00:51:04 visual_prompt]: Epoch 15 / 100: avg data time: 5.87e-02, avg batch time: 0.5016, average train loss: 145.3463
[09/26 00:51:05 visual_prompt]: Inference (val):avg data time: 1.72e-05, avg batch time: 0.1674, average loss: 139.6642
[09/26 00:51:05 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 0.50	
[09/26 00:51:05 visual_prompt]: Training 16 / 100 epoch, with learning rate 49.6201938253052
[09/26 00:51:12 visual_prompt]: Epoch 16 / 100: avg data time: 4.95e-02, avg batch time: 0.4929, average train loss: 151.1651
[09/26 00:51:13 visual_prompt]: Inference (val):avg data time: 1.91e-05, avg batch time: 0.1674, average loss: 150.4330
[09/26 00:51:13 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.00	
[09/26 00:51:13 visual_prompt]: Training 17 / 100 epoch, with learning rate 49.45369001834514
[09/26 00:51:20 visual_prompt]: Epoch 17 / 100: avg data time: 5.08e-02, avg batch time: 0.4940, average train loss: 149.8668
[09/26 00:51:21 visual_prompt]: Inference (val):avg data time: 1.52e-05, avg batch time: 0.1673, average loss: 145.1465
[09/26 00:51:21 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 3.00	
[09/26 00:51:21 visual_prompt]: Training 18 / 100 epoch, with learning rate 49.25739315689991
[09/26 00:51:28 visual_prompt]: Epoch 18 / 100: avg data time: 5.19e-02, avg batch time: 0.4946, average train loss: 162.8686
[09/26 00:51:29 visual_prompt]: Inference (val):avg data time: 1.78e-05, avg batch time: 0.1674, average loss: 152.3493
[09/26 00:51:29 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 1.50	
[09/26 00:51:29 visual_prompt]: Training 19 / 100 epoch, with learning rate 49.03154239845797
[09/26 00:51:36 visual_prompt]: Epoch 19 / 100: avg data time: 4.94e-02, avg batch time: 0.4922, average train loss: 158.8576
[09/26 00:51:37 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1675, average loss: 154.6107
[09/26 00:51:37 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 1.00	
[09/26 00:51:37 visual_prompt]: Training 20 / 100 epoch, with learning rate 48.77641290737884
[09/26 00:51:44 visual_prompt]: Epoch 20 / 100: avg data time: 5.28e-02, avg batch time: 0.4979, average train loss: 151.3608
[09/26 00:51:45 visual_prompt]: Inference (val):avg data time: 1.93e-05, avg batch time: 0.1675, average loss: 141.7955
[09/26 00:51:45 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.50	
[09/26 00:51:45 visual_prompt]: Training 21 / 100 epoch, with learning rate 48.49231551964771
[09/26 00:51:52 visual_prompt]: Epoch 21 / 100: avg data time: 5.02e-02, avg batch time: 0.4929, average train loss: 142.3857
[09/26 00:51:53 visual_prompt]: Inference (val):avg data time: 3.52e-05, avg batch time: 0.1675, average loss: 130.7524
[09/26 00:51:53 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.00	top5: 3.00	
[09/26 00:51:53 visual_prompt]: Best epoch 21: best metric: 0.020
[09/26 00:51:53 visual_prompt]: Training 22 / 100 epoch, with learning rate 48.17959636416968
[09/26 00:52:00 visual_prompt]: Epoch 22 / 100: avg data time: 4.54e-02, avg batch time: 0.4898, average train loss: 142.4786
[09/26 00:52:01 visual_prompt]: Inference (val):avg data time: 1.99e-05, avg batch time: 0.1678, average loss: 135.0890
[09/26 00:52:01 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 1.50	
[09/26 00:52:01 visual_prompt]: Training 23 / 100 epoch, with learning rate 47.83863644106502
[09/26 00:52:08 visual_prompt]: Epoch 23 / 100: avg data time: 5.43e-02, avg batch time: 0.4997, average train loss: 141.3324
[09/26 00:52:09 visual_prompt]: Inference (val):avg data time: 1.92e-05, avg batch time: 0.1677, average loss: 139.3843
[09/26 00:52:09 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.00	
[09/26 00:52:09 visual_prompt]: Training 24 / 100 epoch, with learning rate 47.46985115747918
[09/26 00:52:16 visual_prompt]: Epoch 24 / 100: avg data time: 5.53e-02, avg batch time: 0.4998, average train loss: 148.8814
[09/26 00:52:18 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1678, average loss: 136.1521
[09/26 00:52:18 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 0.50	
[09/26 00:52:18 visual_prompt]: Training 25 / 100 epoch, with learning rate 47.073689821473174
[09/26 00:52:24 visual_prompt]: Epoch 25 / 100: avg data time: 5.33e-02, avg batch time: 0.4987, average train loss: 144.2426
[09/26 00:52:26 visual_prompt]: Inference (val):avg data time: 2.00e-05, avg batch time: 0.1678, average loss: 121.8620
[09/26 00:52:26 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.00	top5: 3.00	
[09/26 00:52:26 visual_prompt]: Training 26 / 100 epoch, with learning rate 46.65063509461097
[09/26 00:52:32 visual_prompt]: Epoch 26 / 100: avg data time: 4.15e-02, avg batch time: 0.4872, average train loss: 145.0306
[09/26 00:52:34 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1675, average loss: 128.3013
[09/26 00:52:34 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 0.00	
[09/26 00:52:34 visual_prompt]: Training 27 / 100 epoch, with learning rate 46.20120240391065
[09/26 00:52:40 visual_prompt]: Epoch 27 / 100: avg data time: 4.89e-02, avg batch time: 0.4939, average train loss: 173.4350
[09/26 00:52:42 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1678, average loss: 143.4908
[09/26 00:52:42 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.00	
[09/26 00:52:42 visual_prompt]: Training 28 / 100 epoch, with learning rate 45.72593931387604
[09/26 00:52:48 visual_prompt]: Epoch 28 / 100: avg data time: 5.30e-02, avg batch time: 0.4972, average train loss: 146.6176
[09/26 00:52:50 visual_prompt]: Inference (val):avg data time: 1.90e-05, avg batch time: 0.1679, average loss: 141.6631
[09/26 00:52:50 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 1.50	
[09/26 00:52:50 visual_prompt]: Training 29 / 100 epoch, with learning rate 45.22542485937369
[09/26 00:52:56 visual_prompt]: Epoch 29 / 100: avg data time: 4.84e-02, avg batch time: 0.4940, average train loss: 157.0647
[09/26 00:52:58 visual_prompt]: Inference (val):avg data time: 3.45e-05, avg batch time: 0.1674, average loss: 143.9145
[09/26 00:52:58 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.50	
[09/26 00:52:58 visual_prompt]: Training 30 / 100 epoch, with learning rate 44.70026884016804
[09/26 00:53:05 visual_prompt]: Epoch 30 / 100: avg data time: 5.37e-02, avg batch time: 0.4982, average train loss: 151.0686
[09/26 00:53:06 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1679, average loss: 136.7970
[09/26 00:53:06 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/26 00:53:06 visual_prompt]: Training 31 / 100 epoch, with learning rate 44.15111107797445
[09/26 00:53:13 visual_prompt]: Epoch 31 / 100: avg data time: 5.27e-02, avg batch time: 0.4978, average train loss: 141.5500
[09/26 00:53:14 visual_prompt]: Inference (val):avg data time: 2.11e-05, avg batch time: 0.1678, average loss: 124.0052
[09/26 00:53:14 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 0.50	
[09/26 00:53:14 visual_prompt]: Training 32 / 100 epoch, with learning rate 43.57862063693486
[09/26 00:53:21 visual_prompt]: Epoch 32 / 100: avg data time: 5.03e-02, avg batch time: 0.4952, average train loss: 144.9259
[09/26 00:53:22 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1676, average loss: 126.9228
[09/26 00:53:22 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 2.50	
[09/26 00:53:22 visual_prompt]: Training 33 / 100 epoch, with learning rate 42.98349500846628
[09/26 00:53:29 visual_prompt]: Epoch 33 / 100: avg data time: 5.42e-02, avg batch time: 0.4985, average train loss: 142.3278
[09/26 00:53:30 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1680, average loss: 137.1116
[09/26 00:53:30 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 2.50	
[09/26 00:53:30 visual_prompt]: Training 34 / 100 epoch, with learning rate 42.36645926147493
[09/26 00:53:37 visual_prompt]: Epoch 34 / 100: avg data time: 5.43e-02, avg batch time: 0.4983, average train loss: 155.6870
[09/26 00:53:38 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1679, average loss: 128.4260
[09/26 00:53:38 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.00	
[09/26 00:53:38 visual_prompt]: Training 35 / 100 epoch, with learning rate 41.72826515897145
[09/26 00:53:45 visual_prompt]: Epoch 35 / 100: avg data time: 4.99e-02, avg batch time: 0.4951, average train loss: 147.6757
[09/26 00:53:46 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1676, average loss: 140.3049
[09/26 00:53:46 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 2.50	
[09/26 00:53:46 visual_prompt]: Training 36 / 100 epoch, with learning rate 41.06969024216348
[09/26 00:53:53 visual_prompt]: Epoch 36 / 100: avg data time: 5.58e-02, avg batch time: 0.5004, average train loss: 144.8822
[09/26 00:53:54 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1680, average loss: 134.0430
[09/26 00:53:54 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.50	
[09/26 00:53:54 visual_prompt]: Training 37 / 100 epoch, with learning rate 40.391536883141455
[09/26 00:54:01 visual_prompt]: Epoch 37 / 100: avg data time: 5.28e-02, avg batch time: 0.4967, average train loss: 154.9942
[09/26 00:54:02 visual_prompt]: Inference (val):avg data time: 1.99e-05, avg batch time: 0.1674, average loss: 123.8224
[09/26 00:54:02 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 1.50	
[09/26 00:54:02 visual_prompt]: Training 38 / 100 epoch, with learning rate 39.69463130731183
[09/26 00:54:09 visual_prompt]: Epoch 38 / 100: avg data time: 5.49e-02, avg batch time: 0.4987, average train loss: 140.9485
[09/26 00:54:11 visual_prompt]: Inference (val):avg data time: 1.87e-05, avg batch time: 0.1677, average loss: 131.8757
[09/26 00:54:11 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.00	
[09/26 00:54:11 visual_prompt]: Training 39 / 100 epoch, with learning rate 38.97982258676867
[09/26 00:54:17 visual_prompt]: Epoch 39 / 100: avg data time: 5.23e-02, avg batch time: 0.4963, average train loss: 133.8831
[09/26 00:54:19 visual_prompt]: Inference (val):avg data time: 1.80e-05, avg batch time: 0.1675, average loss: 118.1018
[09/26 00:54:19 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 4.50	
[09/26 00:54:19 visual_prompt]: Training 40 / 100 epoch, with learning rate 38.24798160583012
[09/26 00:54:25 visual_prompt]: Epoch 40 / 100: avg data time: 5.97e-02, avg batch time: 0.5031, average train loss: 135.3490
[09/26 00:54:27 visual_prompt]: Inference (val):avg data time: 1.90e-05, avg batch time: 0.1675, average loss: 112.0356
[09/26 00:54:27 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/26 00:54:27 visual_prompt]: Training 41 / 100 epoch, with learning rate 37.5
[09/26 00:54:34 visual_prompt]: Epoch 41 / 100: avg data time: 6.38e-02, avg batch time: 0.5085, average train loss: 133.0238
[09/26 00:54:35 visual_prompt]: Inference (val):avg data time: 1.69e-05, avg batch time: 0.1675, average loss: 105.6482
[09/26 00:54:35 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 1.50	
[09/26 00:54:35 visual_prompt]: Training 42 / 100 epoch, with learning rate 36.736789069647266
[09/26 00:54:42 visual_prompt]: Epoch 42 / 100: avg data time: 4.97e-02, avg batch time: 0.4933, average train loss: 121.1290
[09/26 00:54:43 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1674, average loss: 100.4267
[09/26 00:54:43 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.00	
[09/26 00:54:43 visual_prompt]: Training 43 / 100 epoch, with learning rate 35.959278669726935
[09/26 00:54:50 visual_prompt]: Epoch 43 / 100: avg data time: 3.93e-02, avg batch time: 0.4836, average train loss: 108.0406
[09/26 00:54:51 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1678, average loss: 101.7938
[09/26 00:54:51 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 2.00	
[09/26 00:54:51 visual_prompt]: Training 44 / 100 epoch, with learning rate 35.16841607689501
[09/26 00:54:58 visual_prompt]: Epoch 44 / 100: avg data time: 4.70e-02, avg batch time: 0.4917, average train loss: 122.0211
[09/26 00:54:59 visual_prompt]: Inference (val):avg data time: 1.93e-05, avg batch time: 0.1677, average loss: 121.4930
[09/26 00:54:59 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 2.00	
[09/26 00:54:59 visual_prompt]: Training 45 / 100 epoch, with learning rate 34.365164835397806
[09/26 00:55:06 visual_prompt]: Epoch 45 / 100: avg data time: 4.72e-02, avg batch time: 0.4911, average train loss: 110.2353
[09/26 00:55:07 visual_prompt]: Inference (val):avg data time: 1.83e-05, avg batch time: 0.1675, average loss: 96.2382
[09/26 00:55:07 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 1.00	
[09/26 00:55:07 visual_prompt]: Training 46 / 100 epoch, with learning rate 33.55050358314172
[09/26 00:55:14 visual_prompt]: Epoch 46 / 100: avg data time: 4.79e-02, avg batch time: 0.4921, average train loss: 105.4215
[09/26 00:55:15 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1674, average loss: 82.8542
[09/26 00:55:15 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.00	
[09/26 00:55:15 visual_prompt]: Training 47 / 100 epoch, with learning rate 32.72542485937369
[09/26 00:55:22 visual_prompt]: Epoch 47 / 100: avg data time: 4.45e-02, avg batch time: 0.4892, average train loss: 113.4286
[09/26 00:55:23 visual_prompt]: Inference (val):avg data time: 1.90e-05, avg batch time: 0.1675, average loss: 80.0686
[09/26 00:55:23 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.00	
[09/26 00:55:23 visual_prompt]: Training 48 / 100 epoch, with learning rate 31.89093389542498
[09/26 00:55:30 visual_prompt]: Epoch 48 / 100: avg data time: 5.27e-02, avg batch time: 0.4979, average train loss: 109.7129
[09/26 00:55:31 visual_prompt]: Inference (val):avg data time: 1.96e-05, avg batch time: 0.1677, average loss: 85.8712
[09/26 00:55:31 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.00	
[09/26 00:55:31 visual_prompt]: Training 49 / 100 epoch, with learning rate 31.04804738999169
[09/26 00:55:38 visual_prompt]: Epoch 49 / 100: avg data time: 5.19e-02, avg batch time: 0.4954, average train loss: 104.5550
[09/26 00:55:39 visual_prompt]: Inference (val):avg data time: 1.59e-05, avg batch time: 0.1677, average loss: 85.3507
[09/26 00:55:39 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.50	
[09/26 00:55:39 visual_prompt]: Training 50 / 100 epoch, with learning rate 30.19779227044398
[09/26 00:55:46 visual_prompt]: Epoch 50 / 100: avg data time: 5.19e-02, avg batch time: 0.4958, average train loss: 105.6788
[09/26 00:55:47 visual_prompt]: Inference (val):avg data time: 1.79e-05, avg batch time: 0.1676, average loss: 81.2156
[09/26 00:55:47 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.00	
[09/26 00:55:47 visual_prompt]: Training 51 / 100 epoch, with learning rate 29.341204441673263
[09/26 00:55:54 visual_prompt]: Epoch 51 / 100: avg data time: 5.28e-02, avg batch time: 0.4965, average train loss: 105.8499
[09/26 00:55:55 visual_prompt]: Inference (val):avg data time: 1.85e-05, avg batch time: 0.1679, average loss: 71.6203
[09/26 00:55:55 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/26 00:55:55 visual_prompt]: Training 52 / 100 epoch, with learning rate 28.479327524001636
[09/26 00:56:02 visual_prompt]: Epoch 52 / 100: avg data time: 5.39e-02, avg batch time: 0.4975, average train loss: 84.7520
[09/26 00:56:03 visual_prompt]: Inference (val):avg data time: 4.01e-05, avg batch time: 0.1677, average loss: 72.0063
[09/26 00:56:03 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.00	
[09/26 00:56:03 visual_prompt]: Training 53 / 100 epoch, with learning rate 27.61321158169134
[09/26 00:56:10 visual_prompt]: Epoch 53 / 100: avg data time: 5.42e-02, avg batch time: 0.4980, average train loss: 85.1608
[09/26 00:56:11 visual_prompt]: Inference (val):avg data time: 1.59e-05, avg batch time: 0.1673, average loss: 63.4112
[09/26 00:56:11 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 1.50	
[09/26 00:56:11 visual_prompt]: Training 54 / 100 epoch, with learning rate 26.74391184360313
[09/26 00:56:18 visual_prompt]: Epoch 54 / 100: avg data time: 5.07e-02, avg batch time: 0.4942, average train loss: 94.1596
[09/26 00:56:19 visual_prompt]: Inference (val):avg data time: 1.82e-05, avg batch time: 0.1676, average loss: 64.9990
[09/26 00:56:19 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.00	
[09/26 00:56:19 visual_prompt]: Training 55 / 100 epoch, with learning rate 25.872487417562528
[09/26 00:56:26 visual_prompt]: Epoch 55 / 100: avg data time: 5.13e-02, avg batch time: 0.4945, average train loss: 96.3468
[09/26 00:56:27 visual_prompt]: Inference (val):avg data time: 1.75e-05, avg batch time: 0.1675, average loss: 65.0790
[09/26 00:56:27 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.50	
[09/26 00:56:27 visual_prompt]: Training 56 / 100 epoch, with learning rate 25.0
[09/26 00:56:34 visual_prompt]: Epoch 56 / 100: avg data time: 4.95e-02, avg batch time: 0.4931, average train loss: 88.9969
[09/26 00:56:35 visual_prompt]: Inference (val):avg data time: 1.71e-05, avg batch time: 0.1675, average loss: 71.1038
[09/26 00:56:35 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 2.50	
[09/26 00:56:35 visual_prompt]: Training 57 / 100 epoch, with learning rate 24.127512582437483
[09/26 00:56:42 visual_prompt]: Epoch 57 / 100: avg data time: 5.58e-02, avg batch time: 0.4993, average train loss: 83.1078
[09/26 00:56:44 visual_prompt]: Inference (val):avg data time: 1.90e-05, avg batch time: 0.1676, average loss: 61.5588
[09/26 00:56:44 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 2.00	
[09/26 00:56:44 visual_prompt]: Training 58 / 100 epoch, with learning rate 23.256088156396867
[09/26 00:56:50 visual_prompt]: Epoch 58 / 100: avg data time: 5.09e-02, avg batch time: 0.4945, average train loss: 74.4006
[09/26 00:56:52 visual_prompt]: Inference (val):avg data time: 1.95e-05, avg batch time: 0.1676, average loss: 63.4122
[09/26 00:56:52 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.50	
[09/26 00:56:52 visual_prompt]: Training 59 / 100 epoch, with learning rate 22.38678841830867
[09/26 00:56:58 visual_prompt]: Epoch 59 / 100: avg data time: 4.96e-02, avg batch time: 0.4951, average train loss: 75.9537
[09/26 00:57:00 visual_prompt]: Inference (val):avg data time: 1.71e-05, avg batch time: 0.1678, average loss: 66.6822
[09/26 00:57:00 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 2.00	
[09/26 00:57:00 visual_prompt]: Training 60 / 100 epoch, with learning rate 21.52067247599837
[09/26 00:57:06 visual_prompt]: Epoch 60 / 100: avg data time: 5.46e-02, avg batch time: 0.4985, average train loss: 79.7242
[09/26 00:57:08 visual_prompt]: Inference (val):avg data time: 1.77e-05, avg batch time: 0.1675, average loss: 60.5459
[09/26 00:57:08 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.00	
[09/26 00:57:08 visual_prompt]: Training 61 / 100 epoch, with learning rate 20.65879555832674
[09/26 00:57:14 visual_prompt]: Epoch 61 / 100: avg data time: 3.86e-02, avg batch time: 0.4855, average train loss: 68.6695
[09/26 00:57:16 visual_prompt]: Inference (val):avg data time: 1.97e-05, avg batch time: 0.1674, average loss: 56.7327
[09/26 00:57:16 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 0.50	
[09/26 00:57:16 visual_prompt]: Training 62 / 100 epoch, with learning rate 19.80220772955602
[09/26 00:57:22 visual_prompt]: Epoch 62 / 100: avg data time: 5.57e-02, avg batch time: 0.5003, average train loss: 62.5354
[09/26 00:57:24 visual_prompt]: Inference (val):avg data time: 3.72e-05, avg batch time: 0.1678, average loss: 51.5841
[09/26 00:57:24 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 0.00	
[09/26 00:57:24 visual_prompt]: Training 63 / 100 epoch, with learning rate 18.95195261000831
[09/26 00:57:30 visual_prompt]: Epoch 63 / 100: avg data time: 4.71e-02, avg batch time: 0.4921, average train loss: 53.8368
[09/26 00:57:32 visual_prompt]: Inference (val):avg data time: 1.47e-05, avg batch time: 0.1677, average loss: 48.6157
[09/26 00:57:32 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.50	
[09/26 00:57:32 visual_prompt]: Training 64 / 100 epoch, with learning rate 18.10906610457502
[09/26 00:57:39 visual_prompt]: Epoch 64 / 100: avg data time: 5.55e-02, avg batch time: 0.4993, average train loss: 51.5036
[09/26 00:57:40 visual_prompt]: Inference (val):avg data time: 1.83e-05, avg batch time: 0.1675, average loss: 48.6969
[09/26 00:57:40 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.00	top5: 3.50	
[09/26 00:57:40 visual_prompt]: Training 65 / 100 epoch, with learning rate 17.274575140626318
[09/26 00:57:47 visual_prompt]: Epoch 65 / 100: avg data time: 5.12e-02, avg batch time: 0.4946, average train loss: 48.2741
[09/26 00:57:48 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1673, average loss: 45.9200
[09/26 00:57:48 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 0.00	
[09/26 00:57:48 visual_prompt]: Training 66 / 100 epoch, with learning rate 16.449496416858285
[09/26 00:57:55 visual_prompt]: Epoch 66 / 100: avg data time: 5.54e-02, avg batch time: 0.4991, average train loss: 45.8215
[09/26 00:57:56 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1675, average loss: 45.6311
[09/26 00:57:56 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 1.50	
[09/26 00:57:56 visual_prompt]: Training 67 / 100 epoch, with learning rate 15.634835164602197
[09/26 00:58:03 visual_prompt]: Epoch 67 / 100: avg data time: 4.97e-02, avg batch time: 0.4945, average train loss: 43.7849
[09/26 00:58:04 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1679, average loss: 40.4981
[09/26 00:58:04 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.50	
[09/26 00:58:04 visual_prompt]: Training 68 / 100 epoch, with learning rate 14.831583923104999
[09/26 00:58:11 visual_prompt]: Epoch 68 / 100: avg data time: 5.18e-02, avg batch time: 0.4985, average train loss: 40.8199
[09/26 00:58:12 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1677, average loss: 38.8739
[09/26 00:58:12 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 1.50	
[09/26 00:58:12 visual_prompt]: Training 69 / 100 epoch, with learning rate 14.040721330273062
[09/26 00:58:19 visual_prompt]: Epoch 69 / 100: avg data time: 4.70e-02, avg batch time: 0.4907, average train loss: 37.4788
[09/26 00:58:20 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.1678, average loss: 33.6978
[09/26 00:58:20 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.50	
[09/26 00:58:20 visual_prompt]: Training 70 / 100 epoch, with learning rate 13.263210930352736
[09/26 00:58:27 visual_prompt]: Epoch 70 / 100: avg data time: 5.10e-02, avg batch time: 0.4950, average train loss: 36.4960
[09/26 00:58:28 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1678, average loss: 34.6176
[09/26 00:58:28 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 3.50	
[09/26 00:58:28 visual_prompt]: Training 71 / 100 epoch, with learning rate 12.500000000000005
[09/26 00:58:35 visual_prompt]: Epoch 71 / 100: avg data time: 5.34e-02, avg batch time: 0.4973, average train loss: 32.5109
[09/26 00:58:36 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1674, average loss: 31.0656
[09/26 00:58:36 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 0.50	
[09/26 00:58:36 visual_prompt]: Training 72 / 100 epoch, with learning rate 11.75201839416988
[09/26 00:58:43 visual_prompt]: Epoch 72 / 100: avg data time: 5.19e-02, avg batch time: 0.4978, average train loss: 32.8234
[09/26 00:58:44 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1676, average loss: 30.5867
[09/26 00:58:44 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.00	
[09/26 00:58:44 visual_prompt]: Training 73 / 100 epoch, with learning rate 11.020177413231332
[09/26 00:58:51 visual_prompt]: Epoch 73 / 100: avg data time: 4.91e-02, avg batch time: 0.4939, average train loss: 30.5474
[09/26 00:58:52 visual_prompt]: Inference (val):avg data time: 1.96e-05, avg batch time: 0.1679, average loss: 29.2813
[09/26 00:58:52 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 2.00	
[09/26 00:58:52 visual_prompt]: Training 74 / 100 epoch, with learning rate 10.305368692688175
[09/26 00:58:59 visual_prompt]: Epoch 74 / 100: avg data time: 5.11e-02, avg batch time: 0.4950, average train loss: 28.4729
[09/26 00:59:00 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1673, average loss: 25.6838
[09/26 00:59:00 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 2.50	
[09/26 00:59:00 visual_prompt]: Training 75 / 100 epoch, with learning rate 9.608463116858543
[09/26 00:59:07 visual_prompt]: Epoch 75 / 100: avg data time: 5.20e-02, avg batch time: 0.4962, average train loss: 25.6246
[09/26 00:59:08 visual_prompt]: Inference (val):avg data time: 1.86e-05, avg batch time: 0.1678, average loss: 25.3552
[09/26 00:59:08 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 3.50	
[09/26 00:59:08 visual_prompt]: Training 76 / 100 epoch, with learning rate 8.930309757836516
[09/26 00:59:15 visual_prompt]: Epoch 76 / 100: avg data time: 5.43e-02, avg batch time: 0.4977, average train loss: 23.5954
[09/26 00:59:17 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1677, average loss: 23.1348
[09/26 00:59:17 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 2.50	
[09/26 00:59:17 visual_prompt]: Training 77 / 100 epoch, with learning rate 8.271734841028552
[09/26 00:59:23 visual_prompt]: Epoch 77 / 100: avg data time: 5.19e-02, avg batch time: 0.4950, average train loss: 21.2299
[09/26 00:59:25 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1675, average loss: 21.2661
[09/26 00:59:25 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.50	
[09/26 00:59:25 visual_prompt]: Training 78 / 100 epoch, with learning rate 7.633540738525066
[09/26 00:59:31 visual_prompt]: Epoch 78 / 100: avg data time: 4.90e-02, avg batch time: 0.4920, average train loss: 20.4818
[09/26 00:59:33 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1680, average loss: 20.7003
[09/26 00:59:33 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 2.00	
[09/26 00:59:33 visual_prompt]: Training 79 / 100 epoch, with learning rate 7.016504991533726
[09/26 00:59:39 visual_prompt]: Epoch 79 / 100: avg data time: 4.87e-02, avg batch time: 0.4923, average train loss: 19.2217
[09/26 00:59:41 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1674, average loss: 21.0539
[09/26 00:59:41 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 00:59:41 visual_prompt]: Training 80 / 100 epoch, with learning rate 6.4213793630651415
[09/26 00:59:47 visual_prompt]: Epoch 80 / 100: avg data time: 4.41e-02, avg batch time: 0.4881, average train loss: 19.3494
[09/26 00:59:49 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1679, average loss: 18.9066
[09/26 00:59:49 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 5.00	
[09/26 00:59:49 visual_prompt]: Training 81 / 100 epoch, with learning rate 5.848888922025552
[09/26 00:59:55 visual_prompt]: Epoch 81 / 100: avg data time: 5.02e-02, avg batch time: 0.4936, average train loss: 17.2939
[09/26 00:59:57 visual_prompt]: Inference (val):avg data time: 2.00e-05, avg batch time: 0.1677, average loss: 17.9799
[09/26 00:59:57 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.00	
[09/26 00:59:57 visual_prompt]: Training 82 / 100 epoch, with learning rate 5.2997311598319525
[09/26 01:00:03 visual_prompt]: Epoch 82 / 100: avg data time: 5.04e-02, avg batch time: 0.4937, average train loss: 15.8300
[09/26 01:00:05 visual_prompt]: Inference (val):avg data time: 4.73e-05, avg batch time: 0.1675, average loss: 17.1814
[09/26 01:00:05 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.50	
[09/26 01:00:05 visual_prompt]: Training 83 / 100 epoch, with learning rate 4.774575140626316
[09/26 01:00:11 visual_prompt]: Epoch 83 / 100: avg data time: 4.93e-02, avg batch time: 0.4927, average train loss: 15.0085
[09/26 01:00:13 visual_prompt]: Inference (val):avg data time: 1.86e-05, avg batch time: 0.1678, average loss: 16.4305
[09/26 01:00:13 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.50	
[09/26 01:00:13 visual_prompt]: Training 84 / 100 epoch, with learning rate 4.27406068612396
[09/26 01:00:20 visual_prompt]: Epoch 84 / 100: avg data time: 5.40e-02, avg batch time: 0.4993, average train loss: 14.4788
[09/26 01:00:21 visual_prompt]: Inference (val):avg data time: 2.01e-05, avg batch time: 0.1675, average loss: 15.9951
[09/26 01:00:21 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 3.50	
[09/26 01:00:21 visual_prompt]: Training 85 / 100 epoch, with learning rate 3.798797596089351
[09/26 01:00:28 visual_prompt]: Epoch 85 / 100: avg data time: 5.32e-02, avg batch time: 0.4969, average train loss: 13.9836
[09/26 01:00:29 visual_prompt]: Inference (val):avg data time: 2.02e-05, avg batch time: 0.1675, average loss: 15.6519
[09/26 01:00:29 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 3.50	
[09/26 01:00:29 visual_prompt]: Training 86 / 100 epoch, with learning rate 3.349364905389032
[09/26 01:00:36 visual_prompt]: Epoch 86 / 100: avg data time: 5.33e-02, avg batch time: 0.4973, average train loss: 13.9862
[09/26 01:00:37 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1676, average loss: 15.5178
[09/26 01:00:37 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 5.00	
[09/26 01:00:37 visual_prompt]: Training 87 / 100 epoch, with learning rate 2.9263101785268253
[09/26 01:00:44 visual_prompt]: Epoch 87 / 100: avg data time: 5.39e-02, avg batch time: 0.4986, average train loss: 13.9166
[09/26 01:00:45 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1677, average loss: 15.3074
[09/26 01:00:45 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 3.50	
[09/26 01:00:45 visual_prompt]: Training 88 / 100 epoch, with learning rate 2.5301488425208296
[09/26 01:00:52 visual_prompt]: Epoch 88 / 100: avg data time: 5.30e-02, avg batch time: 0.4980, average train loss: 13.5665
[09/26 01:00:53 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1674, average loss: 14.9371
[09/26 01:00:53 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 3.00	
[09/26 01:00:53 visual_prompt]: Training 89 / 100 epoch, with learning rate 2.1613635589349753
[09/26 01:01:00 visual_prompt]: Epoch 89 / 100: avg data time: 5.32e-02, avg batch time: 0.4956, average train loss: 13.4282
[09/26 01:01:01 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1673, average loss: 14.9319
[09/26 01:01:01 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 3.50	
[09/26 01:01:01 visual_prompt]: Training 90 / 100 epoch, with learning rate 1.820403635830317
[09/26 01:01:08 visual_prompt]: Epoch 90 / 100: avg data time: 5.08e-02, avg batch time: 0.4936, average train loss: 13.2332
[09/26 01:01:09 visual_prompt]: Inference (val):avg data time: 2.00e-05, avg batch time: 0.1672, average loss: 14.6260
[09/26 01:01:09 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 5.50	
[09/26 01:01:09 visual_prompt]: Training 91 / 100 epoch, with learning rate 1.507684480352292
[09/26 01:01:16 visual_prompt]: Epoch 91 / 100: avg data time: 4.63e-02, avg batch time: 0.4894, average train loss: 12.8676
[09/26 01:01:17 visual_prompt]: Inference (val):avg data time: 1.59e-05, avg batch time: 0.1673, average loss: 14.4847
[09/26 01:01:17 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 01:01:17 visual_prompt]: Training 92 / 100 epoch, with learning rate 1.2235870926211616
[09/26 01:01:24 visual_prompt]: Epoch 92 / 100: avg data time: 5.32e-02, avg batch time: 0.4965, average train loss: 12.6955
[09/26 01:01:25 visual_prompt]: Inference (val):avg data time: 1.90e-05, avg batch time: 0.1675, average loss: 14.4011
[09/26 01:01:25 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 3.50	
[09/26 01:01:25 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.9684576015420276
[09/26 01:01:32 visual_prompt]: Epoch 93 / 100: avg data time: 5.21e-02, avg batch time: 0.4956, average train loss: 12.5764
[09/26 01:01:33 visual_prompt]: Inference (val):avg data time: 1.70e-05, avg batch time: 0.1674, average loss: 14.5515
[09/26 01:01:34 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 5.00	
[09/26 01:01:34 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.7426068431000882
[09/26 01:01:40 visual_prompt]: Epoch 94 / 100: avg data time: 5.36e-02, avg batch time: 0.4970, average train loss: 12.6707
[09/26 01:01:42 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1676, average loss: 14.3083
[09/26 01:01:42 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.00	
[09/26 01:01:42 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.5463099816548578
[09/26 01:01:48 visual_prompt]: Epoch 95 / 100: avg data time: 3.82e-02, avg batch time: 0.4842, average train loss: 12.4504
[09/26 01:01:49 visual_prompt]: Inference (val):avg data time: 1.86e-05, avg batch time: 0.1676, average loss: 14.2508
[09/26 01:01:49 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 3.50	
[09/26 01:01:49 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.3798061746947995
[09/26 01:01:56 visual_prompt]: Epoch 96 / 100: avg data time: 4.82e-02, avg batch time: 0.4926, average train loss: 12.3635
[09/26 01:01:57 visual_prompt]: Inference (val):avg data time: 1.57e-05, avg batch time: 0.1676, average loss: 14.1125
[09/26 01:01:58 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 01:01:58 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.24329828146074095
[09/26 01:02:04 visual_prompt]: Epoch 97 / 100: avg data time: 5.20e-02, avg batch time: 0.4960, average train loss: 12.2390
[09/26 01:02:06 visual_prompt]: Inference (val):avg data time: 1.79e-05, avg batch time: 0.1673, average loss: 13.8554
[09/26 01:02:06 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 3.00	
[09/26 01:02:06 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.13695261579316775
[09/26 01:02:12 visual_prompt]: Epoch 98 / 100: avg data time: 5.09e-02, avg batch time: 0.4940, average train loss: 12.0774
[09/26 01:02:14 visual_prompt]: Inference (val):avg data time: 1.74e-05, avg batch time: 0.1672, average loss: 13.7263
[09/26 01:02:14 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 5.00	
[09/26 01:02:14 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.06089874350439506
[09/26 01:02:20 visual_prompt]: Epoch 99 / 100: avg data time: 5.15e-02, avg batch time: 0.4946, average train loss: 11.8965
[09/26 01:02:22 visual_prompt]: Inference (val):avg data time: 1.84e-05, avg batch time: 0.1675, average loss: 13.6410
[09/26 01:02:22 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 5.00	
[09/26 01:02:22 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.015229324522605947
[09/26 01:02:28 visual_prompt]: Epoch 100 / 100: avg data time: 4.24e-02, avg batch time: 0.4856, average train loss: 11.8096
[09/26 01:02:30 visual_prompt]: Inference (val):avg data time: 1.82e-05, avg batch time: 0.1672, average loss: 13.6160
[09/26 01:02:30 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 01:02:30 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 01:02:30 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              0
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 01:02:30 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-sun397', 'DATA.NUMBER_CLASSES', '397', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 01:02:30 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 01:02:30 visual_prompt]: Training with config:
[09/26 01:02:30 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-sun397/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr50.0_wd0.001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 50.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-sun397', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 397, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 01:02:30 visual_prompt]: Loading training data...
[09/26 01:02:30 visual_prompt]: Constructing vtab-sun397 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split train[:800], from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/26 01:02:31 visual_prompt]: Number of images: 800
[09/26 01:02:31 visual_prompt]: Number of classes: 309 / 397
[09/26 01:02:31 visual_prompt]: Loading validation data...
[09/26 01:02:31 visual_prompt]: Constructing vtab-sun397 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split validation[:200], from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/26 01:02:31 visual_prompt]: Number of images: 200
[09/26 01:02:31 visual_prompt]: Number of classes: 136 / 397
[09/26 01:02:31 visual_prompt]: Constructing models...
[09/26 01:02:34 visual_prompt]: Total Parameters: 86564749	 Gradient Parameters: 766093
[09/26 01:02:34 visual_prompt]: tuned percent:0.885
[09/26 01:02:34 visual_prompt]: Device used for model: 0
[09/26 01:02:34 visual_prompt]: Setting up Evaluator...
[09/26 01:02:34 visual_prompt]: Setting up Trainer...
[09/26 01:02:34 visual_prompt]: 	Setting up the optimizer...
[09/26 01:02:34 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 01:02:41 visual_prompt]: Epoch 1 / 100: avg data time: 5.47e-02, avg batch time: 0.4996, average train loss: 5.9887
[09/26 01:02:42 visual_prompt]: Inference (val):avg data time: 3.63e-05, avg batch time: 0.1672, average loss: 6.0097
[09/26 01:02:42 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/26 01:02:42 visual_prompt]: Training 2 / 100 epoch, with learning rate 5.0
[09/26 01:02:49 visual_prompt]: Epoch 2 / 100: avg data time: 4.86e-02, avg batch time: 0.4905, average train loss: 5.9070
[09/26 01:02:50 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1673, average loss: 6.2110
[09/26 01:02:50 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 4.00	
[09/26 01:02:50 visual_prompt]: Best epoch 2: best metric: 0.015
[09/26 01:02:50 visual_prompt]: Training 3 / 100 epoch, with learning rate 10.0
[09/26 01:02:57 visual_prompt]: Epoch 3 / 100: avg data time: 5.23e-02, avg batch time: 0.4954, average train loss: 6.0719
[09/26 01:02:59 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1672, average loss: 8.3849
[09/26 01:02:59 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 3.50	
[09/26 01:02:59 visual_prompt]: Training 4 / 100 epoch, with learning rate 15.0
[09/26 01:03:05 visual_prompt]: Epoch 4 / 100: avg data time: 5.29e-02, avg batch time: 0.4972, average train loss: 8.7529
[09/26 01:03:07 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1672, average loss: 10.5693
[09/26 01:03:07 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.00	
[09/26 01:03:07 visual_prompt]: Training 5 / 100 epoch, with learning rate 20.0
[09/26 01:03:13 visual_prompt]: Epoch 5 / 100: avg data time: 4.69e-02, avg batch time: 0.4912, average train loss: 14.4869
[09/26 01:03:15 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1672, average loss: 14.7706
[09/26 01:03:15 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 3.00	
[09/26 01:03:15 visual_prompt]: Training 6 / 100 epoch, with learning rate 25.0
[09/26 01:03:22 visual_prompt]: Epoch 6 / 100: avg data time: 5.06e-02, avg batch time: 0.4945, average train loss: 25.1721
[09/26 01:03:23 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1672, average loss: 24.4064
[09/26 01:03:23 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 0.50	
[09/26 01:03:23 visual_prompt]: Training 7 / 100 epoch, with learning rate 30.0
[09/26 01:03:30 visual_prompt]: Epoch 7 / 100: avg data time: 5.23e-02, avg batch time: 0.4944, average train loss: 33.3132
[09/26 01:03:31 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1673, average loss: 38.7048
[09/26 01:03:31 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 0.50	
[09/26 01:03:31 visual_prompt]: Training 8 / 100 epoch, with learning rate 35.0
[09/26 01:03:38 visual_prompt]: Epoch 8 / 100: avg data time: 5.77e-02, avg batch time: 0.5008, average train loss: 47.1969
[09/26 01:03:39 visual_prompt]: Inference (val):avg data time: 3.89e-05, avg batch time: 0.1673, average loss: 61.9590
[09/26 01:03:39 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.00	
[09/26 01:03:39 visual_prompt]: Training 9 / 100 epoch, with learning rate 40.0
[09/26 01:03:46 visual_prompt]: Epoch 9 / 100: avg data time: 4.65e-02, avg batch time: 0.4914, average train loss: 87.4405
[09/26 01:03:48 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1673, average loss: 70.7615
[09/26 01:03:48 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.50	
[09/26 01:03:48 visual_prompt]: Training 10 / 100 epoch, with learning rate 45.0
[09/26 01:03:54 visual_prompt]: Epoch 10 / 100: avg data time: 5.50e-02, avg batch time: 0.4991, average train loss: 86.6298
[09/26 01:03:56 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1674, average loss: 89.7946
[09/26 01:03:56 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.50	
[09/26 01:03:56 visual_prompt]: Training 11 / 100 epoch, with learning rate 50.0
[09/26 01:04:03 visual_prompt]: Epoch 11 / 100: avg data time: 5.61e-02, avg batch time: 0.4996, average train loss: 112.9376
[09/26 01:04:04 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1674, average loss: 114.5643
[09/26 01:04:04 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 2.50	
[09/26 01:04:04 visual_prompt]: Training 12 / 100 epoch, with learning rate 49.9847706754774
[09/26 01:04:11 visual_prompt]: Epoch 12 / 100: avg data time: 4.20e-02, avg batch time: 0.4882, average train loss: 135.4431
[09/26 01:04:12 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1674, average loss: 115.8284
[09/26 01:04:12 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.00	
[09/26 01:04:12 visual_prompt]: Training 13 / 100 epoch, with learning rate 49.939101256495604
[09/26 01:04:19 visual_prompt]: Epoch 13 / 100: avg data time: 5.44e-02, avg batch time: 0.4995, average train loss: 161.9422
[09/26 01:04:20 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1675, average loss: 130.6621
[09/26 01:04:20 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 4.00	
[09/26 01:04:20 visual_prompt]: Training 14 / 100 epoch, with learning rate 49.86304738420683
[09/26 01:04:27 visual_prompt]: Epoch 14 / 100: avg data time: 4.64e-02, avg batch time: 0.4922, average train loss: 154.0162
[09/26 01:04:28 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1671, average loss: 170.7914
[09/26 01:04:28 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 1.50	
[09/26 01:04:28 visual_prompt]: Training 15 / 100 epoch, with learning rate 49.75670171853926
[09/26 01:04:35 visual_prompt]: Epoch 15 / 100: avg data time: 4.37e-02, avg batch time: 0.4897, average train loss: 167.1528
[09/26 01:04:36 visual_prompt]: Inference (val):avg data time: 1.72e-05, avg batch time: 0.1673, average loss: 148.3876
[09/26 01:04:36 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.00	
[09/26 01:04:36 visual_prompt]: Training 16 / 100 epoch, with learning rate 49.6201938253052
[09/26 01:04:43 visual_prompt]: Epoch 16 / 100: avg data time: 4.88e-02, avg batch time: 0.4928, average train loss: 168.3421
[09/26 01:04:44 visual_prompt]: Inference (val):avg data time: 1.86e-05, avg batch time: 0.1672, average loss: 172.5221
[09/26 01:04:44 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 1.50	
[09/26 01:04:44 visual_prompt]: Training 17 / 100 epoch, with learning rate 49.45369001834514
[09/26 01:04:51 visual_prompt]: Epoch 17 / 100: avg data time: 5.26e-02, avg batch time: 0.4963, average train loss: 173.3300
[09/26 01:04:53 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1676, average loss: 175.4036
[09/26 01:04:53 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.00	
[09/26 01:04:53 visual_prompt]: Training 18 / 100 epoch, with learning rate 49.25739315689991
[09/26 01:04:59 visual_prompt]: Epoch 18 / 100: avg data time: 5.98e-02, avg batch time: 0.5039, average train loss: 171.2948
[09/26 01:05:01 visual_prompt]: Inference (val):avg data time: 1.99e-05, avg batch time: 0.1678, average loss: 151.8202
[09/26 01:05:01 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 1.00	
[09/26 01:05:01 visual_prompt]: Training 19 / 100 epoch, with learning rate 49.03154239845797
[09/26 01:05:08 visual_prompt]: Epoch 19 / 100: avg data time: 4.80e-02, avg batch time: 0.4935, average train loss: 155.2194
[09/26 01:05:09 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1676, average loss: 154.7796
[09/26 01:05:09 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 1.50	
[09/26 01:05:09 visual_prompt]: Training 20 / 100 epoch, with learning rate 48.77641290737884
[09/26 01:05:16 visual_prompt]: Epoch 20 / 100: avg data time: 5.94e-02, avg batch time: 0.5041, average train loss: 167.6582
[09/26 01:05:17 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1674, average loss: 157.3562
[09/26 01:05:17 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 0.00	
[09/26 01:05:17 visual_prompt]: Training 21 / 100 epoch, with learning rate 48.49231551964771
[09/26 01:05:24 visual_prompt]: Epoch 21 / 100: avg data time: 5.98e-02, avg batch time: 0.5041, average train loss: 160.1530
[09/26 01:05:25 visual_prompt]: Inference (val):avg data time: 1.81e-05, avg batch time: 0.1672, average loss: 211.7363
[09/26 01:05:25 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.50	top5: 3.50	
[09/26 01:05:25 visual_prompt]: Best epoch 21: best metric: 0.025
[09/26 01:05:25 visual_prompt]: Training 22 / 100 epoch, with learning rate 48.17959636416968
[09/26 01:05:32 visual_prompt]: Epoch 22 / 100: avg data time: 5.23e-02, avg batch time: 0.4960, average train loss: 189.0981
[09/26 01:05:34 visual_prompt]: Inference (val):avg data time: 1.81e-05, avg batch time: 0.1677, average loss: 184.3215
[09/26 01:05:34 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 2.00	
[09/26 01:05:34 visual_prompt]: Training 23 / 100 epoch, with learning rate 47.83863644106502
[09/26 01:05:40 visual_prompt]: Epoch 23 / 100: avg data time: 4.15e-02, avg batch time: 0.4882, average train loss: 178.4081
[09/26 01:05:42 visual_prompt]: Inference (val):avg data time: 1.87e-05, avg batch time: 0.1678, average loss: 148.1760
[09/26 01:05:42 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 2.00	
[09/26 01:05:42 visual_prompt]: Training 24 / 100 epoch, with learning rate 47.46985115747918
[09/26 01:05:48 visual_prompt]: Epoch 24 / 100: avg data time: 5.76e-02, avg batch time: 0.5019, average train loss: 182.5357
[09/26 01:05:50 visual_prompt]: Inference (val):avg data time: 2.08e-05, avg batch time: 0.1677, average loss: 654.8803
[09/26 01:05:50 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 1.50	
[09/26 01:05:50 visual_prompt]: Training 25 / 100 epoch, with learning rate 47.073689821473174
[09/26 01:05:57 visual_prompt]: Epoch 25 / 100: avg data time: 5.57e-02, avg batch time: 0.4998, average train loss: 210.1100
[09/26 01:05:58 visual_prompt]: Inference (val):avg data time: 1.72e-05, avg batch time: 0.1671, average loss: 150.9987
[09/26 01:05:58 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 1.50	
[09/26 01:05:58 visual_prompt]: Training 26 / 100 epoch, with learning rate 46.65063509461097
[09/26 01:06:05 visual_prompt]: Epoch 26 / 100: avg data time: 5.30e-02, avg batch time: 0.4980, average train loss: 161.2980
[09/26 01:06:06 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1672, average loss: 143.9641
[09/26 01:06:06 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.00	
[09/26 01:06:06 visual_prompt]: Training 27 / 100 epoch, with learning rate 46.20120240391065
[09/26 01:06:13 visual_prompt]: Epoch 27 / 100: avg data time: 4.62e-02, avg batch time: 0.4910, average train loss: 226.8899
[09/26 01:06:14 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1675, average loss: 150.3147
[09/26 01:06:14 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 3.00	
[09/26 01:06:14 visual_prompt]: Training 28 / 100 epoch, with learning rate 45.72593931387604
[09/26 01:06:21 visual_prompt]: Epoch 28 / 100: avg data time: 5.88e-02, avg batch time: 0.5030, average train loss: 180.9110
[09/26 01:06:23 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1678, average loss: 168.0721
[09/26 01:06:23 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 2.50	
[09/26 01:06:23 visual_prompt]: Training 29 / 100 epoch, with learning rate 45.22542485937369
[09/26 01:06:30 visual_prompt]: Epoch 29 / 100: avg data time: 5.90e-02, avg batch time: 0.5037, average train loss: 187.2558
[09/26 01:06:31 visual_prompt]: Inference (val):avg data time: 1.96e-05, avg batch time: 0.1674, average loss: 156.3770
[09/26 01:06:31 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 0.50	
[09/26 01:06:31 visual_prompt]: Training 30 / 100 epoch, with learning rate 44.70026884016804
[09/26 01:06:38 visual_prompt]: Epoch 30 / 100: avg data time: 5.55e-02, avg batch time: 0.4993, average train loss: 166.6643
[09/26 01:06:39 visual_prompt]: Inference (val):avg data time: 2.02e-05, avg batch time: 0.1673, average loss: 172.0810
[09/26 01:06:39 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 2.00	
[09/26 01:06:39 visual_prompt]: Training 31 / 100 epoch, with learning rate 44.15111107797445
[09/26 01:06:46 visual_prompt]: Epoch 31 / 100: avg data time: 5.41e-02, avg batch time: 0.4985, average train loss: 181.2737
[09/26 01:06:47 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1673, average loss: 161.9962
[09/26 01:06:47 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 0.00	
[09/26 01:06:47 visual_prompt]: Training 32 / 100 epoch, with learning rate 43.57862063693486
[09/26 01:06:54 visual_prompt]: Epoch 32 / 100: avg data time: 5.49e-02, avg batch time: 0.5002, average train loss: 165.5187
[09/26 01:06:56 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1673, average loss: 152.3409
[09/26 01:06:56 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.00	
[09/26 01:06:56 visual_prompt]: Training 33 / 100 epoch, with learning rate 42.98349500846628
[09/26 01:07:02 visual_prompt]: Epoch 33 / 100: avg data time: 4.28e-02, avg batch time: 0.4881, average train loss: 166.3739
[09/26 01:07:04 visual_prompt]: Inference (val):avg data time: 1.88e-05, avg batch time: 0.1673, average loss: 142.1882
[09/26 01:07:04 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.00	
[09/26 01:07:04 visual_prompt]: Training 34 / 100 epoch, with learning rate 42.36645926147493
[09/26 01:07:10 visual_prompt]: Epoch 34 / 100: avg data time: 5.11e-02, avg batch time: 0.4947, average train loss: 172.5754
[09/26 01:07:12 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1671, average loss: 150.1232
[09/26 01:07:12 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 0.50	
[09/26 01:07:12 visual_prompt]: Training 35 / 100 epoch, with learning rate 41.72826515897145
[09/26 01:07:19 visual_prompt]: Epoch 35 / 100: avg data time: 5.39e-02, avg batch time: 0.4985, average train loss: 168.8399
[09/26 01:07:20 visual_prompt]: Inference (val):avg data time: 1.88e-05, avg batch time: 0.1679, average loss: 152.9971
[09/26 01:07:20 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 1.00	
[09/26 01:07:20 visual_prompt]: Training 36 / 100 epoch, with learning rate 41.06969024216348
[09/26 01:07:27 visual_prompt]: Epoch 36 / 100: avg data time: 4.69e-02, avg batch time: 0.4923, average train loss: 170.4063
[09/26 01:07:28 visual_prompt]: Inference (val):avg data time: 2.00e-05, avg batch time: 0.1675, average loss: 147.5453
[09/26 01:07:28 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 1.50	
[09/26 01:07:28 visual_prompt]: Training 37 / 100 epoch, with learning rate 40.391536883141455
[09/26 01:07:35 visual_prompt]: Epoch 37 / 100: avg data time: 4.93e-02, avg batch time: 0.4930, average train loss: 163.2659
[09/26 01:07:36 visual_prompt]: Inference (val):avg data time: 1.83e-05, avg batch time: 0.1675, average loss: 154.6002
[09/26 01:07:36 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 1.00	
[09/26 01:07:36 visual_prompt]: Training 38 / 100 epoch, with learning rate 39.69463130731183
[09/26 01:07:43 visual_prompt]: Epoch 38 / 100: avg data time: 5.31e-02, avg batch time: 0.4976, average train loss: 155.3693
[09/26 01:07:45 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1675, average loss: 154.7955
[09/26 01:07:45 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 2.00	
[09/26 01:07:45 visual_prompt]: Training 39 / 100 epoch, with learning rate 38.97982258676867
[09/26 01:07:51 visual_prompt]: Epoch 39 / 100: avg data time: 4.08e-02, avg batch time: 0.4840, average train loss: 156.2345
[09/26 01:07:53 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1676, average loss: 134.0669
[09/26 01:07:53 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.50	
[09/26 01:07:53 visual_prompt]: Training 40 / 100 epoch, with learning rate 38.24798160583012
[09/26 01:07:59 visual_prompt]: Epoch 40 / 100: avg data time: 5.22e-02, avg batch time: 0.4986, average train loss: 139.5002
[09/26 01:08:01 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1674, average loss: 144.3343
[09/26 01:08:01 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 3.00	
[09/26 01:08:01 visual_prompt]: Training 41 / 100 epoch, with learning rate 37.5
[09/26 01:08:08 visual_prompt]: Epoch 41 / 100: avg data time: 5.93e-02, avg batch time: 0.5048, average train loss: 134.5145
[09/26 01:08:09 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1671, average loss: 150.6780
[09/26 01:08:09 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 2.00	
[09/26 01:08:09 visual_prompt]: Training 42 / 100 epoch, with learning rate 36.736789069647266
[09/26 01:08:16 visual_prompt]: Epoch 42 / 100: avg data time: 5.40e-02, avg batch time: 0.4979, average train loss: 126.2188
[09/26 01:08:17 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1676, average loss: 130.7378
[09/26 01:08:17 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 0.50	
[09/26 01:08:17 visual_prompt]: Training 43 / 100 epoch, with learning rate 35.959278669726935
[09/26 01:08:24 visual_prompt]: Epoch 43 / 100: avg data time: 5.96e-02, avg batch time: 0.5022, average train loss: 140.1905
[09/26 01:08:26 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1671, average loss: 140.7101
[09/26 01:08:26 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 1.00	
[09/26 01:08:26 visual_prompt]: Training 44 / 100 epoch, with learning rate 35.16841607689501
[09/26 01:08:32 visual_prompt]: Epoch 44 / 100: avg data time: 5.30e-02, avg batch time: 0.4968, average train loss: 126.5086
[09/26 01:08:34 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1674, average loss: 146.3874
[09/26 01:08:34 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 2.00	
[09/26 01:08:34 visual_prompt]: Training 45 / 100 epoch, with learning rate 34.365164835397806
[09/26 01:08:40 visual_prompt]: Epoch 45 / 100: avg data time: 4.23e-02, avg batch time: 0.4877, average train loss: 137.7520
[09/26 01:08:42 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1668, average loss: 135.1841
[09/26 01:08:42 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 0.00	
[09/26 01:08:42 visual_prompt]: Training 46 / 100 epoch, with learning rate 33.55050358314172
[09/26 01:08:49 visual_prompt]: Epoch 46 / 100: avg data time: 5.53e-02, avg batch time: 0.4994, average train loss: 137.0882
[09/26 01:08:50 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1674, average loss: 131.7349
[09/26 01:08:50 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 2.50	
[09/26 01:08:50 visual_prompt]: Training 47 / 100 epoch, with learning rate 32.72542485937369
[09/26 01:08:57 visual_prompt]: Epoch 47 / 100: avg data time: 5.44e-02, avg batch time: 0.4973, average train loss: 119.2206
[09/26 01:08:58 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1675, average loss: 115.3553
[09/26 01:08:58 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.00	top5: 5.50	
[09/26 01:08:58 visual_prompt]: Training 48 / 100 epoch, with learning rate 31.89093389542498
[09/26 01:09:05 visual_prompt]: Epoch 48 / 100: avg data time: 5.20e-02, avg batch time: 0.4954, average train loss: 117.9606
[09/26 01:09:06 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.1674, average loss: 150.3694
[09/26 01:09:07 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 2.00	
[09/26 01:09:07 visual_prompt]: Training 49 / 100 epoch, with learning rate 31.04804738999169
[09/26 01:09:13 visual_prompt]: Epoch 49 / 100: avg data time: 5.18e-02, avg batch time: 0.4949, average train loss: 110.9173
[09/26 01:09:15 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1674, average loss: 117.0071
[09/26 01:09:15 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 0.00	
[09/26 01:09:15 visual_prompt]: Training 50 / 100 epoch, with learning rate 30.19779227044398
[09/26 01:09:21 visual_prompt]: Epoch 50 / 100: avg data time: 5.07e-02, avg batch time: 0.4943, average train loss: 113.1261
[09/26 01:09:23 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1674, average loss: 115.3064
[09/26 01:09:23 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 1.00	
[09/26 01:09:23 visual_prompt]: Training 51 / 100 epoch, with learning rate 29.341204441673263
[09/26 01:09:30 visual_prompt]: Epoch 51 / 100: avg data time: 5.30e-02, avg batch time: 0.4959, average train loss: 120.8330
[09/26 01:09:31 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1676, average loss: 107.2697
[09/26 01:09:31 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 0.50	
[09/26 01:09:31 visual_prompt]: Training 52 / 100 epoch, with learning rate 28.479327524001636
[09/26 01:09:38 visual_prompt]: Epoch 52 / 100: avg data time: 5.19e-02, avg batch time: 0.4955, average train loss: 100.5526
[09/26 01:09:39 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1672, average loss: 86.2779
[09/26 01:09:39 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.50	
[09/26 01:09:39 visual_prompt]: Training 53 / 100 epoch, with learning rate 27.61321158169134
[09/26 01:09:46 visual_prompt]: Epoch 53 / 100: avg data time: 4.57e-02, avg batch time: 0.4893, average train loss: 87.4179
[09/26 01:09:47 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1672, average loss: 90.6448
[09/26 01:09:47 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 0.00	
[09/26 01:09:47 visual_prompt]: Training 54 / 100 epoch, with learning rate 26.74391184360313
[09/26 01:09:54 visual_prompt]: Epoch 54 / 100: avg data time: 5.16e-02, avg batch time: 0.4950, average train loss: 99.1788
[09/26 01:09:55 visual_prompt]: Inference (val):avg data time: 3.65e-05, avg batch time: 0.1673, average loss: 98.4841
[09/26 01:09:55 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.50	
[09/26 01:09:55 visual_prompt]: Training 55 / 100 epoch, with learning rate 25.872487417562528
[09/26 01:10:02 visual_prompt]: Epoch 55 / 100: avg data time: 4.72e-02, avg batch time: 0.4914, average train loss: 94.2097
[09/26 01:10:04 visual_prompt]: Inference (val):avg data time: 1.88e-05, avg batch time: 0.1673, average loss: 84.7163
[09/26 01:10:04 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 2.00	
[09/26 01:10:04 visual_prompt]: Training 56 / 100 epoch, with learning rate 25.0
[09/26 01:10:10 visual_prompt]: Epoch 56 / 100: avg data time: 5.58e-02, avg batch time: 0.5005, average train loss: 85.5458
[09/26 01:10:12 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1674, average loss: 86.1173
[09/26 01:10:12 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.50	
[09/26 01:10:12 visual_prompt]: Training 57 / 100 epoch, with learning rate 24.127512582437483
[09/26 01:10:19 visual_prompt]: Epoch 57 / 100: avg data time: 5.12e-02, avg batch time: 0.4960, average train loss: 82.6633
[09/26 01:10:20 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1679, average loss: 78.7021
[09/26 01:10:20 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.50	
[09/26 01:10:20 visual_prompt]: Training 58 / 100 epoch, with learning rate 23.256088156396867
[09/26 01:10:27 visual_prompt]: Epoch 58 / 100: avg data time: 4.83e-02, avg batch time: 0.4916, average train loss: 77.1139
[09/26 01:10:28 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1673, average loss: 81.4053
[09/26 01:10:28 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 2.50	
[09/26 01:10:28 visual_prompt]: Training 59 / 100 epoch, with learning rate 22.38678841830867
[09/26 01:10:35 visual_prompt]: Epoch 59 / 100: avg data time: 5.73e-02, avg batch time: 0.5013, average train loss: 84.7713
[09/26 01:10:36 visual_prompt]: Inference (val):avg data time: 4.14e-05, avg batch time: 0.1678, average loss: 66.1990
[09/26 01:10:37 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/26 01:10:37 visual_prompt]: Training 60 / 100 epoch, with learning rate 21.52067247599837
[09/26 01:10:43 visual_prompt]: Epoch 60 / 100: avg data time: 5.14e-02, avg batch time: 0.4948, average train loss: 75.2020
[09/26 01:10:45 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1672, average loss: 64.3338
[09/26 01:10:45 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.00	
[09/26 01:10:45 visual_prompt]: Training 61 / 100 epoch, with learning rate 20.65879555832674
[09/26 01:10:51 visual_prompt]: Epoch 61 / 100: avg data time: 4.73e-02, avg batch time: 0.4922, average train loss: 71.0366
[09/26 01:10:53 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1677, average loss: 56.9830
[09/26 01:10:53 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 1.00	
[09/26 01:10:53 visual_prompt]: Training 62 / 100 epoch, with learning rate 19.80220772955602
[09/26 01:11:00 visual_prompt]: Epoch 62 / 100: avg data time: 5.27e-02, avg batch time: 0.4959, average train loss: 68.6663
[09/26 01:11:01 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1678, average loss: 62.1530
[09/26 01:11:01 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 1.00	
[09/26 01:11:01 visual_prompt]: Training 63 / 100 epoch, with learning rate 18.95195261000831
[09/26 01:11:08 visual_prompt]: Epoch 63 / 100: avg data time: 5.80e-02, avg batch time: 0.5020, average train loss: 64.9649
[09/26 01:11:09 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1676, average loss: 60.8417
[09/26 01:11:09 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.50	
[09/26 01:11:09 visual_prompt]: Training 64 / 100 epoch, with learning rate 18.10906610457502
[09/26 01:11:16 visual_prompt]: Epoch 64 / 100: avg data time: 4.34e-02, avg batch time: 0.4895, average train loss: 60.0581
[09/26 01:11:17 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1674, average loss: 52.7720
[09/26 01:11:17 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 3.00	
[09/26 01:11:17 visual_prompt]: Training 65 / 100 epoch, with learning rate 17.274575140626318
[09/26 01:11:24 visual_prompt]: Epoch 65 / 100: avg data time: 5.58e-02, avg batch time: 0.4998, average train loss: 55.7417
[09/26 01:11:26 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1673, average loss: 47.3478
[09/26 01:11:26 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/26 01:11:26 visual_prompt]: Training 66 / 100 epoch, with learning rate 16.449496416858285
[09/26 01:11:32 visual_prompt]: Epoch 66 / 100: avg data time: 5.12e-02, avg batch time: 0.4955, average train loss: 48.7421
[09/26 01:11:34 visual_prompt]: Inference (val):avg data time: 5.23e-05, avg batch time: 0.1675, average loss: 43.8594
[09/26 01:11:34 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 0.00	
[09/26 01:11:34 visual_prompt]: Training 67 / 100 epoch, with learning rate 15.634835164602197
[09/26 01:11:40 visual_prompt]: Epoch 67 / 100: avg data time: 5.61e-02, avg batch time: 0.5000, average train loss: 50.4695
[09/26 01:11:42 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1673, average loss: 42.1809
[09/26 01:11:42 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 2.50	
[09/26 01:11:42 visual_prompt]: Training 68 / 100 epoch, with learning rate 14.831583923104999
[09/26 01:11:49 visual_prompt]: Epoch 68 / 100: avg data time: 4.81e-02, avg batch time: 0.4917, average train loss: 58.4683
[09/26 01:11:50 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1672, average loss: 51.6581
[09/26 01:11:50 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 0.50	
[09/26 01:11:50 visual_prompt]: Training 69 / 100 epoch, with learning rate 14.040721330273062
[09/26 01:11:57 visual_prompt]: Epoch 69 / 100: avg data time: 5.58e-02, avg batch time: 0.4982, average train loss: 57.2583
[09/26 01:11:58 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1674, average loss: 45.1919
[09/26 01:11:58 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.00	top5: 2.00	
[09/26 01:11:58 visual_prompt]: Training 70 / 100 epoch, with learning rate 13.263210930352736
[09/26 01:12:05 visual_prompt]: Epoch 70 / 100: avg data time: 5.60e-02, avg batch time: 0.4993, average train loss: 50.5078
[09/26 01:12:06 visual_prompt]: Inference (val):avg data time: 3.99e-05, avg batch time: 0.1671, average loss: 39.3604
[09/26 01:12:07 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 2.00	
[09/26 01:12:07 visual_prompt]: Training 71 / 100 epoch, with learning rate 12.500000000000005
[09/26 01:12:13 visual_prompt]: Epoch 71 / 100: avg data time: 5.78e-02, avg batch time: 0.5020, average train loss: 45.2745
[09/26 01:12:15 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1671, average loss: 40.0125
[09/26 01:12:15 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 2.50	
[09/26 01:12:15 visual_prompt]: Training 72 / 100 epoch, with learning rate 11.75201839416988
[09/26 01:12:22 visual_prompt]: Epoch 72 / 100: avg data time: 5.55e-02, avg batch time: 0.4996, average train loss: 42.2376
[09/26 01:12:23 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1677, average loss: 36.6507
[09/26 01:12:23 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 1.50	
[09/26 01:12:23 visual_prompt]: Training 73 / 100 epoch, with learning rate 11.020177413231332
[09/26 01:12:30 visual_prompt]: Epoch 73 / 100: avg data time: 4.52e-02, avg batch time: 0.4880, average train loss: 34.2261
[09/26 01:12:31 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1675, average loss: 31.5057
[09/26 01:12:31 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 2.00	
[09/26 01:12:31 visual_prompt]: Training 74 / 100 epoch, with learning rate 10.305368692688175
[09/26 01:12:38 visual_prompt]: Epoch 74 / 100: avg data time: 4.56e-02, avg batch time: 0.4901, average train loss: 33.6513
[09/26 01:12:39 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1676, average loss: 34.4133
[09/26 01:12:39 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 2.50	
[09/26 01:12:39 visual_prompt]: Training 75 / 100 epoch, with learning rate 9.608463116858543
[09/26 01:12:46 visual_prompt]: Epoch 75 / 100: avg data time: 5.57e-02, avg batch time: 0.4998, average train loss: 36.0659
[09/26 01:12:47 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1674, average loss: 27.3722
[09/26 01:12:47 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 3.00	
[09/26 01:12:47 visual_prompt]: Training 76 / 100 epoch, with learning rate 8.930309757836516
[09/26 01:12:54 visual_prompt]: Epoch 76 / 100: avg data time: 5.62e-02, avg batch time: 0.4997, average train loss: 28.1933
[09/26 01:12:56 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1673, average loss: 22.9352
[09/26 01:12:56 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 1.00	
[09/26 01:12:56 visual_prompt]: Training 77 / 100 epoch, with learning rate 8.271734841028552
[09/26 01:13:02 visual_prompt]: Epoch 77 / 100: avg data time: 4.35e-02, avg batch time: 0.4867, average train loss: 25.3599
[09/26 01:13:04 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.1674, average loss: 27.0798
[09/26 01:13:04 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.00	
[09/26 01:13:04 visual_prompt]: Training 78 / 100 epoch, with learning rate 7.633540738525066
[09/26 01:13:10 visual_prompt]: Epoch 78 / 100: avg data time: 5.21e-02, avg batch time: 0.4958, average train loss: 29.1965
[09/26 01:13:12 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1671, average loss: 23.7771
[09/26 01:13:12 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.00	
[09/26 01:13:12 visual_prompt]: Training 79 / 100 epoch, with learning rate 7.016504991533726
[09/26 01:13:19 visual_prompt]: Epoch 79 / 100: avg data time: 6.05e-02, avg batch time: 0.5052, average train loss: 24.2646
[09/26 01:13:20 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1674, average loss: 20.8153
[09/26 01:13:20 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 2.50	
[09/26 01:13:20 visual_prompt]: Training 80 / 100 epoch, with learning rate 6.4213793630651415
[09/26 01:13:27 visual_prompt]: Epoch 80 / 100: avg data time: 4.66e-02, avg batch time: 0.4902, average train loss: 23.3707
[09/26 01:13:28 visual_prompt]: Inference (val):avg data time: 1.98e-05, avg batch time: 0.1672, average loss: 18.9383
[09/26 01:13:28 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.00	top5: 3.50	
[09/26 01:13:28 visual_prompt]: Training 81 / 100 epoch, with learning rate 5.848888922025552
[09/26 01:13:35 visual_prompt]: Epoch 81 / 100: avg data time: 5.45e-02, avg batch time: 0.4974, average train loss: 20.7488
[09/26 01:13:36 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.1673, average loss: 17.9812
[09/26 01:13:36 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 3.50	
[09/26 01:13:36 visual_prompt]: Training 82 / 100 epoch, with learning rate 5.2997311598319525
[09/26 01:13:43 visual_prompt]: Epoch 82 / 100: avg data time: 4.17e-02, avg batch time: 0.4855, average train loss: 20.1762
[09/26 01:13:45 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1673, average loss: 16.3791
[09/26 01:13:45 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.00	top5: 6.00	
[09/26 01:13:45 visual_prompt]: Training 83 / 100 epoch, with learning rate 4.774575140626316
[09/26 01:13:51 visual_prompt]: Epoch 83 / 100: avg data time: 5.45e-02, avg batch time: 0.4969, average train loss: 18.4513
[09/26 01:13:53 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1674, average loss: 17.0696
[09/26 01:13:53 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 3.50	
[09/26 01:13:53 visual_prompt]: Training 84 / 100 epoch, with learning rate 4.27406068612396
[09/26 01:14:00 visual_prompt]: Epoch 84 / 100: avg data time: 5.49e-02, avg batch time: 0.5010, average train loss: 19.5840
[09/26 01:14:01 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1677, average loss: 16.6277
[09/26 01:14:01 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 3.00	
[09/26 01:14:01 visual_prompt]: Training 85 / 100 epoch, with learning rate 3.798797596089351
[09/26 01:14:08 visual_prompt]: Epoch 85 / 100: avg data time: 5.57e-02, avg batch time: 0.4987, average train loss: 17.0362
[09/26 01:14:09 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1672, average loss: 14.5550
[09/26 01:14:09 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 3.50	
[09/26 01:14:09 visual_prompt]: Training 86 / 100 epoch, with learning rate 3.349364905389032
[09/26 01:14:16 visual_prompt]: Epoch 86 / 100: avg data time: 5.70e-02, avg batch time: 0.4991, average train loss: 15.7699
[09/26 01:14:17 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1676, average loss: 14.4801
[09/26 01:14:17 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.00	
[09/26 01:14:17 visual_prompt]: Training 87 / 100 epoch, with learning rate 2.9263101785268253
[09/26 01:14:24 visual_prompt]: Epoch 87 / 100: avg data time: 5.61e-02, avg batch time: 0.4984, average train loss: 17.1263
[09/26 01:14:26 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1676, average loss: 15.4603
[09/26 01:14:26 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 3.50	
[09/26 01:14:26 visual_prompt]: Training 88 / 100 epoch, with learning rate 2.5301488425208296
[09/26 01:14:32 visual_prompt]: Epoch 88 / 100: avg data time: 5.53e-02, avg batch time: 0.4994, average train loss: 16.9408
[09/26 01:14:34 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1673, average loss: 15.1120
[09/26 01:14:34 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 2.50	
[09/26 01:14:34 visual_prompt]: Training 89 / 100 epoch, with learning rate 2.1613635589349753
[09/26 01:14:41 visual_prompt]: Epoch 89 / 100: avg data time: 5.86e-02, avg batch time: 0.5022, average train loss: 16.5650
[09/26 01:14:42 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1674, average loss: 14.0021
[09/26 01:14:42 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 5.50	
[09/26 01:14:42 visual_prompt]: Training 90 / 100 epoch, with learning rate 1.820403635830317
[09/26 01:14:49 visual_prompt]: Epoch 90 / 100: avg data time: 5.50e-02, avg batch time: 0.4984, average train loss: 14.7154
[09/26 01:14:50 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1674, average loss: 13.2908
[09/26 01:14:50 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.50	
[09/26 01:14:50 visual_prompt]: Training 91 / 100 epoch, with learning rate 1.507684480352292
[09/26 01:14:57 visual_prompt]: Epoch 91 / 100: avg data time: 6.12e-02, avg batch time: 0.5042, average train loss: 14.7046
[09/26 01:14:59 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1675, average loss: 13.6551
[09/26 01:14:59 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/26 01:14:59 visual_prompt]: Training 92 / 100 epoch, with learning rate 1.2235870926211616
[09/26 01:15:05 visual_prompt]: Epoch 92 / 100: avg data time: 5.89e-02, avg batch time: 0.5018, average train loss: 14.6978
[09/26 01:15:07 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1674, average loss: 13.0260
[09/26 01:15:07 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 2.00	
[09/26 01:15:07 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.9684576015420276
[09/26 01:15:14 visual_prompt]: Epoch 93 / 100: avg data time: 5.12e-02, avg batch time: 0.4946, average train loss: 13.7466
[09/26 01:15:15 visual_prompt]: Inference (val):avg data time: 1.97e-05, avg batch time: 0.1672, average loss: 12.3959
[09/26 01:15:15 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 5.00	
[09/26 01:15:15 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.7426068431000882
[09/26 01:15:22 visual_prompt]: Epoch 94 / 100: avg data time: 5.64e-02, avg batch time: 0.4999, average train loss: 12.7342
[09/26 01:15:23 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1676, average loss: 12.1274
[09/26 01:15:23 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 3.00	
[09/26 01:15:23 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.5463099816548578
[09/26 01:15:30 visual_prompt]: Epoch 95 / 100: avg data time: 5.03e-02, avg batch time: 0.4941, average train loss: 12.0623
[09/26 01:15:31 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1676, average loss: 12.1691
[09/26 01:15:31 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.50	
[09/26 01:15:31 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.3798061746947995
[09/26 01:15:38 visual_prompt]: Epoch 96 / 100: avg data time: 5.04e-02, avg batch time: 0.4937, average train loss: 11.5266
[09/26 01:15:39 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1671, average loss: 11.7260
[09/26 01:15:39 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 6.50	
[09/26 01:15:39 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.24329828146074095
[09/26 01:15:46 visual_prompt]: Epoch 97 / 100: avg data time: 5.33e-02, avg batch time: 0.4962, average train loss: 10.7200
[09/26 01:15:48 visual_prompt]: Inference (val):avg data time: 2.01e-05, avg batch time: 0.1672, average loss: 11.5725
[09/26 01:15:48 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.50	
[09/26 01:15:48 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.13695261579316775
[09/26 01:15:54 visual_prompt]: Epoch 98 / 100: avg data time: 5.81e-02, avg batch time: 0.5009, average train loss: 10.3455
[09/26 01:15:56 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.1671, average loss: 11.4543
[09/26 01:15:56 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 5.50	
[09/26 01:15:56 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.06089874350439506
[09/26 01:16:03 visual_prompt]: Epoch 99 / 100: avg data time: 3.85e-02, avg batch time: 0.4840, average train loss: 10.0930
[09/26 01:16:04 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1670, average loss: 11.4080
[09/26 01:16:04 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 5.50	
[09/26 01:16:04 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.015229324522605947
[09/26 01:16:11 visual_prompt]: Epoch 100 / 100: avg data time: 5.78e-02, avg batch time: 0.5005, average train loss: 9.9870
[09/26 01:16:12 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1674, average loss: 11.4004
[09/26 01:16:12 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 5.50	
[09/26 01:16:12 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 01:16:12 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              0
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 01:16:12 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-sun397', 'DATA.NUMBER_CLASSES', '397', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 01:16:12 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 01:16:12 visual_prompt]: Training with config:
[09/26 01:16:12 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-sun397/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr50.0_wd0.0001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 50.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-sun397', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 397, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 01:16:12 visual_prompt]: Loading training data...
[09/26 01:16:12 visual_prompt]: Constructing vtab-sun397 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split train[:800], from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/26 01:16:14 visual_prompt]: Number of images: 800
[09/26 01:16:14 visual_prompt]: Number of classes: 309 / 397
[09/26 01:16:14 visual_prompt]: Loading validation data...
[09/26 01:16:14 visual_prompt]: Constructing vtab-sun397 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split validation[:200], from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/26 01:16:14 visual_prompt]: Number of images: 200
[09/26 01:16:14 visual_prompt]: Number of classes: 136 / 397
[09/26 01:16:14 visual_prompt]: Constructing models...
[09/26 01:16:16 visual_prompt]: Total Parameters: 86564749	 Gradient Parameters: 766093
[09/26 01:16:16 visual_prompt]: tuned percent:0.885
[09/26 01:16:17 visual_prompt]: Device used for model: 0
[09/26 01:16:17 visual_prompt]: Setting up Evaluator...
[09/26 01:16:17 visual_prompt]: Setting up Trainer...
[09/26 01:16:17 visual_prompt]: 	Setting up the optimizer...
[09/26 01:16:17 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 01:16:23 visual_prompt]: Epoch 1 / 100: avg data time: 5.99e-02, avg batch time: 0.5032, average train loss: 5.9878
[09/26 01:16:25 visual_prompt]: Inference (val):avg data time: 4.56e-05, avg batch time: 0.1676, average loss: 6.0097
[09/26 01:16:25 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/26 01:16:25 visual_prompt]: Training 2 / 100 epoch, with learning rate 5.0
[09/26 01:16:32 visual_prompt]: Epoch 2 / 100: avg data time: 5.39e-02, avg batch time: 0.4974, average train loss: 5.9592
[09/26 01:16:33 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1675, average loss: 6.6149
[09/26 01:16:33 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 2.50	
[09/26 01:16:33 visual_prompt]: Best epoch 2: best metric: 0.010
[09/26 01:16:33 visual_prompt]: Training 3 / 100 epoch, with learning rate 10.0
[09/26 01:16:40 visual_prompt]: Epoch 3 / 100: avg data time: 5.26e-02, avg batch time: 0.4957, average train loss: 6.7718
[09/26 01:16:41 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1671, average loss: 7.2161
[09/26 01:16:41 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 3.00	
[09/26 01:16:41 visual_prompt]: Training 4 / 100 epoch, with learning rate 15.0
[09/26 01:16:48 visual_prompt]: Epoch 4 / 100: avg data time: 5.04e-02, avg batch time: 0.4951, average train loss: 9.0671
[09/26 01:16:49 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1675, average loss: 8.8863
[09/26 01:16:49 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.50	
[09/26 01:16:49 visual_prompt]: Training 5 / 100 epoch, with learning rate 20.0
[09/26 01:16:56 visual_prompt]: Epoch 5 / 100: avg data time: 5.29e-02, avg batch time: 0.4949, average train loss: 16.2518
[09/26 01:16:58 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1675, average loss: 24.0071
[09/26 01:16:58 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 3.00	
[09/26 01:16:58 visual_prompt]: Training 6 / 100 epoch, with learning rate 25.0
[09/26 01:17:04 visual_prompt]: Epoch 6 / 100: avg data time: 3.85e-02, avg batch time: 0.4836, average train loss: 58.8450
[09/26 01:17:06 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1673, average loss: 40.2787
[09/26 01:17:06 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 1.50	
[09/26 01:17:06 visual_prompt]: Training 7 / 100 epoch, with learning rate 30.0
[09/26 01:17:12 visual_prompt]: Epoch 7 / 100: avg data time: 4.32e-02, avg batch time: 0.4879, average train loss: 65.7522
[09/26 01:17:14 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1673, average loss: 111.7975
[09/26 01:17:14 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 1.50	
[09/26 01:17:14 visual_prompt]: Training 8 / 100 epoch, with learning rate 35.0
[09/26 01:17:20 visual_prompt]: Epoch 8 / 100: avg data time: 5.07e-02, avg batch time: 0.4938, average train loss: 119.4439
[09/26 01:17:22 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.1674, average loss: 78.4674
[09/26 01:17:22 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.00	
[09/26 01:17:22 visual_prompt]: Training 9 / 100 epoch, with learning rate 40.0
[09/26 01:17:29 visual_prompt]: Epoch 9 / 100: avg data time: 4.79e-02, avg batch time: 0.4906, average train loss: 178.7741
[09/26 01:17:30 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1673, average loss: 105.2435
[09/26 01:17:30 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 1.50	
[09/26 01:17:30 visual_prompt]: Training 10 / 100 epoch, with learning rate 45.0
[09/26 01:17:37 visual_prompt]: Epoch 10 / 100: avg data time: 5.78e-02, avg batch time: 0.5001, average train loss: 154.2648
[09/26 01:17:38 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1675, average loss: 173.5730
[09/26 01:17:38 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 3.00	
[09/26 01:17:38 visual_prompt]: Training 11 / 100 epoch, with learning rate 50.0
[09/26 01:17:45 visual_prompt]: Epoch 11 / 100: avg data time: 5.11e-02, avg batch time: 0.4947, average train loss: 209.0369
[09/26 01:17:47 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.1675, average loss: 175.2991
[09/26 01:17:47 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 2.50	
[09/26 01:17:47 visual_prompt]: Training 12 / 100 epoch, with learning rate 49.9847706754774
[09/26 01:17:53 visual_prompt]: Epoch 12 / 100: avg data time: 5.86e-02, avg batch time: 0.5014, average train loss: 280.1731
[09/26 01:17:55 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1676, average loss: 166.2329
[09/26 01:17:55 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 1.50	
[09/26 01:17:55 visual_prompt]: Training 13 / 100 epoch, with learning rate 49.939101256495604
[09/26 01:18:01 visual_prompt]: Epoch 13 / 100: avg data time: 4.74e-02, avg batch time: 0.4900, average train loss: 180.4360
[09/26 01:18:03 visual_prompt]: Inference (val):avg data time: 1.93e-05, avg batch time: 0.1673, average loss: 200.7223
[09/26 01:18:03 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.00	
[09/26 01:18:03 visual_prompt]: Training 14 / 100 epoch, with learning rate 49.86304738420683
[09/26 01:18:10 visual_prompt]: Epoch 14 / 100: avg data time: 4.93e-02, avg batch time: 0.4936, average train loss: 200.7508
[09/26 01:18:11 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1679, average loss: 164.6315
[09/26 01:18:11 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 0.50	
[09/26 01:18:11 visual_prompt]: Training 15 / 100 epoch, with learning rate 49.75670171853926
[09/26 01:18:18 visual_prompt]: Epoch 15 / 100: avg data time: 4.76e-02, avg batch time: 0.4921, average train loss: 167.1052
[09/26 01:18:19 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1672, average loss: 151.1400
[09/26 01:18:19 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 1.00	
[09/26 01:18:19 visual_prompt]: Training 16 / 100 epoch, with learning rate 49.6201938253052
[09/26 01:18:26 visual_prompt]: Epoch 16 / 100: avg data time: 5.32e-02, avg batch time: 0.4992, average train loss: 176.3132
[09/26 01:18:27 visual_prompt]: Inference (val):avg data time: 1.82e-05, avg batch time: 0.1672, average loss: 274.2079
[09/26 01:18:27 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 3.50	
[09/26 01:18:27 visual_prompt]: Training 17 / 100 epoch, with learning rate 49.45369001834514
[09/26 01:18:34 visual_prompt]: Epoch 17 / 100: avg data time: 4.64e-02, avg batch time: 0.4900, average train loss: 214.2206
[09/26 01:18:36 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1676, average loss: 189.7156
[09/26 01:18:36 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 2.00	
[09/26 01:18:36 visual_prompt]: Training 18 / 100 epoch, with learning rate 49.25739315689991
[09/26 01:18:42 visual_prompt]: Epoch 18 / 100: avg data time: 5.47e-02, avg batch time: 0.4979, average train loss: 201.0234
[09/26 01:18:44 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1673, average loss: 175.5506
[09/26 01:18:44 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 3.00	
[09/26 01:18:44 visual_prompt]: Training 19 / 100 epoch, with learning rate 49.03154239845797
[09/26 01:18:50 visual_prompt]: Epoch 19 / 100: avg data time: 5.31e-02, avg batch time: 0.4975, average train loss: 200.9443
[09/26 01:18:52 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1671, average loss: 179.1594
[09/26 01:18:52 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 0.50	
[09/26 01:18:52 visual_prompt]: Training 20 / 100 epoch, with learning rate 48.77641290737884
[09/26 01:18:59 visual_prompt]: Epoch 20 / 100: avg data time: 5.80e-02, avg batch time: 0.5013, average train loss: 205.0376
[09/26 01:19:00 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1674, average loss: 168.4932
[09/26 01:19:00 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 0.50	
[09/26 01:19:00 visual_prompt]: Training 21 / 100 epoch, with learning rate 48.49231551964771
[09/26 01:19:07 visual_prompt]: Epoch 21 / 100: avg data time: 5.23e-02, avg batch time: 0.4953, average train loss: 200.3809
[09/26 01:19:08 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1678, average loss: 190.7016
[09/26 01:19:08 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 3.50	
[09/26 01:19:08 visual_prompt]: Training 22 / 100 epoch, with learning rate 48.17959636416968
[09/26 01:19:15 visual_prompt]: Epoch 22 / 100: avg data time: 5.14e-02, avg batch time: 0.4959, average train loss: 202.5634
[09/26 01:19:17 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1674, average loss: 169.9225
[09/26 01:19:17 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 0.50	
[09/26 01:19:17 visual_prompt]: Training 23 / 100 epoch, with learning rate 47.83863644106502
[09/26 01:19:23 visual_prompt]: Epoch 23 / 100: avg data time: 4.25e-02, avg batch time: 0.4880, average train loss: 211.4500
[09/26 01:19:25 visual_prompt]: Inference (val):avg data time: 1.97e-05, avg batch time: 0.1675, average loss: 166.8861
[09/26 01:19:25 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 0.50	
[09/26 01:19:25 visual_prompt]: Training 24 / 100 epoch, with learning rate 47.46985115747918
[09/26 01:19:31 visual_prompt]: Epoch 24 / 100: avg data time: 4.73e-02, avg batch time: 0.4902, average train loss: 169.9037
[09/26 01:19:33 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1673, average loss: 149.3868
[09/26 01:19:33 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 1.50	
[09/26 01:19:33 visual_prompt]: Training 25 / 100 epoch, with learning rate 47.073689821473174
[09/26 01:19:39 visual_prompt]: Epoch 25 / 100: avg data time: 5.40e-02, avg batch time: 0.4981, average train loss: 191.8551
[09/26 01:19:41 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1676, average loss: 172.1196
[09/26 01:19:41 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.50	
[09/26 01:19:41 visual_prompt]: Training 26 / 100 epoch, with learning rate 46.65063509461097
[09/26 01:19:48 visual_prompt]: Epoch 26 / 100: avg data time: 5.66e-02, avg batch time: 0.4990, average train loss: 193.5340
[09/26 01:19:49 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1676, average loss: 144.2993
[09/26 01:19:49 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 0.00	
[09/26 01:19:49 visual_prompt]: Training 27 / 100 epoch, with learning rate 46.20120240391065
[09/26 01:19:56 visual_prompt]: Epoch 27 / 100: avg data time: 4.31e-02, avg batch time: 0.4880, average train loss: 178.3887
[09/26 01:19:57 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.1678, average loss: 174.1660
[09/26 01:19:57 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 0.00	
[09/26 01:19:57 visual_prompt]: Training 28 / 100 epoch, with learning rate 45.72593931387604
[09/26 01:20:04 visual_prompt]: Epoch 28 / 100: avg data time: 4.44e-02, avg batch time: 0.4891, average train loss: 191.5939
[09/26 01:20:05 visual_prompt]: Inference (val):avg data time: 1.94e-05, avg batch time: 0.1677, average loss: 163.8565
[09/26 01:20:05 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/26 01:20:05 visual_prompt]: Training 29 / 100 epoch, with learning rate 45.22542485937369
[09/26 01:20:12 visual_prompt]: Epoch 29 / 100: avg data time: 5.62e-02, avg batch time: 0.5007, average train loss: 189.3119
[09/26 01:20:14 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1678, average loss: 161.5349
[09/26 01:20:14 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 0.50	
[09/26 01:20:14 visual_prompt]: Training 30 / 100 epoch, with learning rate 44.70026884016804
[09/26 01:20:20 visual_prompt]: Epoch 30 / 100: avg data time: 5.79e-02, avg batch time: 0.5012, average train loss: 174.0093
[09/26 01:20:22 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1677, average loss: 152.4342
[09/26 01:20:22 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 1.00	
[09/26 01:20:22 visual_prompt]: Training 31 / 100 epoch, with learning rate 44.15111107797445
[09/26 01:20:29 visual_prompt]: Epoch 31 / 100: avg data time: 5.79e-02, avg batch time: 0.5017, average train loss: 170.0321
[09/26 01:20:30 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1678, average loss: 135.8225
[09/26 01:20:30 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 1.00	
[09/26 01:20:30 visual_prompt]: Training 32 / 100 epoch, with learning rate 43.57862063693486
[09/26 01:20:37 visual_prompt]: Epoch 32 / 100: avg data time: 5.20e-02, avg batch time: 0.4959, average train loss: 152.9507
[09/26 01:20:38 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1675, average loss: 132.7373
[09/26 01:20:38 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 2.50	
[09/26 01:20:38 visual_prompt]: Best epoch 32: best metric: 0.015
[09/26 01:20:38 visual_prompt]: Training 33 / 100 epoch, with learning rate 42.98349500846628
[09/26 01:20:45 visual_prompt]: Epoch 33 / 100: avg data time: 5.08e-02, avg batch time: 0.4942, average train loss: 149.5522
[09/26 01:20:47 visual_prompt]: Inference (val):avg data time: 1.97e-05, avg batch time: 0.1677, average loss: 143.6373
[09/26 01:20:47 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.00	
[09/26 01:20:47 visual_prompt]: Training 34 / 100 epoch, with learning rate 42.36645926147493
[09/26 01:20:53 visual_prompt]: Epoch 34 / 100: avg data time: 5.20e-02, avg batch time: 0.4962, average train loss: 158.9782
[09/26 01:20:55 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.1675, average loss: 140.2713
[09/26 01:20:55 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 1.50	
[09/26 01:20:55 visual_prompt]: Training 35 / 100 epoch, with learning rate 41.72826515897145
[09/26 01:21:01 visual_prompt]: Epoch 35 / 100: avg data time: 4.31e-02, avg batch time: 0.4886, average train loss: 150.9724
[09/26 01:21:03 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1673, average loss: 134.2061
[09/26 01:21:03 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.00	
[09/26 01:21:03 visual_prompt]: Training 36 / 100 epoch, with learning rate 41.06969024216348
[09/26 01:21:10 visual_prompt]: Epoch 36 / 100: avg data time: 5.54e-02, avg batch time: 0.4996, average train loss: 149.3548
[09/26 01:21:11 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1678, average loss: 125.1093
[09/26 01:21:11 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 0.50	
[09/26 01:21:11 visual_prompt]: Training 37 / 100 epoch, with learning rate 40.391536883141455
[09/26 01:21:18 visual_prompt]: Epoch 37 / 100: avg data time: 4.45e-02, avg batch time: 0.4893, average train loss: 139.9778
[09/26 01:21:19 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1677, average loss: 125.0094
[09/26 01:21:19 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 1.50	
[09/26 01:21:19 visual_prompt]: Training 38 / 100 epoch, with learning rate 39.69463130731183
[09/26 01:21:26 visual_prompt]: Epoch 38 / 100: avg data time: 5.42e-02, avg batch time: 0.4982, average train loss: 127.9875
[09/26 01:21:27 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1673, average loss: 112.4319
[09/26 01:21:27 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 2.00	
[09/26 01:21:27 visual_prompt]: Training 39 / 100 epoch, with learning rate 38.97982258676867
[09/26 01:21:34 visual_prompt]: Epoch 39 / 100: avg data time: 5.79e-02, avg batch time: 0.5032, average train loss: 115.1900
[09/26 01:21:36 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1677, average loss: 115.9125
[09/26 01:21:36 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 1.50	
[09/26 01:21:36 visual_prompt]: Training 40 / 100 epoch, with learning rate 38.24798160583012
[09/26 01:21:43 visual_prompt]: Epoch 40 / 100: avg data time: 5.52e-02, avg batch time: 0.4995, average train loss: 122.5062
[09/26 01:21:44 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1676, average loss: 140.3192
[09/26 01:21:44 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.50	top5: 4.00	
[09/26 01:21:44 visual_prompt]: Best epoch 40: best metric: 0.025
[09/26 01:21:44 visual_prompt]: Training 41 / 100 epoch, with learning rate 37.5
[09/26 01:21:51 visual_prompt]: Epoch 41 / 100: avg data time: 5.43e-02, avg batch time: 0.4988, average train loss: 141.8387
[09/26 01:21:52 visual_prompt]: Inference (val):avg data time: 1.99e-05, avg batch time: 0.1676, average loss: 115.9966
[09/26 01:21:52 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.00	
[09/26 01:21:52 visual_prompt]: Training 42 / 100 epoch, with learning rate 36.736789069647266
[09/26 01:21:59 visual_prompt]: Epoch 42 / 100: avg data time: 3.79e-02, avg batch time: 0.4835, average train loss: 149.6823
[09/26 01:22:00 visual_prompt]: Inference (val):avg data time: 2.02e-05, avg batch time: 0.1673, average loss: 133.6851
[09/26 01:22:00 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.00	
[09/26 01:22:00 visual_prompt]: Training 43 / 100 epoch, with learning rate 35.959278669726935
[09/26 01:22:07 visual_prompt]: Epoch 43 / 100: avg data time: 5.66e-02, avg batch time: 0.5001, average train loss: 138.6619
[09/26 01:22:08 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1676, average loss: 137.9995
[09/26 01:22:08 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 1.50	
[09/26 01:22:08 visual_prompt]: Training 44 / 100 epoch, with learning rate 35.16841607689501
[09/26 01:22:15 visual_prompt]: Epoch 44 / 100: avg data time: 4.67e-02, avg batch time: 0.4912, average train loss: 126.9446
[09/26 01:22:16 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1677, average loss: 104.4820
[09/26 01:22:16 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.50	
[09/26 01:22:16 visual_prompt]: Training 45 / 100 epoch, with learning rate 34.365164835397806
[09/26 01:22:23 visual_prompt]: Epoch 45 / 100: avg data time: 4.04e-02, avg batch time: 0.4874, average train loss: 134.9219
[09/26 01:22:24 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1680, average loss: 131.9952
[09/26 01:22:24 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 2.50	
[09/26 01:22:24 visual_prompt]: Training 46 / 100 epoch, with learning rate 33.55050358314172
[09/26 01:22:31 visual_prompt]: Epoch 46 / 100: avg data time: 4.87e-02, avg batch time: 0.4934, average train loss: 178.3501
[09/26 01:22:33 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1678, average loss: 171.2267
[09/26 01:22:33 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.50	
[09/26 01:22:33 visual_prompt]: Training 47 / 100 epoch, with learning rate 32.72542485937369
[09/26 01:22:39 visual_prompt]: Epoch 47 / 100: avg data time: 5.49e-02, avg batch time: 0.4983, average train loss: 236.7386
[09/26 01:22:41 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1675, average loss: 162.9399
[09/26 01:22:41 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.50	
[09/26 01:22:41 visual_prompt]: Training 48 / 100 epoch, with learning rate 31.89093389542498
[09/26 01:22:48 visual_prompt]: Epoch 48 / 100: avg data time: 5.94e-02, avg batch time: 0.5026, average train loss: 230.0927
[09/26 01:22:49 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1673, average loss: 185.8855
[09/26 01:22:49 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.50	
[09/26 01:22:49 visual_prompt]: Training 49 / 100 epoch, with learning rate 31.04804738999169
[09/26 01:22:56 visual_prompt]: Epoch 49 / 100: avg data time: 5.35e-02, avg batch time: 0.4975, average train loss: 185.0197
[09/26 01:22:57 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1672, average loss: 148.8477
[09/26 01:22:57 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 4.50	
[09/26 01:22:57 visual_prompt]: Training 50 / 100 epoch, with learning rate 30.19779227044398
[09/26 01:23:04 visual_prompt]: Epoch 50 / 100: avg data time: 5.37e-02, avg batch time: 0.4975, average train loss: 240.9182
[09/26 01:23:05 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1677, average loss: 158.3421
[09/26 01:23:05 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/26 01:23:05 visual_prompt]: Training 51 / 100 epoch, with learning rate 29.341204441673263
[09/26 01:23:12 visual_prompt]: Epoch 51 / 100: avg data time: 4.41e-02, avg batch time: 0.4892, average train loss: 186.6134
[09/26 01:23:13 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1673, average loss: 156.5997
[09/26 01:23:14 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.50	
[09/26 01:23:14 visual_prompt]: Training 52 / 100 epoch, with learning rate 28.479327524001636
[09/26 01:23:20 visual_prompt]: Epoch 52 / 100: avg data time: 5.23e-02, avg batch time: 0.4960, average train loss: 179.5353
[09/26 01:23:22 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1676, average loss: 160.5692
[09/26 01:23:22 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 0.50	
[09/26 01:23:22 visual_prompt]: Training 53 / 100 epoch, with learning rate 27.61321158169134
[09/26 01:23:28 visual_prompt]: Epoch 53 / 100: avg data time: 5.70e-02, avg batch time: 0.4997, average train loss: 152.6466
[09/26 01:23:30 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1675, average loss: 144.5363
[09/26 01:23:30 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 1.50	
[09/26 01:23:30 visual_prompt]: Training 54 / 100 epoch, with learning rate 26.74391184360313
[09/26 01:23:37 visual_prompt]: Epoch 54 / 100: avg data time: 5.41e-02, avg batch time: 0.4964, average train loss: 134.4110
[09/26 01:23:38 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1672, average loss: 124.5299
[09/26 01:23:38 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 0.50	
[09/26 01:23:38 visual_prompt]: Training 55 / 100 epoch, with learning rate 25.872487417562528
[09/26 01:23:45 visual_prompt]: Epoch 55 / 100: avg data time: 5.19e-02, avg batch time: 0.4958, average train loss: 126.5436
[09/26 01:23:46 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1672, average loss: 105.3484
[09/26 01:23:46 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.50	
[09/26 01:23:46 visual_prompt]: Training 56 / 100 epoch, with learning rate 25.0
[09/26 01:23:53 visual_prompt]: Epoch 56 / 100: avg data time: 3.78e-02, avg batch time: 0.4823, average train loss: 97.4724
[09/26 01:23:54 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1673, average loss: 90.7159
[09/26 01:23:54 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 0.50	
[09/26 01:23:54 visual_prompt]: Training 57 / 100 epoch, with learning rate 24.127512582437483
[09/26 01:24:01 visual_prompt]: Epoch 57 / 100: avg data time: 6.16e-02, avg batch time: 0.5050, average train loss: 84.5606
[09/26 01:24:02 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1677, average loss: 86.1284
[09/26 01:24:02 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 0.50	
[09/26 01:24:02 visual_prompt]: Training 58 / 100 epoch, with learning rate 23.256088156396867
[09/26 01:24:09 visual_prompt]: Epoch 58 / 100: avg data time: 5.45e-02, avg batch time: 0.4981, average train loss: 81.0343
[09/26 01:24:11 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1673, average loss: 73.8297
[09/26 01:24:11 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/26 01:24:11 visual_prompt]: Training 59 / 100 epoch, with learning rate 22.38678841830867
[09/26 01:24:17 visual_prompt]: Epoch 59 / 100: avg data time: 4.60e-02, avg batch time: 0.4899, average train loss: 74.0105
[09/26 01:24:19 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1674, average loss: 64.6999
[09/26 01:24:19 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 1.00	
[09/26 01:24:19 visual_prompt]: Training 60 / 100 epoch, with learning rate 21.52067247599837
[09/26 01:24:26 visual_prompt]: Epoch 60 / 100: avg data time: 5.22e-02, avg batch time: 0.4968, average train loss: 57.8304
[09/26 01:24:27 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1671, average loss: 51.8286
[09/26 01:24:27 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 0.50	
[09/26 01:24:27 visual_prompt]: Training 61 / 100 epoch, with learning rate 20.65879555832674
[09/26 01:24:34 visual_prompt]: Epoch 61 / 100: avg data time: 3.94e-02, avg batch time: 0.4816, average train loss: 45.5725
[09/26 01:24:35 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1675, average loss: 47.5137
[09/26 01:24:35 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 4.50	
[09/26 01:24:35 visual_prompt]: Training 62 / 100 epoch, with learning rate 19.80220772955602
[09/26 01:24:42 visual_prompt]: Epoch 62 / 100: avg data time: 5.81e-02, avg batch time: 0.5012, average train loss: 46.4733
[09/26 01:24:43 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1675, average loss: 41.0723
[09/26 01:24:43 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 0.50	
[09/26 01:24:43 visual_prompt]: Training 63 / 100 epoch, with learning rate 18.95195261000831
[09/26 01:24:50 visual_prompt]: Epoch 63 / 100: avg data time: 5.77e-02, avg batch time: 0.5020, average train loss: 40.8169
[09/26 01:24:52 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1672, average loss: 34.0346
[09/26 01:24:52 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.50	
[09/26 01:24:52 visual_prompt]: Training 64 / 100 epoch, with learning rate 18.10906610457502
[09/26 01:24:58 visual_prompt]: Epoch 64 / 100: avg data time: 5.45e-02, avg batch time: 0.4974, average train loss: 32.4367
[09/26 01:25:00 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1673, average loss: 25.8176
[09/26 01:25:00 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.00	
[09/26 01:25:00 visual_prompt]: Training 65 / 100 epoch, with learning rate 17.274575140626318
[09/26 01:25:07 visual_prompt]: Epoch 65 / 100: avg data time: 4.63e-02, avg batch time: 0.4902, average train loss: 32.8407
[09/26 01:25:08 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1674, average loss: 26.4675
[09/26 01:25:08 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 2.50	
[09/26 01:25:08 visual_prompt]: Training 66 / 100 epoch, with learning rate 16.449496416858285
[09/26 01:25:15 visual_prompt]: Epoch 66 / 100: avg data time: 4.72e-02, avg batch time: 0.4895, average train loss: 33.4458
[09/26 01:25:16 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1674, average loss: 22.3723
[09/26 01:25:16 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.50	
[09/26 01:25:16 visual_prompt]: Training 67 / 100 epoch, with learning rate 15.634835164602197
[09/26 01:25:23 visual_prompt]: Epoch 67 / 100: avg data time: 4.47e-02, avg batch time: 0.4891, average train loss: 26.5269
[09/26 01:25:24 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1673, average loss: 24.0688
[09/26 01:25:24 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 3.00	
[09/26 01:25:24 visual_prompt]: Training 68 / 100 epoch, with learning rate 14.831583923104999
[09/26 01:25:31 visual_prompt]: Epoch 68 / 100: avg data time: 5.46e-02, avg batch time: 0.4990, average train loss: 26.3261
[09/26 01:25:33 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1674, average loss: 21.5159
[09/26 01:25:33 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 0.50	
[09/26 01:25:33 visual_prompt]: Training 69 / 100 epoch, with learning rate 14.040721330273062
[09/26 01:25:39 visual_prompt]: Epoch 69 / 100: avg data time: 4.74e-02, avg batch time: 0.4896, average train loss: 24.7595
[09/26 01:25:41 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1674, average loss: 25.6795
[09/26 01:25:41 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 0.00	
[09/26 01:25:41 visual_prompt]: Training 70 / 100 epoch, with learning rate 13.263210930352736
[09/26 01:25:47 visual_prompt]: Epoch 70 / 100: avg data time: 5.62e-02, avg batch time: 0.4992, average train loss: 28.9018
[09/26 01:25:49 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1674, average loss: 22.8082
[09/26 01:25:49 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 3.00	
[09/26 01:25:49 visual_prompt]: Training 71 / 100 epoch, with learning rate 12.500000000000005
[09/26 01:25:56 visual_prompt]: Epoch 71 / 100: avg data time: 5.08e-02, avg batch time: 0.4937, average train loss: 26.1477
[09/26 01:25:57 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1674, average loss: 20.3807
[09/26 01:25:57 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/26 01:25:57 visual_prompt]: Training 72 / 100 epoch, with learning rate 11.75201839416988
[09/26 01:26:04 visual_prompt]: Epoch 72 / 100: avg data time: 5.30e-02, avg batch time: 0.4974, average train loss: 21.6323
[09/26 01:26:05 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1674, average loss: 17.2329
[09/26 01:26:05 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 2.00	
[09/26 01:26:05 visual_prompt]: Training 73 / 100 epoch, with learning rate 11.020177413231332
[09/26 01:26:12 visual_prompt]: Epoch 73 / 100: avg data time: 5.13e-02, avg batch time: 0.4949, average train loss: 21.3890
[09/26 01:26:13 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1677, average loss: 16.8187
[09/26 01:26:14 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 5.50	
[09/26 01:26:14 visual_prompt]: Training 74 / 100 epoch, with learning rate 10.305368692688175
[09/26 01:26:20 visual_prompt]: Epoch 74 / 100: avg data time: 5.54e-02, avg batch time: 0.4988, average train loss: 19.8559
[09/26 01:26:22 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1671, average loss: 14.4612
[09/26 01:26:22 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.00	
[09/26 01:26:22 visual_prompt]: Training 75 / 100 epoch, with learning rate 9.608463116858543
[09/26 01:26:28 visual_prompt]: Epoch 75 / 100: avg data time: 5.48e-02, avg batch time: 0.4975, average train loss: 15.7014
[09/26 01:26:30 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1673, average loss: 12.8491
[09/26 01:26:30 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.50	
[09/26 01:26:30 visual_prompt]: Training 76 / 100 epoch, with learning rate 8.930309757836516
[09/26 01:26:37 visual_prompt]: Epoch 76 / 100: avg data time: 4.59e-02, avg batch time: 0.4894, average train loss: 13.3273
[09/26 01:26:38 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1674, average loss: 12.4452
[09/26 01:26:38 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.50	
[09/26 01:26:38 visual_prompt]: Training 77 / 100 epoch, with learning rate 8.271734841028552
[09/26 01:26:45 visual_prompt]: Epoch 77 / 100: avg data time: 5.62e-02, avg batch time: 0.4991, average train loss: 13.7787
[09/26 01:26:46 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1671, average loss: 11.5662
[09/26 01:26:46 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/26 01:26:46 visual_prompt]: Training 78 / 100 epoch, with learning rate 7.633540738525066
[09/26 01:26:53 visual_prompt]: Epoch 78 / 100: avg data time: 4.78e-02, avg batch time: 0.4917, average train loss: 12.8079
[09/26 01:26:54 visual_prompt]: Inference (val):avg data time: 4.24e-05, avg batch time: 0.1674, average loss: 10.4988
[09/26 01:26:54 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 3.50	
[09/26 01:26:54 visual_prompt]: Training 79 / 100 epoch, with learning rate 7.016504991533726
[09/26 01:27:01 visual_prompt]: Epoch 79 / 100: avg data time: 5.40e-02, avg batch time: 0.4971, average train loss: 10.5909
[09/26 01:27:03 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1676, average loss: 9.9077
[09/26 01:27:03 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.50	
[09/26 01:27:03 visual_prompt]: Training 80 / 100 epoch, with learning rate 6.4213793630651415
[09/26 01:27:09 visual_prompt]: Epoch 80 / 100: avg data time: 4.22e-02, avg batch time: 0.4858, average train loss: 9.2439
[09/26 01:27:11 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1672, average loss: 9.4625
[09/26 01:27:11 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.50	
[09/26 01:27:11 visual_prompt]: Training 81 / 100 epoch, with learning rate 5.848888922025552
[09/26 01:27:18 visual_prompt]: Epoch 81 / 100: avg data time: 6.07e-02, avg batch time: 0.5041, average train loss: 8.3853
[09/26 01:27:19 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1674, average loss: 9.0577
[09/26 01:27:19 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/26 01:27:19 visual_prompt]: Training 82 / 100 epoch, with learning rate 5.2997311598319525
[09/26 01:27:26 visual_prompt]: Epoch 82 / 100: avg data time: 6.03e-02, avg batch time: 0.5032, average train loss: 7.9417
[09/26 01:27:27 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1674, average loss: 10.0668
[09/26 01:27:27 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 1.00	
[09/26 01:27:27 visual_prompt]: Training 83 / 100 epoch, with learning rate 4.774575140626316
[09/26 01:27:34 visual_prompt]: Epoch 83 / 100: avg data time: 5.65e-02, avg batch time: 0.5003, average train loss: 8.1678
[09/26 01:27:36 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1676, average loss: 8.7083
[09/26 01:27:36 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 01:27:36 visual_prompt]: Training 84 / 100 epoch, with learning rate 4.27406068612396
[09/26 01:27:42 visual_prompt]: Epoch 84 / 100: avg data time: 5.48e-02, avg batch time: 0.4973, average train loss: 7.9678
[09/26 01:27:44 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1674, average loss: 8.4891
[09/26 01:27:44 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 5.00	
[09/26 01:27:44 visual_prompt]: Training 85 / 100 epoch, with learning rate 3.798797596089351
[09/26 01:27:51 visual_prompt]: Epoch 85 / 100: avg data time: 6.14e-02, avg batch time: 0.5042, average train loss: 7.3024
[09/26 01:27:52 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1675, average loss: 8.2733
[09/26 01:27:52 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 5.00	
[09/26 01:27:52 visual_prompt]: Training 86 / 100 epoch, with learning rate 3.349364905389032
[09/26 01:27:59 visual_prompt]: Epoch 86 / 100: avg data time: 5.87e-02, avg batch time: 0.5016, average train loss: 7.0531
[09/26 01:28:00 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1673, average loss: 8.0764
[09/26 01:28:00 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.00	top5: 5.00	
[09/26 01:28:00 visual_prompt]: Training 87 / 100 epoch, with learning rate 2.9263101785268253
[09/26 01:28:07 visual_prompt]: Epoch 87 / 100: avg data time: 5.67e-02, avg batch time: 0.5010, average train loss: 6.8744
[09/26 01:28:09 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1675, average loss: 8.0731
[09/26 01:28:09 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 6.00	
[09/26 01:28:09 visual_prompt]: Training 88 / 100 epoch, with learning rate 2.5301488425208296
[09/26 01:28:15 visual_prompt]: Epoch 88 / 100: avg data time: 5.40e-02, avg batch time: 0.4976, average train loss: 6.7865
[09/26 01:28:17 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1674, average loss: 7.9491
[09/26 01:28:17 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 6.50	
[09/26 01:28:17 visual_prompt]: Training 89 / 100 epoch, with learning rate 2.1613635589349753
[09/26 01:28:23 visual_prompt]: Epoch 89 / 100: avg data time: 4.74e-02, avg batch time: 0.4921, average train loss: 6.6680
[09/26 01:28:25 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1675, average loss: 7.8119
[09/26 01:28:25 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 5.50	
[09/26 01:28:25 visual_prompt]: Training 90 / 100 epoch, with learning rate 1.820403635830317
[09/26 01:28:32 visual_prompt]: Epoch 90 / 100: avg data time: 5.23e-02, avg batch time: 0.4966, average train loss: 6.5389
[09/26 01:28:33 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1676, average loss: 7.7789
[09/26 01:28:33 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 4.00	
[09/26 01:28:33 visual_prompt]: Training 91 / 100 epoch, with learning rate 1.507684480352292
[09/26 01:28:40 visual_prompt]: Epoch 91 / 100: avg data time: 5.34e-02, avg batch time: 0.4973, average train loss: 6.4453
[09/26 01:28:41 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1677, average loss: 7.6565
[09/26 01:28:41 visual_prompt]: Classification results with val_vtab-sun397: top1: 3.50	top5: 8.00	
[09/26 01:28:41 visual_prompt]: Best epoch 91: best metric: 0.035
[09/26 01:28:41 visual_prompt]: Training 92 / 100 epoch, with learning rate 1.2235870926211616
[09/26 01:28:48 visual_prompt]: Epoch 92 / 100: avg data time: 5.66e-02, avg batch time: 0.4995, average train loss: 6.3550
[09/26 01:28:50 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1675, average loss: 7.6360
[09/26 01:28:50 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.50	top5: 6.50	
[09/26 01:28:50 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.9684576015420276
[09/26 01:28:56 visual_prompt]: Epoch 93 / 100: avg data time: 5.66e-02, avg batch time: 0.5000, average train loss: 6.2960
[09/26 01:28:58 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1675, average loss: 7.5786
[09/26 01:28:58 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.50	top5: 8.00	
[09/26 01:28:58 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.7426068431000882
[09/26 01:29:04 visual_prompt]: Epoch 94 / 100: avg data time: 4.58e-02, avg batch time: 0.4916, average train loss: 6.1724
[09/26 01:29:06 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1672, average loss: 7.5223
[09/26 01:29:06 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 7.50	
[09/26 01:29:06 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.5463099816548578
[09/26 01:29:13 visual_prompt]: Epoch 95 / 100: avg data time: 5.98e-02, avg batch time: 0.5024, average train loss: 6.1253
[09/26 01:29:14 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1676, average loss: 7.4618
[09/26 01:29:14 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 8.50	
[09/26 01:29:14 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.3798061746947995
[09/26 01:29:21 visual_prompt]: Epoch 96 / 100: avg data time: 3.93e-02, avg batch time: 0.4854, average train loss: 6.0449
[09/26 01:29:22 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1677, average loss: 7.4197
[09/26 01:29:22 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.50	top5: 9.00	
[09/26 01:29:22 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.24329828146074095
[09/26 01:29:29 visual_prompt]: Epoch 97 / 100: avg data time: 5.39e-02, avg batch time: 0.4970, average train loss: 5.9532
[09/26 01:29:31 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1678, average loss: 7.5185
[09/26 01:29:31 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.50	top5: 6.50	
[09/26 01:29:31 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.13695261579316775
[09/26 01:29:37 visual_prompt]: Epoch 98 / 100: avg data time: 5.33e-02, avg batch time: 0.4977, average train loss: 5.8916
[09/26 01:29:39 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1676, average loss: 7.4579
[09/26 01:29:39 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.00	top5: 8.50	
[09/26 01:29:39 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.06089874350439506
[09/26 01:29:45 visual_prompt]: Epoch 99 / 100: avg data time: 4.89e-02, avg batch time: 0.4931, average train loss: 5.8423
[09/26 01:29:47 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1677, average loss: 7.4809
[09/26 01:29:47 visual_prompt]: Classification results with val_vtab-sun397: top1: 3.00	top5: 8.50	
[09/26 01:29:47 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.015229324522605947
[09/26 01:29:54 visual_prompt]: Epoch 100 / 100: avg data time: 5.79e-02, avg batch time: 0.5028, average train loss: 5.8263
[09/26 01:29:55 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1672, average loss: 7.4598
[09/26 01:29:55 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.50	top5: 8.00	
[09/26 01:29:55 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 01:29:55 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              0
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 01:29:55 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-sun397', 'DATA.NUMBER_CLASSES', '397', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 01:29:55 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 01:29:55 visual_prompt]: Training with config:
[09/26 01:29:55 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-sun397/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr50.0_wd0.0/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 50.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-sun397', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 397, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 01:29:55 visual_prompt]: Loading training data...
[09/26 01:29:55 visual_prompt]: Constructing vtab-sun397 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split train[:800], from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/26 01:29:57 visual_prompt]: Number of images: 800
[09/26 01:29:57 visual_prompt]: Number of classes: 309 / 397
[09/26 01:29:57 visual_prompt]: Loading validation data...
[09/26 01:29:57 visual_prompt]: Constructing vtab-sun397 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split validation[:200], from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/26 01:29:57 visual_prompt]: Number of images: 200
[09/26 01:29:57 visual_prompt]: Number of classes: 136 / 397
[09/26 01:29:57 visual_prompt]: Constructing models...
[09/26 01:29:59 visual_prompt]: Total Parameters: 86564749	 Gradient Parameters: 766093
[09/26 01:29:59 visual_prompt]: tuned percent:0.885
[09/26 01:30:00 visual_prompt]: Device used for model: 0
[09/26 01:30:00 visual_prompt]: Setting up Evaluator...
[09/26 01:30:00 visual_prompt]: Setting up Trainer...
[09/26 01:30:00 visual_prompt]: 	Setting up the optimizer...
[09/26 01:30:00 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 01:30:06 visual_prompt]: Epoch 1 / 100: avg data time: 4.12e-02, avg batch time: 0.4843, average train loss: 5.9885
[09/26 01:30:08 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1670, average loss: 6.0097
[09/26 01:30:08 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/26 01:30:08 visual_prompt]: Training 2 / 100 epoch, with learning rate 5.0
[09/26 01:30:14 visual_prompt]: Epoch 2 / 100: avg data time: 5.27e-02, avg batch time: 0.4956, average train loss: 6.0456
[09/26 01:30:16 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1670, average loss: 6.3119
[09/26 01:30:16 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 3.00	
[09/26 01:30:16 visual_prompt]: Training 3 / 100 epoch, with learning rate 10.0
[09/26 01:30:23 visual_prompt]: Epoch 3 / 100: avg data time: 5.79e-02, avg batch time: 0.5009, average train loss: 6.2759
[09/26 01:30:24 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1676, average loss: 7.1131
[09/26 01:30:24 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 4.00	
[09/26 01:30:24 visual_prompt]: Training 4 / 100 epoch, with learning rate 15.0
[09/26 01:30:31 visual_prompt]: Epoch 4 / 100: avg data time: 4.78e-02, avg batch time: 0.4912, average train loss: 6.8797
[09/26 01:30:32 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1674, average loss: 7.4206
[09/26 01:30:32 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 2.50	
[09/26 01:30:32 visual_prompt]: Best epoch 4: best metric: 0.010
[09/26 01:30:32 visual_prompt]: Training 5 / 100 epoch, with learning rate 20.0
[09/26 01:30:39 visual_prompt]: Epoch 5 / 100: avg data time: 4.95e-02, avg batch time: 0.4935, average train loss: 9.0604
[09/26 01:30:40 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1674, average loss: 10.8619
[09/26 01:30:40 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 2.50	
[09/26 01:30:40 visual_prompt]: Training 6 / 100 epoch, with learning rate 25.0
[09/26 01:30:47 visual_prompt]: Epoch 6 / 100: avg data time: 5.49e-02, avg batch time: 0.4979, average train loss: 14.0751
[09/26 01:30:48 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.1674, average loss: 16.9533
[09/26 01:30:48 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 3.00	
[09/26 01:30:48 visual_prompt]: Training 7 / 100 epoch, with learning rate 30.0
[09/26 01:30:55 visual_prompt]: Epoch 7 / 100: avg data time: 4.97e-02, avg batch time: 0.4930, average train loss: 28.0058
[09/26 01:30:57 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1675, average loss: 35.1576
[09/26 01:30:57 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 2.00	
[09/26 01:30:57 visual_prompt]: Training 8 / 100 epoch, with learning rate 35.0
[09/26 01:31:03 visual_prompt]: Epoch 8 / 100: avg data time: 5.67e-02, avg batch time: 0.5001, average train loss: 59.9679
[09/26 01:31:05 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1669, average loss: 81.0208
[09/26 01:31:05 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.50	top5: 4.00	
[09/26 01:31:05 visual_prompt]: Best epoch 8: best metric: 0.025
[09/26 01:31:05 visual_prompt]: Training 9 / 100 epoch, with learning rate 40.0
[09/26 01:31:12 visual_prompt]: Epoch 9 / 100: avg data time: 5.84e-02, avg batch time: 0.5015, average train loss: 105.4635
[09/26 01:31:13 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1672, average loss: 107.5345
[09/26 01:31:13 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.00	
[09/26 01:31:13 visual_prompt]: Training 10 / 100 epoch, with learning rate 45.0
[09/26 01:31:20 visual_prompt]: Epoch 10 / 100: avg data time: 5.33e-02, avg batch time: 0.4952, average train loss: 134.7759
[09/26 01:31:21 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1670, average loss: 122.9273
[09/26 01:31:21 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 3.00	
[09/26 01:31:21 visual_prompt]: Training 11 / 100 epoch, with learning rate 50.0
[09/26 01:31:28 visual_prompt]: Epoch 11 / 100: avg data time: 5.20e-02, avg batch time: 0.4957, average train loss: 166.6334
[09/26 01:31:30 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1671, average loss: 140.7675
[09/26 01:31:30 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.50	
[09/26 01:31:30 visual_prompt]: Training 12 / 100 epoch, with learning rate 49.9847706754774
[09/26 01:31:36 visual_prompt]: Epoch 12 / 100: avg data time: 5.48e-02, avg batch time: 0.4988, average train loss: 155.0886
[09/26 01:31:38 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1671, average loss: 144.2169
[09/26 01:31:38 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 5.00	
[09/26 01:31:38 visual_prompt]: Training 13 / 100 epoch, with learning rate 49.939101256495604
[09/26 01:31:45 visual_prompt]: Epoch 13 / 100: avg data time: 4.78e-02, avg batch time: 0.4915, average train loss: 221.7158
[09/26 01:31:46 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1671, average loss: 225.8978
[09/26 01:31:46 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 0.50	
[09/26 01:31:46 visual_prompt]: Training 14 / 100 epoch, with learning rate 49.86304738420683
[09/26 01:31:53 visual_prompt]: Epoch 14 / 100: avg data time: 5.26e-02, avg batch time: 0.4960, average train loss: 219.9178
[09/26 01:31:54 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1673, average loss: 140.4793
[09/26 01:31:54 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.00	
[09/26 01:31:54 visual_prompt]: Training 15 / 100 epoch, with learning rate 49.75670171853926
[09/26 01:32:01 visual_prompt]: Epoch 15 / 100: avg data time: 5.54e-02, avg batch time: 0.4989, average train loss: 226.1560
[09/26 01:32:03 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1670, average loss: 215.7171
[09/26 01:32:03 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 0.00	
[09/26 01:32:03 visual_prompt]: Training 16 / 100 epoch, with learning rate 49.6201938253052
[09/26 01:32:09 visual_prompt]: Epoch 16 / 100: avg data time: 5.09e-02, avg batch time: 0.4941, average train loss: 257.3354
[09/26 01:32:11 visual_prompt]: Inference (val):avg data time: 4.18e-05, avg batch time: 0.1676, average loss: 231.4301
[09/26 01:32:11 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 1.00	
[09/26 01:32:11 visual_prompt]: Training 17 / 100 epoch, with learning rate 49.45369001834514
[09/26 01:32:17 visual_prompt]: Epoch 17 / 100: avg data time: 4.88e-02, avg batch time: 0.4921, average train loss: 346.2499
[09/26 01:32:19 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1672, average loss: 265.9692
[09/26 01:32:19 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 0.50	
[09/26 01:32:19 visual_prompt]: Training 18 / 100 epoch, with learning rate 49.25739315689991
[09/26 01:32:26 visual_prompt]: Epoch 18 / 100: avg data time: 5.46e-02, avg batch time: 0.4980, average train loss: 264.1839
[09/26 01:32:27 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1673, average loss: 185.1584
[09/26 01:32:27 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 0.50	
[09/26 01:32:27 visual_prompt]: Training 19 / 100 epoch, with learning rate 49.03154239845797
[09/26 01:32:34 visual_prompt]: Epoch 19 / 100: avg data time: 5.87e-02, avg batch time: 0.5036, average train loss: 197.9716
[09/26 01:32:35 visual_prompt]: Inference (val):avg data time: 3.62e-05, avg batch time: 0.1675, average loss: 184.0100
[09/26 01:32:35 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 2.50	
[09/26 01:32:35 visual_prompt]: Training 20 / 100 epoch, with learning rate 48.77641290737884
[09/26 01:32:42 visual_prompt]: Epoch 20 / 100: avg data time: 5.64e-02, avg batch time: 0.5017, average train loss: 162.9161
[09/26 01:32:44 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1672, average loss: 145.1941
[09/26 01:32:44 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.00	
[09/26 01:32:44 visual_prompt]: Training 21 / 100 epoch, with learning rate 48.49231551964771
[09/26 01:32:50 visual_prompt]: Epoch 21 / 100: avg data time: 5.01e-02, avg batch time: 0.4918, average train loss: 143.3050
[09/26 01:32:52 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1672, average loss: 116.3315
[09/26 01:32:52 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 2.50	
[09/26 01:32:52 visual_prompt]: Training 22 / 100 epoch, with learning rate 48.17959636416968
[09/26 01:32:59 visual_prompt]: Epoch 22 / 100: avg data time: 5.50e-02, avg batch time: 0.4981, average train loss: 121.5401
[09/26 01:33:00 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1673, average loss: 122.0603
[09/26 01:33:00 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.50	
[09/26 01:33:00 visual_prompt]: Training 23 / 100 epoch, with learning rate 47.83863644106502
[09/26 01:33:07 visual_prompt]: Epoch 23 / 100: avg data time: 5.54e-02, avg batch time: 0.4985, average train loss: 124.1604
[09/26 01:33:08 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1673, average loss: 109.5526
[09/26 01:33:08 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 2.00	
[09/26 01:33:08 visual_prompt]: Training 24 / 100 epoch, with learning rate 47.46985115747918
[09/26 01:33:15 visual_prompt]: Epoch 24 / 100: avg data time: 5.28e-02, avg batch time: 0.4972, average train loss: 111.9972
[09/26 01:33:16 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1671, average loss: 92.5203
[09/26 01:33:16 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 3.00	
[09/26 01:33:16 visual_prompt]: Training 25 / 100 epoch, with learning rate 47.073689821473174
[09/26 01:33:23 visual_prompt]: Epoch 25 / 100: avg data time: 4.56e-02, avg batch time: 0.4891, average train loss: 87.9687
[09/26 01:33:24 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1676, average loss: 63.8379
[09/26 01:33:24 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 3.50	
[09/26 01:33:24 visual_prompt]: Training 26 / 100 epoch, with learning rate 46.65063509461097
[09/26 01:33:31 visual_prompt]: Epoch 26 / 100: avg data time: 4.06e-02, avg batch time: 0.4853, average train loss: 66.3812
[09/26 01:33:32 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1676, average loss: 55.0563
[09/26 01:33:33 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 3.00	
[09/26 01:33:33 visual_prompt]: Training 27 / 100 epoch, with learning rate 46.20120240391065
[09/26 01:33:39 visual_prompt]: Epoch 27 / 100: avg data time: 4.71e-02, avg batch time: 0.4910, average train loss: 65.2281
[09/26 01:33:41 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1674, average loss: 53.5584
[09/26 01:33:41 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 4.50	
[09/26 01:33:41 visual_prompt]: Training 28 / 100 epoch, with learning rate 45.72593931387604
[09/26 01:33:47 visual_prompt]: Epoch 28 / 100: avg data time: 5.14e-02, avg batch time: 0.4955, average train loss: 60.0500
[09/26 01:33:49 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1673, average loss: 44.9437
[09/26 01:33:49 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 2.00	
[09/26 01:33:49 visual_prompt]: Training 29 / 100 epoch, with learning rate 45.22542485937369
[09/26 01:33:55 visual_prompt]: Epoch 29 / 100: avg data time: 4.05e-02, avg batch time: 0.4850, average train loss: 48.4907
[09/26 01:33:57 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1673, average loss: 38.0926
[09/26 01:33:57 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/26 01:33:57 visual_prompt]: Training 30 / 100 epoch, with learning rate 44.70026884016804
[09/26 01:34:04 visual_prompt]: Epoch 30 / 100: avg data time: 5.60e-02, avg batch time: 0.5012, average train loss: 43.5185
[09/26 01:34:05 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1674, average loss: 36.1031
[09/26 01:34:05 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 2.50	
[09/26 01:34:05 visual_prompt]: Training 31 / 100 epoch, with learning rate 44.15111107797445
[09/26 01:34:12 visual_prompt]: Epoch 31 / 100: avg data time: 5.49e-02, avg batch time: 0.4986, average train loss: 36.8194
[09/26 01:34:13 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1676, average loss: 40.3801
[09/26 01:34:13 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 3.00	
[09/26 01:34:13 visual_prompt]: Training 32 / 100 epoch, with learning rate 43.57862063693486
[09/26 01:34:20 visual_prompt]: Epoch 32 / 100: avg data time: 5.50e-02, avg batch time: 0.4982, average train loss: 40.7040
[09/26 01:34:22 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1673, average loss: 32.4631
[09/26 01:34:22 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 1.00	
[09/26 01:34:22 visual_prompt]: Training 33 / 100 epoch, with learning rate 42.98349500846628
[09/26 01:34:28 visual_prompt]: Epoch 33 / 100: avg data time: 5.85e-02, avg batch time: 0.5019, average train loss: 35.8281
[09/26 01:34:30 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1670, average loss: 24.5452
[09/26 01:34:30 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 01:34:30 visual_prompt]: Training 34 / 100 epoch, with learning rate 42.36645926147493
[09/26 01:34:37 visual_prompt]: Epoch 34 / 100: avg data time: 5.99e-02, avg batch time: 0.5033, average train loss: 27.5185
[09/26 01:34:38 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1672, average loss: 24.0240
[09/26 01:34:38 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 2.00	
[09/26 01:34:38 visual_prompt]: Training 35 / 100 epoch, with learning rate 41.72826515897145
[09/26 01:34:45 visual_prompt]: Epoch 35 / 100: avg data time: 4.28e-02, avg batch time: 0.4894, average train loss: 26.5682
[09/26 01:34:46 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1673, average loss: 23.5117
[09/26 01:34:46 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 2.50	
[09/26 01:34:46 visual_prompt]: Training 36 / 100 epoch, with learning rate 41.06969024216348
[09/26 01:34:53 visual_prompt]: Epoch 36 / 100: avg data time: 4.05e-02, avg batch time: 0.4862, average train loss: 26.2171
[09/26 01:34:54 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1675, average loss: 22.7777
[09/26 01:34:54 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 4.00	
[09/26 01:34:54 visual_prompt]: Training 37 / 100 epoch, with learning rate 40.391536883141455
[09/26 01:35:01 visual_prompt]: Epoch 37 / 100: avg data time: 5.55e-02, avg batch time: 0.4996, average train loss: 21.4426
[09/26 01:35:03 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1675, average loss: 19.7797
[09/26 01:35:03 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 1.50	
[09/26 01:35:03 visual_prompt]: Training 38 / 100 epoch, with learning rate 39.69463130731183
[09/26 01:35:09 visual_prompt]: Epoch 38 / 100: avg data time: 4.09e-02, avg batch time: 0.4857, average train loss: 20.3394
[09/26 01:35:11 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1670, average loss: 18.3483
[09/26 01:35:11 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 4.00	
[09/26 01:35:11 visual_prompt]: Training 39 / 100 epoch, with learning rate 38.97982258676867
[09/26 01:35:17 visual_prompt]: Epoch 39 / 100: avg data time: 5.88e-02, avg batch time: 0.5026, average train loss: 18.5529
[09/26 01:35:19 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1670, average loss: 16.4120
[09/26 01:35:19 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 2.00	
[09/26 01:35:19 visual_prompt]: Training 40 / 100 epoch, with learning rate 38.24798160583012
[09/26 01:35:26 visual_prompt]: Epoch 40 / 100: avg data time: 5.84e-02, avg batch time: 0.5031, average train loss: 19.4969
[09/26 01:35:27 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1676, average loss: 18.4864
[09/26 01:35:27 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 2.50	
[09/26 01:35:27 visual_prompt]: Training 41 / 100 epoch, with learning rate 37.5
[09/26 01:35:34 visual_prompt]: Epoch 41 / 100: avg data time: 5.64e-02, avg batch time: 0.4992, average train loss: 20.8664
[09/26 01:35:35 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1674, average loss: 18.5978
[09/26 01:35:35 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 2.00	
[09/26 01:35:35 visual_prompt]: Training 42 / 100 epoch, with learning rate 36.736789069647266
[09/26 01:35:42 visual_prompt]: Epoch 42 / 100: avg data time: 4.90e-02, avg batch time: 0.4934, average train loss: 21.0701
[09/26 01:35:44 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1674, average loss: 16.9128
[09/26 01:35:44 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 4.00	
[09/26 01:35:44 visual_prompt]: Training 43 / 100 epoch, with learning rate 35.959278669726935
[09/26 01:35:50 visual_prompt]: Epoch 43 / 100: avg data time: 5.72e-02, avg batch time: 0.5020, average train loss: 18.7028
[09/26 01:35:52 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1677, average loss: 17.6474
[09/26 01:35:52 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.50	
[09/26 01:35:52 visual_prompt]: Training 44 / 100 epoch, with learning rate 35.16841607689501
[09/26 01:35:59 visual_prompt]: Epoch 44 / 100: avg data time: 4.91e-02, avg batch time: 0.4937, average train loss: 16.6128
[09/26 01:36:00 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1672, average loss: 15.6769
[09/26 01:36:00 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 1.50	
[09/26 01:36:00 visual_prompt]: Training 45 / 100 epoch, with learning rate 34.365164835397806
[09/26 01:36:07 visual_prompt]: Epoch 45 / 100: avg data time: 5.65e-02, avg batch time: 0.5017, average train loss: 17.8763
[09/26 01:36:08 visual_prompt]: Inference (val):avg data time: 3.92e-05, avg batch time: 0.1670, average loss: 17.7549
[09/26 01:36:08 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.50	
[09/26 01:36:08 visual_prompt]: Training 46 / 100 epoch, with learning rate 33.55050358314172
[09/26 01:36:15 visual_prompt]: Epoch 46 / 100: avg data time: 5.85e-02, avg batch time: 0.5023, average train loss: 16.6585
[09/26 01:36:17 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1674, average loss: 14.8109
[09/26 01:36:17 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 1.50	
[09/26 01:36:17 visual_prompt]: Training 47 / 100 epoch, with learning rate 32.72542485937369
[09/26 01:36:23 visual_prompt]: Epoch 47 / 100: avg data time: 4.73e-02, avg batch time: 0.4910, average train loss: 14.7951
[09/26 01:36:25 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1676, average loss: 12.1477
[09/26 01:36:25 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.00	
[09/26 01:36:25 visual_prompt]: Training 48 / 100 epoch, with learning rate 31.89093389542498
[09/26 01:36:31 visual_prompt]: Epoch 48 / 100: avg data time: 5.42e-02, avg batch time: 0.4985, average train loss: 15.0832
[09/26 01:36:33 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1674, average loss: 13.1500
[09/26 01:36:33 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 3.50	
[09/26 01:36:33 visual_prompt]: Training 49 / 100 epoch, with learning rate 31.04804738999169
[09/26 01:36:40 visual_prompt]: Epoch 49 / 100: avg data time: 5.62e-02, avg batch time: 0.4995, average train loss: 13.8819
[09/26 01:36:41 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1674, average loss: 13.1921
[09/26 01:36:41 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.00	
[09/26 01:36:41 visual_prompt]: Training 50 / 100 epoch, with learning rate 30.19779227044398
[09/26 01:36:48 visual_prompt]: Epoch 50 / 100: avg data time: 5.66e-02, avg batch time: 0.5001, average train loss: 14.0479
[09/26 01:36:49 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1672, average loss: 12.7724
[09/26 01:36:49 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.50	
[09/26 01:36:49 visual_prompt]: Training 51 / 100 epoch, with learning rate 29.341204441673263
[09/26 01:36:56 visual_prompt]: Epoch 51 / 100: avg data time: 5.31e-02, avg batch time: 0.4963, average train loss: 13.3042
[09/26 01:36:58 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1675, average loss: 14.4985
[09/26 01:36:58 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.50	
[09/26 01:36:58 visual_prompt]: Training 52 / 100 epoch, with learning rate 28.479327524001636
[09/26 01:37:04 visual_prompt]: Epoch 52 / 100: avg data time: 5.53e-02, avg batch time: 0.4981, average train loss: 13.0504
[09/26 01:37:06 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1672, average loss: 13.6232
[09/26 01:37:06 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.50	
[09/26 01:37:06 visual_prompt]: Training 53 / 100 epoch, with learning rate 27.61321158169134
[09/26 01:37:13 visual_prompt]: Epoch 53 / 100: avg data time: 5.38e-02, avg batch time: 0.4969, average train loss: 12.9265
[09/26 01:37:14 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1671, average loss: 11.8823
[09/26 01:37:14 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.00	
[09/26 01:37:14 visual_prompt]: Training 54 / 100 epoch, with learning rate 26.74391184360313
[09/26 01:37:21 visual_prompt]: Epoch 54 / 100: avg data time: 4.42e-02, avg batch time: 0.4895, average train loss: 12.4923
[09/26 01:37:22 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1677, average loss: 14.4339
[09/26 01:37:22 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 3.50	
[09/26 01:37:22 visual_prompt]: Training 55 / 100 epoch, with learning rate 25.872487417562528
[09/26 01:37:29 visual_prompt]: Epoch 55 / 100: avg data time: 5.81e-02, avg batch time: 0.5010, average train loss: 12.7534
[09/26 01:37:30 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1673, average loss: 12.5075
[09/26 01:37:30 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 1.50	
[09/26 01:37:30 visual_prompt]: Training 56 / 100 epoch, with learning rate 25.0
[09/26 01:37:37 visual_prompt]: Epoch 56 / 100: avg data time: 4.18e-02, avg batch time: 0.4848, average train loss: 12.8941
[09/26 01:37:38 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1676, average loss: 11.8339
[09/26 01:37:38 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 2.50	
[09/26 01:37:38 visual_prompt]: Training 57 / 100 epoch, with learning rate 24.127512582437483
[09/26 01:37:45 visual_prompt]: Epoch 57 / 100: avg data time: 5.84e-02, avg batch time: 0.5014, average train loss: 12.5817
[09/26 01:37:47 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1673, average loss: 11.9916
[09/26 01:37:47 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 1.00	
[09/26 01:37:47 visual_prompt]: Training 58 / 100 epoch, with learning rate 23.256088156396867
[09/26 01:37:54 visual_prompt]: Epoch 58 / 100: avg data time: 5.75e-02, avg batch time: 0.5008, average train loss: 11.5089
[09/26 01:37:55 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1676, average loss: 11.8917
[09/26 01:37:55 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 5.00	
[09/26 01:37:55 visual_prompt]: Training 59 / 100 epoch, with learning rate 22.38678841830867
[09/26 01:38:02 visual_prompt]: Epoch 59 / 100: avg data time: 5.35e-02, avg batch time: 0.4982, average train loss: 11.8656
[09/26 01:38:03 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1672, average loss: 12.7926
[09/26 01:38:03 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 1.50	
[09/26 01:38:03 visual_prompt]: Training 60 / 100 epoch, with learning rate 21.52067247599837
[09/26 01:38:10 visual_prompt]: Epoch 60 / 100: avg data time: 5.31e-02, avg batch time: 0.4967, average train loss: 11.7998
[09/26 01:38:11 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1674, average loss: 10.4734
[09/26 01:38:11 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/26 01:38:11 visual_prompt]: Training 61 / 100 epoch, with learning rate 20.65879555832674
[09/26 01:38:18 visual_prompt]: Epoch 61 / 100: avg data time: 5.72e-02, avg batch time: 0.5023, average train loss: 11.5451
[09/26 01:38:20 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1676, average loss: 11.3105
[09/26 01:38:20 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 3.00	
[09/26 01:38:20 visual_prompt]: Training 62 / 100 epoch, with learning rate 19.80220772955602
[09/26 01:38:27 visual_prompt]: Epoch 62 / 100: avg data time: 6.10e-02, avg batch time: 0.5047, average train loss: 11.1434
[09/26 01:38:28 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1678, average loss: 11.9166
[09/26 01:38:28 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 3.00	
[09/26 01:38:28 visual_prompt]: Training 63 / 100 epoch, with learning rate 18.95195261000831
[09/26 01:38:35 visual_prompt]: Epoch 63 / 100: avg data time: 4.96e-02, avg batch time: 0.4947, average train loss: 10.5666
[09/26 01:38:36 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1674, average loss: 11.5509
[09/26 01:38:36 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 5.50	
[09/26 01:38:36 visual_prompt]: Training 64 / 100 epoch, with learning rate 18.10906610457502
[09/26 01:38:43 visual_prompt]: Epoch 64 / 100: avg data time: 4.78e-02, avg batch time: 0.4915, average train loss: 10.8242
[09/26 01:38:44 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1679, average loss: 12.1006
[09/26 01:38:44 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 1.50	
[09/26 01:38:44 visual_prompt]: Training 65 / 100 epoch, with learning rate 17.274575140626318
[09/26 01:38:51 visual_prompt]: Epoch 65 / 100: avg data time: 5.19e-02, avg batch time: 0.4964, average train loss: 10.2620
[09/26 01:38:53 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1678, average loss: 10.6476
[09/26 01:38:53 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.50	
[09/26 01:38:53 visual_prompt]: Training 66 / 100 epoch, with learning rate 16.449496416858285
[09/26 01:38:59 visual_prompt]: Epoch 66 / 100: avg data time: 4.71e-02, avg batch time: 0.4910, average train loss: 10.1370
[09/26 01:39:01 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.1677, average loss: 10.7152
[09/26 01:39:01 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 1.00	
[09/26 01:39:01 visual_prompt]: Training 67 / 100 epoch, with learning rate 15.634835164602197
[09/26 01:39:08 visual_prompt]: Epoch 67 / 100: avg data time: 5.47e-02, avg batch time: 0.4989, average train loss: 10.2640
[09/26 01:39:09 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1674, average loss: 10.1946
[09/26 01:39:09 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 2.50	
[09/26 01:39:09 visual_prompt]: Training 68 / 100 epoch, with learning rate 14.831583923104999
[09/26 01:39:16 visual_prompt]: Epoch 68 / 100: avg data time: 5.99e-02, avg batch time: 0.5039, average train loss: 10.1439
[09/26 01:39:17 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1675, average loss: 11.3981
[09/26 01:39:17 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.50	
[09/26 01:39:17 visual_prompt]: Training 69 / 100 epoch, with learning rate 14.040721330273062
[09/26 01:39:24 visual_prompt]: Epoch 69 / 100: avg data time: 4.95e-02, avg batch time: 0.4941, average train loss: 9.9883
[09/26 01:39:25 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1673, average loss: 11.0382
[09/26 01:39:25 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 1.50	
[09/26 01:39:25 visual_prompt]: Training 70 / 100 epoch, with learning rate 13.263210930352736
[09/26 01:39:32 visual_prompt]: Epoch 70 / 100: avg data time: 4.00e-02, avg batch time: 0.4850, average train loss: 9.8904
[09/26 01:39:33 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1674, average loss: 11.1637
[09/26 01:39:34 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 3.00	
[09/26 01:39:34 visual_prompt]: Training 71 / 100 epoch, with learning rate 12.500000000000005
[09/26 01:39:40 visual_prompt]: Epoch 71 / 100: avg data time: 5.50e-02, avg batch time: 0.4995, average train loss: 9.7715
[09/26 01:39:42 visual_prompt]: Inference (val):avg data time: 4.22e-05, avg batch time: 0.1671, average loss: 10.7057
[09/26 01:39:42 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.50	
[09/26 01:39:42 visual_prompt]: Training 72 / 100 epoch, with learning rate 11.75201839416988
[09/26 01:39:48 visual_prompt]: Epoch 72 / 100: avg data time: 4.37e-02, avg batch time: 0.4885, average train loss: 9.7883
[09/26 01:39:50 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1674, average loss: 10.5083
[09/26 01:39:50 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.00	
[09/26 01:39:50 visual_prompt]: Training 73 / 100 epoch, with learning rate 11.020177413231332
[09/26 01:39:57 visual_prompt]: Epoch 73 / 100: avg data time: 5.79e-02, avg batch time: 0.5016, average train loss: 9.4457
[09/26 01:39:58 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1674, average loss: 9.9738
[09/26 01:39:58 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 2.50	
[09/26 01:39:58 visual_prompt]: Training 74 / 100 epoch, with learning rate 10.305368692688175
[09/26 01:40:05 visual_prompt]: Epoch 74 / 100: avg data time: 5.68e-02, avg batch time: 0.5008, average train loss: 9.4285
[09/26 01:40:06 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1673, average loss: 9.2025
[09/26 01:40:06 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 3.50	
[09/26 01:40:06 visual_prompt]: Training 75 / 100 epoch, with learning rate 9.608463116858543
[09/26 01:40:13 visual_prompt]: Epoch 75 / 100: avg data time: 5.48e-02, avg batch time: 0.4992, average train loss: 9.2991
[09/26 01:40:15 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1676, average loss: 11.5364
[09/26 01:40:15 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.00	
[09/26 01:40:15 visual_prompt]: Training 76 / 100 epoch, with learning rate 8.930309757836516
[09/26 01:40:22 visual_prompt]: Epoch 76 / 100: avg data time: 5.75e-02, avg batch time: 0.5001, average train loss: 9.1225
[09/26 01:40:23 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1675, average loss: 10.6306
[09/26 01:40:23 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 4.00	
[09/26 01:40:23 visual_prompt]: Training 77 / 100 epoch, with learning rate 8.271734841028552
[09/26 01:40:30 visual_prompt]: Epoch 77 / 100: avg data time: 4.65e-02, avg batch time: 0.4926, average train loss: 8.7304
[09/26 01:40:31 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1673, average loss: 9.6143
[09/26 01:40:31 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 1.50	
[09/26 01:40:31 visual_prompt]: Training 78 / 100 epoch, with learning rate 7.633540738525066
[09/26 01:40:38 visual_prompt]: Epoch 78 / 100: avg data time: 4.92e-02, avg batch time: 0.4935, average train loss: 8.9493
[09/26 01:40:39 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1674, average loss: 10.2431
[09/26 01:40:39 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 3.50	
[09/26 01:40:39 visual_prompt]: Training 79 / 100 epoch, with learning rate 7.016504991533726
[09/26 01:40:46 visual_prompt]: Epoch 79 / 100: avg data time: 4.52e-02, avg batch time: 0.4903, average train loss: 9.0183
[09/26 01:40:47 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1674, average loss: 9.8156
[09/26 01:40:47 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.50	
[09/26 01:40:47 visual_prompt]: Training 80 / 100 epoch, with learning rate 6.4213793630651415
[09/26 01:40:54 visual_prompt]: Epoch 80 / 100: avg data time: 5.67e-02, avg batch time: 0.5019, average train loss: 8.7393
[09/26 01:40:56 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1675, average loss: 9.9908
[09/26 01:40:56 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.00	
[09/26 01:40:56 visual_prompt]: Training 81 / 100 epoch, with learning rate 5.848888922025552
[09/26 01:41:03 visual_prompt]: Epoch 81 / 100: avg data time: 6.09e-02, avg batch time: 0.5054, average train loss: 8.5055
[09/26 01:41:04 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1677, average loss: 10.1303
[09/26 01:41:04 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/26 01:41:04 visual_prompt]: Training 82 / 100 epoch, with learning rate 5.2997311598319525
[09/26 01:41:11 visual_prompt]: Epoch 82 / 100: avg data time: 5.21e-02, avg batch time: 0.4951, average train loss: 8.8036
[09/26 01:41:12 visual_prompt]: Inference (val):avg data time: 3.38e-05, avg batch time: 0.1675, average loss: 9.6905
[09/26 01:41:12 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/26 01:41:12 visual_prompt]: Training 83 / 100 epoch, with learning rate 4.774575140626316
[09/26 01:41:19 visual_prompt]: Epoch 83 / 100: avg data time: 5.73e-02, avg batch time: 0.5004, average train loss: 8.4636
[09/26 01:41:21 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1678, average loss: 9.3373
[09/26 01:41:21 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 2.00	
[09/26 01:41:21 visual_prompt]: Training 84 / 100 epoch, with learning rate 4.27406068612396
[09/26 01:41:27 visual_prompt]: Epoch 84 / 100: avg data time: 4.70e-02, avg batch time: 0.4925, average train loss: 8.3319
[09/26 01:41:29 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1679, average loss: 10.1840
[09/26 01:41:29 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.50	
[09/26 01:41:29 visual_prompt]: Training 85 / 100 epoch, with learning rate 3.798797596089351
[09/26 01:41:36 visual_prompt]: Epoch 85 / 100: avg data time: 5.57e-02, avg batch time: 0.4993, average train loss: 8.2105
[09/26 01:41:37 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1672, average loss: 9.8845
[09/26 01:41:37 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 3.00	
[09/26 01:41:37 visual_prompt]: Training 86 / 100 epoch, with learning rate 3.349364905389032
[09/26 01:41:44 visual_prompt]: Epoch 86 / 100: avg data time: 5.55e-02, avg batch time: 0.4984, average train loss: 8.6408
[09/26 01:41:45 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1674, average loss: 9.7005
[09/26 01:41:45 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.00	
[09/26 01:41:45 visual_prompt]: Training 87 / 100 epoch, with learning rate 2.9263101785268253
[09/26 01:41:52 visual_prompt]: Epoch 87 / 100: avg data time: 5.79e-02, avg batch time: 0.5019, average train loss: 8.5207
[09/26 01:41:54 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1673, average loss: 9.8051
[09/26 01:41:54 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 3.50	
[09/26 01:41:54 visual_prompt]: Training 88 / 100 epoch, with learning rate 2.5301488425208296
[09/26 01:42:00 visual_prompt]: Epoch 88 / 100: avg data time: 5.68e-02, avg batch time: 0.5006, average train loss: 8.3904
[09/26 01:42:02 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1675, average loss: 10.0654
[09/26 01:42:02 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 3.00	
[09/26 01:42:02 visual_prompt]: Training 89 / 100 epoch, with learning rate 2.1613635589349753
[09/26 01:42:09 visual_prompt]: Epoch 89 / 100: avg data time: 5.71e-02, avg batch time: 0.5014, average train loss: 8.2399
[09/26 01:42:10 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1675, average loss: 10.1290
[09/26 01:42:10 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 3.00	
[09/26 01:42:10 visual_prompt]: Training 90 / 100 epoch, with learning rate 1.820403635830317
[09/26 01:42:17 visual_prompt]: Epoch 90 / 100: avg data time: 4.23e-02, avg batch time: 0.4870, average train loss: 8.2790
[09/26 01:42:18 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1676, average loss: 10.1871
[09/26 01:42:18 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 3.00	
[09/26 01:42:18 visual_prompt]: Training 91 / 100 epoch, with learning rate 1.507684480352292
[09/26 01:42:25 visual_prompt]: Epoch 91 / 100: avg data time: 4.19e-02, avg batch time: 0.4861, average train loss: 8.3415
[09/26 01:42:26 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1676, average loss: 10.0242
[09/26 01:42:26 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 3.50	
[09/26 01:42:26 visual_prompt]: Training 92 / 100 epoch, with learning rate 1.2235870926211616
[09/26 01:42:33 visual_prompt]: Epoch 92 / 100: avg data time: 5.55e-02, avg batch time: 0.4999, average train loss: 8.0787
[09/26 01:42:35 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.1679, average loss: 9.8215
[09/26 01:42:35 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 3.50	
[09/26 01:42:35 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.9684576015420276
[09/26 01:42:41 visual_prompt]: Epoch 93 / 100: avg data time: 5.04e-02, avg batch time: 0.4959, average train loss: 8.1096
[09/26 01:42:43 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1675, average loss: 9.7116
[09/26 01:42:43 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/26 01:42:43 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.7426068431000882
[09/26 01:42:50 visual_prompt]: Epoch 94 / 100: avg data time: 5.61e-02, avg batch time: 0.4998, average train loss: 8.0563
[09/26 01:42:51 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1675, average loss: 9.7844
[09/26 01:42:51 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.50	
[09/26 01:42:51 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.5463099816548578
[09/26 01:42:58 visual_prompt]: Epoch 95 / 100: avg data time: 5.93e-02, avg batch time: 0.5046, average train loss: 7.8252
[09/26 01:42:59 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1678, average loss: 9.7519
[09/26 01:42:59 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 3.50	
[09/26 01:42:59 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.3798061746947995
[09/26 01:43:06 visual_prompt]: Epoch 96 / 100: avg data time: 4.77e-02, avg batch time: 0.4914, average train loss: 8.0237
[09/26 01:43:08 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1674, average loss: 9.7543
[09/26 01:43:08 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 3.50	
[09/26 01:43:08 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.24329828146074095
[09/26 01:43:14 visual_prompt]: Epoch 97 / 100: avg data time: 3.86e-02, avg batch time: 0.4836, average train loss: 7.9474
[09/26 01:43:16 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1674, average loss: 9.7002
[09/26 01:43:16 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 4.00	
[09/26 01:43:16 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.13695261579316775
[09/26 01:43:22 visual_prompt]: Epoch 98 / 100: avg data time: 5.36e-02, avg batch time: 0.4974, average train loss: 8.2282
[09/26 01:43:24 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.1676, average loss: 9.7315
[09/26 01:43:24 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 4.00	
[09/26 01:43:24 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.06089874350439506
[09/26 01:43:31 visual_prompt]: Epoch 99 / 100: avg data time: 5.01e-02, avg batch time: 0.4948, average train loss: 8.0820
[09/26 01:43:32 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1674, average loss: 9.7389
[09/26 01:43:32 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 4.00	
[09/26 01:43:32 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.015229324522605947
[09/26 01:43:39 visual_prompt]: Epoch 100 / 100: avg data time: 4.67e-02, avg batch time: 0.4907, average train loss: 8.2517
[09/26 01:43:40 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1674, average loss: 9.7407
[09/26 01:43:40 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 4.00	
[09/26 01:43:40 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 01:43:40 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              0
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 01:43:40 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-sun397', 'DATA.NUMBER_CLASSES', '397', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 01:43:40 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 01:43:40 visual_prompt]: Training with config:
[09/26 01:43:40 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-sun397/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr25.0_wd0.01/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 25.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-sun397', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 397, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 01:43:40 visual_prompt]: Loading training data...
[09/26 01:43:40 visual_prompt]: Constructing vtab-sun397 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split train[:800], from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/26 01:43:42 visual_prompt]: Number of images: 800
[09/26 01:43:42 visual_prompt]: Number of classes: 309 / 397
[09/26 01:43:42 visual_prompt]: Loading validation data...
[09/26 01:43:42 visual_prompt]: Constructing vtab-sun397 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split validation[:200], from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/26 01:43:42 visual_prompt]: Number of images: 200
[09/26 01:43:42 visual_prompt]: Number of classes: 136 / 397
[09/26 01:43:42 visual_prompt]: Constructing models...
[09/26 01:43:44 visual_prompt]: Total Parameters: 86564749	 Gradient Parameters: 766093
[09/26 01:43:44 visual_prompt]: tuned percent:0.885
[09/26 01:43:44 visual_prompt]: Device used for model: 0
[09/26 01:43:44 visual_prompt]: Setting up Evaluator...
[09/26 01:43:44 visual_prompt]: Setting up Trainer...
[09/26 01:43:44 visual_prompt]: 	Setting up the optimizer...
[09/26 01:43:44 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 01:43:51 visual_prompt]: Epoch 1 / 100: avg data time: 5.59e-02, avg batch time: 0.5008, average train loss: 5.9875
[09/26 01:43:53 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1674, average loss: 6.0097
[09/26 01:43:53 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/26 01:43:53 visual_prompt]: Training 2 / 100 epoch, with learning rate 2.5
[09/26 01:43:59 visual_prompt]: Epoch 2 / 100: avg data time: 5.58e-02, avg batch time: 0.4991, average train loss: 5.7808
[09/26 01:44:01 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1675, average loss: 5.8725
[09/26 01:44:01 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.00	
[09/26 01:44:01 visual_prompt]: Best epoch 2: best metric: 0.005
[09/26 01:44:01 visual_prompt]: Training 3 / 100 epoch, with learning rate 5.0
[09/26 01:44:08 visual_prompt]: Epoch 3 / 100: avg data time: 5.69e-02, avg batch time: 0.5011, average train loss: 5.7883
[09/26 01:44:09 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1671, average loss: 5.8825
[09/26 01:44:09 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 2.50	
[09/26 01:44:09 visual_prompt]: Training 4 / 100 epoch, with learning rate 7.5
[09/26 01:44:16 visual_prompt]: Epoch 4 / 100: avg data time: 6.27e-02, avg batch time: 0.5058, average train loss: 5.8289
[09/26 01:44:18 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1674, average loss: 6.1398
[09/26 01:44:18 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 4.00	
[09/26 01:44:18 visual_prompt]: Best epoch 4: best metric: 0.015
[09/26 01:44:18 visual_prompt]: Training 5 / 100 epoch, with learning rate 10.0
[09/26 01:44:24 visual_prompt]: Epoch 5 / 100: avg data time: 5.67e-02, avg batch time: 0.4994, average train loss: 7.2621
[09/26 01:44:26 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1675, average loss: 6.7288
[09/26 01:44:26 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.50	
[09/26 01:44:26 visual_prompt]: Training 6 / 100 epoch, with learning rate 12.5
[09/26 01:44:33 visual_prompt]: Epoch 6 / 100: avg data time: 5.04e-02, avg batch time: 0.4950, average train loss: 7.9928
[09/26 01:44:34 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1672, average loss: 8.4756
[09/26 01:44:34 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 4.00	
[09/26 01:44:34 visual_prompt]: Training 7 / 100 epoch, with learning rate 15.0
[09/26 01:44:41 visual_prompt]: Epoch 7 / 100: avg data time: 5.45e-02, avg batch time: 0.4989, average train loss: 9.3317
[09/26 01:44:42 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1675, average loss: 8.1027
[09/26 01:44:42 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.00	
[09/26 01:44:42 visual_prompt]: Training 8 / 100 epoch, with learning rate 17.5
[09/26 01:44:49 visual_prompt]: Epoch 8 / 100: avg data time: 5.08e-02, avg batch time: 0.4952, average train loss: 10.1359
[09/26 01:44:51 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1677, average loss: 13.5030
[09/26 01:44:51 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.00	
[09/26 01:44:51 visual_prompt]: Training 9 / 100 epoch, with learning rate 20.0
[09/26 01:44:57 visual_prompt]: Epoch 9 / 100: avg data time: 5.63e-02, avg batch time: 0.4994, average train loss: 21.1235
[09/26 01:44:59 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1669, average loss: 20.2388
[09/26 01:44:59 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.00	
[09/26 01:44:59 visual_prompt]: Training 10 / 100 epoch, with learning rate 22.5
[09/26 01:45:06 visual_prompt]: Epoch 10 / 100: avg data time: 5.37e-02, avg batch time: 0.4963, average train loss: 27.9970
[09/26 01:45:07 visual_prompt]: Inference (val):avg data time: 3.55e-05, avg batch time: 0.1673, average loss: 25.3596
[09/26 01:45:07 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 1.00	
[09/26 01:45:07 visual_prompt]: Training 11 / 100 epoch, with learning rate 25.0
[09/26 01:45:14 visual_prompt]: Epoch 11 / 100: avg data time: 5.50e-02, avg batch time: 0.4977, average train loss: 33.5978
[09/26 01:45:15 visual_prompt]: Inference (val):avg data time: 2.00e-05, avg batch time: 0.1673, average loss: 32.9786
[09/26 01:45:15 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 3.00	
[09/26 01:45:15 visual_prompt]: Training 12 / 100 epoch, with learning rate 24.9923853377387
[09/26 01:45:22 visual_prompt]: Epoch 12 / 100: avg data time: 5.94e-02, avg batch time: 0.5027, average train loss: 32.9049
[09/26 01:45:23 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1669, average loss: 33.8498
[09/26 01:45:23 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 1.50	
[09/26 01:45:23 visual_prompt]: Training 13 / 100 epoch, with learning rate 24.969550628247802
[09/26 01:45:30 visual_prompt]: Epoch 13 / 100: avg data time: 5.07e-02, avg batch time: 0.4963, average train loss: 32.0304
[09/26 01:45:32 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1679, average loss: 29.6762
[09/26 01:45:32 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 2.50	
[09/26 01:45:32 visual_prompt]: Training 14 / 100 epoch, with learning rate 24.931523692103415
[09/26 01:45:38 visual_prompt]: Epoch 14 / 100: avg data time: 5.84e-02, avg batch time: 0.5012, average train loss: 38.6702
[09/26 01:45:40 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1675, average loss: 32.4958
[09/26 01:45:40 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 1.50	
[09/26 01:45:40 visual_prompt]: Training 15 / 100 epoch, with learning rate 24.87835085926963
[09/26 01:45:47 visual_prompt]: Epoch 15 / 100: avg data time: 5.11e-02, avg batch time: 0.4939, average train loss: 39.8478
[09/26 01:45:48 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1675, average loss: 130.3789
[09/26 01:45:48 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 2.50	
[09/26 01:45:48 visual_prompt]: Training 16 / 100 epoch, with learning rate 24.8100969126526
[09/26 01:45:55 visual_prompt]: Epoch 16 / 100: avg data time: 6.14e-02, avg batch time: 0.5050, average train loss: 43.6372
[09/26 01:45:56 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1673, average loss: 30.4950
[09/26 01:45:56 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.00	
[09/26 01:45:56 visual_prompt]: Training 17 / 100 epoch, with learning rate 24.72684500917257
[09/26 01:46:03 visual_prompt]: Epoch 17 / 100: avg data time: 5.60e-02, avg batch time: 0.5003, average train loss: 32.3455
[09/26 01:46:05 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1673, average loss: 36.8657
[09/26 01:46:05 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.00	
[09/26 01:46:05 visual_prompt]: Training 18 / 100 epoch, with learning rate 24.628696578449954
[09/26 01:46:12 visual_prompt]: Epoch 18 / 100: avg data time: 6.25e-02, avg batch time: 0.5068, average train loss: 37.4435
[09/26 01:46:13 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1675, average loss: 28.6611
[09/26 01:46:13 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 1.00	
[09/26 01:46:13 visual_prompt]: Training 19 / 100 epoch, with learning rate 24.515771199228986
[09/26 01:46:20 visual_prompt]: Epoch 19 / 100: avg data time: 5.12e-02, avg batch time: 0.4947, average train loss: 40.1993
[09/26 01:46:21 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1674, average loss: 29.9495
[09/26 01:46:21 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 1.00	
[09/26 01:46:21 visual_prompt]: Training 20 / 100 epoch, with learning rate 24.38820645368942
[09/26 01:46:28 visual_prompt]: Epoch 20 / 100: avg data time: 5.93e-02, avg batch time: 0.5024, average train loss: 41.9976
[09/26 01:46:30 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1677, average loss: 29.5491
[09/26 01:46:30 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 3.50	
[09/26 01:46:30 visual_prompt]: Training 21 / 100 epoch, with learning rate 24.246157759823856
[09/26 01:46:36 visual_prompt]: Epoch 21 / 100: avg data time: 5.16e-02, avg batch time: 0.4947, average train loss: 48.4243
[09/26 01:46:38 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1677, average loss: 32.7547
[09/26 01:46:38 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.00	top5: 3.00	
[09/26 01:46:38 visual_prompt]: Best epoch 21: best metric: 0.020
[09/26 01:46:38 visual_prompt]: Training 22 / 100 epoch, with learning rate 24.08979818208484
[09/26 01:46:45 visual_prompt]: Epoch 22 / 100: avg data time: 5.50e-02, avg batch time: 0.4989, average train loss: 45.0527
[09/26 01:46:46 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1676, average loss: 38.1668
[09/26 01:46:46 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 3.00	
[09/26 01:46:46 visual_prompt]: Training 23 / 100 epoch, with learning rate 23.91931822053251
[09/26 01:46:53 visual_prompt]: Epoch 23 / 100: avg data time: 5.69e-02, avg batch time: 0.5008, average train loss: 42.5855
[09/26 01:46:54 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1671, average loss: 36.6982
[09/26 01:46:54 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.00	
[09/26 01:46:54 visual_prompt]: Training 24 / 100 epoch, with learning rate 23.73492557873959
[09/26 01:47:01 visual_prompt]: Epoch 24 / 100: avg data time: 5.31e-02, avg batch time: 0.4976, average train loss: 45.9584
[09/26 01:47:02 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1676, average loss: 37.7758
[09/26 01:47:02 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 2.50	
[09/26 01:47:02 visual_prompt]: Training 25 / 100 epoch, with learning rate 23.536844910736587
[09/26 01:47:09 visual_prompt]: Epoch 25 / 100: avg data time: 5.39e-02, avg batch time: 0.4983, average train loss: 41.8600
[09/26 01:47:11 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1677, average loss: 68.4289
[09/26 01:47:11 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 2.50	
[09/26 01:47:11 visual_prompt]: Training 26 / 100 epoch, with learning rate 23.325317547305485
[09/26 01:47:18 visual_prompt]: Epoch 26 / 100: avg data time: 5.59e-02, avg batch time: 0.5004, average train loss: 50.3591
[09/26 01:47:19 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1675, average loss: 46.1258
[09/26 01:47:19 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 2.00	
[09/26 01:47:19 visual_prompt]: Training 27 / 100 epoch, with learning rate 23.100601201955325
[09/26 01:47:26 visual_prompt]: Epoch 27 / 100: avg data time: 4.83e-02, avg batch time: 0.4926, average train loss: 51.0824
[09/26 01:47:27 visual_prompt]: Inference (val):avg data time: 3.26e-05, avg batch time: 0.1673, average loss: 44.9679
[09/26 01:47:27 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 0.50	
[09/26 01:47:27 visual_prompt]: Training 28 / 100 epoch, with learning rate 22.86296965693802
[09/26 01:47:34 visual_prompt]: Epoch 28 / 100: avg data time: 5.57e-02, avg batch time: 0.4993, average train loss: 45.8866
[09/26 01:47:35 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1677, average loss: 42.7034
[09/26 01:47:35 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.00	
[09/26 01:47:35 visual_prompt]: Training 29 / 100 epoch, with learning rate 22.612712429686844
[09/26 01:47:42 visual_prompt]: Epoch 29 / 100: avg data time: 5.74e-02, avg batch time: 0.5007, average train loss: 42.2492
[09/26 01:47:44 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1677, average loss: 41.5375
[09/26 01:47:44 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 3.50	
[09/26 01:47:44 visual_prompt]: Training 30 / 100 epoch, with learning rate 22.35013442008402
[09/26 01:47:51 visual_prompt]: Epoch 30 / 100: avg data time: 5.86e-02, avg batch time: 0.5035, average train loss: 44.3032
[09/26 01:47:52 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1671, average loss: 41.6835
[09/26 01:47:52 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 3.00	
[09/26 01:47:52 visual_prompt]: Training 31 / 100 epoch, with learning rate 22.075555538987224
[09/26 01:47:59 visual_prompt]: Epoch 31 / 100: avg data time: 5.31e-02, avg batch time: 0.4965, average train loss: 43.5077
[09/26 01:48:00 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1674, average loss: 36.6785
[09/26 01:48:00 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 0.50	
[09/26 01:48:00 visual_prompt]: Training 32 / 100 epoch, with learning rate 21.78931031846743
[09/26 01:48:07 visual_prompt]: Epoch 32 / 100: avg data time: 5.80e-02, avg batch time: 0.5015, average train loss: 39.0002
[09/26 01:48:09 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1673, average loss: 47.6276
[09/26 01:48:09 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.50	
[09/26 01:48:09 visual_prompt]: Training 33 / 100 epoch, with learning rate 21.49174750423314
[09/26 01:48:15 visual_prompt]: Epoch 33 / 100: avg data time: 6.09e-02, avg batch time: 0.5063, average train loss: 35.1949
[09/26 01:48:17 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1675, average loss: 40.5512
[09/26 01:48:17 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 1.50	
[09/26 01:48:17 visual_prompt]: Training 34 / 100 epoch, with learning rate 21.183229630737465
[09/26 01:48:24 visual_prompt]: Epoch 34 / 100: avg data time: 4.72e-02, avg batch time: 0.4938, average train loss: 33.9210
[09/26 01:48:25 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1672, average loss: 31.4549
[09/26 01:48:25 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 1.00	
[09/26 01:48:25 visual_prompt]: Training 35 / 100 epoch, with learning rate 20.864132579485727
[09/26 01:48:32 visual_prompt]: Epoch 35 / 100: avg data time: 4.55e-02, avg batch time: 0.4897, average train loss: 31.2055
[09/26 01:48:33 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1675, average loss: 30.5124
[09/26 01:48:33 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/26 01:48:33 visual_prompt]: Training 36 / 100 epoch, with learning rate 20.53484512108174
[09/26 01:48:40 visual_prompt]: Epoch 36 / 100: avg data time: 4.74e-02, avg batch time: 0.4939, average train loss: 42.2133
[09/26 01:48:41 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1677, average loss: 39.9517
[09/26 01:48:41 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.00	
[09/26 01:48:41 visual_prompt]: Training 37 / 100 epoch, with learning rate 20.195768441570728
[09/26 01:48:48 visual_prompt]: Epoch 37 / 100: avg data time: 5.67e-02, avg batch time: 0.5001, average train loss: 45.2025
[09/26 01:48:50 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1672, average loss: 41.5332
[09/26 01:48:50 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 3.00	
[09/26 01:48:50 visual_prompt]: Training 38 / 100 epoch, with learning rate 19.847315653655915
[09/26 01:48:57 visual_prompt]: Epoch 38 / 100: avg data time: 5.73e-02, avg batch time: 0.5000, average train loss: 46.8689
[09/26 01:48:58 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1673, average loss: 44.1832
[09/26 01:48:58 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.00	
[09/26 01:48:58 visual_prompt]: Training 39 / 100 epoch, with learning rate 19.489911293384335
[09/26 01:49:05 visual_prompt]: Epoch 39 / 100: avg data time: 5.44e-02, avg batch time: 0.4989, average train loss: 46.8469
[09/26 01:49:06 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1673, average loss: 46.9706
[09/26 01:49:06 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 0.00	
[09/26 01:49:06 visual_prompt]: Training 40 / 100 epoch, with learning rate 19.12399080291506
[09/26 01:49:13 visual_prompt]: Epoch 40 / 100: avg data time: 6.13e-02, avg batch time: 0.5046, average train loss: 43.3638
[09/26 01:49:15 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1674, average loss: 44.3028
[09/26 01:49:15 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 2.00	
[09/26 01:49:15 visual_prompt]: Training 41 / 100 epoch, with learning rate 18.75
[09/26 01:49:21 visual_prompt]: Epoch 41 / 100: avg data time: 5.63e-02, avg batch time: 0.4997, average train loss: 40.7683
[09/26 01:49:23 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1675, average loss: 57.4999
[09/26 01:49:23 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 0.00	
[09/26 01:49:23 visual_prompt]: Training 42 / 100 epoch, with learning rate 18.368394534823633
[09/26 01:49:30 visual_prompt]: Epoch 42 / 100: avg data time: 6.12e-02, avg batch time: 0.5049, average train loss: 40.0963
[09/26 01:49:31 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1672, average loss: 34.2375
[09/26 01:49:31 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.00	
[09/26 01:49:31 visual_prompt]: Training 43 / 100 epoch, with learning rate 17.979639334863467
[09/26 01:49:38 visual_prompt]: Epoch 43 / 100: avg data time: 5.74e-02, avg batch time: 0.5004, average train loss: 35.6439
[09/26 01:49:40 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1674, average loss: 31.6729
[09/26 01:49:40 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 1.50	
[09/26 01:49:40 visual_prompt]: Training 44 / 100 epoch, with learning rate 17.584208038447503
[09/26 01:49:46 visual_prompt]: Epoch 44 / 100: avg data time: 5.93e-02, avg batch time: 0.5037, average train loss: 32.8958
[09/26 01:49:48 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1670, average loss: 31.6496
[09/26 01:49:48 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 1.50	
[09/26 01:49:48 visual_prompt]: Training 45 / 100 epoch, with learning rate 17.182582417698903
[09/26 01:49:55 visual_prompt]: Epoch 45 / 100: avg data time: 5.45e-02, avg batch time: 0.4976, average train loss: 31.3050
[09/26 01:49:56 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1673, average loss: 28.8369
[09/26 01:49:56 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.50	
[09/26 01:49:56 visual_prompt]: Training 46 / 100 epoch, with learning rate 16.77525179157086
[09/26 01:50:03 visual_prompt]: Epoch 46 / 100: avg data time: 4.79e-02, avg batch time: 0.4934, average train loss: 31.4685
[09/26 01:50:04 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1673, average loss: 29.9461
[09/26 01:50:04 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/26 01:50:04 visual_prompt]: Training 47 / 100 epoch, with learning rate 16.362712429686844
[09/26 01:50:11 visual_prompt]: Epoch 47 / 100: avg data time: 6.06e-02, avg batch time: 0.5037, average train loss: 33.9421
[09/26 01:50:13 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1673, average loss: 25.8916
[09/26 01:50:13 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.00	
[09/26 01:50:13 visual_prompt]: Training 48 / 100 epoch, with learning rate 15.94546694771249
[09/26 01:50:19 visual_prompt]: Epoch 48 / 100: avg data time: 5.56e-02, avg batch time: 0.4980, average train loss: 26.6875
[09/26 01:50:21 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1674, average loss: 22.6887
[09/26 01:50:21 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 2.00	
[09/26 01:50:21 visual_prompt]: Training 49 / 100 epoch, with learning rate 15.524023694995845
[09/26 01:50:27 visual_prompt]: Epoch 49 / 100: avg data time: 5.42e-02, avg batch time: 0.4980, average train loss: 25.9439
[09/26 01:50:29 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1672, average loss: 25.8356
[09/26 01:50:29 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.00	
[09/26 01:50:29 visual_prompt]: Training 50 / 100 epoch, with learning rate 15.09889613522199
[09/26 01:50:36 visual_prompt]: Epoch 50 / 100: avg data time: 4.75e-02, avg batch time: 0.4907, average train loss: 33.7715
[09/26 01:50:37 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1673, average loss: 19.9708
[09/26 01:50:37 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 01:50:37 visual_prompt]: Training 51 / 100 epoch, with learning rate 14.670602220836631
[09/26 01:50:44 visual_prompt]: Epoch 51 / 100: avg data time: 5.67e-02, avg batch time: 0.4996, average train loss: 29.7277
[09/26 01:50:45 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1673, average loss: 19.9745
[09/26 01:50:45 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.50	
[09/26 01:50:45 visual_prompt]: Training 52 / 100 epoch, with learning rate 14.239663762000818
[09/26 01:50:52 visual_prompt]: Epoch 52 / 100: avg data time: 5.63e-02, avg batch time: 0.5002, average train loss: 29.0449
[09/26 01:50:54 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1674, average loss: 20.5254
[09/26 01:50:54 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.50	
[09/26 01:50:54 visual_prompt]: Training 53 / 100 epoch, with learning rate 13.80660579084567
[09/26 01:51:00 visual_prompt]: Epoch 53 / 100: avg data time: 5.15e-02, avg batch time: 0.4949, average train loss: 27.8649
[09/26 01:51:02 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1670, average loss: 20.1361
[09/26 01:51:02 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.50	
[09/26 01:51:02 visual_prompt]: Training 54 / 100 epoch, with learning rate 13.371955921801565
[09/26 01:51:09 visual_prompt]: Epoch 54 / 100: avg data time: 5.87e-02, avg batch time: 0.5020, average train loss: 26.2743
[09/26 01:51:10 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1669, average loss: 19.2352
[09/26 01:51:10 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.50	
[09/26 01:51:10 visual_prompt]: Training 55 / 100 epoch, with learning rate 12.936243708781264
[09/26 01:51:17 visual_prompt]: Epoch 55 / 100: avg data time: 6.15e-02, avg batch time: 0.5047, average train loss: 23.5655
[09/26 01:51:19 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1675, average loss: 16.4112
[09/26 01:51:19 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.50	
[09/26 01:51:19 visual_prompt]: Training 56 / 100 epoch, with learning rate 12.5
[09/26 01:51:25 visual_prompt]: Epoch 56 / 100: avg data time: 5.63e-02, avg batch time: 0.5001, average train loss: 19.8373
[09/26 01:51:27 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1674, average loss: 14.8637
[09/26 01:51:27 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 3.00	
[09/26 01:51:27 visual_prompt]: Training 57 / 100 epoch, with learning rate 12.063756291218741
[09/26 01:51:34 visual_prompt]: Epoch 57 / 100: avg data time: 5.56e-02, avg batch time: 0.4985, average train loss: 17.5633
[09/26 01:51:35 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1677, average loss: 13.6002
[09/26 01:51:35 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.50	
[09/26 01:51:35 visual_prompt]: Training 58 / 100 epoch, with learning rate 11.628044078198434
[09/26 01:51:42 visual_prompt]: Epoch 58 / 100: avg data time: 5.68e-02, avg batch time: 0.4998, average train loss: 16.1528
[09/26 01:51:43 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1675, average loss: 14.4840
[09/26 01:51:43 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 2.00	
[09/26 01:51:43 visual_prompt]: Training 59 / 100 epoch, with learning rate 11.193394209154334
[09/26 01:51:50 visual_prompt]: Epoch 59 / 100: avg data time: 4.57e-02, avg batch time: 0.4912, average train loss: 16.3364
[09/26 01:51:51 visual_prompt]: Inference (val):avg data time: 2.08e-05, avg batch time: 0.1674, average loss: 14.4822
[09/26 01:51:51 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 2.50	
[09/26 01:51:51 visual_prompt]: Training 60 / 100 epoch, with learning rate 10.760336237999185
[09/26 01:51:58 visual_prompt]: Epoch 60 / 100: avg data time: 5.99e-02, avg batch time: 0.5032, average train loss: 16.0900
[09/26 01:52:00 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1672, average loss: 14.9713
[09/26 01:52:00 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 5.00	
[09/26 01:52:00 visual_prompt]: Training 61 / 100 epoch, with learning rate 10.32939777916337
[09/26 01:52:06 visual_prompt]: Epoch 61 / 100: avg data time: 5.21e-02, avg batch time: 0.4949, average train loss: 17.1846
[09/26 01:52:08 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1674, average loss: 13.3639
[09/26 01:52:08 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 4.00	
[09/26 01:52:08 visual_prompt]: Training 62 / 100 epoch, with learning rate 9.90110386477801
[09/26 01:52:15 visual_prompt]: Epoch 62 / 100: avg data time: 5.70e-02, avg batch time: 0.5011, average train loss: 15.3880
[09/26 01:52:16 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1671, average loss: 12.7301
[09/26 01:52:16 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.50	
[09/26 01:52:16 visual_prompt]: Training 63 / 100 epoch, with learning rate 9.475976305004155
[09/26 01:52:23 visual_prompt]: Epoch 63 / 100: avg data time: 5.41e-02, avg batch time: 0.4988, average train loss: 15.1111
[09/26 01:52:24 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1674, average loss: 14.3611
[09/26 01:52:24 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 3.50	
[09/26 01:52:24 visual_prompt]: Training 64 / 100 epoch, with learning rate 9.05453305228751
[09/26 01:52:31 visual_prompt]: Epoch 64 / 100: avg data time: 5.05e-02, avg batch time: 0.4946, average train loss: 17.2905
[09/26 01:52:33 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1672, average loss: 12.2369
[09/26 01:52:33 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 2.00	
[09/26 01:52:33 visual_prompt]: Training 65 / 100 epoch, with learning rate 8.637287570313159
[09/26 01:52:39 visual_prompt]: Epoch 65 / 100: avg data time: 5.47e-02, avg batch time: 0.4977, average train loss: 16.4702
[09/26 01:52:41 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1674, average loss: 11.4716
[09/26 01:52:41 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.50	
[09/26 01:52:41 visual_prompt]: Training 66 / 100 epoch, with learning rate 8.224748208429142
[09/26 01:52:48 visual_prompt]: Epoch 66 / 100: avg data time: 5.39e-02, avg batch time: 0.4972, average train loss: 19.2327
[09/26 01:52:49 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1673, average loss: 12.6446
[09/26 01:52:49 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.00	
[09/26 01:52:49 visual_prompt]: Training 67 / 100 epoch, with learning rate 7.817417582301099
[09/26 01:52:56 visual_prompt]: Epoch 67 / 100: avg data time: 5.34e-02, avg batch time: 0.4968, average train loss: 17.4524
[09/26 01:52:57 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1674, average loss: 11.9941
[09/26 01:52:57 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.00	
[09/26 01:52:57 visual_prompt]: Training 68 / 100 epoch, with learning rate 7.415791961552499
[09/26 01:53:04 visual_prompt]: Epoch 68 / 100: avg data time: 5.20e-02, avg batch time: 0.4961, average train loss: 16.9977
[09/26 01:53:05 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1675, average loss: 12.3488
[09/26 01:53:05 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 2.00	
[09/26 01:53:05 visual_prompt]: Training 69 / 100 epoch, with learning rate 7.020360665136531
[09/26 01:53:12 visual_prompt]: Epoch 69 / 100: avg data time: 4.65e-02, avg batch time: 0.4906, average train loss: 17.2017
[09/26 01:53:14 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1669, average loss: 10.8107
[09/26 01:53:14 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 1.50	
[09/26 01:53:14 visual_prompt]: Training 70 / 100 epoch, with learning rate 6.631605465176368
[09/26 01:53:20 visual_prompt]: Epoch 70 / 100: avg data time: 5.43e-02, avg batch time: 0.4972, average train loss: 15.8107
[09/26 01:53:22 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1671, average loss: 10.1916
[09/26 01:53:22 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 2.00	
[09/26 01:53:22 visual_prompt]: Training 71 / 100 epoch, with learning rate 6.250000000000003
[09/26 01:53:29 visual_prompt]: Epoch 71 / 100: avg data time: 5.88e-02, avg batch time: 0.5012, average train loss: 14.0246
[09/26 01:53:30 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1671, average loss: 8.6782
[09/26 01:53:30 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.50	
[09/26 01:53:30 visual_prompt]: Training 72 / 100 epoch, with learning rate 5.87600919708494
[09/26 01:53:37 visual_prompt]: Epoch 72 / 100: avg data time: 6.35e-02, avg batch time: 0.5063, average train loss: 17.3472
[09/26 01:53:38 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1675, average loss: 9.1679
[09/26 01:53:39 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 2.00	
[09/26 01:53:39 visual_prompt]: Training 73 / 100 epoch, with learning rate 5.510088706615666
[09/26 01:53:45 visual_prompt]: Epoch 73 / 100: avg data time: 4.66e-02, avg batch time: 0.4923, average train loss: 14.5387
[09/26 01:53:47 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1671, average loss: 9.4096
[09/26 01:53:47 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/26 01:53:47 visual_prompt]: Training 74 / 100 epoch, with learning rate 5.1526843463440875
[09/26 01:53:53 visual_prompt]: Epoch 74 / 100: avg data time: 5.14e-02, avg batch time: 0.4945, average train loss: 12.2195
[09/26 01:53:55 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1671, average loss: 8.3978
[09/26 01:53:55 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.00	
[09/26 01:53:55 visual_prompt]: Training 75 / 100 epoch, with learning rate 4.804231558429271
[09/26 01:54:02 visual_prompt]: Epoch 75 / 100: avg data time: 4.47e-02, avg batch time: 0.4905, average train loss: 11.1290
[09/26 01:54:03 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1671, average loss: 8.3885
[09/26 01:54:03 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 3.00	
[09/26 01:54:03 visual_prompt]: Training 76 / 100 epoch, with learning rate 4.465154878918258
[09/26 01:54:10 visual_prompt]: Epoch 76 / 100: avg data time: 5.18e-02, avg batch time: 0.4960, average train loss: 10.2985
[09/26 01:54:11 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1670, average loss: 7.8790
[09/26 01:54:11 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 01:54:11 visual_prompt]: Training 77 / 100 epoch, with learning rate 4.135867420514276
[09/26 01:54:18 visual_prompt]: Epoch 77 / 100: avg data time: 6.25e-02, avg batch time: 0.5054, average train loss: 10.1338
[09/26 01:54:20 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1676, average loss: 7.8092
[09/26 01:54:20 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.00	
[09/26 01:54:20 visual_prompt]: Training 78 / 100 epoch, with learning rate 3.816770369262533
[09/26 01:54:26 visual_prompt]: Epoch 78 / 100: avg data time: 5.37e-02, avg batch time: 0.4982, average train loss: 9.5173
[09/26 01:54:28 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1674, average loss: 7.3658
[09/26 01:54:28 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 5.00	
[09/26 01:54:28 visual_prompt]: Training 79 / 100 epoch, with learning rate 3.508252495766863
[09/26 01:54:34 visual_prompt]: Epoch 79 / 100: avg data time: 4.73e-02, avg batch time: 0.4916, average train loss: 9.0467
[09/26 01:54:36 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1670, average loss: 7.2840
[09/26 01:54:36 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 3.50	
[09/26 01:54:36 visual_prompt]: Training 80 / 100 epoch, with learning rate 3.2106896815325707
[09/26 01:54:42 visual_prompt]: Epoch 80 / 100: avg data time: 4.26e-02, avg batch time: 0.4862, average train loss: 8.8374
[09/26 01:54:44 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1671, average loss: 7.2778
[09/26 01:54:44 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 3.00	
[09/26 01:54:44 visual_prompt]: Training 81 / 100 epoch, with learning rate 2.924444461012776
[09/26 01:54:51 visual_prompt]: Epoch 81 / 100: avg data time: 6.36e-02, avg batch time: 0.5057, average train loss: 8.6992
[09/26 01:54:52 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1669, average loss: 7.1483
[09/26 01:54:52 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.00	
[09/26 01:54:52 visual_prompt]: Training 82 / 100 epoch, with learning rate 2.6498655799159763
[09/26 01:54:59 visual_prompt]: Epoch 82 / 100: avg data time: 5.56e-02, avg batch time: 0.4995, average train loss: 8.4464
[09/26 01:55:00 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1670, average loss: 7.0917
[09/26 01:55:00 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 2.50	
[09/26 01:55:00 visual_prompt]: Training 83 / 100 epoch, with learning rate 2.387287570313158
[09/26 01:55:07 visual_prompt]: Epoch 83 / 100: avg data time: 5.81e-02, avg batch time: 0.5007, average train loss: 8.1973
[09/26 01:55:09 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1669, average loss: 6.9807
[09/26 01:55:09 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 3.50	
[09/26 01:55:09 visual_prompt]: Training 84 / 100 epoch, with learning rate 2.13703034306198
[09/26 01:55:15 visual_prompt]: Epoch 84 / 100: avg data time: 5.83e-02, avg batch time: 0.5007, average train loss: 8.0244
[09/26 01:55:17 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1675, average loss: 6.8397
[09/26 01:55:17 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.50	
[09/26 01:55:17 visual_prompt]: Training 85 / 100 epoch, with learning rate 1.8993987980446756
[09/26 01:55:24 visual_prompt]: Epoch 85 / 100: avg data time: 4.72e-02, avg batch time: 0.4908, average train loss: 7.9119
[09/26 01:55:25 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1672, average loss: 6.7696
[09/26 01:55:25 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 5.00	
[09/26 01:55:25 visual_prompt]: Training 86 / 100 epoch, with learning rate 1.674682452694516
[09/26 01:55:32 visual_prompt]: Epoch 86 / 100: avg data time: 6.19e-02, avg batch time: 0.5042, average train loss: 7.7414
[09/26 01:55:33 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1670, average loss: 6.7038
[09/26 01:55:33 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 3.50	
[09/26 01:55:33 visual_prompt]: Training 87 / 100 epoch, with learning rate 1.4631550892634126
[09/26 01:55:40 visual_prompt]: Epoch 87 / 100: avg data time: 5.60e-02, avg batch time: 0.4983, average train loss: 7.6349
[09/26 01:55:42 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1667, average loss: 6.7398
[09/26 01:55:42 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.00	
[09/26 01:55:42 visual_prompt]: Training 88 / 100 epoch, with learning rate 1.2650744212604148
[09/26 01:55:48 visual_prompt]: Epoch 88 / 100: avg data time: 4.75e-02, avg batch time: 0.4903, average train loss: 7.6086
[09/26 01:55:50 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1668, average loss: 6.5815
[09/26 01:55:50 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 3.50	
[09/26 01:55:50 visual_prompt]: Training 89 / 100 epoch, with learning rate 1.0806817794674877
[09/26 01:55:57 visual_prompt]: Epoch 89 / 100: avg data time: 5.53e-02, avg batch time: 0.5005, average train loss: 7.4771
[09/26 01:55:58 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1672, average loss: 6.6980
[09/26 01:55:58 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 5.00	
[09/26 01:55:58 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.9102018179151585
[09/26 01:56:05 visual_prompt]: Epoch 90 / 100: avg data time: 5.27e-02, avg batch time: 0.4965, average train loss: 7.4465
[09/26 01:56:06 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1671, average loss: 6.5861
[09/26 01:56:06 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 5.00	
[09/26 01:56:06 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.753842240176146
[09/26 01:56:13 visual_prompt]: Epoch 91 / 100: avg data time: 5.45e-02, avg batch time: 0.4977, average train loss: 7.4263
[09/26 01:56:15 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.1671, average loss: 6.5674
[09/26 01:56:15 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 01:56:15 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.6117935463105808
[09/26 01:56:21 visual_prompt]: Epoch 92 / 100: avg data time: 4.91e-02, avg batch time: 0.4918, average train loss: 7.3555
[09/26 01:56:23 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1674, average loss: 6.5778
[09/26 01:56:23 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 01:56:23 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.4842288007710138
[09/26 01:56:29 visual_prompt]: Epoch 93 / 100: avg data time: 5.05e-02, avg batch time: 0.4925, average train loss: 7.3410
[09/26 01:56:31 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1673, average loss: 6.5405
[09/26 01:56:31 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 01:56:31 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.3713034215500441
[09/26 01:56:38 visual_prompt]: Epoch 94 / 100: avg data time: 5.46e-02, avg batch time: 0.4971, average train loss: 7.3175
[09/26 01:56:39 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1670, average loss: 6.5483
[09/26 01:56:39 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.50	
[09/26 01:56:39 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.2731549908274289
[09/26 01:56:46 visual_prompt]: Epoch 95 / 100: avg data time: 5.55e-02, avg batch time: 0.4976, average train loss: 7.3011
[09/26 01:56:47 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1668, average loss: 6.5347
[09/26 01:56:47 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 01:56:47 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.18990308734739975
[09/26 01:56:54 visual_prompt]: Epoch 96 / 100: avg data time: 4.94e-02, avg batch time: 0.4916, average train loss: 7.2844
[09/26 01:56:55 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1670, average loss: 6.5292
[09/26 01:56:55 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 5.00	
[09/26 01:56:55 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.12164914073037048
[09/26 01:57:02 visual_prompt]: Epoch 97 / 100: avg data time: 4.46e-02, avg batch time: 0.4901, average train loss: 7.2606
[09/26 01:57:04 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1672, average loss: 6.5240
[09/26 01:57:04 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 4.50	
[09/26 01:57:04 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.06847630789658388
[09/26 01:57:10 visual_prompt]: Epoch 98 / 100: avg data time: 5.26e-02, avg batch time: 0.4960, average train loss: 7.2285
[09/26 01:57:12 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1674, average loss: 6.5063
[09/26 01:57:12 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 5.00	
[09/26 01:57:12 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.03044937175219753
[09/26 01:57:19 visual_prompt]: Epoch 99 / 100: avg data time: 6.32e-02, avg batch time: 0.5054, average train loss: 7.1862
[09/26 01:57:20 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1672, average loss: 6.4987
[09/26 01:57:20 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 01:57:20 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0076146622613029735
[09/26 01:57:27 visual_prompt]: Epoch 100 / 100: avg data time: 5.84e-02, avg batch time: 0.5013, average train loss: 7.1456
[09/26 01:57:28 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1674, average loss: 6.4938
[09/26 01:57:28 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 01:57:28 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 01:57:28 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              0
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 01:57:28 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-sun397', 'DATA.NUMBER_CLASSES', '397', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 01:57:28 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 01:57:28 visual_prompt]: Training with config:
[09/26 01:57:28 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-sun397/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr25.0_wd0.001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 25.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-sun397', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 397, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 01:57:28 visual_prompt]: Loading training data...
[09/26 01:57:28 visual_prompt]: Constructing vtab-sun397 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split train[:800], from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/26 01:57:30 visual_prompt]: Number of images: 800
[09/26 01:57:30 visual_prompt]: Number of classes: 309 / 397
[09/26 01:57:30 visual_prompt]: Loading validation data...
[09/26 01:57:30 visual_prompt]: Constructing vtab-sun397 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split validation[:200], from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/26 01:57:30 visual_prompt]: Number of images: 200
[09/26 01:57:30 visual_prompt]: Number of classes: 136 / 397
[09/26 01:57:30 visual_prompt]: Constructing models...
[09/26 01:57:33 visual_prompt]: Total Parameters: 86564749	 Gradient Parameters: 766093
[09/26 01:57:33 visual_prompt]: tuned percent:0.885
[09/26 01:57:33 visual_prompt]: Device used for model: 0
[09/26 01:57:33 visual_prompt]: Setting up Evaluator...
[09/26 01:57:33 visual_prompt]: Setting up Trainer...
[09/26 01:57:33 visual_prompt]: 	Setting up the optimizer...
[09/26 01:57:33 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 01:57:40 visual_prompt]: Epoch 1 / 100: avg data time: 5.70e-02, avg batch time: 0.5006, average train loss: 5.9902
[09/26 01:57:41 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1676, average loss: 6.0097
[09/26 01:57:41 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/26 01:57:41 visual_prompt]: Training 2 / 100 epoch, with learning rate 2.5
[09/26 01:57:48 visual_prompt]: Epoch 2 / 100: avg data time: 5.81e-02, avg batch time: 0.4999, average train loss: 5.7911
[09/26 01:57:49 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1679, average loss: 6.0626
[09/26 01:57:49 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.00	
[09/26 01:57:49 visual_prompt]: Best epoch 2: best metric: 0.010
[09/26 01:57:49 visual_prompt]: Training 3 / 100 epoch, with learning rate 5.0
[09/26 01:57:56 visual_prompt]: Epoch 3 / 100: avg data time: 5.95e-02, avg batch time: 0.5031, average train loss: 5.8163
[09/26 01:57:58 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1677, average loss: 6.0689
[09/26 01:57:58 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 2.00	
[09/26 01:57:58 visual_prompt]: Training 4 / 100 epoch, with learning rate 7.5
[09/26 01:58:04 visual_prompt]: Epoch 4 / 100: avg data time: 6.05e-02, avg batch time: 0.5039, average train loss: 5.9236
[09/26 01:58:06 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1679, average loss: 6.0065
[09/26 01:58:06 visual_prompt]: Classification results with val_vtab-sun397: top1: 3.00	top5: 5.00	
[09/26 01:58:06 visual_prompt]: Best epoch 4: best metric: 0.030
[09/26 01:58:06 visual_prompt]: Training 5 / 100 epoch, with learning rate 10.0
[09/26 01:58:13 visual_prompt]: Epoch 5 / 100: avg data time: 6.40e-02, avg batch time: 0.5064, average train loss: 6.3024
[09/26 01:58:14 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1673, average loss: 7.0182
[09/26 01:58:14 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 5.50	
[09/26 01:58:14 visual_prompt]: Training 6 / 100 epoch, with learning rate 12.5
[09/26 01:58:21 visual_prompt]: Epoch 6 / 100: avg data time: 5.23e-02, avg batch time: 0.4942, average train loss: 7.4916
[09/26 01:58:23 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1677, average loss: 7.3281
[09/26 01:58:23 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.50	top5: 3.50	
[09/26 01:58:23 visual_prompt]: Training 7 / 100 epoch, with learning rate 15.0
[09/26 01:58:29 visual_prompt]: Epoch 7 / 100: avg data time: 6.01e-02, avg batch time: 0.5021, average train loss: 9.5085
[09/26 01:58:31 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1673, average loss: 9.8546
[09/26 01:58:31 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/26 01:58:31 visual_prompt]: Training 8 / 100 epoch, with learning rate 17.5
[09/26 01:58:38 visual_prompt]: Epoch 8 / 100: avg data time: 5.60e-02, avg batch time: 0.4984, average train loss: 13.9203
[09/26 01:58:39 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1672, average loss: 13.3837
[09/26 01:58:39 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 3.50	
[09/26 01:58:39 visual_prompt]: Training 9 / 100 epoch, with learning rate 20.0
[09/26 01:58:46 visual_prompt]: Epoch 9 / 100: avg data time: 5.66e-02, avg batch time: 0.4997, average train loss: 20.2108
[09/26 01:58:48 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1674, average loss: 18.9794
[09/26 01:58:48 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 6.50	
[09/26 01:58:48 visual_prompt]: Training 10 / 100 epoch, with learning rate 22.5
[09/26 01:58:54 visual_prompt]: Epoch 10 / 100: avg data time: 4.41e-02, avg batch time: 0.4876, average train loss: 44.0107
[09/26 01:58:56 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1675, average loss: 27.8904
[09/26 01:58:56 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 1.50	
[09/26 01:58:56 visual_prompt]: Training 11 / 100 epoch, with learning rate 25.0
[09/26 01:59:02 visual_prompt]: Epoch 11 / 100: avg data time: 5.71e-02, avg batch time: 0.4991, average train loss: 34.8302
[09/26 01:59:04 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1676, average loss: 21.8076
[09/26 01:59:04 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 2.50	
[09/26 01:59:04 visual_prompt]: Training 12 / 100 epoch, with learning rate 24.9923853377387
[09/26 01:59:11 visual_prompt]: Epoch 12 / 100: avg data time: 5.53e-02, avg batch time: 0.4989, average train loss: 39.0793
[09/26 01:59:12 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1674, average loss: 37.8505
[09/26 01:59:12 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.50	
[09/26 01:59:12 visual_prompt]: Training 13 / 100 epoch, with learning rate 24.969550628247802
[09/26 01:59:19 visual_prompt]: Epoch 13 / 100: avg data time: 6.06e-02, avg batch time: 0.5040, average train loss: 48.9058
[09/26 01:59:21 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1674, average loss: 32.0247
[09/26 01:59:21 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 2.50	
[09/26 01:59:21 visual_prompt]: Training 14 / 100 epoch, with learning rate 24.931523692103415
[09/26 01:59:27 visual_prompt]: Epoch 14 / 100: avg data time: 4.79e-02, avg batch time: 0.4937, average train loss: 44.5422
[09/26 01:59:29 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1679, average loss: 34.4599
[09/26 01:59:29 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 0.00	
[09/26 01:59:29 visual_prompt]: Training 15 / 100 epoch, with learning rate 24.87835085926963
[09/26 01:59:36 visual_prompt]: Epoch 15 / 100: avg data time: 4.55e-02, avg batch time: 0.4905, average train loss: 55.4433
[09/26 01:59:37 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1675, average loss: 38.9152
[09/26 01:59:37 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 5.50	
[09/26 01:59:37 visual_prompt]: Training 16 / 100 epoch, with learning rate 24.8100969126526
[09/26 01:59:44 visual_prompt]: Epoch 16 / 100: avg data time: 3.92e-02, avg batch time: 0.4836, average train loss: 50.9091
[09/26 01:59:45 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.1671, average loss: 33.7469
[09/26 01:59:45 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.00	
[09/26 01:59:45 visual_prompt]: Training 17 / 100 epoch, with learning rate 24.72684500917257
[09/26 01:59:52 visual_prompt]: Epoch 17 / 100: avg data time: 5.36e-02, avg batch time: 0.4951, average train loss: 52.9938
[09/26 01:59:53 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1671, average loss: 45.6623
[09/26 01:59:53 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 0.50	
[09/26 01:59:53 visual_prompt]: Training 18 / 100 epoch, with learning rate 24.628696578449954
[09/26 02:00:00 visual_prompt]: Epoch 18 / 100: avg data time: 5.98e-02, avg batch time: 0.5018, average train loss: 50.2595
[09/26 02:00:02 visual_prompt]: Inference (val):avg data time: 1.94e-05, avg batch time: 0.1671, average loss: 34.0871
[09/26 02:00:02 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 4.00	
[09/26 02:00:02 visual_prompt]: Training 19 / 100 epoch, with learning rate 24.515771199228986
[09/26 02:00:08 visual_prompt]: Epoch 19 / 100: avg data time: 5.21e-02, avg batch time: 0.4957, average train loss: 55.8195
[09/26 02:00:10 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1674, average loss: 43.9333
[09/26 02:00:10 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 0.50	
[09/26 02:00:10 visual_prompt]: Training 20 / 100 epoch, with learning rate 24.38820645368942
[09/26 02:00:17 visual_prompt]: Epoch 20 / 100: avg data time: 4.37e-02, avg batch time: 0.4909, average train loss: 57.2975
[09/26 02:00:18 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1671, average loss: 34.9334
[09/26 02:00:18 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.00	top5: 4.00	
[09/26 02:00:18 visual_prompt]: Training 21 / 100 epoch, with learning rate 24.246157759823856
[09/26 02:00:25 visual_prompt]: Epoch 21 / 100: avg data time: 6.35e-02, avg batch time: 0.5060, average train loss: 45.9057
[09/26 02:00:26 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1677, average loss: 139.1675
[09/26 02:00:26 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 0.50	
[09/26 02:00:26 visual_prompt]: Training 22 / 100 epoch, with learning rate 24.08979818208484
[09/26 02:00:33 visual_prompt]: Epoch 22 / 100: avg data time: 5.90e-02, avg batch time: 0.5016, average train loss: 56.5816
[09/26 02:00:35 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1674, average loss: 40.7169
[09/26 02:00:35 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.50	
[09/26 02:00:35 visual_prompt]: Training 23 / 100 epoch, with learning rate 23.91931822053251
[09/26 02:00:41 visual_prompt]: Epoch 23 / 100: avg data time: 5.04e-02, avg batch time: 0.4950, average train loss: 54.0319
[09/26 02:00:43 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.1678, average loss: 29.6961
[09/26 02:00:43 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.00	
[09/26 02:00:43 visual_prompt]: Training 24 / 100 epoch, with learning rate 23.73492557873959
[09/26 02:00:50 visual_prompt]: Epoch 24 / 100: avg data time: 5.57e-02, avg batch time: 0.5010, average train loss: 48.1289
[09/26 02:00:51 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1675, average loss: 31.7953
[09/26 02:00:51 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.00	
[09/26 02:00:51 visual_prompt]: Training 25 / 100 epoch, with learning rate 23.536844910736587
[09/26 02:00:58 visual_prompt]: Epoch 25 / 100: avg data time: 5.22e-02, avg batch time: 0.4952, average train loss: 52.0311
[09/26 02:01:00 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1672, average loss: 48.0533
[09/26 02:01:00 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.00	
[09/26 02:01:00 visual_prompt]: Training 26 / 100 epoch, with learning rate 23.325317547305485
[09/26 02:01:06 visual_prompt]: Epoch 26 / 100: avg data time: 4.82e-02, avg batch time: 0.4916, average train loss: 58.0333
[09/26 02:01:08 visual_prompt]: Inference (val):avg data time: 1.98e-05, avg batch time: 0.1672, average loss: 37.8471
[09/26 02:01:08 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/26 02:01:08 visual_prompt]: Training 27 / 100 epoch, with learning rate 23.100601201955325
[09/26 02:01:14 visual_prompt]: Epoch 27 / 100: avg data time: 4.44e-02, avg batch time: 0.4913, average train loss: 53.0424
[09/26 02:01:16 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1673, average loss: 42.0761
[09/26 02:01:16 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 1.50	
[09/26 02:01:16 visual_prompt]: Training 28 / 100 epoch, with learning rate 22.86296965693802
[09/26 02:01:23 visual_prompt]: Epoch 28 / 100: avg data time: 4.18e-02, avg batch time: 0.4866, average train loss: 58.3832
[09/26 02:01:24 visual_prompt]: Inference (val):avg data time: 3.59e-05, avg batch time: 0.1671, average loss: 43.2736
[09/26 02:01:24 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 3.00	
[09/26 02:01:24 visual_prompt]: Training 29 / 100 epoch, with learning rate 22.612712429686844
[09/26 02:01:31 visual_prompt]: Epoch 29 / 100: avg data time: 6.23e-02, avg batch time: 0.5047, average train loss: 49.7655
[09/26 02:01:32 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1676, average loss: 40.5982
[09/26 02:01:32 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 2.50	
[09/26 02:01:32 visual_prompt]: Training 30 / 100 epoch, with learning rate 22.35013442008402
[09/26 02:01:39 visual_prompt]: Epoch 30 / 100: avg data time: 6.21e-02, avg batch time: 0.5063, average train loss: 50.2490
[09/26 02:01:41 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1677, average loss: 47.5124
[09/26 02:01:41 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 6.00	
[09/26 02:01:41 visual_prompt]: Training 31 / 100 epoch, with learning rate 22.075555538987224
[09/26 02:01:47 visual_prompt]: Epoch 31 / 100: avg data time: 5.54e-02, avg batch time: 0.4984, average train loss: 46.2007
[09/26 02:01:49 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1672, average loss: 38.9705
[09/26 02:01:49 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 0.50	
[09/26 02:01:49 visual_prompt]: Training 32 / 100 epoch, with learning rate 21.78931031846743
[09/26 02:01:56 visual_prompt]: Epoch 32 / 100: avg data time: 5.94e-02, avg batch time: 0.5026, average train loss: 41.3373
[09/26 02:01:57 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1672, average loss: 35.9341
[09/26 02:01:57 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.50	
[09/26 02:01:57 visual_prompt]: Training 33 / 100 epoch, with learning rate 21.49174750423314
[09/26 02:02:04 visual_prompt]: Epoch 33 / 100: avg data time: 5.96e-02, avg batch time: 0.5030, average train loss: 42.0895
[09/26 02:02:06 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1670, average loss: 35.1988
[09/26 02:02:06 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/26 02:02:06 visual_prompt]: Training 34 / 100 epoch, with learning rate 21.183229630737465
[09/26 02:02:12 visual_prompt]: Epoch 34 / 100: avg data time: 5.61e-02, avg batch time: 0.4982, average train loss: 39.0606
[09/26 02:02:14 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1671, average loss: 31.2012
[09/26 02:02:14 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.00	
[09/26 02:02:14 visual_prompt]: Training 35 / 100 epoch, with learning rate 20.864132579485727
[09/26 02:02:21 visual_prompt]: Epoch 35 / 100: avg data time: 5.86e-02, avg batch time: 0.5016, average train loss: 37.5374
[09/26 02:02:22 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1668, average loss: 27.3999
[09/26 02:02:22 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/26 02:02:22 visual_prompt]: Training 36 / 100 epoch, with learning rate 20.53484512108174
[09/26 02:02:29 visual_prompt]: Epoch 36 / 100: avg data time: 5.88e-02, avg batch time: 0.5025, average train loss: 32.9732
[09/26 02:02:30 visual_prompt]: Inference (val):avg data time: 2.02e-05, avg batch time: 0.1670, average loss: 25.6507
[09/26 02:02:30 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 3.50	
[09/26 02:02:30 visual_prompt]: Training 37 / 100 epoch, with learning rate 20.195768441570728
[09/26 02:02:37 visual_prompt]: Epoch 37 / 100: avg data time: 5.12e-02, avg batch time: 0.4953, average train loss: 33.2453
[09/26 02:02:39 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1675, average loss: 40.2371
[09/26 02:02:39 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.00	
[09/26 02:02:39 visual_prompt]: Training 38 / 100 epoch, with learning rate 19.847315653655915
[09/26 02:02:45 visual_prompt]: Epoch 38 / 100: avg data time: 4.32e-02, avg batch time: 0.4884, average train loss: 42.8499
[09/26 02:02:47 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1671, average loss: 33.0919
[09/26 02:02:47 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 3.00	
[09/26 02:02:47 visual_prompt]: Training 39 / 100 epoch, with learning rate 19.489911293384335
[09/26 02:02:54 visual_prompt]: Epoch 39 / 100: avg data time: 5.72e-02, avg batch time: 0.5019, average train loss: 38.5366
[09/26 02:02:55 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1674, average loss: 28.9293
[09/26 02:02:55 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/26 02:02:55 visual_prompt]: Training 40 / 100 epoch, with learning rate 19.12399080291506
[09/26 02:03:02 visual_prompt]: Epoch 40 / 100: avg data time: 6.23e-02, avg batch time: 0.5063, average train loss: 48.0202
[09/26 02:03:03 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1671, average loss: 44.5269
[09/26 02:03:03 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 1.50	
[09/26 02:03:03 visual_prompt]: Training 41 / 100 epoch, with learning rate 18.75
[09/26 02:03:10 visual_prompt]: Epoch 41 / 100: avg data time: 5.20e-02, avg batch time: 0.4951, average train loss: 48.9588
[09/26 02:03:11 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1675, average loss: 34.9594
[09/26 02:03:11 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 3.00	
[09/26 02:03:11 visual_prompt]: Training 42 / 100 epoch, with learning rate 18.368394534823633
[09/26 02:03:18 visual_prompt]: Epoch 42 / 100: avg data time: 5.88e-02, avg batch time: 0.5026, average train loss: 43.5766
[09/26 02:03:20 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1675, average loss: 30.2437
[09/26 02:03:20 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.50	
[09/26 02:03:20 visual_prompt]: Training 43 / 100 epoch, with learning rate 17.979639334863467
[09/26 02:03:27 visual_prompt]: Epoch 43 / 100: avg data time: 5.56e-02, avg batch time: 0.4998, average train loss: 38.5638
[09/26 02:03:28 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1674, average loss: 33.6016
[09/26 02:03:28 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 2.50	
[09/26 02:03:28 visual_prompt]: Training 44 / 100 epoch, with learning rate 17.584208038447503
[09/26 02:03:35 visual_prompt]: Epoch 44 / 100: avg data time: 5.72e-02, avg batch time: 0.4994, average train loss: 41.9458
[09/26 02:03:36 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1670, average loss: 33.0964
[09/26 02:03:36 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.50	
[09/26 02:03:36 visual_prompt]: Training 45 / 100 epoch, with learning rate 17.182582417698903
[09/26 02:03:43 visual_prompt]: Epoch 45 / 100: avg data time: 5.43e-02, avg batch time: 0.4978, average train loss: 35.7269
[09/26 02:03:45 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1673, average loss: 34.3067
[09/26 02:03:45 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 3.50	
[09/26 02:03:45 visual_prompt]: Training 46 / 100 epoch, with learning rate 16.77525179157086
[09/26 02:03:51 visual_prompt]: Epoch 46 / 100: avg data time: 5.30e-02, avg batch time: 0.4958, average train loss: 33.8462
[09/26 02:03:53 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1671, average loss: 27.6500
[09/26 02:03:53 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 1.00	
[09/26 02:03:53 visual_prompt]: Training 47 / 100 epoch, with learning rate 16.362712429686844
[09/26 02:04:00 visual_prompt]: Epoch 47 / 100: avg data time: 5.93e-02, avg batch time: 0.5020, average train loss: 33.4702
[09/26 02:04:01 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1673, average loss: 30.5982
[09/26 02:04:01 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 1.00	
[09/26 02:04:01 visual_prompt]: Training 48 / 100 epoch, with learning rate 15.94546694771249
[09/26 02:04:08 visual_prompt]: Epoch 48 / 100: avg data time: 5.53e-02, avg batch time: 0.4989, average train loss: 31.0145
[09/26 02:04:09 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1671, average loss: 45.8602
[09/26 02:04:09 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 2.50	
[09/26 02:04:09 visual_prompt]: Training 49 / 100 epoch, with learning rate 15.524023694995845
[09/26 02:04:16 visual_prompt]: Epoch 49 / 100: avg data time: 5.62e-02, avg batch time: 0.4990, average train loss: 33.6118
[09/26 02:04:18 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1673, average loss: 29.0965
[09/26 02:04:18 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 5.00	
[09/26 02:04:18 visual_prompt]: Training 50 / 100 epoch, with learning rate 15.09889613522199
[09/26 02:04:24 visual_prompt]: Epoch 50 / 100: avg data time: 4.92e-02, avg batch time: 0.4918, average train loss: 30.8605
[09/26 02:04:26 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1670, average loss: 23.0952
[09/26 02:04:26 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.00	
[09/26 02:04:26 visual_prompt]: Training 51 / 100 epoch, with learning rate 14.670602220836631
[09/26 02:04:33 visual_prompt]: Epoch 51 / 100: avg data time: 5.47e-02, avg batch time: 0.4988, average train loss: 26.7065
[09/26 02:04:34 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1673, average loss: 23.6097
[09/26 02:04:34 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 3.00	
[09/26 02:04:34 visual_prompt]: Training 52 / 100 epoch, with learning rate 14.239663762000818
[09/26 02:04:41 visual_prompt]: Epoch 52 / 100: avg data time: 5.72e-02, avg batch time: 0.4989, average train loss: 28.0608
[09/26 02:04:42 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1672, average loss: 22.3971
[09/26 02:04:42 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 0.50	
[09/26 02:04:42 visual_prompt]: Training 53 / 100 epoch, with learning rate 13.80660579084567
[09/26 02:04:49 visual_prompt]: Epoch 53 / 100: avg data time: 5.74e-02, avg batch time: 0.5007, average train loss: 22.2270
[09/26 02:04:51 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1670, average loss: 18.4799
[09/26 02:04:51 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 1.00	
[09/26 02:04:51 visual_prompt]: Training 54 / 100 epoch, with learning rate 13.371955921801565
[09/26 02:04:57 visual_prompt]: Epoch 54 / 100: avg data time: 5.04e-02, avg batch time: 0.4937, average train loss: 18.2312
[09/26 02:04:59 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1671, average loss: 18.4273
[09/26 02:04:59 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 3.00	
[09/26 02:04:59 visual_prompt]: Training 55 / 100 epoch, with learning rate 12.936243708781264
[09/26 02:05:06 visual_prompt]: Epoch 55 / 100: avg data time: 5.54e-02, avg batch time: 0.4989, average train loss: 19.2699
[09/26 02:05:07 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1670, average loss: 15.8019
[09/26 02:05:07 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 4.00	
[09/26 02:05:07 visual_prompt]: Training 56 / 100 epoch, with learning rate 12.5
[09/26 02:05:14 visual_prompt]: Epoch 56 / 100: avg data time: 4.20e-02, avg batch time: 0.4855, average train loss: 15.9660
[09/26 02:05:15 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1671, average loss: 15.1856
[09/26 02:05:15 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.00	
[09/26 02:05:15 visual_prompt]: Training 57 / 100 epoch, with learning rate 12.063756291218741
[09/26 02:05:22 visual_prompt]: Epoch 57 / 100: avg data time: 5.81e-02, avg batch time: 0.5016, average train loss: 15.8993
[09/26 02:05:24 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1674, average loss: 13.4349
[09/26 02:05:24 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 4.50	
[09/26 02:05:24 visual_prompt]: Training 58 / 100 epoch, with learning rate 11.628044078198434
[09/26 02:05:30 visual_prompt]: Epoch 58 / 100: avg data time: 5.44e-02, avg batch time: 0.4984, average train loss: 13.8585
[09/26 02:05:32 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1672, average loss: 13.8315
[09/26 02:05:32 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.50	
[09/26 02:05:32 visual_prompt]: Training 59 / 100 epoch, with learning rate 11.193394209154334
[09/26 02:05:39 visual_prompt]: Epoch 59 / 100: avg data time: 5.16e-02, avg batch time: 0.4952, average train loss: 14.2819
[09/26 02:05:40 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1670, average loss: 11.9411
[09/26 02:05:40 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 1.00	
[09/26 02:05:40 visual_prompt]: Training 60 / 100 epoch, with learning rate 10.760336237999185
[09/26 02:05:47 visual_prompt]: Epoch 60 / 100: avg data time: 5.31e-02, avg batch time: 0.4968, average train loss: 15.2658
[09/26 02:05:48 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1672, average loss: 12.8811
[09/26 02:05:48 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 2.00	
[09/26 02:05:48 visual_prompt]: Training 61 / 100 epoch, with learning rate 10.32939777916337
[09/26 02:05:55 visual_prompt]: Epoch 61 / 100: avg data time: 5.48e-02, avg batch time: 0.4985, average train loss: 12.8234
[09/26 02:05:56 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1670, average loss: 11.5009
[09/26 02:05:56 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 3.00	
[09/26 02:05:56 visual_prompt]: Training 62 / 100 epoch, with learning rate 9.90110386477801
[09/26 02:06:03 visual_prompt]: Epoch 62 / 100: avg data time: 4.32e-02, avg batch time: 0.4869, average train loss: 19.8716
[09/26 02:06:05 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1674, average loss: 15.2225
[09/26 02:06:05 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 1.50	
[09/26 02:06:05 visual_prompt]: Training 63 / 100 epoch, with learning rate 9.475976305004155
[09/26 02:06:11 visual_prompt]: Epoch 63 / 100: avg data time: 5.54e-02, avg batch time: 0.4986, average train loss: 17.0878
[09/26 02:06:13 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.1670, average loss: 13.6804
[09/26 02:06:13 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/26 02:06:13 visual_prompt]: Training 64 / 100 epoch, with learning rate 9.05453305228751
[09/26 02:06:20 visual_prompt]: Epoch 64 / 100: avg data time: 5.98e-02, avg batch time: 0.5027, average train loss: 15.6480
[09/26 02:06:21 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.1676, average loss: 11.9292
[09/26 02:06:21 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 3.00	
[09/26 02:06:21 visual_prompt]: Training 65 / 100 epoch, with learning rate 8.637287570313159
[09/26 02:06:28 visual_prompt]: Epoch 65 / 100: avg data time: 4.48e-02, avg batch time: 0.4907, average train loss: 13.4685
[09/26 02:06:29 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1671, average loss: 11.2458
[09/26 02:06:29 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 0.50	
[09/26 02:06:29 visual_prompt]: Training 66 / 100 epoch, with learning rate 8.224748208429142
[09/26 02:06:36 visual_prompt]: Epoch 66 / 100: avg data time: 5.13e-02, avg batch time: 0.4947, average train loss: 13.2070
[09/26 02:06:38 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1671, average loss: 10.1341
[09/26 02:06:38 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/26 02:06:38 visual_prompt]: Training 67 / 100 epoch, with learning rate 7.817417582301099
[09/26 02:06:44 visual_prompt]: Epoch 67 / 100: avg data time: 5.64e-02, avg batch time: 0.5000, average train loss: 15.7189
[09/26 02:06:46 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1673, average loss: 26.6680
[09/26 02:06:46 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 2.00	
[09/26 02:06:46 visual_prompt]: Training 68 / 100 epoch, with learning rate 7.415791961552499
[09/26 02:06:53 visual_prompt]: Epoch 68 / 100: avg data time: 4.67e-02, avg batch time: 0.4899, average train loss: 15.9017
[09/26 02:06:54 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1670, average loss: 11.7882
[09/26 02:06:54 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 3.00	
[09/26 02:06:54 visual_prompt]: Training 69 / 100 epoch, with learning rate 7.020360665136531
[09/26 02:07:01 visual_prompt]: Epoch 69 / 100: avg data time: 4.90e-02, avg batch time: 0.4933, average train loss: 16.5783
[09/26 02:07:02 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1674, average loss: 11.2244
[09/26 02:07:02 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.00	
[09/26 02:07:02 visual_prompt]: Training 70 / 100 epoch, with learning rate 6.631605465176368
[09/26 02:07:09 visual_prompt]: Epoch 70 / 100: avg data time: 5.01e-02, avg batch time: 0.4937, average train loss: 13.5411
[09/26 02:07:11 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1674, average loss: 10.0299
[09/26 02:07:11 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 2.50	
[09/26 02:07:11 visual_prompt]: Training 71 / 100 epoch, with learning rate 6.250000000000003
[09/26 02:07:17 visual_prompt]: Epoch 71 / 100: avg data time: 5.48e-02, avg batch time: 0.4985, average train loss: 13.6669
[09/26 02:07:19 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1674, average loss: 10.4021
[09/26 02:07:19 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 3.00	
[09/26 02:07:19 visual_prompt]: Training 72 / 100 epoch, with learning rate 5.87600919708494
[09/26 02:07:25 visual_prompt]: Epoch 72 / 100: avg data time: 5.34e-02, avg batch time: 0.4958, average train loss: 13.8353
[09/26 02:07:27 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1673, average loss: 10.8515
[09/26 02:07:27 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 2.50	
[09/26 02:07:27 visual_prompt]: Training 73 / 100 epoch, with learning rate 5.510088706615666
[09/26 02:07:34 visual_prompt]: Epoch 73 / 100: avg data time: 5.77e-02, avg batch time: 0.5010, average train loss: 11.7480
[09/26 02:07:35 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1669, average loss: 8.6891
[09/26 02:07:35 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.00	
[09/26 02:07:35 visual_prompt]: Training 74 / 100 epoch, with learning rate 5.1526843463440875
[09/26 02:07:42 visual_prompt]: Epoch 74 / 100: avg data time: 5.63e-02, avg batch time: 0.4994, average train loss: 8.9493
[09/26 02:07:43 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1670, average loss: 7.8954
[09/26 02:07:43 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 02:07:43 visual_prompt]: Training 75 / 100 epoch, with learning rate 4.804231558429271
[09/26 02:07:50 visual_prompt]: Epoch 75 / 100: avg data time: 4.70e-02, avg batch time: 0.4899, average train loss: 8.7349
[09/26 02:07:52 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1672, average loss: 8.0762
[09/26 02:07:52 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 0.50	
[09/26 02:07:52 visual_prompt]: Training 76 / 100 epoch, with learning rate 4.465154878918258
[09/26 02:07:58 visual_prompt]: Epoch 76 / 100: avg data time: 5.65e-02, avg batch time: 0.4991, average train loss: 9.4999
[09/26 02:08:00 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1672, average loss: 9.2809
[09/26 02:08:00 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 1.50	
[09/26 02:08:00 visual_prompt]: Training 77 / 100 epoch, with learning rate 4.135867420514276
[09/26 02:08:07 visual_prompt]: Epoch 77 / 100: avg data time: 5.30e-02, avg batch time: 0.4982, average train loss: 11.7337
[09/26 02:08:08 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1674, average loss: 8.7083
[09/26 02:08:08 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 4.00	
[09/26 02:08:08 visual_prompt]: Training 78 / 100 epoch, with learning rate 3.816770369262533
[09/26 02:08:15 visual_prompt]: Epoch 78 / 100: avg data time: 5.78e-02, avg batch time: 0.5025, average train loss: 10.7807
[09/26 02:08:16 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1669, average loss: 8.9346
[09/26 02:08:16 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 3.50	
[09/26 02:08:16 visual_prompt]: Training 79 / 100 epoch, with learning rate 3.508252495766863
[09/26 02:08:23 visual_prompt]: Epoch 79 / 100: avg data time: 6.38e-02, avg batch time: 0.5064, average train loss: 11.1961
[09/26 02:08:25 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1671, average loss: 8.8535
[09/26 02:08:25 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.50	
[09/26 02:08:25 visual_prompt]: Training 80 / 100 epoch, with learning rate 3.2106896815325707
[09/26 02:08:31 visual_prompt]: Epoch 80 / 100: avg data time: 4.67e-02, avg batch time: 0.4908, average train loss: 9.5035
[09/26 02:08:33 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1669, average loss: 8.0089
[09/26 02:08:33 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 4.50	
[09/26 02:08:33 visual_prompt]: Training 81 / 100 epoch, with learning rate 2.924444461012776
[09/26 02:08:40 visual_prompt]: Epoch 81 / 100: avg data time: 4.92e-02, avg batch time: 0.4928, average train loss: 7.7810
[09/26 02:08:41 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1675, average loss: 7.6795
[09/26 02:08:41 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 2.00	
[09/26 02:08:41 visual_prompt]: Training 82 / 100 epoch, with learning rate 2.6498655799159763
[09/26 02:08:48 visual_prompt]: Epoch 82 / 100: avg data time: 6.34e-02, avg batch time: 0.5072, average train loss: 7.3346
[09/26 02:08:49 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1672, average loss: 7.5127
[09/26 02:08:49 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 5.50	
[09/26 02:08:49 visual_prompt]: Training 83 / 100 epoch, with learning rate 2.387287570313158
[09/26 02:08:56 visual_prompt]: Epoch 83 / 100: avg data time: 5.50e-02, avg batch time: 0.4977, average train loss: 7.1907
[09/26 02:08:58 visual_prompt]: Inference (val):avg data time: 1.91e-05, avg batch time: 0.1671, average loss: 7.3840
[09/26 02:08:58 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 2.00	
[09/26 02:08:58 visual_prompt]: Training 84 / 100 epoch, with learning rate 2.13703034306198
[09/26 02:09:04 visual_prompt]: Epoch 84 / 100: avg data time: 4.93e-02, avg batch time: 0.4936, average train loss: 6.7165
[09/26 02:09:06 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1669, average loss: 7.1708
[09/26 02:09:06 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.00	
[09/26 02:09:06 visual_prompt]: Training 85 / 100 epoch, with learning rate 1.8993987980446756
[09/26 02:09:13 visual_prompt]: Epoch 85 / 100: avg data time: 5.29e-02, avg batch time: 0.4954, average train loss: 6.3519
[09/26 02:09:14 visual_prompt]: Inference (val):avg data time: 2.11e-05, avg batch time: 0.1671, average loss: 7.2524
[09/26 02:09:14 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 3.00	
[09/26 02:09:14 visual_prompt]: Training 86 / 100 epoch, with learning rate 1.674682452694516
[09/26 02:09:21 visual_prompt]: Epoch 86 / 100: avg data time: 5.45e-02, avg batch time: 0.4976, average train loss: 6.5243
[09/26 02:09:22 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1672, average loss: 6.9191
[09/26 02:09:22 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 2.50	
[09/26 02:09:22 visual_prompt]: Training 87 / 100 epoch, with learning rate 1.4631550892634126
[09/26 02:09:29 visual_prompt]: Epoch 87 / 100: avg data time: 6.08e-02, avg batch time: 0.5033, average train loss: 6.1565
[09/26 02:09:31 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1672, average loss: 6.8264
[09/26 02:09:31 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.00	
[09/26 02:09:31 visual_prompt]: Training 88 / 100 epoch, with learning rate 1.2650744212604148
[09/26 02:09:37 visual_prompt]: Epoch 88 / 100: avg data time: 5.06e-02, avg batch time: 0.4932, average train loss: 6.1027
[09/26 02:09:39 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1671, average loss: 6.7276
[09/26 02:09:39 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 2.50	
[09/26 02:09:39 visual_prompt]: Training 89 / 100 epoch, with learning rate 1.0806817794674877
[09/26 02:09:46 visual_prompt]: Epoch 89 / 100: avg data time: 5.47e-02, avg batch time: 0.4972, average train loss: 5.9513
[09/26 02:09:47 visual_prompt]: Inference (val):avg data time: 2.11e-05, avg batch time: 0.1672, average loss: 6.8378
[09/26 02:09:47 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/26 02:09:47 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.9102018179151585
[09/26 02:09:54 visual_prompt]: Epoch 90 / 100: avg data time: 5.57e-02, avg batch time: 0.4984, average train loss: 6.0494
[09/26 02:09:55 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1672, average loss: 6.7737
[09/26 02:09:55 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 3.00	
[09/26 02:09:55 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.753842240176146
[09/26 02:10:02 visual_prompt]: Epoch 91 / 100: avg data time: 6.14e-02, avg batch time: 0.5050, average train loss: 6.0518
[09/26 02:10:04 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1670, average loss: 6.9744
[09/26 02:10:04 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.00	top5: 4.00	
[09/26 02:10:04 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.6117935463105808
[09/26 02:10:10 visual_prompt]: Epoch 92 / 100: avg data time: 6.01e-02, avg batch time: 0.5023, average train loss: 6.2236
[09/26 02:10:12 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1671, average loss: 6.8089
[09/26 02:10:12 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 6.00	
[09/26 02:10:12 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.4842288007710138
[09/26 02:10:19 visual_prompt]: Epoch 93 / 100: avg data time: 5.38e-02, avg batch time: 0.4972, average train loss: 5.8359
[09/26 02:10:20 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1672, average loss: 6.6680
[09/26 02:10:20 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.00	top5: 5.50	
[09/26 02:10:20 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.3713034215500441
[09/26 02:10:27 visual_prompt]: Epoch 94 / 100: avg data time: 5.54e-02, avg batch time: 0.4976, average train loss: 5.5788
[09/26 02:10:29 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1669, average loss: 6.5948
[09/26 02:10:29 visual_prompt]: Classification results with val_vtab-sun397: top1: 3.00	top5: 6.00	
[09/26 02:10:29 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.2731549908274289
[09/26 02:10:35 visual_prompt]: Epoch 95 / 100: avg data time: 5.35e-02, avg batch time: 0.4969, average train loss: 5.4621
[09/26 02:10:37 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1669, average loss: 6.5592
[09/26 02:10:37 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 5.00	
[09/26 02:10:37 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.18990308734739975
[09/26 02:10:44 visual_prompt]: Epoch 96 / 100: avg data time: 4.56e-02, avg batch time: 0.4906, average train loss: 5.3835
[09/26 02:10:45 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1671, average loss: 6.5180
[09/26 02:10:45 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.00	top5: 9.50	
[09/26 02:10:45 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.12164914073037048
[09/26 02:10:52 visual_prompt]: Epoch 97 / 100: avg data time: 5.44e-02, avg batch time: 0.4975, average train loss: 5.3438
[09/26 02:10:53 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1671, average loss: 6.5059
[09/26 02:10:53 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 5.50	
[09/26 02:10:53 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.06847630789658388
[09/26 02:11:00 visual_prompt]: Epoch 98 / 100: avg data time: 5.90e-02, avg batch time: 0.5022, average train loss: 5.3010
[09/26 02:11:02 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1674, average loss: 6.4616
[09/26 02:11:02 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 7.50	
[09/26 02:11:02 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.03044937175219753
[09/26 02:11:08 visual_prompt]: Epoch 99 / 100: avg data time: 5.36e-02, avg batch time: 0.4977, average train loss: 5.2247
[09/26 02:11:10 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1672, average loss: 6.4472
[09/26 02:11:10 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 7.50	
[09/26 02:11:10 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0076146622613029735
[09/26 02:11:16 visual_prompt]: Epoch 100 / 100: avg data time: 4.84e-02, avg batch time: 0.4919, average train loss: 5.1916
[09/26 02:11:18 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1672, average loss: 6.4445
[09/26 02:11:18 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.00	top5: 7.50	
[09/26 02:11:18 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 02:11:18 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              0
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 02:11:18 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-sun397', 'DATA.NUMBER_CLASSES', '397', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 02:11:18 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 02:11:18 visual_prompt]: Training with config:
[09/26 02:11:18 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-sun397/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr25.0_wd0.0001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 25.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-sun397', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 397, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 02:11:18 visual_prompt]: Loading training data...
[09/26 02:11:18 visual_prompt]: Constructing vtab-sun397 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split train[:800], from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/26 02:11:19 visual_prompt]: Number of images: 800
[09/26 02:11:19 visual_prompt]: Number of classes: 309 / 397
[09/26 02:11:19 visual_prompt]: Loading validation data...
[09/26 02:11:19 visual_prompt]: Constructing vtab-sun397 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split validation[:200], from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/26 02:11:20 visual_prompt]: Number of images: 200
[09/26 02:11:20 visual_prompt]: Number of classes: 136 / 397
[09/26 02:11:20 visual_prompt]: Constructing models...
[09/26 02:11:22 visual_prompt]: Total Parameters: 86564749	 Gradient Parameters: 766093
[09/26 02:11:22 visual_prompt]: tuned percent:0.885
[09/26 02:11:22 visual_prompt]: Device used for model: 0
[09/26 02:11:22 visual_prompt]: Setting up Evaluator...
[09/26 02:11:22 visual_prompt]: Setting up Trainer...
[09/26 02:11:22 visual_prompt]: 	Setting up the optimizer...
[09/26 02:11:22 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 02:11:29 visual_prompt]: Epoch 1 / 100: avg data time: 5.69e-02, avg batch time: 0.5004, average train loss: 5.9890
[09/26 02:11:31 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1670, average loss: 6.0097
[09/26 02:11:31 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/26 02:11:31 visual_prompt]: Training 2 / 100 epoch, with learning rate 2.5
[09/26 02:11:37 visual_prompt]: Epoch 2 / 100: avg data time: 4.38e-02, avg batch time: 0.4871, average train loss: 5.8955
[09/26 02:11:39 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1669, average loss: 5.9678
[09/26 02:11:39 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 5.00	
[09/26 02:11:39 visual_prompt]: Best epoch 2: best metric: 0.005
[09/26 02:11:39 visual_prompt]: Training 3 / 100 epoch, with learning rate 5.0
[09/26 02:11:46 visual_prompt]: Epoch 3 / 100: avg data time: 5.64e-02, avg batch time: 0.5004, average train loss: 6.0036
[09/26 02:11:47 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1667, average loss: 6.1651
[09/26 02:11:47 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.50	
[09/26 02:11:47 visual_prompt]: Training 4 / 100 epoch, with learning rate 7.5
[09/26 02:11:54 visual_prompt]: Epoch 4 / 100: avg data time: 4.99e-02, avg batch time: 0.4935, average train loss: 5.9360
[09/26 02:11:55 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1672, average loss: 6.1585
[09/26 02:11:55 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.00	top5: 7.50	
[09/26 02:11:55 visual_prompt]: Best epoch 4: best metric: 0.020
[09/26 02:11:55 visual_prompt]: Training 5 / 100 epoch, with learning rate 10.0
[09/26 02:12:02 visual_prompt]: Epoch 5 / 100: avg data time: 5.41e-02, avg batch time: 0.4974, average train loss: 6.4149
[09/26 02:12:04 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1674, average loss: 6.5828
[09/26 02:12:04 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.50	top5: 7.50	
[09/26 02:12:04 visual_prompt]: Best epoch 5: best metric: 0.025
[09/26 02:12:04 visual_prompt]: Training 6 / 100 epoch, with learning rate 12.5
[09/26 02:12:10 visual_prompt]: Epoch 6 / 100: avg data time: 5.53e-02, avg batch time: 0.4981, average train loss: 6.9432
[09/26 02:12:12 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1674, average loss: 6.7680
[09/26 02:12:12 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 7.50	
[09/26 02:12:12 visual_prompt]: Training 7 / 100 epoch, with learning rate 15.0
[09/26 02:12:19 visual_prompt]: Epoch 7 / 100: avg data time: 4.28e-02, avg batch time: 0.4878, average train loss: 8.5788
[09/26 02:12:20 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1670, average loss: 8.3532
[09/26 02:12:20 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 8.50	
[09/26 02:12:20 visual_prompt]: Training 8 / 100 epoch, with learning rate 17.5
[09/26 02:12:27 visual_prompt]: Epoch 8 / 100: avg data time: 5.44e-02, avg batch time: 0.4979, average train loss: 12.6595
[09/26 02:12:28 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1675, average loss: 12.4283
[09/26 02:12:28 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.50	
[09/26 02:12:28 visual_prompt]: Training 9 / 100 epoch, with learning rate 20.0
[09/26 02:12:35 visual_prompt]: Epoch 9 / 100: avg data time: 5.60e-02, avg batch time: 0.4994, average train loss: 16.4665
[09/26 02:12:37 visual_prompt]: Inference (val):avg data time: 4.33e-05, avg batch time: 0.1674, average loss: 31.2356
[09/26 02:12:37 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.50	
[09/26 02:12:37 visual_prompt]: Training 10 / 100 epoch, with learning rate 22.5
[09/26 02:12:43 visual_prompt]: Epoch 10 / 100: avg data time: 5.36e-02, avg batch time: 0.4973, average train loss: 42.4992
[09/26 02:12:45 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1671, average loss: 41.8524
[09/26 02:12:45 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.50	
[09/26 02:12:45 visual_prompt]: Training 11 / 100 epoch, with learning rate 25.0
[09/26 02:12:52 visual_prompt]: Epoch 11 / 100: avg data time: 6.04e-02, avg batch time: 0.5029, average train loss: 70.3754
[09/26 02:12:53 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1670, average loss: 59.5810
[09/26 02:12:53 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 2.00	
[09/26 02:12:53 visual_prompt]: Training 12 / 100 epoch, with learning rate 24.9923853377387
[09/26 02:13:00 visual_prompt]: Epoch 12 / 100: avg data time: 5.39e-02, avg batch time: 0.4967, average train loss: 80.3415
[09/26 02:13:02 visual_prompt]: Inference (val):avg data time: 3.88e-05, avg batch time: 0.1670, average loss: 53.4299
[09/26 02:13:02 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 2.00	
[09/26 02:13:02 visual_prompt]: Training 13 / 100 epoch, with learning rate 24.969550628247802
[09/26 02:13:08 visual_prompt]: Epoch 13 / 100: avg data time: 5.99e-02, avg batch time: 0.5032, average train loss: 66.4792
[09/26 02:13:10 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1674, average loss: 36.8346
[09/26 02:13:10 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.00	
[09/26 02:13:10 visual_prompt]: Training 14 / 100 epoch, with learning rate 24.931523692103415
[09/26 02:13:17 visual_prompt]: Epoch 14 / 100: avg data time: 4.89e-02, avg batch time: 0.4925, average train loss: 50.5562
[09/26 02:13:18 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1673, average loss: 44.0422
[09/26 02:13:18 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 5.00	
[09/26 02:13:18 visual_prompt]: Training 15 / 100 epoch, with learning rate 24.87835085926963
[09/26 02:13:25 visual_prompt]: Epoch 15 / 100: avg data time: 5.05e-02, avg batch time: 0.4940, average train loss: 45.7570
[09/26 02:13:26 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1673, average loss: 35.7775
[09/26 02:13:26 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 2.00	
[09/26 02:13:26 visual_prompt]: Training 16 / 100 epoch, with learning rate 24.8100969126526
[09/26 02:13:33 visual_prompt]: Epoch 16 / 100: avg data time: 5.64e-02, avg batch time: 0.4986, average train loss: 43.8269
[09/26 02:13:35 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1672, average loss: 32.4299
[09/26 02:13:35 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 2.00	
[09/26 02:13:35 visual_prompt]: Training 17 / 100 epoch, with learning rate 24.72684500917257
[09/26 02:13:41 visual_prompt]: Epoch 17 / 100: avg data time: 5.84e-02, avg batch time: 0.5009, average train loss: 41.9193
[09/26 02:13:43 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1674, average loss: 33.5504
[09/26 02:13:43 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 2.50	
[09/26 02:13:43 visual_prompt]: Training 18 / 100 epoch, with learning rate 24.628696578449954
[09/26 02:13:50 visual_prompt]: Epoch 18 / 100: avg data time: 4.25e-02, avg batch time: 0.4866, average train loss: 45.2953
[09/26 02:13:51 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1670, average loss: 35.2332
[09/26 02:13:51 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.00	
[09/26 02:13:51 visual_prompt]: Training 19 / 100 epoch, with learning rate 24.515771199228986
[09/26 02:13:58 visual_prompt]: Epoch 19 / 100: avg data time: 6.37e-02, avg batch time: 0.5064, average train loss: 40.5743
[09/26 02:13:59 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1672, average loss: 32.7331
[09/26 02:13:59 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 1.00	
[09/26 02:13:59 visual_prompt]: Training 20 / 100 epoch, with learning rate 24.38820645368942
[09/26 02:14:06 visual_prompt]: Epoch 20 / 100: avg data time: 5.80e-02, avg batch time: 0.5001, average train loss: 44.2739
[09/26 02:14:08 visual_prompt]: Inference (val):avg data time: 4.36e-05, avg batch time: 0.1673, average loss: 33.8069
[09/26 02:14:08 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 1.50	
[09/26 02:14:08 visual_prompt]: Training 21 / 100 epoch, with learning rate 24.246157759823856
[09/26 02:14:14 visual_prompt]: Epoch 21 / 100: avg data time: 4.65e-02, avg batch time: 0.4890, average train loss: 41.2949
[09/26 02:14:16 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1674, average loss: 36.1552
[09/26 02:14:16 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 1.50	
[09/26 02:14:16 visual_prompt]: Training 22 / 100 epoch, with learning rate 24.08979818208484
[09/26 02:14:23 visual_prompt]: Epoch 22 / 100: avg data time: 4.24e-02, avg batch time: 0.4850, average train loss: 41.3319
[09/26 02:14:24 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1673, average loss: 31.5111
[09/26 02:14:24 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 2.00	
[09/26 02:14:24 visual_prompt]: Training 23 / 100 epoch, with learning rate 23.91931822053251
[09/26 02:14:31 visual_prompt]: Epoch 23 / 100: avg data time: 5.12e-02, avg batch time: 0.4949, average train loss: 46.5596
[09/26 02:14:32 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1677, average loss: 34.9937
[09/26 02:14:32 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.00	
[09/26 02:14:32 visual_prompt]: Training 24 / 100 epoch, with learning rate 23.73492557873959
[09/26 02:14:39 visual_prompt]: Epoch 24 / 100: avg data time: 5.80e-02, avg batch time: 0.5014, average train loss: 42.7757
[09/26 02:14:41 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1669, average loss: 31.3841
[09/26 02:14:41 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 2.50	
[09/26 02:14:41 visual_prompt]: Training 25 / 100 epoch, with learning rate 23.536844910736587
[09/26 02:14:47 visual_prompt]: Epoch 25 / 100: avg data time: 5.78e-02, avg batch time: 0.4999, average train loss: 48.8484
[09/26 02:14:49 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1670, average loss: 34.1060
[09/26 02:14:49 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 5.00	
[09/26 02:14:49 visual_prompt]: Training 26 / 100 epoch, with learning rate 23.325317547305485
[09/26 02:14:56 visual_prompt]: Epoch 26 / 100: avg data time: 5.57e-02, avg batch time: 0.4975, average train loss: 47.2003
[09/26 02:14:57 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1677, average loss: 41.7464
[09/26 02:14:57 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 6.00	
[09/26 02:14:57 visual_prompt]: Training 27 / 100 epoch, with learning rate 23.100601201955325
[09/26 02:15:04 visual_prompt]: Epoch 27 / 100: avg data time: 5.60e-02, avg batch time: 0.4990, average train loss: 52.2797
[09/26 02:15:05 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1671, average loss: 42.5337
[09/26 02:15:05 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 0.50	
[09/26 02:15:05 visual_prompt]: Training 28 / 100 epoch, with learning rate 22.86296965693802
[09/26 02:15:12 visual_prompt]: Epoch 28 / 100: avg data time: 5.62e-02, avg batch time: 0.4980, average train loss: 50.3304
[09/26 02:15:14 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1672, average loss: 32.8270
[09/26 02:15:14 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.00	top5: 3.00	
[09/26 02:15:14 visual_prompt]: Training 29 / 100 epoch, with learning rate 22.612712429686844
[09/26 02:15:20 visual_prompt]: Epoch 29 / 100: avg data time: 5.69e-02, avg batch time: 0.4997, average train loss: 44.9868
[09/26 02:15:22 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1669, average loss: 29.0201
[09/26 02:15:22 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.00	
[09/26 02:15:22 visual_prompt]: Training 30 / 100 epoch, with learning rate 22.35013442008402
[09/26 02:15:29 visual_prompt]: Epoch 30 / 100: avg data time: 5.66e-02, avg batch time: 0.4986, average train loss: 40.5250
[09/26 02:15:30 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1674, average loss: 26.6046
[09/26 02:15:30 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 3.00	
[09/26 02:15:30 visual_prompt]: Training 31 / 100 epoch, with learning rate 22.075555538987224
[09/26 02:15:37 visual_prompt]: Epoch 31 / 100: avg data time: 4.20e-02, avg batch time: 0.4870, average train loss: 35.4702
[09/26 02:15:38 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1673, average loss: 30.8266
[09/26 02:15:38 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 2.50	
[09/26 02:15:38 visual_prompt]: Training 32 / 100 epoch, with learning rate 21.78931031846743
[09/26 02:15:45 visual_prompt]: Epoch 32 / 100: avg data time: 5.18e-02, avg batch time: 0.4949, average train loss: 46.6851
[09/26 02:15:47 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1672, average loss: 30.9468
[09/26 02:15:47 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.00	
[09/26 02:15:47 visual_prompt]: Training 33 / 100 epoch, with learning rate 21.49174750423314
[09/26 02:15:53 visual_prompt]: Epoch 33 / 100: avg data time: 5.34e-02, avg batch time: 0.4952, average train loss: 42.8531
[09/26 02:15:55 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1671, average loss: 40.8822
[09/26 02:15:55 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 02:15:55 visual_prompt]: Training 34 / 100 epoch, with learning rate 21.183229630737465
[09/26 02:16:01 visual_prompt]: Epoch 34 / 100: avg data time: 5.10e-02, avg batch time: 0.4935, average train loss: 51.9857
[09/26 02:16:03 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1669, average loss: 35.6433
[09/26 02:16:03 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.50	
[09/26 02:16:03 visual_prompt]: Training 35 / 100 epoch, with learning rate 20.864132579485727
[09/26 02:16:10 visual_prompt]: Epoch 35 / 100: avg data time: 5.64e-02, avg batch time: 0.4985, average train loss: 36.8851
[09/26 02:16:11 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1668, average loss: 30.6826
[09/26 02:16:11 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.50	
[09/26 02:16:11 visual_prompt]: Training 36 / 100 epoch, with learning rate 20.53484512108174
[09/26 02:16:18 visual_prompt]: Epoch 36 / 100: avg data time: 5.42e-02, avg batch time: 0.4970, average train loss: 36.3292
[09/26 02:16:20 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1669, average loss: 31.8130
[09/26 02:16:20 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 0.50	
[09/26 02:16:20 visual_prompt]: Training 37 / 100 epoch, with learning rate 20.195768441570728
[09/26 02:16:26 visual_prompt]: Epoch 37 / 100: avg data time: 5.38e-02, avg batch time: 0.4963, average train loss: 36.9040
[09/26 02:16:28 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1673, average loss: 22.9646
[09/26 02:16:28 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.50	
[09/26 02:16:28 visual_prompt]: Training 38 / 100 epoch, with learning rate 19.847315653655915
[09/26 02:16:35 visual_prompt]: Epoch 38 / 100: avg data time: 5.70e-02, avg batch time: 0.5011, average train loss: 32.3842
[09/26 02:16:36 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1668, average loss: 28.5078
[09/26 02:16:36 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.50	
[09/26 02:16:36 visual_prompt]: Training 39 / 100 epoch, with learning rate 19.489911293384335
[09/26 02:16:43 visual_prompt]: Epoch 39 / 100: avg data time: 6.44e-02, avg batch time: 0.5065, average train loss: 31.7042
[09/26 02:16:45 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1668, average loss: 26.1620
[09/26 02:16:45 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/26 02:16:45 visual_prompt]: Training 40 / 100 epoch, with learning rate 19.12399080291506
[09/26 02:16:51 visual_prompt]: Epoch 40 / 100: avg data time: 5.48e-02, avg batch time: 0.4970, average train loss: 26.6884
[09/26 02:16:53 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1670, average loss: 18.3867
[09/26 02:16:53 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.00	top5: 4.00	
[09/26 02:16:53 visual_prompt]: Training 41 / 100 epoch, with learning rate 18.75
[09/26 02:17:00 visual_prompt]: Epoch 41 / 100: avg data time: 5.47e-02, avg batch time: 0.4985, average train loss: 22.8120
[09/26 02:17:01 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1674, average loss: 20.6165
[09/26 02:17:01 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/26 02:17:01 visual_prompt]: Training 42 / 100 epoch, with learning rate 18.368394534823633
[09/26 02:17:08 visual_prompt]: Epoch 42 / 100: avg data time: 4.81e-02, avg batch time: 0.4915, average train loss: 22.5854
[09/26 02:17:09 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1678, average loss: 18.0405
[09/26 02:17:09 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.00	
[09/26 02:17:09 visual_prompt]: Training 43 / 100 epoch, with learning rate 17.979639334863467
[09/26 02:17:16 visual_prompt]: Epoch 43 / 100: avg data time: 5.31e-02, avg batch time: 0.4988, average train loss: 23.0694
[09/26 02:17:18 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1680, average loss: 19.2210
[09/26 02:17:18 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 2.00	
[09/26 02:17:18 visual_prompt]: Training 44 / 100 epoch, with learning rate 17.584208038447503
[09/26 02:17:24 visual_prompt]: Epoch 44 / 100: avg data time: 4.16e-02, avg batch time: 0.4869, average train loss: 23.5801
[09/26 02:17:26 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1673, average loss: 21.0228
[09/26 02:17:26 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 3.00	
[09/26 02:17:26 visual_prompt]: Training 45 / 100 epoch, with learning rate 17.182582417698903
[09/26 02:17:33 visual_prompt]: Epoch 45 / 100: avg data time: 5.82e-02, avg batch time: 0.5007, average train loss: 25.1445
[09/26 02:17:34 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1672, average loss: 20.0715
[09/26 02:17:34 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 1.50	
[09/26 02:17:34 visual_prompt]: Training 46 / 100 epoch, with learning rate 16.77525179157086
[09/26 02:17:41 visual_prompt]: Epoch 46 / 100: avg data time: 5.58e-02, avg batch time: 0.4997, average train loss: 25.2183
[09/26 02:17:42 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1671, average loss: 19.3011
[09/26 02:17:42 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.00	
[09/26 02:17:42 visual_prompt]: Training 47 / 100 epoch, with learning rate 16.362712429686844
[09/26 02:17:49 visual_prompt]: Epoch 47 / 100: avg data time: 5.09e-02, avg batch time: 0.4949, average train loss: 22.2475
[09/26 02:17:51 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1674, average loss: 16.5921
[09/26 02:17:51 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 3.00	
[09/26 02:17:51 visual_prompt]: Training 48 / 100 epoch, with learning rate 15.94546694771249
[09/26 02:17:58 visual_prompt]: Epoch 48 / 100: avg data time: 5.69e-02, avg batch time: 0.4997, average train loss: 18.9412
[09/26 02:17:59 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1676, average loss: 15.9715
[09/26 02:17:59 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 0.50	
[09/26 02:17:59 visual_prompt]: Training 49 / 100 epoch, with learning rate 15.524023694995845
[09/26 02:18:06 visual_prompt]: Epoch 49 / 100: avg data time: 5.41e-02, avg batch time: 0.4975, average train loss: 18.5109
[09/26 02:18:07 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1674, average loss: 14.0782
[09/26 02:18:07 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.00	
[09/26 02:18:07 visual_prompt]: Training 50 / 100 epoch, with learning rate 15.09889613522199
[09/26 02:18:14 visual_prompt]: Epoch 50 / 100: avg data time: 5.23e-02, avg batch time: 0.4970, average train loss: 17.6978
[09/26 02:18:16 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1672, average loss: 14.2006
[09/26 02:18:16 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.50	top5: 4.50	
[09/26 02:18:16 visual_prompt]: Training 51 / 100 epoch, with learning rate 14.670602220836631
[09/26 02:18:22 visual_prompt]: Epoch 51 / 100: avg data time: 5.70e-02, avg batch time: 0.4994, average train loss: 17.3154
[09/26 02:18:24 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1673, average loss: 16.6477
[09/26 02:18:24 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 3.50	
[09/26 02:18:24 visual_prompt]: Training 52 / 100 epoch, with learning rate 14.239663762000818
[09/26 02:18:31 visual_prompt]: Epoch 52 / 100: avg data time: 5.38e-02, avg batch time: 0.4975, average train loss: 20.0933
[09/26 02:18:32 visual_prompt]: Inference (val):avg data time: 3.41e-05, avg batch time: 0.1673, average loss: 15.8632
[09/26 02:18:32 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 1.50	
[09/26 02:18:32 visual_prompt]: Training 53 / 100 epoch, with learning rate 13.80660579084567
[09/26 02:18:39 visual_prompt]: Epoch 53 / 100: avg data time: 5.43e-02, avg batch time: 0.4980, average train loss: 16.8124
[09/26 02:18:40 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1671, average loss: 14.5070
[09/26 02:18:40 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 2.50	
[09/26 02:18:40 visual_prompt]: Training 54 / 100 epoch, with learning rate 13.371955921801565
[09/26 02:18:47 visual_prompt]: Epoch 54 / 100: avg data time: 5.39e-02, avg batch time: 0.4981, average train loss: 16.8260
[09/26 02:18:49 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1673, average loss: 11.9884
[09/26 02:18:49 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 1.50	
[09/26 02:18:49 visual_prompt]: Training 55 / 100 epoch, with learning rate 12.936243708781264
[09/26 02:18:55 visual_prompt]: Epoch 55 / 100: avg data time: 5.71e-02, avg batch time: 0.5007, average train loss: 14.5058
[09/26 02:18:57 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1671, average loss: 11.8966
[09/26 02:18:57 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 1.50	
[09/26 02:18:57 visual_prompt]: Training 56 / 100 epoch, with learning rate 12.5
[09/26 02:19:04 visual_prompt]: Epoch 56 / 100: avg data time: 6.38e-02, avg batch time: 0.5065, average train loss: 13.3332
[09/26 02:19:05 visual_prompt]: Inference (val):avg data time: 3.52e-05, avg batch time: 0.1674, average loss: 11.2131
[09/26 02:19:05 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 4.00	
[09/26 02:19:05 visual_prompt]: Training 57 / 100 epoch, with learning rate 12.063756291218741
[09/26 02:19:12 visual_prompt]: Epoch 57 / 100: avg data time: 4.83e-02, avg batch time: 0.4927, average train loss: 12.2479
[09/26 02:19:14 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1673, average loss: 10.1801
[09/26 02:19:14 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.00	
[09/26 02:19:14 visual_prompt]: Training 58 / 100 epoch, with learning rate 11.628044078198434
[09/26 02:19:20 visual_prompt]: Epoch 58 / 100: avg data time: 5.68e-02, avg batch time: 0.4997, average train loss: 11.9687
[09/26 02:19:22 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1670, average loss: 9.0295
[09/26 02:19:22 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.00	
[09/26 02:19:22 visual_prompt]: Training 59 / 100 epoch, with learning rate 11.193394209154334
[09/26 02:19:29 visual_prompt]: Epoch 59 / 100: avg data time: 5.84e-02, avg batch time: 0.5010, average train loss: 9.8579
[09/26 02:19:30 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1672, average loss: 8.1625
[09/26 02:19:30 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 2.50	
[09/26 02:19:30 visual_prompt]: Training 60 / 100 epoch, with learning rate 10.760336237999185
[09/26 02:19:37 visual_prompt]: Epoch 60 / 100: avg data time: 4.40e-02, avg batch time: 0.4877, average train loss: 8.5789
[09/26 02:19:38 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1673, average loss: 7.7032
[09/26 02:19:38 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 1.50	
[09/26 02:19:38 visual_prompt]: Training 61 / 100 epoch, with learning rate 10.32939777916337
[09/26 02:19:45 visual_prompt]: Epoch 61 / 100: avg data time: 5.97e-02, avg batch time: 0.5024, average train loss: 8.9500
[09/26 02:19:47 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1672, average loss: 7.1918
[09/26 02:19:47 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.50	
[09/26 02:19:47 visual_prompt]: Training 62 / 100 epoch, with learning rate 9.90110386477801
[09/26 02:19:54 visual_prompt]: Epoch 62 / 100: avg data time: 5.70e-02, avg batch time: 0.5016, average train loss: 7.8043
[09/26 02:19:55 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1674, average loss: 6.7503
[09/26 02:19:55 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.50	
[09/26 02:19:55 visual_prompt]: Training 63 / 100 epoch, with learning rate 9.475976305004155
[09/26 02:20:02 visual_prompt]: Epoch 63 / 100: avg data time: 6.09e-02, avg batch time: 0.5051, average train loss: 6.8460
[09/26 02:20:03 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1672, average loss: 6.5827
[09/26 02:20:03 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.50	
[09/26 02:20:03 visual_prompt]: Training 64 / 100 epoch, with learning rate 9.05453305228751
[09/26 02:20:10 visual_prompt]: Epoch 64 / 100: avg data time: 4.61e-02, avg batch time: 0.4895, average train loss: 6.4702
[09/26 02:20:12 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1678, average loss: 6.1704
[09/26 02:20:12 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 5.50	
[09/26 02:20:12 visual_prompt]: Training 65 / 100 epoch, with learning rate 8.637287570313159
[09/26 02:20:18 visual_prompt]: Epoch 65 / 100: avg data time: 4.23e-02, avg batch time: 0.4866, average train loss: 6.2080
[09/26 02:20:20 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1674, average loss: 6.3503
[09/26 02:20:20 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 6.00	
[09/26 02:20:20 visual_prompt]: Training 66 / 100 epoch, with learning rate 8.224748208429142
[09/26 02:20:26 visual_prompt]: Epoch 66 / 100: avg data time: 5.60e-02, avg batch time: 0.4996, average train loss: 6.0229
[09/26 02:20:28 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.1674, average loss: 6.3328
[09/26 02:20:28 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.50	top5: 5.00	
[09/26 02:20:28 visual_prompt]: Training 67 / 100 epoch, with learning rate 7.817417582301099
[09/26 02:20:35 visual_prompt]: Epoch 67 / 100: avg data time: 5.35e-02, avg batch time: 0.4976, average train loss: 5.9378
[09/26 02:20:36 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1676, average loss: 6.2485
[09/26 02:20:36 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.50	
[09/26 02:20:36 visual_prompt]: Training 68 / 100 epoch, with learning rate 7.415791961552499
[09/26 02:20:43 visual_prompt]: Epoch 68 / 100: avg data time: 5.56e-02, avg batch time: 0.4998, average train loss: 5.8273
[09/26 02:20:45 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1675, average loss: 6.1005
[09/26 02:20:45 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.50	
[09/26 02:20:45 visual_prompt]: Training 69 / 100 epoch, with learning rate 7.020360665136531
[09/26 02:20:51 visual_prompt]: Epoch 69 / 100: avg data time: 4.48e-02, avg batch time: 0.4906, average train loss: 5.7267
[09/26 02:20:53 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1673, average loss: 5.9252
[09/26 02:20:53 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 6.00	
[09/26 02:20:53 visual_prompt]: Training 70 / 100 epoch, with learning rate 6.631605465176368
[09/26 02:21:00 visual_prompt]: Epoch 70 / 100: avg data time: 5.68e-02, avg batch time: 0.5014, average train loss: 5.4894
[09/26 02:21:01 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1673, average loss: 6.0030
[09/26 02:21:01 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 8.50	
[09/26 02:21:01 visual_prompt]: Training 71 / 100 epoch, with learning rate 6.250000000000003
[09/26 02:21:08 visual_prompt]: Epoch 71 / 100: avg data time: 6.03e-02, avg batch time: 0.5043, average train loss: 5.3961
[09/26 02:21:09 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1672, average loss: 6.0823
[09/26 02:21:09 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 10.00	
[09/26 02:21:09 visual_prompt]: Training 72 / 100 epoch, with learning rate 5.87600919708494
[09/26 02:21:16 visual_prompt]: Epoch 72 / 100: avg data time: 5.41e-02, avg batch time: 0.4992, average train loss: 5.3021
[09/26 02:21:18 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1675, average loss: 5.8499
[09/26 02:21:18 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 7.00	
[09/26 02:21:18 visual_prompt]: Training 73 / 100 epoch, with learning rate 5.510088706615666
[09/26 02:21:24 visual_prompt]: Epoch 73 / 100: avg data time: 4.62e-02, avg batch time: 0.4918, average train loss: 5.0508
[09/26 02:21:26 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1677, average loss: 5.5528
[09/26 02:21:26 visual_prompt]: Classification results with val_vtab-sun397: top1: 3.50	top5: 13.00	
[09/26 02:21:26 visual_prompt]: Best epoch 73: best metric: 0.035
[09/26 02:21:26 visual_prompt]: Training 74 / 100 epoch, with learning rate 5.1526843463440875
[09/26 02:21:33 visual_prompt]: Epoch 74 / 100: avg data time: 5.99e-02, avg batch time: 0.5034, average train loss: 4.7623
[09/26 02:21:34 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1675, average loss: 5.6123
[09/26 02:21:34 visual_prompt]: Classification results with val_vtab-sun397: top1: 5.50	top5: 13.50	
[09/26 02:21:34 visual_prompt]: Best epoch 74: best metric: 0.055
[09/26 02:21:34 visual_prompt]: Training 75 / 100 epoch, with learning rate 4.804231558429271
[09/26 02:21:41 visual_prompt]: Epoch 75 / 100: avg data time: 5.43e-02, avg batch time: 0.4994, average train loss: 4.6199
[09/26 02:21:43 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1677, average loss: 5.5956
[09/26 02:21:43 visual_prompt]: Classification results with val_vtab-sun397: top1: 5.50	top5: 16.00	
[09/26 02:21:43 visual_prompt]: Training 76 / 100 epoch, with learning rate 4.465154878918258
[09/26 02:21:49 visual_prompt]: Epoch 76 / 100: avg data time: 4.80e-02, avg batch time: 0.4936, average train loss: 4.4852
[09/26 02:21:51 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1675, average loss: 5.9248
[09/26 02:21:51 visual_prompt]: Classification results with val_vtab-sun397: top1: 6.00	top5: 12.00	
[09/26 02:21:51 visual_prompt]: Best epoch 76: best metric: 0.060
[09/26 02:21:51 visual_prompt]: Training 77 / 100 epoch, with learning rate 4.135867420514276
[09/26 02:21:57 visual_prompt]: Epoch 77 / 100: avg data time: 4.41e-02, avg batch time: 0.4890, average train loss: 6.8012
[09/26 02:21:59 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1673, average loss: 6.7232
[09/26 02:21:59 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 9.00	
[09/26 02:21:59 visual_prompt]: Training 78 / 100 epoch, with learning rate 3.816770369262533
[09/26 02:22:06 visual_prompt]: Epoch 78 / 100: avg data time: 4.40e-02, avg batch time: 0.4902, average train loss: 6.6426
[09/26 02:22:07 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1675, average loss: 6.2677
[09/26 02:22:07 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.00	top5: 8.50	
[09/26 02:22:07 visual_prompt]: Training 79 / 100 epoch, with learning rate 3.508252495766863
[09/26 02:22:14 visual_prompt]: Epoch 79 / 100: avg data time: 6.20e-02, avg batch time: 0.5063, average train loss: 5.5813
[09/26 02:22:15 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1673, average loss: 5.6953
[09/26 02:22:15 visual_prompt]: Classification results with val_vtab-sun397: top1: 3.00	top5: 12.00	
[09/26 02:22:15 visual_prompt]: Training 80 / 100 epoch, with learning rate 3.2106896815325707
[09/26 02:22:22 visual_prompt]: Epoch 80 / 100: avg data time: 5.98e-02, avg batch time: 0.5041, average train loss: 4.9972
[09/26 02:22:24 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1677, average loss: 5.7008
[09/26 02:22:24 visual_prompt]: Classification results with val_vtab-sun397: top1: 7.50	top5: 17.00	
[09/26 02:22:24 visual_prompt]: Best epoch 80: best metric: 0.075
[09/26 02:22:24 visual_prompt]: Training 81 / 100 epoch, with learning rate 2.924444461012776
[09/26 02:22:31 visual_prompt]: Epoch 81 / 100: avg data time: 5.39e-02, avg batch time: 0.4980, average train loss: 4.7206
[09/26 02:22:32 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1678, average loss: 5.8275
[09/26 02:22:32 visual_prompt]: Classification results with val_vtab-sun397: top1: 8.00	top5: 18.00	
[09/26 02:22:32 visual_prompt]: Best epoch 81: best metric: 0.080
[09/26 02:22:32 visual_prompt]: Training 82 / 100 epoch, with learning rate 2.6498655799159763
[09/26 02:22:39 visual_prompt]: Epoch 82 / 100: avg data time: 5.04e-02, avg batch time: 0.4953, average train loss: 4.1062
[09/26 02:22:40 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1676, average loss: 5.6911
[09/26 02:22:40 visual_prompt]: Classification results with val_vtab-sun397: top1: 8.50	top5: 24.00	
[09/26 02:22:40 visual_prompt]: Best epoch 82: best metric: 0.085
[09/26 02:22:40 visual_prompt]: Training 83 / 100 epoch, with learning rate 2.387287570313158
[09/26 02:22:47 visual_prompt]: Epoch 83 / 100: avg data time: 5.30e-02, avg batch time: 0.4981, average train loss: 3.5888
[09/26 02:22:49 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1675, average loss: 4.9402
[09/26 02:22:49 visual_prompt]: Classification results with val_vtab-sun397: top1: 18.00	top5: 38.00	
[09/26 02:22:49 visual_prompt]: Best epoch 83: best metric: 0.180
[09/26 02:22:49 visual_prompt]: Training 84 / 100 epoch, with learning rate 2.13703034306198
[09/26 02:22:55 visual_prompt]: Epoch 84 / 100: avg data time: 5.55e-02, avg batch time: 0.5004, average train loss: 1.5889
[09/26 02:22:57 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1675, average loss: 4.3422
[09/26 02:22:57 visual_prompt]: Classification results with val_vtab-sun397: top1: 25.50	top5: 50.50	
[09/26 02:22:57 visual_prompt]: Best epoch 84: best metric: 0.255
[09/26 02:22:57 visual_prompt]: Training 85 / 100 epoch, with learning rate 1.8993987980446756
[09/26 02:23:04 visual_prompt]: Epoch 85 / 100: avg data time: 5.85e-02, avg batch time: 0.5024, average train loss: 0.5949
[09/26 02:23:05 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1675, average loss: 4.1930
[09/26 02:23:05 visual_prompt]: Classification results with val_vtab-sun397: top1: 29.00	top5: 56.50	
[09/26 02:23:05 visual_prompt]: Best epoch 85: best metric: 0.290
[09/26 02:23:05 visual_prompt]: Training 86 / 100 epoch, with learning rate 1.674682452694516
[09/26 02:23:12 visual_prompt]: Epoch 86 / 100: avg data time: 5.09e-02, avg batch time: 0.4976, average train loss: 0.2091
[09/26 02:23:14 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1675, average loss: 4.0184
[09/26 02:23:14 visual_prompt]: Classification results with val_vtab-sun397: top1: 30.00	top5: 61.00	
[09/26 02:23:14 visual_prompt]: Best epoch 86: best metric: 0.300
[09/26 02:23:14 visual_prompt]: Training 87 / 100 epoch, with learning rate 1.4631550892634126
[09/26 02:23:20 visual_prompt]: Epoch 87 / 100: avg data time: 5.48e-02, avg batch time: 0.4984, average train loss: 0.1049
[09/26 02:23:22 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1676, average loss: 3.8601
[09/26 02:23:22 visual_prompt]: Classification results with val_vtab-sun397: top1: 32.00	top5: 64.00	
[09/26 02:23:22 visual_prompt]: Best epoch 87: best metric: 0.320
[09/26 02:23:22 visual_prompt]: Training 88 / 100 epoch, with learning rate 1.2650744212604148
[09/26 02:23:29 visual_prompt]: Epoch 88 / 100: avg data time: 5.35e-02, avg batch time: 0.4967, average train loss: 0.0430
[09/26 02:23:30 visual_prompt]: Inference (val):avg data time: 1.99e-05, avg batch time: 0.1675, average loss: 3.8288
[09/26 02:23:30 visual_prompt]: Classification results with val_vtab-sun397: top1: 31.50	top5: 64.00	
[09/26 02:23:30 visual_prompt]: Training 89 / 100 epoch, with learning rate 1.0806817794674877
[09/26 02:23:37 visual_prompt]: Epoch 89 / 100: avg data time: 5.00e-02, avg batch time: 0.4946, average train loss: 0.0275
[09/26 02:23:38 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1673, average loss: 3.6897
[09/26 02:23:38 visual_prompt]: Classification results with val_vtab-sun397: top1: 34.50	top5: 65.00	
[09/26 02:23:38 visual_prompt]: Best epoch 89: best metric: 0.345
[09/26 02:23:38 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.9102018179151585
[09/26 02:23:45 visual_prompt]: Epoch 90 / 100: avg data time: 5.07e-02, avg batch time: 0.4951, average train loss: 0.0224
[09/26 02:23:47 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1674, average loss: 3.6843
[09/26 02:23:47 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 65.50	
[09/26 02:23:47 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.753842240176146
[09/26 02:23:53 visual_prompt]: Epoch 91 / 100: avg data time: 5.77e-02, avg batch time: 0.5012, average train loss: 0.0181
[09/26 02:23:55 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1676, average loss: 3.6571
[09/26 02:23:55 visual_prompt]: Classification results with val_vtab-sun397: top1: 34.00	top5: 66.50	
[09/26 02:23:55 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.6117935463105808
[09/26 02:24:02 visual_prompt]: Epoch 92 / 100: avg data time: 5.58e-02, avg batch time: 0.5005, average train loss: 0.0163
[09/26 02:24:03 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1673, average loss: 3.6487
[09/26 02:24:03 visual_prompt]: Classification results with val_vtab-sun397: top1: 34.00	top5: 66.00	
[09/26 02:24:03 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.4842288007710138
[09/26 02:24:10 visual_prompt]: Epoch 93 / 100: avg data time: 5.82e-02, avg batch time: 0.5022, average train loss: 0.0159
[09/26 02:24:12 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1674, average loss: 3.6469
[09/26 02:24:12 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.00	top5: 66.00	
[09/26 02:24:12 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.3713034215500441
[09/26 02:24:18 visual_prompt]: Epoch 94 / 100: avg data time: 5.49e-02, avg batch time: 0.4981, average train loss: 0.0149
[09/26 02:24:20 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1676, average loss: 3.6467
[09/26 02:24:20 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 66.00	
[09/26 02:24:20 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.2731549908274289
[09/26 02:24:26 visual_prompt]: Epoch 95 / 100: avg data time: 4.05e-02, avg batch time: 0.4846, average train loss: 0.0149
[09/26 02:24:28 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1673, average loss: 3.6465
[09/26 02:24:28 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 66.00	
[09/26 02:24:28 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.18990308734739975
[09/26 02:24:35 visual_prompt]: Epoch 96 / 100: avg data time: 5.83e-02, avg batch time: 0.5036, average train loss: 0.0146
[09/26 02:24:36 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1673, average loss: 3.6456
[09/26 02:24:36 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 66.00	
[09/26 02:24:36 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.12164914073037048
[09/26 02:24:43 visual_prompt]: Epoch 97 / 100: avg data time: 4.68e-02, avg batch time: 0.4899, average train loss: 0.0153
[09/26 02:24:44 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1677, average loss: 3.6459
[09/26 02:24:44 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 66.00	
[09/26 02:24:44 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.06847630789658388
[09/26 02:24:51 visual_prompt]: Epoch 98 / 100: avg data time: 5.43e-02, avg batch time: 0.4986, average train loss: 0.0146
[09/26 02:24:53 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1676, average loss: 3.6460
[09/26 02:24:53 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 66.00	
[09/26 02:24:53 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.03044937175219753
[09/26 02:24:59 visual_prompt]: Epoch 99 / 100: avg data time: 5.66e-02, avg batch time: 0.5006, average train loss: 0.0154
[09/26 02:25:01 visual_prompt]: Inference (val):avg data time: 2.01e-05, avg batch time: 0.1676, average loss: 3.6458
[09/26 02:25:01 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 66.00	
[09/26 02:25:01 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0076146622613029735
[09/26 02:25:08 visual_prompt]: Epoch 100 / 100: avg data time: 4.58e-02, avg batch time: 0.4912, average train loss: 0.0148
[09/26 02:25:09 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1678, average loss: 3.6458
[09/26 02:25:09 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 66.00	
[09/26 02:25:09 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 02:25:09 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              0
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 02:25:09 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-sun397', 'DATA.NUMBER_CLASSES', '397', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 02:25:09 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 02:25:09 visual_prompt]: Training with config:
[09/26 02:25:09 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-sun397/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr25.0_wd0.0/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 25.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-sun397', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 397, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 02:25:09 visual_prompt]: Loading training data...
[09/26 02:25:09 visual_prompt]: Constructing vtab-sun397 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split train[:800], from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/26 02:25:11 visual_prompt]: Number of images: 800
[09/26 02:25:11 visual_prompt]: Number of classes: 309 / 397
[09/26 02:25:11 visual_prompt]: Loading validation data...
[09/26 02:25:11 visual_prompt]: Constructing vtab-sun397 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split validation[:200], from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/26 02:25:11 visual_prompt]: Number of images: 200
[09/26 02:25:11 visual_prompt]: Number of classes: 136 / 397
[09/26 02:25:11 visual_prompt]: Constructing models...
[09/26 02:25:13 visual_prompt]: Total Parameters: 86564749	 Gradient Parameters: 766093
[09/26 02:25:13 visual_prompt]: tuned percent:0.885
[09/26 02:25:14 visual_prompt]: Device used for model: 0
[09/26 02:25:14 visual_prompt]: Setting up Evaluator...
[09/26 02:25:14 visual_prompt]: Setting up Trainer...
[09/26 02:25:14 visual_prompt]: 	Setting up the optimizer...
[09/26 02:25:14 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 02:25:20 visual_prompt]: Epoch 1 / 100: avg data time: 4.58e-02, avg batch time: 0.4884, average train loss: 5.9875
[09/26 02:25:22 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1677, average loss: 6.0097
[09/26 02:25:22 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/26 02:25:22 visual_prompt]: Training 2 / 100 epoch, with learning rate 2.5
[09/26 02:25:29 visual_prompt]: Epoch 2 / 100: avg data time: 6.03e-02, avg batch time: 0.5027, average train loss: 5.7966
[09/26 02:25:30 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1675, average loss: 5.9617
[09/26 02:25:30 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 2.00	
[09/26 02:25:30 visual_prompt]: Best epoch 2: best metric: 0.005
[09/26 02:25:30 visual_prompt]: Training 3 / 100 epoch, with learning rate 5.0
[09/26 02:25:37 visual_prompt]: Epoch 3 / 100: avg data time: 4.44e-02, avg batch time: 0.4892, average train loss: 5.8300
[09/26 02:25:38 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1673, average loss: 6.4826
[09/26 02:25:38 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 3.50	
[09/26 02:25:38 visual_prompt]: Best epoch 3: best metric: 0.010
[09/26 02:25:38 visual_prompt]: Training 4 / 100 epoch, with learning rate 7.5
[09/26 02:25:45 visual_prompt]: Epoch 4 / 100: avg data time: 4.61e-02, avg batch time: 0.4915, average train loss: 6.0438
[09/26 02:25:47 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1677, average loss: 6.2442
[09/26 02:25:47 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 4.50	
[09/26 02:25:47 visual_prompt]: Best epoch 4: best metric: 0.015
[09/26 02:25:47 visual_prompt]: Training 5 / 100 epoch, with learning rate 10.0
[09/26 02:25:53 visual_prompt]: Epoch 5 / 100: avg data time: 4.37e-02, avg batch time: 0.4875, average train loss: 6.2212
[09/26 02:25:55 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1680, average loss: 6.6148
[09/26 02:25:55 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.00	
[09/26 02:25:55 visual_prompt]: Training 6 / 100 epoch, with learning rate 12.5
[09/26 02:26:01 visual_prompt]: Epoch 6 / 100: avg data time: 5.24e-02, avg batch time: 0.4953, average train loss: 6.5714
[09/26 02:26:03 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1679, average loss: 6.4535
[09/26 02:26:03 visual_prompt]: Classification results with val_vtab-sun397: top1: 6.00	top5: 10.00	
[09/26 02:26:03 visual_prompt]: Best epoch 6: best metric: 0.060
[09/26 02:26:03 visual_prompt]: Training 7 / 100 epoch, with learning rate 15.0
[09/26 02:26:10 visual_prompt]: Epoch 7 / 100: avg data time: 5.64e-02, avg batch time: 0.4995, average train loss: 6.7974
[09/26 02:26:11 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1677, average loss: 10.0718
[09/26 02:26:11 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.50	top5: 5.50	
[09/26 02:26:11 visual_prompt]: Training 8 / 100 epoch, with learning rate 17.5
[09/26 02:26:18 visual_prompt]: Epoch 8 / 100: avg data time: 5.66e-02, avg batch time: 0.4999, average train loss: 10.6248
[09/26 02:26:20 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1674, average loss: 13.2985
[09/26 02:26:20 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 0.50	
[09/26 02:26:20 visual_prompt]: Training 9 / 100 epoch, with learning rate 20.0
[09/26 02:26:26 visual_prompt]: Epoch 9 / 100: avg data time: 5.44e-02, avg batch time: 0.4982, average train loss: 22.4488
[09/26 02:26:28 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.1676, average loss: 32.4410
[09/26 02:26:28 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 5.50	
[09/26 02:26:28 visual_prompt]: Training 10 / 100 epoch, with learning rate 22.5
[09/26 02:26:35 visual_prompt]: Epoch 10 / 100: avg data time: 5.04e-02, avg batch time: 0.4941, average train loss: 56.7093
[09/26 02:26:36 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1680, average loss: 35.7400
[09/26 02:26:36 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 2.50	
[09/26 02:26:36 visual_prompt]: Training 11 / 100 epoch, with learning rate 25.0
[09/26 02:26:43 visual_prompt]: Epoch 11 / 100: avg data time: 5.67e-02, avg batch time: 0.4998, average train loss: 93.4386
[09/26 02:26:44 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1672, average loss: 72.7626
[09/26 02:26:44 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 02:26:44 visual_prompt]: Training 12 / 100 epoch, with learning rate 24.9923853377387
[09/26 02:26:51 visual_prompt]: Epoch 12 / 100: avg data time: 4.94e-02, avg batch time: 0.4944, average train loss: 83.5033
[09/26 02:26:53 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1672, average loss: 56.9697
[09/26 02:26:53 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 2.50	
[09/26 02:26:53 visual_prompt]: Training 13 / 100 epoch, with learning rate 24.969550628247802
[09/26 02:27:00 visual_prompt]: Epoch 13 / 100: avg data time: 5.41e-02, avg batch time: 0.4986, average train loss: 61.6658
[09/26 02:27:01 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1682, average loss: 45.9568
[09/26 02:27:01 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 1.50	
[09/26 02:27:01 visual_prompt]: Training 14 / 100 epoch, with learning rate 24.931523692103415
[09/26 02:27:08 visual_prompt]: Epoch 14 / 100: avg data time: 5.09e-02, avg batch time: 0.4952, average train loss: 65.0130
[09/26 02:27:09 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1673, average loss: 50.0035
[09/26 02:27:09 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 2.00	
[09/26 02:27:09 visual_prompt]: Training 15 / 100 epoch, with learning rate 24.87835085926963
[09/26 02:27:16 visual_prompt]: Epoch 15 / 100: avg data time: 5.61e-02, avg batch time: 0.4990, average train loss: 55.2081
[09/26 02:27:18 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1670, average loss: 31.8794
[09/26 02:27:18 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.50	
[09/26 02:27:18 visual_prompt]: Training 16 / 100 epoch, with learning rate 24.8100969126526
[09/26 02:27:24 visual_prompt]: Epoch 16 / 100: avg data time: 5.57e-02, avg batch time: 0.4997, average train loss: 39.9541
[09/26 02:27:26 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1673, average loss: 25.5428
[09/26 02:27:26 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/26 02:27:26 visual_prompt]: Training 17 / 100 epoch, with learning rate 24.72684500917257
[09/26 02:27:33 visual_prompt]: Epoch 17 / 100: avg data time: 6.03e-02, avg batch time: 0.5030, average train loss: 39.6739
[09/26 02:27:34 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1675, average loss: 35.8874
[09/26 02:27:34 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.00	top5: 5.00	
[09/26 02:27:34 visual_prompt]: Training 18 / 100 epoch, with learning rate 24.628696578449954
[09/26 02:27:41 visual_prompt]: Epoch 18 / 100: avg data time: 5.61e-02, avg batch time: 0.4992, average train loss: 38.9982
[09/26 02:27:43 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1674, average loss: 29.3362
[09/26 02:27:43 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.00	
[09/26 02:27:43 visual_prompt]: Training 19 / 100 epoch, with learning rate 24.515771199228986
[09/26 02:27:49 visual_prompt]: Epoch 19 / 100: avg data time: 6.16e-02, avg batch time: 0.5062, average train loss: 31.1567
[09/26 02:27:51 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1672, average loss: 26.5855
[09/26 02:27:51 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 2.50	
[09/26 02:27:51 visual_prompt]: Training 20 / 100 epoch, with learning rate 24.38820645368942
[09/26 02:27:58 visual_prompt]: Epoch 20 / 100: avg data time: 4.62e-02, avg batch time: 0.4913, average train loss: 26.4223
[09/26 02:27:59 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1672, average loss: 21.3039
[09/26 02:27:59 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 3.00	
[09/26 02:27:59 visual_prompt]: Training 21 / 100 epoch, with learning rate 24.246157759823856
[09/26 02:28:06 visual_prompt]: Epoch 21 / 100: avg data time: 5.92e-02, avg batch time: 0.5024, average train loss: 21.9139
[09/26 02:28:07 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1674, average loss: 19.2059
[09/26 02:28:07 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.00	
[09/26 02:28:07 visual_prompt]: Training 22 / 100 epoch, with learning rate 24.08979818208484
[09/26 02:28:14 visual_prompt]: Epoch 22 / 100: avg data time: 5.80e-02, avg batch time: 0.5011, average train loss: 19.8019
[09/26 02:28:16 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1672, average loss: 18.2167
[09/26 02:28:16 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 2.00	
[09/26 02:28:16 visual_prompt]: Training 23 / 100 epoch, with learning rate 23.91931822053251
[09/26 02:28:22 visual_prompt]: Epoch 23 / 100: avg data time: 5.45e-02, avg batch time: 0.4986, average train loss: 20.3163
[09/26 02:28:24 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1673, average loss: 16.0194
[09/26 02:28:24 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.00	
[09/26 02:28:24 visual_prompt]: Training 24 / 100 epoch, with learning rate 23.73492557873959
[09/26 02:28:31 visual_prompt]: Epoch 24 / 100: avg data time: 5.39e-02, avg batch time: 0.4978, average train loss: 20.4621
[09/26 02:28:32 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1675, average loss: 17.5155
[09/26 02:28:32 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.50	
[09/26 02:28:32 visual_prompt]: Training 25 / 100 epoch, with learning rate 23.536844910736587
[09/26 02:28:39 visual_prompt]: Epoch 25 / 100: avg data time: 5.54e-02, avg batch time: 0.4991, average train loss: 22.2627
[09/26 02:28:41 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1678, average loss: 17.4606
[09/26 02:28:41 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.00	top5: 4.00	
[09/26 02:28:41 visual_prompt]: Training 26 / 100 epoch, with learning rate 23.325317547305485
[09/26 02:28:47 visual_prompt]: Epoch 26 / 100: avg data time: 4.21e-02, avg batch time: 0.4873, average train loss: 16.5458
[09/26 02:28:49 visual_prompt]: Inference (val):avg data time: 2.05e-05, avg batch time: 0.1675, average loss: 12.5011
[09/26 02:28:49 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.50	
[09/26 02:28:49 visual_prompt]: Training 27 / 100 epoch, with learning rate 23.100601201955325
[09/26 02:28:56 visual_prompt]: Epoch 27 / 100: avg data time: 5.83e-02, avg batch time: 0.5020, average train loss: 15.7927
[09/26 02:28:57 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1674, average loss: 14.9953
[09/26 02:28:57 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.00	
[09/26 02:28:57 visual_prompt]: Training 28 / 100 epoch, with learning rate 22.86296965693802
[09/26 02:29:04 visual_prompt]: Epoch 28 / 100: avg data time: 5.52e-02, avg batch time: 0.5001, average train loss: 16.0801
[09/26 02:29:05 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1675, average loss: 14.0883
[09/26 02:29:05 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 2.50	
[09/26 02:29:05 visual_prompt]: Training 29 / 100 epoch, with learning rate 22.612712429686844
[09/26 02:29:12 visual_prompt]: Epoch 29 / 100: avg data time: 6.00e-02, avg batch time: 0.5050, average train loss: 12.7744
[09/26 02:29:14 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1673, average loss: 11.2154
[09/26 02:29:14 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 3.00	
[09/26 02:29:14 visual_prompt]: Training 30 / 100 epoch, with learning rate 22.35013442008402
[09/26 02:29:20 visual_prompt]: Epoch 30 / 100: avg data time: 5.65e-02, avg batch time: 0.5010, average train loss: 11.3927
[09/26 02:29:22 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1671, average loss: 11.3112
[09/26 02:29:22 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.00	
[09/26 02:29:22 visual_prompt]: Training 31 / 100 epoch, with learning rate 22.075555538987224
[09/26 02:29:29 visual_prompt]: Epoch 31 / 100: avg data time: 5.74e-02, avg batch time: 0.5029, average train loss: 10.2134
[09/26 02:29:30 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1677, average loss: 12.4472
[09/26 02:29:30 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 3.50	
[09/26 02:29:30 visual_prompt]: Training 32 / 100 epoch, with learning rate 21.78931031846743
[09/26 02:29:37 visual_prompt]: Epoch 32 / 100: avg data time: 4.61e-02, avg batch time: 0.4922, average train loss: 9.7597
[09/26 02:29:38 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1675, average loss: 10.8160
[09/26 02:29:38 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 6.00	
[09/26 02:29:38 visual_prompt]: Training 33 / 100 epoch, with learning rate 21.49174750423314
[09/26 02:29:45 visual_prompt]: Epoch 33 / 100: avg data time: 4.72e-02, avg batch time: 0.4924, average train loss: 9.6703
[09/26 02:29:47 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1674, average loss: 11.3404
[09/26 02:29:47 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 1.50	
[09/26 02:29:47 visual_prompt]: Training 34 / 100 epoch, with learning rate 21.183229630737465
[09/26 02:29:53 visual_prompt]: Epoch 34 / 100: avg data time: 4.83e-02, avg batch time: 0.4955, average train loss: 8.5455
[09/26 02:29:55 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1678, average loss: 12.4279
[09/26 02:29:55 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 2.50	
[09/26 02:29:55 visual_prompt]: Training 35 / 100 epoch, with learning rate 20.864132579485727
[09/26 02:30:02 visual_prompt]: Epoch 35 / 100: avg data time: 4.97e-02, avg batch time: 0.4950, average train loss: 8.6695
[09/26 02:30:03 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1676, average loss: 11.8606
[09/26 02:30:03 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.00	top5: 5.50	
[09/26 02:30:03 visual_prompt]: Training 36 / 100 epoch, with learning rate 20.53484512108174
[09/26 02:30:10 visual_prompt]: Epoch 36 / 100: avg data time: 5.20e-02, avg batch time: 0.4965, average train loss: 8.5292
[09/26 02:30:11 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1674, average loss: 10.3315
[09/26 02:30:11 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 5.00	
[09/26 02:30:11 visual_prompt]: Training 37 / 100 epoch, with learning rate 20.195768441570728
[09/26 02:30:18 visual_prompt]: Epoch 37 / 100: avg data time: 4.50e-02, avg batch time: 0.4903, average train loss: 7.9087
[09/26 02:30:19 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1675, average loss: 13.7376
[09/26 02:30:19 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 5.00	
[09/26 02:30:19 visual_prompt]: Training 38 / 100 epoch, with learning rate 19.847315653655915
[09/26 02:30:26 visual_prompt]: Epoch 38 / 100: avg data time: 5.95e-02, avg batch time: 0.5040, average train loss: 7.8165
[09/26 02:30:28 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1678, average loss: 8.7395
[09/26 02:30:28 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.00	
[09/26 02:30:28 visual_prompt]: Training 39 / 100 epoch, with learning rate 19.489911293384335
[09/26 02:30:34 visual_prompt]: Epoch 39 / 100: avg data time: 4.65e-02, avg batch time: 0.4932, average train loss: 9.1484
[09/26 02:30:36 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1678, average loss: 10.4713
[09/26 02:30:36 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 5.50	
[09/26 02:30:36 visual_prompt]: Training 40 / 100 epoch, with learning rate 19.12399080291506
[09/26 02:30:43 visual_prompt]: Epoch 40 / 100: avg data time: 5.55e-02, avg batch time: 0.4994, average train loss: 8.4646
[09/26 02:30:44 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1678, average loss: 11.3815
[09/26 02:30:44 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 4.50	
[09/26 02:30:44 visual_prompt]: Training 41 / 100 epoch, with learning rate 18.75
[09/26 02:30:51 visual_prompt]: Epoch 41 / 100: avg data time: 5.86e-02, avg batch time: 0.5032, average train loss: 7.7857
[09/26 02:30:52 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1675, average loss: 9.3600
[09/26 02:30:52 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.50	top5: 6.00	
[09/26 02:30:52 visual_prompt]: Training 42 / 100 epoch, with learning rate 18.368394534823633
[09/26 02:30:59 visual_prompt]: Epoch 42 / 100: avg data time: 5.92e-02, avg batch time: 0.5042, average train loss: 7.2748
[09/26 02:31:01 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1672, average loss: 8.7918
[09/26 02:31:01 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 6.50	
[09/26 02:31:01 visual_prompt]: Training 43 / 100 epoch, with learning rate 17.979639334863467
[09/26 02:31:08 visual_prompt]: Epoch 43 / 100: avg data time: 6.07e-02, avg batch time: 0.5051, average train loss: 7.0245
[09/26 02:31:09 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1673, average loss: 10.0653
[09/26 02:31:09 visual_prompt]: Classification results with val_vtab-sun397: top1: 3.50	top5: 6.50	
[09/26 02:31:09 visual_prompt]: Training 44 / 100 epoch, with learning rate 17.584208038447503
[09/26 02:31:16 visual_prompt]: Epoch 44 / 100: avg data time: 5.61e-02, avg batch time: 0.5000, average train loss: 6.9238
[09/26 02:31:17 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1673, average loss: 11.2268
[09/26 02:31:17 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.50	top5: 4.50	
[09/26 02:31:17 visual_prompt]: Training 45 / 100 epoch, with learning rate 17.182582417698903
[09/26 02:31:24 visual_prompt]: Epoch 45 / 100: avg data time: 5.80e-02, avg batch time: 0.5035, average train loss: 7.3225
[09/26 02:31:26 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1677, average loss: 9.5880
[09/26 02:31:26 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.50	top5: 7.50	
[09/26 02:31:26 visual_prompt]: Training 46 / 100 epoch, with learning rate 16.77525179157086
[09/26 02:31:33 visual_prompt]: Epoch 46 / 100: avg data time: 5.97e-02, avg batch time: 0.5032, average train loss: 7.6487
[09/26 02:31:34 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1674, average loss: 10.6641
[09/26 02:31:34 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.50	top5: 5.50	
[09/26 02:31:34 visual_prompt]: Training 47 / 100 epoch, with learning rate 16.362712429686844
[09/26 02:31:41 visual_prompt]: Epoch 47 / 100: avg data time: 5.50e-02, avg batch time: 0.4985, average train loss: 6.7302
[09/26 02:31:42 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1674, average loss: 7.7333
[09/26 02:31:42 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 8.50	
[09/26 02:31:42 visual_prompt]: Training 48 / 100 epoch, with learning rate 15.94546694771249
[09/26 02:31:49 visual_prompt]: Epoch 48 / 100: avg data time: 4.91e-02, avg batch time: 0.4943, average train loss: 6.6894
[09/26 02:31:51 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1672, average loss: 7.5384
[09/26 02:31:51 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.00	top5: 7.50	
[09/26 02:31:51 visual_prompt]: Training 49 / 100 epoch, with learning rate 15.524023694995845
[09/26 02:31:57 visual_prompt]: Epoch 49 / 100: avg data time: 5.18e-02, avg batch time: 0.4978, average train loss: 6.2909
[09/26 02:31:59 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1674, average loss: 10.0222
[09/26 02:31:59 visual_prompt]: Classification results with val_vtab-sun397: top1: 3.00	top5: 7.00	
[09/26 02:31:59 visual_prompt]: Training 50 / 100 epoch, with learning rate 15.09889613522199
[09/26 02:32:06 visual_prompt]: Epoch 50 / 100: avg data time: 6.32e-02, avg batch time: 0.5077, average train loss: 6.4540
[09/26 02:32:07 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1675, average loss: 8.2337
[09/26 02:32:07 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.50	top5: 8.00	
[09/26 02:32:07 visual_prompt]: Training 51 / 100 epoch, with learning rate 14.670602220836631
[09/26 02:32:14 visual_prompt]: Epoch 51 / 100: avg data time: 5.70e-02, avg batch time: 0.5007, average train loss: 6.1258
[09/26 02:32:16 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1677, average loss: 9.0058
[09/26 02:32:16 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.00	top5: 7.00	
[09/26 02:32:16 visual_prompt]: Training 52 / 100 epoch, with learning rate 14.239663762000818
[09/26 02:32:22 visual_prompt]: Epoch 52 / 100: avg data time: 5.43e-02, avg batch time: 0.4979, average train loss: 5.9994
[09/26 02:32:24 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1673, average loss: 10.8747
[09/26 02:32:24 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.50	top5: 7.00	
[09/26 02:32:24 visual_prompt]: Training 53 / 100 epoch, with learning rate 13.80660579084567
[09/26 02:32:30 visual_prompt]: Epoch 53 / 100: avg data time: 4.24e-02, avg batch time: 0.4872, average train loss: 6.0486
[09/26 02:32:32 visual_prompt]: Inference (val):avg data time: 1.96e-05, avg batch time: 0.1674, average loss: 9.0516
[09/26 02:32:32 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.00	top5: 7.50	
[09/26 02:32:32 visual_prompt]: Training 54 / 100 epoch, with learning rate 13.371955921801565
[09/26 02:32:39 visual_prompt]: Epoch 54 / 100: avg data time: 5.73e-02, avg batch time: 0.5014, average train loss: 5.7992
[09/26 02:32:40 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1679, average loss: 9.6563
[09/26 02:32:40 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.50	top5: 9.00	
[09/26 02:32:40 visual_prompt]: Training 55 / 100 epoch, with learning rate 12.936243708781264
[09/26 02:32:47 visual_prompt]: Epoch 55 / 100: avg data time: 5.56e-02, avg batch time: 0.4991, average train loss: 5.9176
[09/26 02:32:49 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1678, average loss: 8.9504
[09/26 02:32:49 visual_prompt]: Classification results with val_vtab-sun397: top1: 3.00	top5: 7.50	
[09/26 02:32:49 visual_prompt]: Training 56 / 100 epoch, with learning rate 12.5
[09/26 02:32:55 visual_prompt]: Epoch 56 / 100: avg data time: 4.45e-02, avg batch time: 0.4889, average train loss: 5.5241
[09/26 02:32:57 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1673, average loss: 10.0798
[09/26 02:32:57 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.00	top5: 9.00	
[09/26 02:32:57 visual_prompt]: Training 57 / 100 epoch, with learning rate 12.063756291218741
[09/26 02:33:04 visual_prompt]: Epoch 57 / 100: avg data time: 5.49e-02, avg batch time: 0.4987, average train loss: 5.4655
[09/26 02:33:05 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1672, average loss: 10.5103
[09/26 02:33:05 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.00	top5: 8.50	
[09/26 02:33:05 visual_prompt]: Training 58 / 100 epoch, with learning rate 11.628044078198434
[09/26 02:33:12 visual_prompt]: Epoch 58 / 100: avg data time: 5.16e-02, avg batch time: 0.4955, average train loss: 5.3165
[09/26 02:33:13 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1675, average loss: 9.5399
[09/26 02:33:13 visual_prompt]: Classification results with val_vtab-sun397: top1: 3.50	top5: 9.00	
[09/26 02:33:13 visual_prompt]: Training 59 / 100 epoch, with learning rate 11.193394209154334
[09/26 02:33:20 visual_prompt]: Epoch 59 / 100: avg data time: 6.05e-02, avg batch time: 0.5037, average train loss: 5.3406
[09/26 02:33:22 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1677, average loss: 7.9473
[09/26 02:33:22 visual_prompt]: Classification results with val_vtab-sun397: top1: 5.00	top5: 9.00	
[09/26 02:33:22 visual_prompt]: Training 60 / 100 epoch, with learning rate 10.760336237999185
[09/26 02:33:28 visual_prompt]: Epoch 60 / 100: avg data time: 5.55e-02, avg batch time: 0.4989, average train loss: 5.2310
[09/26 02:33:30 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.1676, average loss: 7.8097
[09/26 02:33:30 visual_prompt]: Classification results with val_vtab-sun397: top1: 6.00	top5: 10.50	
[09/26 02:33:30 visual_prompt]: Training 61 / 100 epoch, with learning rate 10.32939777916337
[09/26 02:33:37 visual_prompt]: Epoch 61 / 100: avg data time: 4.41e-02, avg batch time: 0.4886, average train loss: 5.0987
[09/26 02:33:38 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1683, average loss: 8.7977
[09/26 02:33:38 visual_prompt]: Classification results with val_vtab-sun397: top1: 3.50	top5: 11.00	
[09/26 02:33:38 visual_prompt]: Training 62 / 100 epoch, with learning rate 9.90110386477801
[09/26 02:33:45 visual_prompt]: Epoch 62 / 100: avg data time: 5.75e-02, avg batch time: 0.5032, average train loss: 5.0230
[09/26 02:33:46 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1673, average loss: 8.9176
[09/26 02:33:46 visual_prompt]: Classification results with val_vtab-sun397: top1: 5.50	top5: 9.50	
[09/26 02:33:46 visual_prompt]: Training 63 / 100 epoch, with learning rate 9.475976305004155
[09/26 02:33:53 visual_prompt]: Epoch 63 / 100: avg data time: 5.13e-02, avg batch time: 0.4955, average train loss: 5.0335
[09/26 02:33:55 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1672, average loss: 7.8423
[09/26 02:33:55 visual_prompt]: Classification results with val_vtab-sun397: top1: 4.00	top5: 11.00	
[09/26 02:33:55 visual_prompt]: Training 64 / 100 epoch, with learning rate 9.05453305228751
[09/26 02:34:01 visual_prompt]: Epoch 64 / 100: avg data time: 4.84e-02, avg batch time: 0.4940, average train loss: 4.8255
[09/26 02:34:03 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1674, average loss: 7.8702
[09/26 02:34:03 visual_prompt]: Classification results with val_vtab-sun397: top1: 6.00	top5: 12.00	
[09/26 02:34:03 visual_prompt]: Training 65 / 100 epoch, with learning rate 8.637287570313159
[09/26 02:34:10 visual_prompt]: Epoch 65 / 100: avg data time: 5.93e-02, avg batch time: 0.5029, average train loss: 4.8887
[09/26 02:34:11 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1675, average loss: 9.8460
[09/26 02:34:11 visual_prompt]: Classification results with val_vtab-sun397: top1: 3.00	top5: 11.00	
[09/26 02:34:11 visual_prompt]: Training 66 / 100 epoch, with learning rate 8.224748208429142
[09/26 02:34:18 visual_prompt]: Epoch 66 / 100: avg data time: 5.37e-02, avg batch time: 0.4977, average train loss: 4.8883
[09/26 02:34:19 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1672, average loss: 7.8658
[09/26 02:34:19 visual_prompt]: Classification results with val_vtab-sun397: top1: 5.00	top5: 12.50	
[09/26 02:34:19 visual_prompt]: Training 67 / 100 epoch, with learning rate 7.817417582301099
[09/26 02:34:26 visual_prompt]: Epoch 67 / 100: avg data time: 5.59e-02, avg batch time: 0.5003, average train loss: 4.8037
[09/26 02:34:28 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1673, average loss: 6.7640
[09/26 02:34:28 visual_prompt]: Classification results with val_vtab-sun397: top1: 4.00	top5: 13.00	
[09/26 02:34:28 visual_prompt]: Training 68 / 100 epoch, with learning rate 7.415791961552499
[09/26 02:34:35 visual_prompt]: Epoch 68 / 100: avg data time: 5.57e-02, avg batch time: 0.4994, average train loss: 4.6556
[09/26 02:34:36 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1677, average loss: 9.1198
[09/26 02:34:36 visual_prompt]: Classification results with val_vtab-sun397: top1: 5.00	top5: 10.00	
[09/26 02:34:36 visual_prompt]: Training 69 / 100 epoch, with learning rate 7.020360665136531
[09/26 02:34:43 visual_prompt]: Epoch 69 / 100: avg data time: 5.35e-02, avg batch time: 0.4968, average train loss: 4.4789
[09/26 02:34:44 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1671, average loss: 8.6430
[09/26 02:34:44 visual_prompt]: Classification results with val_vtab-sun397: top1: 3.50	top5: 11.00	
[09/26 02:34:44 visual_prompt]: Training 70 / 100 epoch, with learning rate 6.631605465176368
[09/26 02:34:51 visual_prompt]: Epoch 70 / 100: avg data time: 5.54e-02, avg batch time: 0.4999, average train loss: 4.4351
[09/26 02:34:53 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1675, average loss: 8.1508
[09/26 02:34:53 visual_prompt]: Classification results with val_vtab-sun397: top1: 3.00	top5: 11.50	
[09/26 02:34:53 visual_prompt]: Training 71 / 100 epoch, with learning rate 6.250000000000003
[09/26 02:34:59 visual_prompt]: Epoch 71 / 100: avg data time: 5.87e-02, avg batch time: 0.5025, average train loss: 4.4067
[09/26 02:35:01 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1675, average loss: 7.5980
[09/26 02:35:01 visual_prompt]: Classification results with val_vtab-sun397: top1: 4.50	top5: 13.50	
[09/26 02:35:01 visual_prompt]: Training 72 / 100 epoch, with learning rate 5.87600919708494
[09/26 02:35:08 visual_prompt]: Epoch 72 / 100: avg data time: 4.18e-02, avg batch time: 0.4882, average train loss: 4.3624
[09/26 02:35:09 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1672, average loss: 9.1639
[09/26 02:35:09 visual_prompt]: Classification results with val_vtab-sun397: top1: 5.50	top5: 11.50	
[09/26 02:35:09 visual_prompt]: Training 73 / 100 epoch, with learning rate 5.510088706615666
[09/26 02:35:16 visual_prompt]: Epoch 73 / 100: avg data time: 5.80e-02, avg batch time: 0.5016, average train loss: 4.2352
[09/26 02:35:18 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1676, average loss: 8.9506
[09/26 02:35:18 visual_prompt]: Classification results with val_vtab-sun397: top1: 5.50	top5: 12.00	
[09/26 02:35:18 visual_prompt]: Training 74 / 100 epoch, with learning rate 5.1526843463440875
[09/26 02:35:24 visual_prompt]: Epoch 74 / 100: avg data time: 5.73e-02, avg batch time: 0.5017, average train loss: 4.1302
[09/26 02:35:26 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1678, average loss: 9.4011
[09/26 02:35:26 visual_prompt]: Classification results with val_vtab-sun397: top1: 4.50	top5: 12.00	
[09/26 02:35:26 visual_prompt]: Training 75 / 100 epoch, with learning rate 4.804231558429271
[09/26 02:35:33 visual_prompt]: Epoch 75 / 100: avg data time: 5.63e-02, avg batch time: 0.5009, average train loss: 4.1125
[09/26 02:35:34 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1675, average loss: 8.0443
[09/26 02:35:34 visual_prompt]: Classification results with val_vtab-sun397: top1: 6.00	top5: 14.00	
[09/26 02:35:34 visual_prompt]: Training 76 / 100 epoch, with learning rate 4.465154878918258
[09/26 02:35:41 visual_prompt]: Epoch 76 / 100: avg data time: 5.02e-02, avg batch time: 0.4944, average train loss: 4.0939
[09/26 02:35:42 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1674, average loss: 7.7883
[09/26 02:35:42 visual_prompt]: Classification results with val_vtab-sun397: top1: 5.50	top5: 12.00	
[09/26 02:35:42 visual_prompt]: Training 77 / 100 epoch, with learning rate 4.135867420514276
[09/26 02:35:49 visual_prompt]: Epoch 77 / 100: avg data time: 5.09e-02, avg batch time: 0.4958, average train loss: 4.0147
[09/26 02:35:50 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1676, average loss: 7.4242
[09/26 02:35:50 visual_prompt]: Classification results with val_vtab-sun397: top1: 6.50	top5: 12.50	
[09/26 02:35:50 visual_prompt]: Best epoch 77: best metric: 0.065
[09/26 02:35:50 visual_prompt]: Training 78 / 100 epoch, with learning rate 3.816770369262533
[09/26 02:35:57 visual_prompt]: Epoch 78 / 100: avg data time: 4.96e-02, avg batch time: 0.4948, average train loss: 3.9634
[09/26 02:35:59 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1673, average loss: 9.3168
[09/26 02:35:59 visual_prompt]: Classification results with val_vtab-sun397: top1: 4.50	top5: 13.00	
[09/26 02:35:59 visual_prompt]: Training 79 / 100 epoch, with learning rate 3.508252495766863
[09/26 02:36:05 visual_prompt]: Epoch 79 / 100: avg data time: 4.81e-02, avg batch time: 0.4952, average train loss: 3.8463
[09/26 02:36:07 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1676, average loss: 9.0139
[09/26 02:36:07 visual_prompt]: Classification results with val_vtab-sun397: top1: 5.50	top5: 11.50	
[09/26 02:36:07 visual_prompt]: Training 80 / 100 epoch, with learning rate 3.2106896815325707
[09/26 02:36:14 visual_prompt]: Epoch 80 / 100: avg data time: 4.71e-02, avg batch time: 0.4941, average train loss: 3.8175
[09/26 02:36:15 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1677, average loss: 8.1114
[09/26 02:36:15 visual_prompt]: Classification results with val_vtab-sun397: top1: 7.00	top5: 13.00	
[09/26 02:36:15 visual_prompt]: Best epoch 80: best metric: 0.070
[09/26 02:36:15 visual_prompt]: Training 81 / 100 epoch, with learning rate 2.924444461012776
[09/26 02:36:22 visual_prompt]: Epoch 81 / 100: avg data time: 5.61e-02, avg batch time: 0.5006, average train loss: 3.7626
[09/26 02:36:24 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1676, average loss: 8.3970
[09/26 02:36:24 visual_prompt]: Classification results with val_vtab-sun397: top1: 4.50	top5: 12.00	
[09/26 02:36:24 visual_prompt]: Training 82 / 100 epoch, with learning rate 2.6498655799159763
[09/26 02:36:30 visual_prompt]: Epoch 82 / 100: avg data time: 4.80e-02, avg batch time: 0.4921, average train loss: 3.7557
[09/26 02:36:32 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1678, average loss: 8.2221
[09/26 02:36:32 visual_prompt]: Classification results with val_vtab-sun397: top1: 7.00	top5: 12.50	
[09/26 02:36:32 visual_prompt]: Training 83 / 100 epoch, with learning rate 2.387287570313158
[09/26 02:36:38 visual_prompt]: Epoch 83 / 100: avg data time: 4.20e-02, avg batch time: 0.4862, average train loss: 3.6629
[09/26 02:36:40 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1674, average loss: 8.6584
[09/26 02:36:40 visual_prompt]: Classification results with val_vtab-sun397: top1: 5.50	top5: 12.50	
[09/26 02:36:40 visual_prompt]: Training 84 / 100 epoch, with learning rate 2.13703034306198
[09/26 02:36:47 visual_prompt]: Epoch 84 / 100: avg data time: 4.75e-02, avg batch time: 0.4924, average train loss: 3.6396
[09/26 02:36:48 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1675, average loss: 9.1129
[09/26 02:36:48 visual_prompt]: Classification results with val_vtab-sun397: top1: 5.50	top5: 13.50	
[09/26 02:36:48 visual_prompt]: Training 85 / 100 epoch, with learning rate 1.8993987980446756
[09/26 02:36:55 visual_prompt]: Epoch 85 / 100: avg data time: 4.95e-02, avg batch time: 0.4941, average train loss: 3.6024
[09/26 02:36:56 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1676, average loss: 8.3335
[09/26 02:36:56 visual_prompt]: Classification results with val_vtab-sun397: top1: 5.50	top5: 12.00	
[09/26 02:36:56 visual_prompt]: Training 86 / 100 epoch, with learning rate 1.674682452694516
[09/26 02:37:03 visual_prompt]: Epoch 86 / 100: avg data time: 5.77e-02, avg batch time: 0.5020, average train loss: 3.6627
[09/26 02:37:05 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1677, average loss: 8.4129
[09/26 02:37:05 visual_prompt]: Classification results with val_vtab-sun397: top1: 6.50	top5: 12.50	
[09/26 02:37:05 visual_prompt]: Training 87 / 100 epoch, with learning rate 1.4631550892634126
[09/26 02:37:12 visual_prompt]: Epoch 87 / 100: avg data time: 5.39e-02, avg batch time: 0.4987, average train loss: 3.6543
[09/26 02:37:13 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1675, average loss: 7.8487
[09/26 02:37:13 visual_prompt]: Classification results with val_vtab-sun397: top1: 6.50	top5: 14.00	
[09/26 02:37:13 visual_prompt]: Training 88 / 100 epoch, with learning rate 1.2650744212604148
[09/26 02:37:20 visual_prompt]: Epoch 88 / 100: avg data time: 4.51e-02, avg batch time: 0.4904, average train loss: 3.5361
[09/26 02:37:21 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1679, average loss: 8.0948
[09/26 02:37:21 visual_prompt]: Classification results with val_vtab-sun397: top1: 6.00	top5: 13.00	
[09/26 02:37:21 visual_prompt]: Training 89 / 100 epoch, with learning rate 1.0806817794674877
[09/26 02:37:28 visual_prompt]: Epoch 89 / 100: avg data time: 5.77e-02, avg batch time: 0.5016, average train loss: 3.5327
[09/26 02:37:30 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1673, average loss: 7.6357
[09/26 02:37:30 visual_prompt]: Classification results with val_vtab-sun397: top1: 7.00	top5: 14.00	
[09/26 02:37:30 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.9102018179151585
[09/26 02:37:36 visual_prompt]: Epoch 90 / 100: avg data time: 4.81e-02, avg batch time: 0.4938, average train loss: 3.4932
[09/26 02:37:38 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1676, average loss: 8.6206
[09/26 02:37:38 visual_prompt]: Classification results with val_vtab-sun397: top1: 6.50	top5: 13.00	
[09/26 02:37:38 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.753842240176146
[09/26 02:37:45 visual_prompt]: Epoch 91 / 100: avg data time: 5.88e-02, avg batch time: 0.5024, average train loss: 3.4668
[09/26 02:37:46 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1674, average loss: 7.8710
[09/26 02:37:46 visual_prompt]: Classification results with val_vtab-sun397: top1: 7.00	top5: 13.50	
[09/26 02:37:46 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.6117935463105808
[09/26 02:37:53 visual_prompt]: Epoch 92 / 100: avg data time: 4.28e-02, avg batch time: 0.4876, average train loss: 3.5333
[09/26 02:37:54 visual_prompt]: Inference (val):avg data time: 4.19e-05, avg batch time: 0.1675, average loss: 8.1422
[09/26 02:37:54 visual_prompt]: Classification results with val_vtab-sun397: top1: 7.00	top5: 13.00	
[09/26 02:37:54 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.4842288007710138
[09/26 02:38:01 visual_prompt]: Epoch 93 / 100: avg data time: 4.37e-02, avg batch time: 0.4892, average train loss: 3.5132
[09/26 02:38:03 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1675, average loss: 8.1547
[09/26 02:38:03 visual_prompt]: Classification results with val_vtab-sun397: top1: 5.50	top5: 13.00	
[09/26 02:38:03 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.3713034215500441
[09/26 02:38:09 visual_prompt]: Epoch 94 / 100: avg data time: 5.47e-02, avg batch time: 0.4994, average train loss: 3.4740
[09/26 02:38:11 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1677, average loss: 8.0345
[09/26 02:38:11 visual_prompt]: Classification results with val_vtab-sun397: top1: 6.00	top5: 12.50	
[09/26 02:38:11 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.2731549908274289
[09/26 02:38:18 visual_prompt]: Epoch 95 / 100: avg data time: 5.99e-02, avg batch time: 0.5032, average train loss: 3.4078
[09/26 02:38:19 visual_prompt]: Inference (val):avg data time: 4.63e-05, avg batch time: 0.1676, average loss: 7.9007
[09/26 02:38:19 visual_prompt]: Classification results with val_vtab-sun397: top1: 6.00	top5: 13.00	
[09/26 02:38:19 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.18990308734739975
[09/26 02:38:26 visual_prompt]: Epoch 96 / 100: avg data time: 5.16e-02, avg batch time: 0.4962, average train loss: 3.4544
[09/26 02:38:28 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1678, average loss: 8.0047
[09/26 02:38:28 visual_prompt]: Classification results with val_vtab-sun397: top1: 6.00	top5: 12.50	
[09/26 02:38:28 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.12164914073037048
[09/26 02:38:34 visual_prompt]: Epoch 97 / 100: avg data time: 4.72e-02, avg batch time: 0.4907, average train loss: 3.4181
[09/26 02:38:36 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1673, average loss: 8.1481
[09/26 02:38:36 visual_prompt]: Classification results with val_vtab-sun397: top1: 5.50	top5: 12.50	
[09/26 02:38:36 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.06847630789658388
[09/26 02:38:42 visual_prompt]: Epoch 98 / 100: avg data time: 4.25e-02, avg batch time: 0.4878, average train loss: 3.4487
[09/26 02:38:44 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1678, average loss: 8.0715
[09/26 02:38:44 visual_prompt]: Classification results with val_vtab-sun397: top1: 5.50	top5: 13.00	
[09/26 02:38:44 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.03044937175219753
[09/26 02:38:51 visual_prompt]: Epoch 99 / 100: avg data time: 4.06e-02, avg batch time: 0.4865, average train loss: 3.4358
[09/26 02:38:52 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1677, average loss: 8.0479
[09/26 02:38:52 visual_prompt]: Classification results with val_vtab-sun397: top1: 5.50	top5: 13.00	
[09/26 02:38:52 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0076146622613029735
[09/26 02:38:59 visual_prompt]: Epoch 100 / 100: avg data time: 5.12e-02, avg batch time: 0.4972, average train loss: 3.4089
[09/26 02:39:00 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.1675, average loss: 8.0488
[09/26 02:39:00 visual_prompt]: Classification results with val_vtab-sun397: top1: 5.50	top5: 13.00	
[09/26 02:39:00 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 02:39:00 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              0
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 02:39:00 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-sun397', 'DATA.NUMBER_CLASSES', '397', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 02:39:00 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 02:39:00 visual_prompt]: Training with config:
[09/26 02:39:00 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-sun397/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr10.0_wd0.01/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 10.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-sun397', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 397, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 02:39:00 visual_prompt]: Loading training data...
[09/26 02:39:00 visual_prompt]: Constructing vtab-sun397 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split train[:800], from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/26 02:39:02 visual_prompt]: Number of images: 800
[09/26 02:39:02 visual_prompt]: Number of classes: 309 / 397
[09/26 02:39:02 visual_prompt]: Loading validation data...
[09/26 02:39:02 visual_prompt]: Constructing vtab-sun397 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split validation[:200], from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/26 02:39:02 visual_prompt]: Number of images: 200
[09/26 02:39:02 visual_prompt]: Number of classes: 136 / 397
[09/26 02:39:02 visual_prompt]: Constructing models...
[09/26 02:39:05 visual_prompt]: Total Parameters: 86564749	 Gradient Parameters: 766093
[09/26 02:39:05 visual_prompt]: tuned percent:0.885
[09/26 02:39:05 visual_prompt]: Device used for model: 0
[09/26 02:39:05 visual_prompt]: Setting up Evaluator...
[09/26 02:39:05 visual_prompt]: Setting up Trainer...
[09/26 02:39:05 visual_prompt]: 	Setting up the optimizer...
[09/26 02:39:05 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 02:39:12 visual_prompt]: Epoch 1 / 100: avg data time: 4.61e-02, avg batch time: 0.4907, average train loss: 5.9912
[09/26 02:39:13 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1670, average loss: 6.0097
[09/26 02:39:13 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/26 02:39:13 visual_prompt]: Training 2 / 100 epoch, with learning rate 1.0
[09/26 02:39:20 visual_prompt]: Epoch 2 / 100: avg data time: 5.07e-02, avg batch time: 0.4932, average train loss: 5.7497
[09/26 02:39:21 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1669, average loss: 5.8042
[09/26 02:39:21 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 5.00	
[09/26 02:39:21 visual_prompt]: Best epoch 2: best metric: 0.005
[09/26 02:39:21 visual_prompt]: Training 3 / 100 epoch, with learning rate 2.0
[09/26 02:39:28 visual_prompt]: Epoch 3 / 100: avg data time: 4.56e-02, avg batch time: 0.4887, average train loss: 5.6963
[09/26 02:39:30 visual_prompt]: Inference (val):avg data time: 1.94e-05, avg batch time: 0.1673, average loss: 5.8507
[09/26 02:39:30 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 4.50	
[09/26 02:39:30 visual_prompt]: Best epoch 3: best metric: 0.015
[09/26 02:39:30 visual_prompt]: Training 4 / 100 epoch, with learning rate 3.0
[09/26 02:39:36 visual_prompt]: Epoch 4 / 100: avg data time: 5.93e-02, avg batch time: 0.5026, average train loss: 5.7273
[09/26 02:39:38 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1669, average loss: 5.8455
[09/26 02:39:38 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.50	
[09/26 02:39:38 visual_prompt]: Training 5 / 100 epoch, with learning rate 4.0
[09/26 02:39:45 visual_prompt]: Epoch 5 / 100: avg data time: 6.01e-02, avg batch time: 0.5044, average train loss: 5.7145
[09/26 02:39:46 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1676, average loss: 5.8702
[09/26 02:39:46 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 5.50	
[09/26 02:39:46 visual_prompt]: Training 6 / 100 epoch, with learning rate 5.0
[09/26 02:39:53 visual_prompt]: Epoch 6 / 100: avg data time: 5.40e-02, avg batch time: 0.4978, average train loss: 5.7891
[09/26 02:39:55 visual_prompt]: Inference (val):avg data time: 1.97e-05, avg batch time: 0.1677, average loss: 5.9666
[09/26 02:39:55 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.50	
[09/26 02:39:55 visual_prompt]: Training 7 / 100 epoch, with learning rate 6.0
[09/26 02:40:01 visual_prompt]: Epoch 7 / 100: avg data time: 5.47e-02, avg batch time: 0.4983, average train loss: 7.4752
[09/26 02:40:03 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1677, average loss: 7.3464
[09/26 02:40:03 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 3.50	
[09/26 02:40:03 visual_prompt]: Training 8 / 100 epoch, with learning rate 7.0
[09/26 02:40:10 visual_prompt]: Epoch 8 / 100: avg data time: 5.48e-02, avg batch time: 0.4971, average train loss: 8.2188
[09/26 02:40:11 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1674, average loss: 7.6768
[09/26 02:40:11 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 2.50	
[09/26 02:40:11 visual_prompt]: Training 9 / 100 epoch, with learning rate 8.0
[09/26 02:40:18 visual_prompt]: Epoch 9 / 100: avg data time: 4.41e-02, avg batch time: 0.4904, average train loss: 9.7693
[09/26 02:40:19 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1677, average loss: 7.8674
[09/26 02:40:19 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.50	
[09/26 02:40:19 visual_prompt]: Training 10 / 100 epoch, with learning rate 9.0
[09/26 02:40:26 visual_prompt]: Epoch 10 / 100: avg data time: 5.99e-02, avg batch time: 0.5026, average train loss: 10.5183
[09/26 02:40:28 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1675, average loss: 8.0923
[09/26 02:40:28 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 1.00	
[09/26 02:40:28 visual_prompt]: Training 11 / 100 epoch, with learning rate 10.0
[09/26 02:40:34 visual_prompt]: Epoch 11 / 100: avg data time: 5.34e-02, avg batch time: 0.4979, average train loss: 10.5575
[09/26 02:40:36 visual_prompt]: Inference (val):avg data time: 1.90e-05, avg batch time: 0.1673, average loss: 9.1036
[09/26 02:40:36 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 2.50	
[09/26 02:40:36 visual_prompt]: Training 12 / 100 epoch, with learning rate 9.996954135095478
[09/26 02:40:43 visual_prompt]: Epoch 12 / 100: avg data time: 6.06e-02, avg batch time: 0.5043, average train loss: 10.7046
[09/26 02:40:44 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1675, average loss: 8.0867
[09/26 02:40:44 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.00	
[09/26 02:40:44 visual_prompt]: Training 13 / 100 epoch, with learning rate 9.987820251299121
[09/26 02:40:51 visual_prompt]: Epoch 13 / 100: avg data time: 5.88e-02, avg batch time: 0.5028, average train loss: 8.6488
[09/26 02:40:53 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1674, average loss: 9.1428
[09/26 02:40:53 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.50	
[09/26 02:40:53 visual_prompt]: Training 14 / 100 epoch, with learning rate 9.972609476841367
[09/26 02:40:59 visual_prompt]: Epoch 14 / 100: avg data time: 5.36e-02, avg batch time: 0.4969, average train loss: 10.0357
[09/26 02:41:01 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1679, average loss: 8.8471
[09/26 02:41:01 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 2.00	
[09/26 02:41:01 visual_prompt]: Training 15 / 100 epoch, with learning rate 9.951340343707852
[09/26 02:41:08 visual_prompt]: Epoch 15 / 100: avg data time: 5.39e-02, avg batch time: 0.4985, average train loss: 9.9439
[09/26 02:41:09 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1673, average loss: 8.3934
[09/26 02:41:09 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.00	
[09/26 02:41:09 visual_prompt]: Training 16 / 100 epoch, with learning rate 9.924038765061042
[09/26 02:41:16 visual_prompt]: Epoch 16 / 100: avg data time: 4.95e-02, avg batch time: 0.4934, average train loss: 9.6815
[09/26 02:41:18 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1681, average loss: 11.1233
[09/26 02:41:18 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 2.00	
[09/26 02:41:18 visual_prompt]: Training 17 / 100 epoch, with learning rate 9.890738003669028
[09/26 02:41:24 visual_prompt]: Epoch 17 / 100: avg data time: 5.52e-02, avg batch time: 0.4995, average train loss: 11.1595
[09/26 02:41:26 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1674, average loss: 8.7959
[09/26 02:41:26 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 3.00	
[09/26 02:41:26 visual_prompt]: Training 18 / 100 epoch, with learning rate 9.851478631379981
[09/26 02:41:33 visual_prompt]: Epoch 18 / 100: avg data time: 4.55e-02, avg batch time: 0.4906, average train loss: 11.0216
[09/26 02:41:34 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1674, average loss: 10.1968
[09/26 02:41:34 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.00	
[09/26 02:41:34 visual_prompt]: Training 19 / 100 epoch, with learning rate 9.806308479691594
[09/26 02:41:41 visual_prompt]: Epoch 19 / 100: avg data time: 4.13e-02, avg batch time: 0.4856, average train loss: 10.2784
[09/26 02:41:42 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1673, average loss: 8.5535
[09/26 02:41:42 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 2.00	
[09/26 02:41:42 visual_prompt]: Training 20 / 100 epoch, with learning rate 9.755282581475768
[09/26 02:41:49 visual_prompt]: Epoch 20 / 100: avg data time: 5.23e-02, avg batch time: 0.4954, average train loss: 8.9949
[09/26 02:41:50 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1672, average loss: 7.9448
[09/26 02:41:50 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 1.00	
[09/26 02:41:50 visual_prompt]: Training 21 / 100 epoch, with learning rate 9.698463103929543
[09/26 02:41:57 visual_prompt]: Epoch 21 / 100: avg data time: 5.80e-02, avg batch time: 0.5004, average train loss: 9.2280
[09/26 02:41:59 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1674, average loss: 7.9241
[09/26 02:41:59 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 3.50	
[09/26 02:41:59 visual_prompt]: Training 22 / 100 epoch, with learning rate 9.635919272833938
[09/26 02:42:06 visual_prompt]: Epoch 22 / 100: avg data time: 5.89e-02, avg batch time: 0.5031, average train loss: 10.3029
[09/26 02:42:07 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1676, average loss: 10.3867
[09/26 02:42:07 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.00	
[09/26 02:42:07 visual_prompt]: Training 23 / 100 epoch, with learning rate 9.567727288213003
[09/26 02:42:14 visual_prompt]: Epoch 23 / 100: avg data time: 5.31e-02, avg batch time: 0.4974, average train loss: 11.1910
[09/26 02:42:15 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1676, average loss: 9.1738
[09/26 02:42:15 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 5.00	
[09/26 02:42:15 visual_prompt]: Training 24 / 100 epoch, with learning rate 9.493970231495835
[09/26 02:42:22 visual_prompt]: Epoch 24 / 100: avg data time: 5.70e-02, avg batch time: 0.4994, average train loss: 11.2621
[09/26 02:42:24 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1681, average loss: 8.7546
[09/26 02:42:24 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/26 02:42:24 visual_prompt]: Training 25 / 100 epoch, with learning rate 9.414737964294634
[09/26 02:42:30 visual_prompt]: Epoch 25 / 100: avg data time: 4.33e-02, avg batch time: 0.4876, average train loss: 9.8797
[09/26 02:42:32 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1673, average loss: 8.2079
[09/26 02:42:32 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 2.50	
[09/26 02:42:32 visual_prompt]: Training 26 / 100 epoch, with learning rate 9.330127018922195
[09/26 02:42:39 visual_prompt]: Epoch 26 / 100: avg data time: 4.85e-02, avg batch time: 0.4933, average train loss: 8.7273
[09/26 02:42:40 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1673, average loss: 7.3618
[09/26 02:42:40 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 4.00	
[09/26 02:42:40 visual_prompt]: Training 27 / 100 epoch, with learning rate 9.240240480782129
[09/26 02:42:47 visual_prompt]: Epoch 27 / 100: avg data time: 5.38e-02, avg batch time: 0.4975, average train loss: 7.8931
[09/26 02:42:48 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1677, average loss: 7.8330
[09/26 02:42:48 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 6.50	
[09/26 02:42:48 visual_prompt]: Training 28 / 100 epoch, with learning rate 9.145187862775208
[09/26 02:42:55 visual_prompt]: Epoch 28 / 100: avg data time: 5.34e-02, avg batch time: 0.4978, average train loss: 8.6192
[09/26 02:42:57 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1674, average loss: 7.6768
[09/26 02:42:57 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.00	top5: 5.50	
[09/26 02:42:57 visual_prompt]: Best epoch 28: best metric: 0.020
[09/26 02:42:57 visual_prompt]: Training 29 / 100 epoch, with learning rate 9.045084971874736
[09/26 02:43:04 visual_prompt]: Epoch 29 / 100: avg data time: 5.64e-02, avg batch time: 0.5018, average train loss: 8.9985
[09/26 02:43:05 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1675, average loss: 7.9998
[09/26 02:43:05 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.00	
[09/26 02:43:05 visual_prompt]: Training 30 / 100 epoch, with learning rate 8.940053768033609
[09/26 02:43:12 visual_prompt]: Epoch 30 / 100: avg data time: 5.81e-02, avg batch time: 0.5033, average train loss: 8.9658
[09/26 02:43:13 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1674, average loss: 8.1163
[09/26 02:43:13 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 3.00	
[09/26 02:43:13 visual_prompt]: Training 31 / 100 epoch, with learning rate 8.83022221559489
[09/26 02:43:20 visual_prompt]: Epoch 31 / 100: avg data time: 5.45e-02, avg batch time: 0.4976, average train loss: 8.8362
[09/26 02:43:22 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1677, average loss: 7.5820
[09/26 02:43:22 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 2.00	
[09/26 02:43:22 visual_prompt]: Training 32 / 100 epoch, with learning rate 8.715724127386972
[09/26 02:43:29 visual_prompt]: Epoch 32 / 100: avg data time: 6.20e-02, avg batch time: 0.5046, average train loss: 9.3940
[09/26 02:43:30 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1676, average loss: 8.0085
[09/26 02:43:30 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.00	
[09/26 02:43:30 visual_prompt]: Training 33 / 100 epoch, with learning rate 8.596699001693256
[09/26 02:43:37 visual_prompt]: Epoch 33 / 100: avg data time: 5.41e-02, avg batch time: 0.4977, average train loss: 9.4090
[09/26 02:43:38 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1677, average loss: 8.4433
[09/26 02:43:38 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/26 02:43:38 visual_prompt]: Training 34 / 100 epoch, with learning rate 8.473291852294986
[09/26 02:43:45 visual_prompt]: Epoch 34 / 100: avg data time: 4.95e-02, avg batch time: 0.4929, average train loss: 9.8633
[09/26 02:43:47 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1672, average loss: 8.4056
[09/26 02:43:47 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.00	
[09/26 02:43:47 visual_prompt]: Training 35 / 100 epoch, with learning rate 8.345653031794292
[09/26 02:43:53 visual_prompt]: Epoch 35 / 100: avg data time: 4.38e-02, avg batch time: 0.4888, average train loss: 10.1492
[09/26 02:43:55 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1680, average loss: 7.5285
[09/26 02:43:55 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.50	top5: 4.50	
[09/26 02:43:55 visual_prompt]: Best epoch 35: best metric: 0.025
[09/26 02:43:55 visual_prompt]: Training 36 / 100 epoch, with learning rate 8.213938048432697
[09/26 02:44:01 visual_prompt]: Epoch 36 / 100: avg data time: 4.92e-02, avg batch time: 0.4953, average train loss: 9.4061
[09/26 02:44:03 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1675, average loss: 7.9721
[09/26 02:44:03 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 5.00	
[09/26 02:44:03 visual_prompt]: Training 37 / 100 epoch, with learning rate 8.078307376628292
[09/26 02:44:10 visual_prompt]: Epoch 37 / 100: avg data time: 4.54e-02, avg batch time: 0.4904, average train loss: 8.9895
[09/26 02:44:11 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.1679, average loss: 8.7188
[09/26 02:44:11 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 4.50	
[09/26 02:44:11 visual_prompt]: Training 38 / 100 epoch, with learning rate 7.938926261462366
[09/26 02:44:18 visual_prompt]: Epoch 38 / 100: avg data time: 5.43e-02, avg batch time: 0.4984, average train loss: 9.4271
[09/26 02:44:20 visual_prompt]: Inference (val):avg data time: 3.90e-05, avg batch time: 0.1674, average loss: 7.9669
[09/26 02:44:20 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 3.50	
[09/26 02:44:20 visual_prompt]: Training 39 / 100 epoch, with learning rate 7.795964517353734
[09/26 02:44:26 visual_prompt]: Epoch 39 / 100: avg data time: 4.74e-02, avg batch time: 0.4928, average train loss: 8.4741
[09/26 02:44:28 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1675, average loss: 8.5032
[09/26 02:44:28 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 5.00	
[09/26 02:44:28 visual_prompt]: Training 40 / 100 epoch, with learning rate 7.649596321166024
[09/26 02:44:35 visual_prompt]: Epoch 40 / 100: avg data time: 5.64e-02, avg batch time: 0.5020, average train loss: 8.0367
[09/26 02:44:36 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1688, average loss: 7.7317
[09/26 02:44:36 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/26 02:44:36 visual_prompt]: Training 41 / 100 epoch, with learning rate 7.5
[09/26 02:44:43 visual_prompt]: Epoch 41 / 100: avg data time: 5.03e-02, avg batch time: 0.4933, average train loss: 7.4404
[09/26 02:44:44 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1671, average loss: 7.7389
[09/26 02:44:44 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.00	top5: 3.50	
[09/26 02:44:44 visual_prompt]: Training 42 / 100 epoch, with learning rate 7.347357813929454
[09/26 02:44:51 visual_prompt]: Epoch 42 / 100: avg data time: 5.23e-02, avg batch time: 0.4955, average train loss: 6.8508
[09/26 02:44:53 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1674, average loss: 6.9764
[09/26 02:44:53 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.50	
[09/26 02:44:53 visual_prompt]: Training 43 / 100 epoch, with learning rate 7.191855733945387
[09/26 02:44:59 visual_prompt]: Epoch 43 / 100: avg data time: 4.43e-02, avg batch time: 0.4875, average train loss: 7.0342
[09/26 02:45:01 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1674, average loss: 18.5754
[09/26 02:45:01 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.50	
[09/26 02:45:01 visual_prompt]: Training 44 / 100 epoch, with learning rate 7.033683215379002
[09/26 02:45:08 visual_prompt]: Epoch 44 / 100: avg data time: 5.71e-02, avg batch time: 0.5002, average train loss: 8.9790
[09/26 02:45:09 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1677, average loss: 6.9697
[09/26 02:45:09 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.50	top5: 6.00	
[09/26 02:45:09 visual_prompt]: Training 45 / 100 epoch, with learning rate 6.873032967079561
[09/26 02:45:16 visual_prompt]: Epoch 45 / 100: avg data time: 4.72e-02, avg batch time: 0.4919, average train loss: 11.8150
[09/26 02:45:17 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1672, average loss: 9.0046
[09/26 02:45:17 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 0.50	
[09/26 02:45:17 visual_prompt]: Training 46 / 100 epoch, with learning rate 6.710100716628345
[09/26 02:45:24 visual_prompt]: Epoch 46 / 100: avg data time: 4.38e-02, avg batch time: 0.4889, average train loss: 11.1667
[09/26 02:45:26 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1676, average loss: 8.6280
[09/26 02:45:26 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.00	
[09/26 02:45:26 visual_prompt]: Training 47 / 100 epoch, with learning rate 6.545084971874737
[09/26 02:45:32 visual_prompt]: Epoch 47 / 100: avg data time: 5.09e-02, avg batch time: 0.4952, average train loss: 10.1091
[09/26 02:45:34 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1672, average loss: 8.2931
[09/26 02:45:34 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/26 02:45:34 visual_prompt]: Training 48 / 100 epoch, with learning rate 6.378186779084995
[09/26 02:45:41 visual_prompt]: Epoch 48 / 100: avg data time: 5.63e-02, avg batch time: 0.4997, average train loss: 10.2571
[09/26 02:45:42 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1677, average loss: 9.2780
[09/26 02:45:42 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 3.00	
[09/26 02:45:42 visual_prompt]: Training 49 / 100 epoch, with learning rate 6.209609477998338
[09/26 02:45:49 visual_prompt]: Epoch 49 / 100: avg data time: 5.48e-02, avg batch time: 0.4985, average train loss: 9.0071
[09/26 02:45:51 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1674, average loss: 8.8170
[09/26 02:45:51 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.50	
[09/26 02:45:51 visual_prompt]: Training 50 / 100 epoch, with learning rate 6.039558454088796
[09/26 02:45:57 visual_prompt]: Epoch 50 / 100: avg data time: 4.36e-02, avg batch time: 0.4894, average train loss: 8.3414
[09/26 02:45:59 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1674, average loss: 8.6858
[09/26 02:45:59 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.50	
[09/26 02:45:59 visual_prompt]: Training 51 / 100 epoch, with learning rate 5.868240888334652
[09/26 02:46:06 visual_prompt]: Epoch 51 / 100: avg data time: 5.74e-02, avg batch time: 0.5014, average train loss: 8.8441
[09/26 02:46:07 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1676, average loss: 8.2699
[09/26 02:46:07 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 2.00	
[09/26 02:46:07 visual_prompt]: Training 52 / 100 epoch, with learning rate 5.695865504800327
[09/26 02:46:14 visual_prompt]: Epoch 52 / 100: avg data time: 4.08e-02, avg batch time: 0.4878, average train loss: 7.7619
[09/26 02:46:15 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1676, average loss: 8.0554
[09/26 02:46:15 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.00	top5: 4.00	
[09/26 02:46:15 visual_prompt]: Training 53 / 100 epoch, with learning rate 5.522642316338268
[09/26 02:46:22 visual_prompt]: Epoch 53 / 100: avg data time: 5.57e-02, avg batch time: 0.4995, average train loss: 7.3817
[09/26 02:46:24 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1674, average loss: 7.7754
[09/26 02:46:24 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.00	
[09/26 02:46:24 visual_prompt]: Training 54 / 100 epoch, with learning rate 5.3487823687206255
[09/26 02:46:30 visual_prompt]: Epoch 54 / 100: avg data time: 5.40e-02, avg batch time: 0.4983, average train loss: 7.0523
[09/26 02:46:32 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1676, average loss: 7.5129
[09/26 02:46:32 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 5.50	
[09/26 02:46:32 visual_prompt]: Training 55 / 100 epoch, with learning rate 5.174497483512505
[09/26 02:46:39 visual_prompt]: Epoch 55 / 100: avg data time: 5.90e-02, avg batch time: 0.5027, average train loss: 6.9554
[09/26 02:46:40 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1674, average loss: 7.4724
[09/26 02:46:40 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 4.00	
[09/26 02:46:40 visual_prompt]: Training 56 / 100 epoch, with learning rate 5.0
[09/26 02:46:47 visual_prompt]: Epoch 56 / 100: avg data time: 5.17e-02, avg batch time: 0.4951, average train loss: 6.7599
[09/26 02:46:49 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1676, average loss: 7.0516
[09/26 02:46:49 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 1.50	
[09/26 02:46:49 visual_prompt]: Training 57 / 100 epoch, with learning rate 4.8255025164874965
[09/26 02:46:55 visual_prompt]: Epoch 57 / 100: avg data time: 5.77e-02, avg batch time: 0.5005, average train loss: 6.4236
[09/26 02:46:57 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1671, average loss: 6.8491
[09/26 02:46:57 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 3.00	
[09/26 02:46:57 visual_prompt]: Training 58 / 100 epoch, with learning rate 4.651217631279374
[09/26 02:47:04 visual_prompt]: Epoch 58 / 100: avg data time: 5.83e-02, avg batch time: 0.5030, average train loss: 6.3930
[09/26 02:47:05 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1678, average loss: 6.6166
[09/26 02:47:05 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 2.50	
[09/26 02:47:05 visual_prompt]: Training 59 / 100 epoch, with learning rate 4.477357683661733
[09/26 02:47:12 visual_prompt]: Epoch 59 / 100: avg data time: 4.74e-02, avg batch time: 0.4913, average train loss: 6.1435
[09/26 02:47:13 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1675, average loss: 6.5275
[09/26 02:47:13 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 02:47:13 visual_prompt]: Training 60 / 100 epoch, with learning rate 4.3041344951996745
[09/26 02:47:20 visual_prompt]: Epoch 60 / 100: avg data time: 6.22e-02, avg batch time: 0.5051, average train loss: 5.9539
[09/26 02:47:22 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1673, average loss: 6.4468
[09/26 02:47:22 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 2.00	
[09/26 02:47:22 visual_prompt]: Training 61 / 100 epoch, with learning rate 4.131759111665349
[09/26 02:47:29 visual_prompt]: Epoch 61 / 100: avg data time: 5.87e-02, avg batch time: 0.5024, average train loss: 5.9155
[09/26 02:47:30 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1678, average loss: 6.4837
[09/26 02:47:30 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.50	
[09/26 02:47:30 visual_prompt]: Training 62 / 100 epoch, with learning rate 3.960441545911204
[09/26 02:47:37 visual_prompt]: Epoch 62 / 100: avg data time: 3.99e-02, avg batch time: 0.4862, average train loss: 5.8670
[09/26 02:47:38 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1672, average loss: 6.2648
[09/26 02:47:38 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 7.00	
[09/26 02:47:38 visual_prompt]: Training 63 / 100 epoch, with learning rate 3.790390522001662
[09/26 02:47:45 visual_prompt]: Epoch 63 / 100: avg data time: 5.64e-02, avg batch time: 0.4995, average train loss: 5.7429
[09/26 02:47:46 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.1673, average loss: 6.4776
[09/26 02:47:46 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/26 02:47:46 visual_prompt]: Training 64 / 100 epoch, with learning rate 3.6218132209150045
[09/26 02:47:53 visual_prompt]: Epoch 64 / 100: avg data time: 5.93e-02, avg batch time: 0.5029, average train loss: 5.7838
[09/26 02:47:55 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1672, average loss: 6.4341
[09/26 02:47:55 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 2.50	
[09/26 02:47:55 visual_prompt]: Training 65 / 100 epoch, with learning rate 3.454915028125263
[09/26 02:48:02 visual_prompt]: Epoch 65 / 100: avg data time: 5.61e-02, avg batch time: 0.5000, average train loss: 5.8064
[09/26 02:48:03 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.1673, average loss: 6.3158
[09/26 02:48:03 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 5.50	
[09/26 02:48:03 visual_prompt]: Training 66 / 100 epoch, with learning rate 3.289899283371657
[09/26 02:48:10 visual_prompt]: Epoch 66 / 100: avg data time: 5.09e-02, avg batch time: 0.4955, average train loss: 5.7087
[09/26 02:48:11 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1676, average loss: 6.3584
[09/26 02:48:11 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 1.50	
[09/26 02:48:11 visual_prompt]: Training 67 / 100 epoch, with learning rate 3.1269670329204398
[09/26 02:48:18 visual_prompt]: Epoch 67 / 100: avg data time: 4.97e-02, avg batch time: 0.4928, average train loss: 5.7371
[09/26 02:48:19 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1673, average loss: 6.5126
[09/26 02:48:20 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.00	
[09/26 02:48:20 visual_prompt]: Training 68 / 100 epoch, with learning rate 2.9663167846209997
[09/26 02:48:26 visual_prompt]: Epoch 68 / 100: avg data time: 5.40e-02, avg batch time: 0.4997, average train loss: 5.6960
[09/26 02:48:28 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1673, average loss: 6.2264
[09/26 02:48:28 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 5.50	
[09/26 02:48:28 visual_prompt]: Training 69 / 100 epoch, with learning rate 2.8081442660546125
[09/26 02:48:34 visual_prompt]: Epoch 69 / 100: avg data time: 4.34e-02, avg batch time: 0.4871, average train loss: 5.6512
[09/26 02:48:36 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1676, average loss: 6.2899
[09/26 02:48:36 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 5.00	
[09/26 02:48:36 visual_prompt]: Training 70 / 100 epoch, with learning rate 2.6526421860705476
[09/26 02:48:43 visual_prompt]: Epoch 70 / 100: avg data time: 5.75e-02, avg batch time: 0.5003, average train loss: 5.8058
[09/26 02:48:44 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1681, average loss: 6.2432
[09/26 02:48:44 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 3.00	
[09/26 02:48:44 visual_prompt]: Training 71 / 100 epoch, with learning rate 2.500000000000001
[09/26 02:48:51 visual_prompt]: Epoch 71 / 100: avg data time: 5.77e-02, avg batch time: 0.5007, average train loss: 5.7114
[09/26 02:48:53 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1678, average loss: 6.1689
[09/26 02:48:53 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 5.00	
[09/26 02:48:53 visual_prompt]: Training 72 / 100 epoch, with learning rate 2.350403678833976
[09/26 02:48:59 visual_prompt]: Epoch 72 / 100: avg data time: 5.54e-02, avg batch time: 0.5001, average train loss: 5.6777
[09/26 02:49:01 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1677, average loss: 6.2225
[09/26 02:49:01 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 2.50	
[09/26 02:49:01 visual_prompt]: Training 73 / 100 epoch, with learning rate 2.2040354826462667
[09/26 02:49:08 visual_prompt]: Epoch 73 / 100: avg data time: 4.44e-02, avg batch time: 0.4918, average train loss: 5.6125
[09/26 02:49:09 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1677, average loss: 6.2432
[09/26 02:49:09 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.00	
[09/26 02:49:09 visual_prompt]: Training 74 / 100 epoch, with learning rate 2.061073738537635
[09/26 02:49:16 visual_prompt]: Epoch 74 / 100: avg data time: 6.39e-02, avg batch time: 0.5071, average train loss: 5.6076
[09/26 02:49:18 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1673, average loss: 6.1428
[09/26 02:49:18 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 5.00	
[09/26 02:49:18 visual_prompt]: Training 75 / 100 epoch, with learning rate 1.9216926233717087
[09/26 02:49:24 visual_prompt]: Epoch 75 / 100: avg data time: 4.29e-02, avg batch time: 0.4879, average train loss: 5.6757
[09/26 02:49:26 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1674, average loss: 6.1848
[09/26 02:49:26 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.00	
[09/26 02:49:26 visual_prompt]: Training 76 / 100 epoch, with learning rate 1.7860619515673033
[09/26 02:49:32 visual_prompt]: Epoch 76 / 100: avg data time: 4.19e-02, avg batch time: 0.4858, average train loss: 5.6503
[09/26 02:49:34 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1677, average loss: 6.1310
[09/26 02:49:34 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 3.50	
[09/26 02:49:34 visual_prompt]: Training 77 / 100 epoch, with learning rate 1.6543469682057106
[09/26 02:49:41 visual_prompt]: Epoch 77 / 100: avg data time: 5.44e-02, avg batch time: 0.4983, average train loss: 5.5925
[09/26 02:49:42 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1672, average loss: 6.1098
[09/26 02:49:42 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 5.00	
[09/26 02:49:42 visual_prompt]: Training 78 / 100 epoch, with learning rate 1.5267081477050133
[09/26 02:49:49 visual_prompt]: Epoch 78 / 100: avg data time: 5.71e-02, avg batch time: 0.5004, average train loss: 6.2037
[09/26 02:49:50 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1675, average loss: 6.2377
[09/26 02:49:50 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 2.50	
[09/26 02:49:50 visual_prompt]: Training 79 / 100 epoch, with learning rate 1.403300998306745
[09/26 02:49:57 visual_prompt]: Epoch 79 / 100: avg data time: 6.06e-02, avg batch time: 0.5036, average train loss: 5.9979
[09/26 02:49:59 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1675, average loss: 6.1418
[09/26 02:49:59 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 2.50	
[09/26 02:49:59 visual_prompt]: Training 80 / 100 epoch, with learning rate 1.2842758726130281
[09/26 02:50:06 visual_prompt]: Epoch 80 / 100: avg data time: 5.66e-02, avg batch time: 0.5005, average train loss: 6.0736
[09/26 02:50:07 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1677, average loss: 6.2366
[09/26 02:50:07 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 6.50	
[09/26 02:50:07 visual_prompt]: Training 81 / 100 epoch, with learning rate 1.1697777844051105
[09/26 02:50:14 visual_prompt]: Epoch 81 / 100: avg data time: 4.46e-02, avg batch time: 0.4912, average train loss: 5.9205
[09/26 02:50:15 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1672, average loss: 6.1929
[09/26 02:50:15 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 3.00	
[09/26 02:50:15 visual_prompt]: Training 82 / 100 epoch, with learning rate 1.0599462319663906
[09/26 02:50:22 visual_prompt]: Epoch 82 / 100: avg data time: 5.39e-02, avg batch time: 0.4979, average train loss: 5.9751
[09/26 02:50:24 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1677, average loss: 6.1418
[09/26 02:50:24 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.00	
[09/26 02:50:24 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.9549150281252633
[09/26 02:50:30 visual_prompt]: Epoch 83 / 100: avg data time: 5.04e-02, avg batch time: 0.4942, average train loss: 5.8986
[09/26 02:50:32 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1670, average loss: 6.2101
[09/26 02:50:32 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.00	
[09/26 02:50:32 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.8548121372247919
[09/26 02:50:39 visual_prompt]: Epoch 84 / 100: avg data time: 5.70e-02, avg batch time: 0.5001, average train loss: 5.9008
[09/26 02:50:40 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1674, average loss: 6.1907
[09/26 02:50:40 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.00	
[09/26 02:50:40 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.7597595192178702
[09/26 02:50:47 visual_prompt]: Epoch 85 / 100: avg data time: 6.19e-02, avg batch time: 0.5053, average train loss: 5.7666
[09/26 02:50:49 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1673, average loss: 6.1029
[09/26 02:50:49 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.50	
[09/26 02:50:49 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.6698729810778065
[09/26 02:50:55 visual_prompt]: Epoch 86 / 100: avg data time: 5.41e-02, avg batch time: 0.4961, average train loss: 5.6357
[09/26 02:50:57 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1676, average loss: 6.0962
[09/26 02:50:57 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 02:50:57 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.5852620357053651
[09/26 02:51:04 visual_prompt]: Epoch 87 / 100: avg data time: 4.74e-02, avg batch time: 0.4914, average train loss: 5.6237
[09/26 02:51:05 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1675, average loss: 6.1107
[09/26 02:51:05 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 5.00	
[09/26 02:51:05 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.5060297685041659
[09/26 02:51:12 visual_prompt]: Epoch 88 / 100: avg data time: 5.36e-02, avg batch time: 0.4970, average train loss: 5.5933
[09/26 02:51:13 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1675, average loss: 6.1057
[09/26 02:51:13 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 5.00	
[09/26 02:51:13 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.4322727117869951
[09/26 02:51:20 visual_prompt]: Epoch 89 / 100: avg data time: 4.50e-02, avg batch time: 0.4883, average train loss: 5.5725
[09/26 02:51:21 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1672, average loss: 6.0665
[09/26 02:51:21 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.50	
[09/26 02:51:21 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.36408072716606343
[09/26 02:51:28 visual_prompt]: Epoch 90 / 100: avg data time: 5.67e-02, avg batch time: 0.4993, average train loss: 5.5461
[09/26 02:51:30 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1671, average loss: 6.0874
[09/26 02:51:30 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 5.00	
[09/26 02:51:30 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.3015368960704584
[09/26 02:51:37 visual_prompt]: Epoch 91 / 100: avg data time: 5.48e-02, avg batch time: 0.4982, average train loss: 5.5077
[09/26 02:51:38 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1672, average loss: 6.1335
[09/26 02:51:38 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.50	
[09/26 02:51:38 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.24471741852423234
[09/26 02:51:45 visual_prompt]: Epoch 92 / 100: avg data time: 4.89e-02, avg batch time: 0.4915, average train loss: 5.5579
[09/26 02:51:46 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1675, average loss: 6.0715
[09/26 02:51:46 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 5.00	
[09/26 02:51:46 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.19369152030840553
[09/26 02:51:53 visual_prompt]: Epoch 93 / 100: avg data time: 5.64e-02, avg batch time: 0.5013, average train loss: 5.5221
[09/26 02:51:55 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1672, average loss: 6.1182
[09/26 02:51:55 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.50	
[09/26 02:51:55 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.14852136862001764
[09/26 02:52:01 visual_prompt]: Epoch 94 / 100: avg data time: 5.18e-02, avg batch time: 0.4964, average train loss: 5.5233
[09/26 02:52:03 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1674, average loss: 6.0907
[09/26 02:52:03 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.00	
[09/26 02:52:03 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.10926199633097156
[09/26 02:52:10 visual_prompt]: Epoch 95 / 100: avg data time: 5.80e-02, avg batch time: 0.5015, average train loss: 5.4811
[09/26 02:52:11 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1667, average loss: 6.0764
[09/26 02:52:11 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 5.00	
[09/26 02:52:11 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.0759612349389599
[09/26 02:52:18 visual_prompt]: Epoch 96 / 100: avg data time: 5.64e-02, avg batch time: 0.4990, average train loss: 5.4708
[09/26 02:52:19 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1670, average loss: 6.0783
[09/26 02:52:19 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.00	
[09/26 02:52:19 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.04865965629214819
[09/26 02:52:26 visual_prompt]: Epoch 97 / 100: avg data time: 5.40e-02, avg batch time: 0.4965, average train loss: 5.4572
[09/26 02:52:28 visual_prompt]: Inference (val):avg data time: 4.34e-05, avg batch time: 0.1669, average loss: 6.0744
[09/26 02:52:28 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 02:52:28 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.02739052315863355
[09/26 02:52:34 visual_prompt]: Epoch 98 / 100: avg data time: 5.71e-02, avg batch time: 0.4999, average train loss: 5.4479
[09/26 02:52:36 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1671, average loss: 6.0776
[09/26 02:52:36 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 02:52:36 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.012179748700879012
[09/26 02:52:43 visual_prompt]: Epoch 99 / 100: avg data time: 5.68e-02, avg batch time: 0.4993, average train loss: 5.4416
[09/26 02:52:44 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1673, average loss: 6.0819
[09/26 02:52:44 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 02:52:44 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0030458649045211894
[09/26 02:52:51 visual_prompt]: Epoch 100 / 100: avg data time: 6.27e-02, avg batch time: 0.5049, average train loss: 5.4369
[09/26 02:52:53 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1670, average loss: 6.0815
[09/26 02:52:53 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 02:52:53 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 02:52:53 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              0
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 02:52:53 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-sun397', 'DATA.NUMBER_CLASSES', '397', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 02:52:53 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 02:52:53 visual_prompt]: Training with config:
[09/26 02:52:53 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-sun397/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr10.0_wd0.001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 10.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-sun397', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 397, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 02:52:53 visual_prompt]: Loading training data...
[09/26 02:52:53 visual_prompt]: Constructing vtab-sun397 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split train[:800], from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/26 02:52:54 visual_prompt]: Number of images: 800
[09/26 02:52:54 visual_prompt]: Number of classes: 309 / 397
[09/26 02:52:54 visual_prompt]: Loading validation data...
[09/26 02:52:54 visual_prompt]: Constructing vtab-sun397 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split validation[:200], from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/26 02:52:54 visual_prompt]: Number of images: 200
[09/26 02:52:54 visual_prompt]: Number of classes: 136 / 397
[09/26 02:52:54 visual_prompt]: Constructing models...
[09/26 02:52:57 visual_prompt]: Total Parameters: 86564749	 Gradient Parameters: 766093
[09/26 02:52:57 visual_prompt]: tuned percent:0.885
[09/26 02:52:57 visual_prompt]: Device used for model: 0
[09/26 02:52:57 visual_prompt]: Setting up Evaluator...
[09/26 02:52:57 visual_prompt]: Setting up Trainer...
[09/26 02:52:57 visual_prompt]: 	Setting up the optimizer...
[09/26 02:52:57 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 02:53:04 visual_prompt]: Epoch 1 / 100: avg data time: 5.37e-02, avg batch time: 0.4971, average train loss: 5.9883
[09/26 02:53:05 visual_prompt]: Inference (val):avg data time: 1.94e-05, avg batch time: 0.1667, average loss: 6.0097
[09/26 02:53:05 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/26 02:53:05 visual_prompt]: Training 2 / 100 epoch, with learning rate 1.0
[09/26 02:53:12 visual_prompt]: Epoch 2 / 100: avg data time: 5.01e-02, avg batch time: 0.4941, average train loss: 5.7397
[09/26 02:53:13 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1670, average loss: 5.8409
[09/26 02:53:13 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 4.50	
[09/26 02:53:13 visual_prompt]: Best epoch 2: best metric: 0.015
[09/26 02:53:13 visual_prompt]: Training 3 / 100 epoch, with learning rate 2.0
[09/26 02:53:20 visual_prompt]: Epoch 3 / 100: avg data time: 5.81e-02, avg batch time: 0.5002, average train loss: 5.6359
[09/26 02:53:22 visual_prompt]: Inference (val):avg data time: 2.08e-05, avg batch time: 0.1672, average loss: 6.1615
[09/26 02:53:22 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 5.00	
[09/26 02:53:22 visual_prompt]: Training 4 / 100 epoch, with learning rate 3.0
[09/26 02:53:29 visual_prompt]: Epoch 4 / 100: avg data time: 6.23e-02, avg batch time: 0.5041, average train loss: 5.8301
[09/26 02:53:30 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1671, average loss: 6.0943
[09/26 02:53:30 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 02:53:30 visual_prompt]: Training 5 / 100 epoch, with learning rate 4.0
[09/26 02:53:37 visual_prompt]: Epoch 5 / 100: avg data time: 6.09e-02, avg batch time: 0.5035, average train loss: 5.9158
[09/26 02:53:39 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1675, average loss: 5.9060
[09/26 02:53:39 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.50	
[09/26 02:53:39 visual_prompt]: Training 6 / 100 epoch, with learning rate 5.0
[09/26 02:53:45 visual_prompt]: Epoch 6 / 100: avg data time: 5.79e-02, avg batch time: 0.5004, average train loss: 5.8705
[09/26 02:53:47 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1674, average loss: 6.0188
[09/26 02:53:47 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.00	top5: 4.50	
[09/26 02:53:47 visual_prompt]: Best epoch 6: best metric: 0.020
[09/26 02:53:47 visual_prompt]: Training 7 / 100 epoch, with learning rate 6.0
[09/26 02:53:54 visual_prompt]: Epoch 7 / 100: avg data time: 4.83e-02, avg batch time: 0.4932, average train loss: 6.1112
[09/26 02:53:55 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1679, average loss: 6.1174
[09/26 02:53:55 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 2.00	
[09/26 02:53:55 visual_prompt]: Training 8 / 100 epoch, with learning rate 7.0
[09/26 02:54:02 visual_prompt]: Epoch 8 / 100: avg data time: 5.43e-02, avg batch time: 0.4980, average train loss: 6.0163
[09/26 02:54:03 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1677, average loss: 6.1117
[09/26 02:54:03 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.50	
[09/26 02:54:03 visual_prompt]: Training 9 / 100 epoch, with learning rate 8.0
[09/26 02:54:10 visual_prompt]: Epoch 9 / 100: avg data time: 5.93e-02, avg batch time: 0.5038, average train loss: 6.0116
[09/26 02:54:12 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1675, average loss: 6.1498
[09/26 02:54:12 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 4.00	
[09/26 02:54:12 visual_prompt]: Training 10 / 100 epoch, with learning rate 9.0
[09/26 02:54:18 visual_prompt]: Epoch 10 / 100: avg data time: 5.38e-02, avg batch time: 0.4977, average train loss: 6.0501
[09/26 02:54:20 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1675, average loss: 6.3629
[09/26 02:54:20 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 4.50	
[09/26 02:54:20 visual_prompt]: Training 11 / 100 epoch, with learning rate 10.0
[09/26 02:54:27 visual_prompt]: Epoch 11 / 100: avg data time: 6.07e-02, avg batch time: 0.5046, average train loss: 11.9236
[09/26 02:54:28 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1677, average loss: 9.5428
[09/26 02:54:28 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 3.50	
[09/26 02:54:28 visual_prompt]: Training 12 / 100 epoch, with learning rate 9.996954135095478
[09/26 02:54:35 visual_prompt]: Epoch 12 / 100: avg data time: 5.21e-02, avg batch time: 0.4977, average train loss: 11.4832
[09/26 02:54:37 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1678, average loss: 7.8461
[09/26 02:54:37 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 3.50	
[09/26 02:54:37 visual_prompt]: Training 13 / 100 epoch, with learning rate 9.987820251299121
[09/26 02:54:43 visual_prompt]: Epoch 13 / 100: avg data time: 5.12e-02, avg batch time: 0.4945, average train loss: 11.9279
[09/26 02:54:45 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1674, average loss: 10.3547
[09/26 02:54:45 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 2.00	
[09/26 02:54:45 visual_prompt]: Training 14 / 100 epoch, with learning rate 9.972609476841367
[09/26 02:54:52 visual_prompt]: Epoch 14 / 100: avg data time: 5.86e-02, avg batch time: 0.5009, average train loss: 12.4601
[09/26 02:54:53 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1671, average loss: 9.0022
[09/26 02:54:53 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 1.00	
[09/26 02:54:53 visual_prompt]: Training 15 / 100 epoch, with learning rate 9.951340343707852
[09/26 02:55:00 visual_prompt]: Epoch 15 / 100: avg data time: 5.58e-02, avg batch time: 0.4994, average train loss: 13.0106
[09/26 02:55:02 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1670, average loss: 8.8932
[09/26 02:55:02 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.00	top5: 4.50	
[09/26 02:55:02 visual_prompt]: Training 16 / 100 epoch, with learning rate 9.924038765061042
[09/26 02:55:08 visual_prompt]: Epoch 16 / 100: avg data time: 5.93e-02, avg batch time: 0.5028, average train loss: 14.6185
[09/26 02:55:10 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1674, average loss: 11.5463
[09/26 02:55:10 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.00	top5: 4.00	
[09/26 02:55:10 visual_prompt]: Training 17 / 100 epoch, with learning rate 9.890738003669028
[09/26 02:55:17 visual_prompt]: Epoch 17 / 100: avg data time: 5.19e-02, avg batch time: 0.4946, average train loss: 16.2082
[09/26 02:55:18 visual_prompt]: Inference (val):avg data time: 2.05e-05, avg batch time: 0.1672, average loss: 31.4683
[09/26 02:55:18 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 4.00	
[09/26 02:55:18 visual_prompt]: Training 18 / 100 epoch, with learning rate 9.851478631379981
[09/26 02:55:25 visual_prompt]: Epoch 18 / 100: avg data time: 5.54e-02, avg batch time: 0.4994, average train loss: 17.0750
[09/26 02:55:26 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1677, average loss: 14.0393
[09/26 02:55:26 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 2.50	
[09/26 02:55:26 visual_prompt]: Training 19 / 100 epoch, with learning rate 9.806308479691594
[09/26 02:55:33 visual_prompt]: Epoch 19 / 100: avg data time: 5.52e-02, avg batch time: 0.4987, average train loss: 15.4206
[09/26 02:55:35 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1670, average loss: 14.5534
[09/26 02:55:35 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 2.50	
[09/26 02:55:35 visual_prompt]: Training 20 / 100 epoch, with learning rate 9.755282581475768
[09/26 02:55:41 visual_prompt]: Epoch 20 / 100: avg data time: 5.73e-02, avg batch time: 0.5011, average train loss: 19.6807
[09/26 02:55:43 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1672, average loss: 14.2240
[09/26 02:55:43 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.00	top5: 6.00	
[09/26 02:55:43 visual_prompt]: Training 21 / 100 epoch, with learning rate 9.698463103929543
[09/26 02:55:50 visual_prompt]: Epoch 21 / 100: avg data time: 4.74e-02, avg batch time: 0.4914, average train loss: 14.2865
[09/26 02:55:51 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1670, average loss: 13.7785
[09/26 02:55:51 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.00	
[09/26 02:55:51 visual_prompt]: Training 22 / 100 epoch, with learning rate 9.635919272833938
[09/26 02:55:58 visual_prompt]: Epoch 22 / 100: avg data time: 5.70e-02, avg batch time: 0.5002, average train loss: 12.4135
[09/26 02:55:59 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1672, average loss: 12.1602
[09/26 02:55:59 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/26 02:55:59 visual_prompt]: Training 23 / 100 epoch, with learning rate 9.567727288213003
[09/26 02:56:06 visual_prompt]: Epoch 23 / 100: avg data time: 5.17e-02, avg batch time: 0.4966, average train loss: 11.9668
[09/26 02:56:08 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.1673, average loss: 11.8963
[09/26 02:56:08 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 2.50	
[09/26 02:56:08 visual_prompt]: Training 24 / 100 epoch, with learning rate 9.493970231495835
[09/26 02:56:14 visual_prompt]: Epoch 24 / 100: avg data time: 4.71e-02, avg batch time: 0.4904, average train loss: 10.3993
[09/26 02:56:16 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1680, average loss: 11.7488
[09/26 02:56:16 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.50	
[09/26 02:56:16 visual_prompt]: Training 25 / 100 epoch, with learning rate 9.414737964294634
[09/26 02:56:23 visual_prompt]: Epoch 25 / 100: avg data time: 5.94e-02, avg batch time: 0.5028, average train loss: 14.2009
[09/26 02:56:24 visual_prompt]: Inference (val):avg data time: 2.05e-05, avg batch time: 0.1674, average loss: 13.3656
[09/26 02:56:24 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.50	
[09/26 02:56:24 visual_prompt]: Training 26 / 100 epoch, with learning rate 9.330127018922195
[09/26 02:56:31 visual_prompt]: Epoch 26 / 100: avg data time: 5.12e-02, avg batch time: 0.4944, average train loss: 18.5143
[09/26 02:56:33 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1669, average loss: 101.6516
[09/26 02:56:33 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 5.00	
[09/26 02:56:33 visual_prompt]: Training 27 / 100 epoch, with learning rate 9.240240480782129
[09/26 02:56:39 visual_prompt]: Epoch 27 / 100: avg data time: 5.36e-02, avg batch time: 0.4987, average train loss: 39.2378
[09/26 02:56:41 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1676, average loss: 16.4884
[09/26 02:56:41 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.00	
[09/26 02:56:41 visual_prompt]: Training 28 / 100 epoch, with learning rate 9.145187862775208
[09/26 02:56:48 visual_prompt]: Epoch 28 / 100: avg data time: 5.63e-02, avg batch time: 0.4987, average train loss: 21.2326
[09/26 02:56:49 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1670, average loss: 14.4605
[09/26 02:56:49 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.00	top5: 6.00	
[09/26 02:56:49 visual_prompt]: Training 29 / 100 epoch, with learning rate 9.045084971874736
[09/26 02:56:56 visual_prompt]: Epoch 29 / 100: avg data time: 5.83e-02, avg batch time: 0.5031, average train loss: 22.0205
[09/26 02:56:57 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1675, average loss: 14.6189
[09/26 02:56:57 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.50	
[09/26 02:56:57 visual_prompt]: Training 30 / 100 epoch, with learning rate 8.940053768033609
[09/26 02:57:04 visual_prompt]: Epoch 30 / 100: avg data time: 5.68e-02, avg batch time: 0.5001, average train loss: 20.2164
[09/26 02:57:06 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1681, average loss: 17.4000
[09/26 02:57:06 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 3.50	
[09/26 02:57:06 visual_prompt]: Training 31 / 100 epoch, with learning rate 8.83022221559489
[09/26 02:57:13 visual_prompt]: Epoch 31 / 100: avg data time: 5.27e-02, avg batch time: 0.4951, average train loss: 22.3229
[09/26 02:57:14 visual_prompt]: Inference (val):avg data time: 2.00e-05, avg batch time: 0.1670, average loss: 16.9211
[09/26 02:57:14 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.50	
[09/26 02:57:14 visual_prompt]: Training 32 / 100 epoch, with learning rate 8.715724127386972
[09/26 02:57:21 visual_prompt]: Epoch 32 / 100: avg data time: 5.60e-02, avg batch time: 0.4995, average train loss: 18.8920
[09/26 02:57:22 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1677, average loss: 14.0326
[09/26 02:57:22 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.50	top5: 4.50	
[09/26 02:57:22 visual_prompt]: Best epoch 32: best metric: 0.025
[09/26 02:57:22 visual_prompt]: Training 33 / 100 epoch, with learning rate 8.596699001693256
[09/26 02:57:29 visual_prompt]: Epoch 33 / 100: avg data time: 5.35e-02, avg batch time: 0.4977, average train loss: 20.4341
[09/26 02:57:31 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1675, average loss: 53.2017
[09/26 02:57:31 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 3.50	
[09/26 02:57:31 visual_prompt]: Training 34 / 100 epoch, with learning rate 8.473291852294986
[09/26 02:57:37 visual_prompt]: Epoch 34 / 100: avg data time: 4.22e-02, avg batch time: 0.4860, average train loss: 22.0118
[09/26 02:57:39 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1675, average loss: 12.7262
[09/26 02:57:39 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.00	
[09/26 02:57:39 visual_prompt]: Training 35 / 100 epoch, with learning rate 8.345653031794292
[09/26 02:57:46 visual_prompt]: Epoch 35 / 100: avg data time: 5.68e-02, avg batch time: 0.5020, average train loss: 15.1514
[09/26 02:57:47 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1680, average loss: 12.0155
[09/26 02:57:47 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.00	
[09/26 02:57:47 visual_prompt]: Training 36 / 100 epoch, with learning rate 8.213938048432697
[09/26 02:57:54 visual_prompt]: Epoch 36 / 100: avg data time: 4.92e-02, avg batch time: 0.4945, average train loss: 15.0437
[09/26 02:57:55 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1678, average loss: 10.9901
[09/26 02:57:55 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.00	
[09/26 02:57:55 visual_prompt]: Training 37 / 100 epoch, with learning rate 8.078307376628292
[09/26 02:58:02 visual_prompt]: Epoch 37 / 100: avg data time: 6.27e-02, avg batch time: 0.5047, average train loss: 15.0162
[09/26 02:58:04 visual_prompt]: Inference (val):avg data time: 2.00e-05, avg batch time: 0.1676, average loss: 10.4068
[09/26 02:58:04 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.00	
[09/26 02:58:04 visual_prompt]: Training 38 / 100 epoch, with learning rate 7.938926261462366
[09/26 02:58:11 visual_prompt]: Epoch 38 / 100: avg data time: 5.75e-02, avg batch time: 0.5001, average train loss: 11.8015
[09/26 02:58:12 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1675, average loss: 12.9829
[09/26 02:58:12 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 2.50	
[09/26 02:58:12 visual_prompt]: Training 39 / 100 epoch, with learning rate 7.795964517353734
[09/26 02:58:19 visual_prompt]: Epoch 39 / 100: avg data time: 5.96e-02, avg batch time: 0.5029, average train loss: 26.7834
[09/26 02:58:20 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1674, average loss: 11.2907
[09/26 02:58:20 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.50	
[09/26 02:58:20 visual_prompt]: Training 40 / 100 epoch, with learning rate 7.649596321166024
[09/26 02:58:27 visual_prompt]: Epoch 40 / 100: avg data time: 4.51e-02, avg batch time: 0.4903, average train loss: 18.1736
[09/26 02:58:29 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1676, average loss: 14.3321
[09/26 02:58:29 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.50	
[09/26 02:58:29 visual_prompt]: Training 41 / 100 epoch, with learning rate 7.5
[09/26 02:58:35 visual_prompt]: Epoch 41 / 100: avg data time: 5.95e-02, avg batch time: 0.5024, average train loss: 15.3468
[09/26 02:58:37 visual_prompt]: Inference (val):avg data time: 2.00e-05, avg batch time: 0.1673, average loss: 10.2430
[09/26 02:58:37 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.00	
[09/26 02:58:37 visual_prompt]: Training 42 / 100 epoch, with learning rate 7.347357813929454
[09/26 02:58:44 visual_prompt]: Epoch 42 / 100: avg data time: 4.80e-02, avg batch time: 0.4911, average train loss: 12.9855
[09/26 02:58:45 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1677, average loss: 11.0995
[09/26 02:58:45 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.00	
[09/26 02:58:45 visual_prompt]: Training 43 / 100 epoch, with learning rate 7.191855733945387
[09/26 02:58:52 visual_prompt]: Epoch 43 / 100: avg data time: 5.00e-02, avg batch time: 0.4940, average train loss: 12.9564
[09/26 02:58:53 visual_prompt]: Inference (val):avg data time: 1.97e-05, avg batch time: 0.1670, average loss: 10.6865
[09/26 02:58:53 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 1.00	
[09/26 02:58:53 visual_prompt]: Training 44 / 100 epoch, with learning rate 7.033683215379002
[09/26 02:59:00 visual_prompt]: Epoch 44 / 100: avg data time: 5.60e-02, avg batch time: 0.4983, average train loss: 15.7248
[09/26 02:59:02 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1673, average loss: 10.2130
[09/26 02:59:02 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.50	
[09/26 02:59:02 visual_prompt]: Training 45 / 100 epoch, with learning rate 6.873032967079561
[09/26 02:59:08 visual_prompt]: Epoch 45 / 100: avg data time: 5.43e-02, avg batch time: 0.4990, average train loss: 13.4549
[09/26 02:59:10 visual_prompt]: Inference (val):avg data time: 2.00e-05, avg batch time: 0.1671, average loss: 9.4357
[09/26 02:59:10 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.00	
[09/26 02:59:10 visual_prompt]: Training 46 / 100 epoch, with learning rate 6.710100716628345
[09/26 02:59:17 visual_prompt]: Epoch 46 / 100: avg data time: 5.72e-02, avg batch time: 0.5004, average train loss: 13.1772
[09/26 02:59:18 visual_prompt]: Inference (val):avg data time: 3.99e-05, avg batch time: 0.1672, average loss: 10.1334
[09/26 02:59:18 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 3.00	
[09/26 02:59:18 visual_prompt]: Training 47 / 100 epoch, with learning rate 6.545084971874737
[09/26 02:59:25 visual_prompt]: Epoch 47 / 100: avg data time: 5.62e-02, avg batch time: 0.5003, average train loss: 10.9654
[09/26 02:59:27 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1676, average loss: 8.3983
[09/26 02:59:27 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.00	
[09/26 02:59:27 visual_prompt]: Training 48 / 100 epoch, with learning rate 6.378186779084995
[09/26 02:59:33 visual_prompt]: Epoch 48 / 100: avg data time: 4.28e-02, avg batch time: 0.4860, average train loss: 10.7862
[09/26 02:59:35 visual_prompt]: Inference (val):avg data time: 1.96e-05, avg batch time: 0.1674, average loss: 8.9324
[09/26 02:59:35 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 3.00	
[09/26 02:59:35 visual_prompt]: Training 49 / 100 epoch, with learning rate 6.209609477998338
[09/26 02:59:41 visual_prompt]: Epoch 49 / 100: avg data time: 6.05e-02, avg batch time: 0.5050, average train loss: 11.1857
[09/26 02:59:43 visual_prompt]: Inference (val):avg data time: 2.08e-05, avg batch time: 0.1675, average loss: 8.7050
[09/26 02:59:43 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.50	
[09/26 02:59:43 visual_prompt]: Training 50 / 100 epoch, with learning rate 6.039558454088796
[09/26 02:59:50 visual_prompt]: Epoch 50 / 100: avg data time: 5.51e-02, avg batch time: 0.4998, average train loss: 10.4899
[09/26 02:59:51 visual_prompt]: Inference (val):avg data time: 1.90e-05, avg batch time: 0.1673, average loss: 7.6247
[09/26 02:59:51 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 2.50	
[09/26 02:59:51 visual_prompt]: Training 51 / 100 epoch, with learning rate 5.868240888334652
[09/26 02:59:58 visual_prompt]: Epoch 51 / 100: avg data time: 5.69e-02, avg batch time: 0.5000, average train loss: 8.7046
[09/26 03:00:00 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1672, average loss: 7.3736
[09/26 03:00:00 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.00	
[09/26 03:00:00 visual_prompt]: Training 52 / 100 epoch, with learning rate 5.695865504800327
[09/26 03:00:06 visual_prompt]: Epoch 52 / 100: avg data time: 5.42e-02, avg batch time: 0.4975, average train loss: 8.5766
[09/26 03:00:08 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1668, average loss: 7.2930
[09/26 03:00:08 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/26 03:00:08 visual_prompt]: Training 53 / 100 epoch, with learning rate 5.522642316338268
[09/26 03:00:15 visual_prompt]: Epoch 53 / 100: avg data time: 6.00e-02, avg batch time: 0.5040, average train loss: 12.0169
[09/26 03:00:16 visual_prompt]: Inference (val):avg data time: 1.93e-05, avg batch time: 0.1676, average loss: 10.3237
[09/26 03:00:16 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 3.50	
[09/26 03:00:16 visual_prompt]: Training 54 / 100 epoch, with learning rate 5.3487823687206255
[09/26 03:00:23 visual_prompt]: Epoch 54 / 100: avg data time: 6.40e-02, avg batch time: 0.5082, average train loss: 13.4341
[09/26 03:00:25 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1674, average loss: 9.0255
[09/26 03:00:25 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.00	
[09/26 03:00:25 visual_prompt]: Training 55 / 100 epoch, with learning rate 5.174497483512505
[09/26 03:00:31 visual_prompt]: Epoch 55 / 100: avg data time: 5.94e-02, avg batch time: 0.5031, average train loss: 10.2139
[09/26 03:00:33 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1672, average loss: 8.6933
[09/26 03:00:33 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.50	
[09/26 03:00:33 visual_prompt]: Training 56 / 100 epoch, with learning rate 5.0
[09/26 03:00:40 visual_prompt]: Epoch 56 / 100: avg data time: 5.27e-02, avg batch time: 0.4963, average train loss: 9.3890
[09/26 03:00:41 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1677, average loss: 7.8035
[09/26 03:00:41 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 4.50	
[09/26 03:00:41 visual_prompt]: Training 57 / 100 epoch, with learning rate 4.8255025164874965
[09/26 03:00:48 visual_prompt]: Epoch 57 / 100: avg data time: 4.79e-02, avg batch time: 0.4918, average train loss: 8.3297
[09/26 03:00:49 visual_prompt]: Inference (val):avg data time: 1.69e-05, avg batch time: 0.1672, average loss: 7.3142
[09/26 03:00:49 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.50	
[09/26 03:00:49 visual_prompt]: Training 58 / 100 epoch, with learning rate 4.651217631279374
[09/26 03:00:56 visual_prompt]: Epoch 58 / 100: avg data time: 5.28e-02, avg batch time: 0.4962, average train loss: 8.5641
[09/26 03:00:58 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1674, average loss: 7.5134
[09/26 03:00:58 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 4.00	
[09/26 03:00:58 visual_prompt]: Training 59 / 100 epoch, with learning rate 4.477357683661733
[09/26 03:01:05 visual_prompt]: Epoch 59 / 100: avg data time: 6.06e-02, avg batch time: 0.5044, average train loss: 7.9693
[09/26 03:01:06 visual_prompt]: Inference (val):avg data time: 2.05e-05, avg batch time: 0.1673, average loss: 7.1547
[09/26 03:01:06 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 3.00	
[09/26 03:01:06 visual_prompt]: Training 60 / 100 epoch, with learning rate 4.3041344951996745
[09/26 03:01:13 visual_prompt]: Epoch 60 / 100: avg data time: 5.52e-02, avg batch time: 0.4992, average train loss: 7.0644
[09/26 03:01:14 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1678, average loss: 6.8871
[09/26 03:01:14 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.50	
[09/26 03:01:14 visual_prompt]: Training 61 / 100 epoch, with learning rate 4.131759111665349
[09/26 03:01:21 visual_prompt]: Epoch 61 / 100: avg data time: 6.02e-02, avg batch time: 0.5048, average train loss: 6.8680
[09/26 03:01:23 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1677, average loss: 6.6142
[09/26 03:01:23 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 2.50	
[09/26 03:01:23 visual_prompt]: Training 62 / 100 epoch, with learning rate 3.960441545911204
[09/26 03:01:30 visual_prompt]: Epoch 62 / 100: avg data time: 5.78e-02, avg batch time: 0.5015, average train loss: 6.6432
[09/26 03:01:31 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1675, average loss: 6.5969
[09/26 03:01:31 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.00	
[09/26 03:01:31 visual_prompt]: Training 63 / 100 epoch, with learning rate 3.790390522001662
[09/26 03:01:38 visual_prompt]: Epoch 63 / 100: avg data time: 4.19e-02, avg batch time: 0.4870, average train loss: 7.4348
[09/26 03:01:39 visual_prompt]: Inference (val):avg data time: 1.93e-05, avg batch time: 0.1672, average loss: 6.8432
[09/26 03:01:39 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 5.50	
[09/26 03:01:39 visual_prompt]: Training 64 / 100 epoch, with learning rate 3.6218132209150045
[09/26 03:01:46 visual_prompt]: Epoch 64 / 100: avg data time: 5.84e-02, avg batch time: 0.5023, average train loss: 6.7519
[09/26 03:01:48 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1673, average loss: 6.6426
[09/26 03:01:48 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 3.00	
[09/26 03:01:48 visual_prompt]: Training 65 / 100 epoch, with learning rate 3.454915028125263
[09/26 03:01:54 visual_prompt]: Epoch 65 / 100: avg data time: 5.60e-02, avg batch time: 0.4993, average train loss: 6.4810
[09/26 03:01:56 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1673, average loss: 6.4225
[09/26 03:01:56 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 1.50	
[09/26 03:01:56 visual_prompt]: Training 66 / 100 epoch, with learning rate 3.289899283371657
[09/26 03:02:03 visual_prompt]: Epoch 66 / 100: avg data time: 4.52e-02, avg batch time: 0.4909, average train loss: 6.2890
[09/26 03:02:04 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1675, average loss: 6.3301
[09/26 03:02:04 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 3.00	
[09/26 03:02:04 visual_prompt]: Training 67 / 100 epoch, with learning rate 3.1269670329204398
[09/26 03:02:11 visual_prompt]: Epoch 67 / 100: avg data time: 6.35e-02, avg batch time: 0.5062, average train loss: 6.0895
[09/26 03:02:12 visual_prompt]: Inference (val):avg data time: 2.01e-05, avg batch time: 0.1674, average loss: 6.3336
[09/26 03:02:13 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.00	
[09/26 03:02:13 visual_prompt]: Training 68 / 100 epoch, with learning rate 2.9663167846209997
[09/26 03:02:19 visual_prompt]: Epoch 68 / 100: avg data time: 5.16e-02, avg batch time: 0.4981, average train loss: 6.0874
[09/26 03:02:21 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1674, average loss: 6.2341
[09/26 03:02:21 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 5.00	
[09/26 03:02:21 visual_prompt]: Training 69 / 100 epoch, with learning rate 2.8081442660546125
[09/26 03:02:28 visual_prompt]: Epoch 69 / 100: avg data time: 5.27e-02, avg batch time: 0.4959, average train loss: 5.9386
[09/26 03:02:29 visual_prompt]: Inference (val):avg data time: 1.86e-05, avg batch time: 0.1667, average loss: 6.1595
[09/26 03:02:29 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 4.50	
[09/26 03:02:29 visual_prompt]: Training 70 / 100 epoch, with learning rate 2.6526421860705476
[09/26 03:02:36 visual_prompt]: Epoch 70 / 100: avg data time: 5.78e-02, avg batch time: 0.5008, average train loss: 5.9171
[09/26 03:02:37 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1670, average loss: 6.1346
[09/26 03:02:37 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 2.00	
[09/26 03:02:37 visual_prompt]: Training 71 / 100 epoch, with learning rate 2.500000000000001
[09/26 03:02:44 visual_prompt]: Epoch 71 / 100: avg data time: 6.04e-02, avg batch time: 0.5024, average train loss: 5.8940
[09/26 03:02:46 visual_prompt]: Inference (val):avg data time: 2.02e-05, avg batch time: 0.1671, average loss: 6.1937
[09/26 03:02:46 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 5.50	
[09/26 03:02:46 visual_prompt]: Training 72 / 100 epoch, with learning rate 2.350403678833976
[09/26 03:02:53 visual_prompt]: Epoch 72 / 100: avg data time: 6.00e-02, avg batch time: 0.5021, average train loss: 5.8756
[09/26 03:02:54 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1670, average loss: 6.1769
[09/26 03:02:54 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 3.00	
[09/26 03:02:54 visual_prompt]: Training 73 / 100 epoch, with learning rate 2.2040354826462667
[09/26 03:03:01 visual_prompt]: Epoch 73 / 100: avg data time: 5.77e-02, avg batch time: 0.4999, average train loss: 5.7948
[09/26 03:03:02 visual_prompt]: Inference (val):avg data time: 1.81e-05, avg batch time: 0.1668, average loss: 6.0940
[09/26 03:03:02 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 2.50	
[09/26 03:03:02 visual_prompt]: Training 74 / 100 epoch, with learning rate 2.061073738537635
[09/26 03:03:09 visual_prompt]: Epoch 74 / 100: avg data time: 5.81e-02, avg batch time: 0.5008, average train loss: 5.7752
[09/26 03:03:11 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1671, average loss: 6.1040
[09/26 03:03:11 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.00	
[09/26 03:03:11 visual_prompt]: Training 75 / 100 epoch, with learning rate 1.9216926233717087
[09/26 03:03:17 visual_prompt]: Epoch 75 / 100: avg data time: 4.97e-02, avg batch time: 0.4927, average train loss: 5.8422
[09/26 03:03:19 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1669, average loss: 6.1623
[09/26 03:03:19 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.00	
[09/26 03:03:19 visual_prompt]: Training 76 / 100 epoch, with learning rate 1.7860619515673033
[09/26 03:03:26 visual_prompt]: Epoch 76 / 100: avg data time: 5.81e-02, avg batch time: 0.5011, average train loss: 5.7022
[09/26 03:03:27 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.1673, average loss: 6.0626
[09/26 03:03:27 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 3.50	
[09/26 03:03:27 visual_prompt]: Training 77 / 100 epoch, with learning rate 1.6543469682057106
[09/26 03:03:34 visual_prompt]: Epoch 77 / 100: avg data time: 5.68e-02, avg batch time: 0.5006, average train loss: 5.6197
[09/26 03:03:36 visual_prompt]: Inference (val):avg data time: 1.73e-05, avg batch time: 0.1670, average loss: 6.0774
[09/26 03:03:36 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.00	
[09/26 03:03:36 visual_prompt]: Training 78 / 100 epoch, with learning rate 1.5267081477050133
[09/26 03:03:42 visual_prompt]: Epoch 78 / 100: avg data time: 5.51e-02, avg batch time: 0.4983, average train loss: 5.5998
[09/26 03:03:44 visual_prompt]: Inference (val):avg data time: 1.87e-05, avg batch time: 0.1675, average loss: 6.0631
[09/26 03:03:44 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 03:03:44 visual_prompt]: Training 79 / 100 epoch, with learning rate 1.403300998306745
[09/26 03:03:51 visual_prompt]: Epoch 79 / 100: avg data time: 5.11e-02, avg batch time: 0.4945, average train loss: 5.5805
[09/26 03:03:52 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1673, average loss: 6.0261
[09/26 03:03:52 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 4.50	
[09/26 03:03:52 visual_prompt]: Training 80 / 100 epoch, with learning rate 1.2842758726130281
[09/26 03:03:59 visual_prompt]: Epoch 80 / 100: avg data time: 4.88e-02, avg batch time: 0.4942, average train loss: 5.5640
[09/26 03:04:00 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1671, average loss: 6.0305
[09/26 03:04:00 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 03:04:00 visual_prompt]: Training 81 / 100 epoch, with learning rate 1.1697777844051105
[09/26 03:04:07 visual_prompt]: Epoch 81 / 100: avg data time: 5.82e-02, avg batch time: 0.5021, average train loss: 5.5279
[09/26 03:04:09 visual_prompt]: Inference (val):avg data time: 1.96e-05, avg batch time: 0.1670, average loss: 5.9741
[09/26 03:04:09 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.00	
[09/26 03:04:09 visual_prompt]: Training 82 / 100 epoch, with learning rate 1.0599462319663906
[09/26 03:04:16 visual_prompt]: Epoch 82 / 100: avg data time: 5.91e-02, avg batch time: 0.5028, average train loss: 5.5567
[09/26 03:04:17 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1673, average loss: 6.0452
[09/26 03:04:17 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 5.50	
[09/26 03:04:17 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.9549150281252633
[09/26 03:04:24 visual_prompt]: Epoch 83 / 100: avg data time: 6.03e-02, avg batch time: 0.5029, average train loss: 5.5410
[09/26 03:04:26 visual_prompt]: Inference (val):avg data time: 3.32e-05, avg batch time: 0.1670, average loss: 6.0329
[09/26 03:04:26 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 4.50	
[09/26 03:04:26 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.8548121372247919
[09/26 03:04:32 visual_prompt]: Epoch 84 / 100: avg data time: 6.05e-02, avg batch time: 0.5031, average train loss: 5.5457
[09/26 03:04:34 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1671, average loss: 6.0487
[09/26 03:04:34 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.00	
[09/26 03:04:34 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.7597595192178702
[09/26 03:04:41 visual_prompt]: Epoch 85 / 100: avg data time: 5.86e-02, avg batch time: 0.5006, average train loss: 5.5206
[09/26 03:04:42 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1669, average loss: 6.0207
[09/26 03:04:42 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.00	
[09/26 03:04:42 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.6698729810778065
[09/26 03:04:49 visual_prompt]: Epoch 86 / 100: avg data time: 5.77e-02, avg batch time: 0.5014, average train loss: 5.5197
[09/26 03:04:51 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1673, average loss: 6.0126
[09/26 03:04:51 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.50	
[09/26 03:04:51 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.5852620357053651
[09/26 03:04:57 visual_prompt]: Epoch 87 / 100: avg data time: 4.51e-02, avg batch time: 0.4894, average train loss: 5.4852
[09/26 03:04:59 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1673, average loss: 6.0126
[09/26 03:04:59 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 5.50	
[09/26 03:04:59 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.5060297685041659
[09/26 03:05:05 visual_prompt]: Epoch 88 / 100: avg data time: 4.29e-02, avg batch time: 0.4866, average train loss: 5.4480
[09/26 03:05:07 visual_prompt]: Inference (val):avg data time: 2.01e-05, avg batch time: 0.1673, average loss: 5.9594
[09/26 03:05:07 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 5.50	
[09/26 03:05:07 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.4322727117869951
[09/26 03:05:13 visual_prompt]: Epoch 89 / 100: avg data time: 4.36e-02, avg batch time: 0.4870, average train loss: 5.4870
[09/26 03:05:15 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1676, average loss: 6.0350
[09/26 03:05:15 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.50	
[09/26 03:05:15 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.36408072716606343
[09/26 03:05:22 visual_prompt]: Epoch 90 / 100: avg data time: 5.99e-02, avg batch time: 0.5034, average train loss: 5.4837
[09/26 03:05:23 visual_prompt]: Inference (val):avg data time: 2.05e-05, avg batch time: 0.1672, average loss: 6.0335
[09/26 03:05:23 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 5.00	
[09/26 03:05:23 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.3015368960704584
[09/26 03:05:30 visual_prompt]: Epoch 91 / 100: avg data time: 5.97e-02, avg batch time: 0.5022, average train loss: 5.4555
[09/26 03:05:32 visual_prompt]: Inference (val):avg data time: 1.99e-05, avg batch time: 0.1677, average loss: 5.9769
[09/26 03:05:32 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 6.00	
[09/26 03:05:32 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.24471741852423234
[09/26 03:05:38 visual_prompt]: Epoch 92 / 100: avg data time: 4.97e-02, avg batch time: 0.4927, average train loss: 5.4023
[09/26 03:05:40 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1678, average loss: 6.0293
[09/26 03:05:40 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 6.00	
[09/26 03:05:40 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.19369152030840553
[09/26 03:05:47 visual_prompt]: Epoch 93 / 100: avg data time: 5.10e-02, avg batch time: 0.4940, average train loss: 5.3565
[09/26 03:05:48 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1672, average loss: 5.9198
[09/26 03:05:48 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 6.50	
[09/26 03:05:48 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.14852136862001764
[09/26 03:05:55 visual_prompt]: Epoch 94 / 100: avg data time: 5.91e-02, avg batch time: 0.5025, average train loss: 5.2621
[09/26 03:05:57 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1674, average loss: 5.9641
[09/26 03:05:57 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 5.50	
[09/26 03:05:57 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.10926199633097156
[09/26 03:06:03 visual_prompt]: Epoch 95 / 100: avg data time: 4.61e-02, avg batch time: 0.4892, average train loss: 5.2012
[09/26 03:06:05 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1676, average loss: 5.9546
[09/26 03:06:05 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 6.00	
[09/26 03:06:05 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.0759612349389599
[09/26 03:06:12 visual_prompt]: Epoch 96 / 100: avg data time: 4.94e-02, avg batch time: 0.4925, average train loss: 5.1506
[09/26 03:06:13 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1674, average loss: 5.8819
[09/26 03:06:13 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.50	top5: 8.50	
[09/26 03:06:13 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.04865965629214819
[09/26 03:06:20 visual_prompt]: Epoch 97 / 100: avg data time: 5.78e-02, avg batch time: 0.5008, average train loss: 5.0950
[09/26 03:06:21 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1673, average loss: 5.8942
[09/26 03:06:21 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.50	top5: 5.50	
[09/26 03:06:21 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.02739052315863355
[09/26 03:06:28 visual_prompt]: Epoch 98 / 100: avg data time: 5.77e-02, avg batch time: 0.4998, average train loss: 5.0614
[09/26 03:06:30 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1676, average loss: 5.9401
[09/26 03:06:30 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.00	top5: 7.00	
[09/26 03:06:30 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.012179748700879012
[09/26 03:06:36 visual_prompt]: Epoch 99 / 100: avg data time: 5.89e-02, avg batch time: 0.5021, average train loss: 5.0145
[09/26 03:06:38 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1672, average loss: 5.8854
[09/26 03:06:38 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.00	top5: 7.50	
[09/26 03:06:38 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0030458649045211894
[09/26 03:06:45 visual_prompt]: Epoch 100 / 100: avg data time: 5.57e-02, avg batch time: 0.5000, average train loss: 4.9963
[09/26 03:06:46 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1680, average loss: 5.8941
[09/26 03:06:46 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.00	top5: 7.00	
[09/26 03:06:46 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 03:06:46 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              0
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 03:06:46 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-sun397', 'DATA.NUMBER_CLASSES', '397', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 03:06:46 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 03:06:46 visual_prompt]: Training with config:
[09/26 03:06:46 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-sun397/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr10.0_wd0.0001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 10.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-sun397', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 397, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 03:06:46 visual_prompt]: Loading training data...
[09/26 03:06:46 visual_prompt]: Constructing vtab-sun397 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split train[:800], from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/26 03:06:48 visual_prompt]: Number of images: 800
[09/26 03:06:48 visual_prompt]: Number of classes: 309 / 397
[09/26 03:06:48 visual_prompt]: Loading validation data...
[09/26 03:06:48 visual_prompt]: Constructing vtab-sun397 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split validation[:200], from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/26 03:06:48 visual_prompt]: Number of images: 200
[09/26 03:06:48 visual_prompt]: Number of classes: 136 / 397
[09/26 03:06:48 visual_prompt]: Constructing models...
[09/26 03:06:50 visual_prompt]: Total Parameters: 86564749	 Gradient Parameters: 766093
[09/26 03:06:50 visual_prompt]: tuned percent:0.885
[09/26 03:06:51 visual_prompt]: Device used for model: 0
[09/26 03:06:51 visual_prompt]: Setting up Evaluator...
[09/26 03:06:51 visual_prompt]: Setting up Trainer...
[09/26 03:06:51 visual_prompt]: 	Setting up the optimizer...
[09/26 03:06:51 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 03:06:57 visual_prompt]: Epoch 1 / 100: avg data time: 5.26e-02, avg batch time: 0.4945, average train loss: 5.9890
[09/26 03:06:59 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1671, average loss: 6.0097
[09/26 03:06:59 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/26 03:06:59 visual_prompt]: Training 2 / 100 epoch, with learning rate 1.0
[09/26 03:07:06 visual_prompt]: Epoch 2 / 100: avg data time: 5.63e-02, avg batch time: 0.4995, average train loss: 5.7576
[09/26 03:07:07 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1667, average loss: 5.8051
[09/26 03:07:07 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 3.50	
[09/26 03:07:07 visual_prompt]: Best epoch 2: best metric: 0.015
[09/26 03:07:07 visual_prompt]: Training 3 / 100 epoch, with learning rate 2.0
[09/26 03:07:14 visual_prompt]: Epoch 3 / 100: avg data time: 5.60e-02, avg batch time: 0.4990, average train loss: 5.6651
[09/26 03:07:15 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1670, average loss: 5.9461
[09/26 03:07:15 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 5.50	
[09/26 03:07:15 visual_prompt]: Training 4 / 100 epoch, with learning rate 3.0
[09/26 03:07:22 visual_prompt]: Epoch 4 / 100: avg data time: 5.31e-02, avg batch time: 0.4964, average train loss: 5.7049
[09/26 03:07:24 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1675, average loss: 6.0758
[09/26 03:07:24 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.50	top5: 4.50	
[09/26 03:07:24 visual_prompt]: Best epoch 4: best metric: 0.025
[09/26 03:07:24 visual_prompt]: Training 5 / 100 epoch, with learning rate 4.0
[09/26 03:07:30 visual_prompt]: Epoch 5 / 100: avg data time: 5.46e-02, avg batch time: 0.4966, average train loss: 5.9028
[09/26 03:07:32 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1668, average loss: 6.4156
[09/26 03:07:32 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.00	
[09/26 03:07:32 visual_prompt]: Training 6 / 100 epoch, with learning rate 5.0
[09/26 03:07:39 visual_prompt]: Epoch 6 / 100: avg data time: 4.46e-02, avg batch time: 0.4878, average train loss: 6.4061
[09/26 03:07:40 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1672, average loss: 6.4250
[09/26 03:07:40 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/26 03:07:40 visual_prompt]: Training 7 / 100 epoch, with learning rate 6.0
[09/26 03:07:47 visual_prompt]: Epoch 7 / 100: avg data time: 6.08e-02, avg batch time: 0.5042, average train loss: 6.4293
[09/26 03:07:48 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1672, average loss: 6.3558
[09/26 03:07:48 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 1.00	
[09/26 03:07:48 visual_prompt]: Training 8 / 100 epoch, with learning rate 7.0
[09/26 03:07:55 visual_prompt]: Epoch 8 / 100: avg data time: 5.90e-02, avg batch time: 0.5019, average train loss: 7.7798
[09/26 03:07:57 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1671, average loss: 7.1384
[09/26 03:07:57 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 0.50	
[09/26 03:07:57 visual_prompt]: Training 9 / 100 epoch, with learning rate 8.0
[09/26 03:08:03 visual_prompt]: Epoch 9 / 100: avg data time: 4.76e-02, avg batch time: 0.4903, average train loss: 8.2769
[09/26 03:08:05 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1670, average loss: 7.1577
[09/26 03:08:05 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 3.00	
[09/26 03:08:05 visual_prompt]: Training 10 / 100 epoch, with learning rate 9.0
[09/26 03:08:12 visual_prompt]: Epoch 10 / 100: avg data time: 5.38e-02, avg batch time: 0.4965, average train loss: 7.6849
[09/26 03:08:13 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1672, average loss: 7.4352
[09/26 03:08:13 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 7.00	
[09/26 03:08:13 visual_prompt]: Training 11 / 100 epoch, with learning rate 10.0
[09/26 03:08:20 visual_prompt]: Epoch 11 / 100: avg data time: 5.88e-02, avg batch time: 0.5020, average train loss: 8.1688
[09/26 03:08:22 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1674, average loss: 6.9860
[09/26 03:08:22 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.50	
[09/26 03:08:22 visual_prompt]: Training 12 / 100 epoch, with learning rate 9.996954135095478
[09/26 03:08:28 visual_prompt]: Epoch 12 / 100: avg data time: 4.38e-02, avg batch time: 0.4888, average train loss: 6.9800
[09/26 03:08:30 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1679, average loss: 6.5401
[09/26 03:08:30 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.00	
[09/26 03:08:30 visual_prompt]: Training 13 / 100 epoch, with learning rate 9.987820251299121
[09/26 03:08:37 visual_prompt]: Epoch 13 / 100: avg data time: 5.31e-02, avg batch time: 0.4951, average train loss: 6.6065
[09/26 03:08:38 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1670, average loss: 6.5783
[09/26 03:08:38 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.00	
[09/26 03:08:38 visual_prompt]: Training 14 / 100 epoch, with learning rate 9.972609476841367
[09/26 03:08:45 visual_prompt]: Epoch 14 / 100: avg data time: 4.62e-02, avg batch time: 0.4893, average train loss: 6.2525
[09/26 03:08:46 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1673, average loss: 6.7310
[09/26 03:08:46 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.00	
[09/26 03:08:46 visual_prompt]: Training 15 / 100 epoch, with learning rate 9.951340343707852
[09/26 03:08:53 visual_prompt]: Epoch 15 / 100: avg data time: 5.10e-02, avg batch time: 0.4940, average train loss: 6.5435
[09/26 03:08:55 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1673, average loss: 6.3291
[09/26 03:08:55 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.50	
[09/26 03:08:55 visual_prompt]: Training 16 / 100 epoch, with learning rate 9.924038765061042
[09/26 03:09:01 visual_prompt]: Epoch 16 / 100: avg data time: 5.80e-02, avg batch time: 0.5012, average train loss: 6.3168
[09/26 03:09:03 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1669, average loss: 6.0826
[09/26 03:09:03 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 10.00	
[09/26 03:09:03 visual_prompt]: Training 17 / 100 epoch, with learning rate 9.890738003669028
[09/26 03:09:10 visual_prompt]: Epoch 17 / 100: avg data time: 5.25e-02, avg batch time: 0.4961, average train loss: 5.8795
[09/26 03:09:11 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1673, average loss: 6.1376
[09/26 03:09:11 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 03:09:11 visual_prompt]: Training 18 / 100 epoch, with learning rate 9.851478631379981
[09/26 03:09:18 visual_prompt]: Epoch 18 / 100: avg data time: 4.57e-02, avg batch time: 0.4881, average train loss: 5.7566
[09/26 03:09:19 visual_prompt]: Inference (val):avg data time: 2.11e-05, avg batch time: 0.1673, average loss: 5.8790
[09/26 03:09:19 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 7.00	
[09/26 03:09:19 visual_prompt]: Training 19 / 100 epoch, with learning rate 9.806308479691594
[09/26 03:09:26 visual_prompt]: Epoch 19 / 100: avg data time: 5.63e-02, avg batch time: 0.4992, average train loss: 5.6091
[09/26 03:09:28 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1679, average loss: 6.0767
[09/26 03:09:28 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.00	
[09/26 03:09:28 visual_prompt]: Training 20 / 100 epoch, with learning rate 9.755282581475768
[09/26 03:09:35 visual_prompt]: Epoch 20 / 100: avg data time: 5.34e-02, avg batch time: 0.4962, average train loss: 5.6392
[09/26 03:09:36 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1669, average loss: 5.9219
[09/26 03:09:36 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 7.50	
[09/26 03:09:36 visual_prompt]: Training 21 / 100 epoch, with learning rate 9.698463103929543
[09/26 03:09:43 visual_prompt]: Epoch 21 / 100: avg data time: 5.47e-02, avg batch time: 0.4973, average train loss: 5.6478
[09/26 03:09:44 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.1670, average loss: 5.8586
[09/26 03:09:44 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 9.00	
[09/26 03:09:44 visual_prompt]: Training 22 / 100 epoch, with learning rate 9.635919272833938
[09/26 03:09:51 visual_prompt]: Epoch 22 / 100: avg data time: 5.51e-02, avg batch time: 0.4982, average train loss: 5.6107
[09/26 03:09:53 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1679, average loss: 5.9133
[09/26 03:09:53 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 6.00	
[09/26 03:09:53 visual_prompt]: Training 23 / 100 epoch, with learning rate 9.567727288213003
[09/26 03:10:00 visual_prompt]: Epoch 23 / 100: avg data time: 4.87e-02, avg batch time: 0.4934, average train loss: 5.5208
[09/26 03:10:01 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1687, average loss: 6.1302
[09/26 03:10:01 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.00	top5: 7.00	
[09/26 03:10:01 visual_prompt]: Training 24 / 100 epoch, with learning rate 9.493970231495835
[09/26 03:10:08 visual_prompt]: Epoch 24 / 100: avg data time: 6.00e-02, avg batch time: 0.5034, average train loss: 5.5276
[09/26 03:10:09 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1674, average loss: 5.9547
[09/26 03:10:09 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 7.50	
[09/26 03:10:09 visual_prompt]: Training 25 / 100 epoch, with learning rate 9.414737964294634
[09/26 03:10:16 visual_prompt]: Epoch 25 / 100: avg data time: 5.18e-02, avg batch time: 0.4957, average train loss: 5.4407
[09/26 03:10:18 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1680, average loss: 6.0699
[09/26 03:10:18 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.00	top5: 6.00	
[09/26 03:10:18 visual_prompt]: Training 26 / 100 epoch, with learning rate 9.330127018922195
[09/26 03:10:24 visual_prompt]: Epoch 26 / 100: avg data time: 5.65e-02, avg batch time: 0.5002, average train loss: 5.4585
[09/26 03:10:26 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1679, average loss: 6.1021
[09/26 03:10:26 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.00	top5: 9.50	
[09/26 03:10:26 visual_prompt]: Training 27 / 100 epoch, with learning rate 9.240240480782129
[09/26 03:10:33 visual_prompt]: Epoch 27 / 100: avg data time: 5.49e-02, avg batch time: 0.5001, average train loss: 5.6823
[09/26 03:10:34 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1673, average loss: 6.1768
[09/26 03:10:34 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.50	
[09/26 03:10:34 visual_prompt]: Training 28 / 100 epoch, with learning rate 9.145187862775208
[09/26 03:10:41 visual_prompt]: Epoch 28 / 100: avg data time: 5.52e-02, avg batch time: 0.4992, average train loss: 5.6865
[09/26 03:10:43 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1675, average loss: 6.1188
[09/26 03:10:43 visual_prompt]: Classification results with val_vtab-sun397: top1: 3.00	top5: 6.50	
[09/26 03:10:43 visual_prompt]: Best epoch 28: best metric: 0.030
[09/26 03:10:43 visual_prompt]: Training 29 / 100 epoch, with learning rate 9.045084971874736
[09/26 03:10:49 visual_prompt]: Epoch 29 / 100: avg data time: 5.10e-02, avg batch time: 0.4938, average train loss: 5.5576
[09/26 03:10:51 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1680, average loss: 5.9978
[09/26 03:10:51 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 6.50	
[09/26 03:10:51 visual_prompt]: Training 30 / 100 epoch, with learning rate 8.940053768033609
[09/26 03:10:58 visual_prompt]: Epoch 30 / 100: avg data time: 5.74e-02, avg batch time: 0.5002, average train loss: 5.4454
[09/26 03:10:59 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1680, average loss: 5.7518
[09/26 03:10:59 visual_prompt]: Classification results with val_vtab-sun397: top1: 3.00	top5: 11.50	
[09/26 03:10:59 visual_prompt]: Training 31 / 100 epoch, with learning rate 8.83022221559489
[09/26 03:11:06 visual_prompt]: Epoch 31 / 100: avg data time: 6.27e-02, avg batch time: 0.5049, average train loss: 5.4240
[09/26 03:11:08 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1683, average loss: 5.8347
[09/26 03:11:08 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 6.00	
[09/26 03:11:08 visual_prompt]: Training 32 / 100 epoch, with learning rate 8.715724127386972
[09/26 03:11:15 visual_prompt]: Epoch 32 / 100: avg data time: 5.57e-02, avg batch time: 0.4983, average train loss: 5.2584
[09/26 03:11:16 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1676, average loss: 5.8245
[09/26 03:11:16 visual_prompt]: Classification results with val_vtab-sun397: top1: 4.00	top5: 10.50	
[09/26 03:11:16 visual_prompt]: Best epoch 32: best metric: 0.040
[09/26 03:11:16 visual_prompt]: Training 33 / 100 epoch, with learning rate 8.596699001693256
[09/26 03:11:23 visual_prompt]: Epoch 33 / 100: avg data time: 5.14e-02, avg batch time: 0.4934, average train loss: 5.2987
[09/26 03:11:24 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1677, average loss: 5.9310
[09/26 03:11:24 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 6.50	
[09/26 03:11:24 visual_prompt]: Training 34 / 100 epoch, with learning rate 8.473291852294986
[09/26 03:11:31 visual_prompt]: Epoch 34 / 100: avg data time: 5.11e-02, avg batch time: 0.4944, average train loss: 5.3359
[09/26 03:11:33 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1678, average loss: 5.9807
[09/26 03:11:33 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 7.00	
[09/26 03:11:33 visual_prompt]: Training 35 / 100 epoch, with learning rate 8.345653031794292
[09/26 03:11:39 visual_prompt]: Epoch 35 / 100: avg data time: 4.82e-02, avg batch time: 0.4926, average train loss: 5.4008
[09/26 03:11:41 visual_prompt]: Inference (val):avg data time: 4.43e-05, avg batch time: 0.1670, average loss: 5.9990
[09/26 03:11:41 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 5.00	
[09/26 03:11:41 visual_prompt]: Training 36 / 100 epoch, with learning rate 8.213938048432697
[09/26 03:11:48 visual_prompt]: Epoch 36 / 100: avg data time: 5.66e-02, avg batch time: 0.4998, average train loss: 5.2914
[09/26 03:11:49 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1679, average loss: 5.9643
[09/26 03:11:49 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 9.00	
[09/26 03:11:49 visual_prompt]: Training 37 / 100 epoch, with learning rate 8.078307376628292
[09/26 03:11:56 visual_prompt]: Epoch 37 / 100: avg data time: 5.59e-02, avg batch time: 0.4998, average train loss: 5.2720
[09/26 03:11:57 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1678, average loss: 5.9205
[09/26 03:11:57 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.00	top5: 11.00	
[09/26 03:11:57 visual_prompt]: Training 38 / 100 epoch, with learning rate 7.938926261462366
[09/26 03:12:04 visual_prompt]: Epoch 38 / 100: avg data time: 5.75e-02, avg batch time: 0.5017, average train loss: 5.3524
[09/26 03:12:06 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1676, average loss: 6.0427
[09/26 03:12:06 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.00	top5: 7.50	
[09/26 03:12:06 visual_prompt]: Training 39 / 100 epoch, with learning rate 7.795964517353734
[09/26 03:12:13 visual_prompt]: Epoch 39 / 100: avg data time: 5.80e-02, avg batch time: 0.5033, average train loss: 5.2103
[09/26 03:12:14 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1678, average loss: 5.8595
[09/26 03:12:14 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.00	top5: 8.50	
[09/26 03:12:14 visual_prompt]: Training 40 / 100 epoch, with learning rate 7.649596321166024
[09/26 03:12:21 visual_prompt]: Epoch 40 / 100: avg data time: 4.72e-02, avg batch time: 0.4904, average train loss: 5.1763
[09/26 03:12:23 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1679, average loss: 5.9860
[09/26 03:12:23 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 6.50	
[09/26 03:12:23 visual_prompt]: Training 41 / 100 epoch, with learning rate 7.5
[09/26 03:12:29 visual_prompt]: Epoch 41 / 100: avg data time: 4.78e-02, avg batch time: 0.4917, average train loss: 5.2635
[09/26 03:12:31 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1677, average loss: 5.9115
[09/26 03:12:31 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 6.50	
[09/26 03:12:31 visual_prompt]: Training 42 / 100 epoch, with learning rate 7.347357813929454
[09/26 03:12:38 visual_prompt]: Epoch 42 / 100: avg data time: 5.65e-02, avg batch time: 0.5003, average train loss: 5.0816
[09/26 03:12:39 visual_prompt]: Inference (val):avg data time: 3.26e-05, avg batch time: 0.1676, average loss: 6.0401
[09/26 03:12:39 visual_prompt]: Classification results with val_vtab-sun397: top1: 3.00	top5: 10.00	
[09/26 03:12:39 visual_prompt]: Training 43 / 100 epoch, with learning rate 7.191855733945387
[09/26 03:12:46 visual_prompt]: Epoch 43 / 100: avg data time: 5.62e-02, avg batch time: 0.5001, average train loss: 4.9682
[09/26 03:12:48 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1679, average loss: 5.8989
[09/26 03:12:48 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 12.00	
[09/26 03:12:48 visual_prompt]: Training 44 / 100 epoch, with learning rate 7.033683215379002
[09/26 03:12:54 visual_prompt]: Epoch 44 / 100: avg data time: 6.00e-02, avg batch time: 0.5032, average train loss: 5.0454
[09/26 03:12:56 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1680, average loss: 6.0954
[09/26 03:12:56 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 7.50	
[09/26 03:12:56 visual_prompt]: Training 45 / 100 epoch, with learning rate 6.873032967079561
[09/26 03:13:03 visual_prompt]: Epoch 45 / 100: avg data time: 5.89e-02, avg batch time: 0.5023, average train loss: 5.0141
[09/26 03:13:04 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1679, average loss: 5.8031
[09/26 03:13:04 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 9.50	
[09/26 03:13:04 visual_prompt]: Training 46 / 100 epoch, with learning rate 6.710100716628345
[09/26 03:13:11 visual_prompt]: Epoch 46 / 100: avg data time: 4.64e-02, avg batch time: 0.4914, average train loss: 4.9331
[09/26 03:13:12 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1679, average loss: 5.8842
[09/26 03:13:12 visual_prompt]: Classification results with val_vtab-sun397: top1: 3.00	top5: 10.00	
[09/26 03:13:12 visual_prompt]: Training 47 / 100 epoch, with learning rate 6.545084971874737
[09/26 03:13:19 visual_prompt]: Epoch 47 / 100: avg data time: 6.06e-02, avg batch time: 0.5034, average train loss: 4.8354
[09/26 03:13:21 visual_prompt]: Inference (val):avg data time: 4.36e-05, avg batch time: 0.1677, average loss: 5.8713
[09/26 03:13:21 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 12.00	
[09/26 03:13:21 visual_prompt]: Training 48 / 100 epoch, with learning rate 6.378186779084995
[09/26 03:13:28 visual_prompt]: Epoch 48 / 100: avg data time: 5.66e-02, avg batch time: 0.5000, average train loss: 4.8592
[09/26 03:13:29 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1677, average loss: 5.9054
[09/26 03:13:29 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.50	top5: 12.50	
[09/26 03:13:29 visual_prompt]: Training 49 / 100 epoch, with learning rate 6.209609477998338
[09/26 03:13:36 visual_prompt]: Epoch 49 / 100: avg data time: 4.23e-02, avg batch time: 0.4891, average train loss: 4.9337
[09/26 03:13:37 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1680, average loss: 5.8290
[09/26 03:13:37 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.00	top5: 8.50	
[09/26 03:13:37 visual_prompt]: Training 50 / 100 epoch, with learning rate 6.039558454088796
[09/26 03:13:44 visual_prompt]: Epoch 50 / 100: avg data time: 3.87e-02, avg batch time: 0.4844, average train loss: 4.8032
[09/26 03:13:45 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1680, average loss: 5.8404
[09/26 03:13:45 visual_prompt]: Classification results with val_vtab-sun397: top1: 4.00	top5: 10.50	
[09/26 03:13:45 visual_prompt]: Training 51 / 100 epoch, with learning rate 5.868240888334652
[09/26 03:13:52 visual_prompt]: Epoch 51 / 100: avg data time: 5.86e-02, avg batch time: 0.5034, average train loss: 4.8199
[09/26 03:13:54 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1678, average loss: 5.7362
[09/26 03:13:54 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.00	top5: 12.00	
[09/26 03:13:54 visual_prompt]: Training 52 / 100 epoch, with learning rate 5.695865504800327
[09/26 03:14:01 visual_prompt]: Epoch 52 / 100: avg data time: 5.39e-02, avg batch time: 0.4984, average train loss: 4.6649
[09/26 03:14:02 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1679, average loss: 5.8014
[09/26 03:14:02 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.50	top5: 14.00	
[09/26 03:14:02 visual_prompt]: Training 53 / 100 epoch, with learning rate 5.522642316338268
[09/26 03:14:09 visual_prompt]: Epoch 53 / 100: avg data time: 4.65e-02, avg batch time: 0.4925, average train loss: 4.6329
[09/26 03:14:10 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1674, average loss: 5.8285
[09/26 03:14:10 visual_prompt]: Classification results with val_vtab-sun397: top1: 3.50	top5: 10.50	
[09/26 03:14:10 visual_prompt]: Training 54 / 100 epoch, with learning rate 5.3487823687206255
[09/26 03:14:17 visual_prompt]: Epoch 54 / 100: avg data time: 4.84e-02, avg batch time: 0.4934, average train loss: 4.4307
[09/26 03:14:19 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1674, average loss: 5.7982
[09/26 03:14:19 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 13.00	
[09/26 03:14:19 visual_prompt]: Training 55 / 100 epoch, with learning rate 5.174497483512505
[09/26 03:14:25 visual_prompt]: Epoch 55 / 100: avg data time: 5.42e-02, avg batch time: 0.4983, average train loss: 4.2394
[09/26 03:14:27 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1678, average loss: 6.0511
[09/26 03:14:27 visual_prompt]: Classification results with val_vtab-sun397: top1: 6.50	top5: 15.50	
[09/26 03:14:27 visual_prompt]: Best epoch 55: best metric: 0.065
[09/26 03:14:27 visual_prompt]: Training 56 / 100 epoch, with learning rate 5.0
[09/26 03:14:34 visual_prompt]: Epoch 56 / 100: avg data time: 5.31e-02, avg batch time: 0.4970, average train loss: 4.0739
[09/26 03:14:35 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1676, average loss: 5.7871
[09/26 03:14:35 visual_prompt]: Classification results with val_vtab-sun397: top1: 7.00	top5: 18.00	
[09/26 03:14:35 visual_prompt]: Best epoch 56: best metric: 0.070
[09/26 03:14:35 visual_prompt]: Training 57 / 100 epoch, with learning rate 4.8255025164874965
[09/26 03:14:42 visual_prompt]: Epoch 57 / 100: avg data time: 5.26e-02, avg batch time: 0.4960, average train loss: 3.7628
[09/26 03:14:43 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1671, average loss: 6.5512
[09/26 03:14:43 visual_prompt]: Classification results with val_vtab-sun397: top1: 6.50	top5: 19.00	
[09/26 03:14:43 visual_prompt]: Training 58 / 100 epoch, with learning rate 4.651217631279374
[09/26 03:14:50 visual_prompt]: Epoch 58 / 100: avg data time: 5.68e-02, avg batch time: 0.4992, average train loss: 2.9014
[09/26 03:14:52 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1671, average loss: 6.1656
[09/26 03:14:52 visual_prompt]: Classification results with val_vtab-sun397: top1: 8.50	top5: 22.00	
[09/26 03:14:52 visual_prompt]: Best epoch 58: best metric: 0.085
[09/26 03:14:52 visual_prompt]: Training 59 / 100 epoch, with learning rate 4.477357683661733
[09/26 03:14:58 visual_prompt]: Epoch 59 / 100: avg data time: 5.25e-02, avg batch time: 0.4965, average train loss: 1.9009
[09/26 03:15:00 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1675, average loss: 5.8995
[09/26 03:15:00 visual_prompt]: Classification results with val_vtab-sun397: top1: 14.00	top5: 33.50	
[09/26 03:15:00 visual_prompt]: Best epoch 59: best metric: 0.140
[09/26 03:15:00 visual_prompt]: Training 60 / 100 epoch, with learning rate 4.3041344951996745
[09/26 03:15:07 visual_prompt]: Epoch 60 / 100: avg data time: 5.80e-02, avg batch time: 0.5012, average train loss: 0.9475
[09/26 03:15:08 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1678, average loss: 5.8448
[09/26 03:15:08 visual_prompt]: Classification results with val_vtab-sun397: top1: 12.00	top5: 31.50	
[09/26 03:15:08 visual_prompt]: Training 61 / 100 epoch, with learning rate 4.131759111665349
[09/26 03:15:15 visual_prompt]: Epoch 61 / 100: avg data time: 5.60e-02, avg batch time: 0.4997, average train loss: 0.5158
[09/26 03:15:16 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1678, average loss: 6.3995
[09/26 03:15:16 visual_prompt]: Classification results with val_vtab-sun397: top1: 12.50	top5: 26.50	
[09/26 03:15:16 visual_prompt]: Training 62 / 100 epoch, with learning rate 3.960441545911204
[09/26 03:15:23 visual_prompt]: Epoch 62 / 100: avg data time: 4.80e-02, avg batch time: 0.4924, average train loss: 0.2180
[09/26 03:15:25 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1675, average loss: 6.6194
[09/26 03:15:25 visual_prompt]: Classification results with val_vtab-sun397: top1: 12.00	top5: 32.50	
[09/26 03:15:25 visual_prompt]: Training 63 / 100 epoch, with learning rate 3.790390522001662
[09/26 03:15:31 visual_prompt]: Epoch 63 / 100: avg data time: 5.41e-02, avg batch time: 0.4968, average train loss: 0.0960
[09/26 03:15:33 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1678, average loss: 6.4480
[09/26 03:15:33 visual_prompt]: Classification results with val_vtab-sun397: top1: 12.00	top5: 33.00	
[09/26 03:15:33 visual_prompt]: Training 64 / 100 epoch, with learning rate 3.6218132209150045
[09/26 03:15:40 visual_prompt]: Epoch 64 / 100: avg data time: 4.59e-02, avg batch time: 0.4932, average train loss: 0.0565
[09/26 03:15:41 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1680, average loss: 5.8687
[09/26 03:15:41 visual_prompt]: Classification results with val_vtab-sun397: top1: 18.00	top5: 38.50	
[09/26 03:15:41 visual_prompt]: Best epoch 64: best metric: 0.180
[09/26 03:15:41 visual_prompt]: Training 65 / 100 epoch, with learning rate 3.454915028125263
[09/26 03:15:48 visual_prompt]: Epoch 65 / 100: avg data time: 4.66e-02, avg batch time: 0.4929, average train loss: 0.0270
[09/26 03:15:49 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1676, average loss: 5.8549
[09/26 03:15:49 visual_prompt]: Classification results with val_vtab-sun397: top1: 16.00	top5: 36.00	
[09/26 03:15:49 visual_prompt]: Training 66 / 100 epoch, with learning rate 3.289899283371657
[09/26 03:15:56 visual_prompt]: Epoch 66 / 100: avg data time: 5.72e-02, avg batch time: 0.5008, average train loss: 0.0108
[09/26 03:15:58 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1680, average loss: 5.6693
[09/26 03:15:58 visual_prompt]: Classification results with val_vtab-sun397: top1: 17.00	top5: 37.00	
[09/26 03:15:58 visual_prompt]: Training 67 / 100 epoch, with learning rate 3.1269670329204398
[09/26 03:16:05 visual_prompt]: Epoch 67 / 100: avg data time: 5.60e-02, avg batch time: 0.5016, average train loss: 0.0175
[09/26 03:16:06 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1678, average loss: 5.5111
[09/26 03:16:06 visual_prompt]: Classification results with val_vtab-sun397: top1: 17.50	top5: 37.50	
[09/26 03:16:06 visual_prompt]: Training 68 / 100 epoch, with learning rate 2.9663167846209997
[09/26 03:16:13 visual_prompt]: Epoch 68 / 100: avg data time: 5.77e-02, avg batch time: 0.5019, average train loss: 0.0092
[09/26 03:16:14 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1676, average loss: 5.3238
[09/26 03:16:14 visual_prompt]: Classification results with val_vtab-sun397: top1: 17.00	top5: 36.50	
[09/26 03:16:14 visual_prompt]: Training 69 / 100 epoch, with learning rate 2.8081442660546125
[09/26 03:16:21 visual_prompt]: Epoch 69 / 100: avg data time: 5.81e-02, avg batch time: 0.5013, average train loss: 0.0074
[09/26 03:16:23 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1677, average loss: 5.2785
[09/26 03:16:23 visual_prompt]: Classification results with val_vtab-sun397: top1: 17.50	top5: 35.50	
[09/26 03:16:23 visual_prompt]: Training 70 / 100 epoch, with learning rate 2.6526421860705476
[09/26 03:16:29 visual_prompt]: Epoch 70 / 100: avg data time: 4.82e-02, avg batch time: 0.4926, average train loss: 0.0072
[09/26 03:16:31 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1678, average loss: 5.2099
[09/26 03:16:31 visual_prompt]: Classification results with val_vtab-sun397: top1: 17.00	top5: 36.50	
[09/26 03:16:31 visual_prompt]: Training 71 / 100 epoch, with learning rate 2.500000000000001
[09/26 03:16:38 visual_prompt]: Epoch 71 / 100: avg data time: 4.20e-02, avg batch time: 0.4867, average train loss: 0.0073
[09/26 03:16:39 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1677, average loss: 5.1439
[09/26 03:16:39 visual_prompt]: Classification results with val_vtab-sun397: top1: 19.00	top5: 36.00	
[09/26 03:16:39 visual_prompt]: Best epoch 71: best metric: 0.190
[09/26 03:16:39 visual_prompt]: Training 72 / 100 epoch, with learning rate 2.350403678833976
[09/26 03:16:46 visual_prompt]: Epoch 72 / 100: avg data time: 5.65e-02, avg batch time: 0.4997, average train loss: 0.0080
[09/26 03:16:47 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1681, average loss: 5.0990
[09/26 03:16:47 visual_prompt]: Classification results with val_vtab-sun397: top1: 19.00	top5: 35.50	
[09/26 03:16:47 visual_prompt]: Training 73 / 100 epoch, with learning rate 2.2040354826462667
[09/26 03:16:54 visual_prompt]: Epoch 73 / 100: avg data time: 4.52e-02, avg batch time: 0.4899, average train loss: 0.0086
[09/26 03:16:56 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1678, average loss: 5.0504
[09/26 03:16:56 visual_prompt]: Classification results with val_vtab-sun397: top1: 19.00	top5: 35.50	
[09/26 03:16:56 visual_prompt]: Training 74 / 100 epoch, with learning rate 2.061073738537635
[09/26 03:17:02 visual_prompt]: Epoch 74 / 100: avg data time: 4.91e-02, avg batch time: 0.4927, average train loss: 0.0092
[09/26 03:17:04 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1678, average loss: 5.0119
[09/26 03:17:04 visual_prompt]: Classification results with val_vtab-sun397: top1: 18.50	top5: 36.50	
[09/26 03:17:04 visual_prompt]: Training 75 / 100 epoch, with learning rate 1.9216926233717087
[09/26 03:17:11 visual_prompt]: Epoch 75 / 100: avg data time: 4.27e-02, avg batch time: 0.4872, average train loss: 0.0096
[09/26 03:17:12 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1681, average loss: 4.9829
[09/26 03:17:12 visual_prompt]: Classification results with val_vtab-sun397: top1: 18.50	top5: 37.00	
[09/26 03:17:12 visual_prompt]: Training 76 / 100 epoch, with learning rate 1.7860619515673033
[09/26 03:17:19 visual_prompt]: Epoch 76 / 100: avg data time: 5.36e-02, avg batch time: 0.4971, average train loss: 0.0105
[09/26 03:17:20 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1677, average loss: 4.9506
[09/26 03:17:20 visual_prompt]: Classification results with val_vtab-sun397: top1: 18.50	top5: 37.00	
[09/26 03:17:20 visual_prompt]: Training 77 / 100 epoch, with learning rate 1.6543469682057106
[09/26 03:17:27 visual_prompt]: Epoch 77 / 100: avg data time: 5.27e-02, avg batch time: 0.4969, average train loss: 0.0108
[09/26 03:17:29 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1677, average loss: 4.9235
[09/26 03:17:29 visual_prompt]: Classification results with val_vtab-sun397: top1: 18.00	top5: 37.00	
[09/26 03:17:29 visual_prompt]: Training 78 / 100 epoch, with learning rate 1.5267081477050133
[09/26 03:17:35 visual_prompt]: Epoch 78 / 100: avg data time: 5.58e-02, avg batch time: 0.5002, average train loss: 0.0115
[09/26 03:17:37 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1678, average loss: 4.9035
[09/26 03:17:37 visual_prompt]: Classification results with val_vtab-sun397: top1: 18.00	top5: 36.50	
[09/26 03:17:37 visual_prompt]: Training 79 / 100 epoch, with learning rate 1.403300998306745
[09/26 03:17:44 visual_prompt]: Epoch 79 / 100: avg data time: 5.24e-02, avg batch time: 0.4954, average train loss: 0.0117
[09/26 03:17:45 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1682, average loss: 4.8849
[09/26 03:17:45 visual_prompt]: Classification results with val_vtab-sun397: top1: 18.50	top5: 37.00	
[09/26 03:17:45 visual_prompt]: Training 80 / 100 epoch, with learning rate 1.2842758726130281
[09/26 03:17:52 visual_prompt]: Epoch 80 / 100: avg data time: 4.61e-02, avg batch time: 0.4892, average train loss: 0.0123
[09/26 03:17:53 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1680, average loss: 4.8676
[09/26 03:17:53 visual_prompt]: Classification results with val_vtab-sun397: top1: 18.50	top5: 37.00	
[09/26 03:17:53 visual_prompt]: Training 81 / 100 epoch, with learning rate 1.1697777844051105
[09/26 03:18:00 visual_prompt]: Epoch 81 / 100: avg data time: 5.78e-02, avg batch time: 0.5013, average train loss: 0.0127
[09/26 03:18:02 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1679, average loss: 4.8514
[09/26 03:18:02 visual_prompt]: Classification results with val_vtab-sun397: top1: 19.00	top5: 37.00	
[09/26 03:18:02 visual_prompt]: Training 82 / 100 epoch, with learning rate 1.0599462319663906
[09/26 03:18:08 visual_prompt]: Epoch 82 / 100: avg data time: 5.76e-02, avg batch time: 0.5009, average train loss: 0.0127
[09/26 03:18:10 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1678, average loss: 4.8308
[09/26 03:18:10 visual_prompt]: Classification results with val_vtab-sun397: top1: 19.00	top5: 37.00	
[09/26 03:18:10 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.9549150281252633
[09/26 03:18:17 visual_prompt]: Epoch 83 / 100: avg data time: 4.90e-02, avg batch time: 0.4918, average train loss: 0.0132
[09/26 03:18:18 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1681, average loss: 4.8140
[09/26 03:18:18 visual_prompt]: Classification results with val_vtab-sun397: top1: 19.00	top5: 37.00	
[09/26 03:18:18 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.8548121372247919
[09/26 03:18:25 visual_prompt]: Epoch 84 / 100: avg data time: 5.94e-02, avg batch time: 0.5041, average train loss: 0.0130
[09/26 03:18:27 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1679, average loss: 4.8046
[09/26 03:18:27 visual_prompt]: Classification results with val_vtab-sun397: top1: 19.00	top5: 37.50	
[09/26 03:18:27 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.7597595192178702
[09/26 03:18:33 visual_prompt]: Epoch 85 / 100: avg data time: 4.47e-02, avg batch time: 0.4885, average train loss: 0.0135
[09/26 03:18:35 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1678, average loss: 4.7936
[09/26 03:18:35 visual_prompt]: Classification results with val_vtab-sun397: top1: 19.00	top5: 37.50	
[09/26 03:18:35 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.6698729810778065
[09/26 03:18:41 visual_prompt]: Epoch 86 / 100: avg data time: 4.66e-02, avg batch time: 0.4900, average train loss: 0.0134
[09/26 03:18:43 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1678, average loss: 4.7837
[09/26 03:18:43 visual_prompt]: Classification results with val_vtab-sun397: top1: 19.00	top5: 37.00	
[09/26 03:18:43 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.5852620357053651
[09/26 03:18:50 visual_prompt]: Epoch 87 / 100: avg data time: 5.46e-02, avg batch time: 0.4999, average train loss: 0.0139
[09/26 03:18:51 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1679, average loss: 4.7785
[09/26 03:18:51 visual_prompt]: Classification results with val_vtab-sun397: top1: 19.00	top5: 37.00	
[09/26 03:18:51 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.5060297685041659
[09/26 03:18:58 visual_prompt]: Epoch 88 / 100: avg data time: 5.95e-02, avg batch time: 0.5037, average train loss: 0.0138
[09/26 03:19:00 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1680, average loss: 4.7693
[09/26 03:19:00 visual_prompt]: Classification results with val_vtab-sun397: top1: 19.00	top5: 36.50	
[09/26 03:19:00 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.4322727117869951
[09/26 03:19:06 visual_prompt]: Epoch 89 / 100: avg data time: 5.90e-02, avg batch time: 0.5023, average train loss: 0.0141
[09/26 03:19:08 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1676, average loss: 4.7672
[09/26 03:19:08 visual_prompt]: Classification results with val_vtab-sun397: top1: 19.00	top5: 36.50	
[09/26 03:19:08 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.36408072716606343
[09/26 03:19:15 visual_prompt]: Epoch 90 / 100: avg data time: 6.14e-02, avg batch time: 0.5046, average train loss: 0.0138
[09/26 03:19:16 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1674, average loss: 4.7629
[09/26 03:19:16 visual_prompt]: Classification results with val_vtab-sun397: top1: 19.00	top5: 36.50	
[09/26 03:19:16 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.3015368960704584
[09/26 03:19:23 visual_prompt]: Epoch 91 / 100: avg data time: 5.86e-02, avg batch time: 0.5016, average train loss: 0.0142
[09/26 03:19:25 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1678, average loss: 4.7608
[09/26 03:19:25 visual_prompt]: Classification results with val_vtab-sun397: top1: 19.00	top5: 37.00	
[09/26 03:19:25 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.24471741852423234
[09/26 03:19:32 visual_prompt]: Epoch 92 / 100: avg data time: 5.51e-02, avg batch time: 0.4990, average train loss: 0.0140
[09/26 03:19:33 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1672, average loss: 4.7592
[09/26 03:19:33 visual_prompt]: Classification results with val_vtab-sun397: top1: 19.00	top5: 37.00	
[09/26 03:19:33 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.19369152030840553
[09/26 03:19:40 visual_prompt]: Epoch 93 / 100: avg data time: 4.90e-02, avg batch time: 0.4935, average train loss: 0.0141
[09/26 03:19:41 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1671, average loss: 4.7562
[09/26 03:19:41 visual_prompt]: Classification results with val_vtab-sun397: top1: 19.00	top5: 37.00	
[09/26 03:19:41 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.14852136862001764
[09/26 03:19:48 visual_prompt]: Epoch 94 / 100: avg data time: 5.36e-02, avg batch time: 0.4978, average train loss: 0.0141
[09/26 03:19:50 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1674, average loss: 4.7557
[09/26 03:19:50 visual_prompt]: Classification results with val_vtab-sun397: top1: 19.00	top5: 37.50	
[09/26 03:19:50 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.10926199633097156
[09/26 03:19:56 visual_prompt]: Epoch 95 / 100: avg data time: 4.66e-02, avg batch time: 0.4929, average train loss: 0.0143
[09/26 03:19:58 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1673, average loss: 4.7521
[09/26 03:19:58 visual_prompt]: Classification results with val_vtab-sun397: top1: 19.00	top5: 37.50	
[09/26 03:19:58 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.0759612349389599
[09/26 03:20:05 visual_prompt]: Epoch 96 / 100: avg data time: 6.23e-02, avg batch time: 0.5059, average train loss: 0.0143
[09/26 03:20:06 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1677, average loss: 4.7499
[09/26 03:20:06 visual_prompt]: Classification results with val_vtab-sun397: top1: 19.00	top5: 37.50	
[09/26 03:20:06 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.04865965629214819
[09/26 03:20:13 visual_prompt]: Epoch 97 / 100: avg data time: 5.82e-02, avg batch time: 0.5025, average train loss: 0.0142
[09/26 03:20:15 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1676, average loss: 4.7498
[09/26 03:20:15 visual_prompt]: Classification results with val_vtab-sun397: top1: 19.00	top5: 37.50	
[09/26 03:20:15 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.02739052315863355
[09/26 03:20:21 visual_prompt]: Epoch 98 / 100: avg data time: 4.97e-02, avg batch time: 0.4955, average train loss: 0.0140
[09/26 03:20:23 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1675, average loss: 4.7496
[09/26 03:20:23 visual_prompt]: Classification results with val_vtab-sun397: top1: 19.00	top5: 37.50	
[09/26 03:20:23 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.012179748700879012
[09/26 03:20:30 visual_prompt]: Epoch 99 / 100: avg data time: 4.44e-02, avg batch time: 0.4877, average train loss: 0.0141
[09/26 03:20:31 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1673, average loss: 4.7495
[09/26 03:20:31 visual_prompt]: Classification results with val_vtab-sun397: top1: 19.00	top5: 37.50	
[09/26 03:20:31 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0030458649045211894
[09/26 03:20:38 visual_prompt]: Epoch 100 / 100: avg data time: 5.73e-02, avg batch time: 0.5017, average train loss: 0.0141
[09/26 03:20:39 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1674, average loss: 4.7494
[09/26 03:20:39 visual_prompt]: Classification results with val_vtab-sun397: top1: 19.00	top5: 37.50	
[09/26 03:20:39 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 03:20:39 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              0
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 03:20:39 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-sun397', 'DATA.NUMBER_CLASSES', '397', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 03:20:39 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 03:20:39 visual_prompt]: Training with config:
[09/26 03:20:39 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-sun397/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr10.0_wd0.0/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 10.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-sun397', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 397, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 03:20:39 visual_prompt]: Loading training data...
[09/26 03:20:39 visual_prompt]: Constructing vtab-sun397 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split train[:800], from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/26 03:20:41 visual_prompt]: Number of images: 800
[09/26 03:20:41 visual_prompt]: Number of classes: 309 / 397
[09/26 03:20:41 visual_prompt]: Loading validation data...
[09/26 03:20:41 visual_prompt]: Constructing vtab-sun397 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split validation[:200], from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/26 03:20:41 visual_prompt]: Number of images: 200
[09/26 03:20:41 visual_prompt]: Number of classes: 136 / 397
[09/26 03:20:41 visual_prompt]: Constructing models...
[09/26 03:20:44 visual_prompt]: Total Parameters: 86564749	 Gradient Parameters: 766093
[09/26 03:20:44 visual_prompt]: tuned percent:0.885
[09/26 03:20:44 visual_prompt]: Device used for model: 0
[09/26 03:20:44 visual_prompt]: Setting up Evaluator...
[09/26 03:20:44 visual_prompt]: Setting up Trainer...
[09/26 03:20:44 visual_prompt]: 	Setting up the optimizer...
[09/26 03:20:44 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 03:20:51 visual_prompt]: Epoch 1 / 100: avg data time: 5.90e-02, avg batch time: 0.5039, average train loss: 5.9895
[09/26 03:20:52 visual_prompt]: Inference (val):avg data time: 4.18e-05, avg batch time: 0.1668, average loss: 6.0097
[09/26 03:20:52 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/26 03:20:52 visual_prompt]: Training 2 / 100 epoch, with learning rate 1.0
[09/26 03:20:59 visual_prompt]: Epoch 2 / 100: avg data time: 4.95e-02, avg batch time: 0.4929, average train loss: 5.7863
[09/26 03:21:01 visual_prompt]: Inference (val):avg data time: 4.09e-05, avg batch time: 0.1670, average loss: 5.8162
[09/26 03:21:01 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 3.00	
[09/26 03:21:01 visual_prompt]: Best epoch 2: best metric: 0.010
[09/26 03:21:01 visual_prompt]: Training 3 / 100 epoch, with learning rate 2.0
[09/26 03:21:08 visual_prompt]: Epoch 3 / 100: avg data time: 5.75e-02, avg batch time: 0.5013, average train loss: 5.6647
[09/26 03:21:09 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1674, average loss: 6.4063
[09/26 03:21:09 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 3.00	
[09/26 03:21:09 visual_prompt]: Training 4 / 100 epoch, with learning rate 3.0
[09/26 03:21:16 visual_prompt]: Epoch 4 / 100: avg data time: 5.21e-02, avg batch time: 0.4945, average train loss: 5.7561
[09/26 03:21:17 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1673, average loss: 5.9407
[09/26 03:21:17 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 5.00	
[09/26 03:21:17 visual_prompt]: Best epoch 4: best metric: 0.015
[09/26 03:21:17 visual_prompt]: Training 5 / 100 epoch, with learning rate 4.0
[09/26 03:21:24 visual_prompt]: Epoch 5 / 100: avg data time: 5.38e-02, avg batch time: 0.4967, average train loss: 5.8054
[09/26 03:21:26 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1673, average loss: 6.0390
[09/26 03:21:26 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 3.50	
[09/26 03:21:26 visual_prompt]: Training 6 / 100 epoch, with learning rate 5.0
[09/26 03:21:32 visual_prompt]: Epoch 6 / 100: avg data time: 4.26e-02, avg batch time: 0.4885, average train loss: 5.7693
[09/26 03:21:34 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1673, average loss: 5.9274
[09/26 03:21:34 visual_prompt]: Classification results with val_vtab-sun397: top1: 3.00	top5: 10.00	
[09/26 03:21:34 visual_prompt]: Best epoch 6: best metric: 0.030
[09/26 03:21:34 visual_prompt]: Training 7 / 100 epoch, with learning rate 6.0
[09/26 03:21:41 visual_prompt]: Epoch 7 / 100: avg data time: 5.89e-02, avg batch time: 0.5013, average train loss: 5.7394
[09/26 03:21:42 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1672, average loss: 6.4404
[09/26 03:21:42 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.00	top5: 7.50	
[09/26 03:21:42 visual_prompt]: Training 8 / 100 epoch, with learning rate 7.0
[09/26 03:21:49 visual_prompt]: Epoch 8 / 100: avg data time: 5.38e-02, avg batch time: 0.4971, average train loss: 5.6319
[09/26 03:21:51 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1674, average loss: 5.7042
[09/26 03:21:51 visual_prompt]: Classification results with val_vtab-sun397: top1: 9.00	top5: 17.00	
[09/26 03:21:51 visual_prompt]: Best epoch 8: best metric: 0.090
[09/26 03:21:51 visual_prompt]: Training 9 / 100 epoch, with learning rate 8.0
[09/26 03:21:57 visual_prompt]: Epoch 9 / 100: avg data time: 5.12e-02, avg batch time: 0.4946, average train loss: 5.3260
[09/26 03:21:59 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.1671, average loss: 5.5964
[09/26 03:21:59 visual_prompt]: Classification results with val_vtab-sun397: top1: 12.00	top5: 21.50	
[09/26 03:21:59 visual_prompt]: Best epoch 9: best metric: 0.120
[09/26 03:21:59 visual_prompt]: Training 10 / 100 epoch, with learning rate 9.0
[09/26 03:22:06 visual_prompt]: Epoch 10 / 100: avg data time: 5.62e-02, avg batch time: 0.5005, average train loss: 3.9764
[09/26 03:22:07 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1675, average loss: 5.3658
[09/26 03:22:07 visual_prompt]: Classification results with val_vtab-sun397: top1: 12.00	top5: 31.00	
[09/26 03:22:07 visual_prompt]: Training 11 / 100 epoch, with learning rate 10.0
[09/26 03:22:14 visual_prompt]: Epoch 11 / 100: avg data time: 5.45e-02, avg batch time: 0.4976, average train loss: 3.7633
[09/26 03:22:16 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1675, average loss: 6.0648
[09/26 03:22:16 visual_prompt]: Classification results with val_vtab-sun397: top1: 9.50	top5: 26.50	
[09/26 03:22:16 visual_prompt]: Training 12 / 100 epoch, with learning rate 9.996954135095478
[09/26 03:22:22 visual_prompt]: Epoch 12 / 100: avg data time: 4.59e-02, avg batch time: 0.4903, average train loss: 2.5652
[09/26 03:22:24 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1673, average loss: 5.6184
[09/26 03:22:24 visual_prompt]: Classification results with val_vtab-sun397: top1: 17.50	top5: 47.00	
[09/26 03:22:24 visual_prompt]: Best epoch 12: best metric: 0.175
[09/26 03:22:24 visual_prompt]: Training 13 / 100 epoch, with learning rate 9.987820251299121
[09/26 03:22:31 visual_prompt]: Epoch 13 / 100: avg data time: 5.65e-02, avg batch time: 0.5012, average train loss: 1.5296
[09/26 03:22:32 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1674, average loss: 5.5584
[09/26 03:22:32 visual_prompt]: Classification results with val_vtab-sun397: top1: 25.50	top5: 47.00	
[09/26 03:22:32 visual_prompt]: Best epoch 13: best metric: 0.255
[09/26 03:22:32 visual_prompt]: Training 14 / 100 epoch, with learning rate 9.972609476841367
[09/26 03:22:39 visual_prompt]: Epoch 14 / 100: avg data time: 5.20e-02, avg batch time: 0.4961, average train loss: 0.8692
[09/26 03:22:40 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1675, average loss: 6.2242
[09/26 03:22:40 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.50	top5: 48.00	
[09/26 03:22:40 visual_prompt]: Training 15 / 100 epoch, with learning rate 9.951340343707852
[09/26 03:22:47 visual_prompt]: Epoch 15 / 100: avg data time: 6.92e-02, avg batch time: 0.5125, average train loss: 0.4571
[09/26 03:22:49 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1675, average loss: 6.5067
[09/26 03:22:49 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.50	top5: 53.50	
[09/26 03:22:49 visual_prompt]: Best epoch 15: best metric: 0.285
[09/26 03:22:49 visual_prompt]: Training 16 / 100 epoch, with learning rate 9.924038765061042
[09/26 03:22:56 visual_prompt]: Epoch 16 / 100: avg data time: 5.66e-02, avg batch time: 0.5007, average train loss: 0.3402
[09/26 03:22:57 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1674, average loss: 7.2474
[09/26 03:22:57 visual_prompt]: Classification results with val_vtab-sun397: top1: 24.00	top5: 53.50	
[09/26 03:22:57 visual_prompt]: Training 17 / 100 epoch, with learning rate 9.890738003669028
[09/26 03:23:04 visual_prompt]: Epoch 17 / 100: avg data time: 4.64e-02, avg batch time: 0.4905, average train loss: 0.2126
[09/26 03:23:05 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1679, average loss: 7.5617
[09/26 03:23:05 visual_prompt]: Classification results with val_vtab-sun397: top1: 23.00	top5: 50.50	
[09/26 03:23:05 visual_prompt]: Training 18 / 100 epoch, with learning rate 9.851478631379981
[09/26 03:23:12 visual_prompt]: Epoch 18 / 100: avg data time: 6.21e-02, avg batch time: 0.5054, average train loss: 0.2032
[09/26 03:23:14 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1680, average loss: 6.7634
[09/26 03:23:14 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.50	top5: 50.50	
[09/26 03:23:14 visual_prompt]: Training 19 / 100 epoch, with learning rate 9.806308479691594
[09/26 03:23:21 visual_prompt]: Epoch 19 / 100: avg data time: 4.78e-02, avg batch time: 0.4927, average train loss: 0.1045
[09/26 03:23:22 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1676, average loss: 8.0512
[09/26 03:23:22 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 51.00	
[09/26 03:23:22 visual_prompt]: Training 20 / 100 epoch, with learning rate 9.755282581475768
[09/26 03:23:29 visual_prompt]: Epoch 20 / 100: avg data time: 5.74e-02, avg batch time: 0.5009, average train loss: 0.0705
[09/26 03:23:31 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1675, average loss: 7.8842
[09/26 03:23:31 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 52.50	
[09/26 03:23:31 visual_prompt]: Training 21 / 100 epoch, with learning rate 9.698463103929543
[09/26 03:23:37 visual_prompt]: Epoch 21 / 100: avg data time: 5.85e-02, avg batch time: 0.5018, average train loss: 0.1202
[09/26 03:23:39 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1675, average loss: 8.2607
[09/26 03:23:39 visual_prompt]: Classification results with val_vtab-sun397: top1: 25.50	top5: 52.50	
[09/26 03:23:39 visual_prompt]: Training 22 / 100 epoch, with learning rate 9.635919272833938
[09/26 03:23:46 visual_prompt]: Epoch 22 / 100: avg data time: 5.27e-02, avg batch time: 0.4965, average train loss: 0.0802
[09/26 03:23:47 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.1677, average loss: 7.1378
[09/26 03:23:47 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 50.00	
[09/26 03:23:47 visual_prompt]: Training 23 / 100 epoch, with learning rate 9.567727288213003
[09/26 03:23:54 visual_prompt]: Epoch 23 / 100: avg data time: 5.73e-02, avg batch time: 0.5019, average train loss: 0.0359
[09/26 03:23:56 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1673, average loss: 7.3856
[09/26 03:23:56 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.50	top5: 52.00	
[09/26 03:23:56 visual_prompt]: Training 24 / 100 epoch, with learning rate 9.493970231495835
[09/26 03:24:02 visual_prompt]: Epoch 24 / 100: avg data time: 5.46e-02, avg batch time: 0.4994, average train loss: 0.0216
[09/26 03:24:04 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1673, average loss: 7.4084
[09/26 03:24:04 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.50	top5: 55.00	
[09/26 03:24:04 visual_prompt]: Training 25 / 100 epoch, with learning rate 9.414737964294634
[09/26 03:24:11 visual_prompt]: Epoch 25 / 100: avg data time: 5.87e-02, avg batch time: 0.5017, average train loss: 0.0447
[09/26 03:24:12 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1674, average loss: 7.7638
[09/26 03:24:12 visual_prompt]: Classification results with val_vtab-sun397: top1: 29.50	top5: 53.50	
[09/26 03:24:12 visual_prompt]: Best epoch 25: best metric: 0.295
[09/26 03:24:12 visual_prompt]: Training 26 / 100 epoch, with learning rate 9.330127018922195
[09/26 03:24:19 visual_prompt]: Epoch 26 / 100: avg data time: 5.42e-02, avg batch time: 0.4975, average train loss: 0.0164
[09/26 03:24:21 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1674, average loss: 7.9003
[09/26 03:24:21 visual_prompt]: Classification results with val_vtab-sun397: top1: 26.50	top5: 53.50	
[09/26 03:24:21 visual_prompt]: Training 27 / 100 epoch, with learning rate 9.240240480782129
[09/26 03:24:27 visual_prompt]: Epoch 27 / 100: avg data time: 5.26e-02, avg batch time: 0.4975, average train loss: 0.0118
[09/26 03:24:29 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1675, average loss: 8.2565
[09/26 03:24:29 visual_prompt]: Classification results with val_vtab-sun397: top1: 29.50	top5: 51.50	
[09/26 03:24:29 visual_prompt]: Training 28 / 100 epoch, with learning rate 9.145187862775208
[09/26 03:24:36 visual_prompt]: Epoch 28 / 100: avg data time: 5.74e-02, avg batch time: 0.5016, average train loss: 0.0020
[09/26 03:24:37 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1676, average loss: 8.7044
[09/26 03:24:37 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.00	top5: 51.50	
[09/26 03:24:37 visual_prompt]: Training 29 / 100 epoch, with learning rate 9.045084971874736
[09/26 03:24:44 visual_prompt]: Epoch 29 / 100: avg data time: 5.77e-02, avg batch time: 0.5008, average train loss: 0.0007
[09/26 03:24:46 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1674, average loss: 8.8969
[09/26 03:24:46 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.50	top5: 50.50	
[09/26 03:24:46 visual_prompt]: Training 30 / 100 epoch, with learning rate 8.940053768033609
[09/26 03:24:52 visual_prompt]: Epoch 30 / 100: avg data time: 5.72e-02, avg batch time: 0.4999, average train loss: 0.0020
[09/26 03:24:54 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1674, average loss: 8.7983
[09/26 03:24:54 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.50	top5: 51.50	
[09/26 03:24:54 visual_prompt]: Training 31 / 100 epoch, with learning rate 8.83022221559489
[09/26 03:25:01 visual_prompt]: Epoch 31 / 100: avg data time: 5.61e-02, avg batch time: 0.4984, average train loss: 0.0003
[09/26 03:25:02 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1676, average loss: 8.7067
[09/26 03:25:02 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 52.00	
[09/26 03:25:02 visual_prompt]: Training 32 / 100 epoch, with learning rate 8.715724127386972
[09/26 03:25:09 visual_prompt]: Epoch 32 / 100: avg data time: 5.41e-02, avg batch time: 0.4983, average train loss: 0.0002
[09/26 03:25:11 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1675, average loss: 8.6907
[09/26 03:25:11 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.50	top5: 51.50	
[09/26 03:25:11 visual_prompt]: Training 33 / 100 epoch, with learning rate 8.596699001693256
[09/26 03:25:17 visual_prompt]: Epoch 33 / 100: avg data time: 5.73e-02, avg batch time: 0.4997, average train loss: 0.0002
[09/26 03:25:19 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1681, average loss: 8.6946
[09/26 03:25:19 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.50	top5: 51.00	
[09/26 03:25:19 visual_prompt]: Training 34 / 100 epoch, with learning rate 8.473291852294986
[09/26 03:25:26 visual_prompt]: Epoch 34 / 100: avg data time: 6.02e-02, avg batch time: 0.5048, average train loss: 0.0002
[09/26 03:25:27 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1683, average loss: 8.6946
[09/26 03:25:27 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.50	top5: 51.00	
[09/26 03:25:27 visual_prompt]: Training 35 / 100 epoch, with learning rate 8.345653031794292
[09/26 03:25:34 visual_prompt]: Epoch 35 / 100: avg data time: 6.02e-02, avg batch time: 0.5036, average train loss: 0.0001
[09/26 03:25:36 visual_prompt]: Inference (val):avg data time: 3.44e-05, avg batch time: 0.1668, average loss: 8.6982
[09/26 03:25:36 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.50	top5: 51.00	
[09/26 03:25:36 visual_prompt]: Training 36 / 100 epoch, with learning rate 8.213938048432697
[09/26 03:25:43 visual_prompt]: Epoch 36 / 100: avg data time: 4.77e-02, avg batch time: 0.4926, average train loss: 0.0002
[09/26 03:25:44 visual_prompt]: Inference (val):avg data time: 4.01e-05, avg batch time: 0.1679, average loss: 8.6946
[09/26 03:25:44 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.50	top5: 51.50	
[09/26 03:25:44 visual_prompt]: Training 37 / 100 epoch, with learning rate 8.078307376628292
[09/26 03:25:51 visual_prompt]: Epoch 37 / 100: avg data time: 5.13e-02, avg batch time: 0.4949, average train loss: 0.0006
[09/26 03:25:52 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.1675, average loss: 8.7677
[09/26 03:25:52 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.50	top5: 51.50	
[09/26 03:25:52 visual_prompt]: Training 38 / 100 epoch, with learning rate 7.938926261462366
[09/26 03:25:59 visual_prompt]: Epoch 38 / 100: avg data time: 5.04e-02, avg batch time: 0.4958, average train loss: 0.0002
[09/26 03:26:01 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1677, average loss: 8.8059
[09/26 03:26:01 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.50	top5: 51.50	
[09/26 03:26:01 visual_prompt]: Training 39 / 100 epoch, with learning rate 7.795964517353734
[09/26 03:26:07 visual_prompt]: Epoch 39 / 100: avg data time: 4.65e-02, avg batch time: 0.4919, average train loss: 0.0001
[09/26 03:26:09 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1677, average loss: 8.8075
[09/26 03:26:09 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.50	top5: 51.50	
[09/26 03:26:09 visual_prompt]: Training 40 / 100 epoch, with learning rate 7.649596321166024
[09/26 03:26:16 visual_prompt]: Epoch 40 / 100: avg data time: 5.28e-02, avg batch time: 0.4967, average train loss: 0.0001
[09/26 03:26:17 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1677, average loss: 8.8090
[09/26 03:26:17 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.50	top5: 51.50	
[09/26 03:26:17 visual_prompt]: Training 41 / 100 epoch, with learning rate 7.5
[09/26 03:26:24 visual_prompt]: Epoch 41 / 100: avg data time: 5.46e-02, avg batch time: 0.4985, average train loss: 0.0003
[09/26 03:26:26 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1679, average loss: 8.8121
[09/26 03:26:26 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.50	top5: 52.00	
[09/26 03:26:26 visual_prompt]: Training 42 / 100 epoch, with learning rate 7.347357813929454
[09/26 03:26:33 visual_prompt]: Epoch 42 / 100: avg data time: 5.97e-02, avg batch time: 0.5043, average train loss: 0.0001
[09/26 03:26:34 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1677, average loss: 8.8341
[09/26 03:26:34 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.50	top5: 52.00	
[09/26 03:26:34 visual_prompt]: Training 43 / 100 epoch, with learning rate 7.191855733945387
[09/26 03:26:41 visual_prompt]: Epoch 43 / 100: avg data time: 5.71e-02, avg batch time: 0.4996, average train loss: 0.0002
[09/26 03:26:42 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.1674, average loss: 8.8407
[09/26 03:26:42 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.50	top5: 52.00	
[09/26 03:26:42 visual_prompt]: Training 44 / 100 epoch, with learning rate 7.033683215379002
[09/26 03:26:49 visual_prompt]: Epoch 44 / 100: avg data time: 4.82e-02, avg batch time: 0.4930, average train loss: 0.0003
[09/26 03:26:51 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1675, average loss: 8.8397
[09/26 03:26:51 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.50	top5: 52.00	
[09/26 03:26:51 visual_prompt]: Training 45 / 100 epoch, with learning rate 6.873032967079561
[09/26 03:26:58 visual_prompt]: Epoch 45 / 100: avg data time: 6.22e-02, avg batch time: 0.5049, average train loss: 0.0001
[09/26 03:26:59 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1678, average loss: 8.8544
[09/26 03:26:59 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 52.00	
[09/26 03:26:59 visual_prompt]: Training 46 / 100 epoch, with learning rate 6.710100716628345
[09/26 03:27:06 visual_prompt]: Epoch 46 / 100: avg data time: 5.91e-02, avg batch time: 0.5026, average train loss: 0.0006
[09/26 03:27:08 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1677, average loss: 8.7742
[09/26 03:27:08 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.50	top5: 52.50	
[09/26 03:27:08 visual_prompt]: Training 47 / 100 epoch, with learning rate 6.545084971874737
[09/26 03:27:14 visual_prompt]: Epoch 47 / 100: avg data time: 5.65e-02, avg batch time: 0.4997, average train loss: 0.0005
[09/26 03:27:16 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1679, average loss: 8.7652
[09/26 03:27:16 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.50	top5: 52.00	
[09/26 03:27:16 visual_prompt]: Training 48 / 100 epoch, with learning rate 6.378186779084995
[09/26 03:27:23 visual_prompt]: Epoch 48 / 100: avg data time: 5.57e-02, avg batch time: 0.5007, average train loss: 0.0001
[09/26 03:27:24 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1673, average loss: 8.7740
[09/26 03:27:24 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.50	top5: 52.00	
[09/26 03:27:24 visual_prompt]: Training 49 / 100 epoch, with learning rate 6.209609477998338
[09/26 03:27:31 visual_prompt]: Epoch 49 / 100: avg data time: 5.74e-02, avg batch time: 0.5015, average train loss: 0.0001
[09/26 03:27:33 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1680, average loss: 8.7786
[09/26 03:27:33 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.50	top5: 52.00	
[09/26 03:27:33 visual_prompt]: Training 50 / 100 epoch, with learning rate 6.039558454088796
[09/26 03:27:39 visual_prompt]: Epoch 50 / 100: avg data time: 5.79e-02, avg batch time: 0.5018, average train loss: 0.0001
[09/26 03:27:41 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1674, average loss: 8.7808
[09/26 03:27:41 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.50	top5: 52.00	
[09/26 03:27:41 visual_prompt]: Training 51 / 100 epoch, with learning rate 5.868240888334652
[09/26 03:27:48 visual_prompt]: Epoch 51 / 100: avg data time: 5.92e-02, avg batch time: 0.5021, average train loss: 0.0001
[09/26 03:27:49 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1676, average loss: 8.7830
[09/26 03:27:49 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.50	top5: 52.00	
[09/26 03:27:49 visual_prompt]: Training 52 / 100 epoch, with learning rate 5.695865504800327
[09/26 03:27:56 visual_prompt]: Epoch 52 / 100: avg data time: 5.72e-02, avg batch time: 0.5010, average train loss: 0.0001
[09/26 03:27:58 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1676, average loss: 8.7842
[09/26 03:27:58 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.50	top5: 52.00	
[09/26 03:27:58 visual_prompt]: Training 53 / 100 epoch, with learning rate 5.522642316338268
[09/26 03:28:05 visual_prompt]: Epoch 53 / 100: avg data time: 5.42e-02, avg batch time: 0.4984, average train loss: 0.0001
[09/26 03:28:06 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1677, average loss: 8.7854
[09/26 03:28:06 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.50	top5: 52.00	
[09/26 03:28:06 visual_prompt]: Training 54 / 100 epoch, with learning rate 5.3487823687206255
[09/26 03:28:13 visual_prompt]: Epoch 54 / 100: avg data time: 4.52e-02, avg batch time: 0.4899, average train loss: 0.0001
[09/26 03:28:14 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1678, average loss: 8.7870
[09/26 03:28:14 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.50	top5: 52.00	
[09/26 03:28:14 visual_prompt]: Training 55 / 100 epoch, with learning rate 5.174497483512505
[09/26 03:28:21 visual_prompt]: Epoch 55 / 100: avg data time: 5.46e-02, avg batch time: 0.4984, average train loss: 0.0001
[09/26 03:28:23 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1677, average loss: 8.7875
[09/26 03:28:23 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.50	top5: 52.00	
[09/26 03:28:23 visual_prompt]: Training 56 / 100 epoch, with learning rate 5.0
[09/26 03:28:29 visual_prompt]: Epoch 56 / 100: avg data time: 6.11e-02, avg batch time: 0.5053, average train loss: 0.0001
[09/26 03:28:31 visual_prompt]: Inference (val):avg data time: 3.43e-05, avg batch time: 0.1676, average loss: 8.7887
[09/26 03:28:31 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.50	top5: 52.00	
[09/26 03:28:31 visual_prompt]: Training 57 / 100 epoch, with learning rate 4.8255025164874965
[09/26 03:28:38 visual_prompt]: Epoch 57 / 100: avg data time: 5.14e-02, avg batch time: 0.4961, average train loss: 0.0001
[09/26 03:28:39 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1676, average loss: 8.7907
[09/26 03:28:39 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.50	top5: 52.00	
[09/26 03:28:39 visual_prompt]: Training 58 / 100 epoch, with learning rate 4.651217631279374
[09/26 03:28:46 visual_prompt]: Epoch 58 / 100: avg data time: 5.65e-02, avg batch time: 0.5004, average train loss: 0.0001
[09/26 03:28:48 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1678, average loss: 8.7906
[09/26 03:28:48 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.50	top5: 52.00	
[09/26 03:28:48 visual_prompt]: Training 59 / 100 epoch, with learning rate 4.477357683661733
[09/26 03:28:55 visual_prompt]: Epoch 59 / 100: avg data time: 5.93e-02, avg batch time: 0.5042, average train loss: 0.0001
[09/26 03:28:56 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1675, average loss: 8.7896
[09/26 03:28:56 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.50	top5: 52.00	
[09/26 03:28:56 visual_prompt]: Training 60 / 100 epoch, with learning rate 4.3041344951996745
[09/26 03:29:03 visual_prompt]: Epoch 60 / 100: avg data time: 5.76e-02, avg batch time: 0.5017, average train loss: 0.0001
[09/26 03:29:04 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1680, average loss: 8.7900
[09/26 03:29:04 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.50	top5: 52.00	
[09/26 03:29:04 visual_prompt]: Training 61 / 100 epoch, with learning rate 4.131759111665349
[09/26 03:29:11 visual_prompt]: Epoch 61 / 100: avg data time: 4.45e-02, avg batch time: 0.4909, average train loss: 0.0001
[09/26 03:29:13 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1677, average loss: 8.7905
[09/26 03:29:13 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.50	top5: 52.00	
[09/26 03:29:13 visual_prompt]: Training 62 / 100 epoch, with learning rate 3.960441545911204
[09/26 03:29:19 visual_prompt]: Epoch 62 / 100: avg data time: 5.32e-02, avg batch time: 0.4972, average train loss: 0.0001
[09/26 03:29:21 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1678, average loss: 8.7911
[09/26 03:29:21 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.50	top5: 52.00	
[09/26 03:29:21 visual_prompt]: Training 63 / 100 epoch, with learning rate 3.790390522001662
[09/26 03:29:28 visual_prompt]: Epoch 63 / 100: avg data time: 6.15e-02, avg batch time: 0.5057, average train loss: 0.0001
[09/26 03:29:29 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1675, average loss: 8.7912
[09/26 03:29:29 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.50	top5: 52.00	
[09/26 03:29:29 visual_prompt]: Training 64 / 100 epoch, with learning rate 3.6218132209150045
[09/26 03:29:36 visual_prompt]: Epoch 64 / 100: avg data time: 5.79e-02, avg batch time: 0.5025, average train loss: 0.0001
[09/26 03:29:38 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1673, average loss: 8.7919
[09/26 03:29:38 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.50	top5: 52.00	
[09/26 03:29:38 visual_prompt]: Training 65 / 100 epoch, with learning rate 3.454915028125263
[09/26 03:29:45 visual_prompt]: Epoch 65 / 100: avg data time: 6.14e-02, avg batch time: 0.5063, average train loss: 0.0001
[09/26 03:29:46 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1679, average loss: 8.7913
[09/26 03:29:46 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.50	top5: 52.00	
[09/26 03:29:46 visual_prompt]: Training 66 / 100 epoch, with learning rate 3.289899283371657
[09/26 03:29:53 visual_prompt]: Epoch 66 / 100: avg data time: 6.12e-02, avg batch time: 0.5045, average train loss: 0.0001
[09/26 03:29:55 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1675, average loss: 8.7908
[09/26 03:29:55 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.50	top5: 52.00	
[09/26 03:29:55 visual_prompt]: Training 67 / 100 epoch, with learning rate 3.1269670329204398
[09/26 03:30:02 visual_prompt]: Epoch 67 / 100: avg data time: 5.53e-02, avg batch time: 0.4999, average train loss: 0.0000
[09/26 03:30:03 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1679, average loss: 8.7903
[09/26 03:30:03 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.50	top5: 52.00	
[09/26 03:30:03 visual_prompt]: Training 68 / 100 epoch, with learning rate 2.9663167846209997
[09/26 03:30:10 visual_prompt]: Epoch 68 / 100: avg data time: 5.43e-02, avg batch time: 0.4979, average train loss: 0.0000
[09/26 03:30:11 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1675, average loss: 8.7904
[09/26 03:30:11 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.50	top5: 52.00	
[09/26 03:30:11 visual_prompt]: Training 69 / 100 epoch, with learning rate 2.8081442660546125
[09/26 03:30:18 visual_prompt]: Epoch 69 / 100: avg data time: 5.24e-02, avg batch time: 0.4980, average train loss: 0.0001
[09/26 03:30:20 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1677, average loss: 8.7908
[09/26 03:30:20 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 52.00	
[09/26 03:30:20 visual_prompt]: Training 70 / 100 epoch, with learning rate 2.6526421860705476
[09/26 03:30:27 visual_prompt]: Epoch 70 / 100: avg data time: 5.72e-02, avg batch time: 0.5020, average train loss: 0.0001
[09/26 03:30:28 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1679, average loss: 8.7904
[09/26 03:30:28 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 52.00	
[09/26 03:30:28 visual_prompt]: Training 71 / 100 epoch, with learning rate 2.500000000000001
[09/26 03:30:35 visual_prompt]: Epoch 71 / 100: avg data time: 5.45e-02, avg batch time: 0.4987, average train loss: 0.0000
[09/26 03:30:36 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1679, average loss: 8.7899
[09/26 03:30:36 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 52.00	
[09/26 03:30:36 visual_prompt]: Training 72 / 100 epoch, with learning rate 2.350403678833976
[09/26 03:30:43 visual_prompt]: Epoch 72 / 100: avg data time: 6.00e-02, avg batch time: 0.5038, average train loss: 0.0001
[09/26 03:30:45 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1684, average loss: 8.7906
[09/26 03:30:45 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 52.00	
[09/26 03:30:45 visual_prompt]: Training 73 / 100 epoch, with learning rate 2.2040354826462667
[09/26 03:30:52 visual_prompt]: Epoch 73 / 100: avg data time: 5.66e-02, avg batch time: 0.5006, average train loss: 0.0001
[09/26 03:30:53 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1672, average loss: 8.7921
[09/26 03:30:53 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 52.00	
[09/26 03:30:53 visual_prompt]: Training 74 / 100 epoch, with learning rate 2.061073738537635
[09/26 03:31:00 visual_prompt]: Epoch 74 / 100: avg data time: 4.94e-02, avg batch time: 0.4937, average train loss: 0.0001
[09/26 03:31:01 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1678, average loss: 8.7933
[09/26 03:31:01 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 52.00	
[09/26 03:31:01 visual_prompt]: Training 75 / 100 epoch, with learning rate 1.9216926233717087
[09/26 03:31:08 visual_prompt]: Epoch 75 / 100: avg data time: 5.61e-02, avg batch time: 0.4998, average train loss: 0.0001
[09/26 03:31:10 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1676, average loss: 8.7937
[09/26 03:31:10 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 52.00	
[09/26 03:31:10 visual_prompt]: Training 76 / 100 epoch, with learning rate 1.7860619515673033
[09/26 03:31:16 visual_prompt]: Epoch 76 / 100: avg data time: 5.85e-02, avg batch time: 0.5024, average train loss: 0.0001
[09/26 03:31:18 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1676, average loss: 8.7950
[09/26 03:31:18 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 52.00	
[09/26 03:31:18 visual_prompt]: Training 77 / 100 epoch, with learning rate 1.6543469682057106
[09/26 03:31:25 visual_prompt]: Epoch 77 / 100: avg data time: 6.05e-02, avg batch time: 0.5042, average train loss: 0.0001
[09/26 03:31:26 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1675, average loss: 8.7953
[09/26 03:31:26 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 52.00	
[09/26 03:31:26 visual_prompt]: Training 78 / 100 epoch, with learning rate 1.5267081477050133
[09/26 03:31:33 visual_prompt]: Epoch 78 / 100: avg data time: 4.28e-02, avg batch time: 0.4877, average train loss: 0.0001
[09/26 03:31:35 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1679, average loss: 8.7958
[09/26 03:31:35 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 52.00	
[09/26 03:31:35 visual_prompt]: Training 79 / 100 epoch, with learning rate 1.403300998306745
[09/26 03:31:41 visual_prompt]: Epoch 79 / 100: avg data time: 5.66e-02, avg batch time: 0.5016, average train loss: 0.0001
[09/26 03:31:43 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1677, average loss: 8.7963
[09/26 03:31:43 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 52.00	
[09/26 03:31:43 visual_prompt]: Training 80 / 100 epoch, with learning rate 1.2842758726130281
[09/26 03:31:50 visual_prompt]: Epoch 80 / 100: avg data time: 6.21e-02, avg batch time: 0.5066, average train loss: 0.0000
[09/26 03:31:51 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1675, average loss: 8.7963
[09/26 03:31:51 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 52.00	
[09/26 03:31:51 visual_prompt]: Training 81 / 100 epoch, with learning rate 1.1697777844051105
[09/26 03:31:58 visual_prompt]: Epoch 81 / 100: avg data time: 5.31e-02, avg batch time: 0.4985, average train loss: 0.0007
[09/26 03:32:00 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1675, average loss: 8.7911
[09/26 03:32:00 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 52.00	
[09/26 03:32:00 visual_prompt]: Training 82 / 100 epoch, with learning rate 1.0599462319663906
[09/26 03:32:06 visual_prompt]: Epoch 82 / 100: avg data time: 6.54e-02, avg batch time: 0.5093, average train loss: 0.0001
[09/26 03:32:08 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1675, average loss: 8.7893
[09/26 03:32:08 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 52.00	
[09/26 03:32:08 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.9549150281252633
[09/26 03:32:15 visual_prompt]: Epoch 83 / 100: avg data time: 4.88e-02, avg batch time: 0.4946, average train loss: 0.0001
[09/26 03:32:16 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1677, average loss: 8.7890
[09/26 03:32:16 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 52.00	
[09/26 03:32:16 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.8548121372247919
[09/26 03:32:23 visual_prompt]: Epoch 84 / 100: avg data time: 5.29e-02, avg batch time: 0.4977, average train loss: 0.0000
[09/26 03:32:25 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1675, average loss: 8.7890
[09/26 03:32:25 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 52.00	
[09/26 03:32:25 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.7597595192178702
[09/26 03:32:31 visual_prompt]: Epoch 85 / 100: avg data time: 4.83e-02, avg batch time: 0.4941, average train loss: 0.0001
[09/26 03:32:33 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1676, average loss: 8.7890
[09/26 03:32:33 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 52.00	
[09/26 03:32:33 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.6698729810778065
[09/26 03:32:40 visual_prompt]: Epoch 86 / 100: avg data time: 6.50e-02, avg batch time: 0.5085, average train loss: 0.0001
[09/26 03:32:41 visual_prompt]: Inference (val):avg data time: 2.01e-05, avg batch time: 0.1675, average loss: 8.7890
[09/26 03:32:41 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 52.00	
[09/26 03:32:41 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.5852620357053651
[09/26 03:32:48 visual_prompt]: Epoch 87 / 100: avg data time: 4.47e-02, avg batch time: 0.4910, average train loss: 0.0000
[09/26 03:32:49 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1677, average loss: 8.7890
[09/26 03:32:49 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 52.00	
[09/26 03:32:49 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.5060297685041659
[09/26 03:32:56 visual_prompt]: Epoch 88 / 100: avg data time: 6.09e-02, avg batch time: 0.5059, average train loss: 0.0001
[09/26 03:32:58 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1676, average loss: 8.7891
[09/26 03:32:58 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 52.00	
[09/26 03:32:58 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.4322727117869951
[09/26 03:33:05 visual_prompt]: Epoch 89 / 100: avg data time: 6.03e-02, avg batch time: 0.5055, average train loss: 0.0003
[09/26 03:33:06 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1677, average loss: 8.7890
[09/26 03:33:06 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 52.00	
[09/26 03:33:06 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.36408072716606343
[09/26 03:33:13 visual_prompt]: Epoch 90 / 100: avg data time: 5.40e-02, avg batch time: 0.5002, average train loss: 0.0001
[09/26 03:33:15 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1675, average loss: 8.7888
[09/26 03:33:15 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 52.00	
[09/26 03:33:15 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.3015368960704584
[09/26 03:33:21 visual_prompt]: Epoch 91 / 100: avg data time: 4.53e-02, avg batch time: 0.4909, average train loss: 0.0000
[09/26 03:33:23 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1676, average loss: 8.7888
[09/26 03:33:23 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 52.00	
[09/26 03:33:23 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.24471741852423234
[09/26 03:33:30 visual_prompt]: Epoch 92 / 100: avg data time: 6.03e-02, avg batch time: 0.5049, average train loss: 0.0000
[09/26 03:33:31 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1676, average loss: 8.7888
[09/26 03:33:31 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 52.00	
[09/26 03:33:31 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.19369152030840553
[09/26 03:33:38 visual_prompt]: Epoch 93 / 100: avg data time: 5.17e-02, avg batch time: 0.4960, average train loss: 0.0004
[09/26 03:33:40 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1680, average loss: 8.7905
[09/26 03:33:40 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 52.00	
[09/26 03:33:40 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.14852136862001764
[09/26 03:33:46 visual_prompt]: Epoch 94 / 100: avg data time: 5.85e-02, avg batch time: 0.5026, average train loss: 0.0000
[09/26 03:33:48 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1677, average loss: 8.7911
[09/26 03:33:48 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 52.00	
[09/26 03:33:48 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.10926199633097156
[09/26 03:33:55 visual_prompt]: Epoch 95 / 100: avg data time: 5.31e-02, avg batch time: 0.4983, average train loss: 0.0000
[09/26 03:33:56 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1675, average loss: 8.7912
[09/26 03:33:56 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 52.00	
[09/26 03:33:56 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.0759612349389599
[09/26 03:34:03 visual_prompt]: Epoch 96 / 100: avg data time: 4.43e-02, avg batch time: 0.4888, average train loss: 0.0002
[09/26 03:34:05 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1677, average loss: 8.7911
[09/26 03:34:05 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 52.00	
[09/26 03:34:05 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.04865965629214819
[09/26 03:34:11 visual_prompt]: Epoch 97 / 100: avg data time: 6.31e-02, avg batch time: 0.5077, average train loss: 0.0000
[09/26 03:34:13 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1674, average loss: 8.7911
[09/26 03:34:13 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 52.00	
[09/26 03:34:13 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.02739052315863355
[09/26 03:34:20 visual_prompt]: Epoch 98 / 100: avg data time: 6.19e-02, avg batch time: 0.5064, average train loss: 0.0001
[09/26 03:34:21 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.1678, average loss: 8.7911
[09/26 03:34:21 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 52.00	
[09/26 03:34:21 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.012179748700879012
[09/26 03:34:28 visual_prompt]: Epoch 99 / 100: avg data time: 5.72e-02, avg batch time: 0.5018, average train loss: 0.0001
[09/26 03:34:30 visual_prompt]: Inference (val):avg data time: 2.11e-05, avg batch time: 0.1675, average loss: 8.7911
[09/26 03:34:30 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 52.00	
[09/26 03:34:30 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0030458649045211894
[09/26 03:34:37 visual_prompt]: Epoch 100 / 100: avg data time: 5.74e-02, avg batch time: 0.5013, average train loss: 0.0001
[09/26 03:34:38 visual_prompt]: Inference (val):avg data time: 2.01e-05, avg batch time: 0.1679, average loss: 8.7911
[09/26 03:34:38 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 52.00	
[09/26 03:34:38 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 03:34:38 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              0
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 03:34:38 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-sun397', 'DATA.NUMBER_CLASSES', '397', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 03:34:38 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 03:34:38 visual_prompt]: Training with config:
[09/26 03:34:38 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-sun397/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr5.0_wd0.01/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 5.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-sun397', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 397, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 03:34:38 visual_prompt]: Loading training data...
[09/26 03:34:38 visual_prompt]: Constructing vtab-sun397 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split train[:800], from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/26 03:34:40 visual_prompt]: Number of images: 800
[09/26 03:34:40 visual_prompt]: Number of classes: 309 / 397
[09/26 03:34:40 visual_prompt]: Loading validation data...
[09/26 03:34:40 visual_prompt]: Constructing vtab-sun397 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split validation[:200], from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/26 03:34:40 visual_prompt]: Number of images: 200
[09/26 03:34:40 visual_prompt]: Number of classes: 136 / 397
[09/26 03:34:40 visual_prompt]: Constructing models...
[09/26 03:34:42 visual_prompt]: Total Parameters: 86564749	 Gradient Parameters: 766093
[09/26 03:34:42 visual_prompt]: tuned percent:0.885
[09/26 03:34:42 visual_prompt]: Device used for model: 0
[09/26 03:34:42 visual_prompt]: Setting up Evaluator...
[09/26 03:34:42 visual_prompt]: Setting up Trainer...
[09/26 03:34:42 visual_prompt]: 	Setting up the optimizer...
[09/26 03:34:42 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 03:34:49 visual_prompt]: Epoch 1 / 100: avg data time: 6.31e-02, avg batch time: 0.5059, average train loss: 5.9893
[09/26 03:34:51 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1681, average loss: 6.0097
[09/26 03:34:51 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/26 03:34:51 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.5
[09/26 03:34:58 visual_prompt]: Epoch 2 / 100: avg data time: 5.73e-02, avg batch time: 0.4993, average train loss: 5.7766
[09/26 03:34:59 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1673, average loss: 5.8103
[09/26 03:34:59 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.00	
[09/26 03:34:59 visual_prompt]: Best epoch 2: best metric: 0.010
[09/26 03:34:59 visual_prompt]: Training 3 / 100 epoch, with learning rate 1.0
[09/26 03:35:06 visual_prompt]: Epoch 3 / 100: avg data time: 5.91e-02, avg batch time: 0.5028, average train loss: 5.6285
[09/26 03:35:08 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1673, average loss: 5.8089
[09/26 03:35:08 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 03:35:08 visual_prompt]: Training 4 / 100 epoch, with learning rate 1.5
[09/26 03:35:15 visual_prompt]: Epoch 4 / 100: avg data time: 6.38e-02, avg batch time: 0.5071, average train loss: 5.6790
[09/26 03:35:16 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1675, average loss: 5.7943
[09/26 03:35:16 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 03:35:16 visual_prompt]: Training 5 / 100 epoch, with learning rate 2.0
[09/26 03:35:23 visual_prompt]: Epoch 5 / 100: avg data time: 5.54e-02, avg batch time: 0.4982, average train loss: 5.7295
[09/26 03:35:25 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1676, average loss: 5.9010
[09/26 03:35:25 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 3.50	
[09/26 03:35:25 visual_prompt]: Training 6 / 100 epoch, with learning rate 2.5
[09/26 03:35:31 visual_prompt]: Epoch 6 / 100: avg data time: 6.07e-02, avg batch time: 0.5042, average train loss: 6.1645
[09/26 03:35:33 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1675, average loss: 6.2023
[09/26 03:35:33 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 3.00	
[09/26 03:35:33 visual_prompt]: Training 7 / 100 epoch, with learning rate 3.0
[09/26 03:35:40 visual_prompt]: Epoch 7 / 100: avg data time: 5.53e-02, avg batch time: 0.4983, average train loss: 6.0989
[09/26 03:35:41 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1675, average loss: 6.0161
[09/26 03:35:41 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 4.50	
[09/26 03:35:41 visual_prompt]: Best epoch 7: best metric: 0.015
[09/26 03:35:41 visual_prompt]: Training 8 / 100 epoch, with learning rate 3.5
[09/26 03:35:48 visual_prompt]: Epoch 8 / 100: avg data time: 5.15e-02, avg batch time: 0.4951, average train loss: 5.9894
[09/26 03:35:50 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1673, average loss: 6.0295
[09/26 03:35:50 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.50	
[09/26 03:35:50 visual_prompt]: Training 9 / 100 epoch, with learning rate 4.0
[09/26 03:35:56 visual_prompt]: Epoch 9 / 100: avg data time: 6.34e-02, avg batch time: 0.5062, average train loss: 6.0127
[09/26 03:35:58 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1672, average loss: 5.9610
[09/26 03:35:58 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 2.00	
[09/26 03:35:58 visual_prompt]: Training 10 / 100 epoch, with learning rate 4.5
[09/26 03:36:05 visual_prompt]: Epoch 10 / 100: avg data time: 5.74e-02, avg batch time: 0.4997, average train loss: 5.8702
[09/26 03:36:06 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1672, average loss: 6.0282
[09/26 03:36:06 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.00	
[09/26 03:36:06 visual_prompt]: Training 11 / 100 epoch, with learning rate 5.0
[09/26 03:36:13 visual_prompt]: Epoch 11 / 100: avg data time: 4.67e-02, avg batch time: 0.4907, average train loss: 5.7889
[09/26 03:36:15 visual_prompt]: Inference (val):avg data time: 2.08e-05, avg batch time: 0.1670, average loss: 6.0306
[09/26 03:36:15 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 2.00	
[09/26 03:36:15 visual_prompt]: Training 12 / 100 epoch, with learning rate 4.998477067547739
[09/26 03:36:21 visual_prompt]: Epoch 12 / 100: avg data time: 4.79e-02, avg batch time: 0.4932, average train loss: 5.9448
[09/26 03:36:23 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1674, average loss: 6.1935
[09/26 03:36:23 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 2.50	
[09/26 03:36:23 visual_prompt]: Training 13 / 100 epoch, with learning rate 4.993910125649561
[09/26 03:36:30 visual_prompt]: Epoch 13 / 100: avg data time: 4.57e-02, avg batch time: 0.4896, average train loss: 5.9993
[09/26 03:36:31 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1673, average loss: 16.3670
[09/26 03:36:31 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.00	
[09/26 03:36:31 visual_prompt]: Training 14 / 100 epoch, with learning rate 4.986304738420683
[09/26 03:36:38 visual_prompt]: Epoch 14 / 100: avg data time: 4.88e-02, avg batch time: 0.4929, average train loss: 7.0534
[09/26 03:36:39 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1672, average loss: 6.6143
[09/26 03:36:39 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 03:36:39 visual_prompt]: Training 15 / 100 epoch, with learning rate 4.975670171853926
[09/26 03:36:46 visual_prompt]: Epoch 15 / 100: avg data time: 4.92e-02, avg batch time: 0.4928, average train loss: 6.8737
[09/26 03:36:48 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1670, average loss: 7.0787
[09/26 03:36:48 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 4.00	
[09/26 03:36:48 visual_prompt]: Training 16 / 100 epoch, with learning rate 4.962019382530521
[09/26 03:36:55 visual_prompt]: Epoch 16 / 100: avg data time: 5.32e-02, avg batch time: 0.4969, average train loss: 6.9086
[09/26 03:36:56 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1676, average loss: 6.5070
[09/26 03:36:56 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 2.50	
[09/26 03:36:56 visual_prompt]: Training 17 / 100 epoch, with learning rate 4.945369001834514
[09/26 03:37:03 visual_prompt]: Epoch 17 / 100: avg data time: 6.28e-02, avg batch time: 0.5052, average train loss: 6.5984
[09/26 03:37:04 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1667, average loss: 6.6042
[09/26 03:37:04 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 3.00	
[09/26 03:37:04 visual_prompt]: Training 18 / 100 epoch, with learning rate 4.925739315689991
[09/26 03:37:11 visual_prompt]: Epoch 18 / 100: avg data time: 5.34e-02, avg batch time: 0.4954, average train loss: 6.4250
[09/26 03:37:13 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1671, average loss: 6.3419
[09/26 03:37:13 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 5.50	
[09/26 03:37:13 visual_prompt]: Training 19 / 100 epoch, with learning rate 4.903154239845797
[09/26 03:37:20 visual_prompt]: Epoch 19 / 100: avg data time: 5.36e-02, avg batch time: 0.4962, average train loss: 6.0561
[09/26 03:37:21 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1674, average loss: 6.2778
[09/26 03:37:21 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.50	
[09/26 03:37:21 visual_prompt]: Training 20 / 100 epoch, with learning rate 4.877641290737884
[09/26 03:37:28 visual_prompt]: Epoch 20 / 100: avg data time: 5.71e-02, avg batch time: 0.5014, average train loss: 5.9870
[09/26 03:37:29 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1670, average loss: 6.2692
[09/26 03:37:29 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.00	
[09/26 03:37:29 visual_prompt]: Training 21 / 100 epoch, with learning rate 4.849231551964771
[09/26 03:37:36 visual_prompt]: Epoch 21 / 100: avg data time: 6.17e-02, avg batch time: 0.5045, average train loss: 6.0553
[09/26 03:37:38 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1673, average loss: 6.0098
[09/26 03:37:38 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 2.50	
[09/26 03:37:38 visual_prompt]: Training 22 / 100 epoch, with learning rate 4.817959636416969
[09/26 03:37:45 visual_prompt]: Epoch 22 / 100: avg data time: 4.75e-02, avg batch time: 0.4924, average train loss: 5.8525
[09/26 03:37:46 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1673, average loss: 7.1295
[09/26 03:37:46 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 2.50	
[09/26 03:37:46 visual_prompt]: Training 23 / 100 epoch, with learning rate 4.783863644106502
[09/26 03:37:53 visual_prompt]: Epoch 23 / 100: avg data time: 5.58e-02, avg batch time: 0.4996, average train loss: 6.9705
[09/26 03:37:55 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1670, average loss: 6.5476
[09/26 03:37:55 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 5.00	
[09/26 03:37:55 visual_prompt]: Training 24 / 100 epoch, with learning rate 4.7469851157479175
[09/26 03:38:01 visual_prompt]: Epoch 24 / 100: avg data time: 6.05e-02, avg batch time: 0.5041, average train loss: 6.6979
[09/26 03:38:03 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1677, average loss: 6.4538
[09/26 03:38:03 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 03:38:03 visual_prompt]: Training 25 / 100 epoch, with learning rate 4.707368982147317
[09/26 03:38:10 visual_prompt]: Epoch 25 / 100: avg data time: 6.34e-02, avg batch time: 0.5071, average train loss: 6.5583
[09/26 03:38:11 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1672, average loss: 6.5534
[09/26 03:38:11 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 2.00	
[09/26 03:38:11 visual_prompt]: Training 26 / 100 epoch, with learning rate 4.665063509461097
[09/26 03:38:18 visual_prompt]: Epoch 26 / 100: avg data time: 5.91e-02, avg batch time: 0.5041, average train loss: 6.4137
[09/26 03:38:20 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1677, average loss: 6.4466
[09/26 03:38:20 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 4.00	
[09/26 03:38:20 visual_prompt]: Training 27 / 100 epoch, with learning rate 4.620120240391064
[09/26 03:38:26 visual_prompt]: Epoch 27 / 100: avg data time: 4.66e-02, avg batch time: 0.4916, average train loss: 6.2454
[09/26 03:38:28 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1674, average loss: 6.2329
[09/26 03:38:28 visual_prompt]: Classification results with val_vtab-sun397: top1: 3.00	top5: 6.00	
[09/26 03:38:28 visual_prompt]: Best epoch 27: best metric: 0.030
[09/26 03:38:28 visual_prompt]: Training 28 / 100 epoch, with learning rate 4.572593931387604
[09/26 03:38:35 visual_prompt]: Epoch 28 / 100: avg data time: 5.41e-02, avg batch time: 0.4978, average train loss: 5.9030
[09/26 03:38:36 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1677, average loss: 6.2093
[09/26 03:38:36 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 2.50	
[09/26 03:38:36 visual_prompt]: Training 29 / 100 epoch, with learning rate 4.522542485937368
[09/26 03:38:43 visual_prompt]: Epoch 29 / 100: avg data time: 5.82e-02, avg batch time: 0.5009, average train loss: 5.8459
[09/26 03:38:45 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1673, average loss: 6.0725
[09/26 03:38:45 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.50	
[09/26 03:38:45 visual_prompt]: Training 30 / 100 epoch, with learning rate 4.4700268840168045
[09/26 03:38:52 visual_prompt]: Epoch 30 / 100: avg data time: 6.15e-02, avg batch time: 0.5049, average train loss: 5.8262
[09/26 03:38:53 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1670, average loss: 6.2403
[09/26 03:38:53 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 2.00	
[09/26 03:38:53 visual_prompt]: Training 31 / 100 epoch, with learning rate 4.415111107797445
[09/26 03:39:00 visual_prompt]: Epoch 31 / 100: avg data time: 5.59e-02, avg batch time: 0.4984, average train loss: 5.7169
[09/26 03:39:01 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1674, average loss: 6.1033
[09/26 03:39:01 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.50	
[09/26 03:39:01 visual_prompt]: Training 32 / 100 epoch, with learning rate 4.357862063693486
[09/26 03:39:08 visual_prompt]: Epoch 32 / 100: avg data time: 5.80e-02, avg batch time: 0.5005, average train loss: 5.7811
[09/26 03:39:10 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1675, average loss: 6.5225
[09/26 03:39:10 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/26 03:39:10 visual_prompt]: Training 33 / 100 epoch, with learning rate 4.298349500846628
[09/26 03:39:17 visual_prompt]: Epoch 33 / 100: avg data time: 5.76e-02, avg batch time: 0.4999, average train loss: 5.7481
[09/26 03:39:18 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1672, average loss: 6.0533
[09/26 03:39:18 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 4.50	
[09/26 03:39:18 visual_prompt]: Training 34 / 100 epoch, with learning rate 4.236645926147493
[09/26 03:39:25 visual_prompt]: Epoch 34 / 100: avg data time: 5.28e-02, avg batch time: 0.4974, average train loss: 5.8577
[09/26 03:39:26 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1673, average loss: 6.1228
[09/26 03:39:26 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.00	
[09/26 03:39:26 visual_prompt]: Training 35 / 100 epoch, with learning rate 4.172826515897146
[09/26 03:39:33 visual_prompt]: Epoch 35 / 100: avg data time: 5.38e-02, avg batch time: 0.4978, average train loss: 6.9191
[09/26 03:39:35 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1674, average loss: 6.6485
[09/26 03:39:35 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 4.00	
[09/26 03:39:35 visual_prompt]: Training 36 / 100 epoch, with learning rate 4.106969024216348
[09/26 03:39:42 visual_prompt]: Epoch 36 / 100: avg data time: 5.94e-02, avg batch time: 0.5026, average train loss: 6.3184
[09/26 03:39:43 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1675, average loss: 6.7449
[09/26 03:39:43 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 6.00	
[09/26 03:39:43 visual_prompt]: Training 37 / 100 epoch, with learning rate 4.039153688314146
[09/26 03:39:50 visual_prompt]: Epoch 37 / 100: avg data time: 5.45e-02, avg batch time: 0.4977, average train loss: 6.5707
[09/26 03:39:52 visual_prompt]: Inference (val):avg data time: 4.45e-05, avg batch time: 0.1672, average loss: 6.7660
[09/26 03:39:52 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 1.50	
[09/26 03:39:52 visual_prompt]: Training 38 / 100 epoch, with learning rate 3.969463130731183
[09/26 03:39:58 visual_prompt]: Epoch 38 / 100: avg data time: 5.39e-02, avg batch time: 0.4959, average train loss: 8.4416
[09/26 03:40:00 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1674, average loss: 7.0318
[09/26 03:40:00 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 2.50	
[09/26 03:40:00 visual_prompt]: Training 39 / 100 epoch, with learning rate 3.897982258676867
[09/26 03:40:07 visual_prompt]: Epoch 39 / 100: avg data time: 5.67e-02, avg batch time: 0.4998, average train loss: 7.4009
[09/26 03:40:08 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1675, average loss: 7.2589
[09/26 03:40:08 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 2.50	
[09/26 03:40:08 visual_prompt]: Training 40 / 100 epoch, with learning rate 3.824798160583012
[09/26 03:40:15 visual_prompt]: Epoch 40 / 100: avg data time: 5.50e-02, avg batch time: 0.4987, average train loss: 7.4476
[09/26 03:40:17 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1670, average loss: 6.9768
[09/26 03:40:17 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 3.00	
[09/26 03:40:17 visual_prompt]: Training 41 / 100 epoch, with learning rate 3.75
[09/26 03:40:23 visual_prompt]: Epoch 41 / 100: avg data time: 6.24e-02, avg batch time: 0.5045, average train loss: 6.9930
[09/26 03:40:25 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1670, average loss: 6.6422
[09/26 03:40:25 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.00	
[09/26 03:40:25 visual_prompt]: Training 42 / 100 epoch, with learning rate 3.673678906964727
[09/26 03:40:32 visual_prompt]: Epoch 42 / 100: avg data time: 5.79e-02, avg batch time: 0.5005, average train loss: 6.6328
[09/26 03:40:33 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1675, average loss: 6.5040
[09/26 03:40:33 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 5.00	
[09/26 03:40:33 visual_prompt]: Training 43 / 100 epoch, with learning rate 3.5959278669726933
[09/26 03:40:40 visual_prompt]: Epoch 43 / 100: avg data time: 6.65e-02, avg batch time: 0.5107, average train loss: 6.7309
[09/26 03:40:42 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1673, average loss: 6.5084
[09/26 03:40:42 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 5.00	
[09/26 03:40:42 visual_prompt]: Training 44 / 100 epoch, with learning rate 3.516841607689501
[09/26 03:40:49 visual_prompt]: Epoch 44 / 100: avg data time: 5.98e-02, avg batch time: 0.5031, average train loss: 6.6087
[09/26 03:40:50 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1675, average loss: 6.6466
[09/26 03:40:50 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.00	
[09/26 03:40:50 visual_prompt]: Training 45 / 100 epoch, with learning rate 3.4365164835397803
[09/26 03:40:57 visual_prompt]: Epoch 45 / 100: avg data time: 6.49e-02, avg batch time: 0.5083, average train loss: 6.3666
[09/26 03:40:59 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1675, average loss: 6.4028
[09/26 03:40:59 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 4.00	
[09/26 03:40:59 visual_prompt]: Training 46 / 100 epoch, with learning rate 3.3550503583141724
[09/26 03:41:06 visual_prompt]: Epoch 46 / 100: avg data time: 5.29e-02, avg batch time: 0.4961, average train loss: 6.2194
[09/26 03:41:07 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1679, average loss: 6.2000
[09/26 03:41:07 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.00	
[09/26 03:41:07 visual_prompt]: Training 47 / 100 epoch, with learning rate 3.2725424859373686
[09/26 03:41:14 visual_prompt]: Epoch 47 / 100: avg data time: 5.55e-02, avg batch time: 0.4977, average train loss: 5.8890
[09/26 03:41:16 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1677, average loss: 6.3880
[09/26 03:41:16 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.00	
[09/26 03:41:16 visual_prompt]: Training 48 / 100 epoch, with learning rate 3.1890933895424975
[09/26 03:41:22 visual_prompt]: Epoch 48 / 100: avg data time: 5.22e-02, avg batch time: 0.4965, average train loss: 5.7065
[09/26 03:41:24 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1671, average loss: 6.1860
[09/26 03:41:24 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 3.00	
[09/26 03:41:24 visual_prompt]: Training 49 / 100 epoch, with learning rate 3.104804738999169
[09/26 03:41:31 visual_prompt]: Epoch 49 / 100: avg data time: 5.90e-02, avg batch time: 0.5025, average train loss: 5.7501
[09/26 03:41:32 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.1670, average loss: 6.8702
[09/26 03:41:32 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.50	
[09/26 03:41:32 visual_prompt]: Training 50 / 100 epoch, with learning rate 3.019779227044398
[09/26 03:41:39 visual_prompt]: Epoch 50 / 100: avg data time: 5.55e-02, avg batch time: 0.4999, average train loss: 6.6320
[09/26 03:41:41 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1671, average loss: 7.3571
[09/26 03:41:41 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.00	
[09/26 03:41:41 visual_prompt]: Training 51 / 100 epoch, with learning rate 2.934120444167326
[09/26 03:41:48 visual_prompt]: Epoch 51 / 100: avg data time: 5.59e-02, avg batch time: 0.4981, average train loss: 6.2814
[09/26 03:41:49 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1676, average loss: 6.4459
[09/26 03:41:49 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.00	
[09/26 03:41:49 visual_prompt]: Training 52 / 100 epoch, with learning rate 2.8479327524001636
[09/26 03:41:56 visual_prompt]: Epoch 52 / 100: avg data time: 4.79e-02, avg batch time: 0.4922, average train loss: 6.4190
[09/26 03:41:57 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1670, average loss: 6.6969
[09/26 03:41:57 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 2.50	
[09/26 03:41:57 visual_prompt]: Training 53 / 100 epoch, with learning rate 2.761321158169134
[09/26 03:42:04 visual_prompt]: Epoch 53 / 100: avg data time: 4.16e-02, avg batch time: 0.4874, average train loss: 7.8469
[09/26 03:42:06 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1675, average loss: 7.0249
[09/26 03:42:06 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 3.00	
[09/26 03:42:06 visual_prompt]: Training 54 / 100 epoch, with learning rate 2.6743911843603128
[09/26 03:42:12 visual_prompt]: Epoch 54 / 100: avg data time: 5.45e-02, avg batch time: 0.4971, average train loss: 6.7361
[09/26 03:42:14 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1674, average loss: 6.6972
[09/26 03:42:14 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 2.50	
[09/26 03:42:14 visual_prompt]: Training 55 / 100 epoch, with learning rate 2.5872487417562526
[09/26 03:42:21 visual_prompt]: Epoch 55 / 100: avg data time: 5.91e-02, avg batch time: 0.5013, average train loss: 6.4469
[09/26 03:42:22 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1677, average loss: 6.4594
[09/26 03:42:22 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 5.50	
[09/26 03:42:22 visual_prompt]: Training 56 / 100 epoch, with learning rate 2.5
[09/26 03:42:29 visual_prompt]: Epoch 56 / 100: avg data time: 5.38e-02, avg batch time: 0.4961, average train loss: 6.3556
[09/26 03:42:31 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1673, average loss: 6.4212
[09/26 03:42:31 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 3.00	
[09/26 03:42:31 visual_prompt]: Training 57 / 100 epoch, with learning rate 2.4127512582437483
[09/26 03:42:38 visual_prompt]: Epoch 57 / 100: avg data time: 6.70e-02, avg batch time: 0.5107, average train loss: 6.2097
[09/26 03:42:39 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1675, average loss: 6.3648
[09/26 03:42:39 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 5.00	
[09/26 03:42:39 visual_prompt]: Training 58 / 100 epoch, with learning rate 2.325608815639687
[09/26 03:42:46 visual_prompt]: Epoch 58 / 100: avg data time: 6.01e-02, avg batch time: 0.5025, average train loss: 6.0781
[09/26 03:42:47 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1675, average loss: 6.3045
[09/26 03:42:47 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.50	
[09/26 03:42:47 visual_prompt]: Training 59 / 100 epoch, with learning rate 2.2386788418308665
[09/26 03:42:54 visual_prompt]: Epoch 59 / 100: avg data time: 4.77e-02, avg batch time: 0.4921, average train loss: 5.9896
[09/26 03:42:56 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1673, average loss: 6.3723
[09/26 03:42:56 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 03:42:56 visual_prompt]: Training 60 / 100 epoch, with learning rate 2.1520672475998373
[09/26 03:43:02 visual_prompt]: Epoch 60 / 100: avg data time: 4.36e-02, avg batch time: 0.4874, average train loss: 5.9309
[09/26 03:43:04 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1673, average loss: 6.1900
[09/26 03:43:04 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 3.00	
[09/26 03:43:04 visual_prompt]: Training 61 / 100 epoch, with learning rate 2.0658795558326744
[09/26 03:43:11 visual_prompt]: Epoch 61 / 100: avg data time: 5.64e-02, avg batch time: 0.4996, average train loss: 5.8138
[09/26 03:43:12 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1675, average loss: 6.2299
[09/26 03:43:12 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.50	
[09/26 03:43:12 visual_prompt]: Training 62 / 100 epoch, with learning rate 1.980220772955602
[09/26 03:43:19 visual_prompt]: Epoch 62 / 100: avg data time: 5.59e-02, avg batch time: 0.4989, average train loss: 5.7413
[09/26 03:43:21 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1674, average loss: 6.1114
[09/26 03:43:21 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.50	
[09/26 03:43:21 visual_prompt]: Training 63 / 100 epoch, with learning rate 1.895195261000831
[09/26 03:43:28 visual_prompt]: Epoch 63 / 100: avg data time: 5.34e-02, avg batch time: 0.4980, average train loss: 5.6758
[09/26 03:43:29 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1669, average loss: 6.1809
[09/26 03:43:29 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 3.00	
[09/26 03:43:29 visual_prompt]: Training 64 / 100 epoch, with learning rate 1.8109066104575022
[09/26 03:43:36 visual_prompt]: Epoch 64 / 100: avg data time: 6.20e-02, avg batch time: 0.5061, average train loss: 5.6968
[09/26 03:43:38 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1677, average loss: 6.0604
[09/26 03:43:38 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.50	
[09/26 03:43:38 visual_prompt]: Training 65 / 100 epoch, with learning rate 1.7274575140626316
[09/26 03:43:45 visual_prompt]: Epoch 65 / 100: avg data time: 6.20e-02, avg batch time: 0.5074, average train loss: 5.6135
[09/26 03:43:46 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1672, average loss: 6.0940
[09/26 03:43:46 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 3.50	
[09/26 03:43:46 visual_prompt]: Training 66 / 100 epoch, with learning rate 1.6449496416858285
[09/26 03:43:53 visual_prompt]: Epoch 66 / 100: avg data time: 6.08e-02, avg batch time: 0.5039, average train loss: 5.6174
[09/26 03:43:55 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1672, average loss: 6.1000
[09/26 03:43:55 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 5.50	
[09/26 03:43:55 visual_prompt]: Training 67 / 100 epoch, with learning rate 1.5634835164602199
[09/26 03:44:01 visual_prompt]: Epoch 67 / 100: avg data time: 5.20e-02, avg batch time: 0.4947, average train loss: 5.5978
[09/26 03:44:03 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1671, average loss: 6.1338
[09/26 03:44:03 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 3.50	
[09/26 03:44:03 visual_prompt]: Training 68 / 100 epoch, with learning rate 1.4831583923104998
[09/26 03:44:10 visual_prompt]: Epoch 68 / 100: avg data time: 5.65e-02, avg batch time: 0.4992, average train loss: 5.5835
[09/26 03:44:11 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1673, average loss: 6.1004
[09/26 03:44:11 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.50	
[09/26 03:44:11 visual_prompt]: Training 69 / 100 epoch, with learning rate 1.4040721330273063
[09/26 03:44:18 visual_prompt]: Epoch 69 / 100: avg data time: 5.55e-02, avg batch time: 0.4984, average train loss: 5.5166
[09/26 03:44:20 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1670, average loss: 6.0648
[09/26 03:44:20 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.50	
[09/26 03:44:20 visual_prompt]: Training 70 / 100 epoch, with learning rate 1.3263210930352738
[09/26 03:44:26 visual_prompt]: Epoch 70 / 100: avg data time: 5.49e-02, avg batch time: 0.4981, average train loss: 5.5517
[09/26 03:44:28 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1676, average loss: 6.0454
[09/26 03:44:28 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.00	
[09/26 03:44:28 visual_prompt]: Training 71 / 100 epoch, with learning rate 1.2500000000000004
[09/26 03:44:35 visual_prompt]: Epoch 71 / 100: avg data time: 6.52e-02, avg batch time: 0.5071, average train loss: 5.5269
[09/26 03:44:36 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1674, average loss: 6.1504
[09/26 03:44:36 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 3.00	
[09/26 03:44:36 visual_prompt]: Training 72 / 100 epoch, with learning rate 1.175201839416988
[09/26 03:44:43 visual_prompt]: Epoch 72 / 100: avg data time: 5.92e-02, avg batch time: 0.5027, average train loss: 5.5351
[09/26 03:44:45 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1673, average loss: 6.0766
[09/26 03:44:45 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.00	
[09/26 03:44:45 visual_prompt]: Training 73 / 100 epoch, with learning rate 1.1020177413231333
[09/26 03:44:52 visual_prompt]: Epoch 73 / 100: avg data time: 5.12e-02, avg batch time: 0.4948, average train loss: 5.5005
[09/26 03:44:53 visual_prompt]: Inference (val):avg data time: 4.87e-05, avg batch time: 0.1675, average loss: 6.0631
[09/26 03:44:53 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.00	
[09/26 03:44:53 visual_prompt]: Training 74 / 100 epoch, with learning rate 1.0305368692688175
[09/26 03:45:00 visual_prompt]: Epoch 74 / 100: avg data time: 4.42e-02, avg batch time: 0.4882, average train loss: 5.5262
[09/26 03:45:01 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1674, average loss: 6.0724
[09/26 03:45:01 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.50	
[09/26 03:45:01 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.9608463116858543
[09/26 03:45:08 visual_prompt]: Epoch 75 / 100: avg data time: 5.35e-02, avg batch time: 0.4962, average train loss: 5.5400
[09/26 03:45:10 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1673, average loss: 6.0817
[09/26 03:45:10 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 4.50	
[09/26 03:45:10 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.8930309757836516
[09/26 03:45:16 visual_prompt]: Epoch 76 / 100: avg data time: 5.16e-02, avg batch time: 0.4962, average train loss: 5.5137
[09/26 03:45:18 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1673, average loss: 6.0519
[09/26 03:45:18 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.50	
[09/26 03:45:18 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.8271734841028553
[09/26 03:45:25 visual_prompt]: Epoch 77 / 100: avg data time: 5.62e-02, avg batch time: 0.4986, average train loss: 5.4992
[09/26 03:45:26 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1673, average loss: 6.0550
[09/26 03:45:26 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 03:45:26 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.7633540738525066
[09/26 03:45:33 visual_prompt]: Epoch 78 / 100: avg data time: 5.49e-02, avg batch time: 0.4987, average train loss: 5.5118
[09/26 03:45:35 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1670, average loss: 6.0605
[09/26 03:45:35 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 5.00	
[09/26 03:45:35 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.7016504991533725
[09/26 03:45:41 visual_prompt]: Epoch 79 / 100: avg data time: 5.72e-02, avg batch time: 0.5004, average train loss: 5.4859
[09/26 03:45:43 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1671, average loss: 6.0680
[09/26 03:45:43 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 03:45:43 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.6421379363065141
[09/26 03:45:50 visual_prompt]: Epoch 80 / 100: avg data time: 5.57e-02, avg batch time: 0.4992, average train loss: 5.4862
[09/26 03:45:51 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1676, average loss: 6.0939
[09/26 03:45:51 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 5.00	
[09/26 03:45:51 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.5848888922025552
[09/26 03:45:58 visual_prompt]: Epoch 81 / 100: avg data time: 4.44e-02, avg batch time: 0.4893, average train loss: 5.4948
[09/26 03:45:59 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1674, average loss: 6.0583
[09/26 03:46:00 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 03:46:00 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.5299731159831953
[09/26 03:46:06 visual_prompt]: Epoch 82 / 100: avg data time: 5.80e-02, avg batch time: 0.5014, average train loss: 5.4767
[09/26 03:46:08 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1676, average loss: 6.0552
[09/26 03:46:08 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 4.50	
[09/26 03:46:08 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.47745751406263165
[09/26 03:46:15 visual_prompt]: Epoch 83 / 100: avg data time: 4.75e-02, avg batch time: 0.4911, average train loss: 5.4543
[09/26 03:46:16 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1671, average loss: 6.1339
[09/26 03:46:16 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 5.00	
[09/26 03:46:16 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.42740606861239594
[09/26 03:46:23 visual_prompt]: Epoch 84 / 100: avg data time: 5.83e-02, avg batch time: 0.5025, average train loss: 5.4759
[09/26 03:46:24 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1670, average loss: 6.0797
[09/26 03:46:24 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 5.00	
[09/26 03:46:24 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.3798797596089351
[09/26 03:46:31 visual_prompt]: Epoch 85 / 100: avg data time: 5.58e-02, avg batch time: 0.4994, average train loss: 5.4691
[09/26 03:46:33 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1671, average loss: 6.0708
[09/26 03:46:33 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.00	
[09/26 03:46:33 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.33493649053890323
[09/26 03:46:40 visual_prompt]: Epoch 86 / 100: avg data time: 6.06e-02, avg batch time: 0.5044, average train loss: 5.4854
[09/26 03:46:41 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1674, average loss: 6.0613
[09/26 03:46:41 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 4.50	
[09/26 03:46:41 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.29263101785268253
[09/26 03:46:48 visual_prompt]: Epoch 87 / 100: avg data time: 5.72e-02, avg batch time: 0.5003, average train loss: 5.4747
[09/26 03:46:50 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1674, average loss: 6.0651
[09/26 03:46:50 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 03:46:50 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.25301488425208296
[09/26 03:46:56 visual_prompt]: Epoch 88 / 100: avg data time: 4.74e-02, avg batch time: 0.4924, average train loss: 5.4668
[09/26 03:46:58 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1671, average loss: 6.0700
[09/26 03:46:58 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 4.50	
[09/26 03:46:58 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.21613635589349756
[09/26 03:47:05 visual_prompt]: Epoch 89 / 100: avg data time: 5.53e-02, avg batch time: 0.4993, average train loss: 5.4607
[09/26 03:47:06 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1673, average loss: 6.0672
[09/26 03:47:06 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 5.00	
[09/26 03:47:06 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.18204036358303172
[09/26 03:47:13 visual_prompt]: Epoch 90 / 100: avg data time: 4.94e-02, avg batch time: 0.4930, average train loss: 5.4616
[09/26 03:47:14 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1673, average loss: 6.0649
[09/26 03:47:14 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 5.00	
[09/26 03:47:14 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.1507684480352292
[09/26 03:47:21 visual_prompt]: Epoch 91 / 100: avg data time: 5.07e-02, avg batch time: 0.4937, average train loss: 5.4454
[09/26 03:47:23 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1669, average loss: 6.0689
[09/26 03:47:23 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.50	
[09/26 03:47:23 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.12235870926211617
[09/26 03:47:29 visual_prompt]: Epoch 92 / 100: avg data time: 5.14e-02, avg batch time: 0.4954, average train loss: 5.4551
[09/26 03:47:31 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1673, average loss: 6.0646
[09/26 03:47:31 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 03:47:31 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.09684576015420276
[09/26 03:47:38 visual_prompt]: Epoch 93 / 100: avg data time: 4.76e-02, avg batch time: 0.4905, average train loss: 5.4487
[09/26 03:47:39 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1673, average loss: 6.0645
[09/26 03:47:39 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 03:47:39 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.07426068431000882
[09/26 03:47:46 visual_prompt]: Epoch 94 / 100: avg data time: 4.76e-02, avg batch time: 0.4923, average train loss: 5.4401
[09/26 03:47:48 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1675, average loss: 6.0552
[09/26 03:47:48 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 03:47:48 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.05463099816548578
[09/26 03:47:54 visual_prompt]: Epoch 95 / 100: avg data time: 5.65e-02, avg batch time: 0.5007, average train loss: 5.4152
[09/26 03:47:56 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1672, average loss: 6.0683
[09/26 03:47:56 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.50	
[09/26 03:47:56 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.03798061746947995
[09/26 03:48:03 visual_prompt]: Epoch 96 / 100: avg data time: 4.86e-02, avg batch time: 0.4939, average train loss: 5.3867
[09/26 03:48:04 visual_prompt]: Inference (val):avg data time: 2.00e-05, avg batch time: 0.1672, average loss: 6.0079
[09/26 03:48:04 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 6.00	
[09/26 03:48:04 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.024329828146074095
[09/26 03:48:11 visual_prompt]: Epoch 97 / 100: avg data time: 4.34e-02, avg batch time: 0.4883, average train loss: 5.3101
[09/26 03:48:12 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1672, average loss: 5.9928
[09/26 03:48:12 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 6.00	
[09/26 03:48:12 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.013695261579316775
[09/26 03:48:19 visual_prompt]: Epoch 98 / 100: avg data time: 5.24e-02, avg batch time: 0.4972, average train loss: 5.2380
[09/26 03:48:21 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1676, average loss: 5.9605
[09/26 03:48:21 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.00	top5: 6.50	
[09/26 03:48:21 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.006089874350439506
[09/26 03:48:28 visual_prompt]: Epoch 99 / 100: avg data time: 5.53e-02, avg batch time: 0.4989, average train loss: 5.2111
[09/26 03:48:29 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1673, average loss: 5.9321
[09/26 03:48:29 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.00	top5: 6.50	
[09/26 03:48:29 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0015229324522605947
[09/26 03:48:36 visual_prompt]: Epoch 100 / 100: avg data time: 6.32e-02, avg batch time: 0.5062, average train loss: 5.1706
[09/26 03:48:37 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1672, average loss: 5.9227
[09/26 03:48:37 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.00	top5: 7.00	
[09/26 03:48:37 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 03:48:37 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              0
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 03:48:37 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-sun397', 'DATA.NUMBER_CLASSES', '397', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 03:48:37 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 03:48:37 visual_prompt]: Training with config:
[09/26 03:48:37 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-sun397/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr5.0_wd0.001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 5.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-sun397', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 397, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 03:48:37 visual_prompt]: Loading training data...
[09/26 03:48:37 visual_prompt]: Constructing vtab-sun397 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split train[:800], from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/26 03:48:39 visual_prompt]: Number of images: 800
[09/26 03:48:39 visual_prompt]: Number of classes: 309 / 397
[09/26 03:48:39 visual_prompt]: Loading validation data...
[09/26 03:48:39 visual_prompt]: Constructing vtab-sun397 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split validation[:200], from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/26 03:48:39 visual_prompt]: Number of images: 200
[09/26 03:48:39 visual_prompt]: Number of classes: 136 / 397
[09/26 03:48:39 visual_prompt]: Constructing models...
[09/26 03:48:42 visual_prompt]: Total Parameters: 86564749	 Gradient Parameters: 766093
[09/26 03:48:42 visual_prompt]: tuned percent:0.885
[09/26 03:48:42 visual_prompt]: Device used for model: 0
[09/26 03:48:42 visual_prompt]: Setting up Evaluator...
[09/26 03:48:42 visual_prompt]: Setting up Trainer...
[09/26 03:48:42 visual_prompt]: 	Setting up the optimizer...
[09/26 03:48:42 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 03:48:49 visual_prompt]: Epoch 1 / 100: avg data time: 5.88e-02, avg batch time: 0.5016, average train loss: 5.9893
[09/26 03:48:50 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1671, average loss: 6.0097
[09/26 03:48:50 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/26 03:48:50 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.5
[09/26 03:48:57 visual_prompt]: Epoch 2 / 100: avg data time: 6.01e-02, avg batch time: 0.5025, average train loss: 5.7689
[09/26 03:48:59 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1671, average loss: 5.8188
[09/26 03:48:59 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.50	
[09/26 03:48:59 visual_prompt]: Best epoch 2: best metric: 0.010
[09/26 03:48:59 visual_prompt]: Training 3 / 100 epoch, with learning rate 1.0
[09/26 03:49:05 visual_prompt]: Epoch 3 / 100: avg data time: 5.09e-02, avg batch time: 0.4954, average train loss: 5.6441
[09/26 03:49:07 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1679, average loss: 5.8419
[09/26 03:49:07 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 03:49:07 visual_prompt]: Training 4 / 100 epoch, with learning rate 1.5
[09/26 03:49:14 visual_prompt]: Epoch 4 / 100: avg data time: 6.05e-02, avg batch time: 0.5053, average train loss: 5.7707
[09/26 03:49:15 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1677, average loss: 5.8625
[09/26 03:49:15 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.00	
[09/26 03:49:15 visual_prompt]: Training 5 / 100 epoch, with learning rate 2.0
[09/26 03:49:22 visual_prompt]: Epoch 5 / 100: avg data time: 5.66e-02, avg batch time: 0.5010, average train loss: 6.1024
[09/26 03:49:24 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1682, average loss: 5.9971
[09/26 03:49:24 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 3.00	
[09/26 03:49:24 visual_prompt]: Best epoch 5: best metric: 0.015
[09/26 03:49:24 visual_prompt]: Training 6 / 100 epoch, with learning rate 2.5
[09/26 03:49:31 visual_prompt]: Epoch 6 / 100: avg data time: 6.22e-02, avg batch time: 0.5043, average train loss: 6.4808
[09/26 03:49:32 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1678, average loss: 6.3187
[09/26 03:49:32 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 2.50	
[09/26 03:49:32 visual_prompt]: Training 7 / 100 epoch, with learning rate 3.0
[09/26 03:49:39 visual_prompt]: Epoch 7 / 100: avg data time: 5.75e-02, avg batch time: 0.5002, average train loss: 7.5493
[09/26 03:49:41 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1679, average loss: 6.5559
[09/26 03:49:41 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 3.00	
[09/26 03:49:41 visual_prompt]: Training 8 / 100 epoch, with learning rate 3.5
[09/26 03:49:48 visual_prompt]: Epoch 8 / 100: avg data time: 6.39e-02, avg batch time: 0.5062, average train loss: 7.1492
[09/26 03:49:49 visual_prompt]: Inference (val):avg data time: 3.43e-05, avg batch time: 0.1672, average loss: 6.0262
[09/26 03:49:49 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 3.50	
[09/26 03:49:49 visual_prompt]: Training 9 / 100 epoch, with learning rate 4.0
[09/26 03:49:56 visual_prompt]: Epoch 9 / 100: avg data time: 5.12e-02, avg batch time: 0.4943, average train loss: 7.8565
[09/26 03:49:58 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1673, average loss: 6.9105
[09/26 03:49:58 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 2.00	
[09/26 03:49:58 visual_prompt]: Training 10 / 100 epoch, with learning rate 4.5
[09/26 03:50:04 visual_prompt]: Epoch 10 / 100: avg data time: 5.87e-02, avg batch time: 0.5021, average train loss: 8.4163
[09/26 03:50:06 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1671, average loss: 6.7224
[09/26 03:50:06 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.00	
[09/26 03:50:06 visual_prompt]: Training 11 / 100 epoch, with learning rate 5.0
[09/26 03:50:13 visual_prompt]: Epoch 11 / 100: avg data time: 6.06e-02, avg batch time: 0.5034, average train loss: 8.6119
[09/26 03:50:14 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1673, average loss: 7.1669
[09/26 03:50:14 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 3.00	
[09/26 03:50:14 visual_prompt]: Training 12 / 100 epoch, with learning rate 4.998477067547739
[09/26 03:50:21 visual_prompt]: Epoch 12 / 100: avg data time: 5.00e-02, avg batch time: 0.4930, average train loss: 8.8564
[09/26 03:50:23 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1672, average loss: 7.5076
[09/26 03:50:23 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 6.50	
[09/26 03:50:23 visual_prompt]: Training 13 / 100 epoch, with learning rate 4.993910125649561
[09/26 03:50:29 visual_prompt]: Epoch 13 / 100: avg data time: 5.31e-02, avg batch time: 0.4954, average train loss: 7.7923
[09/26 03:50:31 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1669, average loss: 6.8115
[09/26 03:50:31 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 5.50	
[09/26 03:50:31 visual_prompt]: Training 14 / 100 epoch, with learning rate 4.986304738420683
[09/26 03:50:38 visual_prompt]: Epoch 14 / 100: avg data time: 5.81e-02, avg batch time: 0.5003, average train loss: 6.9000
[09/26 03:50:39 visual_prompt]: Inference (val):avg data time: 2.08e-05, avg batch time: 0.1670, average loss: 6.8651
[09/26 03:50:39 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 2.50	
[09/26 03:50:39 visual_prompt]: Training 15 / 100 epoch, with learning rate 4.975670171853926
[09/26 03:50:46 visual_prompt]: Epoch 15 / 100: avg data time: 4.65e-02, avg batch time: 0.4896, average train loss: 7.5425
[09/26 03:50:48 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1673, average loss: 6.8565
[09/26 03:50:48 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 4.50	
[09/26 03:50:48 visual_prompt]: Training 16 / 100 epoch, with learning rate 4.962019382530521
[09/26 03:50:55 visual_prompt]: Epoch 16 / 100: avg data time: 6.38e-02, avg batch time: 0.5062, average train loss: 7.5185
[09/26 03:50:56 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1673, average loss: 7.0009
[09/26 03:50:56 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.00	
[09/26 03:50:56 visual_prompt]: Training 17 / 100 epoch, with learning rate 4.945369001834514
[09/26 03:51:03 visual_prompt]: Epoch 17 / 100: avg data time: 5.44e-02, avg batch time: 0.4989, average train loss: 7.4453
[09/26 03:51:04 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1672, average loss: 6.5483
[09/26 03:51:04 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 5.00	
[09/26 03:51:04 visual_prompt]: Training 18 / 100 epoch, with learning rate 4.925739315689991
[09/26 03:51:11 visual_prompt]: Epoch 18 / 100: avg data time: 5.40e-02, avg batch time: 0.4975, average train loss: 6.9220
[09/26 03:51:13 visual_prompt]: Inference (val):avg data time: 1.98e-05, avg batch time: 0.1674, average loss: 6.3230
[09/26 03:51:13 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 3.50	
[09/26 03:51:13 visual_prompt]: Training 19 / 100 epoch, with learning rate 4.903154239845797
[09/26 03:51:20 visual_prompt]: Epoch 19 / 100: avg data time: 6.02e-02, avg batch time: 0.5042, average train loss: 6.5075
[09/26 03:51:21 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1674, average loss: 8.2996
[09/26 03:51:21 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.00	
[09/26 03:51:21 visual_prompt]: Training 20 / 100 epoch, with learning rate 4.877641290737884
[09/26 03:51:28 visual_prompt]: Epoch 20 / 100: avg data time: 7.55e-02, avg batch time: 0.5181, average train loss: 7.1349
[09/26 03:51:30 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1669, average loss: 6.4806
[09/26 03:51:30 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 3.50	
[09/26 03:51:30 visual_prompt]: Training 21 / 100 epoch, with learning rate 4.849231551964771
[09/26 03:51:37 visual_prompt]: Epoch 21 / 100: avg data time: 5.71e-02, avg batch time: 0.5022, average train loss: 12.8257
[09/26 03:51:38 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1675, average loss: 6.5522
[09/26 03:51:38 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 4.00	
[09/26 03:51:38 visual_prompt]: Training 22 / 100 epoch, with learning rate 4.817959636416969
[09/26 03:51:45 visual_prompt]: Epoch 22 / 100: avg data time: 5.66e-02, avg batch time: 0.4997, average train loss: 8.0318
[09/26 03:51:47 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1674, average loss: 6.8037
[09/26 03:51:47 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 3.00	
[09/26 03:51:47 visual_prompt]: Training 23 / 100 epoch, with learning rate 4.783863644106502
[09/26 03:51:53 visual_prompt]: Epoch 23 / 100: avg data time: 5.15e-02, avg batch time: 0.4955, average train loss: 6.8853
[09/26 03:51:55 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1676, average loss: 6.6935
[09/26 03:51:55 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.50	
[09/26 03:51:55 visual_prompt]: Training 24 / 100 epoch, with learning rate 4.7469851157479175
[09/26 03:52:02 visual_prompt]: Epoch 24 / 100: avg data time: 5.48e-02, avg batch time: 0.4986, average train loss: 6.8374
[09/26 03:52:03 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1676, average loss: 6.4683
[09/26 03:52:03 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 2.00	
[09/26 03:52:03 visual_prompt]: Training 25 / 100 epoch, with learning rate 4.707368982147317
[09/26 03:52:10 visual_prompt]: Epoch 25 / 100: avg data time: 5.26e-02, avg batch time: 0.4965, average train loss: 6.6261
[09/26 03:52:12 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1675, average loss: 6.3508
[09/26 03:52:12 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 3.50	
[09/26 03:52:12 visual_prompt]: Training 26 / 100 epoch, with learning rate 4.665063509461097
[09/26 03:52:18 visual_prompt]: Epoch 26 / 100: avg data time: 5.63e-02, avg batch time: 0.4993, average train loss: 7.2105
[09/26 03:52:20 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1671, average loss: 6.5646
[09/26 03:52:20 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.00	
[09/26 03:52:20 visual_prompt]: Training 27 / 100 epoch, with learning rate 4.620120240391064
[09/26 03:52:27 visual_prompt]: Epoch 27 / 100: avg data time: 5.65e-02, avg batch time: 0.4998, average train loss: 7.7075
[09/26 03:52:28 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1673, average loss: 6.5343
[09/26 03:52:28 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 7.00	
[09/26 03:52:28 visual_prompt]: Training 28 / 100 epoch, with learning rate 4.572593931387604
[09/26 03:52:35 visual_prompt]: Epoch 28 / 100: avg data time: 5.78e-02, avg batch time: 0.5031, average train loss: 8.1210
[09/26 03:52:37 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1675, average loss: 7.8140
[09/26 03:52:37 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 03:52:37 visual_prompt]: Training 29 / 100 epoch, with learning rate 4.522542485937368
[09/26 03:52:44 visual_prompt]: Epoch 29 / 100: avg data time: 5.35e-02, avg batch time: 0.4969, average train loss: 9.7956
[09/26 03:52:45 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1672, average loss: 7.1307
[09/26 03:52:45 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 3.00	
[09/26 03:52:45 visual_prompt]: Training 30 / 100 epoch, with learning rate 4.4700268840168045
[09/26 03:52:52 visual_prompt]: Epoch 30 / 100: avg data time: 5.63e-02, avg batch time: 0.4992, average train loss: 8.0722
[09/26 03:52:54 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1675, average loss: 6.9462
[09/26 03:52:54 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 3.00	
[09/26 03:52:54 visual_prompt]: Training 31 / 100 epoch, with learning rate 4.415111107797445
[09/26 03:53:00 visual_prompt]: Epoch 31 / 100: avg data time: 5.56e-02, avg batch time: 0.4999, average train loss: 9.0584
[09/26 03:53:02 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1674, average loss: 7.0204
[09/26 03:53:02 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 4.00	
[09/26 03:53:02 visual_prompt]: Training 32 / 100 epoch, with learning rate 4.357862063693486
[09/26 03:53:09 visual_prompt]: Epoch 32 / 100: avg data time: 6.09e-02, avg batch time: 0.5033, average train loss: 9.1410
[09/26 03:53:10 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1675, average loss: 7.3787
[09/26 03:53:10 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.00	
[09/26 03:53:10 visual_prompt]: Training 33 / 100 epoch, with learning rate 4.298349500846628
[09/26 03:53:17 visual_prompt]: Epoch 33 / 100: avg data time: 4.66e-02, avg batch time: 0.4900, average train loss: 8.3108
[09/26 03:53:18 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1672, average loss: 7.1949
[09/26 03:53:18 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 1.50	
[09/26 03:53:18 visual_prompt]: Training 34 / 100 epoch, with learning rate 4.236645926147493
[09/26 03:53:25 visual_prompt]: Epoch 34 / 100: avg data time: 5.85e-02, avg batch time: 0.5015, average train loss: 7.0554
[09/26 03:53:27 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.1667, average loss: 6.5188
[09/26 03:53:27 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 5.50	
[09/26 03:53:27 visual_prompt]: Training 35 / 100 epoch, with learning rate 4.172826515897146
[09/26 03:53:34 visual_prompt]: Epoch 35 / 100: avg data time: 6.37e-02, avg batch time: 0.5066, average train loss: 7.3281
[09/26 03:53:35 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1673, average loss: 6.9632
[09/26 03:53:35 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.00	
[09/26 03:53:35 visual_prompt]: Training 36 / 100 epoch, with learning rate 4.106969024216348
[09/26 03:53:42 visual_prompt]: Epoch 36 / 100: avg data time: 5.68e-02, avg batch time: 0.5002, average train loss: 8.3634
[09/26 03:53:44 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1671, average loss: 6.4981
[09/26 03:53:44 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 2.00	
[09/26 03:53:44 visual_prompt]: Training 37 / 100 epoch, with learning rate 4.039153688314146
[09/26 03:53:50 visual_prompt]: Epoch 37 / 100: avg data time: 5.35e-02, avg batch time: 0.4962, average train loss: 8.2739
[09/26 03:53:52 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1675, average loss: 6.8011
[09/26 03:53:52 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 6.00	
[09/26 03:53:52 visual_prompt]: Training 38 / 100 epoch, with learning rate 3.969463130731183
[09/26 03:53:59 visual_prompt]: Epoch 38 / 100: avg data time: 4.33e-02, avg batch time: 0.4879, average train loss: 10.3565
[09/26 03:54:00 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1668, average loss: 8.0108
[09/26 03:54:00 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 5.00	
[09/26 03:54:00 visual_prompt]: Training 39 / 100 epoch, with learning rate 3.897982258676867
[09/26 03:54:07 visual_prompt]: Epoch 39 / 100: avg data time: 5.74e-02, avg batch time: 0.5006, average train loss: 10.2018
[09/26 03:54:09 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1669, average loss: 7.6177
[09/26 03:54:09 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 03:54:09 visual_prompt]: Training 40 / 100 epoch, with learning rate 3.824798160583012
[09/26 03:54:15 visual_prompt]: Epoch 40 / 100: avg data time: 5.73e-02, avg batch time: 0.5001, average train loss: 8.9295
[09/26 03:54:17 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1676, average loss: 6.8519
[09/26 03:54:17 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.00	
[09/26 03:54:17 visual_prompt]: Training 41 / 100 epoch, with learning rate 3.75
[09/26 03:54:24 visual_prompt]: Epoch 41 / 100: avg data time: 4.63e-02, avg batch time: 0.4899, average train loss: 8.5868
[09/26 03:54:25 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1674, average loss: 7.2741
[09/26 03:54:25 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 2.00	
[09/26 03:54:25 visual_prompt]: Training 42 / 100 epoch, with learning rate 3.673678906964727
[09/26 03:54:32 visual_prompt]: Epoch 42 / 100: avg data time: 5.21e-02, avg batch time: 0.4956, average train loss: 8.1643
[09/26 03:54:33 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1677, average loss: 6.5674
[09/26 03:54:33 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.00	
[09/26 03:54:33 visual_prompt]: Training 43 / 100 epoch, with learning rate 3.5959278669726933
[09/26 03:54:40 visual_prompt]: Epoch 43 / 100: avg data time: 5.90e-02, avg batch time: 0.5024, average train loss: 13.6351
[09/26 03:54:42 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1678, average loss: 7.6328
[09/26 03:54:42 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 0.00	
[09/26 03:54:42 visual_prompt]: Training 44 / 100 epoch, with learning rate 3.516841607689501
[09/26 03:54:49 visual_prompt]: Epoch 44 / 100: avg data time: 6.05e-02, avg batch time: 0.5038, average train loss: 8.5869
[09/26 03:54:50 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1676, average loss: 7.2091
[09/26 03:54:50 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 2.00	
[09/26 03:54:50 visual_prompt]: Training 45 / 100 epoch, with learning rate 3.4365164835397803
[09/26 03:54:57 visual_prompt]: Epoch 45 / 100: avg data time: 5.69e-02, avg batch time: 0.5007, average train loss: 7.2718
[09/26 03:54:59 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1671, average loss: 6.4475
[09/26 03:54:59 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 5.50	
[09/26 03:54:59 visual_prompt]: Training 46 / 100 epoch, with learning rate 3.3550503583141724
[09/26 03:55:05 visual_prompt]: Epoch 46 / 100: avg data time: 5.54e-02, avg batch time: 0.4996, average train loss: 6.3816
[09/26 03:55:07 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1671, average loss: 6.2701
[09/26 03:55:07 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 3.00	
[09/26 03:55:07 visual_prompt]: Training 47 / 100 epoch, with learning rate 3.2725424859373686
[09/26 03:55:14 visual_prompt]: Epoch 47 / 100: avg data time: 5.69e-02, avg batch time: 0.4995, average train loss: 6.4419
[09/26 03:55:15 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1671, average loss: 6.4132
[09/26 03:55:15 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.00	
[09/26 03:55:15 visual_prompt]: Training 48 / 100 epoch, with learning rate 3.1890933895424975
[09/26 03:55:22 visual_prompt]: Epoch 48 / 100: avg data time: 5.34e-02, avg batch time: 0.4967, average train loss: 6.5290
[09/26 03:55:24 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1678, average loss: 6.3984
[09/26 03:55:24 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.50	
[09/26 03:55:24 visual_prompt]: Training 49 / 100 epoch, with learning rate 3.104804738999169
[09/26 03:55:31 visual_prompt]: Epoch 49 / 100: avg data time: 6.79e-02, avg batch time: 0.5103, average train loss: 6.5296
[09/26 03:55:32 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1672, average loss: 6.3751
[09/26 03:55:32 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 2.50	
[09/26 03:55:32 visual_prompt]: Training 50 / 100 epoch, with learning rate 3.019779227044398
[09/26 03:55:39 visual_prompt]: Epoch 50 / 100: avg data time: 5.36e-02, avg batch time: 0.4959, average train loss: 6.3510
[09/26 03:55:41 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1676, average loss: 6.2426
[09/26 03:55:41 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 3.50	
[09/26 03:55:41 visual_prompt]: Training 51 / 100 epoch, with learning rate 2.934120444167326
[09/26 03:55:48 visual_prompt]: Epoch 51 / 100: avg data time: 6.39e-02, avg batch time: 0.5064, average train loss: 5.9951
[09/26 03:55:49 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1674, average loss: 6.2338
[09/26 03:55:49 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 2.50	
[09/26 03:55:49 visual_prompt]: Training 52 / 100 epoch, with learning rate 2.8479327524001636
[09/26 03:55:56 visual_prompt]: Epoch 52 / 100: avg data time: 4.74e-02, avg batch time: 0.4918, average train loss: 5.9797
[09/26 03:55:57 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1678, average loss: 6.1217
[09/26 03:55:57 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 3.50	
[09/26 03:55:57 visual_prompt]: Training 53 / 100 epoch, with learning rate 2.761321158169134
[09/26 03:56:04 visual_prompt]: Epoch 53 / 100: avg data time: 5.68e-02, avg batch time: 0.5000, average train loss: 5.9178
[09/26 03:56:06 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1676, average loss: 6.1598
[09/26 03:56:06 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 3.00	
[09/26 03:56:06 visual_prompt]: Training 54 / 100 epoch, with learning rate 2.6743911843603128
[09/26 03:56:13 visual_prompt]: Epoch 54 / 100: avg data time: 5.52e-02, avg batch time: 0.4981, average train loss: 5.8903
[09/26 03:56:14 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1677, average loss: 6.1462
[09/26 03:56:14 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 2.00	
[09/26 03:56:14 visual_prompt]: Training 55 / 100 epoch, with learning rate 2.5872487417562526
[09/26 03:56:21 visual_prompt]: Epoch 55 / 100: avg data time: 5.78e-02, avg batch time: 0.4997, average train loss: 5.9064
[09/26 03:56:23 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1674, average loss: 6.1179
[09/26 03:56:23 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 3.50	
[09/26 03:56:23 visual_prompt]: Training 56 / 100 epoch, with learning rate 2.5
[09/26 03:56:29 visual_prompt]: Epoch 56 / 100: avg data time: 6.01e-02, avg batch time: 0.5040, average train loss: 5.9554
[09/26 03:56:31 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1679, average loss: 6.1405
[09/26 03:56:31 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 2.00	
[09/26 03:56:31 visual_prompt]: Training 57 / 100 epoch, with learning rate 2.4127512582437483
[09/26 03:56:38 visual_prompt]: Epoch 57 / 100: avg data time: 5.81e-02, avg batch time: 0.5030, average train loss: 5.7846
[09/26 03:56:39 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1675, average loss: 6.0063
[09/26 03:56:39 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 4.00	
[09/26 03:56:39 visual_prompt]: Training 58 / 100 epoch, with learning rate 2.325608815639687
[09/26 03:56:46 visual_prompt]: Epoch 58 / 100: avg data time: 5.46e-02, avg batch time: 0.4972, average train loss: 5.7466
[09/26 03:56:48 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1676, average loss: 6.0883
[09/26 03:56:48 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 1.50	
[09/26 03:56:48 visual_prompt]: Training 59 / 100 epoch, with learning rate 2.2386788418308665
[09/26 03:56:55 visual_prompt]: Epoch 59 / 100: avg data time: 6.50e-02, avg batch time: 0.5073, average train loss: 5.7396
[09/26 03:56:56 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1670, average loss: 6.0987
[09/26 03:56:56 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.00	
[09/26 03:56:56 visual_prompt]: Training 60 / 100 epoch, with learning rate 2.1520672475998373
[09/26 03:57:03 visual_prompt]: Epoch 60 / 100: avg data time: 5.17e-02, avg batch time: 0.4963, average train loss: 5.6811
[09/26 03:57:04 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1678, average loss: 6.0471
[09/26 03:57:04 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.00	
[09/26 03:57:04 visual_prompt]: Training 61 / 100 epoch, with learning rate 2.0658795558326744
[09/26 03:57:11 visual_prompt]: Epoch 61 / 100: avg data time: 4.51e-02, avg batch time: 0.4884, average train loss: 5.6601
[09/26 03:57:13 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1673, average loss: 5.9989
[09/26 03:57:13 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.00	top5: 4.00	
[09/26 03:57:13 visual_prompt]: Best epoch 61: best metric: 0.020
[09/26 03:57:13 visual_prompt]: Training 62 / 100 epoch, with learning rate 1.980220772955602
[09/26 03:57:19 visual_prompt]: Epoch 62 / 100: avg data time: 5.23e-02, avg batch time: 0.4958, average train loss: 5.6111
[09/26 03:57:21 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1672, average loss: 5.9675
[09/26 03:57:21 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 5.00	
[09/26 03:57:21 visual_prompt]: Training 63 / 100 epoch, with learning rate 1.895195261000831
[09/26 03:57:28 visual_prompt]: Epoch 63 / 100: avg data time: 4.96e-02, avg batch time: 0.4936, average train loss: 5.5021
[09/26 03:57:29 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1673, average loss: 6.1288
[09/26 03:57:29 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.00	
[09/26 03:57:29 visual_prompt]: Training 64 / 100 epoch, with learning rate 1.8109066104575022
[09/26 03:57:36 visual_prompt]: Epoch 64 / 100: avg data time: 5.64e-02, avg batch time: 0.5002, average train loss: 5.5113
[09/26 03:57:38 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1674, average loss: 6.0871
[09/26 03:57:38 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.00	top5: 6.50	
[09/26 03:57:38 visual_prompt]: Training 65 / 100 epoch, with learning rate 1.7274575140626316
[09/26 03:57:45 visual_prompt]: Epoch 65 / 100: avg data time: 4.61e-02, avg batch time: 0.4936, average train loss: 5.3960
[09/26 03:57:46 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1676, average loss: 5.8531
[09/26 03:57:46 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 5.50	
[09/26 03:57:46 visual_prompt]: Training 66 / 100 epoch, with learning rate 1.6449496416858285
[09/26 03:57:53 visual_prompt]: Epoch 66 / 100: avg data time: 6.33e-02, avg batch time: 0.5075, average train loss: 5.2782
[09/26 03:57:54 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1675, average loss: 5.8036
[09/26 03:57:54 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 6.50	
[09/26 03:57:54 visual_prompt]: Training 67 / 100 epoch, with learning rate 1.5634835164602199
[09/26 03:58:01 visual_prompt]: Epoch 67 / 100: avg data time: 5.59e-02, avg batch time: 0.4989, average train loss: 5.2733
[09/26 03:58:03 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1674, average loss: 5.8210
[09/26 03:58:03 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 7.00	
[09/26 03:58:03 visual_prompt]: Training 68 / 100 epoch, with learning rate 1.4831583923104998
[09/26 03:58:10 visual_prompt]: Epoch 68 / 100: avg data time: 5.97e-02, avg batch time: 0.5031, average train loss: 5.2398
[09/26 03:58:11 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1676, average loss: 5.8241
[09/26 03:58:11 visual_prompt]: Classification results with val_vtab-sun397: top1: 3.00	top5: 6.00	
[09/26 03:58:11 visual_prompt]: Best epoch 68: best metric: 0.030
[09/26 03:58:11 visual_prompt]: Training 69 / 100 epoch, with learning rate 1.4040721330273063
[09/26 03:58:18 visual_prompt]: Epoch 69 / 100: avg data time: 4.87e-02, avg batch time: 0.4938, average train loss: 5.1285
[09/26 03:58:20 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1676, average loss: 5.7274
[09/26 03:58:20 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.00	top5: 10.50	
[09/26 03:58:20 visual_prompt]: Training 70 / 100 epoch, with learning rate 1.3263210930352738
[09/26 03:58:26 visual_prompt]: Epoch 70 / 100: avg data time: 5.63e-02, avg batch time: 0.5002, average train loss: 5.3579
[09/26 03:58:28 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1679, average loss: 5.9232
[09/26 03:58:28 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 6.00	
[09/26 03:58:28 visual_prompt]: Training 71 / 100 epoch, with learning rate 1.2500000000000004
[09/26 03:58:35 visual_prompt]: Epoch 71 / 100: avg data time: 6.01e-02, avg batch time: 0.5041, average train loss: 5.2908
[09/26 03:58:36 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1674, average loss: 5.7444
[09/26 03:58:36 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 8.00	
[09/26 03:58:36 visual_prompt]: Training 72 / 100 epoch, with learning rate 1.175201839416988
[09/26 03:58:43 visual_prompt]: Epoch 72 / 100: avg data time: 5.61e-02, avg batch time: 0.4996, average train loss: 5.2918
[09/26 03:58:45 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1678, average loss: 5.7613
[09/26 03:58:45 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.00	top5: 8.00	
[09/26 03:58:45 visual_prompt]: Training 73 / 100 epoch, with learning rate 1.1020177413231333
[09/26 03:58:52 visual_prompt]: Epoch 73 / 100: avg data time: 6.24e-02, avg batch time: 0.5082, average train loss: 5.1483
[09/26 03:58:53 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1674, average loss: 5.7334
[09/26 03:58:53 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 6.50	
[09/26 03:58:53 visual_prompt]: Training 74 / 100 epoch, with learning rate 1.0305368692688175
[09/26 03:59:00 visual_prompt]: Epoch 74 / 100: avg data time: 5.58e-02, avg batch time: 0.5007, average train loss: 5.0802
[09/26 03:59:02 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1678, average loss: 5.7256
[09/26 03:59:02 visual_prompt]: Classification results with val_vtab-sun397: top1: 3.00	top5: 8.00	
[09/26 03:59:02 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.9608463116858543
[09/26 03:59:09 visual_prompt]: Epoch 75 / 100: avg data time: 5.57e-02, avg batch time: 0.4992, average train loss: 5.0217
[09/26 03:59:10 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1678, average loss: 5.8552
[09/26 03:59:10 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 8.00	
[09/26 03:59:10 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.8930309757836516
[09/26 03:59:17 visual_prompt]: Epoch 76 / 100: avg data time: 5.62e-02, avg batch time: 0.4997, average train loss: 5.0321
[09/26 03:59:18 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1677, average loss: 5.6714
[09/26 03:59:18 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.50	top5: 10.00	
[09/26 03:59:18 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.8271734841028553
[09/26 03:59:25 visual_prompt]: Epoch 77 / 100: avg data time: 5.88e-02, avg batch time: 0.5027, average train loss: 4.9294
[09/26 03:59:27 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1676, average loss: 5.6959
[09/26 03:59:27 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 9.50	
[09/26 03:59:27 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.7633540738525066
[09/26 03:59:34 visual_prompt]: Epoch 78 / 100: avg data time: 5.49e-02, avg batch time: 0.4982, average train loss: 4.8993
[09/26 03:59:35 visual_prompt]: Inference (val):avg data time: 2.08e-05, avg batch time: 0.1674, average loss: 5.6518
[09/26 03:59:35 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 10.50	
[09/26 03:59:35 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.7016504991533725
[09/26 03:59:42 visual_prompt]: Epoch 79 / 100: avg data time: 5.83e-02, avg batch time: 0.5022, average train loss: 4.7768
[09/26 03:59:44 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1673, average loss: 5.7879
[09/26 03:59:44 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 10.50	
[09/26 03:59:44 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.6421379363065141
[09/26 03:59:50 visual_prompt]: Epoch 80 / 100: avg data time: 5.67e-02, avg batch time: 0.5008, average train loss: 4.8369
[09/26 03:59:52 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.1674, average loss: 5.7203
[09/26 03:59:52 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.50	top5: 9.50	
[09/26 03:59:52 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.5848888922025552
[09/26 03:59:59 visual_prompt]: Epoch 81 / 100: avg data time: 6.00e-02, avg batch time: 0.5050, average train loss: 4.4979
[09/26 04:00:00 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1674, average loss: 5.4484
[09/26 04:00:00 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.00	top5: 15.00	
[09/26 04:00:00 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.5299731159831953
[09/26 04:00:07 visual_prompt]: Epoch 82 / 100: avg data time: 4.96e-02, avg batch time: 0.4940, average train loss: 4.1943
[09/26 04:00:09 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1678, average loss: 5.2777
[09/26 04:00:09 visual_prompt]: Classification results with val_vtab-sun397: top1: 7.50	top5: 21.00	
[09/26 04:00:09 visual_prompt]: Best epoch 82: best metric: 0.075
[09/26 04:00:09 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.47745751406263165
[09/26 04:00:15 visual_prompt]: Epoch 83 / 100: avg data time: 5.38e-02, avg batch time: 0.4980, average train loss: 3.5474
[09/26 04:00:17 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1674, average loss: 5.0635
[09/26 04:00:17 visual_prompt]: Classification results with val_vtab-sun397: top1: 8.50	top5: 27.00	
[09/26 04:00:17 visual_prompt]: Best epoch 83: best metric: 0.085
[09/26 04:00:17 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.42740606861239594
[09/26 04:00:24 visual_prompt]: Epoch 84 / 100: avg data time: 5.98e-02, avg batch time: 0.5035, average train loss: 2.8384
[09/26 04:00:25 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1672, average loss: 4.9613
[09/26 04:00:25 visual_prompt]: Classification results with val_vtab-sun397: top1: 13.50	top5: 31.50	
[09/26 04:00:25 visual_prompt]: Best epoch 84: best metric: 0.135
[09/26 04:00:25 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.3798797596089351
[09/26 04:00:32 visual_prompt]: Epoch 85 / 100: avg data time: 5.53e-02, avg batch time: 0.4989, average train loss: 2.1060
[09/26 04:00:34 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1674, average loss: 4.8338
[09/26 04:00:34 visual_prompt]: Classification results with val_vtab-sun397: top1: 14.50	top5: 34.50	
[09/26 04:00:34 visual_prompt]: Best epoch 85: best metric: 0.145
[09/26 04:00:34 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.33493649053890323
[09/26 04:00:40 visual_prompt]: Epoch 86 / 100: avg data time: 5.54e-02, avg batch time: 0.5009, average train loss: 1.4722
[09/26 04:00:42 visual_prompt]: Inference (val):avg data time: 1.91e-05, avg batch time: 0.1675, average loss: 4.8029
[09/26 04:00:42 visual_prompt]: Classification results with val_vtab-sun397: top1: 14.50	top5: 36.00	
[09/26 04:00:42 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.29263101785268253
[09/26 04:00:49 visual_prompt]: Epoch 87 / 100: avg data time: 5.56e-02, avg batch time: 0.5009, average train loss: 1.0499
[09/26 04:00:50 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1674, average loss: 4.7159
[09/26 04:00:50 visual_prompt]: Classification results with val_vtab-sun397: top1: 17.00	top5: 36.00	
[09/26 04:00:50 visual_prompt]: Best epoch 87: best metric: 0.170
[09/26 04:00:50 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.25301488425208296
[09/26 04:00:57 visual_prompt]: Epoch 88 / 100: avg data time: 5.49e-02, avg batch time: 0.4989, average train loss: 0.7423
[09/26 04:00:59 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1674, average loss: 4.7174
[09/26 04:00:59 visual_prompt]: Classification results with val_vtab-sun397: top1: 17.50	top5: 36.00	
[09/26 04:00:59 visual_prompt]: Best epoch 88: best metric: 0.175
[09/26 04:00:59 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.21613635589349756
[09/26 04:01:05 visual_prompt]: Epoch 89 / 100: avg data time: 5.72e-02, avg batch time: 0.5015, average train loss: 0.5424
[09/26 04:01:07 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1678, average loss: 4.6927
[09/26 04:01:07 visual_prompt]: Classification results with val_vtab-sun397: top1: 18.50	top5: 37.50	
[09/26 04:01:07 visual_prompt]: Best epoch 89: best metric: 0.185
[09/26 04:01:07 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.18204036358303172
[09/26 04:01:14 visual_prompt]: Epoch 90 / 100: avg data time: 4.71e-02, avg batch time: 0.4908, average train loss: 0.4271
[09/26 04:01:15 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1675, average loss: 4.6569
[09/26 04:01:15 visual_prompt]: Classification results with val_vtab-sun397: top1: 19.50	top5: 38.50	
[09/26 04:01:15 visual_prompt]: Best epoch 90: best metric: 0.195
[09/26 04:01:15 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.1507684480352292
[09/26 04:01:22 visual_prompt]: Epoch 91 / 100: avg data time: 4.81e-02, avg batch time: 0.4924, average train loss: 0.3532
[09/26 04:01:24 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1676, average loss: 4.6725
[09/26 04:01:24 visual_prompt]: Classification results with val_vtab-sun397: top1: 20.00	top5: 38.50	
[09/26 04:01:24 visual_prompt]: Best epoch 91: best metric: 0.200
[09/26 04:01:24 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.12235870926211617
[09/26 04:01:30 visual_prompt]: Epoch 92 / 100: avg data time: 5.31e-02, avg batch time: 0.4976, average train loss: 0.3118
[09/26 04:01:32 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1675, average loss: 4.6479
[09/26 04:01:32 visual_prompt]: Classification results with val_vtab-sun397: top1: 20.00	top5: 38.50	
[09/26 04:01:32 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.09684576015420276
[09/26 04:01:39 visual_prompt]: Epoch 93 / 100: avg data time: 5.75e-02, avg batch time: 0.5015, average train loss: 0.2826
[09/26 04:01:40 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1672, average loss: 4.6293
[09/26 04:01:40 visual_prompt]: Classification results with val_vtab-sun397: top1: 19.50	top5: 40.00	
[09/26 04:01:40 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.07426068431000882
[09/26 04:01:47 visual_prompt]: Epoch 94 / 100: avg data time: 4.62e-02, avg batch time: 0.4917, average train loss: 0.2603
[09/26 04:01:49 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1674, average loss: 4.6420
[09/26 04:01:49 visual_prompt]: Classification results with val_vtab-sun397: top1: 19.50	top5: 39.00	
[09/26 04:01:49 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.05463099816548578
[09/26 04:01:55 visual_prompt]: Epoch 95 / 100: avg data time: 5.46e-02, avg batch time: 0.4986, average train loss: 0.2501
[09/26 04:01:57 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1673, average loss: 4.6202
[09/26 04:01:57 visual_prompt]: Classification results with val_vtab-sun397: top1: 20.00	top5: 40.50	
[09/26 04:01:57 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.03798061746947995
[09/26 04:02:04 visual_prompt]: Epoch 96 / 100: avg data time: 5.34e-02, avg batch time: 0.4968, average train loss: 0.2429
[09/26 04:02:05 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1674, average loss: 4.6459
[09/26 04:02:05 visual_prompt]: Classification results with val_vtab-sun397: top1: 20.50	top5: 40.00	
[09/26 04:02:05 visual_prompt]: Best epoch 96: best metric: 0.205
[09/26 04:02:05 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.024329828146074095
[09/26 04:02:12 visual_prompt]: Epoch 97 / 100: avg data time: 5.70e-02, avg batch time: 0.5016, average train loss: 0.2381
[09/26 04:02:14 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1672, average loss: 4.6345
[09/26 04:02:14 visual_prompt]: Classification results with val_vtab-sun397: top1: 19.50	top5: 40.50	
[09/26 04:02:14 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.013695261579316775
[09/26 04:02:20 visual_prompt]: Epoch 98 / 100: avg data time: 4.82e-02, avg batch time: 0.4929, average train loss: 0.2329
[09/26 04:02:22 visual_prompt]: Inference (val):avg data time: 1.95e-05, avg batch time: 0.1674, average loss: 4.6325
[09/26 04:02:22 visual_prompt]: Classification results with val_vtab-sun397: top1: 20.00	top5: 40.00	
[09/26 04:02:22 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.006089874350439506
[09/26 04:02:29 visual_prompt]: Epoch 99 / 100: avg data time: 5.55e-02, avg batch time: 0.4990, average train loss: 0.2319
[09/26 04:02:30 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1674, average loss: 4.6365
[09/26 04:02:30 visual_prompt]: Classification results with val_vtab-sun397: top1: 20.00	top5: 40.00	
[09/26 04:02:30 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0015229324522605947
[09/26 04:02:37 visual_prompt]: Epoch 100 / 100: avg data time: 6.66e-02, avg batch time: 0.5100, average train loss: 0.2296
[09/26 04:02:39 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1673, average loss: 4.6371
[09/26 04:02:39 visual_prompt]: Classification results with val_vtab-sun397: top1: 20.00	top5: 40.00	
[09/26 04:02:39 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 04:02:39 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              0
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 04:02:39 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-sun397', 'DATA.NUMBER_CLASSES', '397', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 04:02:39 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 04:02:39 visual_prompt]: Training with config:
[09/26 04:02:39 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-sun397/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr5.0_wd0.0001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 5.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-sun397', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 397, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 04:02:39 visual_prompt]: Loading training data...
[09/26 04:02:39 visual_prompt]: Constructing vtab-sun397 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split train[:800], from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/26 04:02:40 visual_prompt]: Number of images: 800
[09/26 04:02:40 visual_prompt]: Number of classes: 309 / 397
[09/26 04:02:40 visual_prompt]: Loading validation data...
[09/26 04:02:40 visual_prompt]: Constructing vtab-sun397 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split validation[:200], from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/26 04:02:41 visual_prompt]: Number of images: 200
[09/26 04:02:41 visual_prompt]: Number of classes: 136 / 397
[09/26 04:02:41 visual_prompt]: Constructing models...
[09/26 04:02:43 visual_prompt]: Total Parameters: 86564749	 Gradient Parameters: 766093
[09/26 04:02:43 visual_prompt]: tuned percent:0.885
[09/26 04:02:43 visual_prompt]: Device used for model: 0
[09/26 04:02:43 visual_prompt]: Setting up Evaluator...
[09/26 04:02:43 visual_prompt]: Setting up Trainer...
[09/26 04:02:43 visual_prompt]: 	Setting up the optimizer...
[09/26 04:02:43 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 04:02:50 visual_prompt]: Epoch 1 / 100: avg data time: 5.97e-02, avg batch time: 0.5026, average train loss: 5.9898
[09/26 04:02:52 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.1668, average loss: 6.0097
[09/26 04:02:52 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/26 04:02:52 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.5
[09/26 04:02:58 visual_prompt]: Epoch 2 / 100: avg data time: 5.55e-02, avg batch time: 0.4979, average train loss: 5.7795
[09/26 04:03:00 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1670, average loss: 5.8157
[09/26 04:03:00 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.50	
[09/26 04:03:00 visual_prompt]: Best epoch 2: best metric: 0.010
[09/26 04:03:00 visual_prompt]: Training 3 / 100 epoch, with learning rate 1.0
[09/26 04:03:07 visual_prompt]: Epoch 3 / 100: avg data time: 5.69e-02, avg batch time: 0.5010, average train loss: 5.6351
[09/26 04:03:08 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1669, average loss: 5.8419
[09/26 04:03:08 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 04:03:08 visual_prompt]: Training 4 / 100 epoch, with learning rate 1.5
[09/26 04:03:15 visual_prompt]: Epoch 4 / 100: avg data time: 5.62e-02, avg batch time: 0.4995, average train loss: 5.6153
[09/26 04:03:17 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1671, average loss: 5.7295
[09/26 04:03:17 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 8.50	
[09/26 04:03:17 visual_prompt]: Best epoch 4: best metric: 0.015
[09/26 04:03:17 visual_prompt]: Training 5 / 100 epoch, with learning rate 2.0
[09/26 04:03:24 visual_prompt]: Epoch 5 / 100: avg data time: 6.48e-02, avg batch time: 0.5086, average train loss: 5.6289
[09/26 04:03:25 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1677, average loss: 5.8160
[09/26 04:03:25 visual_prompt]: Classification results with val_vtab-sun397: top1: 3.00	top5: 5.50	
[09/26 04:03:25 visual_prompt]: Best epoch 5: best metric: 0.030
[09/26 04:03:25 visual_prompt]: Training 6 / 100 epoch, with learning rate 2.5
[09/26 04:03:32 visual_prompt]: Epoch 6 / 100: avg data time: 5.44e-02, avg batch time: 0.4975, average train loss: 5.3637
[09/26 04:03:34 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1677, average loss: 5.5697
[09/26 04:03:34 visual_prompt]: Classification results with val_vtab-sun397: top1: 4.00	top5: 11.00	
[09/26 04:03:34 visual_prompt]: Best epoch 6: best metric: 0.040
[09/26 04:03:34 visual_prompt]: Training 7 / 100 epoch, with learning rate 3.0
[09/26 04:03:40 visual_prompt]: Epoch 7 / 100: avg data time: 5.35e-02, avg batch time: 0.4961, average train loss: 4.9364
[09/26 04:03:42 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1674, average loss: 7.5935
[09/26 04:03:42 visual_prompt]: Classification results with val_vtab-sun397: top1: 4.00	top5: 15.00	
[09/26 04:03:42 visual_prompt]: Training 8 / 100 epoch, with learning rate 3.5
[09/26 04:03:49 visual_prompt]: Epoch 8 / 100: avg data time: 6.51e-02, avg batch time: 0.5082, average train loss: 5.2337
[09/26 04:03:50 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.1675, average loss: 5.4710
[09/26 04:03:50 visual_prompt]: Classification results with val_vtab-sun397: top1: 8.00	top5: 22.50	
[09/26 04:03:50 visual_prompt]: Best epoch 8: best metric: 0.080
[09/26 04:03:50 visual_prompt]: Training 9 / 100 epoch, with learning rate 4.0
[09/26 04:03:57 visual_prompt]: Epoch 9 / 100: avg data time: 5.40e-02, avg batch time: 0.4971, average train loss: 6.0444
[09/26 04:03:59 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1673, average loss: 20.7781
[09/26 04:03:59 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 7.50	
[09/26 04:03:59 visual_prompt]: Training 10 / 100 epoch, with learning rate 4.5
[09/26 04:04:06 visual_prompt]: Epoch 10 / 100: avg data time: 6.63e-02, avg batch time: 0.5088, average train loss: 9.4532
[09/26 04:04:07 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1677, average loss: 6.6919
[09/26 04:04:07 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 7.50	
[09/26 04:04:07 visual_prompt]: Training 11 / 100 epoch, with learning rate 5.0
[09/26 04:04:14 visual_prompt]: Epoch 11 / 100: avg data time: 6.63e-02, avg batch time: 0.5106, average train loss: 7.2029
[09/26 04:04:16 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1676, average loss: 5.9944
[09/26 04:04:16 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 11.00	
[09/26 04:04:16 visual_prompt]: Training 12 / 100 epoch, with learning rate 4.998477067547739
[09/26 04:04:23 visual_prompt]: Epoch 12 / 100: avg data time: 5.75e-02, avg batch time: 0.5013, average train loss: 5.5803
[09/26 04:04:24 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1676, average loss: 5.7416
[09/26 04:04:24 visual_prompt]: Classification results with val_vtab-sun397: top1: 5.00	top5: 19.00	
[09/26 04:04:24 visual_prompt]: Training 13 / 100 epoch, with learning rate 4.993910125649561
[09/26 04:04:31 visual_prompt]: Epoch 13 / 100: avg data time: 6.03e-02, avg batch time: 0.5038, average train loss: 5.6804
[09/26 04:04:33 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1679, average loss: 5.3948
[09/26 04:04:33 visual_prompt]: Classification results with val_vtab-sun397: top1: 8.00	top5: 24.00	
[09/26 04:04:33 visual_prompt]: Training 14 / 100 epoch, with learning rate 4.986304738420683
[09/26 04:04:39 visual_prompt]: Epoch 14 / 100: avg data time: 5.56e-02, avg batch time: 0.5002, average train loss: 4.5661
[09/26 04:04:41 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1675, average loss: 5.0721
[09/26 04:04:41 visual_prompt]: Classification results with val_vtab-sun397: top1: 13.50	top5: 33.00	
[09/26 04:04:41 visual_prompt]: Best epoch 14: best metric: 0.135
[09/26 04:04:41 visual_prompt]: Training 15 / 100 epoch, with learning rate 4.975670171853926
[09/26 04:04:48 visual_prompt]: Epoch 15 / 100: avg data time: 6.12e-02, avg batch time: 0.5040, average train loss: 4.1249
[09/26 04:04:50 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1675, average loss: 5.0473
[09/26 04:04:50 visual_prompt]: Classification results with val_vtab-sun397: top1: 14.00	top5: 30.50	
[09/26 04:04:50 visual_prompt]: Best epoch 15: best metric: 0.140
[09/26 04:04:50 visual_prompt]: Training 16 / 100 epoch, with learning rate 4.962019382530521
[09/26 04:04:56 visual_prompt]: Epoch 16 / 100: avg data time: 6.41e-02, avg batch time: 0.5091, average train loss: 3.6367
[09/26 04:04:58 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1679, average loss: 5.0150
[09/26 04:04:58 visual_prompt]: Classification results with val_vtab-sun397: top1: 19.00	top5: 38.00	
[09/26 04:04:58 visual_prompt]: Best epoch 16: best metric: 0.190
[09/26 04:04:58 visual_prompt]: Training 17 / 100 epoch, with learning rate 4.945369001834514
[09/26 04:05:05 visual_prompt]: Epoch 17 / 100: avg data time: 5.63e-02, avg batch time: 0.4992, average train loss: 4.0136
[09/26 04:05:06 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1672, average loss: 6.5413
[09/26 04:05:06 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.50	top5: 15.50	
[09/26 04:05:06 visual_prompt]: Training 18 / 100 epoch, with learning rate 4.925739315689991
[09/26 04:05:13 visual_prompt]: Epoch 18 / 100: avg data time: 5.96e-02, avg batch time: 0.5030, average train loss: 6.3386
[09/26 04:05:15 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1678, average loss: 5.9380
[09/26 04:05:15 visual_prompt]: Classification results with val_vtab-sun397: top1: 10.00	top5: 22.50	
[09/26 04:05:15 visual_prompt]: Training 19 / 100 epoch, with learning rate 4.903154239845797
[09/26 04:05:22 visual_prompt]: Epoch 19 / 100: avg data time: 6.26e-02, avg batch time: 0.5061, average train loss: 6.9097
[09/26 04:05:23 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1673, average loss: 5.9386
[09/26 04:05:23 visual_prompt]: Classification results with val_vtab-sun397: top1: 5.00	top5: 12.00	
[09/26 04:05:23 visual_prompt]: Training 20 / 100 epoch, with learning rate 4.877641290737884
[09/26 04:05:30 visual_prompt]: Epoch 20 / 100: avg data time: 6.67e-02, avg batch time: 0.5109, average train loss: 5.1942
[09/26 04:05:32 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1676, average loss: 5.4078
[09/26 04:05:32 visual_prompt]: Classification results with val_vtab-sun397: top1: 7.50	top5: 23.00	
[09/26 04:05:32 visual_prompt]: Training 21 / 100 epoch, with learning rate 4.849231551964771
[09/26 04:05:39 visual_prompt]: Epoch 21 / 100: avg data time: 5.01e-02, avg batch time: 0.4947, average train loss: 4.6425
[09/26 04:05:40 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1678, average loss: 4.9747
[09/26 04:05:40 visual_prompt]: Classification results with val_vtab-sun397: top1: 13.00	top5: 34.00	
[09/26 04:05:40 visual_prompt]: Training 22 / 100 epoch, with learning rate 4.817959636416969
[09/26 04:05:47 visual_prompt]: Epoch 22 / 100: avg data time: 6.13e-02, avg batch time: 0.5043, average train loss: 2.8348
[09/26 04:05:49 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1674, average loss: 5.6619
[09/26 04:05:49 visual_prompt]: Classification results with val_vtab-sun397: top1: 15.00	top5: 36.50	
[09/26 04:05:49 visual_prompt]: Training 23 / 100 epoch, with learning rate 4.783863644106502
[09/26 04:05:56 visual_prompt]: Epoch 23 / 100: avg data time: 6.05e-02, avg batch time: 0.5041, average train loss: 1.8933
[09/26 04:05:57 visual_prompt]: Inference (val):avg data time: 3.92e-05, avg batch time: 0.1674, average loss: 5.5846
[09/26 04:05:57 visual_prompt]: Classification results with val_vtab-sun397: top1: 19.50	top5: 39.50	
[09/26 04:05:57 visual_prompt]: Best epoch 23: best metric: 0.195
[09/26 04:05:57 visual_prompt]: Training 24 / 100 epoch, with learning rate 4.7469851157479175
[09/26 04:06:04 visual_prompt]: Epoch 24 / 100: avg data time: 4.69e-02, avg batch time: 0.4909, average train loss: 1.2297
[09/26 04:06:06 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.1675, average loss: 5.2376
[09/26 04:06:06 visual_prompt]: Classification results with val_vtab-sun397: top1: 19.50	top5: 45.00	
[09/26 04:06:06 visual_prompt]: Training 25 / 100 epoch, with learning rate 4.707368982147317
[09/26 04:06:13 visual_prompt]: Epoch 25 / 100: avg data time: 6.22e-02, avg batch time: 0.5058, average train loss: 1.9078
[09/26 04:06:14 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1674, average loss: 5.9018
[09/26 04:06:14 visual_prompt]: Classification results with val_vtab-sun397: top1: 17.50	top5: 44.50	
[09/26 04:06:14 visual_prompt]: Training 26 / 100 epoch, with learning rate 4.665063509461097
[09/26 04:06:21 visual_prompt]: Epoch 26 / 100: avg data time: 6.49e-02, avg batch time: 0.5092, average train loss: 2.0064
[09/26 04:06:23 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1675, average loss: 5.7473
[09/26 04:06:23 visual_prompt]: Classification results with val_vtab-sun397: top1: 15.50	top5: 41.00	
[09/26 04:06:23 visual_prompt]: Training 27 / 100 epoch, with learning rate 4.620120240391064
[09/26 04:06:30 visual_prompt]: Epoch 27 / 100: avg data time: 5.69e-02, avg batch time: 0.5006, average train loss: 1.6576
[09/26 04:06:31 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1676, average loss: 4.7231
[09/26 04:06:31 visual_prompt]: Classification results with val_vtab-sun397: top1: 29.00	top5: 50.50	
[09/26 04:06:31 visual_prompt]: Best epoch 27: best metric: 0.290
[09/26 04:06:31 visual_prompt]: Training 28 / 100 epoch, with learning rate 4.572593931387604
[09/26 04:06:38 visual_prompt]: Epoch 28 / 100: avg data time: 5.86e-02, avg batch time: 0.5019, average train loss: 0.6997
[09/26 04:06:40 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1678, average loss: 4.9274
[09/26 04:06:40 visual_prompt]: Classification results with val_vtab-sun397: top1: 23.50	top5: 49.50	
[09/26 04:06:40 visual_prompt]: Training 29 / 100 epoch, with learning rate 4.522542485937368
[09/26 04:06:46 visual_prompt]: Epoch 29 / 100: avg data time: 5.80e-02, avg batch time: 0.5013, average train loss: 0.3843
[09/26 04:06:48 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1676, average loss: 5.1919
[09/26 04:06:48 visual_prompt]: Classification results with val_vtab-sun397: top1: 23.50	top5: 48.50	
[09/26 04:06:48 visual_prompt]: Training 30 / 100 epoch, with learning rate 4.4700268840168045
[09/26 04:06:55 visual_prompt]: Epoch 30 / 100: avg data time: 5.08e-02, avg batch time: 0.4954, average train loss: 0.2544
[09/26 04:06:56 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1674, average loss: 5.0686
[09/26 04:06:56 visual_prompt]: Classification results with val_vtab-sun397: top1: 26.50	top5: 52.50	
[09/26 04:06:56 visual_prompt]: Training 31 / 100 epoch, with learning rate 4.415111107797445
[09/26 04:07:03 visual_prompt]: Epoch 31 / 100: avg data time: 5.45e-02, avg batch time: 0.4982, average train loss: 0.2218
[09/26 04:07:05 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1673, average loss: 4.8973
[09/26 04:07:05 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.50	top5: 52.00	
[09/26 04:07:05 visual_prompt]: Training 32 / 100 epoch, with learning rate 4.357862063693486
[09/26 04:07:11 visual_prompt]: Epoch 32 / 100: avg data time: 5.55e-02, avg batch time: 0.5003, average train loss: 0.1666
[09/26 04:07:13 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1676, average loss: 4.8021
[09/26 04:07:13 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.50	top5: 54.00	
[09/26 04:07:13 visual_prompt]: Training 33 / 100 epoch, with learning rate 4.298349500846628
[09/26 04:07:20 visual_prompt]: Epoch 33 / 100: avg data time: 5.77e-02, avg batch time: 0.5021, average train loss: 0.1849
[09/26 04:07:21 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1674, average loss: 5.5438
[09/26 04:07:21 visual_prompt]: Classification results with val_vtab-sun397: top1: 25.00	top5: 51.50	
[09/26 04:07:21 visual_prompt]: Training 34 / 100 epoch, with learning rate 4.236645926147493
[09/26 04:07:28 visual_prompt]: Epoch 34 / 100: avg data time: 6.29e-02, avg batch time: 0.5095, average train loss: 0.1224
[09/26 04:07:30 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1672, average loss: 4.7263
[09/26 04:07:30 visual_prompt]: Classification results with val_vtab-sun397: top1: 32.00	top5: 56.50	
[09/26 04:07:30 visual_prompt]: Best epoch 34: best metric: 0.320
[09/26 04:07:30 visual_prompt]: Training 35 / 100 epoch, with learning rate 4.172826515897146
[09/26 04:07:37 visual_prompt]: Epoch 35 / 100: avg data time: 6.28e-02, avg batch time: 0.5080, average train loss: 0.0522
[09/26 04:07:38 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1678, average loss: 4.2666
[09/26 04:07:38 visual_prompt]: Classification results with val_vtab-sun397: top1: 31.00	top5: 61.00	
[09/26 04:07:38 visual_prompt]: Training 36 / 100 epoch, with learning rate 4.106969024216348
[09/26 04:07:45 visual_prompt]: Epoch 36 / 100: avg data time: 6.29e-02, avg batch time: 0.5065, average train loss: 0.0340
[09/26 04:07:47 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1675, average loss: 4.0227
[09/26 04:07:47 visual_prompt]: Classification results with val_vtab-sun397: top1: 31.00	top5: 59.00	
[09/26 04:07:47 visual_prompt]: Training 37 / 100 epoch, with learning rate 4.039153688314146
[09/26 04:07:54 visual_prompt]: Epoch 37 / 100: avg data time: 5.92e-02, avg batch time: 0.5038, average train loss: 0.0212
[09/26 04:07:55 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1676, average loss: 3.9120
[09/26 04:07:55 visual_prompt]: Classification results with val_vtab-sun397: top1: 31.00	top5: 60.00	
[09/26 04:07:55 visual_prompt]: Training 38 / 100 epoch, with learning rate 3.969463130731183
[09/26 04:08:02 visual_prompt]: Epoch 38 / 100: avg data time: 5.07e-02, avg batch time: 0.4964, average train loss: 0.0107
[09/26 04:08:03 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1679, average loss: 3.7844
[09/26 04:08:03 visual_prompt]: Classification results with val_vtab-sun397: top1: 32.50	top5: 58.50	
[09/26 04:08:03 visual_prompt]: Best epoch 38: best metric: 0.325
[09/26 04:08:03 visual_prompt]: Training 39 / 100 epoch, with learning rate 3.897982258676867
[09/26 04:08:10 visual_prompt]: Epoch 39 / 100: avg data time: 4.41e-02, avg batch time: 0.4890, average train loss: 0.0179
[09/26 04:08:12 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1674, average loss: 3.7474
[09/26 04:08:12 visual_prompt]: Classification results with val_vtab-sun397: top1: 32.50	top5: 61.50	
[09/26 04:08:12 visual_prompt]: Training 40 / 100 epoch, with learning rate 3.824798160583012
[09/26 04:08:19 visual_prompt]: Epoch 40 / 100: avg data time: 5.39e-02, avg batch time: 0.4981, average train loss: 0.0154
[09/26 04:08:20 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1674, average loss: 3.8307
[09/26 04:08:20 visual_prompt]: Classification results with val_vtab-sun397: top1: 35.00	top5: 60.50	
[09/26 04:08:20 visual_prompt]: Best epoch 40: best metric: 0.350
[09/26 04:08:20 visual_prompt]: Training 41 / 100 epoch, with learning rate 3.75
[09/26 04:08:27 visual_prompt]: Epoch 41 / 100: avg data time: 5.69e-02, avg batch time: 0.5015, average train loss: 0.0132
[09/26 04:08:28 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1676, average loss: 3.7201
[09/26 04:08:28 visual_prompt]: Classification results with val_vtab-sun397: top1: 32.50	top5: 61.50	
[09/26 04:08:28 visual_prompt]: Training 42 / 100 epoch, with learning rate 3.673678906964727
[09/26 04:08:35 visual_prompt]: Epoch 42 / 100: avg data time: 5.53e-02, avg batch time: 0.4999, average train loss: 0.0107
[09/26 04:08:37 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1674, average loss: 3.5495
[09/26 04:08:37 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 61.50	
[09/26 04:08:37 visual_prompt]: Training 43 / 100 epoch, with learning rate 3.5959278669726933
[09/26 04:08:44 visual_prompt]: Epoch 43 / 100: avg data time: 5.57e-02, avg batch time: 0.5004, average train loss: 0.0111
[09/26 04:08:45 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1676, average loss: 3.4766
[09/26 04:08:45 visual_prompt]: Classification results with val_vtab-sun397: top1: 32.50	top5: 62.00	
[09/26 04:08:45 visual_prompt]: Training 44 / 100 epoch, with learning rate 3.516841607689501
[09/26 04:08:52 visual_prompt]: Epoch 44 / 100: avg data time: 6.50e-02, avg batch time: 0.5099, average train loss: 0.0117
[09/26 04:08:54 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1676, average loss: 3.4315
[09/26 04:08:54 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.00	top5: 62.00	
[09/26 04:08:54 visual_prompt]: Training 45 / 100 epoch, with learning rate 3.4365164835397803
[09/26 04:09:01 visual_prompt]: Epoch 45 / 100: avg data time: 5.61e-02, avg batch time: 0.5001, average train loss: 0.0123
[09/26 04:09:02 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1677, average loss: 3.3960
[09/26 04:09:02 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.00	top5: 62.00	
[09/26 04:09:02 visual_prompt]: Training 46 / 100 epoch, with learning rate 3.3550503583141724
[09/26 04:09:09 visual_prompt]: Epoch 46 / 100: avg data time: 5.63e-02, avg batch time: 0.5006, average train loss: 0.0147
[09/26 04:09:10 visual_prompt]: Inference (val):avg data time: 2.00e-05, avg batch time: 0.1675, average loss: 3.3643
[09/26 04:09:10 visual_prompt]: Classification results with val_vtab-sun397: top1: 32.50	top5: 62.00	
[09/26 04:09:10 visual_prompt]: Training 47 / 100 epoch, with learning rate 3.2725424859373686
[09/26 04:09:17 visual_prompt]: Epoch 47 / 100: avg data time: 4.82e-02, avg batch time: 0.4930, average train loss: 0.0155
[09/26 04:09:19 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1676, average loss: 3.3523
[09/26 04:09:19 visual_prompt]: Classification results with val_vtab-sun397: top1: 32.00	top5: 62.00	
[09/26 04:09:19 visual_prompt]: Training 48 / 100 epoch, with learning rate 3.1890933895424975
[09/26 04:09:26 visual_prompt]: Epoch 48 / 100: avg data time: 5.45e-02, avg batch time: 0.4985, average train loss: 0.0171
[09/26 04:09:27 visual_prompt]: Inference (val):avg data time: 2.00e-05, avg batch time: 0.1673, average loss: 3.3180
[09/26 04:09:27 visual_prompt]: Classification results with val_vtab-sun397: top1: 36.00	top5: 63.00	
[09/26 04:09:27 visual_prompt]: Best epoch 48: best metric: 0.360
[09/26 04:09:27 visual_prompt]: Training 49 / 100 epoch, with learning rate 3.104804738999169
[09/26 04:09:34 visual_prompt]: Epoch 49 / 100: avg data time: 5.49e-02, avg batch time: 0.4993, average train loss: 0.0169
[09/26 04:09:35 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1673, average loss: 3.3010
[09/26 04:09:35 visual_prompt]: Classification results with val_vtab-sun397: top1: 35.50	top5: 63.00	
[09/26 04:09:35 visual_prompt]: Training 50 / 100 epoch, with learning rate 3.019779227044398
[09/26 04:09:42 visual_prompt]: Epoch 50 / 100: avg data time: 5.51e-02, avg batch time: 0.4993, average train loss: 0.0179
[09/26 04:09:44 visual_prompt]: Inference (val):avg data time: 2.01e-05, avg batch time: 0.1673, average loss: 3.2539
[09/26 04:09:44 visual_prompt]: Classification results with val_vtab-sun397: top1: 36.50	top5: 63.00	
[09/26 04:09:44 visual_prompt]: Best epoch 50: best metric: 0.365
[09/26 04:09:44 visual_prompt]: Training 51 / 100 epoch, with learning rate 2.934120444167326
[09/26 04:09:51 visual_prompt]: Epoch 51 / 100: avg data time: 5.71e-02, avg batch time: 0.5018, average train loss: 0.0188
[09/26 04:09:52 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1673, average loss: 3.2347
[09/26 04:09:52 visual_prompt]: Classification results with val_vtab-sun397: top1: 36.00	top5: 63.00	
[09/26 04:09:52 visual_prompt]: Training 52 / 100 epoch, with learning rate 2.8479327524001636
[09/26 04:09:59 visual_prompt]: Epoch 52 / 100: avg data time: 5.95e-02, avg batch time: 0.5042, average train loss: 0.0192
[09/26 04:10:01 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1679, average loss: 3.2134
[09/26 04:10:01 visual_prompt]: Classification results with val_vtab-sun397: top1: 36.00	top5: 63.50	
[09/26 04:10:01 visual_prompt]: Training 53 / 100 epoch, with learning rate 2.761321158169134
[09/26 04:10:08 visual_prompt]: Epoch 53 / 100: avg data time: 5.69e-02, avg batch time: 0.5022, average train loss: 0.0196
[09/26 04:10:09 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1678, average loss: 3.2088
[09/26 04:10:09 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.00	top5: 62.50	
[09/26 04:10:09 visual_prompt]: Best epoch 53: best metric: 0.370
[09/26 04:10:09 visual_prompt]: Training 54 / 100 epoch, with learning rate 2.6743911843603128
[09/26 04:10:16 visual_prompt]: Epoch 54 / 100: avg data time: 6.09e-02, avg batch time: 0.5055, average train loss: 0.0195
[09/26 04:10:18 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1675, average loss: 3.2121
[09/26 04:10:18 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.00	top5: 63.00	
[09/26 04:10:18 visual_prompt]: Training 55 / 100 epoch, with learning rate 2.5872487417562526
[09/26 04:10:24 visual_prompt]: Epoch 55 / 100: avg data time: 6.12e-02, avg batch time: 0.5058, average train loss: 0.0191
[09/26 04:10:26 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1672, average loss: 3.2018
[09/26 04:10:26 visual_prompt]: Classification results with val_vtab-sun397: top1: 36.00	top5: 63.00	
[09/26 04:10:26 visual_prompt]: Training 56 / 100 epoch, with learning rate 2.5
[09/26 04:10:33 visual_prompt]: Epoch 56 / 100: avg data time: 5.95e-02, avg batch time: 0.5041, average train loss: 0.0194
[09/26 04:10:34 visual_prompt]: Inference (val):avg data time: 1.90e-05, avg batch time: 0.1675, average loss: 3.1971
[09/26 04:10:34 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.50	top5: 63.50	
[09/26 04:10:34 visual_prompt]: Best epoch 56: best metric: 0.375
[09/26 04:10:34 visual_prompt]: Training 57 / 100 epoch, with learning rate 2.4127512582437483
[09/26 04:10:41 visual_prompt]: Epoch 57 / 100: avg data time: 5.30e-02, avg batch time: 0.4966, average train loss: 0.0204
[09/26 04:10:43 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1676, average loss: 3.1687
[09/26 04:10:43 visual_prompt]: Classification results with val_vtab-sun397: top1: 35.50	top5: 62.50	
[09/26 04:10:43 visual_prompt]: Training 58 / 100 epoch, with learning rate 2.325608815639687
[09/26 04:10:50 visual_prompt]: Epoch 58 / 100: avg data time: 5.95e-02, avg batch time: 0.5035, average train loss: 0.0208
[09/26 04:10:51 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1674, average loss: 3.1891
[09/26 04:10:51 visual_prompt]: Classification results with val_vtab-sun397: top1: 36.00	top5: 63.00	
[09/26 04:10:51 visual_prompt]: Training 59 / 100 epoch, with learning rate 2.2386788418308665
[09/26 04:10:58 visual_prompt]: Epoch 59 / 100: avg data time: 4.75e-02, avg batch time: 0.4927, average train loss: 0.0199
[09/26 04:11:00 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1674, average loss: 3.1831
[09/26 04:11:00 visual_prompt]: Classification results with val_vtab-sun397: top1: 36.50	top5: 63.00	
[09/26 04:11:00 visual_prompt]: Training 60 / 100 epoch, with learning rate 2.1520672475998373
[09/26 04:11:06 visual_prompt]: Epoch 60 / 100: avg data time: 5.84e-02, avg batch time: 0.5019, average train loss: 0.0195
[09/26 04:11:08 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1675, average loss: 3.1968
[09/26 04:11:08 visual_prompt]: Classification results with val_vtab-sun397: top1: 36.50	top5: 62.50	
[09/26 04:11:08 visual_prompt]: Training 61 / 100 epoch, with learning rate 2.0658795558326744
[09/26 04:11:15 visual_prompt]: Epoch 61 / 100: avg data time: 5.87e-02, avg batch time: 0.5024, average train loss: 0.0196
[09/26 04:11:16 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1675, average loss: 3.1844
[09/26 04:11:16 visual_prompt]: Classification results with val_vtab-sun397: top1: 36.00	top5: 62.00	
[09/26 04:11:16 visual_prompt]: Training 62 / 100 epoch, with learning rate 1.980220772955602
[09/26 04:11:23 visual_prompt]: Epoch 62 / 100: avg data time: 6.94e-02, avg batch time: 0.5129, average train loss: 0.0195
[09/26 04:11:25 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1674, average loss: 3.1315
[09/26 04:11:25 visual_prompt]: Classification results with val_vtab-sun397: top1: 36.00	top5: 61.50	
[09/26 04:11:25 visual_prompt]: Training 63 / 100 epoch, with learning rate 1.895195261000831
[09/26 04:11:32 visual_prompt]: Epoch 63 / 100: avg data time: 6.21e-02, avg batch time: 0.5069, average train loss: 0.0199
[09/26 04:11:33 visual_prompt]: Inference (val):avg data time: 2.02e-05, avg batch time: 0.1675, average loss: 3.1507
[09/26 04:11:33 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.00	top5: 62.00	
[09/26 04:11:33 visual_prompt]: Best epoch 63: best metric: 0.380
[09/26 04:11:33 visual_prompt]: Training 64 / 100 epoch, with learning rate 1.8109066104575022
[09/26 04:11:40 visual_prompt]: Epoch 64 / 100: avg data time: 6.71e-02, avg batch time: 0.5103, average train loss: 0.0196
[09/26 04:11:42 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1673, average loss: 3.1794
[09/26 04:11:42 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.50	top5: 62.00	
[09/26 04:11:42 visual_prompt]: Training 65 / 100 epoch, with learning rate 1.7274575140626316
[09/26 04:11:49 visual_prompt]: Epoch 65 / 100: avg data time: 5.62e-02, avg batch time: 0.5006, average train loss: 0.0213
[09/26 04:11:50 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1673, average loss: 3.1541
[09/26 04:11:50 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.00	top5: 61.50	
[09/26 04:11:50 visual_prompt]: Training 66 / 100 epoch, with learning rate 1.6449496416858285
[09/26 04:11:57 visual_prompt]: Epoch 66 / 100: avg data time: 5.98e-02, avg batch time: 0.5043, average train loss: 0.0199
[09/26 04:11:59 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1675, average loss: 3.1644
[09/26 04:11:59 visual_prompt]: Classification results with val_vtab-sun397: top1: 36.50	top5: 62.50	
[09/26 04:11:59 visual_prompt]: Training 67 / 100 epoch, with learning rate 1.5634835164602199
[09/26 04:12:06 visual_prompt]: Epoch 67 / 100: avg data time: 6.75e-02, avg batch time: 0.5110, average train loss: 0.0201
[09/26 04:12:07 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1675, average loss: 3.1590
[09/26 04:12:07 visual_prompt]: Classification results with val_vtab-sun397: top1: 36.50	top5: 62.00	
[09/26 04:12:07 visual_prompt]: Training 68 / 100 epoch, with learning rate 1.4831583923104998
[09/26 04:12:14 visual_prompt]: Epoch 68 / 100: avg data time: 6.46e-02, avg batch time: 0.5084, average train loss: 0.0190
[09/26 04:12:16 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1672, average loss: 3.1529
[09/26 04:12:16 visual_prompt]: Classification results with val_vtab-sun397: top1: 36.50	top5: 62.50	
[09/26 04:12:16 visual_prompt]: Training 69 / 100 epoch, with learning rate 1.4040721330273063
[09/26 04:12:23 visual_prompt]: Epoch 69 / 100: avg data time: 5.77e-02, avg batch time: 0.5020, average train loss: 0.0190
[09/26 04:12:24 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1672, average loss: 3.1561
[09/26 04:12:24 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.00	top5: 62.50	
[09/26 04:12:24 visual_prompt]: Training 70 / 100 epoch, with learning rate 1.3263210930352738
[09/26 04:12:31 visual_prompt]: Epoch 70 / 100: avg data time: 6.85e-02, avg batch time: 0.5120, average train loss: 0.0190
[09/26 04:12:33 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1674, average loss: 3.1483
[09/26 04:12:33 visual_prompt]: Classification results with val_vtab-sun397: top1: 36.50	top5: 61.50	
[09/26 04:12:33 visual_prompt]: Training 71 / 100 epoch, with learning rate 1.2500000000000004
[09/26 04:12:40 visual_prompt]: Epoch 71 / 100: avg data time: 6.31e-02, avg batch time: 0.5069, average train loss: 0.0190
[09/26 04:12:41 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1675, average loss: 3.1440
[09/26 04:12:41 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.00	top5: 62.50	
[09/26 04:12:41 visual_prompt]: Training 72 / 100 epoch, with learning rate 1.175201839416988
[09/26 04:12:48 visual_prompt]: Epoch 72 / 100: avg data time: 5.66e-02, avg batch time: 0.5003, average train loss: 0.0186
[09/26 04:12:49 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1674, average loss: 3.1556
[09/26 04:12:49 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.50	top5: 62.50	
[09/26 04:12:49 visual_prompt]: Training 73 / 100 epoch, with learning rate 1.1020177413231333
[09/26 04:12:56 visual_prompt]: Epoch 73 / 100: avg data time: 5.67e-02, avg batch time: 0.5013, average train loss: 0.0188
[09/26 04:12:58 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1674, average loss: 3.1514
[09/26 04:12:58 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.00	top5: 62.50	
[09/26 04:12:58 visual_prompt]: Training 74 / 100 epoch, with learning rate 1.0305368692688175
[09/26 04:13:05 visual_prompt]: Epoch 74 / 100: avg data time: 5.88e-02, avg batch time: 0.5028, average train loss: 0.0188
[09/26 04:13:06 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1674, average loss: 3.1322
[09/26 04:13:06 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.00	top5: 62.50	
[09/26 04:13:06 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.9608463116858543
[09/26 04:13:13 visual_prompt]: Epoch 75 / 100: avg data time: 6.11e-02, avg batch time: 0.5063, average train loss: 0.0184
[09/26 04:13:15 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1677, average loss: 3.1375
[09/26 04:13:15 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.50	top5: 62.50	
[09/26 04:13:15 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.8930309757836516
[09/26 04:13:22 visual_prompt]: Epoch 76 / 100: avg data time: 5.72e-02, avg batch time: 0.5016, average train loss: 0.0184
[09/26 04:13:23 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1677, average loss: 3.1357
[09/26 04:13:23 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.00	top5: 63.00	
[09/26 04:13:23 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.8271734841028553
[09/26 04:13:30 visual_prompt]: Epoch 77 / 100: avg data time: 5.94e-02, avg batch time: 0.5037, average train loss: 0.0184
[09/26 04:13:32 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1678, average loss: 3.1497
[09/26 04:13:32 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.50	top5: 63.00	
[09/26 04:13:32 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.7633540738525066
[09/26 04:13:39 visual_prompt]: Epoch 78 / 100: avg data time: 6.83e-02, avg batch time: 0.5119, average train loss: 0.0183
[09/26 04:13:40 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1675, average loss: 3.1448
[09/26 04:13:40 visual_prompt]: Classification results with val_vtab-sun397: top1: 36.50	top5: 62.50	
[09/26 04:13:40 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.7016504991533725
[09/26 04:13:47 visual_prompt]: Epoch 79 / 100: avg data time: 5.81e-02, avg batch time: 0.5018, average train loss: 0.0179
[09/26 04:13:49 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1674, average loss: 3.1468
[09/26 04:13:49 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.00	top5: 63.50	
[09/26 04:13:49 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.6421379363065141
[09/26 04:13:56 visual_prompt]: Epoch 80 / 100: avg data time: 6.49e-02, avg batch time: 0.5092, average train loss: 0.0180
[09/26 04:13:57 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1676, average loss: 3.1521
[09/26 04:13:57 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.50	top5: 62.50	
[09/26 04:13:57 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.5848888922025552
[09/26 04:14:04 visual_prompt]: Epoch 81 / 100: avg data time: 5.49e-02, avg batch time: 0.4999, average train loss: 0.0177
[09/26 04:14:06 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1676, average loss: 3.1431
[09/26 04:14:06 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.00	top5: 63.00	
[09/26 04:14:06 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.5299731159831953
[09/26 04:14:13 visual_prompt]: Epoch 82 / 100: avg data time: 5.72e-02, avg batch time: 0.5008, average train loss: 0.0179
[09/26 04:14:14 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1676, average loss: 3.1444
[09/26 04:14:14 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.00	top5: 63.00	
[09/26 04:14:14 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.47745751406263165
[09/26 04:14:21 visual_prompt]: Epoch 83 / 100: avg data time: 6.34e-02, avg batch time: 0.5063, average train loss: 0.0178
[09/26 04:14:23 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1675, average loss: 3.1472
[09/26 04:14:23 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.00	top5: 63.50	
[09/26 04:14:23 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.42740606861239594
[09/26 04:14:30 visual_prompt]: Epoch 84 / 100: avg data time: 5.84e-02, avg batch time: 0.5023, average train loss: 0.0181
[09/26 04:14:31 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1676, average loss: 3.1754
[09/26 04:14:31 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.00	top5: 62.50	
[09/26 04:14:31 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.3798797596089351
[09/26 04:14:38 visual_prompt]: Epoch 85 / 100: avg data time: 5.73e-02, avg batch time: 0.5030, average train loss: 0.0216
[09/26 04:14:40 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1678, average loss: 3.1623
[09/26 04:14:40 visual_prompt]: Classification results with val_vtab-sun397: top1: 36.50	top5: 64.00	
[09/26 04:14:40 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.33493649053890323
[09/26 04:14:47 visual_prompt]: Epoch 86 / 100: avg data time: 6.44e-02, avg batch time: 0.5085, average train loss: 0.0209
[09/26 04:14:48 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1677, average loss: 3.1663
[09/26 04:14:48 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.00	top5: 63.50	
[09/26 04:14:48 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.29263101785268253
[09/26 04:14:55 visual_prompt]: Epoch 87 / 100: avg data time: 5.98e-02, avg batch time: 0.5061, average train loss: 0.0192
[09/26 04:14:56 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1676, average loss: 3.1590
[09/26 04:14:57 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.00	top5: 64.50	
[09/26 04:14:57 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.25301488425208296
[09/26 04:15:03 visual_prompt]: Epoch 88 / 100: avg data time: 6.06e-02, avg batch time: 0.5048, average train loss: 0.0189
[09/26 04:15:05 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1675, average loss: 3.1487
[09/26 04:15:05 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.00	top5: 65.00	
[09/26 04:15:05 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.21613635589349756
[09/26 04:15:12 visual_prompt]: Epoch 89 / 100: avg data time: 6.18e-02, avg batch time: 0.5062, average train loss: 0.0184
[09/26 04:15:13 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1674, average loss: 3.1429
[09/26 04:15:13 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.00	top5: 65.00	
[09/26 04:15:13 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.18204036358303172
[09/26 04:15:20 visual_prompt]: Epoch 90 / 100: avg data time: 6.28e-02, avg batch time: 0.5065, average train loss: 0.0182
[09/26 04:15:22 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1674, average loss: 3.1424
[09/26 04:15:22 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.00	top5: 65.00	
[09/26 04:15:22 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.1507684480352292
[09/26 04:15:29 visual_prompt]: Epoch 91 / 100: avg data time: 6.50e-02, avg batch time: 0.5088, average train loss: 0.0182
[09/26 04:15:30 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.1677, average loss: 3.1441
[09/26 04:15:30 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.00	top5: 64.50	
[09/26 04:15:30 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.12235870926211617
[09/26 04:15:37 visual_prompt]: Epoch 92 / 100: avg data time: 5.52e-02, avg batch time: 0.4998, average train loss: 0.0180
[09/26 04:15:39 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1676, average loss: 3.1448
[09/26 04:15:39 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.00	top5: 64.50	
[09/26 04:15:39 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.09684576015420276
[09/26 04:15:46 visual_prompt]: Epoch 93 / 100: avg data time: 6.11e-02, avg batch time: 0.5068, average train loss: 0.0179
[09/26 04:15:47 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1674, average loss: 3.1451
[09/26 04:15:47 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.00	top5: 64.00	
[09/26 04:15:47 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.07426068431000882
[09/26 04:15:54 visual_prompt]: Epoch 94 / 100: avg data time: 6.14e-02, avg batch time: 0.5051, average train loss: 0.0177
[09/26 04:15:56 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1673, average loss: 3.1453
[09/26 04:15:56 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.00	top5: 64.00	
[09/26 04:15:56 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.05463099816548578
[09/26 04:16:03 visual_prompt]: Epoch 95 / 100: avg data time: 6.12e-02, avg batch time: 0.5049, average train loss: 0.0177
[09/26 04:16:04 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1679, average loss: 3.1451
[09/26 04:16:04 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.00	top5: 64.00	
[09/26 04:16:04 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.03798061746947995
[09/26 04:16:11 visual_prompt]: Epoch 96 / 100: avg data time: 5.30e-02, avg batch time: 0.4979, average train loss: 0.0181
[09/26 04:16:13 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1677, average loss: 3.1445
[09/26 04:16:13 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.00	top5: 64.00	
[09/26 04:16:13 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.024329828146074095
[09/26 04:16:19 visual_prompt]: Epoch 97 / 100: avg data time: 5.44e-02, avg batch time: 0.4984, average train loss: 0.0176
[09/26 04:16:21 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1673, average loss: 3.1443
[09/26 04:16:21 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.00	top5: 64.00	
[09/26 04:16:21 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.013695261579316775
[09/26 04:16:28 visual_prompt]: Epoch 98 / 100: avg data time: 5.58e-02, avg batch time: 0.4996, average train loss: 0.0176
[09/26 04:16:29 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1676, average loss: 3.1439
[09/26 04:16:29 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.00	top5: 64.00	
[09/26 04:16:29 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.006089874350439506
[09/26 04:16:36 visual_prompt]: Epoch 99 / 100: avg data time: 6.79e-02, avg batch time: 0.5116, average train loss: 0.0178
[09/26 04:16:38 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1676, average loss: 3.1437
[09/26 04:16:38 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.00	top5: 64.00	
[09/26 04:16:38 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0015229324522605947
[09/26 04:16:45 visual_prompt]: Epoch 100 / 100: avg data time: 5.53e-02, avg batch time: 0.5002, average train loss: 0.0178
[09/26 04:16:46 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1675, average loss: 3.1437
[09/26 04:16:46 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.00	top5: 64.00	
[09/26 04:16:46 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 04:16:46 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              0
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 04:16:46 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-sun397', 'DATA.NUMBER_CLASSES', '397', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 04:16:46 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 04:16:46 visual_prompt]: Training with config:
[09/26 04:16:46 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-sun397/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr5.0_wd0.0/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 5.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-sun397', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 397, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 04:16:46 visual_prompt]: Loading training data...
[09/26 04:16:46 visual_prompt]: Constructing vtab-sun397 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split train[:800], from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/26 04:16:48 visual_prompt]: Number of images: 800
[09/26 04:16:48 visual_prompt]: Number of classes: 309 / 397
[09/26 04:16:48 visual_prompt]: Loading validation data...
[09/26 04:16:48 visual_prompt]: Constructing vtab-sun397 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split validation[:200], from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/26 04:16:48 visual_prompt]: Number of images: 200
[09/26 04:16:48 visual_prompt]: Number of classes: 136 / 397
[09/26 04:16:48 visual_prompt]: Constructing models...
[09/26 04:16:50 visual_prompt]: Total Parameters: 86564749	 Gradient Parameters: 766093
[09/26 04:16:50 visual_prompt]: tuned percent:0.885
[09/26 04:16:51 visual_prompt]: Device used for model: 0
[09/26 04:16:51 visual_prompt]: Setting up Evaluator...
[09/26 04:16:51 visual_prompt]: Setting up Trainer...
[09/26 04:16:51 visual_prompt]: 	Setting up the optimizer...
[09/26 04:16:51 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 04:16:57 visual_prompt]: Epoch 1 / 100: avg data time: 6.31e-02, avg batch time: 0.5079, average train loss: 5.9899
[09/26 04:16:59 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1673, average loss: 6.0097
[09/26 04:16:59 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/26 04:16:59 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.5
[09/26 04:17:06 visual_prompt]: Epoch 2 / 100: avg data time: 6.94e-02, avg batch time: 0.5119, average train loss: 5.8068
[09/26 04:17:08 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1672, average loss: 5.8145
[09/26 04:17:08 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 4.50	
[09/26 04:17:08 visual_prompt]: Best epoch 2: best metric: 0.015
[09/26 04:17:08 visual_prompt]: Training 3 / 100 epoch, with learning rate 1.0
[09/26 04:17:15 visual_prompt]: Epoch 3 / 100: avg data time: 6.79e-02, avg batch time: 0.5106, average train loss: 5.6324
[09/26 04:17:16 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1669, average loss: 5.8708
[09/26 04:17:16 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 4.50	
[09/26 04:17:16 visual_prompt]: Training 4 / 100 epoch, with learning rate 1.5
[09/26 04:17:23 visual_prompt]: Epoch 4 / 100: avg data time: 5.55e-02, avg batch time: 0.4979, average train loss: 5.6457
[09/26 04:17:25 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1672, average loss: 5.8849
[09/26 04:17:25 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 4.50	
[09/26 04:17:25 visual_prompt]: Training 5 / 100 epoch, with learning rate 2.0
[09/26 04:17:32 visual_prompt]: Epoch 5 / 100: avg data time: 6.47e-02, avg batch time: 0.5076, average train loss: 5.7367
[09/26 04:17:33 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1671, average loss: 5.8703
[09/26 04:17:33 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 3.00	
[09/26 04:17:33 visual_prompt]: Training 6 / 100 epoch, with learning rate 2.5
[09/26 04:17:40 visual_prompt]: Epoch 6 / 100: avg data time: 5.46e-02, avg batch time: 0.4976, average train loss: 5.9377
[09/26 04:17:42 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1673, average loss: 5.8037
[09/26 04:17:42 visual_prompt]: Classification results with val_vtab-sun397: top1: 3.50	top5: 9.50	
[09/26 04:17:42 visual_prompt]: Best epoch 6: best metric: 0.035
[09/26 04:17:42 visual_prompt]: Training 7 / 100 epoch, with learning rate 3.0
[09/26 04:17:49 visual_prompt]: Epoch 7 / 100: avg data time: 6.22e-02, avg batch time: 0.5060, average train loss: 6.0403
[09/26 04:17:50 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1672, average loss: 5.9734
[09/26 04:17:50 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 7.50	
[09/26 04:17:50 visual_prompt]: Training 8 / 100 epoch, with learning rate 3.5
[09/26 04:17:57 visual_prompt]: Epoch 8 / 100: avg data time: 6.17e-02, avg batch time: 0.5047, average train loss: 5.8915
[09/26 04:17:59 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1674, average loss: 6.0391
[09/26 04:17:59 visual_prompt]: Classification results with val_vtab-sun397: top1: 3.00	top5: 6.50	
[09/26 04:17:59 visual_prompt]: Training 9 / 100 epoch, with learning rate 4.0
[09/26 04:18:06 visual_prompt]: Epoch 9 / 100: avg data time: 5.70e-02, avg batch time: 0.4999, average train loss: 6.0514
[09/26 04:18:07 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1673, average loss: 5.8942
[09/26 04:18:07 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.50	top5: 9.50	
[09/26 04:18:07 visual_prompt]: Training 10 / 100 epoch, with learning rate 4.5
[09/26 04:18:14 visual_prompt]: Epoch 10 / 100: avg data time: 5.77e-02, avg batch time: 0.5002, average train loss: 6.2624
[09/26 04:18:16 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1674, average loss: 5.5516
[09/26 04:18:16 visual_prompt]: Classification results with val_vtab-sun397: top1: 7.50	top5: 17.00	
[09/26 04:18:16 visual_prompt]: Best epoch 10: best metric: 0.075
[09/26 04:18:16 visual_prompt]: Training 11 / 100 epoch, with learning rate 5.0
[09/26 04:18:22 visual_prompt]: Epoch 11 / 100: avg data time: 5.27e-02, avg batch time: 0.4984, average train loss: 5.0750
[09/26 04:18:24 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1672, average loss: 5.8358
[09/26 04:18:24 visual_prompt]: Classification results with val_vtab-sun397: top1: 5.00	top5: 16.50	
[09/26 04:18:24 visual_prompt]: Training 12 / 100 epoch, with learning rate 4.998477067547739
[09/26 04:18:31 visual_prompt]: Epoch 12 / 100: avg data time: 6.14e-02, avg batch time: 0.5040, average train loss: 4.5392
[09/26 04:18:32 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1671, average loss: 5.5666
[09/26 04:18:32 visual_prompt]: Classification results with val_vtab-sun397: top1: 10.00	top5: 22.00	
[09/26 04:18:32 visual_prompt]: Best epoch 12: best metric: 0.100
[09/26 04:18:32 visual_prompt]: Training 13 / 100 epoch, with learning rate 4.993910125649561
[09/26 04:18:39 visual_prompt]: Epoch 13 / 100: avg data time: 6.21e-02, avg batch time: 0.5071, average train loss: 3.0148
[09/26 04:18:41 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1673, average loss: 5.5302
[09/26 04:18:41 visual_prompt]: Classification results with val_vtab-sun397: top1: 13.50	top5: 35.50	
[09/26 04:18:41 visual_prompt]: Best epoch 13: best metric: 0.135
[09/26 04:18:41 visual_prompt]: Training 14 / 100 epoch, with learning rate 4.986304738420683
[09/26 04:18:48 visual_prompt]: Epoch 14 / 100: avg data time: 6.40e-02, avg batch time: 0.5068, average train loss: 1.5440
[09/26 04:18:49 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1674, average loss: 4.8079
[09/26 04:18:49 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.00	top5: 46.50	
[09/26 04:18:49 visual_prompt]: Best epoch 14: best metric: 0.220
[09/26 04:18:49 visual_prompt]: Training 15 / 100 epoch, with learning rate 4.975670171853926
[09/26 04:18:56 visual_prompt]: Epoch 15 / 100: avg data time: 6.69e-02, avg batch time: 0.5109, average train loss: 0.6587
[09/26 04:18:58 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1674, average loss: 5.5315
[09/26 04:18:58 visual_prompt]: Classification results with val_vtab-sun397: top1: 23.00	top5: 48.00	
[09/26 04:18:58 visual_prompt]: Best epoch 15: best metric: 0.230
[09/26 04:18:58 visual_prompt]: Training 16 / 100 epoch, with learning rate 4.962019382530521
[09/26 04:19:05 visual_prompt]: Epoch 16 / 100: avg data time: 7.63e-02, avg batch time: 0.5197, average train loss: 0.4491
[09/26 04:19:07 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1672, average loss: 5.5514
[09/26 04:19:07 visual_prompt]: Classification results with val_vtab-sun397: top1: 24.50	top5: 48.00	
[09/26 04:19:07 visual_prompt]: Best epoch 16: best metric: 0.245
[09/26 04:19:07 visual_prompt]: Training 17 / 100 epoch, with learning rate 4.945369001834514
[09/26 04:19:14 visual_prompt]: Epoch 17 / 100: avg data time: 6.47e-02, avg batch time: 0.5080, average train loss: 0.1945
[09/26 04:19:15 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1675, average loss: 5.4739
[09/26 04:19:15 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.50	top5: 54.00	
[09/26 04:19:15 visual_prompt]: Best epoch 17: best metric: 0.275
[09/26 04:19:15 visual_prompt]: Training 18 / 100 epoch, with learning rate 4.925739315689991
[09/26 04:19:22 visual_prompt]: Epoch 18 / 100: avg data time: 5.69e-02, avg batch time: 0.5001, average train loss: 0.0804
[09/26 04:19:24 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1671, average loss: 5.5635
[09/26 04:19:24 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 55.50	
[09/26 04:19:24 visual_prompt]: Best epoch 18: best metric: 0.280
[09/26 04:19:24 visual_prompt]: Training 19 / 100 epoch, with learning rate 4.903154239845797
[09/26 04:19:31 visual_prompt]: Epoch 19 / 100: avg data time: 6.46e-02, avg batch time: 0.5087, average train loss: 0.0729
[09/26 04:19:32 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1676, average loss: 5.5767
[09/26 04:19:32 visual_prompt]: Classification results with val_vtab-sun397: top1: 29.00	top5: 53.00	
[09/26 04:19:32 visual_prompt]: Best epoch 19: best metric: 0.290
[09/26 04:19:32 visual_prompt]: Training 20 / 100 epoch, with learning rate 4.877641290737884
[09/26 04:19:39 visual_prompt]: Epoch 20 / 100: avg data time: 6.00e-02, avg batch time: 0.5034, average train loss: 0.0271
[09/26 04:19:41 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1672, average loss: 5.3439
[09/26 04:19:41 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 58.50	
[09/26 04:19:41 visual_prompt]: Training 21 / 100 epoch, with learning rate 4.849231551964771
[09/26 04:19:48 visual_prompt]: Epoch 21 / 100: avg data time: 6.71e-02, avg batch time: 0.5104, average train loss: 0.0069
[09/26 04:19:49 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1674, average loss: 5.4418
[09/26 04:19:49 visual_prompt]: Classification results with val_vtab-sun397: top1: 30.50	top5: 56.50	
[09/26 04:19:49 visual_prompt]: Best epoch 21: best metric: 0.305
[09/26 04:19:49 visual_prompt]: Training 22 / 100 epoch, with learning rate 4.817959636416969
[09/26 04:19:56 visual_prompt]: Epoch 22 / 100: avg data time: 5.99e-02, avg batch time: 0.5031, average train loss: 0.0076
[09/26 04:19:58 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1675, average loss: 5.3765
[09/26 04:19:58 visual_prompt]: Classification results with val_vtab-sun397: top1: 31.00	top5: 57.50	
[09/26 04:19:58 visual_prompt]: Best epoch 22: best metric: 0.310
[09/26 04:19:58 visual_prompt]: Training 23 / 100 epoch, with learning rate 4.783863644106502
[09/26 04:20:05 visual_prompt]: Epoch 23 / 100: avg data time: 6.74e-02, avg batch time: 0.5108, average train loss: 0.0022
[09/26 04:20:07 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1678, average loss: 5.4533
[09/26 04:20:07 visual_prompt]: Classification results with val_vtab-sun397: top1: 30.50	top5: 55.50	
[09/26 04:20:07 visual_prompt]: Training 24 / 100 epoch, with learning rate 4.7469851157479175
[09/26 04:20:13 visual_prompt]: Epoch 24 / 100: avg data time: 5.01e-02, avg batch time: 0.4956, average train loss: 0.0055
[09/26 04:20:15 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1676, average loss: 5.3696
[09/26 04:20:15 visual_prompt]: Classification results with val_vtab-sun397: top1: 31.00	top5: 54.00	
[09/26 04:20:15 visual_prompt]: Training 25 / 100 epoch, with learning rate 4.707368982147317
[09/26 04:20:22 visual_prompt]: Epoch 25 / 100: avg data time: 5.34e-02, avg batch time: 0.4969, average train loss: 0.0022
[09/26 04:20:23 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1671, average loss: 5.3839
[09/26 04:20:23 visual_prompt]: Classification results with val_vtab-sun397: top1: 31.00	top5: 54.00	
[09/26 04:20:23 visual_prompt]: Training 26 / 100 epoch, with learning rate 4.665063509461097
[09/26 04:20:30 visual_prompt]: Epoch 26 / 100: avg data time: 6.12e-02, avg batch time: 0.5039, average train loss: 0.0014
[09/26 04:20:32 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1680, average loss: 5.2936
[09/26 04:20:32 visual_prompt]: Classification results with val_vtab-sun397: top1: 31.50	top5: 55.00	
[09/26 04:20:32 visual_prompt]: Best epoch 26: best metric: 0.315
[09/26 04:20:32 visual_prompt]: Training 27 / 100 epoch, with learning rate 4.620120240391064
[09/26 04:20:39 visual_prompt]: Epoch 27 / 100: avg data time: 5.93e-02, avg batch time: 0.5038, average train loss: 0.0013
[09/26 04:20:40 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1680, average loss: 5.1863
[09/26 04:20:40 visual_prompt]: Classification results with val_vtab-sun397: top1: 34.00	top5: 54.50	
[09/26 04:20:40 visual_prompt]: Best epoch 27: best metric: 0.340
[09/26 04:20:40 visual_prompt]: Training 28 / 100 epoch, with learning rate 4.572593931387604
[09/26 04:20:47 visual_prompt]: Epoch 28 / 100: avg data time: 6.01e-02, avg batch time: 0.5035, average train loss: 0.0011
[09/26 04:20:49 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1681, average loss: 5.2469
[09/26 04:20:49 visual_prompt]: Classification results with val_vtab-sun397: top1: 32.00	top5: 55.00	
[09/26 04:20:49 visual_prompt]: Training 29 / 100 epoch, with learning rate 4.522542485937368
[09/26 04:20:56 visual_prompt]: Epoch 29 / 100: avg data time: 5.19e-02, avg batch time: 0.4957, average train loss: 0.0005
[09/26 04:20:57 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1676, average loss: 5.2572
[09/26 04:20:57 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 55.00	
[09/26 04:20:57 visual_prompt]: Training 30 / 100 epoch, with learning rate 4.4700268840168045
[09/26 04:21:04 visual_prompt]: Epoch 30 / 100: avg data time: 6.31e-02, avg batch time: 0.5073, average train loss: 0.0004
[09/26 04:21:06 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1672, average loss: 5.2516
[09/26 04:21:06 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 55.50	
[09/26 04:21:06 visual_prompt]: Training 31 / 100 epoch, with learning rate 4.415111107797445
[09/26 04:21:13 visual_prompt]: Epoch 31 / 100: avg data time: 6.37e-02, avg batch time: 0.5077, average train loss: 0.0005
[09/26 04:21:14 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1670, average loss: 5.2493
[09/26 04:21:14 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 56.00	
[09/26 04:21:14 visual_prompt]: Training 32 / 100 epoch, with learning rate 4.357862063693486
[09/26 04:21:21 visual_prompt]: Epoch 32 / 100: avg data time: 6.39e-02, avg batch time: 0.5069, average train loss: 0.0004
[09/26 04:21:23 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.1670, average loss: 5.2445
[09/26 04:21:23 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.00	top5: 56.00	
[09/26 04:21:23 visual_prompt]: Training 33 / 100 epoch, with learning rate 4.298349500846628
[09/26 04:21:30 visual_prompt]: Epoch 33 / 100: avg data time: 5.40e-02, avg batch time: 0.4976, average train loss: 0.0004
[09/26 04:21:31 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1676, average loss: 5.2403
[09/26 04:21:31 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 56.50	
[09/26 04:21:31 visual_prompt]: Training 34 / 100 epoch, with learning rate 4.236645926147493
[09/26 04:21:38 visual_prompt]: Epoch 34 / 100: avg data time: 5.49e-02, avg batch time: 0.4988, average train loss: 0.0004
[09/26 04:21:40 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1672, average loss: 5.2345
[09/26 04:21:40 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 57.00	
[09/26 04:21:40 visual_prompt]: Training 35 / 100 epoch, with learning rate 4.172826515897146
[09/26 04:21:46 visual_prompt]: Epoch 35 / 100: avg data time: 6.42e-02, avg batch time: 0.5073, average train loss: 0.0003
[09/26 04:21:48 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1671, average loss: 5.2272
[09/26 04:21:48 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 57.00	
[09/26 04:21:48 visual_prompt]: Training 36 / 100 epoch, with learning rate 4.106969024216348
[09/26 04:21:55 visual_prompt]: Epoch 36 / 100: avg data time: 5.75e-02, avg batch time: 0.5010, average train loss: 0.0004
[09/26 04:21:56 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1672, average loss: 5.2225
[09/26 04:21:56 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 57.00	
[09/26 04:21:56 visual_prompt]: Training 37 / 100 epoch, with learning rate 4.039153688314146
[09/26 04:22:03 visual_prompt]: Epoch 37 / 100: avg data time: 6.61e-02, avg batch time: 0.5093, average train loss: 0.0003
[09/26 04:22:05 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1674, average loss: 5.2172
[09/26 04:22:05 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 57.00	
[09/26 04:22:05 visual_prompt]: Training 38 / 100 epoch, with learning rate 3.969463130731183
[09/26 04:22:12 visual_prompt]: Epoch 38 / 100: avg data time: 5.18e-02, avg batch time: 0.4953, average train loss: 0.0003
[09/26 04:22:13 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1677, average loss: 5.2134
[09/26 04:22:13 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 56.50	
[09/26 04:22:13 visual_prompt]: Training 39 / 100 epoch, with learning rate 3.897982258676867
[09/26 04:22:20 visual_prompt]: Epoch 39 / 100: avg data time: 5.90e-02, avg batch time: 0.5021, average train loss: 0.0003
[09/26 04:22:22 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1675, average loss: 5.2098
[09/26 04:22:22 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 56.50	
[09/26 04:22:22 visual_prompt]: Training 40 / 100 epoch, with learning rate 3.824798160583012
[09/26 04:22:29 visual_prompt]: Epoch 40 / 100: avg data time: 6.18e-02, avg batch time: 0.5046, average train loss: 0.0003
[09/26 04:22:30 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1675, average loss: 5.2078
[09/26 04:22:30 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 57.00	
[09/26 04:22:30 visual_prompt]: Training 41 / 100 epoch, with learning rate 3.75
[09/26 04:22:37 visual_prompt]: Epoch 41 / 100: avg data time: 6.51e-02, avg batch time: 0.5113, average train loss: 0.0003
[09/26 04:22:39 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1675, average loss: 5.2076
[09/26 04:22:39 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 57.50	
[09/26 04:22:39 visual_prompt]: Training 42 / 100 epoch, with learning rate 3.673678906964727
[09/26 04:22:46 visual_prompt]: Epoch 42 / 100: avg data time: 5.67e-02, avg batch time: 0.4998, average train loss: 0.0003
[09/26 04:22:47 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1673, average loss: 5.2068
[09/26 04:22:47 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 57.50	
[09/26 04:22:47 visual_prompt]: Training 43 / 100 epoch, with learning rate 3.5959278669726933
[09/26 04:22:54 visual_prompt]: Epoch 43 / 100: avg data time: 4.79e-02, avg batch time: 0.4928, average train loss: 0.0003
[09/26 04:22:56 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1673, average loss: 5.2041
[09/26 04:22:56 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 57.50	
[09/26 04:22:56 visual_prompt]: Training 44 / 100 epoch, with learning rate 3.516841607689501
[09/26 04:23:02 visual_prompt]: Epoch 44 / 100: avg data time: 6.08e-02, avg batch time: 0.5051, average train loss: 0.0003
[09/26 04:23:04 visual_prompt]: Inference (val):avg data time: 2.08e-05, avg batch time: 0.1675, average loss: 5.2020
[09/26 04:23:04 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 57.50	
[09/26 04:23:04 visual_prompt]: Training 45 / 100 epoch, with learning rate 3.4365164835397803
[09/26 04:23:11 visual_prompt]: Epoch 45 / 100: avg data time: 6.13e-02, avg batch time: 0.5051, average train loss: 0.0003
[09/26 04:23:13 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1675, average loss: 5.1998
[09/26 04:23:13 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 57.50	
[09/26 04:23:13 visual_prompt]: Training 46 / 100 epoch, with learning rate 3.3550503583141724
[09/26 04:23:19 visual_prompt]: Epoch 46 / 100: avg data time: 5.10e-02, avg batch time: 0.4977, average train loss: 0.0002
[09/26 04:23:21 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1671, average loss: 5.1985
[09/26 04:23:21 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 57.50	
[09/26 04:23:21 visual_prompt]: Training 47 / 100 epoch, with learning rate 3.2725424859373686
[09/26 04:23:28 visual_prompt]: Epoch 47 / 100: avg data time: 6.26e-02, avg batch time: 0.5057, average train loss: 0.0002
[09/26 04:23:29 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1675, average loss: 5.1971
[09/26 04:23:29 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 57.00	
[09/26 04:23:29 visual_prompt]: Training 48 / 100 epoch, with learning rate 3.1890933895424975
[09/26 04:23:36 visual_prompt]: Epoch 48 / 100: avg data time: 4.96e-02, avg batch time: 0.4945, average train loss: 0.0002
[09/26 04:23:38 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1669, average loss: 5.1957
[09/26 04:23:38 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 57.00	
[09/26 04:23:38 visual_prompt]: Training 49 / 100 epoch, with learning rate 3.104804738999169
[09/26 04:23:45 visual_prompt]: Epoch 49 / 100: avg data time: 5.99e-02, avg batch time: 0.5028, average train loss: 0.0002
[09/26 04:23:46 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1675, average loss: 5.1942
[09/26 04:23:46 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 57.00	
[09/26 04:23:46 visual_prompt]: Training 50 / 100 epoch, with learning rate 3.019779227044398
[09/26 04:23:53 visual_prompt]: Epoch 50 / 100: avg data time: 6.53e-02, avg batch time: 0.5079, average train loss: 0.0002
[09/26 04:23:55 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1672, average loss: 5.1924
[09/26 04:23:55 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 57.50	
[09/26 04:23:55 visual_prompt]: Training 51 / 100 epoch, with learning rate 2.934120444167326
[09/26 04:24:02 visual_prompt]: Epoch 51 / 100: avg data time: 6.17e-02, avg batch time: 0.5054, average train loss: 0.0002
[09/26 04:24:03 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1676, average loss: 5.1917
[09/26 04:24:03 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 57.00	
[09/26 04:24:03 visual_prompt]: Training 52 / 100 epoch, with learning rate 2.8479327524001636
[09/26 04:24:10 visual_prompt]: Epoch 52 / 100: avg data time: 4.74e-02, avg batch time: 0.4927, average train loss: 0.0002
[09/26 04:24:11 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1674, average loss: 5.1905
[09/26 04:24:11 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 57.50	
[09/26 04:24:11 visual_prompt]: Training 53 / 100 epoch, with learning rate 2.761321158169134
[09/26 04:24:18 visual_prompt]: Epoch 53 / 100: avg data time: 6.16e-02, avg batch time: 0.5047, average train loss: 0.0002
[09/26 04:24:20 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1679, average loss: 5.1886
[09/26 04:24:20 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 57.50	
[09/26 04:24:20 visual_prompt]: Training 54 / 100 epoch, with learning rate 2.6743911843603128
[09/26 04:24:27 visual_prompt]: Epoch 54 / 100: avg data time: 4.96e-02, avg batch time: 0.4953, average train loss: 0.0002
[09/26 04:24:28 visual_prompt]: Inference (val):avg data time: 3.74e-05, avg batch time: 0.1674, average loss: 5.1869
[09/26 04:24:28 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 57.50	
[09/26 04:24:28 visual_prompt]: Training 55 / 100 epoch, with learning rate 2.5872487417562526
[09/26 04:24:35 visual_prompt]: Epoch 55 / 100: avg data time: 6.76e-02, avg batch time: 0.5106, average train loss: 0.0002
[09/26 04:24:37 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1679, average loss: 5.1857
[09/26 04:24:37 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 57.50	
[09/26 04:24:37 visual_prompt]: Training 56 / 100 epoch, with learning rate 2.5
[09/26 04:24:44 visual_prompt]: Epoch 56 / 100: avg data time: 6.42e-02, avg batch time: 0.5093, average train loss: 0.0003
[09/26 04:24:45 visual_prompt]: Inference (val):avg data time: 2.11e-05, avg batch time: 0.1671, average loss: 5.1847
[09/26 04:24:45 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 57.50	
[09/26 04:24:45 visual_prompt]: Training 57 / 100 epoch, with learning rate 2.4127512582437483
[09/26 04:24:52 visual_prompt]: Epoch 57 / 100: avg data time: 7.05e-02, avg batch time: 0.5136, average train loss: 0.0002
[09/26 04:24:54 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1678, average loss: 5.1837
[09/26 04:24:54 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 57.50	
[09/26 04:24:54 visual_prompt]: Training 58 / 100 epoch, with learning rate 2.325608815639687
[09/26 04:25:01 visual_prompt]: Epoch 58 / 100: avg data time: 6.49e-02, avg batch time: 0.5097, average train loss: 0.0002
[09/26 04:25:02 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1670, average loss: 5.1826
[09/26 04:25:02 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 58.00	
[09/26 04:25:02 visual_prompt]: Training 59 / 100 epoch, with learning rate 2.2386788418308665
[09/26 04:25:09 visual_prompt]: Epoch 59 / 100: avg data time: 6.51e-02, avg batch time: 0.5086, average train loss: 0.0002
[09/26 04:25:11 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1676, average loss: 5.1814
[09/26 04:25:11 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 58.00	
[09/26 04:25:11 visual_prompt]: Training 60 / 100 epoch, with learning rate 2.1520672475998373
[09/26 04:25:18 visual_prompt]: Epoch 60 / 100: avg data time: 6.66e-02, avg batch time: 0.5097, average train loss: 0.0002
[09/26 04:25:20 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1676, average loss: 5.1805
[09/26 04:25:20 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 58.00	
[09/26 04:25:20 visual_prompt]: Training 61 / 100 epoch, with learning rate 2.0658795558326744
[09/26 04:25:26 visual_prompt]: Epoch 61 / 100: avg data time: 6.02e-02, avg batch time: 0.5052, average train loss: 0.0002
[09/26 04:25:28 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1675, average loss: 5.1800
[09/26 04:25:28 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 58.00	
[09/26 04:25:28 visual_prompt]: Training 62 / 100 epoch, with learning rate 1.980220772955602
[09/26 04:25:35 visual_prompt]: Epoch 62 / 100: avg data time: 6.68e-02, avg batch time: 0.5101, average train loss: 0.0002
[09/26 04:25:37 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1679, average loss: 5.1792
[09/26 04:25:37 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 58.00	
[09/26 04:25:37 visual_prompt]: Training 63 / 100 epoch, with learning rate 1.895195261000831
[09/26 04:25:44 visual_prompt]: Epoch 63 / 100: avg data time: 6.60e-02, avg batch time: 0.5095, average train loss: 0.0002
[09/26 04:25:45 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1677, average loss: 5.1785
[09/26 04:25:45 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 58.00	
[09/26 04:25:45 visual_prompt]: Training 64 / 100 epoch, with learning rate 1.8109066104575022
[09/26 04:25:52 visual_prompt]: Epoch 64 / 100: avg data time: 6.50e-02, avg batch time: 0.5083, average train loss: 0.0002
[09/26 04:25:54 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1678, average loss: 5.1782
[09/26 04:25:54 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 58.00	
[09/26 04:25:54 visual_prompt]: Training 65 / 100 epoch, with learning rate 1.7274575140626316
[09/26 04:26:01 visual_prompt]: Epoch 65 / 100: avg data time: 5.81e-02, avg batch time: 0.5012, average train loss: 0.0002
[09/26 04:26:02 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1675, average loss: 5.1773
[09/26 04:26:02 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 58.00	
[09/26 04:26:02 visual_prompt]: Training 66 / 100 epoch, with learning rate 1.6449496416858285
[09/26 04:26:09 visual_prompt]: Epoch 66 / 100: avg data time: 6.40e-02, avg batch time: 0.5075, average train loss: 0.0002
[09/26 04:26:11 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1678, average loss: 5.1766
[09/26 04:26:11 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 58.00	
[09/26 04:26:11 visual_prompt]: Training 67 / 100 epoch, with learning rate 1.5634835164602199
[09/26 04:26:18 visual_prompt]: Epoch 67 / 100: avg data time: 5.14e-02, avg batch time: 0.4945, average train loss: 0.0002
[09/26 04:26:19 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1673, average loss: 5.1765
[09/26 04:26:19 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 58.00	
[09/26 04:26:19 visual_prompt]: Training 68 / 100 epoch, with learning rate 1.4831583923104998
[09/26 04:26:26 visual_prompt]: Epoch 68 / 100: avg data time: 6.43e-02, avg batch time: 0.5076, average train loss: 0.0002
[09/26 04:26:28 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1673, average loss: 5.1765
[09/26 04:26:28 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 58.00	
[09/26 04:26:28 visual_prompt]: Training 69 / 100 epoch, with learning rate 1.4040721330273063
[09/26 04:26:35 visual_prompt]: Epoch 69 / 100: avg data time: 5.65e-02, avg batch time: 0.4997, average train loss: 0.0002
[09/26 04:26:36 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1678, average loss: 5.1764
[09/26 04:26:36 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 58.00	
[09/26 04:26:36 visual_prompt]: Training 70 / 100 epoch, with learning rate 1.3263210930352738
[09/26 04:26:43 visual_prompt]: Epoch 70 / 100: avg data time: 6.79e-02, avg batch time: 0.5115, average train loss: 0.0002
[09/26 04:26:45 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.1673, average loss: 5.1762
[09/26 04:26:45 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 58.00	
[09/26 04:26:45 visual_prompt]: Training 71 / 100 epoch, with learning rate 1.2500000000000004
[09/26 04:26:52 visual_prompt]: Epoch 71 / 100: avg data time: 6.54e-02, avg batch time: 0.5102, average train loss: 0.0002
[09/26 04:26:53 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1673, average loss: 5.1761
[09/26 04:26:53 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 58.00	
[09/26 04:26:53 visual_prompt]: Training 72 / 100 epoch, with learning rate 1.175201839416988
[09/26 04:27:00 visual_prompt]: Epoch 72 / 100: avg data time: 5.92e-02, avg batch time: 0.5028, average train loss: 0.0002
[09/26 04:27:02 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1674, average loss: 5.1756
[09/26 04:27:02 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 58.00	
[09/26 04:27:02 visual_prompt]: Training 73 / 100 epoch, with learning rate 1.1020177413231333
[09/26 04:27:09 visual_prompt]: Epoch 73 / 100: avg data time: 6.03e-02, avg batch time: 0.5053, average train loss: 0.0002
[09/26 04:27:10 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1674, average loss: 5.1751
[09/26 04:27:10 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 58.00	
[09/26 04:27:10 visual_prompt]: Training 74 / 100 epoch, with learning rate 1.0305368692688175
[09/26 04:27:17 visual_prompt]: Epoch 74 / 100: avg data time: 6.11e-02, avg batch time: 0.5060, average train loss: 0.0002
[09/26 04:27:19 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1675, average loss: 5.1746
[09/26 04:27:19 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 58.00	
[09/26 04:27:19 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.9608463116858543
[09/26 04:27:26 visual_prompt]: Epoch 75 / 100: avg data time: 5.94e-02, avg batch time: 0.5032, average train loss: 0.0002
[09/26 04:27:27 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1676, average loss: 5.1743
[09/26 04:27:27 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 58.00	
[09/26 04:27:27 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.8930309757836516
[09/26 04:27:34 visual_prompt]: Epoch 76 / 100: avg data time: 6.14e-02, avg batch time: 0.5050, average train loss: 0.0002
[09/26 04:27:36 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1673, average loss: 5.1739
[09/26 04:27:36 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 58.00	
[09/26 04:27:36 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.8271734841028553
[09/26 04:27:43 visual_prompt]: Epoch 77 / 100: avg data time: 6.51e-02, avg batch time: 0.5088, average train loss: 0.0002
[09/26 04:27:44 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1672, average loss: 5.1735
[09/26 04:27:44 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 58.00	
[09/26 04:27:44 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.7633540738525066
[09/26 04:27:51 visual_prompt]: Epoch 78 / 100: avg data time: 6.23e-02, avg batch time: 0.5057, average train loss: 0.0002
[09/26 04:27:53 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1675, average loss: 5.1732
[09/26 04:27:53 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 58.00	
[09/26 04:27:53 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.7016504991533725
[09/26 04:27:59 visual_prompt]: Epoch 79 / 100: avg data time: 5.55e-02, avg batch time: 0.4999, average train loss: 0.0002
[09/26 04:28:01 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1677, average loss: 5.1730
[09/26 04:28:01 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 58.00	
[09/26 04:28:01 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.6421379363065141
[09/26 04:28:08 visual_prompt]: Epoch 80 / 100: avg data time: 6.10e-02, avg batch time: 0.5043, average train loss: 0.0002
[09/26 04:28:09 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1674, average loss: 5.1728
[09/26 04:28:09 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 58.00	
[09/26 04:28:09 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.5848888922025552
[09/26 04:28:16 visual_prompt]: Epoch 81 / 100: avg data time: 5.32e-02, avg batch time: 0.4966, average train loss: 0.0002
[09/26 04:28:18 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1670, average loss: 5.1727
[09/26 04:28:18 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 58.00	
[09/26 04:28:18 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.5299731159831953
[09/26 04:28:25 visual_prompt]: Epoch 82 / 100: avg data time: 6.26e-02, avg batch time: 0.5056, average train loss: 0.0002
[09/26 04:28:26 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1672, average loss: 5.1725
[09/26 04:28:26 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 58.00	
[09/26 04:28:26 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.47745751406263165
[09/26 04:28:33 visual_prompt]: Epoch 83 / 100: avg data time: 6.31e-02, avg batch time: 0.5062, average train loss: 0.0002
[09/26 04:28:35 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1671, average loss: 5.1722
[09/26 04:28:35 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 58.00	
[09/26 04:28:35 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.42740606861239594
[09/26 04:28:42 visual_prompt]: Epoch 84 / 100: avg data time: 5.95e-02, avg batch time: 0.5034, average train loss: 0.0002
[09/26 04:28:43 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1675, average loss: 5.1721
[09/26 04:28:43 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 58.00	
[09/26 04:28:43 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.3798797596089351
[09/26 04:28:50 visual_prompt]: Epoch 85 / 100: avg data time: 6.40e-02, avg batch time: 0.5073, average train loss: 0.0002
[09/26 04:28:52 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1673, average loss: 5.1720
[09/26 04:28:52 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 58.00	
[09/26 04:28:52 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.33493649053890323
[09/26 04:28:59 visual_prompt]: Epoch 86 / 100: avg data time: 6.71e-02, avg batch time: 0.5101, average train loss: 0.0003
[09/26 04:29:00 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1678, average loss: 5.1718
[09/26 04:29:00 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 58.00	
[09/26 04:29:00 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.29263101785268253
[09/26 04:29:07 visual_prompt]: Epoch 87 / 100: avg data time: 6.13e-02, avg batch time: 0.5042, average train loss: 0.0002
[09/26 04:29:09 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1677, average loss: 5.1717
[09/26 04:29:09 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 58.00	
[09/26 04:29:09 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.25301488425208296
[09/26 04:29:15 visual_prompt]: Epoch 88 / 100: avg data time: 5.90e-02, avg batch time: 0.5017, average train loss: 0.0002
[09/26 04:29:17 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1674, average loss: 5.1716
[09/26 04:29:17 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 58.00	
[09/26 04:29:17 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.21613635589349756
[09/26 04:29:24 visual_prompt]: Epoch 89 / 100: avg data time: 6.22e-02, avg batch time: 0.5058, average train loss: 0.0002
[09/26 04:29:25 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1672, average loss: 5.1715
[09/26 04:29:25 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 58.00	
[09/26 04:29:25 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.18204036358303172
[09/26 04:29:32 visual_prompt]: Epoch 90 / 100: avg data time: 6.06e-02, avg batch time: 0.5045, average train loss: 0.0002
[09/26 04:29:34 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1676, average loss: 5.1714
[09/26 04:29:34 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 58.00	
[09/26 04:29:34 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.1507684480352292
[09/26 04:29:41 visual_prompt]: Epoch 91 / 100: avg data time: 5.45e-02, avg batch time: 0.4984, average train loss: 0.0002
[09/26 04:29:42 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1672, average loss: 5.1713
[09/26 04:29:42 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 58.00	
[09/26 04:29:42 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.12235870926211617
[09/26 04:29:49 visual_prompt]: Epoch 92 / 100: avg data time: 6.26e-02, avg batch time: 0.5056, average train loss: 0.0002
[09/26 04:29:51 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1674, average loss: 5.1713
[09/26 04:29:51 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 58.00	
[09/26 04:29:51 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.09684576015420276
[09/26 04:29:58 visual_prompt]: Epoch 93 / 100: avg data time: 5.74e-02, avg batch time: 0.5012, average train loss: 0.0002
[09/26 04:29:59 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1673, average loss: 5.1712
[09/26 04:29:59 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 58.00	
[09/26 04:29:59 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.07426068431000882
[09/26 04:30:06 visual_prompt]: Epoch 94 / 100: avg data time: 6.04e-02, avg batch time: 0.5036, average train loss: 0.0003
[09/26 04:30:08 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1677, average loss: 5.1713
[09/26 04:30:08 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 58.00	
[09/26 04:30:08 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.05463099816548578
[09/26 04:30:15 visual_prompt]: Epoch 95 / 100: avg data time: 6.98e-02, avg batch time: 0.5143, average train loss: 0.0002
[09/26 04:30:16 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1672, average loss: 5.1713
[09/26 04:30:16 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 58.00	
[09/26 04:30:16 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.03798061746947995
[09/26 04:30:23 visual_prompt]: Epoch 96 / 100: avg data time: 6.92e-02, avg batch time: 0.5116, average train loss: 0.0002
[09/26 04:30:25 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1672, average loss: 5.1713
[09/26 04:30:25 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 58.00	
[09/26 04:30:25 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.024329828146074095
[09/26 04:30:32 visual_prompt]: Epoch 97 / 100: avg data time: 6.55e-02, avg batch time: 0.5087, average train loss: 0.0002
[09/26 04:30:33 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1674, average loss: 5.1713
[09/26 04:30:33 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 58.00	
[09/26 04:30:33 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.013695261579316775
[09/26 04:30:40 visual_prompt]: Epoch 98 / 100: avg data time: 6.55e-02, avg batch time: 0.5096, average train loss: 0.0002
[09/26 04:30:42 visual_prompt]: Inference (val):avg data time: 1.96e-05, avg batch time: 0.1679, average loss: 5.1713
[09/26 04:30:42 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 58.00	
[09/26 04:30:42 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.006089874350439506
[09/26 04:30:49 visual_prompt]: Epoch 99 / 100: avg data time: 6.57e-02, avg batch time: 0.5100, average train loss: 0.0002
[09/26 04:30:50 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1679, average loss: 5.1713
[09/26 04:30:51 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 58.00	
[09/26 04:30:51 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0015229324522605947
[09/26 04:30:57 visual_prompt]: Epoch 100 / 100: avg data time: 6.42e-02, avg batch time: 0.5072, average train loss: 0.0002
[09/26 04:30:59 visual_prompt]: Inference (val):avg data time: 4.43e-05, avg batch time: 0.1676, average loss: 5.1713
[09/26 04:30:59 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 58.00	
[09/26 04:30:59 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 04:30:59 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              0
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 04:30:59 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-sun397', 'DATA.NUMBER_CLASSES', '397', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 04:30:59 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 04:30:59 visual_prompt]: Training with config:
[09/26 04:30:59 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-sun397/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr2.5_wd0.01/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 2.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-sun397', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 397, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 04:30:59 visual_prompt]: Loading training data...
[09/26 04:30:59 visual_prompt]: Constructing vtab-sun397 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split train[:800], from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/26 04:31:00 visual_prompt]: Number of images: 800
[09/26 04:31:00 visual_prompt]: Number of classes: 309 / 397
[09/26 04:31:00 visual_prompt]: Loading validation data...
[09/26 04:31:00 visual_prompt]: Constructing vtab-sun397 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split validation[:200], from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/26 04:31:01 visual_prompt]: Number of images: 200
[09/26 04:31:01 visual_prompt]: Number of classes: 136 / 397
[09/26 04:31:01 visual_prompt]: Constructing models...
[09/26 04:31:03 visual_prompt]: Total Parameters: 86564749	 Gradient Parameters: 766093
[09/26 04:31:03 visual_prompt]: tuned percent:0.885
[09/26 04:31:03 visual_prompt]: Device used for model: 0
[09/26 04:31:03 visual_prompt]: Setting up Evaluator...
[09/26 04:31:03 visual_prompt]: Setting up Trainer...
[09/26 04:31:03 visual_prompt]: 	Setting up the optimizer...
[09/26 04:31:03 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 04:31:10 visual_prompt]: Epoch 1 / 100: avg data time: 6.66e-02, avg batch time: 0.5122, average train loss: 5.9886
[09/26 04:31:12 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1678, average loss: 6.0097
[09/26 04:31:12 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/26 04:31:12 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.25
[09/26 04:31:19 visual_prompt]: Epoch 2 / 100: avg data time: 5.99e-02, avg batch time: 0.5019, average train loss: 5.8124
[09/26 04:31:20 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1675, average loss: 5.8507
[09/26 04:31:20 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 5.00	
[09/26 04:31:20 visual_prompt]: Best epoch 2: best metric: 0.005
[09/26 04:31:20 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.5
[09/26 04:31:27 visual_prompt]: Epoch 3 / 100: avg data time: 7.06e-02, avg batch time: 0.5127, average train loss: 5.6271
[09/26 04:31:29 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1674, average loss: 5.7821
[09/26 04:31:29 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 5.50	
[09/26 04:31:29 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.75
[09/26 04:31:36 visual_prompt]: Epoch 4 / 100: avg data time: 6.01e-02, avg batch time: 0.5042, average train loss: 5.6074
[09/26 04:31:38 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.1674, average loss: 5.8034
[09/26 04:31:38 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 04:31:38 visual_prompt]: Training 5 / 100 epoch, with learning rate 1.0
[09/26 04:31:44 visual_prompt]: Epoch 5 / 100: avg data time: 4.92e-02, avg batch time: 0.4938, average train loss: 5.6961
[09/26 04:31:46 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1673, average loss: 5.8279
[09/26 04:31:46 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.50	
[09/26 04:31:46 visual_prompt]: Best epoch 5: best metric: 0.010
[09/26 04:31:46 visual_prompt]: Training 6 / 100 epoch, with learning rate 1.25
[09/26 04:31:53 visual_prompt]: Epoch 6 / 100: avg data time: 5.07e-02, avg batch time: 0.4938, average train loss: 5.6965
[09/26 04:31:54 visual_prompt]: Inference (val):avg data time: 3.47e-05, avg batch time: 0.1673, average loss: 5.8083
[09/26 04:31:54 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 3.50	
[09/26 04:31:54 visual_prompt]: Training 7 / 100 epoch, with learning rate 1.5
[09/26 04:32:01 visual_prompt]: Epoch 7 / 100: avg data time: 5.75e-02, avg batch time: 0.5004, average train loss: 5.6432
[09/26 04:32:03 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1676, average loss: 5.8720
[09/26 04:32:03 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 3.00	
[09/26 04:32:03 visual_prompt]: Training 8 / 100 epoch, with learning rate 1.75
[09/26 04:32:10 visual_prompt]: Epoch 8 / 100: avg data time: 5.79e-02, avg batch time: 0.5011, average train loss: 5.6404
[09/26 04:32:11 visual_prompt]: Inference (val):avg data time: 4.14e-05, avg batch time: 0.1675, average loss: 5.8379
[09/26 04:32:11 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 5.00	
[09/26 04:32:11 visual_prompt]: Training 9 / 100 epoch, with learning rate 2.0
[09/26 04:32:18 visual_prompt]: Epoch 9 / 100: avg data time: 6.20e-02, avg batch time: 0.5041, average train loss: 5.6440
[09/26 04:32:20 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1671, average loss: 5.8289
[09/26 04:32:20 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.00	
[09/26 04:32:20 visual_prompt]: Training 10 / 100 epoch, with learning rate 2.25
[09/26 04:32:27 visual_prompt]: Epoch 10 / 100: avg data time: 5.80e-02, avg batch time: 0.5026, average train loss: 5.6279
[09/26 04:32:28 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1671, average loss: 6.1047
[09/26 04:32:28 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.50	
[09/26 04:32:28 visual_prompt]: Training 11 / 100 epoch, with learning rate 2.5
[09/26 04:32:35 visual_prompt]: Epoch 11 / 100: avg data time: 6.59e-02, avg batch time: 0.5082, average train loss: 5.6205
[09/26 04:32:37 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1671, average loss: 5.9063
[09/26 04:32:37 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.50	
[09/26 04:32:37 visual_prompt]: Training 12 / 100 epoch, with learning rate 2.4992385337738696
[09/26 04:32:44 visual_prompt]: Epoch 12 / 100: avg data time: 6.18e-02, avg batch time: 0.5049, average train loss: 5.6234
[09/26 04:32:45 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1675, average loss: 5.8981
[09/26 04:32:45 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 4.50	
[09/26 04:32:45 visual_prompt]: Training 13 / 100 epoch, with learning rate 2.4969550628247803
[09/26 04:32:52 visual_prompt]: Epoch 13 / 100: avg data time: 6.21e-02, avg batch time: 0.5052, average train loss: 5.6165
[09/26 04:32:53 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1673, average loss: 5.8724
[09/26 04:32:53 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 6.50	
[09/26 04:32:53 visual_prompt]: Best epoch 13: best metric: 0.015
[09/26 04:32:53 visual_prompt]: Training 14 / 100 epoch, with learning rate 2.4931523692103417
[09/26 04:33:00 visual_prompt]: Epoch 14 / 100: avg data time: 6.60e-02, avg batch time: 0.5084, average train loss: 5.5957
[09/26 04:33:02 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1677, average loss: 6.5484
[09/26 04:33:02 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 3.00	
[09/26 04:33:02 visual_prompt]: Training 15 / 100 epoch, with learning rate 2.487835085926963
[09/26 04:33:09 visual_prompt]: Epoch 15 / 100: avg data time: 5.65e-02, avg batch time: 0.5009, average train loss: 5.7349
[09/26 04:33:10 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1671, average loss: 5.9313
[09/26 04:33:10 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.00	
[09/26 04:33:10 visual_prompt]: Training 16 / 100 epoch, with learning rate 2.4810096912652604
[09/26 04:33:17 visual_prompt]: Epoch 16 / 100: avg data time: 6.10e-02, avg batch time: 0.5035, average train loss: 5.6874
[09/26 04:33:19 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1674, average loss: 5.9512
[09/26 04:33:19 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.00	
[09/26 04:33:19 visual_prompt]: Training 17 / 100 epoch, with learning rate 2.472684500917257
[09/26 04:33:26 visual_prompt]: Epoch 17 / 100: avg data time: 6.11e-02, avg batch time: 0.5032, average train loss: 5.6097
[09/26 04:33:27 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1669, average loss: 5.9674
[09/26 04:33:27 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.00	
[09/26 04:33:27 visual_prompt]: Training 18 / 100 epoch, with learning rate 2.4628696578449953
[09/26 04:33:34 visual_prompt]: Epoch 18 / 100: avg data time: 6.00e-02, avg batch time: 0.5030, average train loss: 5.6108
[09/26 04:33:36 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1668, average loss: 5.9705
[09/26 04:33:36 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.50	
[09/26 04:33:36 visual_prompt]: Training 19 / 100 epoch, with learning rate 2.4515771199228986
[09/26 04:33:43 visual_prompt]: Epoch 19 / 100: avg data time: 6.62e-02, avg batch time: 0.5092, average train loss: 5.6114
[09/26 04:33:44 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1669, average loss: 5.9214
[09/26 04:33:44 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.00	
[09/26 04:33:44 visual_prompt]: Training 20 / 100 epoch, with learning rate 2.438820645368942
[09/26 04:33:51 visual_prompt]: Epoch 20 / 100: avg data time: 6.21e-02, avg batch time: 0.5049, average train loss: 5.5587
[09/26 04:33:53 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1671, average loss: 6.0045
[09/26 04:33:53 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.00	
[09/26 04:33:53 visual_prompt]: Training 21 / 100 epoch, with learning rate 2.4246157759823856
[09/26 04:34:00 visual_prompt]: Epoch 21 / 100: avg data time: 6.56e-02, avg batch time: 0.5088, average train loss: 5.6016
[09/26 04:34:01 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1668, average loss: 5.9581
[09/26 04:34:01 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 5.00	
[09/26 04:34:01 visual_prompt]: Training 22 / 100 epoch, with learning rate 2.4089798182084845
[09/26 04:34:08 visual_prompt]: Epoch 22 / 100: avg data time: 5.23e-02, avg batch time: 0.4960, average train loss: 5.6137
[09/26 04:34:10 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1674, average loss: 6.1507
[09/26 04:34:10 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.00	
[09/26 04:34:10 visual_prompt]: Training 23 / 100 epoch, with learning rate 2.391931822053251
[09/26 04:34:17 visual_prompt]: Epoch 23 / 100: avg data time: 6.29e-02, avg batch time: 0.5072, average train loss: 5.7275
[09/26 04:34:18 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1666, average loss: 6.0147
[09/26 04:34:18 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 3.00	
[09/26 04:34:18 visual_prompt]: Training 24 / 100 epoch, with learning rate 2.3734925578739587
[09/26 04:34:25 visual_prompt]: Epoch 24 / 100: avg data time: 6.42e-02, avg batch time: 0.5068, average train loss: 5.5959
[09/26 04:34:27 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1670, average loss: 5.9465
[09/26 04:34:27 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.50	
[09/26 04:34:27 visual_prompt]: Training 25 / 100 epoch, with learning rate 2.3536844910736585
[09/26 04:34:34 visual_prompt]: Epoch 25 / 100: avg data time: 6.17e-02, avg batch time: 0.5045, average train loss: 5.5879
[09/26 04:34:35 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1671, average loss: 5.9254
[09/26 04:34:35 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.50	
[09/26 04:34:35 visual_prompt]: Training 26 / 100 epoch, with learning rate 2.3325317547305486
[09/26 04:34:42 visual_prompt]: Epoch 26 / 100: avg data time: 6.27e-02, avg batch time: 0.5058, average train loss: 5.5737
[09/26 04:34:44 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1671, average loss: 6.1565
[09/26 04:34:44 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.50	
[09/26 04:34:44 visual_prompt]: Training 27 / 100 epoch, with learning rate 2.310060120195532
[09/26 04:34:50 visual_prompt]: Epoch 27 / 100: avg data time: 6.22e-02, avg batch time: 0.5047, average train loss: 5.6346
[09/26 04:34:52 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1670, average loss: 6.0234
[09/26 04:34:52 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.00	
[09/26 04:34:52 visual_prompt]: Training 28 / 100 epoch, with learning rate 2.286296965693802
[09/26 04:34:59 visual_prompt]: Epoch 28 / 100: avg data time: 6.97e-02, avg batch time: 0.5122, average train loss: 5.5958
[09/26 04:35:01 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1675, average loss: 6.0079
[09/26 04:35:01 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.50	
[09/26 04:35:01 visual_prompt]: Training 29 / 100 epoch, with learning rate 2.261271242968684
[09/26 04:35:08 visual_prompt]: Epoch 29 / 100: avg data time: 6.81e-02, avg batch time: 0.5123, average train loss: 5.7082
[09/26 04:35:09 visual_prompt]: Inference (val):avg data time: 4.74e-05, avg batch time: 0.1673, average loss: 6.0172
[09/26 04:35:09 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 5.00	
[09/26 04:35:09 visual_prompt]: Training 30 / 100 epoch, with learning rate 2.2350134420084022
[09/26 04:35:16 visual_prompt]: Epoch 30 / 100: avg data time: 5.88e-02, avg batch time: 0.5017, average train loss: 5.8869
[09/26 04:35:18 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1670, average loss: 6.0771
[09/26 04:35:18 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 3.50	
[09/26 04:35:18 visual_prompt]: Training 31 / 100 epoch, with learning rate 2.2075555538987226
[09/26 04:35:24 visual_prompt]: Epoch 31 / 100: avg data time: 6.61e-02, avg batch time: 0.5092, average train loss: 5.6817
[09/26 04:35:26 visual_prompt]: Inference (val):avg data time: 1.91e-05, avg batch time: 0.1670, average loss: 6.2755
[09/26 04:35:26 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 3.00	
[09/26 04:35:26 visual_prompt]: Training 32 / 100 epoch, with learning rate 2.178931031846743
[09/26 04:35:33 visual_prompt]: Epoch 32 / 100: avg data time: 6.52e-02, avg batch time: 0.5093, average train loss: 5.6602
[09/26 04:35:35 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1671, average loss: 6.0129
[09/26 04:35:35 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 5.50	
[09/26 04:35:35 visual_prompt]: Training 33 / 100 epoch, with learning rate 2.149174750423314
[09/26 04:35:41 visual_prompt]: Epoch 33 / 100: avg data time: 6.62e-02, avg batch time: 0.5093, average train loss: 5.6455
[09/26 04:35:43 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1674, average loss: 6.0284
[09/26 04:35:43 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.50	
[09/26 04:35:43 visual_prompt]: Training 34 / 100 epoch, with learning rate 2.1183229630737466
[09/26 04:35:50 visual_prompt]: Epoch 34 / 100: avg data time: 6.96e-02, avg batch time: 0.5119, average train loss: 5.5993
[09/26 04:35:52 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1670, average loss: 5.9865
[09/26 04:35:52 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 4.50	
[09/26 04:35:52 visual_prompt]: Training 35 / 100 epoch, with learning rate 2.086413257948573
[09/26 04:35:59 visual_prompt]: Epoch 35 / 100: avg data time: 6.74e-02, avg batch time: 0.5117, average train loss: 5.6149
[09/26 04:36:00 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1672, average loss: 6.1253
[09/26 04:36:00 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.00	
[09/26 04:36:00 visual_prompt]: Training 36 / 100 epoch, with learning rate 2.053484512108174
[09/26 04:36:07 visual_prompt]: Epoch 36 / 100: avg data time: 6.27e-02, avg batch time: 0.5059, average train loss: 5.6090
[09/26 04:36:09 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1671, average loss: 6.0564
[09/26 04:36:09 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 3.00	
[09/26 04:36:09 visual_prompt]: Training 37 / 100 epoch, with learning rate 2.019576844157073
[09/26 04:36:16 visual_prompt]: Epoch 37 / 100: avg data time: 6.52e-02, avg batch time: 0.5073, average train loss: 5.5967
[09/26 04:36:17 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1669, average loss: 6.2337
[09/26 04:36:17 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 3.50	
[09/26 04:36:17 visual_prompt]: Training 38 / 100 epoch, with learning rate 1.9847315653655915
[09/26 04:36:24 visual_prompt]: Epoch 38 / 100: avg data time: 7.11e-02, avg batch time: 0.5136, average train loss: 5.6728
[09/26 04:36:26 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1671, average loss: 6.0958
[09/26 04:36:26 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 5.50	
[09/26 04:36:26 visual_prompt]: Training 39 / 100 epoch, with learning rate 1.9489911293384334
[09/26 04:36:33 visual_prompt]: Epoch 39 / 100: avg data time: 5.22e-02, avg batch time: 0.4947, average train loss: 5.6792
[09/26 04:36:34 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1673, average loss: 6.0628
[09/26 04:36:34 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.50	
[09/26 04:36:34 visual_prompt]: Training 40 / 100 epoch, with learning rate 1.912399080291506
[09/26 04:36:41 visual_prompt]: Epoch 40 / 100: avg data time: 6.63e-02, avg batch time: 0.5096, average train loss: 5.5920
[09/26 04:36:43 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1671, average loss: 6.0687
[09/26 04:36:43 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 5.00	
[09/26 04:36:43 visual_prompt]: Training 41 / 100 epoch, with learning rate 1.875
[09/26 04:36:50 visual_prompt]: Epoch 41 / 100: avg data time: 5.08e-02, avg batch time: 0.4944, average train loss: 5.5800
[09/26 04:36:51 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1669, average loss: 6.0166
[09/26 04:36:51 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 4.50	
[09/26 04:36:51 visual_prompt]: Training 42 / 100 epoch, with learning rate 1.8368394534823635
[09/26 04:36:58 visual_prompt]: Epoch 42 / 100: avg data time: 6.73e-02, avg batch time: 0.5101, average train loss: 5.5538
[09/26 04:37:00 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1670, average loss: 6.0326
[09/26 04:37:00 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.00	
[09/26 04:37:00 visual_prompt]: Training 43 / 100 epoch, with learning rate 1.7979639334863466
[09/26 04:37:07 visual_prompt]: Epoch 43 / 100: avg data time: 6.38e-02, avg batch time: 0.5062, average train loss: 5.5451
[09/26 04:37:08 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1668, average loss: 6.0489
[09/26 04:37:08 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 4.00	
[09/26 04:37:08 visual_prompt]: Training 44 / 100 epoch, with learning rate 1.7584208038447504
[09/26 04:37:15 visual_prompt]: Epoch 44 / 100: avg data time: 6.44e-02, avg batch time: 0.5064, average train loss: 5.5591
[09/26 04:37:17 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1674, average loss: 6.0460
[09/26 04:37:17 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 4.50	
[09/26 04:37:17 visual_prompt]: Training 45 / 100 epoch, with learning rate 1.7182582417698902
[09/26 04:37:24 visual_prompt]: Epoch 45 / 100: avg data time: 6.09e-02, avg batch time: 0.5041, average train loss: 5.5829
[09/26 04:37:26 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1670, average loss: 5.9953
[09/26 04:37:26 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 04:37:26 visual_prompt]: Training 46 / 100 epoch, with learning rate 1.6775251791570862
[09/26 04:37:32 visual_prompt]: Epoch 46 / 100: avg data time: 5.79e-02, avg batch time: 0.5001, average train loss: 5.5837
[09/26 04:37:34 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1667, average loss: 5.9878
[09/26 04:37:34 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.50	
[09/26 04:37:34 visual_prompt]: Training 47 / 100 epoch, with learning rate 1.6362712429686843
[09/26 04:37:41 visual_prompt]: Epoch 47 / 100: avg data time: 5.64e-02, avg batch time: 0.4992, average train loss: 5.5600
[09/26 04:37:42 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1670, average loss: 6.0230
[09/26 04:37:42 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.00	
[09/26 04:37:42 visual_prompt]: Training 48 / 100 epoch, with learning rate 1.5945466947712488
[09/26 04:37:49 visual_prompt]: Epoch 48 / 100: avg data time: 6.53e-02, avg batch time: 0.5095, average train loss: 5.5356
[09/26 04:37:51 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1668, average loss: 6.0451
[09/26 04:37:51 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 4.50	
[09/26 04:37:51 visual_prompt]: Training 49 / 100 epoch, with learning rate 1.5524023694995845
[09/26 04:37:58 visual_prompt]: Epoch 49 / 100: avg data time: 6.49e-02, avg batch time: 0.5083, average train loss: 5.5474
[09/26 04:38:00 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1673, average loss: 6.0236
[09/26 04:38:00 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 4.50	
[09/26 04:38:00 visual_prompt]: Training 50 / 100 epoch, with learning rate 1.509889613522199
[09/26 04:38:06 visual_prompt]: Epoch 50 / 100: avg data time: 5.89e-02, avg batch time: 0.5007, average train loss: 5.5788
[09/26 04:38:08 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1670, average loss: 6.0344
[09/26 04:38:08 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.00	
[09/26 04:38:08 visual_prompt]: Training 51 / 100 epoch, with learning rate 1.467060222083663
[09/26 04:38:15 visual_prompt]: Epoch 51 / 100: avg data time: 6.04e-02, avg batch time: 0.5049, average train loss: 5.5222
[09/26 04:38:17 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1669, average loss: 6.0225
[09/26 04:38:17 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.00	
[09/26 04:38:17 visual_prompt]: Training 52 / 100 epoch, with learning rate 1.4239663762000818
[09/26 04:38:23 visual_prompt]: Epoch 52 / 100: avg data time: 6.17e-02, avg batch time: 0.5068, average train loss: 5.5472
[09/26 04:38:25 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1679, average loss: 5.9983
[09/26 04:38:25 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 5.00	
[09/26 04:38:25 visual_prompt]: Training 53 / 100 epoch, with learning rate 1.380660579084567
[09/26 04:38:32 visual_prompt]: Epoch 53 / 100: avg data time: 6.32e-02, avg batch time: 0.5053, average train loss: 5.5549
[09/26 04:38:34 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1674, average loss: 6.0209
[09/26 04:38:34 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.50	
[09/26 04:38:34 visual_prompt]: Training 54 / 100 epoch, with learning rate 1.3371955921801564
[09/26 04:38:41 visual_prompt]: Epoch 54 / 100: avg data time: 6.67e-02, avg batch time: 0.5100, average train loss: 5.5402
[09/26 04:38:42 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1672, average loss: 5.9996
[09/26 04:38:42 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 4.50	
[09/26 04:38:42 visual_prompt]: Training 55 / 100 epoch, with learning rate 1.2936243708781263
[09/26 04:38:49 visual_prompt]: Epoch 55 / 100: avg data time: 4.90e-02, avg batch time: 0.4925, average train loss: 5.5259
[09/26 04:38:50 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1675, average loss: 6.0214
[09/26 04:38:50 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 3.00	
[09/26 04:38:50 visual_prompt]: Training 56 / 100 epoch, with learning rate 1.25
[09/26 04:38:57 visual_prompt]: Epoch 56 / 100: avg data time: 6.52e-02, avg batch time: 0.5076, average train loss: 5.5376
[09/26 04:38:59 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1674, average loss: 6.0530
[09/26 04:38:59 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.00	
[09/26 04:38:59 visual_prompt]: Training 57 / 100 epoch, with learning rate 1.2063756291218741
[09/26 04:39:06 visual_prompt]: Epoch 57 / 100: avg data time: 6.03e-02, avg batch time: 0.5032, average train loss: 5.5174
[09/26 04:39:07 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1676, average loss: 6.0321
[09/26 04:39:08 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.00	
[09/26 04:39:08 visual_prompt]: Training 58 / 100 epoch, with learning rate 1.1628044078198434
[09/26 04:39:14 visual_prompt]: Epoch 58 / 100: avg data time: 6.46e-02, avg batch time: 0.5076, average train loss: 5.5072
[09/26 04:39:16 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1673, average loss: 6.0157
[09/26 04:39:16 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.00	
[09/26 04:39:16 visual_prompt]: Training 59 / 100 epoch, with learning rate 1.1193394209154333
[09/26 04:39:23 visual_prompt]: Epoch 59 / 100: avg data time: 5.85e-02, avg batch time: 0.5010, average train loss: 5.5624
[09/26 04:39:24 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1676, average loss: 6.0047
[09/26 04:39:24 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.50	
[09/26 04:39:24 visual_prompt]: Training 60 / 100 epoch, with learning rate 1.0760336237999186
[09/26 04:39:31 visual_prompt]: Epoch 60 / 100: avg data time: 6.10e-02, avg batch time: 0.5034, average train loss: 5.5409
[09/26 04:39:33 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1669, average loss: 5.9936
[09/26 04:39:33 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.50	
[09/26 04:39:33 visual_prompt]: Training 61 / 100 epoch, with learning rate 1.0329397779163372
[09/26 04:39:40 visual_prompt]: Epoch 61 / 100: avg data time: 5.88e-02, avg batch time: 0.5020, average train loss: 5.5013
[09/26 04:39:41 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1678, average loss: 5.9826
[09/26 04:39:41 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.00	
[09/26 04:39:41 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.990110386477801
[09/26 04:39:48 visual_prompt]: Epoch 62 / 100: avg data time: 6.47e-02, avg batch time: 0.5070, average train loss: 5.5634
[09/26 04:39:50 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1677, average loss: 6.0041
[09/26 04:39:50 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 04:39:50 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.9475976305004155
[09/26 04:39:57 visual_prompt]: Epoch 63 / 100: avg data time: 5.48e-02, avg batch time: 0.4979, average train loss: 5.5357
[09/26 04:39:58 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1672, average loss: 6.0160
[09/26 04:39:58 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.00	
[09/26 04:39:58 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.9054533052287511
[09/26 04:40:05 visual_prompt]: Epoch 64 / 100: avg data time: 5.81e-02, avg batch time: 0.5028, average train loss: 5.4961
[09/26 04:40:07 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1671, average loss: 6.0239
[09/26 04:40:07 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 5.00	
[09/26 04:40:07 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.8637287570313158
[09/26 04:40:13 visual_prompt]: Epoch 65 / 100: avg data time: 5.75e-02, avg batch time: 0.5003, average train loss: 5.5110
[09/26 04:40:15 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1669, average loss: 6.0814
[09/26 04:40:15 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 5.00	
[09/26 04:40:15 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.8224748208429142
[09/26 04:40:22 visual_prompt]: Epoch 66 / 100: avg data time: 6.40e-02, avg batch time: 0.5084, average train loss: 5.4944
[09/26 04:40:23 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1668, average loss: 6.0148
[09/26 04:40:23 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.50	
[09/26 04:40:23 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.7817417582301099
[09/26 04:40:30 visual_prompt]: Epoch 67 / 100: avg data time: 7.05e-02, avg batch time: 0.5126, average train loss: 5.5066
[09/26 04:40:32 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1677, average loss: 6.0080
[09/26 04:40:32 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 5.00	
[09/26 04:40:32 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.7415791961552499
[09/26 04:40:39 visual_prompt]: Epoch 68 / 100: avg data time: 6.86e-02, avg batch time: 0.5107, average train loss: 5.4919
[09/26 04:40:40 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1669, average loss: 6.0513
[09/26 04:40:40 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 04:40:40 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.7020360665136531
[09/26 04:40:47 visual_prompt]: Epoch 69 / 100: avg data time: 6.31e-02, avg batch time: 0.5061, average train loss: 5.5077
[09/26 04:40:49 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1672, average loss: 6.0167
[09/26 04:40:49 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 4.50	
[09/26 04:40:49 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.6631605465176369
[09/26 04:40:56 visual_prompt]: Epoch 70 / 100: avg data time: 6.82e-02, avg batch time: 0.5106, average train loss: 5.4702
[09/26 04:40:57 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1669, average loss: 6.0002
[09/26 04:40:57 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.50	
[09/26 04:40:57 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.6250000000000002
[09/26 04:41:04 visual_prompt]: Epoch 71 / 100: avg data time: 6.08e-02, avg batch time: 0.5051, average train loss: 5.4694
[09/26 04:41:06 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1675, average loss: 6.1004
[09/26 04:41:06 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 04:41:06 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.587600919708494
[09/26 04:41:13 visual_prompt]: Epoch 72 / 100: avg data time: 5.95e-02, avg batch time: 0.5024, average train loss: 5.5172
[09/26 04:41:14 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1668, average loss: 6.0302
[09/26 04:41:14 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 3.50	
[09/26 04:41:14 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.5510088706615667
[09/26 04:41:21 visual_prompt]: Epoch 73 / 100: avg data time: 6.33e-02, avg batch time: 0.5068, average train loss: 5.4795
[09/26 04:41:23 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1671, average loss: 6.0345
[09/26 04:41:23 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 04:41:23 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.5152684346344087
[09/26 04:41:30 visual_prompt]: Epoch 74 / 100: avg data time: 6.16e-02, avg batch time: 0.5041, average train loss: 5.4759
[09/26 04:41:31 visual_prompt]: Inference (val):avg data time: 3.59e-05, avg batch time: 0.1672, average loss: 6.0284
[09/26 04:41:31 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 04:41:31 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.48042315584292716
[09/26 04:41:38 visual_prompt]: Epoch 75 / 100: avg data time: 6.41e-02, avg batch time: 0.5068, average train loss: 5.4926
[09/26 04:41:40 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1669, average loss: 6.0125
[09/26 04:41:40 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 4.00	
[09/26 04:41:40 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.4465154878918258
[09/26 04:41:47 visual_prompt]: Epoch 76 / 100: avg data time: 6.41e-02, avg batch time: 0.5085, average train loss: 5.4761
[09/26 04:41:48 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1672, average loss: 6.0173
[09/26 04:41:48 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 5.00	
[09/26 04:41:48 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.41358674205142765
[09/26 04:41:55 visual_prompt]: Epoch 77 / 100: avg data time: 6.72e-02, avg batch time: 0.5092, average train loss: 5.4797
[09/26 04:41:57 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1678, average loss: 6.0085
[09/26 04:41:57 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.50	
[09/26 04:41:57 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.3816770369262533
[09/26 04:42:04 visual_prompt]: Epoch 78 / 100: avg data time: 6.75e-02, avg batch time: 0.5105, average train loss: 5.4719
[09/26 04:42:06 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1672, average loss: 6.0065
[09/26 04:42:06 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 5.50	
[09/26 04:42:06 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.35082524957668626
[09/26 04:42:13 visual_prompt]: Epoch 79 / 100: avg data time: 6.07e-02, avg batch time: 0.5030, average train loss: 5.4519
[09/26 04:42:14 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1674, average loss: 5.9989
[09/26 04:42:14 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 6.00	
[09/26 04:42:14 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.32106896815325703
[09/26 04:42:21 visual_prompt]: Epoch 80 / 100: avg data time: 6.55e-02, avg batch time: 0.5083, average train loss: 5.4563
[09/26 04:42:23 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1670, average loss: 6.0709
[09/26 04:42:23 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 3.50	
[09/26 04:42:23 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.2924444461012776
[09/26 04:42:30 visual_prompt]: Epoch 81 / 100: avg data time: 6.35e-02, avg batch time: 0.5072, average train loss: 5.4881
[09/26 04:42:31 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1676, average loss: 6.0158
[09/26 04:42:31 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 04:42:31 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.26498655799159765
[09/26 04:42:38 visual_prompt]: Epoch 82 / 100: avg data time: 5.99e-02, avg batch time: 0.5032, average train loss: 5.4716
[09/26 04:42:40 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1677, average loss: 6.0075
[09/26 04:42:40 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 04:42:40 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.23872875703131582
[09/26 04:42:47 visual_prompt]: Epoch 83 / 100: avg data time: 6.16e-02, avg batch time: 0.5045, average train loss: 5.4597
[09/26 04:42:48 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1675, average loss: 6.0175
[09/26 04:42:48 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.50	
[09/26 04:42:48 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.21370303430619797
[09/26 04:42:55 visual_prompt]: Epoch 84 / 100: avg data time: 5.00e-02, avg batch time: 0.4941, average train loss: 5.4371
[09/26 04:42:57 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1679, average loss: 5.9823
[09/26 04:42:57 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.50	
[09/26 04:42:57 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.18993987980446755
[09/26 04:43:03 visual_prompt]: Epoch 85 / 100: avg data time: 5.14e-02, avg batch time: 0.4952, average train loss: 5.3887
[09/26 04:43:05 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1674, average loss: 5.9806
[09/26 04:43:05 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.50	
[09/26 04:43:05 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.16746824526945162
[09/26 04:43:12 visual_prompt]: Epoch 86 / 100: avg data time: 5.97e-02, avg batch time: 0.5036, average train loss: 5.4173
[09/26 04:43:14 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1674, average loss: 5.9761
[09/26 04:43:14 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 04:43:14 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.14631550892634126
[09/26 04:43:20 visual_prompt]: Epoch 87 / 100: avg data time: 6.14e-02, avg batch time: 0.5039, average train loss: 5.3030
[09/26 04:43:22 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1676, average loss: 5.9131
[09/26 04:43:22 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.00	top5: 4.50	
[09/26 04:43:22 visual_prompt]: Best epoch 87: best metric: 0.020
[09/26 04:43:22 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.12650744212604148
[09/26 04:43:29 visual_prompt]: Epoch 88 / 100: avg data time: 5.36e-02, avg batch time: 0.4980, average train loss: 5.2818
[09/26 04:43:30 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1679, average loss: 6.0620
[09/26 04:43:30 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 5.00	
[09/26 04:43:30 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.10806817794674878
[09/26 04:43:37 visual_prompt]: Epoch 89 / 100: avg data time: 5.37e-02, avg batch time: 0.4972, average train loss: 5.3029
[09/26 04:43:39 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1676, average loss: 6.1074
[09/26 04:43:39 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 5.50	
[09/26 04:43:39 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.09102018179151586
[09/26 04:43:46 visual_prompt]: Epoch 90 / 100: avg data time: 6.49e-02, avg batch time: 0.5075, average train loss: 5.3538
[09/26 04:43:47 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1677, average loss: 5.9601
[09/26 04:43:47 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 6.00	
[09/26 04:43:47 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.0753842240176146
[09/26 04:43:54 visual_prompt]: Epoch 91 / 100: avg data time: 6.50e-02, avg batch time: 0.5075, average train loss: 5.2461
[09/26 04:43:56 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1678, average loss: 5.9108
[09/26 04:43:56 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.00	top5: 7.50	
[09/26 04:43:56 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.061179354631058086
[09/26 04:44:03 visual_prompt]: Epoch 92 / 100: avg data time: 6.60e-02, avg batch time: 0.5087, average train loss: 5.1686
[09/26 04:44:04 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1676, average loss: 5.8229
[09/26 04:44:04 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 8.00	
[09/26 04:44:04 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.04842288007710138
[09/26 04:44:11 visual_prompt]: Epoch 93 / 100: avg data time: 5.03e-02, avg batch time: 0.4933, average train loss: 5.1016
[09/26 04:44:13 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1672, average loss: 5.7875
[09/26 04:44:13 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.00	top5: 7.50	
[09/26 04:44:13 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.03713034215500441
[09/26 04:44:20 visual_prompt]: Epoch 94 / 100: avg data time: 6.80e-02, avg batch time: 0.5116, average train loss: 5.0708
[09/26 04:44:21 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1675, average loss: 5.7610
[09/26 04:44:21 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 7.50	
[09/26 04:44:21 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.02731549908274289
[09/26 04:44:28 visual_prompt]: Epoch 95 / 100: avg data time: 5.99e-02, avg batch time: 0.5019, average train loss: 5.0238
[09/26 04:44:30 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1673, average loss: 5.7430
[09/26 04:44:30 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 7.50	
[09/26 04:44:30 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.018990308734739975
[09/26 04:44:36 visual_prompt]: Epoch 96 / 100: avg data time: 6.25e-02, avg batch time: 0.5061, average train loss: 4.9764
[09/26 04:44:38 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1671, average loss: 5.7542
[09/26 04:44:38 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.50	top5: 8.50	
[09/26 04:44:38 visual_prompt]: Best epoch 96: best metric: 0.025
[09/26 04:44:38 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.012164914073037048
[09/26 04:44:45 visual_prompt]: Epoch 97 / 100: avg data time: 5.69e-02, avg batch time: 0.4995, average train loss: 4.9567
[09/26 04:44:46 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1672, average loss: 5.7370
[09/26 04:44:46 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.00	top5: 9.00	
[09/26 04:44:46 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.006847630789658388
[09/26 04:44:53 visual_prompt]: Epoch 98 / 100: avg data time: 6.00e-02, avg batch time: 0.5030, average train loss: 4.9351
[09/26 04:44:55 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1673, average loss: 5.7339
[09/26 04:44:55 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.00	top5: 9.00	
[09/26 04:44:55 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.003044937175219753
[09/26 04:45:02 visual_prompt]: Epoch 99 / 100: avg data time: 6.72e-02, avg batch time: 0.5106, average train loss: 4.9195
[09/26 04:45:04 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1674, average loss: 5.7315
[09/26 04:45:04 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.50	top5: 9.00	
[09/26 04:45:04 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0007614662261302974
[09/26 04:45:10 visual_prompt]: Epoch 100 / 100: avg data time: 6.55e-02, avg batch time: 0.5092, average train loss: 4.9085
[09/26 04:45:12 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1675, average loss: 5.7289
[09/26 04:45:12 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.50	top5: 9.00	
[09/26 04:45:12 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 04:45:12 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              0
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 04:45:12 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-sun397', 'DATA.NUMBER_CLASSES', '397', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 04:45:12 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 04:45:12 visual_prompt]: Training with config:
[09/26 04:45:12 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-sun397/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr2.5_wd0.001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 2.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-sun397', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 397, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 04:45:12 visual_prompt]: Loading training data...
[09/26 04:45:12 visual_prompt]: Constructing vtab-sun397 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split train[:800], from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/26 04:45:13 visual_prompt]: Number of images: 800
[09/26 04:45:13 visual_prompt]: Number of classes: 309 / 397
[09/26 04:45:13 visual_prompt]: Loading validation data...
[09/26 04:45:13 visual_prompt]: Constructing vtab-sun397 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split validation[:200], from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/26 04:45:14 visual_prompt]: Number of images: 200
[09/26 04:45:14 visual_prompt]: Number of classes: 136 / 397
[09/26 04:45:14 visual_prompt]: Constructing models...
[09/26 04:45:16 visual_prompt]: Total Parameters: 86564749	 Gradient Parameters: 766093
[09/26 04:45:16 visual_prompt]: tuned percent:0.885
[09/26 04:45:16 visual_prompt]: Device used for model: 0
[09/26 04:45:16 visual_prompt]: Setting up Evaluator...
[09/26 04:45:16 visual_prompt]: Setting up Trainer...
[09/26 04:45:16 visual_prompt]: 	Setting up the optimizer...
[09/26 04:45:16 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 04:45:23 visual_prompt]: Epoch 1 / 100: avg data time: 6.41e-02, avg batch time: 0.5099, average train loss: 5.9897
[09/26 04:45:25 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1675, average loss: 6.0097
[09/26 04:45:25 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/26 04:45:25 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.25
[09/26 04:45:32 visual_prompt]: Epoch 2 / 100: avg data time: 6.93e-02, avg batch time: 0.5127, average train loss: 5.8215
[09/26 04:45:34 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1674, average loss: 5.8544
[09/26 04:45:34 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 04:45:34 visual_prompt]: Best epoch 2: best metric: 0.005
[09/26 04:45:34 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.5
[09/26 04:45:41 visual_prompt]: Epoch 3 / 100: avg data time: 6.77e-02, avg batch time: 0.5104, average train loss: 5.5998
[09/26 04:45:42 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1676, average loss: 5.7560
[09/26 04:45:42 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.50	top5: 6.50	
[09/26 04:45:42 visual_prompt]: Best epoch 3: best metric: 0.025
[09/26 04:45:42 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.75
[09/26 04:45:49 visual_prompt]: Epoch 4 / 100: avg data time: 6.83e-02, avg batch time: 0.5121, average train loss: 5.3718
[09/26 04:45:51 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1674, average loss: 5.4521
[09/26 04:45:51 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 11.00	
[09/26 04:45:51 visual_prompt]: Training 5 / 100 epoch, with learning rate 1.0
[09/26 04:45:58 visual_prompt]: Epoch 5 / 100: avg data time: 5.88e-02, avg batch time: 0.5030, average train loss: 4.7985
[09/26 04:45:59 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1674, average loss: 4.9691
[09/26 04:45:59 visual_prompt]: Classification results with val_vtab-sun397: top1: 12.00	top5: 23.00	
[09/26 04:45:59 visual_prompt]: Best epoch 5: best metric: 0.120
[09/26 04:45:59 visual_prompt]: Training 6 / 100 epoch, with learning rate 1.25
[09/26 04:46:06 visual_prompt]: Epoch 6 / 100: avg data time: 5.95e-02, avg batch time: 0.5017, average train loss: 3.2750
[09/26 04:46:08 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1680, average loss: 4.0242
[09/26 04:46:08 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 49.00	
[09/26 04:46:08 visual_prompt]: Best epoch 6: best metric: 0.280
[09/26 04:46:08 visual_prompt]: Training 7 / 100 epoch, with learning rate 1.5
[09/26 04:46:15 visual_prompt]: Epoch 7 / 100: avg data time: 6.82e-02, avg batch time: 0.5123, average train loss: 1.3594
[09/26 04:46:16 visual_prompt]: Inference (val):avg data time: 3.26e-05, avg batch time: 0.1671, average loss: 3.2786
[09/26 04:46:16 visual_prompt]: Classification results with val_vtab-sun397: top1: 40.00	top5: 64.50	
[09/26 04:46:16 visual_prompt]: Best epoch 7: best metric: 0.400
[09/26 04:46:16 visual_prompt]: Training 8 / 100 epoch, with learning rate 1.75
[09/26 04:46:23 visual_prompt]: Epoch 8 / 100: avg data time: 5.86e-02, avg batch time: 0.5017, average train loss: 0.3968
[09/26 04:46:25 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1674, average loss: 2.9114
[09/26 04:46:25 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.50	top5: 69.00	
[09/26 04:46:25 visual_prompt]: Best epoch 8: best metric: 0.425
[09/26 04:46:25 visual_prompt]: Training 9 / 100 epoch, with learning rate 2.0
[09/26 04:46:32 visual_prompt]: Epoch 9 / 100: avg data time: 4.83e-02, avg batch time: 0.4928, average train loss: 0.1798
[09/26 04:46:33 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1676, average loss: 2.9379
[09/26 04:46:33 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.50	top5: 69.50	
[09/26 04:46:33 visual_prompt]: Training 10 / 100 epoch, with learning rate 2.25
[09/26 04:46:40 visual_prompt]: Epoch 10 / 100: avg data time: 7.56e-02, avg batch time: 0.5188, average train loss: 0.1503
[09/26 04:46:42 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1671, average loss: 3.0403
[09/26 04:46:42 visual_prompt]: Classification results with val_vtab-sun397: top1: 40.00	top5: 67.00	
[09/26 04:46:42 visual_prompt]: Training 11 / 100 epoch, with learning rate 2.5
[09/26 04:46:49 visual_prompt]: Epoch 11 / 100: avg data time: 6.19e-02, avg batch time: 0.5061, average train loss: 0.2558
[09/26 04:46:50 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1676, average loss: 3.0359
[09/26 04:46:50 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.00	top5: 71.00	
[09/26 04:46:50 visual_prompt]: Training 12 / 100 epoch, with learning rate 2.4992385337738696
[09/26 04:46:57 visual_prompt]: Epoch 12 / 100: avg data time: 6.11e-02, avg batch time: 0.5045, average train loss: 0.3053
[09/26 04:46:59 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1672, average loss: 3.1782
[09/26 04:46:59 visual_prompt]: Classification results with val_vtab-sun397: top1: 40.00	top5: 66.00	
[09/26 04:46:59 visual_prompt]: Training 13 / 100 epoch, with learning rate 2.4969550628247803
[09/26 04:47:06 visual_prompt]: Epoch 13 / 100: avg data time: 6.45e-02, avg batch time: 0.5071, average train loss: 0.4426
[09/26 04:47:07 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1675, average loss: 3.2843
[09/26 04:47:07 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.00	top5: 61.00	
[09/26 04:47:07 visual_prompt]: Training 14 / 100 epoch, with learning rate 2.4931523692103417
[09/26 04:47:14 visual_prompt]: Epoch 14 / 100: avg data time: 5.56e-02, avg batch time: 0.4997, average train loss: 0.2918
[09/26 04:47:16 visual_prompt]: Inference (val):avg data time: 4.03e-05, avg batch time: 0.1674, average loss: 2.9690
[09/26 04:47:16 visual_prompt]: Classification results with val_vtab-sun397: top1: 44.00	top5: 67.50	
[09/26 04:47:16 visual_prompt]: Best epoch 14: best metric: 0.440
[09/26 04:47:16 visual_prompt]: Training 15 / 100 epoch, with learning rate 2.487835085926963
[09/26 04:47:23 visual_prompt]: Epoch 15 / 100: avg data time: 5.82e-02, avg batch time: 0.5023, average train loss: 0.1812
[09/26 04:47:24 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1675, average loss: 3.0133
[09/26 04:47:24 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.50	top5: 70.00	
[09/26 04:47:24 visual_prompt]: Training 16 / 100 epoch, with learning rate 2.4810096912652604
[09/26 04:47:31 visual_prompt]: Epoch 16 / 100: avg data time: 6.32e-02, avg batch time: 0.5067, average train loss: 0.2094
[09/26 04:47:33 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1677, average loss: 3.1458
[09/26 04:47:33 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.50	top5: 68.00	
[09/26 04:47:33 visual_prompt]: Training 17 / 100 epoch, with learning rate 2.472684500917257
[09/26 04:47:40 visual_prompt]: Epoch 17 / 100: avg data time: 6.31e-02, avg batch time: 0.5069, average train loss: 0.2671
[09/26 04:47:41 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1673, average loss: 3.0136
[09/26 04:47:41 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.00	top5: 71.00	
[09/26 04:47:41 visual_prompt]: Training 18 / 100 epoch, with learning rate 2.4628696578449953
[09/26 04:47:48 visual_prompt]: Epoch 18 / 100: avg data time: 6.55e-02, avg batch time: 0.5089, average train loss: 0.2236
[09/26 04:47:50 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1676, average loss: 2.9953
[09/26 04:47:50 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.00	top5: 69.50	
[09/26 04:47:50 visual_prompt]: Training 19 / 100 epoch, with learning rate 2.4515771199228986
[09/26 04:47:57 visual_prompt]: Epoch 19 / 100: avg data time: 6.04e-02, avg batch time: 0.5035, average train loss: 0.2112
[09/26 04:47:59 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1676, average loss: 3.0251
[09/26 04:47:59 visual_prompt]: Classification results with val_vtab-sun397: top1: 40.50	top5: 68.50	
[09/26 04:47:59 visual_prompt]: Training 20 / 100 epoch, with learning rate 2.438820645368942
[09/26 04:48:05 visual_prompt]: Epoch 20 / 100: avg data time: 5.61e-02, avg batch time: 0.4991, average train loss: 0.2512
[09/26 04:48:07 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1669, average loss: 3.2981
[09/26 04:48:07 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.50	top5: 65.50	
[09/26 04:48:07 visual_prompt]: Training 21 / 100 epoch, with learning rate 2.4246157759823856
[09/26 04:48:14 visual_prompt]: Epoch 21 / 100: avg data time: 6.05e-02, avg batch time: 0.5028, average train loss: 1.0834
[09/26 04:48:15 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1671, average loss: 5.7782
[09/26 04:48:15 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 5.50	
[09/26 04:48:15 visual_prompt]: Training 22 / 100 epoch, with learning rate 2.4089798182084845
[09/26 04:48:22 visual_prompt]: Epoch 22 / 100: avg data time: 5.78e-02, avg batch time: 0.5011, average train loss: 5.6265
[09/26 04:48:24 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1672, average loss: 5.8327
[09/26 04:48:24 visual_prompt]: Classification results with val_vtab-sun397: top1: 3.50	top5: 7.00	
[09/26 04:48:24 visual_prompt]: Training 23 / 100 epoch, with learning rate 2.391931822053251
[09/26 04:48:31 visual_prompt]: Epoch 23 / 100: avg data time: 6.14e-02, avg batch time: 0.5053, average train loss: 5.3635
[09/26 04:48:32 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1680, average loss: 5.3166
[09/26 04:48:32 visual_prompt]: Classification results with val_vtab-sun397: top1: 6.00	top5: 17.50	
[09/26 04:48:32 visual_prompt]: Training 24 / 100 epoch, with learning rate 2.3734925578739587
[09/26 04:48:39 visual_prompt]: Epoch 24 / 100: avg data time: 4.95e-02, avg batch time: 0.4935, average train loss: 4.5145
[09/26 04:48:41 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1672, average loss: 5.0209
[09/26 04:48:41 visual_prompt]: Classification results with val_vtab-sun397: top1: 11.00	top5: 28.00	
[09/26 04:48:41 visual_prompt]: Training 25 / 100 epoch, with learning rate 2.3536844910736585
[09/26 04:48:48 visual_prompt]: Epoch 25 / 100: avg data time: 6.26e-02, avg batch time: 0.5084, average train loss: 3.4928
[09/26 04:48:49 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1676, average loss: 4.1675
[09/26 04:48:49 visual_prompt]: Classification results with val_vtab-sun397: top1: 24.50	top5: 46.50	
[09/26 04:48:49 visual_prompt]: Training 26 / 100 epoch, with learning rate 2.3325317547305486
[09/26 04:48:56 visual_prompt]: Epoch 26 / 100: avg data time: 6.41e-02, avg batch time: 0.5080, average train loss: 2.2372
[09/26 04:48:58 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1673, average loss: 3.9564
[09/26 04:48:58 visual_prompt]: Classification results with val_vtab-sun397: top1: 25.50	top5: 54.00	
[09/26 04:48:58 visual_prompt]: Training 27 / 100 epoch, with learning rate 2.310060120195532
[09/26 04:49:05 visual_prompt]: Epoch 27 / 100: avg data time: 5.91e-02, avg batch time: 0.5041, average train loss: 2.1269
[09/26 04:49:06 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1679, average loss: 4.0357
[09/26 04:49:06 visual_prompt]: Classification results with val_vtab-sun397: top1: 19.50	top5: 51.50	
[09/26 04:49:06 visual_prompt]: Training 28 / 100 epoch, with learning rate 2.286296965693802
[09/26 04:49:13 visual_prompt]: Epoch 28 / 100: avg data time: 6.82e-02, avg batch time: 0.5119, average train loss: 0.8102
[09/26 04:49:15 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1675, average loss: 3.6216
[09/26 04:49:15 visual_prompt]: Classification results with val_vtab-sun397: top1: 25.50	top5: 55.00	
[09/26 04:49:15 visual_prompt]: Training 29 / 100 epoch, with learning rate 2.261271242968684
[09/26 04:49:21 visual_prompt]: Epoch 29 / 100: avg data time: 4.83e-02, avg batch time: 0.4931, average train loss: 0.4453
[09/26 04:49:23 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1673, average loss: 3.3954
[09/26 04:49:23 visual_prompt]: Classification results with val_vtab-sun397: top1: 32.50	top5: 61.00	
[09/26 04:49:23 visual_prompt]: Training 30 / 100 epoch, with learning rate 2.2350134420084022
[09/26 04:49:30 visual_prompt]: Epoch 30 / 100: avg data time: 6.61e-02, avg batch time: 0.5104, average train loss: 0.2732
[09/26 04:49:32 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1669, average loss: 3.1779
[09/26 04:49:32 visual_prompt]: Classification results with val_vtab-sun397: top1: 30.00	top5: 66.50	
[09/26 04:49:32 visual_prompt]: Training 31 / 100 epoch, with learning rate 2.2075555538987226
[09/26 04:49:39 visual_prompt]: Epoch 31 / 100: avg data time: 5.79e-02, avg batch time: 0.5026, average train loss: 0.2791
[09/26 04:49:40 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1672, average loss: 3.3325
[09/26 04:49:40 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.00	top5: 65.00	
[09/26 04:49:40 visual_prompt]: Training 32 / 100 epoch, with learning rate 2.178931031846743
[09/26 04:49:47 visual_prompt]: Epoch 32 / 100: avg data time: 5.82e-02, avg batch time: 0.5019, average train loss: 0.2838
[09/26 04:49:49 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1670, average loss: 3.4409
[09/26 04:49:49 visual_prompt]: Classification results with val_vtab-sun397: top1: 30.00	top5: 61.00	
[09/26 04:49:49 visual_prompt]: Training 33 / 100 epoch, with learning rate 2.149174750423314
[09/26 04:49:55 visual_prompt]: Epoch 33 / 100: avg data time: 5.87e-02, avg batch time: 0.5028, average train loss: 0.3016
[09/26 04:49:57 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1672, average loss: 3.1528
[09/26 04:49:57 visual_prompt]: Classification results with val_vtab-sun397: top1: 40.50	top5: 66.00	
[09/26 04:49:57 visual_prompt]: Training 34 / 100 epoch, with learning rate 2.1183229630737466
[09/26 04:50:04 visual_prompt]: Epoch 34 / 100: avg data time: 6.55e-02, avg batch time: 0.5099, average train loss: 0.2396
[09/26 04:50:05 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1675, average loss: 3.0981
[09/26 04:50:05 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 69.00	
[09/26 04:50:05 visual_prompt]: Training 35 / 100 epoch, with learning rate 2.086413257948573
[09/26 04:50:12 visual_prompt]: Epoch 35 / 100: avg data time: 6.51e-02, avg batch time: 0.5089, average train loss: 0.2171
[09/26 04:50:14 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1675, average loss: 3.0811
[09/26 04:50:14 visual_prompt]: Classification results with val_vtab-sun397: top1: 43.00	top5: 70.50	
[09/26 04:50:14 visual_prompt]: Training 36 / 100 epoch, with learning rate 2.053484512108174
[09/26 04:50:21 visual_prompt]: Epoch 36 / 100: avg data time: 5.10e-02, avg batch time: 0.4962, average train loss: 0.2067
[09/26 04:50:22 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1673, average loss: 3.0670
[09/26 04:50:22 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.00	top5: 70.00	
[09/26 04:50:22 visual_prompt]: Training 37 / 100 epoch, with learning rate 2.019576844157073
[09/26 04:50:29 visual_prompt]: Epoch 37 / 100: avg data time: 6.41e-02, avg batch time: 0.5085, average train loss: 0.2021
[09/26 04:50:31 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1673, average loss: 3.0859
[09/26 04:50:31 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 70.50	
[09/26 04:50:31 visual_prompt]: Training 38 / 100 epoch, with learning rate 1.9847315653655915
[09/26 04:50:38 visual_prompt]: Epoch 38 / 100: avg data time: 5.73e-02, avg batch time: 0.5011, average train loss: 0.2582
[09/26 04:50:39 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1671, average loss: 3.2592
[09/26 04:50:39 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.50	top5: 66.00	
[09/26 04:50:39 visual_prompt]: Training 39 / 100 epoch, with learning rate 1.9489911293384334
[09/26 04:50:46 visual_prompt]: Epoch 39 / 100: avg data time: 6.01e-02, avg batch time: 0.5033, average train loss: 0.2418
[09/26 04:50:48 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1671, average loss: 3.0301
[09/26 04:50:48 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.50	top5: 70.00	
[09/26 04:50:48 visual_prompt]: Training 40 / 100 epoch, with learning rate 1.912399080291506
[09/26 04:50:55 visual_prompt]: Epoch 40 / 100: avg data time: 6.41e-02, avg batch time: 0.5076, average train loss: 0.1953
[09/26 04:50:56 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.1672, average loss: 2.9937
[09/26 04:50:56 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.50	top5: 69.00	
[09/26 04:50:56 visual_prompt]: Training 41 / 100 epoch, with learning rate 1.875
[09/26 04:51:03 visual_prompt]: Epoch 41 / 100: avg data time: 7.04e-02, avg batch time: 0.5133, average train loss: 0.1572
[09/26 04:51:05 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1672, average loss: 3.0814
[09/26 04:51:05 visual_prompt]: Classification results with val_vtab-sun397: top1: 43.00	top5: 70.50	
[09/26 04:51:05 visual_prompt]: Training 42 / 100 epoch, with learning rate 1.8368394534823635
[09/26 04:51:12 visual_prompt]: Epoch 42 / 100: avg data time: 6.36e-02, avg batch time: 0.5070, average train loss: 0.1651
[09/26 04:51:14 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1669, average loss: 3.0563
[09/26 04:51:14 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.50	top5: 71.00	
[09/26 04:51:14 visual_prompt]: Training 43 / 100 epoch, with learning rate 1.7979639334863466
[09/26 04:51:21 visual_prompt]: Epoch 43 / 100: avg data time: 6.70e-02, avg batch time: 0.5112, average train loss: 0.1769
[09/26 04:51:22 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1672, average loss: 3.0660
[09/26 04:51:22 visual_prompt]: Classification results with val_vtab-sun397: top1: 43.50	top5: 70.50	
[09/26 04:51:22 visual_prompt]: Training 44 / 100 epoch, with learning rate 1.7584208038447504
[09/26 04:51:29 visual_prompt]: Epoch 44 / 100: avg data time: 6.77e-02, avg batch time: 0.5118, average train loss: 0.1987
[09/26 04:51:31 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1676, average loss: 2.9942
[09/26 04:51:31 visual_prompt]: Classification results with val_vtab-sun397: top1: 46.00	top5: 74.00	
[09/26 04:51:31 visual_prompt]: Best epoch 44: best metric: 0.460
[09/26 04:51:31 visual_prompt]: Training 45 / 100 epoch, with learning rate 1.7182582417698902
[09/26 04:51:38 visual_prompt]: Epoch 45 / 100: avg data time: 6.71e-02, avg batch time: 0.5106, average train loss: 0.1761
[09/26 04:51:40 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1676, average loss: 3.0276
[09/26 04:51:40 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.50	top5: 73.50	
[09/26 04:51:40 visual_prompt]: Training 46 / 100 epoch, with learning rate 1.6775251791570862
[09/26 04:51:47 visual_prompt]: Epoch 46 / 100: avg data time: 7.42e-02, avg batch time: 0.5167, average train loss: 0.1701
[09/26 04:51:48 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1679, average loss: 3.0310
[09/26 04:51:48 visual_prompt]: Classification results with val_vtab-sun397: top1: 44.00	top5: 72.50	
[09/26 04:51:48 visual_prompt]: Training 47 / 100 epoch, with learning rate 1.6362712429686843
[09/26 04:51:55 visual_prompt]: Epoch 47 / 100: avg data time: 6.22e-02, avg batch time: 0.5053, average train loss: 0.1826
[09/26 04:51:57 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1674, average loss: 3.0086
[09/26 04:51:57 visual_prompt]: Classification results with val_vtab-sun397: top1: 44.00	top5: 74.00	
[09/26 04:51:57 visual_prompt]: Training 48 / 100 epoch, with learning rate 1.5945466947712488
[09/26 04:52:04 visual_prompt]: Epoch 48 / 100: avg data time: 5.05e-02, avg batch time: 0.4941, average train loss: 0.1683
[09/26 04:52:05 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1678, average loss: 3.0185
[09/26 04:52:05 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.50	top5: 71.00	
[09/26 04:52:05 visual_prompt]: Training 49 / 100 epoch, with learning rate 1.5524023694995845
[09/26 04:52:12 visual_prompt]: Epoch 49 / 100: avg data time: 6.48e-02, avg batch time: 0.5082, average train loss: 2.7915
[09/26 04:52:14 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1678, average loss: 4.8707
[09/26 04:52:14 visual_prompt]: Classification results with val_vtab-sun397: top1: 16.00	top5: 32.00	
[09/26 04:52:14 visual_prompt]: Training 50 / 100 epoch, with learning rate 1.509889613522199
[09/26 04:52:21 visual_prompt]: Epoch 50 / 100: avg data time: 5.75e-02, avg batch time: 0.5000, average train loss: 0.9626
[09/26 04:52:22 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1679, average loss: 3.0313
[09/26 04:52:22 visual_prompt]: Classification results with val_vtab-sun397: top1: 36.50	top5: 68.50	
[09/26 04:52:22 visual_prompt]: Training 51 / 100 epoch, with learning rate 1.467060222083663
[09/26 04:52:29 visual_prompt]: Epoch 51 / 100: avg data time: 6.54e-02, avg batch time: 0.5083, average train loss: 0.1923
[09/26 04:52:31 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1675, average loss: 2.8943
[09/26 04:52:31 visual_prompt]: Classification results with val_vtab-sun397: top1: 44.00	top5: 71.50	
[09/26 04:52:31 visual_prompt]: Training 52 / 100 epoch, with learning rate 1.4239663762000818
[09/26 04:52:38 visual_prompt]: Epoch 52 / 100: avg data time: 5.46e-02, avg batch time: 0.4982, average train loss: 0.1132
[09/26 04:52:39 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1679, average loss: 2.9180
[09/26 04:52:39 visual_prompt]: Classification results with val_vtab-sun397: top1: 43.50	top5: 71.00	
[09/26 04:52:39 visual_prompt]: Training 53 / 100 epoch, with learning rate 1.380660579084567
[09/26 04:52:46 visual_prompt]: Epoch 53 / 100: avg data time: 6.20e-02, avg batch time: 0.5057, average train loss: 0.1211
[09/26 04:52:48 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1681, average loss: 2.9652
[09/26 04:52:48 visual_prompt]: Classification results with val_vtab-sun397: top1: 44.50	top5: 71.00	
[09/26 04:52:48 visual_prompt]: Training 54 / 100 epoch, with learning rate 1.3371955921801564
[09/26 04:52:55 visual_prompt]: Epoch 54 / 100: avg data time: 6.48e-02, avg batch time: 0.5100, average train loss: 0.1469
[09/26 04:52:56 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1676, average loss: 2.9770
[09/26 04:52:56 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.50	top5: 72.50	
[09/26 04:52:56 visual_prompt]: Training 55 / 100 epoch, with learning rate 1.2936243708781263
[09/26 04:53:03 visual_prompt]: Epoch 55 / 100: avg data time: 4.80e-02, avg batch time: 0.4933, average train loss: 0.1609
[09/26 04:53:05 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.1674, average loss: 2.9937
[09/26 04:53:05 visual_prompt]: Classification results with val_vtab-sun397: top1: 43.50	top5: 74.50	
[09/26 04:53:05 visual_prompt]: Training 56 / 100 epoch, with learning rate 1.25
[09/26 04:53:12 visual_prompt]: Epoch 56 / 100: avg data time: 5.77e-02, avg batch time: 0.5011, average train loss: 0.1569
[09/26 04:53:13 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1670, average loss: 2.9880
[09/26 04:53:13 visual_prompt]: Classification results with val_vtab-sun397: top1: 43.50	top5: 72.00	
[09/26 04:53:13 visual_prompt]: Training 57 / 100 epoch, with learning rate 1.2063756291218741
[09/26 04:53:20 visual_prompt]: Epoch 57 / 100: avg data time: 4.71e-02, avg batch time: 0.4911, average train loss: 0.1513
[09/26 04:53:21 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1672, average loss: 2.9878
[09/26 04:53:21 visual_prompt]: Classification results with val_vtab-sun397: top1: 44.50	top5: 74.50	
[09/26 04:53:21 visual_prompt]: Training 58 / 100 epoch, with learning rate 1.1628044078198434
[09/26 04:53:28 visual_prompt]: Epoch 58 / 100: avg data time: 6.59e-02, avg batch time: 0.5093, average train loss: 0.1479
[09/26 04:53:30 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1672, average loss: 3.0090
[09/26 04:53:30 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.00	top5: 73.00	
[09/26 04:53:30 visual_prompt]: Training 59 / 100 epoch, with learning rate 1.1193394209154333
[09/26 04:53:37 visual_prompt]: Epoch 59 / 100: avg data time: 5.90e-02, avg batch time: 0.5032, average train loss: 0.1475
[09/26 04:53:38 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1681, average loss: 3.0040
[09/26 04:53:38 visual_prompt]: Classification results with val_vtab-sun397: top1: 44.50	top5: 75.00	
[09/26 04:53:38 visual_prompt]: Training 60 / 100 epoch, with learning rate 1.0760336237999186
[09/26 04:53:45 visual_prompt]: Epoch 60 / 100: avg data time: 5.74e-02, avg batch time: 0.5013, average train loss: 0.1502
[09/26 04:53:47 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1680, average loss: 3.0045
[09/26 04:53:47 visual_prompt]: Classification results with val_vtab-sun397: top1: 44.50	top5: 73.50	
[09/26 04:53:47 visual_prompt]: Training 61 / 100 epoch, with learning rate 1.0329397779163372
[09/26 04:53:54 visual_prompt]: Epoch 61 / 100: avg data time: 6.64e-02, avg batch time: 0.5090, average train loss: 0.1501
[09/26 04:53:55 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1679, average loss: 3.0177
[09/26 04:53:55 visual_prompt]: Classification results with val_vtab-sun397: top1: 44.50	top5: 73.00	
[09/26 04:53:55 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.990110386477801
[09/26 04:54:02 visual_prompt]: Epoch 62 / 100: avg data time: 6.30e-02, avg batch time: 0.5068, average train loss: 0.1501
[09/26 04:54:04 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1678, average loss: 3.0185
[09/26 04:54:04 visual_prompt]: Classification results with val_vtab-sun397: top1: 44.00	top5: 74.00	
[09/26 04:54:04 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.9475976305004155
[09/26 04:54:11 visual_prompt]: Epoch 63 / 100: avg data time: 5.97e-02, avg batch time: 0.5029, average train loss: 0.1466
[09/26 04:54:12 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1676, average loss: 2.9892
[09/26 04:54:12 visual_prompt]: Classification results with val_vtab-sun397: top1: 46.00	top5: 74.00	
[09/26 04:54:12 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.9054533052287511
[09/26 04:54:19 visual_prompt]: Epoch 64 / 100: avg data time: 5.31e-02, avg batch time: 0.4973, average train loss: 0.1373
[09/26 04:54:21 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.1679, average loss: 2.9693
[09/26 04:54:21 visual_prompt]: Classification results with val_vtab-sun397: top1: 45.50	top5: 74.50	
[09/26 04:54:21 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.8637287570313158
[09/26 04:54:28 visual_prompt]: Epoch 65 / 100: avg data time: 6.00e-02, avg batch time: 0.5028, average train loss: 0.1350
[09/26 04:54:29 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1672, average loss: 2.9807
[09/26 04:54:29 visual_prompt]: Classification results with val_vtab-sun397: top1: 46.00	top5: 74.00	
[09/26 04:54:29 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.8224748208429142
[09/26 04:54:36 visual_prompt]: Epoch 66 / 100: avg data time: 5.68e-02, avg batch time: 0.5011, average train loss: 0.1288
[09/26 04:54:38 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1671, average loss: 2.9800
[09/26 04:54:38 visual_prompt]: Classification results with val_vtab-sun397: top1: 47.50	top5: 73.50	
[09/26 04:54:38 visual_prompt]: Best epoch 66: best metric: 0.475
[09/26 04:54:38 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.7817417582301099
[09/26 04:54:44 visual_prompt]: Epoch 67 / 100: avg data time: 5.43e-02, avg batch time: 0.4984, average train loss: 0.1236
[09/26 04:54:46 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1672, average loss: 3.0337
[09/26 04:54:46 visual_prompt]: Classification results with val_vtab-sun397: top1: 47.50	top5: 74.00	
[09/26 04:54:46 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.7415791961552499
[09/26 04:54:53 visual_prompt]: Epoch 68 / 100: avg data time: 5.90e-02, avg batch time: 0.5027, average train loss: 0.1254
[09/26 04:54:54 visual_prompt]: Inference (val):avg data time: 1.99e-05, avg batch time: 0.1676, average loss: 3.0236
[09/26 04:54:54 visual_prompt]: Classification results with val_vtab-sun397: top1: 48.00	top5: 72.00	
[09/26 04:54:54 visual_prompt]: Best epoch 68: best metric: 0.480
[09/26 04:54:54 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.7020360665136531
[09/26 04:55:01 visual_prompt]: Epoch 69 / 100: avg data time: 6.27e-02, avg batch time: 0.5063, average train loss: 0.1263
[09/26 04:55:03 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1679, average loss: 2.9836
[09/26 04:55:03 visual_prompt]: Classification results with val_vtab-sun397: top1: 47.00	top5: 76.50	
[09/26 04:55:03 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.6631605465176369
[09/26 04:55:10 visual_prompt]: Epoch 70 / 100: avg data time: 6.08e-02, avg batch time: 0.5037, average train loss: 0.1239
[09/26 04:55:12 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1674, average loss: 3.0266
[09/26 04:55:12 visual_prompt]: Classification results with val_vtab-sun397: top1: 43.50	top5: 74.50	
[09/26 04:55:12 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.6250000000000002
[09/26 04:55:18 visual_prompt]: Epoch 71 / 100: avg data time: 5.64e-02, avg batch time: 0.5008, average train loss: 0.1261
[09/26 04:55:20 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1677, average loss: 3.0098
[09/26 04:55:20 visual_prompt]: Classification results with val_vtab-sun397: top1: 45.50	top5: 75.50	
[09/26 04:55:20 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.587600919708494
[09/26 04:55:27 visual_prompt]: Epoch 72 / 100: avg data time: 6.47e-02, avg batch time: 0.5081, average train loss: 0.1238
[09/26 04:55:28 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1678, average loss: 3.0432
[09/26 04:55:28 visual_prompt]: Classification results with val_vtab-sun397: top1: 45.00	top5: 73.00	
[09/26 04:55:28 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.5510088706615667
[09/26 04:55:35 visual_prompt]: Epoch 73 / 100: avg data time: 6.04e-02, avg batch time: 0.5049, average train loss: 0.1262
[09/26 04:55:37 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1681, average loss: 3.0158
[09/26 04:55:37 visual_prompt]: Classification results with val_vtab-sun397: top1: 47.50	top5: 73.50	
[09/26 04:55:37 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.5152684346344087
[09/26 04:55:44 visual_prompt]: Epoch 74 / 100: avg data time: 6.16e-02, avg batch time: 0.5064, average train loss: 0.1276
[09/26 04:55:46 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1677, average loss: 3.0169
[09/26 04:55:46 visual_prompt]: Classification results with val_vtab-sun397: top1: 47.50	top5: 75.00	
[09/26 04:55:46 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.48042315584292716
[09/26 04:55:53 visual_prompt]: Epoch 75 / 100: avg data time: 7.76e-02, avg batch time: 0.5206, average train loss: 0.1199
[09/26 04:55:54 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1672, average loss: 3.0072
[09/26 04:55:54 visual_prompt]: Classification results with val_vtab-sun397: top1: 47.50	top5: 75.00	
[09/26 04:55:54 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.4465154878918258
[09/26 04:56:01 visual_prompt]: Epoch 76 / 100: avg data time: 6.39e-02, avg batch time: 0.5085, average train loss: 0.1153
[09/26 04:56:03 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1679, average loss: 3.0042
[09/26 04:56:03 visual_prompt]: Classification results with val_vtab-sun397: top1: 47.50	top5: 75.00	
[09/26 04:56:03 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.41358674205142765
[09/26 04:56:10 visual_prompt]: Epoch 77 / 100: avg data time: 6.32e-02, avg batch time: 0.5063, average train loss: 0.1108
[09/26 04:56:11 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1671, average loss: 3.0043
[09/26 04:56:11 visual_prompt]: Classification results with val_vtab-sun397: top1: 46.50	top5: 76.00	
[09/26 04:56:11 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.3816770369262533
[09/26 04:56:18 visual_prompt]: Epoch 78 / 100: avg data time: 5.88e-02, avg batch time: 0.5018, average train loss: 0.1072
[09/26 04:56:20 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1678, average loss: 3.0150
[09/26 04:56:20 visual_prompt]: Classification results with val_vtab-sun397: top1: 46.50	top5: 76.50	
[09/26 04:56:20 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.35082524957668626
[09/26 04:56:27 visual_prompt]: Epoch 79 / 100: avg data time: 6.74e-02, avg batch time: 0.5122, average train loss: 0.1061
[09/26 04:56:28 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1675, average loss: 3.0236
[09/26 04:56:28 visual_prompt]: Classification results with val_vtab-sun397: top1: 47.00	top5: 76.00	
[09/26 04:56:28 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.32106896815325703
[09/26 04:56:35 visual_prompt]: Epoch 80 / 100: avg data time: 5.55e-02, avg batch time: 0.4983, average train loss: 0.1049
[09/26 04:56:37 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1673, average loss: 3.0340
[09/26 04:56:37 visual_prompt]: Classification results with val_vtab-sun397: top1: 47.50	top5: 75.50	
[09/26 04:56:37 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.2924444461012776
[09/26 04:56:44 visual_prompt]: Epoch 81 / 100: avg data time: 7.55e-02, avg batch time: 0.5184, average train loss: 0.1029
[09/26 04:56:46 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1675, average loss: 3.0308
[09/26 04:56:46 visual_prompt]: Classification results with val_vtab-sun397: top1: 45.50	top5: 74.50	
[09/26 04:56:46 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.26498655799159765
[09/26 04:56:52 visual_prompt]: Epoch 82 / 100: avg data time: 5.91e-02, avg batch time: 0.5018, average train loss: 0.0997
[09/26 04:56:54 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1678, average loss: 3.0184
[09/26 04:56:54 visual_prompt]: Classification results with val_vtab-sun397: top1: 47.00	top5: 75.50	
[09/26 04:56:54 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.23872875703131582
[09/26 04:57:01 visual_prompt]: Epoch 83 / 100: avg data time: 6.02e-02, avg batch time: 0.5050, average train loss: 0.0993
[09/26 04:57:03 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1675, average loss: 3.0333
[09/26 04:57:03 visual_prompt]: Classification results with val_vtab-sun397: top1: 46.00	top5: 74.00	
[09/26 04:57:03 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.21370303430619797
[09/26 04:57:09 visual_prompt]: Epoch 84 / 100: avg data time: 6.45e-02, avg batch time: 0.5080, average train loss: 0.0993
[09/26 04:57:11 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1680, average loss: 3.0465
[09/26 04:57:11 visual_prompt]: Classification results with val_vtab-sun397: top1: 47.50	top5: 74.50	
[09/26 04:57:11 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.18993987980446755
[09/26 04:57:18 visual_prompt]: Epoch 85 / 100: avg data time: 5.74e-02, avg batch time: 0.5013, average train loss: 0.0979
[09/26 04:57:20 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1678, average loss: 3.0400
[09/26 04:57:20 visual_prompt]: Classification results with val_vtab-sun397: top1: 48.50	top5: 74.50	
[09/26 04:57:20 visual_prompt]: Best epoch 85: best metric: 0.485
[09/26 04:57:20 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.16746824526945162
[09/26 04:57:26 visual_prompt]: Epoch 86 / 100: avg data time: 5.01e-02, avg batch time: 0.4935, average train loss: 0.0969
[09/26 04:57:28 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1675, average loss: 3.0695
[09/26 04:57:28 visual_prompt]: Classification results with val_vtab-sun397: top1: 47.00	top5: 75.00	
[09/26 04:57:28 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.14631550892634126
[09/26 04:57:35 visual_prompt]: Epoch 87 / 100: avg data time: 6.36e-02, avg batch time: 0.5074, average train loss: 0.0961
[09/26 04:57:37 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1680, average loss: 3.0485
[09/26 04:57:37 visual_prompt]: Classification results with val_vtab-sun397: top1: 47.50	top5: 74.00	
[09/26 04:57:37 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.12650744212604148
[09/26 04:57:44 visual_prompt]: Epoch 88 / 100: avg data time: 4.93e-02, avg batch time: 0.4939, average train loss: 0.0956
[09/26 04:57:45 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1677, average loss: 3.0419
[09/26 04:57:45 visual_prompt]: Classification results with val_vtab-sun397: top1: 48.50	top5: 75.00	
[09/26 04:57:45 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.10806817794674878
[09/26 04:57:52 visual_prompt]: Epoch 89 / 100: avg data time: 6.18e-02, avg batch time: 0.5058, average train loss: 0.0952
[09/26 04:57:54 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1677, average loss: 3.0537
[09/26 04:57:54 visual_prompt]: Classification results with val_vtab-sun397: top1: 48.00	top5: 73.50	
[09/26 04:57:54 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.09102018179151586
[09/26 04:58:00 visual_prompt]: Epoch 90 / 100: avg data time: 5.71e-02, avg batch time: 0.4998, average train loss: 0.0946
[09/26 04:58:02 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1676, average loss: 3.0534
[09/26 04:58:02 visual_prompt]: Classification results with val_vtab-sun397: top1: 47.50	top5: 73.50	
[09/26 04:58:02 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.0753842240176146
[09/26 04:58:09 visual_prompt]: Epoch 91 / 100: avg data time: 6.65e-02, avg batch time: 0.5104, average train loss: 0.0942
[09/26 04:58:11 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1679, average loss: 3.0646
[09/26 04:58:11 visual_prompt]: Classification results with val_vtab-sun397: top1: 48.00	top5: 73.50	
[09/26 04:58:11 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.061179354631058086
[09/26 04:58:17 visual_prompt]: Epoch 92 / 100: avg data time: 4.59e-02, avg batch time: 0.4908, average train loss: 0.0935
[09/26 04:58:19 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1675, average loss: 3.0612
[09/26 04:58:19 visual_prompt]: Classification results with val_vtab-sun397: top1: 48.50	top5: 73.00	
[09/26 04:58:19 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.04842288007710138
[09/26 04:58:26 visual_prompt]: Epoch 93 / 100: avg data time: 6.21e-02, avg batch time: 0.5056, average train loss: 0.0932
[09/26 04:58:28 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1677, average loss: 3.0614
[09/26 04:58:28 visual_prompt]: Classification results with val_vtab-sun397: top1: 47.00	top5: 73.50	
[09/26 04:58:28 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.03713034215500441
[09/26 04:58:34 visual_prompt]: Epoch 94 / 100: avg data time: 4.70e-02, avg batch time: 0.4897, average train loss: 0.0929
[09/26 04:58:36 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1676, average loss: 3.0500
[09/26 04:58:36 visual_prompt]: Classification results with val_vtab-sun397: top1: 48.00	top5: 74.00	
[09/26 04:58:36 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.02731549908274289
[09/26 04:58:43 visual_prompt]: Epoch 95 / 100: avg data time: 5.51e-02, avg batch time: 0.5003, average train loss: 0.0927
[09/26 04:58:44 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1680, average loss: 3.0624
[09/26 04:58:44 visual_prompt]: Classification results with val_vtab-sun397: top1: 47.00	top5: 74.00	
[09/26 04:58:44 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.018990308734739975
[09/26 04:58:51 visual_prompt]: Epoch 96 / 100: avg data time: 6.62e-02, avg batch time: 0.5088, average train loss: 0.0925
[09/26 04:58:53 visual_prompt]: Inference (val):avg data time: 2.11e-05, avg batch time: 0.1676, average loss: 3.0635
[09/26 04:58:53 visual_prompt]: Classification results with val_vtab-sun397: top1: 48.50	top5: 73.50	
[09/26 04:58:53 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.012164914073037048
[09/26 04:59:00 visual_prompt]: Epoch 97 / 100: avg data time: 6.44e-02, avg batch time: 0.5075, average train loss: 0.0922
[09/26 04:59:01 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1675, average loss: 3.0627
[09/26 04:59:01 visual_prompt]: Classification results with val_vtab-sun397: top1: 48.00	top5: 73.50	
[09/26 04:59:01 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.006847630789658388
[09/26 04:59:08 visual_prompt]: Epoch 98 / 100: avg data time: 6.05e-02, avg batch time: 0.5041, average train loss: 0.0924
[09/26 04:59:10 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1675, average loss: 3.0630
[09/26 04:59:10 visual_prompt]: Classification results with val_vtab-sun397: top1: 48.00	top5: 73.50	
[09/26 04:59:10 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.003044937175219753
[09/26 04:59:17 visual_prompt]: Epoch 99 / 100: avg data time: 6.19e-02, avg batch time: 0.5048, average train loss: 0.0919
[09/26 04:59:18 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.1678, average loss: 3.0635
[09/26 04:59:18 visual_prompt]: Classification results with val_vtab-sun397: top1: 48.00	top5: 73.50	
[09/26 04:59:18 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0007614662261302974
[09/26 04:59:25 visual_prompt]: Epoch 100 / 100: avg data time: 6.38e-02, avg batch time: 0.5086, average train loss: 0.0921
[09/26 04:59:27 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1683, average loss: 3.0631
[09/26 04:59:27 visual_prompt]: Classification results with val_vtab-sun397: top1: 48.00	top5: 73.50	
[09/26 04:59:27 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 04:59:27 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              0
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 04:59:27 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-sun397', 'DATA.NUMBER_CLASSES', '397', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 04:59:27 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 04:59:27 visual_prompt]: Training with config:
[09/26 04:59:27 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-sun397/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr2.5_wd0.0001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 2.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-sun397', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 397, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 04:59:27 visual_prompt]: Loading training data...
[09/26 04:59:27 visual_prompt]: Constructing vtab-sun397 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split train[:800], from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/26 04:59:28 visual_prompt]: Number of images: 800
[09/26 04:59:28 visual_prompt]: Number of classes: 309 / 397
[09/26 04:59:28 visual_prompt]: Loading validation data...
[09/26 04:59:28 visual_prompt]: Constructing vtab-sun397 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split validation[:200], from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/26 04:59:29 visual_prompt]: Number of images: 200
[09/26 04:59:29 visual_prompt]: Number of classes: 136 / 397
[09/26 04:59:29 visual_prompt]: Constructing models...
[09/26 04:59:31 visual_prompt]: Total Parameters: 86564749	 Gradient Parameters: 766093
[09/26 04:59:31 visual_prompt]: tuned percent:0.885
[09/26 04:59:31 visual_prompt]: Device used for model: 0
[09/26 04:59:31 visual_prompt]: Setting up Evaluator...
[09/26 04:59:31 visual_prompt]: Setting up Trainer...
[09/26 04:59:31 visual_prompt]: 	Setting up the optimizer...
[09/26 04:59:31 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 04:59:38 visual_prompt]: Epoch 1 / 100: avg data time: 6.07e-02, avg batch time: 0.5055, average train loss: 5.9871
[09/26 04:59:39 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1676, average loss: 6.0097
[09/26 04:59:39 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/26 04:59:39 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.25
[09/26 04:59:46 visual_prompt]: Epoch 2 / 100: avg data time: 5.89e-02, avg batch time: 0.5035, average train loss: 5.8162
[09/26 04:59:48 visual_prompt]: Inference (val):avg data time: 2.08e-05, avg batch time: 0.1676, average loss: 5.8261
[09/26 04:59:48 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 04:59:48 visual_prompt]: Best epoch 2: best metric: 0.005
[09/26 04:59:48 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.5
[09/26 04:59:55 visual_prompt]: Epoch 3 / 100: avg data time: 5.97e-02, avg batch time: 0.5021, average train loss: 5.6127
[09/26 04:59:56 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1675, average loss: 5.7110
[09/26 04:59:56 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.50	top5: 6.50	
[09/26 04:59:56 visual_prompt]: Best epoch 3: best metric: 0.025
[09/26 04:59:56 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.75
[09/26 05:00:03 visual_prompt]: Epoch 4 / 100: avg data time: 6.19e-02, avg batch time: 0.5057, average train loss: 5.3029
[09/26 05:00:05 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1675, average loss: 5.8186
[09/26 05:00:05 visual_prompt]: Classification results with val_vtab-sun397: top1: 3.50	top5: 12.00	
[09/26 05:00:05 visual_prompt]: Best epoch 4: best metric: 0.035
[09/26 05:00:05 visual_prompt]: Training 5 / 100 epoch, with learning rate 1.0
[09/26 05:00:12 visual_prompt]: Epoch 5 / 100: avg data time: 4.79e-02, avg batch time: 0.4928, average train loss: 4.7145
[09/26 05:00:13 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1675, average loss: 4.8474
[09/26 05:00:13 visual_prompt]: Classification results with val_vtab-sun397: top1: 12.00	top5: 30.00	
[09/26 05:00:13 visual_prompt]: Best epoch 5: best metric: 0.120
[09/26 05:00:13 visual_prompt]: Training 6 / 100 epoch, with learning rate 1.25
[09/26 05:00:20 visual_prompt]: Epoch 6 / 100: avg data time: 5.79e-02, avg batch time: 0.5010, average train loss: 3.3649
[09/26 05:00:22 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1678, average loss: 4.0385
[09/26 05:00:22 visual_prompt]: Classification results with val_vtab-sun397: top1: 25.00	top5: 49.00	
[09/26 05:00:22 visual_prompt]: Best epoch 6: best metric: 0.250
[09/26 05:00:22 visual_prompt]: Training 7 / 100 epoch, with learning rate 1.5
[09/26 05:00:29 visual_prompt]: Epoch 7 / 100: avg data time: 5.39e-02, avg batch time: 0.4970, average train loss: 1.4216
[09/26 05:00:30 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1676, average loss: 3.1452
[09/26 05:00:30 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.00	top5: 62.50	
[09/26 05:00:30 visual_prompt]: Best epoch 7: best metric: 0.370
[09/26 05:00:30 visual_prompt]: Training 8 / 100 epoch, with learning rate 1.75
[09/26 05:00:37 visual_prompt]: Epoch 8 / 100: avg data time: 7.03e-02, avg batch time: 0.5126, average train loss: 0.3127
[09/26 05:00:39 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1677, average loss: 3.1389
[09/26 05:00:39 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.00	top5: 68.00	
[09/26 05:00:39 visual_prompt]: Training 9 / 100 epoch, with learning rate 2.0
[09/26 05:00:46 visual_prompt]: Epoch 9 / 100: avg data time: 6.55e-02, avg batch time: 0.5100, average train loss: 0.0822
[09/26 05:00:47 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1675, average loss: 3.1026
[09/26 05:00:47 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.00	top5: 67.00	
[09/26 05:00:47 visual_prompt]: Training 10 / 100 epoch, with learning rate 2.25
[09/26 05:00:54 visual_prompt]: Epoch 10 / 100: avg data time: 6.14e-02, avg batch time: 0.5052, average train loss: 0.0315
[09/26 05:00:56 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1678, average loss: 3.1497
[09/26 05:00:56 visual_prompt]: Classification results with val_vtab-sun397: top1: 36.00	top5: 67.00	
[09/26 05:00:56 visual_prompt]: Training 11 / 100 epoch, with learning rate 2.5
[09/26 05:01:03 visual_prompt]: Epoch 11 / 100: avg data time: 6.00e-02, avg batch time: 0.5034, average train loss: 0.0187
[09/26 05:01:04 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1673, average loss: 3.1036
[09/26 05:01:04 visual_prompt]: Classification results with val_vtab-sun397: top1: 36.50	top5: 68.00	
[09/26 05:01:04 visual_prompt]: Training 12 / 100 epoch, with learning rate 2.4992385337738696
[09/26 05:01:11 visual_prompt]: Epoch 12 / 100: avg data time: 6.53e-02, avg batch time: 0.5079, average train loss: 0.0124
[09/26 05:01:13 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1677, average loss: 2.9993
[09/26 05:01:13 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.50	top5: 66.00	
[09/26 05:01:13 visual_prompt]: Best epoch 12: best metric: 0.395
[09/26 05:01:13 visual_prompt]: Training 13 / 100 epoch, with learning rate 2.4969550628247803
[09/26 05:01:20 visual_prompt]: Epoch 13 / 100: avg data time: 6.15e-02, avg batch time: 0.5060, average train loss: 0.0102
[09/26 05:01:21 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1670, average loss: 2.9590
[09/26 05:01:21 visual_prompt]: Classification results with val_vtab-sun397: top1: 40.50	top5: 67.50	
[09/26 05:01:21 visual_prompt]: Best epoch 13: best metric: 0.405
[09/26 05:01:21 visual_prompt]: Training 14 / 100 epoch, with learning rate 2.4931523692103417
[09/26 05:01:28 visual_prompt]: Epoch 14 / 100: avg data time: 6.97e-02, avg batch time: 0.5121, average train loss: 0.0102
[09/26 05:01:30 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1677, average loss: 2.9764
[09/26 05:01:30 visual_prompt]: Classification results with val_vtab-sun397: top1: 40.00	top5: 67.50	
[09/26 05:01:30 visual_prompt]: Training 15 / 100 epoch, with learning rate 2.487835085926963
[09/26 05:01:37 visual_prompt]: Epoch 15 / 100: avg data time: 5.44e-02, avg batch time: 0.4971, average train loss: 0.0100
[09/26 05:01:39 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1673, average loss: 2.9559
[09/26 05:01:39 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.50	top5: 67.50	
[09/26 05:01:39 visual_prompt]: Best epoch 15: best metric: 0.415
[09/26 05:01:39 visual_prompt]: Training 16 / 100 epoch, with learning rate 2.4810096912652604
[09/26 05:01:46 visual_prompt]: Epoch 16 / 100: avg data time: 6.55e-02, avg batch time: 0.5088, average train loss: 0.0104
[09/26 05:01:47 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1674, average loss: 2.9467
[09/26 05:01:47 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.50	top5: 67.50	
[09/26 05:01:47 visual_prompt]: Training 17 / 100 epoch, with learning rate 2.472684500917257
[09/26 05:01:54 visual_prompt]: Epoch 17 / 100: avg data time: 4.99e-02, avg batch time: 0.4944, average train loss: 0.0110
[09/26 05:01:56 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1669, average loss: 2.9377
[09/26 05:01:56 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.00	top5: 69.50	
[09/26 05:01:56 visual_prompt]: Training 18 / 100 epoch, with learning rate 2.4628696578449953
[09/26 05:02:02 visual_prompt]: Epoch 18 / 100: avg data time: 5.78e-02, avg batch time: 0.5018, average train loss: 0.0117
[09/26 05:02:04 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1675, average loss: 2.9337
[09/26 05:02:04 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.00	top5: 69.00	
[09/26 05:02:04 visual_prompt]: Training 19 / 100 epoch, with learning rate 2.4515771199228986
[09/26 05:02:11 visual_prompt]: Epoch 19 / 100: avg data time: 6.45e-02, avg batch time: 0.5095, average train loss: 0.0126
[09/26 05:02:13 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1671, average loss: 2.9288
[09/26 05:02:13 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.50	top5: 69.00	
[09/26 05:02:13 visual_prompt]: Training 20 / 100 epoch, with learning rate 2.438820645368942
[09/26 05:02:19 visual_prompt]: Epoch 20 / 100: avg data time: 6.50e-02, avg batch time: 0.5082, average train loss: 0.0132
[09/26 05:02:21 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1676, average loss: 2.9229
[09/26 05:02:21 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.00	top5: 69.00	
[09/26 05:02:21 visual_prompt]: Training 21 / 100 epoch, with learning rate 2.4246157759823856
[09/26 05:02:28 visual_prompt]: Epoch 21 / 100: avg data time: 6.96e-02, avg batch time: 0.5123, average train loss: 0.0136
[09/26 05:02:30 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1674, average loss: 2.9230
[09/26 05:02:30 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.50	top5: 70.00	
[09/26 05:02:30 visual_prompt]: Training 22 / 100 epoch, with learning rate 2.4089798182084845
[09/26 05:02:37 visual_prompt]: Epoch 22 / 100: avg data time: 6.34e-02, avg batch time: 0.5066, average train loss: 0.0142
[09/26 05:02:38 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1677, average loss: 2.9231
[09/26 05:02:38 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.00	top5: 69.00	
[09/26 05:02:38 visual_prompt]: Training 23 / 100 epoch, with learning rate 2.391931822053251
[09/26 05:02:45 visual_prompt]: Epoch 23 / 100: avg data time: 5.49e-02, avg batch time: 0.4992, average train loss: 0.0146
[09/26 05:02:47 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1673, average loss: 2.8987
[09/26 05:02:47 visual_prompt]: Classification results with val_vtab-sun397: top1: 40.50	top5: 70.00	
[09/26 05:02:47 visual_prompt]: Training 24 / 100 epoch, with learning rate 2.3734925578739587
[09/26 05:02:54 visual_prompt]: Epoch 24 / 100: avg data time: 5.61e-02, avg batch time: 0.4993, average train loss: 0.0150
[09/26 05:02:55 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1671, average loss: 2.9114
[09/26 05:02:55 visual_prompt]: Classification results with val_vtab-sun397: top1: 40.00	top5: 69.00	
[09/26 05:02:55 visual_prompt]: Training 25 / 100 epoch, with learning rate 2.3536844910736585
[09/26 05:03:02 visual_prompt]: Epoch 25 / 100: avg data time: 6.26e-02, avg batch time: 0.5083, average train loss: 0.0154
[09/26 05:03:04 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1671, average loss: 2.9123
[09/26 05:03:04 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.50	top5: 70.50	
[09/26 05:03:04 visual_prompt]: Training 26 / 100 epoch, with learning rate 2.3325317547305486
[09/26 05:03:11 visual_prompt]: Epoch 26 / 100: avg data time: 5.96e-02, avg batch time: 0.5032, average train loss: 0.0156
[09/26 05:03:12 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1671, average loss: 2.9174
[09/26 05:03:12 visual_prompt]: Classification results with val_vtab-sun397: top1: 40.00	top5: 68.50	
[09/26 05:03:12 visual_prompt]: Training 27 / 100 epoch, with learning rate 2.310060120195532
[09/26 05:03:19 visual_prompt]: Epoch 27 / 100: avg data time: 6.03e-02, avg batch time: 0.5039, average train loss: 0.0156
[09/26 05:03:21 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1672, average loss: 2.9138
[09/26 05:03:21 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.50	top5: 69.50	
[09/26 05:03:21 visual_prompt]: Training 28 / 100 epoch, with learning rate 2.286296965693802
[09/26 05:03:28 visual_prompt]: Epoch 28 / 100: avg data time: 5.72e-02, avg batch time: 0.5003, average train loss: 0.0158
[09/26 05:03:29 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1672, average loss: 2.9050
[09/26 05:03:29 visual_prompt]: Classification results with val_vtab-sun397: top1: 40.00	top5: 69.00	
[09/26 05:03:29 visual_prompt]: Training 29 / 100 epoch, with learning rate 2.261271242968684
[09/26 05:03:36 visual_prompt]: Epoch 29 / 100: avg data time: 5.50e-02, avg batch time: 0.4995, average train loss: 0.0157
[09/26 05:03:38 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1678, average loss: 2.9119
[09/26 05:03:38 visual_prompt]: Classification results with val_vtab-sun397: top1: 40.00	top5: 70.50	
[09/26 05:03:38 visual_prompt]: Training 30 / 100 epoch, with learning rate 2.2350134420084022
[09/26 05:03:45 visual_prompt]: Epoch 30 / 100: avg data time: 5.73e-02, avg batch time: 0.5019, average train loss: 0.0158
[09/26 05:03:46 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1680, average loss: 2.9004
[09/26 05:03:46 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.50	top5: 69.00	
[09/26 05:03:46 visual_prompt]: Training 31 / 100 epoch, with learning rate 2.2075555538987226
[09/26 05:03:53 visual_prompt]: Epoch 31 / 100: avg data time: 6.52e-02, avg batch time: 0.5085, average train loss: 0.0157
[09/26 05:03:55 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1677, average loss: 2.8918
[09/26 05:03:55 visual_prompt]: Classification results with val_vtab-sun397: top1: 40.50	top5: 70.50	
[09/26 05:03:55 visual_prompt]: Training 32 / 100 epoch, with learning rate 2.178931031846743
[09/26 05:04:02 visual_prompt]: Epoch 32 / 100: avg data time: 6.22e-02, avg batch time: 0.5062, average train loss: 0.0159
[09/26 05:04:03 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1681, average loss: 2.9058
[09/26 05:04:03 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.50	top5: 68.50	
[09/26 05:04:03 visual_prompt]: Best epoch 32: best metric: 0.425
[09/26 05:04:03 visual_prompt]: Training 33 / 100 epoch, with learning rate 2.149174750423314
[09/26 05:04:10 visual_prompt]: Epoch 33 / 100: avg data time: 6.51e-02, avg batch time: 0.5087, average train loss: 0.0159
[09/26 05:04:12 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1676, average loss: 2.9004
[09/26 05:04:12 visual_prompt]: Classification results with val_vtab-sun397: top1: 40.00	top5: 69.00	
[09/26 05:04:12 visual_prompt]: Training 34 / 100 epoch, with learning rate 2.1183229630737466
[09/26 05:04:19 visual_prompt]: Epoch 34 / 100: avg data time: 5.51e-02, avg batch time: 0.4981, average train loss: 0.0159
[09/26 05:04:20 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1676, average loss: 2.8951
[09/26 05:04:20 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.00	top5: 71.00	
[09/26 05:04:20 visual_prompt]: Training 35 / 100 epoch, with learning rate 2.086413257948573
[09/26 05:04:27 visual_prompt]: Epoch 35 / 100: avg data time: 5.87e-02, avg batch time: 0.5011, average train loss: 0.0159
[09/26 05:04:29 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1676, average loss: 2.9085
[09/26 05:04:29 visual_prompt]: Classification results with val_vtab-sun397: top1: 40.00	top5: 70.50	
[09/26 05:04:29 visual_prompt]: Training 36 / 100 epoch, with learning rate 2.053484512108174
[09/26 05:04:36 visual_prompt]: Epoch 36 / 100: avg data time: 6.20e-02, avg batch time: 0.5061, average train loss: 0.0158
[09/26 05:04:37 visual_prompt]: Inference (val):avg data time: 1.95e-05, avg batch time: 0.1676, average loss: 2.9034
[09/26 05:04:37 visual_prompt]: Classification results with val_vtab-sun397: top1: 40.50	top5: 72.00	
[09/26 05:04:37 visual_prompt]: Training 37 / 100 epoch, with learning rate 2.019576844157073
[09/26 05:04:44 visual_prompt]: Epoch 37 / 100: avg data time: 6.12e-02, avg batch time: 0.5055, average train loss: 0.0156
[09/26 05:04:46 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1677, average loss: 2.9057
[09/26 05:04:46 visual_prompt]: Classification results with val_vtab-sun397: top1: 40.50	top5: 70.00	
[09/26 05:04:46 visual_prompt]: Training 38 / 100 epoch, with learning rate 1.9847315653655915
[09/26 05:04:53 visual_prompt]: Epoch 38 / 100: avg data time: 6.28e-02, avg batch time: 0.5056, average train loss: 0.0155
[09/26 05:04:54 visual_prompt]: Inference (val):avg data time: 1.99e-05, avg batch time: 0.1679, average loss: 2.8921
[09/26 05:04:54 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.50	top5: 69.00	
[09/26 05:04:54 visual_prompt]: Training 39 / 100 epoch, with learning rate 1.9489911293384334
[09/26 05:05:01 visual_prompt]: Epoch 39 / 100: avg data time: 6.16e-02, avg batch time: 0.5046, average train loss: 0.0154
[09/26 05:05:03 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1677, average loss: 2.9145
[09/26 05:05:03 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.50	top5: 70.50	
[09/26 05:05:03 visual_prompt]: Training 40 / 100 epoch, with learning rate 1.912399080291506
[09/26 05:05:10 visual_prompt]: Epoch 40 / 100: avg data time: 5.67e-02, avg batch time: 0.5014, average train loss: 0.0155
[09/26 05:05:11 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1679, average loss: 2.9063
[09/26 05:05:11 visual_prompt]: Classification results with val_vtab-sun397: top1: 40.50	top5: 71.50	
[09/26 05:05:11 visual_prompt]: Training 41 / 100 epoch, with learning rate 1.875
[09/26 05:05:18 visual_prompt]: Epoch 41 / 100: avg data time: 6.22e-02, avg batch time: 0.5054, average train loss: 0.0155
[09/26 05:05:20 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1677, average loss: 2.8925
[09/26 05:05:20 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.50	top5: 71.00	
[09/26 05:05:20 visual_prompt]: Training 42 / 100 epoch, with learning rate 1.8368394534823635
[09/26 05:05:27 visual_prompt]: Epoch 42 / 100: avg data time: 6.27e-02, avg batch time: 0.5060, average train loss: 0.0153
[09/26 05:05:28 visual_prompt]: Inference (val):avg data time: 1.86e-05, avg batch time: 0.1676, average loss: 2.8948
[09/26 05:05:28 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.00	top5: 71.50	
[09/26 05:05:28 visual_prompt]: Training 43 / 100 epoch, with learning rate 1.7979639334863466
[09/26 05:05:35 visual_prompt]: Epoch 43 / 100: avg data time: 6.91e-02, avg batch time: 0.5113, average train loss: 0.0149
[09/26 05:05:37 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1679, average loss: 2.8761
[09/26 05:05:37 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.00	top5: 71.50	
[09/26 05:05:37 visual_prompt]: Training 44 / 100 epoch, with learning rate 1.7584208038447504
[09/26 05:05:44 visual_prompt]: Epoch 44 / 100: avg data time: 7.23e-02, avg batch time: 0.5161, average train loss: 0.0150
[09/26 05:05:46 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1677, average loss: 2.8998
[09/26 05:05:46 visual_prompt]: Classification results with val_vtab-sun397: top1: 43.00	top5: 70.50	
[09/26 05:05:46 visual_prompt]: Best epoch 44: best metric: 0.430
[09/26 05:05:46 visual_prompt]: Training 45 / 100 epoch, with learning rate 1.7182582417698902
[09/26 05:05:53 visual_prompt]: Epoch 45 / 100: avg data time: 6.65e-02, avg batch time: 0.5110, average train loss: 0.0150
[09/26 05:05:54 visual_prompt]: Inference (val):avg data time: 3.81e-05, avg batch time: 0.1674, average loss: 2.8929
[09/26 05:05:54 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.50	top5: 70.50	
[09/26 05:05:54 visual_prompt]: Training 46 / 100 epoch, with learning rate 1.6775251791570862
[09/26 05:06:01 visual_prompt]: Epoch 46 / 100: avg data time: 5.48e-02, avg batch time: 0.4976, average train loss: 0.0148
[09/26 05:06:03 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1675, average loss: 2.9146
[09/26 05:06:03 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.00	top5: 71.00	
[09/26 05:06:03 visual_prompt]: Training 47 / 100 epoch, with learning rate 1.6362712429686843
[09/26 05:06:09 visual_prompt]: Epoch 47 / 100: avg data time: 4.90e-02, avg batch time: 0.4947, average train loss: 0.0149
[09/26 05:06:11 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1674, average loss: 2.9021
[09/26 05:06:11 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.50	top5: 71.50	
[09/26 05:06:11 visual_prompt]: Training 48 / 100 epoch, with learning rate 1.5945466947712488
[09/26 05:06:18 visual_prompt]: Epoch 48 / 100: avg data time: 6.09e-02, avg batch time: 0.5061, average train loss: 0.0147
[09/26 05:06:20 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1678, average loss: 2.9049
[09/26 05:06:20 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.50	top5: 72.50	
[09/26 05:06:20 visual_prompt]: Training 49 / 100 epoch, with learning rate 1.5524023694995845
[09/26 05:06:27 visual_prompt]: Epoch 49 / 100: avg data time: 7.22e-02, avg batch time: 0.5149, average train loss: 0.0146
[09/26 05:06:28 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1678, average loss: 2.9081
[09/26 05:06:28 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.50	top5: 71.50	
[09/26 05:06:28 visual_prompt]: Training 50 / 100 epoch, with learning rate 1.509889613522199
[09/26 05:06:35 visual_prompt]: Epoch 50 / 100: avg data time: 6.81e-02, avg batch time: 0.5116, average train loss: 0.0148
[09/26 05:06:37 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1675, average loss: 2.9055
[09/26 05:06:37 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.50	top5: 72.00	
[09/26 05:06:37 visual_prompt]: Training 51 / 100 epoch, with learning rate 1.467060222083663
[09/26 05:06:44 visual_prompt]: Epoch 51 / 100: avg data time: 6.57e-02, avg batch time: 0.5086, average train loss: 0.0148
[09/26 05:06:46 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1677, average loss: 2.9185
[09/26 05:06:46 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.50	top5: 71.50	
[09/26 05:06:46 visual_prompt]: Training 52 / 100 epoch, with learning rate 1.4239663762000818
[09/26 05:06:52 visual_prompt]: Epoch 52 / 100: avg data time: 6.21e-02, avg batch time: 0.5050, average train loss: 0.0145
[09/26 05:06:54 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1678, average loss: 2.9262
[09/26 05:06:54 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.50	top5: 71.00	
[09/26 05:06:54 visual_prompt]: Training 53 / 100 epoch, with learning rate 1.380660579084567
[09/26 05:07:01 visual_prompt]: Epoch 53 / 100: avg data time: 6.01e-02, avg batch time: 0.5042, average train loss: 0.0143
[09/26 05:07:03 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1677, average loss: 2.9233
[09/26 05:07:03 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.50	top5: 72.00	
[09/26 05:07:03 visual_prompt]: Training 54 / 100 epoch, with learning rate 1.3371955921801564
[09/26 05:07:10 visual_prompt]: Epoch 54 / 100: avg data time: 5.84e-02, avg batch time: 0.5014, average train loss: 0.0141
[09/26 05:07:11 visual_prompt]: Inference (val):avg data time: 3.80e-05, avg batch time: 0.1677, average loss: 2.9303
[09/26 05:07:11 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.00	top5: 71.50	
[09/26 05:07:11 visual_prompt]: Training 55 / 100 epoch, with learning rate 1.2936243708781263
[09/26 05:07:18 visual_prompt]: Epoch 55 / 100: avg data time: 5.72e-02, avg batch time: 0.4993, average train loss: 0.0140
[09/26 05:07:20 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.1678, average loss: 2.9131
[09/26 05:07:20 visual_prompt]: Classification results with val_vtab-sun397: top1: 43.50	top5: 72.00	
[09/26 05:07:20 visual_prompt]: Best epoch 55: best metric: 0.435
[09/26 05:07:20 visual_prompt]: Training 56 / 100 epoch, with learning rate 1.25
[09/26 05:07:26 visual_prompt]: Epoch 56 / 100: avg data time: 5.62e-02, avg batch time: 0.4996, average train loss: 0.0139
[09/26 05:07:28 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1680, average loss: 2.9227
[09/26 05:07:28 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.00	top5: 70.50	
[09/26 05:07:28 visual_prompt]: Training 57 / 100 epoch, with learning rate 1.2063756291218741
[09/26 05:07:35 visual_prompt]: Epoch 57 / 100: avg data time: 6.20e-02, avg batch time: 0.5061, average train loss: 0.0138
[09/26 05:07:37 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1676, average loss: 2.9225
[09/26 05:07:37 visual_prompt]: Classification results with val_vtab-sun397: top1: 44.00	top5: 71.50	
[09/26 05:07:37 visual_prompt]: Best epoch 57: best metric: 0.440
[09/26 05:07:37 visual_prompt]: Training 58 / 100 epoch, with learning rate 1.1628044078198434
[09/26 05:07:43 visual_prompt]: Epoch 58 / 100: avg data time: 6.13e-02, avg batch time: 0.5036, average train loss: 0.0137
[09/26 05:07:45 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1675, average loss: 2.9315
[09/26 05:07:45 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.50	top5: 71.00	
[09/26 05:07:45 visual_prompt]: Training 59 / 100 epoch, with learning rate 1.1193394209154333
[09/26 05:07:52 visual_prompt]: Epoch 59 / 100: avg data time: 6.33e-02, avg batch time: 0.5069, average train loss: 0.0138
[09/26 05:07:54 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1675, average loss: 2.9520
[09/26 05:07:54 visual_prompt]: Classification results with val_vtab-sun397: top1: 40.50	top5: 72.00	
[09/26 05:07:54 visual_prompt]: Training 60 / 100 epoch, with learning rate 1.0760336237999186
[09/26 05:08:00 visual_prompt]: Epoch 60 / 100: avg data time: 5.98e-02, avg batch time: 0.5025, average train loss: 0.0137
[09/26 05:08:02 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1679, average loss: 2.9403
[09/26 05:08:02 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.00	top5: 71.50	
[09/26 05:08:02 visual_prompt]: Training 61 / 100 epoch, with learning rate 1.0329397779163372
[09/26 05:08:09 visual_prompt]: Epoch 61 / 100: avg data time: 6.21e-02, avg batch time: 0.5053, average train loss: 0.0136
[09/26 05:08:11 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1678, average loss: 2.9667
[09/26 05:08:11 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.00	top5: 70.50	
[09/26 05:08:11 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.990110386477801
[09/26 05:08:17 visual_prompt]: Epoch 62 / 100: avg data time: 5.76e-02, avg batch time: 0.4999, average train loss: 0.0136
[09/26 05:08:19 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1678, average loss: 2.9411
[09/26 05:08:19 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.50	top5: 72.00	
[09/26 05:08:19 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.9475976305004155
[09/26 05:08:26 visual_prompt]: Epoch 63 / 100: avg data time: 5.09e-02, avg batch time: 0.4953, average train loss: 0.0136
[09/26 05:08:27 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1669, average loss: 2.9422
[09/26 05:08:27 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.50	top5: 72.00	
[09/26 05:08:27 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.9054533052287511
[09/26 05:08:34 visual_prompt]: Epoch 64 / 100: avg data time: 5.89e-02, avg batch time: 0.5020, average train loss: 0.0134
[09/26 05:08:36 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1672, average loss: 2.9457
[09/26 05:08:36 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.50	top5: 71.50	
[09/26 05:08:36 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.8637287570313158
[09/26 05:08:43 visual_prompt]: Epoch 65 / 100: avg data time: 6.69e-02, avg batch time: 0.5096, average train loss: 0.0133
[09/26 05:08:44 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1672, average loss: 2.9503
[09/26 05:08:44 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.50	top5: 71.50	
[09/26 05:08:44 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.8224748208429142
[09/26 05:08:51 visual_prompt]: Epoch 66 / 100: avg data time: 6.55e-02, avg batch time: 0.5080, average train loss: 0.0136
[09/26 05:08:53 visual_prompt]: Inference (val):avg data time: 2.00e-05, avg batch time: 0.1681, average loss: 2.9348
[09/26 05:08:53 visual_prompt]: Classification results with val_vtab-sun397: top1: 43.00	top5: 72.00	
[09/26 05:08:53 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.7817417582301099
[09/26 05:09:00 visual_prompt]: Epoch 67 / 100: avg data time: 5.72e-02, avg batch time: 0.5005, average train loss: 0.0137
[09/26 05:09:01 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1681, average loss: 2.9515
[09/26 05:09:01 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.50	top5: 72.50	
[09/26 05:09:01 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.7415791961552499
[09/26 05:09:08 visual_prompt]: Epoch 68 / 100: avg data time: 4.90e-02, avg batch time: 0.4932, average train loss: 0.0135
[09/26 05:09:10 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1678, average loss: 2.9358
[09/26 05:09:10 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.00	top5: 72.00	
[09/26 05:09:10 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.7020360665136531
[09/26 05:09:17 visual_prompt]: Epoch 69 / 100: avg data time: 6.59e-02, avg batch time: 0.5087, average train loss: 0.0133
[09/26 05:09:18 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1677, average loss: 2.9503
[09/26 05:09:18 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.00	top5: 72.50	
[09/26 05:09:18 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.6631605465176369
[09/26 05:09:25 visual_prompt]: Epoch 70 / 100: avg data time: 6.07e-02, avg batch time: 0.5040, average train loss: 0.0132
[09/26 05:09:27 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1674, average loss: 2.9425
[09/26 05:09:27 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.00	top5: 71.50	
[09/26 05:09:27 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.6250000000000002
[09/26 05:09:34 visual_prompt]: Epoch 71 / 100: avg data time: 6.37e-02, avg batch time: 0.5069, average train loss: 0.0131
[09/26 05:09:35 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1671, average loss: 2.9532
[09/26 05:09:35 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.50	top5: 71.50	
[09/26 05:09:35 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.587600919708494
[09/26 05:09:42 visual_prompt]: Epoch 72 / 100: avg data time: 6.29e-02, avg batch time: 0.5066, average train loss: 0.0131
[09/26 05:09:44 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1678, average loss: 2.9535
[09/26 05:09:44 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.00	top5: 71.50	
[09/26 05:09:44 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.5510088706615667
[09/26 05:09:51 visual_prompt]: Epoch 73 / 100: avg data time: 6.70e-02, avg batch time: 0.5099, average train loss: 0.0129
[09/26 05:09:52 visual_prompt]: Inference (val):avg data time: 2.05e-05, avg batch time: 0.1674, average loss: 2.9548
[09/26 05:09:52 visual_prompt]: Classification results with val_vtab-sun397: top1: 43.00	top5: 72.50	
[09/26 05:09:52 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.5152684346344087
[09/26 05:09:59 visual_prompt]: Epoch 74 / 100: avg data time: 6.64e-02, avg batch time: 0.5105, average train loss: 0.0129
[09/26 05:10:01 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1674, average loss: 2.9549
[09/26 05:10:01 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.50	top5: 73.00	
[09/26 05:10:01 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.48042315584292716
[09/26 05:10:08 visual_prompt]: Epoch 75 / 100: avg data time: 5.83e-02, avg batch time: 0.5024, average train loss: 0.0128
[09/26 05:10:09 visual_prompt]: Inference (val):avg data time: 2.05e-05, avg batch time: 0.1673, average loss: 2.9540
[09/26 05:10:09 visual_prompt]: Classification results with val_vtab-sun397: top1: 43.00	top5: 71.50	
[09/26 05:10:09 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.4465154878918258
[09/26 05:10:16 visual_prompt]: Epoch 76 / 100: avg data time: 5.56e-02, avg batch time: 0.4999, average train loss: 0.0128
[09/26 05:10:18 visual_prompt]: Inference (val):avg data time: 1.96e-05, avg batch time: 0.1676, average loss: 2.9440
[09/26 05:10:18 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.00	top5: 71.00	
[09/26 05:10:18 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.41358674205142765
[09/26 05:10:25 visual_prompt]: Epoch 77 / 100: avg data time: 6.60e-02, avg batch time: 0.5088, average train loss: 0.0129
[09/26 05:10:26 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1678, average loss: 2.9589
[09/26 05:10:26 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.50	top5: 72.00	
[09/26 05:10:26 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.3816770369262533
[09/26 05:10:33 visual_prompt]: Epoch 78 / 100: avg data time: 6.50e-02, avg batch time: 0.5093, average train loss: 0.0128
[09/26 05:10:35 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1681, average loss: 2.9476
[09/26 05:10:35 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.50	top5: 72.50	
[09/26 05:10:35 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.35082524957668626
[09/26 05:10:42 visual_prompt]: Epoch 79 / 100: avg data time: 5.38e-02, avg batch time: 0.4992, average train loss: 0.0128
[09/26 05:10:43 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1679, average loss: 2.9549
[09/26 05:10:43 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.50	top5: 71.50	
[09/26 05:10:43 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.32106896815325703
[09/26 05:10:50 visual_prompt]: Epoch 80 / 100: avg data time: 6.88e-02, avg batch time: 0.5122, average train loss: 0.0127
[09/26 05:10:52 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1673, average loss: 2.9498
[09/26 05:10:52 visual_prompt]: Classification results with val_vtab-sun397: top1: 43.00	top5: 72.50	
[09/26 05:10:52 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.2924444461012776
[09/26 05:10:59 visual_prompt]: Epoch 81 / 100: avg data time: 7.64e-02, avg batch time: 0.5193, average train loss: 0.0127
[09/26 05:11:01 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1678, average loss: 2.9448
[09/26 05:11:01 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.50	top5: 73.00	
[09/26 05:11:01 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.26498655799159765
[09/26 05:11:08 visual_prompt]: Epoch 82 / 100: avg data time: 6.28e-02, avg batch time: 0.5070, average train loss: 0.0126
[09/26 05:11:09 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1675, average loss: 2.9460
[09/26 05:11:09 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.50	top5: 72.50	
[09/26 05:11:09 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.23872875703131582
[09/26 05:11:16 visual_prompt]: Epoch 83 / 100: avg data time: 5.65e-02, avg batch time: 0.5002, average train loss: 0.0127
[09/26 05:11:18 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1672, average loss: 2.9503
[09/26 05:11:18 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.50	top5: 72.50	
[09/26 05:11:18 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.21370303430619797
[09/26 05:11:25 visual_prompt]: Epoch 84 / 100: avg data time: 6.35e-02, avg batch time: 0.5067, average train loss: 0.0126
[09/26 05:11:26 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1677, average loss: 2.9452
[09/26 05:11:26 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.50	top5: 72.50	
[09/26 05:11:26 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.18993987980446755
[09/26 05:11:33 visual_prompt]: Epoch 85 / 100: avg data time: 4.99e-02, avg batch time: 0.4946, average train loss: 0.0125
[09/26 05:11:35 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1674, average loss: 2.9632
[09/26 05:11:35 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.50	top5: 71.50	
[09/26 05:11:35 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.16746824526945162
[09/26 05:11:42 visual_prompt]: Epoch 86 / 100: avg data time: 6.39e-02, avg batch time: 0.5061, average train loss: 0.0125
[09/26 05:11:43 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1679, average loss: 2.9532
[09/26 05:11:43 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.50	top5: 72.50	
[09/26 05:11:43 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.14631550892634126
[09/26 05:11:50 visual_prompt]: Epoch 87 / 100: avg data time: 5.49e-02, avg batch time: 0.4981, average train loss: 0.0125
[09/26 05:11:52 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1678, average loss: 2.9571
[09/26 05:11:52 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.50	top5: 72.00	
[09/26 05:11:52 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.12650744212604148
[09/26 05:11:59 visual_prompt]: Epoch 88 / 100: avg data time: 6.21e-02, avg batch time: 0.5053, average train loss: 0.0125
[09/26 05:12:00 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1678, average loss: 2.9583
[09/26 05:12:01 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.50	top5: 72.50	
[09/26 05:12:01 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.10806817794674878
[09/26 05:12:07 visual_prompt]: Epoch 89 / 100: avg data time: 6.74e-02, avg batch time: 0.5100, average train loss: 0.0125
[09/26 05:12:09 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1675, average loss: 2.9574
[09/26 05:12:09 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.50	top5: 72.00	
[09/26 05:12:09 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.09102018179151586
[09/26 05:12:16 visual_prompt]: Epoch 90 / 100: avg data time: 6.40e-02, avg batch time: 0.5065, average train loss: 0.0124
[09/26 05:12:18 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1675, average loss: 2.9595
[09/26 05:12:18 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.50	top5: 72.50	
[09/26 05:12:18 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.0753842240176146
[09/26 05:12:25 visual_prompt]: Epoch 91 / 100: avg data time: 5.60e-02, avg batch time: 0.4996, average train loss: 0.0125
[09/26 05:12:26 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1676, average loss: 2.9601
[09/26 05:12:26 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.50	top5: 72.00	
[09/26 05:12:26 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.061179354631058086
[09/26 05:12:33 visual_prompt]: Epoch 92 / 100: avg data time: 5.81e-02, avg batch time: 0.5009, average train loss: 0.0125
[09/26 05:12:35 visual_prompt]: Inference (val):avg data time: 4.39e-05, avg batch time: 0.1676, average loss: 2.9588
[09/26 05:12:35 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.50	top5: 72.50	
[09/26 05:12:35 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.04842288007710138
[09/26 05:12:42 visual_prompt]: Epoch 93 / 100: avg data time: 5.83e-02, avg batch time: 0.5019, average train loss: 0.0124
[09/26 05:12:43 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1674, average loss: 2.9592
[09/26 05:12:43 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.50	top5: 72.50	
[09/26 05:12:43 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.03713034215500441
[09/26 05:12:50 visual_prompt]: Epoch 94 / 100: avg data time: 5.97e-02, avg batch time: 0.5023, average train loss: 0.0124
[09/26 05:12:52 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1677, average loss: 2.9597
[09/26 05:12:52 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.50	top5: 72.50	
[09/26 05:12:52 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.02731549908274289
[09/26 05:12:58 visual_prompt]: Epoch 95 / 100: avg data time: 5.55e-02, avg batch time: 0.4988, average train loss: 0.0124
[09/26 05:13:00 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1677, average loss: 2.9588
[09/26 05:13:00 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.50	top5: 72.50	
[09/26 05:13:00 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.018990308734739975
[09/26 05:13:07 visual_prompt]: Epoch 96 / 100: avg data time: 5.67e-02, avg batch time: 0.4997, average train loss: 0.0124
[09/26 05:13:08 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1677, average loss: 2.9578
[09/26 05:13:08 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.50	top5: 72.50	
[09/26 05:13:08 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.012164914073037048
[09/26 05:13:15 visual_prompt]: Epoch 97 / 100: avg data time: 6.26e-02, avg batch time: 0.5072, average train loss: 0.0124
[09/26 05:13:17 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1678, average loss: 2.9576
[09/26 05:13:17 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.50	top5: 72.50	
[09/26 05:13:17 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.006847630789658388
[09/26 05:13:24 visual_prompt]: Epoch 98 / 100: avg data time: 5.34e-02, avg batch time: 0.4957, average train loss: 0.0124
[09/26 05:13:25 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1677, average loss: 2.9576
[09/26 05:13:25 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.50	top5: 72.50	
[09/26 05:13:25 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.003044937175219753
[09/26 05:13:32 visual_prompt]: Epoch 99 / 100: avg data time: 7.08e-02, avg batch time: 0.5132, average train loss: 0.0123
[09/26 05:13:34 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1678, average loss: 2.9575
[09/26 05:13:34 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.50	top5: 72.50	
[09/26 05:13:34 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0007614662261302974
[09/26 05:13:41 visual_prompt]: Epoch 100 / 100: avg data time: 6.00e-02, avg batch time: 0.5048, average train loss: 0.0124
[09/26 05:13:43 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1679, average loss: 2.9575
[09/26 05:13:43 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.50	top5: 72.50	
[09/26 05:13:43 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 05:13:43 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              0
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 05:13:43 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-sun397', 'DATA.NUMBER_CLASSES', '397', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 05:13:43 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 05:13:43 visual_prompt]: Training with config:
[09/26 05:13:43 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-sun397/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr2.5_wd0.0/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 2.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-sun397', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 397, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 05:13:43 visual_prompt]: Loading training data...
[09/26 05:13:43 visual_prompt]: Constructing vtab-sun397 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split train[:800], from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/26 05:13:44 visual_prompt]: Number of images: 800
[09/26 05:13:44 visual_prompt]: Number of classes: 309 / 397
[09/26 05:13:44 visual_prompt]: Loading validation data...
[09/26 05:13:44 visual_prompt]: Constructing vtab-sun397 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split validation[:200], from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/26 05:13:44 visual_prompt]: Number of images: 200
[09/26 05:13:44 visual_prompt]: Number of classes: 136 / 397
[09/26 05:13:44 visual_prompt]: Constructing models...
[09/26 05:13:47 visual_prompt]: Total Parameters: 86564749	 Gradient Parameters: 766093
[09/26 05:13:47 visual_prompt]: tuned percent:0.885
[09/26 05:13:47 visual_prompt]: Device used for model: 0
[09/26 05:13:47 visual_prompt]: Setting up Evaluator...
[09/26 05:13:47 visual_prompt]: Setting up Trainer...
[09/26 05:13:47 visual_prompt]: 	Setting up the optimizer...
[09/26 05:13:47 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 05:13:54 visual_prompt]: Epoch 1 / 100: avg data time: 6.09e-02, avg batch time: 0.5057, average train loss: 5.9876
[09/26 05:13:55 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1675, average loss: 6.0097
[09/26 05:13:55 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/26 05:13:55 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.25
[09/26 05:14:02 visual_prompt]: Epoch 2 / 100: avg data time: 4.91e-02, avg batch time: 0.4920, average train loss: 5.8176
[09/26 05:14:04 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1677, average loss: 5.8124
[09/26 05:14:04 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 05:14:04 visual_prompt]: Best epoch 2: best metric: 0.005
[09/26 05:14:04 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.5
[09/26 05:14:10 visual_prompt]: Epoch 3 / 100: avg data time: 5.20e-02, avg batch time: 0.4953, average train loss: 5.5898
[09/26 05:14:12 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1672, average loss: 5.7869
[09/26 05:14:12 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 5.00	
[09/26 05:14:12 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.75
[09/26 05:14:19 visual_prompt]: Epoch 4 / 100: avg data time: 6.50e-02, avg batch time: 0.5072, average train loss: 5.4712
[09/26 05:14:21 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1673, average loss: 5.6849
[09/26 05:14:21 visual_prompt]: Classification results with val_vtab-sun397: top1: 3.50	top5: 7.50	
[09/26 05:14:21 visual_prompt]: Best epoch 4: best metric: 0.035
[09/26 05:14:21 visual_prompt]: Training 5 / 100 epoch, with learning rate 1.0
[09/26 05:14:27 visual_prompt]: Epoch 5 / 100: avg data time: 5.59e-02, avg batch time: 0.4991, average train loss: 5.0221
[09/26 05:14:29 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1675, average loss: 5.2402
[09/26 05:14:29 visual_prompt]: Classification results with val_vtab-sun397: top1: 8.50	top5: 23.00	
[09/26 05:14:29 visual_prompt]: Best epoch 5: best metric: 0.085
[09/26 05:14:29 visual_prompt]: Training 6 / 100 epoch, with learning rate 1.25
[09/26 05:14:36 visual_prompt]: Epoch 6 / 100: avg data time: 5.57e-02, avg batch time: 0.5003, average train loss: 3.5392
[09/26 05:14:37 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1678, average loss: 3.9087
[09/26 05:14:37 visual_prompt]: Classification results with val_vtab-sun397: top1: 26.00	top5: 52.00	
[09/26 05:14:37 visual_prompt]: Best epoch 6: best metric: 0.260
[09/26 05:14:37 visual_prompt]: Training 7 / 100 epoch, with learning rate 1.5
[09/26 05:14:44 visual_prompt]: Epoch 7 / 100: avg data time: 5.15e-02, avg batch time: 0.4966, average train loss: 1.3495
[09/26 05:14:46 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1674, average loss: 3.2266
[09/26 05:14:46 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.50	top5: 64.00	
[09/26 05:14:46 visual_prompt]: Best epoch 7: best metric: 0.375
[09/26 05:14:46 visual_prompt]: Training 8 / 100 epoch, with learning rate 1.75
[09/26 05:14:53 visual_prompt]: Epoch 8 / 100: avg data time: 6.65e-02, avg batch time: 0.5094, average train loss: 0.2106
[09/26 05:14:54 visual_prompt]: Inference (val):avg data time: 1.94e-05, avg batch time: 0.1676, average loss: 3.1145
[09/26 05:14:54 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 67.00	
[09/26 05:14:54 visual_prompt]: Best epoch 8: best metric: 0.385
[09/26 05:14:54 visual_prompt]: Training 9 / 100 epoch, with learning rate 2.0
[09/26 05:15:01 visual_prompt]: Epoch 9 / 100: avg data time: 5.94e-02, avg batch time: 0.5034, average train loss: 0.0673
[09/26 05:15:03 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1682, average loss: 3.1401
[09/26 05:15:03 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.00	top5: 67.00	
[09/26 05:15:03 visual_prompt]: Training 10 / 100 epoch, with learning rate 2.25
[09/26 05:15:10 visual_prompt]: Epoch 10 / 100: avg data time: 5.74e-02, avg batch time: 0.5012, average train loss: 0.0382
[09/26 05:15:11 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1676, average loss: 2.9855
[09/26 05:15:11 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.00	top5: 67.50	
[09/26 05:15:11 visual_prompt]: Training 11 / 100 epoch, with learning rate 2.5
[09/26 05:15:18 visual_prompt]: Epoch 11 / 100: avg data time: 6.17e-02, avg batch time: 0.5078, average train loss: 0.0134
[09/26 05:15:20 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1678, average loss: 3.0292
[09/26 05:15:20 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 68.50	
[09/26 05:15:20 visual_prompt]: Best epoch 11: best metric: 0.390
[09/26 05:15:20 visual_prompt]: Training 12 / 100 epoch, with learning rate 2.4992385337738696
[09/26 05:15:27 visual_prompt]: Epoch 12 / 100: avg data time: 5.97e-02, avg batch time: 0.5043, average train loss: 0.0066
[09/26 05:15:28 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1674, average loss: 2.9990
[09/26 05:15:28 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 70.00	
[09/26 05:15:28 visual_prompt]: Training 13 / 100 epoch, with learning rate 2.4969550628247803
[09/26 05:15:35 visual_prompt]: Epoch 13 / 100: avg data time: 6.30e-02, avg batch time: 0.5062, average train loss: 0.0041
[09/26 05:15:37 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1676, average loss: 2.9789
[09/26 05:15:37 visual_prompt]: Classification results with val_vtab-sun397: top1: 40.00	top5: 70.00	
[09/26 05:15:37 visual_prompt]: Best epoch 13: best metric: 0.400
[09/26 05:15:37 visual_prompt]: Training 14 / 100 epoch, with learning rate 2.4931523692103417
[09/26 05:15:43 visual_prompt]: Epoch 14 / 100: avg data time: 4.64e-02, avg batch time: 0.4922, average train loss: 0.0034
[09/26 05:15:45 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1675, average loss: 2.9900
[09/26 05:15:45 visual_prompt]: Classification results with val_vtab-sun397: top1: 40.50	top5: 70.00	
[09/26 05:15:45 visual_prompt]: Best epoch 14: best metric: 0.405
[09/26 05:15:45 visual_prompt]: Training 15 / 100 epoch, with learning rate 2.487835085926963
[09/26 05:15:52 visual_prompt]: Epoch 15 / 100: avg data time: 6.05e-02, avg batch time: 0.5043, average train loss: 0.0030
[09/26 05:15:53 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.1677, average loss: 2.9955
[09/26 05:15:53 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.00	top5: 68.50	
[09/26 05:15:53 visual_prompt]: Best epoch 15: best metric: 0.420
[09/26 05:15:53 visual_prompt]: Training 16 / 100 epoch, with learning rate 2.4810096912652604
[09/26 05:16:00 visual_prompt]: Epoch 16 / 100: avg data time: 5.76e-02, avg batch time: 0.5013, average train loss: 0.0027
[09/26 05:16:02 visual_prompt]: Inference (val):avg data time: 3.90e-05, avg batch time: 0.1676, average loss: 2.9980
[09/26 05:16:02 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.50	top5: 68.50	
[09/26 05:16:02 visual_prompt]: Best epoch 16: best metric: 0.425
[09/26 05:16:02 visual_prompt]: Training 17 / 100 epoch, with learning rate 2.472684500917257
[09/26 05:16:09 visual_prompt]: Epoch 17 / 100: avg data time: 6.27e-02, avg batch time: 0.5057, average train loss: 0.0025
[09/26 05:16:10 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1687, average loss: 2.9978
[09/26 05:16:10 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.50	top5: 68.50	
[09/26 05:16:10 visual_prompt]: Training 18 / 100 epoch, with learning rate 2.4628696578449953
[09/26 05:16:17 visual_prompt]: Epoch 18 / 100: avg data time: 6.16e-02, avg batch time: 0.5043, average train loss: 0.0023
[09/26 05:16:19 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1679, average loss: 2.9995
[09/26 05:16:19 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.00	top5: 68.50	
[09/26 05:16:19 visual_prompt]: Training 19 / 100 epoch, with learning rate 2.4515771199228986
[09/26 05:16:26 visual_prompt]: Epoch 19 / 100: avg data time: 5.49e-02, avg batch time: 0.4988, average train loss: 0.0022
[09/26 05:16:27 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1681, average loss: 3.0023
[09/26 05:16:27 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.50	top5: 69.00	
[09/26 05:16:27 visual_prompt]: Training 20 / 100 epoch, with learning rate 2.438820645368942
[09/26 05:16:34 visual_prompt]: Epoch 20 / 100: avg data time: 6.19e-02, avg batch time: 0.5058, average train loss: 0.0020
[09/26 05:16:36 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1674, average loss: 3.0055
[09/26 05:16:36 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.50	top5: 69.00	
[09/26 05:16:36 visual_prompt]: Training 21 / 100 epoch, with learning rate 2.4246157759823856
[09/26 05:16:43 visual_prompt]: Epoch 21 / 100: avg data time: 5.69e-02, avg batch time: 0.4999, average train loss: 0.0019
[09/26 05:16:44 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1671, average loss: 3.0054
[09/26 05:16:44 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.00	top5: 68.50	
[09/26 05:16:44 visual_prompt]: Training 22 / 100 epoch, with learning rate 2.4089798182084845
[09/26 05:16:51 visual_prompt]: Epoch 22 / 100: avg data time: 6.01e-02, avg batch time: 0.5040, average train loss: 0.0019
[09/26 05:16:53 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1680, average loss: 3.0078
[09/26 05:16:53 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.50	top5: 68.50	
[09/26 05:16:53 visual_prompt]: Training 23 / 100 epoch, with learning rate 2.391931822053251
[09/26 05:16:59 visual_prompt]: Epoch 23 / 100: avg data time: 5.27e-02, avg batch time: 0.4970, average train loss: 0.0018
[09/26 05:17:01 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1679, average loss: 3.0103
[09/26 05:17:01 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.50	top5: 69.00	
[09/26 05:17:01 visual_prompt]: Training 24 / 100 epoch, with learning rate 2.3734925578739587
[09/26 05:17:08 visual_prompt]: Epoch 24 / 100: avg data time: 6.79e-02, avg batch time: 0.5100, average train loss: 0.0017
[09/26 05:17:10 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1681, average loss: 3.0122
[09/26 05:17:10 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.50	top5: 69.00	
[09/26 05:17:10 visual_prompt]: Training 25 / 100 epoch, with learning rate 2.3536844910736585
[09/26 05:17:16 visual_prompt]: Epoch 25 / 100: avg data time: 5.85e-02, avg batch time: 0.5018, average train loss: 0.0016
[09/26 05:17:18 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1676, average loss: 3.0141
[09/26 05:17:18 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.50	top5: 69.00	
[09/26 05:17:18 visual_prompt]: Training 26 / 100 epoch, with learning rate 2.3325317547305486
[09/26 05:17:25 visual_prompt]: Epoch 26 / 100: avg data time: 5.74e-02, avg batch time: 0.5013, average train loss: 0.0016
[09/26 05:17:26 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1678, average loss: 3.0153
[09/26 05:17:26 visual_prompt]: Classification results with val_vtab-sun397: top1: 43.00	top5: 69.00	
[09/26 05:17:26 visual_prompt]: Best epoch 26: best metric: 0.430
[09/26 05:17:26 visual_prompt]: Training 27 / 100 epoch, with learning rate 2.310060120195532
[09/26 05:17:33 visual_prompt]: Epoch 27 / 100: avg data time: 5.96e-02, avg batch time: 0.5040, average train loss: 0.0015
[09/26 05:17:35 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1679, average loss: 3.0158
[09/26 05:17:35 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.50	top5: 69.00	
[09/26 05:17:35 visual_prompt]: Training 28 / 100 epoch, with learning rate 2.286296965693802
[09/26 05:17:42 visual_prompt]: Epoch 28 / 100: avg data time: 6.62e-02, avg batch time: 0.5093, average train loss: 0.0015
[09/26 05:17:43 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1676, average loss: 3.0181
[09/26 05:17:43 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.00	top5: 69.00	
[09/26 05:17:43 visual_prompt]: Training 29 / 100 epoch, with learning rate 2.261271242968684
[09/26 05:17:50 visual_prompt]: Epoch 29 / 100: avg data time: 6.01e-02, avg batch time: 0.5033, average train loss: 0.0014
[09/26 05:17:52 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1676, average loss: 3.0196
[09/26 05:17:52 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.00	top5: 69.00	
[09/26 05:17:52 visual_prompt]: Training 30 / 100 epoch, with learning rate 2.2350134420084022
[09/26 05:17:59 visual_prompt]: Epoch 30 / 100: avg data time: 5.90e-02, avg batch time: 0.5026, average train loss: 0.0014
[09/26 05:18:00 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1673, average loss: 3.0207
[09/26 05:18:00 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.00	top5: 69.50	
[09/26 05:18:00 visual_prompt]: Training 31 / 100 epoch, with learning rate 2.2075555538987226
[09/26 05:18:07 visual_prompt]: Epoch 31 / 100: avg data time: 6.40e-02, avg batch time: 0.5063, average train loss: 0.0014
[09/26 05:18:09 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1677, average loss: 3.0226
[09/26 05:18:09 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.00	top5: 69.50	
[09/26 05:18:09 visual_prompt]: Training 32 / 100 epoch, with learning rate 2.178931031846743
[09/26 05:18:16 visual_prompt]: Epoch 32 / 100: avg data time: 6.01e-02, avg batch time: 0.5058, average train loss: 0.0013
[09/26 05:18:17 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1675, average loss: 3.0221
[09/26 05:18:17 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.00	top5: 70.00	
[09/26 05:18:17 visual_prompt]: Training 33 / 100 epoch, with learning rate 2.149174750423314
[09/26 05:18:24 visual_prompt]: Epoch 33 / 100: avg data time: 5.58e-02, avg batch time: 0.4986, average train loss: 0.0013
[09/26 05:18:26 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1673, average loss: 3.0227
[09/26 05:18:26 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.00	top5: 70.00	
[09/26 05:18:26 visual_prompt]: Training 34 / 100 epoch, with learning rate 2.1183229630737466
[09/26 05:18:33 visual_prompt]: Epoch 34 / 100: avg data time: 5.27e-02, avg batch time: 0.4978, average train loss: 0.0012
[09/26 05:18:34 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1673, average loss: 3.0247
[09/26 05:18:34 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.00	top5: 70.50	
[09/26 05:18:34 visual_prompt]: Training 35 / 100 epoch, with learning rate 2.086413257948573
[09/26 05:18:41 visual_prompt]: Epoch 35 / 100: avg data time: 6.26e-02, avg batch time: 0.5059, average train loss: 0.0012
[09/26 05:18:43 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1671, average loss: 3.0273
[09/26 05:18:43 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.50	top5: 70.50	
[09/26 05:18:43 visual_prompt]: Training 36 / 100 epoch, with learning rate 2.053484512108174
[09/26 05:18:50 visual_prompt]: Epoch 36 / 100: avg data time: 5.43e-02, avg batch time: 0.4985, average train loss: 0.0012
[09/26 05:18:51 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1672, average loss: 3.0287
[09/26 05:18:51 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.50	top5: 70.50	
[09/26 05:18:51 visual_prompt]: Training 37 / 100 epoch, with learning rate 2.019576844157073
[09/26 05:18:58 visual_prompt]: Epoch 37 / 100: avg data time: 5.63e-02, avg batch time: 0.5003, average train loss: 0.0012
[09/26 05:19:00 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1673, average loss: 3.0289
[09/26 05:19:00 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.50	top5: 69.00	
[09/26 05:19:00 visual_prompt]: Training 38 / 100 epoch, with learning rate 1.9847315653655915
[09/26 05:19:07 visual_prompt]: Epoch 38 / 100: avg data time: 6.06e-02, avg batch time: 0.5041, average train loss: 0.0011
[09/26 05:19:08 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1672, average loss: 3.0292
[09/26 05:19:08 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.50	top5: 69.00	
[09/26 05:19:08 visual_prompt]: Training 39 / 100 epoch, with learning rate 1.9489911293384334
[09/26 05:19:15 visual_prompt]: Epoch 39 / 100: avg data time: 4.91e-02, avg batch time: 0.4933, average train loss: 0.0011
[09/26 05:19:16 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1672, average loss: 3.0313
[09/26 05:19:16 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.50	top5: 69.00	
[09/26 05:19:16 visual_prompt]: Training 40 / 100 epoch, with learning rate 1.912399080291506
[09/26 05:19:23 visual_prompt]: Epoch 40 / 100: avg data time: 6.05e-02, avg batch time: 0.5035, average train loss: 0.0011
[09/26 05:19:25 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1675, average loss: 3.0330
[09/26 05:19:25 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.50	top5: 69.50	
[09/26 05:19:25 visual_prompt]: Training 41 / 100 epoch, with learning rate 1.875
[09/26 05:19:32 visual_prompt]: Epoch 41 / 100: avg data time: 5.58e-02, avg batch time: 0.5000, average train loss: 0.0011
[09/26 05:19:33 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1675, average loss: 3.0340
[09/26 05:19:33 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.00	top5: 69.00	
[09/26 05:19:33 visual_prompt]: Training 42 / 100 epoch, with learning rate 1.8368394534823635
[09/26 05:19:40 visual_prompt]: Epoch 42 / 100: avg data time: 5.94e-02, avg batch time: 0.5043, average train loss: 0.0011
[09/26 05:19:42 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1675, average loss: 3.0356
[09/26 05:19:42 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.00	top5: 69.00	
[09/26 05:19:42 visual_prompt]: Training 43 / 100 epoch, with learning rate 1.7979639334863466
[09/26 05:19:48 visual_prompt]: Epoch 43 / 100: avg data time: 4.99e-02, avg batch time: 0.4932, average train loss: 0.0011
[09/26 05:19:50 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1673, average loss: 3.0358
[09/26 05:19:50 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.00	top5: 69.00	
[09/26 05:19:50 visual_prompt]: Training 44 / 100 epoch, with learning rate 1.7584208038447504
[09/26 05:19:57 visual_prompt]: Epoch 44 / 100: avg data time: 5.38e-02, avg batch time: 0.4981, average train loss: 0.0010
[09/26 05:19:58 visual_prompt]: Inference (val):avg data time: 2.00e-05, avg batch time: 0.1673, average loss: 3.0357
[09/26 05:19:58 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.00	top5: 69.00	
[09/26 05:19:58 visual_prompt]: Training 45 / 100 epoch, with learning rate 1.7182582417698902
[09/26 05:20:05 visual_prompt]: Epoch 45 / 100: avg data time: 6.12e-02, avg batch time: 0.5055, average train loss: 0.0010
[09/26 05:20:07 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1674, average loss: 3.0354
[09/26 05:20:07 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.00	top5: 69.50	
[09/26 05:20:07 visual_prompt]: Training 46 / 100 epoch, with learning rate 1.6775251791570862
[09/26 05:20:14 visual_prompt]: Epoch 46 / 100: avg data time: 5.43e-02, avg batch time: 0.4987, average train loss: 0.0010
[09/26 05:20:15 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1671, average loss: 3.0337
[09/26 05:20:15 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.00	top5: 69.50	
[09/26 05:20:15 visual_prompt]: Training 47 / 100 epoch, with learning rate 1.6362712429686843
[09/26 05:20:22 visual_prompt]: Epoch 47 / 100: avg data time: 5.29e-02, avg batch time: 0.4975, average train loss: 0.0010
[09/26 05:20:24 visual_prompt]: Inference (val):avg data time: 3.62e-05, avg batch time: 0.1676, average loss: 3.0347
[09/26 05:20:24 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.00	top5: 69.50	
[09/26 05:20:24 visual_prompt]: Training 48 / 100 epoch, with learning rate 1.5945466947712488
[09/26 05:20:30 visual_prompt]: Epoch 48 / 100: avg data time: 5.70e-02, avg batch time: 0.5001, average train loss: 0.0010
[09/26 05:20:32 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1672, average loss: 3.0344
[09/26 05:20:32 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.00	top5: 69.50	
[09/26 05:20:32 visual_prompt]: Training 49 / 100 epoch, with learning rate 1.5524023694995845
[09/26 05:20:39 visual_prompt]: Epoch 49 / 100: avg data time: 6.11e-02, avg batch time: 0.5058, average train loss: 0.0010
[09/26 05:20:41 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1674, average loss: 3.0353
[09/26 05:20:41 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.00	top5: 69.50	
[09/26 05:20:41 visual_prompt]: Training 50 / 100 epoch, with learning rate 1.509889613522199
[09/26 05:20:47 visual_prompt]: Epoch 50 / 100: avg data time: 5.94e-02, avg batch time: 0.5034, average train loss: 0.0010
[09/26 05:20:49 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1673, average loss: 3.0373
[09/26 05:20:49 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.00	top5: 69.50	
[09/26 05:20:49 visual_prompt]: Training 51 / 100 epoch, with learning rate 1.467060222083663
[09/26 05:20:56 visual_prompt]: Epoch 51 / 100: avg data time: 6.25e-02, avg batch time: 0.5067, average train loss: 0.0009
[09/26 05:20:58 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1673, average loss: 3.0383
[09/26 05:20:58 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.00	top5: 69.50	
[09/26 05:20:58 visual_prompt]: Training 52 / 100 epoch, with learning rate 1.4239663762000818
[09/26 05:21:04 visual_prompt]: Epoch 52 / 100: avg data time: 5.67e-02, avg batch time: 0.5005, average train loss: 0.0009
[09/26 05:21:06 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1670, average loss: 3.0386
[09/26 05:21:06 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.00	top5: 69.50	
[09/26 05:21:06 visual_prompt]: Training 53 / 100 epoch, with learning rate 1.380660579084567
[09/26 05:21:13 visual_prompt]: Epoch 53 / 100: avg data time: 6.24e-02, avg batch time: 0.5054, average train loss: 0.0009
[09/26 05:21:15 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1670, average loss: 3.0379
[09/26 05:21:15 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.00	top5: 69.50	
[09/26 05:21:15 visual_prompt]: Training 54 / 100 epoch, with learning rate 1.3371955921801564
[09/26 05:21:21 visual_prompt]: Epoch 54 / 100: avg data time: 6.36e-02, avg batch time: 0.5070, average train loss: 0.0009
[09/26 05:21:23 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1674, average loss: 3.0377
[09/26 05:21:23 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.00	top5: 69.50	
[09/26 05:21:23 visual_prompt]: Training 55 / 100 epoch, with learning rate 1.2936243708781263
[09/26 05:21:30 visual_prompt]: Epoch 55 / 100: avg data time: 6.03e-02, avg batch time: 0.5030, average train loss: 0.0009
[09/26 05:21:32 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1673, average loss: 3.0360
[09/26 05:21:32 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.50	top5: 69.50	
[09/26 05:21:32 visual_prompt]: Training 56 / 100 epoch, with learning rate 1.25
[09/26 05:21:38 visual_prompt]: Epoch 56 / 100: avg data time: 6.29e-02, avg batch time: 0.5071, average train loss: 0.0009
[09/26 05:21:40 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1673, average loss: 3.0379
[09/26 05:21:40 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.50	top5: 69.50	
[09/26 05:21:40 visual_prompt]: Training 57 / 100 epoch, with learning rate 1.2063756291218741
[09/26 05:21:47 visual_prompt]: Epoch 57 / 100: avg data time: 5.57e-02, avg batch time: 0.4989, average train loss: 0.0009
[09/26 05:21:48 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1671, average loss: 3.0380
[09/26 05:21:48 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.50	top5: 69.50	
[09/26 05:21:48 visual_prompt]: Training 58 / 100 epoch, with learning rate 1.1628044078198434
[09/26 05:21:55 visual_prompt]: Epoch 58 / 100: avg data time: 5.74e-02, avg batch time: 0.5021, average train loss: 0.0009
[09/26 05:21:57 visual_prompt]: Inference (val):avg data time: 1.93e-05, avg batch time: 0.1672, average loss: 3.0387
[09/26 05:21:57 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.50	top5: 70.00	
[09/26 05:21:57 visual_prompt]: Training 59 / 100 epoch, with learning rate 1.1193394209154333
[09/26 05:22:04 visual_prompt]: Epoch 59 / 100: avg data time: 6.03e-02, avg batch time: 0.5039, average train loss: 0.0008
[09/26 05:22:05 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1674, average loss: 3.0395
[09/26 05:22:05 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.50	top5: 70.00	
[09/26 05:22:05 visual_prompt]: Training 60 / 100 epoch, with learning rate 1.0760336237999186
[09/26 05:22:12 visual_prompt]: Epoch 60 / 100: avg data time: 5.32e-02, avg batch time: 0.4982, average train loss: 0.0009
[09/26 05:22:14 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1674, average loss: 3.0397
[09/26 05:22:14 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.50	top5: 70.00	
[09/26 05:22:14 visual_prompt]: Training 61 / 100 epoch, with learning rate 1.0329397779163372
[09/26 05:22:21 visual_prompt]: Epoch 61 / 100: avg data time: 6.29e-02, avg batch time: 0.5059, average train loss: 0.0008
[09/26 05:22:22 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1673, average loss: 3.0405
[09/26 05:22:22 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.50	top5: 70.00	
[09/26 05:22:22 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.990110386477801
[09/26 05:22:29 visual_prompt]: Epoch 62 / 100: avg data time: 6.29e-02, avg batch time: 0.5075, average train loss: 0.0009
[09/26 05:22:31 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1676, average loss: 3.0405
[09/26 05:22:31 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.50	top5: 70.00	
[09/26 05:22:31 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.9475976305004155
[09/26 05:22:38 visual_prompt]: Epoch 63 / 100: avg data time: 6.24e-02, avg batch time: 0.5068, average train loss: 0.0009
[09/26 05:22:39 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1675, average loss: 3.0403
[09/26 05:22:39 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.50	top5: 70.00	
[09/26 05:22:39 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.9054533052287511
[09/26 05:22:46 visual_prompt]: Epoch 64 / 100: avg data time: 4.66e-02, avg batch time: 0.4928, average train loss: 0.0008
[09/26 05:22:48 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1676, average loss: 3.0409
[09/26 05:22:48 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.50	top5: 70.00	
[09/26 05:22:48 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.8637287570313158
[09/26 05:22:54 visual_prompt]: Epoch 65 / 100: avg data time: 5.66e-02, avg batch time: 0.5012, average train loss: 0.0008
[09/26 05:22:56 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1674, average loss: 3.0411
[09/26 05:22:56 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.50	top5: 70.00	
[09/26 05:22:56 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.8224748208429142
[09/26 05:23:03 visual_prompt]: Epoch 66 / 100: avg data time: 5.71e-02, avg batch time: 0.5007, average train loss: 0.0008
[09/26 05:23:04 visual_prompt]: Inference (val):avg data time: 4.39e-05, avg batch time: 0.1672, average loss: 3.0412
[09/26 05:23:04 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.50	top5: 70.00	
[09/26 05:23:04 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.7817417582301099
[09/26 05:23:11 visual_prompt]: Epoch 67 / 100: avg data time: 5.68e-02, avg batch time: 0.5012, average train loss: 0.0008
[09/26 05:23:13 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1676, average loss: 3.0413
[09/26 05:23:13 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.50	top5: 70.00	
[09/26 05:23:13 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.7415791961552499
[09/26 05:23:20 visual_prompt]: Epoch 68 / 100: avg data time: 6.13e-02, avg batch time: 0.5062, average train loss: 0.0008
[09/26 05:23:21 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1672, average loss: 3.0418
[09/26 05:23:21 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.50	top5: 69.50	
[09/26 05:23:21 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.7020360665136531
[09/26 05:23:28 visual_prompt]: Epoch 69 / 100: avg data time: 5.89e-02, avg batch time: 0.5041, average train loss: 0.0008
[09/26 05:23:30 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1676, average loss: 3.0424
[09/26 05:23:30 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.50	top5: 70.00	
[09/26 05:23:30 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.6631605465176369
[09/26 05:23:37 visual_prompt]: Epoch 70 / 100: avg data time: 5.61e-02, avg batch time: 0.5009, average train loss: 0.0008
[09/26 05:23:38 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1675, average loss: 3.0427
[09/26 05:23:38 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.50	top5: 70.00	
[09/26 05:23:38 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.6250000000000002
[09/26 05:23:45 visual_prompt]: Epoch 71 / 100: avg data time: 6.36e-02, avg batch time: 0.5071, average train loss: 0.0008
[09/26 05:23:47 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1676, average loss: 3.0428
[09/26 05:23:47 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.50	top5: 70.00	
[09/26 05:23:47 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.587600919708494
[09/26 05:23:54 visual_prompt]: Epoch 72 / 100: avg data time: 6.37e-02, avg batch time: 0.5077, average train loss: 0.0008
[09/26 05:23:55 visual_prompt]: Inference (val):avg data time: 3.76e-05, avg batch time: 0.1674, average loss: 3.0426
[09/26 05:23:55 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.50	top5: 70.00	
[09/26 05:23:55 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.5510088706615667
[09/26 05:24:02 visual_prompt]: Epoch 73 / 100: avg data time: 6.27e-02, avg batch time: 0.5074, average train loss: 0.0008
[09/26 05:24:04 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1675, average loss: 3.0428
[09/26 05:24:04 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.50	top5: 70.00	
[09/26 05:24:04 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.5152684346344087
[09/26 05:24:11 visual_prompt]: Epoch 74 / 100: avg data time: 5.80e-02, avg batch time: 0.5029, average train loss: 0.0008
[09/26 05:24:12 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1678, average loss: 3.0430
[09/26 05:24:12 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.50	top5: 70.00	
[09/26 05:24:12 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.48042315584292716
[09/26 05:24:19 visual_prompt]: Epoch 75 / 100: avg data time: 5.46e-02, avg batch time: 0.4999, average train loss: 0.0008
[09/26 05:24:21 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1675, average loss: 3.0434
[09/26 05:24:21 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.50	top5: 70.00	
[09/26 05:24:21 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.4465154878918258
[09/26 05:24:28 visual_prompt]: Epoch 76 / 100: avg data time: 5.94e-02, avg batch time: 0.5044, average train loss: 0.0008
[09/26 05:24:29 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1674, average loss: 3.0436
[09/26 05:24:29 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.50	top5: 70.00	
[09/26 05:24:29 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.41358674205142765
[09/26 05:24:36 visual_prompt]: Epoch 77 / 100: avg data time: 5.99e-02, avg batch time: 0.5035, average train loss: 0.0008
[09/26 05:24:38 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1674, average loss: 3.0436
[09/26 05:24:38 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.50	top5: 70.00	
[09/26 05:24:38 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.3816770369262533
[09/26 05:24:45 visual_prompt]: Epoch 78 / 100: avg data time: 5.89e-02, avg batch time: 0.5034, average train loss: 0.0008
[09/26 05:24:46 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1672, average loss: 3.0435
[09/26 05:24:46 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.50	top5: 70.00	
[09/26 05:24:46 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.35082524957668626
[09/26 05:24:53 visual_prompt]: Epoch 79 / 100: avg data time: 6.26e-02, avg batch time: 0.5065, average train loss: 0.0008
[09/26 05:24:55 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1675, average loss: 3.0434
[09/26 05:24:55 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.50	top5: 70.00	
[09/26 05:24:55 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.32106896815325703
[09/26 05:25:02 visual_prompt]: Epoch 80 / 100: avg data time: 5.80e-02, avg batch time: 0.5027, average train loss: 0.0008
[09/26 05:25:03 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1675, average loss: 3.0439
[09/26 05:25:03 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.50	top5: 70.00	
[09/26 05:25:03 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.2924444461012776
[09/26 05:25:10 visual_prompt]: Epoch 81 / 100: avg data time: 5.33e-02, avg batch time: 0.4977, average train loss: 0.0008
[09/26 05:25:12 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1673, average loss: 3.0440
[09/26 05:25:12 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.50	top5: 70.00	
[09/26 05:25:12 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.26498655799159765
[09/26 05:25:19 visual_prompt]: Epoch 82 / 100: avg data time: 6.07e-02, avg batch time: 0.5051, average train loss: 0.0008
[09/26 05:25:20 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1672, average loss: 3.0440
[09/26 05:25:20 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.50	top5: 70.00	
[09/26 05:25:20 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.23872875703131582
[09/26 05:25:27 visual_prompt]: Epoch 83 / 100: avg data time: 4.53e-02, avg batch time: 0.4906, average train loss: 0.0008
[09/26 05:25:28 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1675, average loss: 3.0441
[09/26 05:25:28 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.50	top5: 70.00	
[09/26 05:25:28 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.21370303430619797
[09/26 05:25:35 visual_prompt]: Epoch 84 / 100: avg data time: 4.83e-02, avg batch time: 0.4932, average train loss: 0.0008
[09/26 05:25:37 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1673, average loss: 3.0443
[09/26 05:25:37 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.50	top5: 70.00	
[09/26 05:25:37 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.18993987980446755
[09/26 05:25:44 visual_prompt]: Epoch 85 / 100: avg data time: 5.78e-02, avg batch time: 0.5023, average train loss: 0.0008
[09/26 05:25:45 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1675, average loss: 3.0442
[09/26 05:25:45 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.50	top5: 70.00	
[09/26 05:25:45 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.16746824526945162
[09/26 05:25:52 visual_prompt]: Epoch 86 / 100: avg data time: 5.94e-02, avg batch time: 0.5030, average train loss: 0.0008
[09/26 05:25:54 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1674, average loss: 3.0441
[09/26 05:25:54 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.50	top5: 70.00	
[09/26 05:25:54 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.14631550892634126
[09/26 05:26:00 visual_prompt]: Epoch 87 / 100: avg data time: 5.50e-02, avg batch time: 0.4998, average train loss: 0.0007
[09/26 05:26:02 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1678, average loss: 3.0441
[09/26 05:26:02 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.50	top5: 70.00	
[09/26 05:26:02 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.12650744212604148
[09/26 05:26:09 visual_prompt]: Epoch 88 / 100: avg data time: 4.48e-02, avg batch time: 0.4895, average train loss: 0.0008
[09/26 05:26:10 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1676, average loss: 3.0442
[09/26 05:26:10 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.50	top5: 70.00	
[09/26 05:26:10 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.10806817794674878
[09/26 05:26:17 visual_prompt]: Epoch 89 / 100: avg data time: 5.57e-02, avg batch time: 0.5006, average train loss: 0.0008
[09/26 05:26:19 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1677, average loss: 3.0442
[09/26 05:26:19 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.50	top5: 70.00	
[09/26 05:26:19 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.09102018179151586
[09/26 05:26:26 visual_prompt]: Epoch 90 / 100: avg data time: 6.08e-02, avg batch time: 0.5047, average train loss: 0.0008
[09/26 05:26:27 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1675, average loss: 3.0443
[09/26 05:26:27 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.50	top5: 70.00	
[09/26 05:26:27 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.0753842240176146
[09/26 05:26:34 visual_prompt]: Epoch 91 / 100: avg data time: 6.09e-02, avg batch time: 0.5045, average train loss: 0.0008
[09/26 05:26:36 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1671, average loss: 3.0444
[09/26 05:26:36 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.50	top5: 70.00	
[09/26 05:26:36 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.061179354631058086
[09/26 05:26:43 visual_prompt]: Epoch 92 / 100: avg data time: 5.42e-02, avg batch time: 0.5015, average train loss: 0.0008
[09/26 05:26:44 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1669, average loss: 3.0444
[09/26 05:26:44 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.50	top5: 70.00	
[09/26 05:26:44 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.04842288007710138
[09/26 05:26:51 visual_prompt]: Epoch 93 / 100: avg data time: 5.63e-02, avg batch time: 0.5018, average train loss: 0.0008
[09/26 05:26:53 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1676, average loss: 3.0444
[09/26 05:26:53 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.50	top5: 70.00	
[09/26 05:26:53 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.03713034215500441
[09/26 05:26:59 visual_prompt]: Epoch 94 / 100: avg data time: 5.68e-02, avg batch time: 0.5020, average train loss: 0.0008
[09/26 05:27:01 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1676, average loss: 3.0444
[09/26 05:27:01 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.50	top5: 70.00	
[09/26 05:27:01 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.02731549908274289
[09/26 05:27:08 visual_prompt]: Epoch 95 / 100: avg data time: 5.63e-02, avg batch time: 0.4993, average train loss: 0.0008
[09/26 05:27:10 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1675, average loss: 3.0444
[09/26 05:27:10 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.50	top5: 70.00	
[09/26 05:27:10 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.018990308734739975
[09/26 05:27:16 visual_prompt]: Epoch 96 / 100: avg data time: 5.82e-02, avg batch time: 0.5026, average train loss: 0.0008
[09/26 05:27:18 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1674, average loss: 3.0445
[09/26 05:27:18 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.50	top5: 70.00	
[09/26 05:27:18 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.012164914073037048
[09/26 05:27:25 visual_prompt]: Epoch 97 / 100: avg data time: 5.89e-02, avg batch time: 0.5033, average train loss: 0.0008
[09/26 05:27:26 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1676, average loss: 3.0445
[09/26 05:27:26 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.50	top5: 70.00	
[09/26 05:27:26 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.006847630789658388
[09/26 05:27:33 visual_prompt]: Epoch 98 / 100: avg data time: 6.71e-02, avg batch time: 0.5101, average train loss: 0.0008
[09/26 05:27:35 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1673, average loss: 3.0445
[09/26 05:27:35 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.50	top5: 70.00	
[09/26 05:27:35 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.003044937175219753
[09/26 05:27:42 visual_prompt]: Epoch 99 / 100: avg data time: 6.22e-02, avg batch time: 0.5058, average train loss: 0.0008
[09/26 05:27:44 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1673, average loss: 3.0445
[09/26 05:27:44 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.50	top5: 70.00	
[09/26 05:27:44 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0007614662261302974
[09/26 05:27:50 visual_prompt]: Epoch 100 / 100: avg data time: 5.77e-02, avg batch time: 0.5010, average train loss: 0.0008
[09/26 05:27:52 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1671, average loss: 3.0445
[09/26 05:27:52 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.50	top5: 70.00	
[09/26 05:27:52 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 05:27:52 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              0
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 05:27:52 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-sun397', 'DATA.NUMBER_CLASSES', '397', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 05:27:52 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 05:27:52 visual_prompt]: Training with config:
[09/26 05:27:52 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-sun397/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr1.0_wd0.01/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 1.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-sun397', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 397, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 05:27:52 visual_prompt]: Loading training data...
[09/26 05:27:52 visual_prompt]: Constructing vtab-sun397 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split train[:800], from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/26 05:27:53 visual_prompt]: Number of images: 800
[09/26 05:27:53 visual_prompt]: Number of classes: 309 / 397
[09/26 05:27:53 visual_prompt]: Loading validation data...
[09/26 05:27:53 visual_prompt]: Constructing vtab-sun397 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split validation[:200], from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/26 05:27:54 visual_prompt]: Number of images: 200
[09/26 05:27:54 visual_prompt]: Number of classes: 136 / 397
[09/26 05:27:54 visual_prompt]: Constructing models...
[09/26 05:27:56 visual_prompt]: Total Parameters: 86564749	 Gradient Parameters: 766093
[09/26 05:27:56 visual_prompt]: tuned percent:0.885
[09/26 05:27:56 visual_prompt]: Device used for model: 0
[09/26 05:27:56 visual_prompt]: Setting up Evaluator...
[09/26 05:27:56 visual_prompt]: Setting up Trainer...
[09/26 05:27:56 visual_prompt]: 	Setting up the optimizer...
[09/26 05:27:56 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 05:28:03 visual_prompt]: Epoch 1 / 100: avg data time: 5.52e-02, avg batch time: 0.5004, average train loss: 5.9886
[09/26 05:28:05 visual_prompt]: Inference (val):avg data time: 4.27e-05, avg batch time: 0.1670, average loss: 6.0097
[09/26 05:28:05 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/26 05:28:05 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.1
[09/26 05:28:12 visual_prompt]: Epoch 2 / 100: avg data time: 5.54e-02, avg batch time: 0.4989, average train loss: 5.8885
[09/26 05:28:13 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1669, average loss: 5.8430
[09/26 05:28:13 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 05:28:13 visual_prompt]: Best epoch 2: best metric: 0.005
[09/26 05:28:13 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.2
[09/26 05:28:20 visual_prompt]: Epoch 3 / 100: avg data time: 6.74e-02, avg batch time: 0.5100, average train loss: 5.6701
[09/26 05:28:22 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1671, average loss: 5.8151
[09/26 05:28:22 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.50	
[09/26 05:28:22 visual_prompt]: Best epoch 3: best metric: 0.010
[09/26 05:28:22 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.3
[09/26 05:28:29 visual_prompt]: Epoch 4 / 100: avg data time: 5.85e-02, avg batch time: 0.5015, average train loss: 5.5671
[09/26 05:28:30 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1671, average loss: 5.6568
[09/26 05:28:30 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.00	top5: 9.00	
[09/26 05:28:30 visual_prompt]: Best epoch 4: best metric: 0.020
[09/26 05:28:30 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.4
[09/26 05:28:37 visual_prompt]: Epoch 5 / 100: avg data time: 6.24e-02, avg batch time: 0.5056, average train loss: 5.3738
[09/26 05:28:39 visual_prompt]: Inference (val):avg data time: 3.67e-05, avg batch time: 0.1672, average loss: 5.4316
[09/26 05:28:39 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.00	top5: 11.00	
[09/26 05:28:39 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.5
[09/26 05:28:46 visual_prompt]: Epoch 6 / 100: avg data time: 6.40e-02, avg batch time: 0.5086, average train loss: 5.5011
[09/26 05:28:47 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1672, average loss: 5.7495
[09/26 05:28:47 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 4.50	
[09/26 05:28:47 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.6
[09/26 05:28:54 visual_prompt]: Epoch 7 / 100: avg data time: 4.97e-02, avg batch time: 0.4922, average train loss: 5.6131
[09/26 05:28:56 visual_prompt]: Inference (val):avg data time: 3.62e-05, avg batch time: 0.1668, average loss: 5.6887
[09/26 05:28:56 visual_prompt]: Classification results with val_vtab-sun397: top1: 3.00	top5: 7.50	
[09/26 05:28:56 visual_prompt]: Best epoch 7: best metric: 0.030
[09/26 05:28:56 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.7
[09/26 05:29:03 visual_prompt]: Epoch 8 / 100: avg data time: 5.59e-02, avg batch time: 0.5006, average train loss: 5.5008
[09/26 05:29:04 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1671, average loss: 5.8017
[09/26 05:29:04 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.00	
[09/26 05:29:04 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.8
[09/26 05:29:11 visual_prompt]: Epoch 9 / 100: avg data time: 5.34e-02, avg batch time: 0.4991, average train loss: 5.6363
[09/26 05:29:13 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1675, average loss: 5.8407
[09/26 05:29:13 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 4.50	
[09/26 05:29:13 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.9
[09/26 05:29:20 visual_prompt]: Epoch 10 / 100: avg data time: 6.48e-02, avg batch time: 0.5092, average train loss: 5.6455
[09/26 05:29:21 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1672, average loss: 5.9391
[09/26 05:29:21 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 5.50	
[09/26 05:29:21 visual_prompt]: Training 11 / 100 epoch, with learning rate 1.0
[09/26 05:29:28 visual_prompt]: Epoch 11 / 100: avg data time: 5.30e-02, avg batch time: 0.4960, average train loss: 5.5939
[09/26 05:29:30 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1673, average loss: 5.8645
[09/26 05:29:30 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.00	
[09/26 05:29:30 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.9996954135095479
[09/26 05:29:36 visual_prompt]: Epoch 12 / 100: avg data time: 6.40e-02, avg batch time: 0.5068, average train loss: 5.5983
[09/26 05:29:38 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1677, average loss: 5.8112
[09/26 05:29:38 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 5.00	
[09/26 05:29:38 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.9987820251299121
[09/26 05:29:45 visual_prompt]: Epoch 13 / 100: avg data time: 6.15e-02, avg batch time: 0.5037, average train loss: 5.5596
[09/26 05:29:46 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1670, average loss: 5.8308
[09/26 05:29:46 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 5.00	
[09/26 05:29:46 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.9972609476841366
[09/26 05:29:53 visual_prompt]: Epoch 14 / 100: avg data time: 6.05e-02, avg batch time: 0.5045, average train loss: 5.5723
[09/26 05:29:55 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1671, average loss: 5.8655
[09/26 05:29:55 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 5.00	
[09/26 05:29:55 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.9951340343707852
[09/26 05:30:02 visual_prompt]: Epoch 15 / 100: avg data time: 6.24e-02, avg batch time: 0.5055, average train loss: 5.5688
[09/26 05:30:03 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1671, average loss: 5.8369
[09/26 05:30:03 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.50	
[09/26 05:30:03 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.9924038765061041
[09/26 05:30:10 visual_prompt]: Epoch 16 / 100: avg data time: 6.41e-02, avg batch time: 0.5084, average train loss: 5.5262
[09/26 05:30:12 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1674, average loss: 5.8560
[09/26 05:30:12 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 05:30:12 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.9890738003669028
[09/26 05:30:19 visual_prompt]: Epoch 17 / 100: avg data time: 5.55e-02, avg batch time: 0.4985, average train loss: 5.5351
[09/26 05:30:20 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1674, average loss: 5.8741
[09/26 05:30:20 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.50	
[09/26 05:30:20 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.9851478631379982
[09/26 05:30:27 visual_prompt]: Epoch 18 / 100: avg data time: 5.98e-02, avg batch time: 0.5035, average train loss: 5.5615
[09/26 05:30:29 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1679, average loss: 5.8924
[09/26 05:30:29 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 05:30:29 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.9806308479691594
[09/26 05:30:36 visual_prompt]: Epoch 19 / 100: avg data time: 6.16e-02, avg batch time: 0.5044, average train loss: 5.5583
[09/26 05:30:37 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1674, average loss: 5.9001
[09/26 05:30:37 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 6.00	
[09/26 05:30:37 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.9755282581475768
[09/26 05:30:44 visual_prompt]: Epoch 20 / 100: avg data time: 5.86e-02, avg batch time: 0.5034, average train loss: 5.5599
[09/26 05:30:46 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1669, average loss: 5.9050
[09/26 05:30:46 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 5.00	
[09/26 05:30:46 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.9698463103929542
[09/26 05:30:53 visual_prompt]: Epoch 21 / 100: avg data time: 6.04e-02, avg batch time: 0.5027, average train loss: 5.5309
[09/26 05:30:54 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1669, average loss: 5.9028
[09/26 05:30:54 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.00	
[09/26 05:30:54 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.9635919272833937
[09/26 05:31:01 visual_prompt]: Epoch 22 / 100: avg data time: 5.99e-02, avg batch time: 0.5046, average train loss: 5.5285
[09/26 05:31:03 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1671, average loss: 5.9037
[09/26 05:31:03 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 5.00	
[09/26 05:31:03 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.9567727288213004
[09/26 05:31:10 visual_prompt]: Epoch 23 / 100: avg data time: 5.37e-02, avg batch time: 0.4964, average train loss: 5.5371
[09/26 05:31:11 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1672, average loss: 5.8644
[09/26 05:31:11 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 5.50	
[09/26 05:31:11 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.9493970231495835
[09/26 05:31:18 visual_prompt]: Epoch 24 / 100: avg data time: 5.56e-02, avg batch time: 0.4979, average train loss: 5.5404
[09/26 05:31:19 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1673, average loss: 5.8755
[09/26 05:31:19 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 05:31:19 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.9414737964294635
[09/26 05:31:26 visual_prompt]: Epoch 25 / 100: avg data time: 5.56e-02, avg batch time: 0.4989, average train loss: 5.5272
[09/26 05:31:28 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1669, average loss: 5.8688
[09/26 05:31:28 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 05:31:28 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.9330127018922194
[09/26 05:31:35 visual_prompt]: Epoch 26 / 100: avg data time: 5.83e-02, avg batch time: 0.5007, average train loss: 5.5101
[09/26 05:31:36 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1670, average loss: 5.8552
[09/26 05:31:36 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.50	
[09/26 05:31:36 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.9240240480782129
[09/26 05:31:43 visual_prompt]: Epoch 27 / 100: avg data time: 5.40e-02, avg batch time: 0.5002, average train loss: 5.5395
[09/26 05:31:45 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1666, average loss: 5.8894
[09/26 05:31:45 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.50	
[09/26 05:31:45 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.9145187862775208
[09/26 05:31:52 visual_prompt]: Epoch 28 / 100: avg data time: 5.76e-02, avg batch time: 0.4999, average train loss: 5.5139
[09/26 05:31:53 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1669, average loss: 5.8814
[09/26 05:31:53 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 4.50	
[09/26 05:31:53 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.9045084971874737
[09/26 05:32:00 visual_prompt]: Epoch 29 / 100: avg data time: 5.50e-02, avg batch time: 0.4974, average train loss: 5.5162
[09/26 05:32:02 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1668, average loss: 5.8962
[09/26 05:32:02 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 5.50	
[09/26 05:32:02 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.8940053768033609
[09/26 05:32:08 visual_prompt]: Epoch 30 / 100: avg data time: 6.22e-02, avg batch time: 0.5050, average train loss: 5.5047
[09/26 05:32:10 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1669, average loss: 5.9163
[09/26 05:32:10 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 5.00	
[09/26 05:32:10 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.883022221559489
[09/26 05:32:17 visual_prompt]: Epoch 31 / 100: avg data time: 5.77e-02, avg batch time: 0.5013, average train loss: 5.5654
[09/26 05:32:18 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1666, average loss: 5.8959
[09/26 05:32:18 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.50	
[09/26 05:32:18 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.8715724127386971
[09/26 05:32:25 visual_prompt]: Epoch 32 / 100: avg data time: 4.57e-02, avg batch time: 0.4884, average train loss: 5.5422
[09/26 05:32:27 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1669, average loss: 5.9168
[09/26 05:32:27 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 5.00	
[09/26 05:32:27 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.8596699001693255
[09/26 05:32:33 visual_prompt]: Epoch 33 / 100: avg data time: 5.88e-02, avg batch time: 0.5024, average train loss: 5.5172
[09/26 05:32:35 visual_prompt]: Inference (val):avg data time: 2.11e-05, avg batch time: 0.1673, average loss: 5.8995
[09/26 05:32:35 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.50	
[09/26 05:32:35 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.8473291852294986
[09/26 05:32:42 visual_prompt]: Epoch 34 / 100: avg data time: 5.78e-02, avg batch time: 0.5014, average train loss: 5.5331
[09/26 05:32:44 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1669, average loss: 5.9108
[09/26 05:32:44 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 05:32:44 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.8345653031794291
[09/26 05:32:50 visual_prompt]: Epoch 35 / 100: avg data time: 5.93e-02, avg batch time: 0.5032, average train loss: 5.5104
[09/26 05:32:52 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1668, average loss: 5.8860
[09/26 05:32:52 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 5.00	
[09/26 05:32:52 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.8213938048432696
[09/26 05:32:59 visual_prompt]: Epoch 36 / 100: avg data time: 5.54e-02, avg batch time: 0.4978, average train loss: 5.5215
[09/26 05:33:00 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1668, average loss: 5.8921
[09/26 05:33:00 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.50	
[09/26 05:33:00 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.8078307376628291
[09/26 05:33:07 visual_prompt]: Epoch 37 / 100: avg data time: 6.40e-02, avg batch time: 0.5063, average train loss: 5.4895
[09/26 05:33:09 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1668, average loss: 5.9206
[09/26 05:33:09 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.00	
[09/26 05:33:09 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.7938926261462366
[09/26 05:33:16 visual_prompt]: Epoch 38 / 100: avg data time: 5.70e-02, avg batch time: 0.4992, average train loss: 5.5067
[09/26 05:33:17 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1669, average loss: 5.9438
[09/26 05:33:17 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.00	
[09/26 05:33:17 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.7795964517353734
[09/26 05:33:24 visual_prompt]: Epoch 39 / 100: avg data time: 5.83e-02, avg batch time: 0.5026, average train loss: 5.5104
[09/26 05:33:26 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1672, average loss: 5.8937
[09/26 05:33:26 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 6.00	
[09/26 05:33:26 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.7649596321166025
[09/26 05:33:33 visual_prompt]: Epoch 40 / 100: avg data time: 6.03e-02, avg batch time: 0.5026, average train loss: 5.5036
[09/26 05:33:34 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1677, average loss: 5.9479
[09/26 05:33:34 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 2.50	
[09/26 05:33:34 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.75
[09/26 05:33:41 visual_prompt]: Epoch 41 / 100: avg data time: 6.57e-02, avg batch time: 0.5083, average train loss: 5.5314
[09/26 05:33:43 visual_prompt]: Inference (val):avg data time: 4.24e-05, avg batch time: 0.1671, average loss: 5.9822
[09/26 05:33:43 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.00	
[09/26 05:33:43 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.7347357813929454
[09/26 05:33:50 visual_prompt]: Epoch 42 / 100: avg data time: 5.98e-02, avg batch time: 0.5035, average train loss: 5.5302
[09/26 05:33:51 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1678, average loss: 5.9242
[09/26 05:33:51 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 5.00	
[09/26 05:33:51 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.7191855733945387
[09/26 05:33:58 visual_prompt]: Epoch 43 / 100: avg data time: 6.64e-02, avg batch time: 0.5084, average train loss: 5.5136
[09/26 05:34:00 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1675, average loss: 5.9330
[09/26 05:34:00 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 5.00	
[09/26 05:34:00 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.7033683215379002
[09/26 05:34:06 visual_prompt]: Epoch 44 / 100: avg data time: 5.65e-02, avg batch time: 0.4994, average train loss: 5.4856
[09/26 05:34:08 visual_prompt]: Inference (val):avg data time: 3.53e-05, avg batch time: 0.1671, average loss: 5.9434
[09/26 05:34:08 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 5.00	
[09/26 05:34:08 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.6873032967079561
[09/26 05:34:15 visual_prompt]: Epoch 45 / 100: avg data time: 6.46e-02, avg batch time: 0.5068, average train loss: 5.4948
[09/26 05:34:17 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1676, average loss: 5.9603
[09/26 05:34:17 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 5.00	
[09/26 05:34:17 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.6710100716628344
[09/26 05:34:23 visual_prompt]: Epoch 46 / 100: avg data time: 5.52e-02, avg batch time: 0.4975, average train loss: 5.5125
[09/26 05:34:25 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1674, average loss: 5.9196
[09/26 05:34:25 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 05:34:25 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.6545084971874737
[09/26 05:34:32 visual_prompt]: Epoch 47 / 100: avg data time: 5.52e-02, avg batch time: 0.4978, average train loss: 5.4968
[09/26 05:34:33 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1675, average loss: 5.9075
[09/26 05:34:33 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.50	
[09/26 05:34:33 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.6378186779084996
[09/26 05:34:40 visual_prompt]: Epoch 48 / 100: avg data time: 5.18e-02, avg batch time: 0.4970, average train loss: 5.4953
[09/26 05:34:42 visual_prompt]: Inference (val):avg data time: 1.89e-05, avg batch time: 0.1677, average loss: 5.9361
[09/26 05:34:42 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 5.00	
[09/26 05:34:42 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.6209609477998338
[09/26 05:34:49 visual_prompt]: Epoch 49 / 100: avg data time: 5.92e-02, avg batch time: 0.5026, average train loss: 5.5121
[09/26 05:34:50 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1677, average loss: 5.9613
[09/26 05:34:50 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 5.50	
[09/26 05:34:50 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.6039558454088796
[09/26 05:34:57 visual_prompt]: Epoch 50 / 100: avg data time: 6.24e-02, avg batch time: 0.5055, average train loss: 5.4994
[09/26 05:34:59 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1676, average loss: 5.8997
[09/26 05:34:59 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 4.50	
[09/26 05:34:59 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.5868240888334653
[09/26 05:35:06 visual_prompt]: Epoch 51 / 100: avg data time: 5.95e-02, avg batch time: 0.5025, average train loss: 5.4962
[09/26 05:35:07 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1674, average loss: 5.9157
[09/26 05:35:07 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.00	
[09/26 05:35:07 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.5695865504800327
[09/26 05:35:14 visual_prompt]: Epoch 52 / 100: avg data time: 5.31e-02, avg batch time: 0.4974, average train loss: 5.4851
[09/26 05:35:16 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1675, average loss: 5.9164
[09/26 05:35:16 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 05:35:16 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.5522642316338268
[09/26 05:35:22 visual_prompt]: Epoch 53 / 100: avg data time: 5.89e-02, avg batch time: 0.5028, average train loss: 5.4861
[09/26 05:35:24 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1674, average loss: 5.9318
[09/26 05:35:24 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.00	
[09/26 05:35:24 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.5348782368720626
[09/26 05:35:31 visual_prompt]: Epoch 54 / 100: avg data time: 5.86e-02, avg batch time: 0.5018, average train loss: 5.4878
[09/26 05:35:33 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1675, average loss: 5.9067
[09/26 05:35:33 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 05:35:33 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.5174497483512506
[09/26 05:35:39 visual_prompt]: Epoch 55 / 100: avg data time: 6.15e-02, avg batch time: 0.5042, average train loss: 5.4829
[09/26 05:35:41 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1671, average loss: 5.9567
[09/26 05:35:41 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 05:35:41 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.5
[09/26 05:35:48 visual_prompt]: Epoch 56 / 100: avg data time: 6.21e-02, avg batch time: 0.5043, average train loss: 5.4899
[09/26 05:35:50 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1672, average loss: 5.9139
[09/26 05:35:50 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.00	
[09/26 05:35:50 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.48255025164874965
[09/26 05:35:56 visual_prompt]: Epoch 57 / 100: avg data time: 6.30e-02, avg batch time: 0.5062, average train loss: 5.4834
[09/26 05:35:58 visual_prompt]: Inference (val):avg data time: 4.79e-05, avg batch time: 0.1671, average loss: 5.9287
[09/26 05:35:58 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 05:35:58 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.46512176312793735
[09/26 05:36:05 visual_prompt]: Epoch 58 / 100: avg data time: 5.57e-02, avg batch time: 0.4989, average train loss: 5.4918
[09/26 05:36:07 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1680, average loss: 5.9164
[09/26 05:36:07 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 4.50	
[09/26 05:36:07 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.44773576836617335
[09/26 05:36:13 visual_prompt]: Epoch 59 / 100: avg data time: 5.58e-02, avg batch time: 0.4999, average train loss: 5.4790
[09/26 05:36:15 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1673, average loss: 5.9533
[09/26 05:36:15 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.00	
[09/26 05:36:15 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.4304134495199674
[09/26 05:36:22 visual_prompt]: Epoch 60 / 100: avg data time: 5.26e-02, avg batch time: 0.4951, average train loss: 5.4794
[09/26 05:36:23 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1673, average loss: 5.9502
[09/26 05:36:23 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 05:36:23 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.41317591116653485
[09/26 05:36:30 visual_prompt]: Epoch 61 / 100: avg data time: 6.17e-02, avg batch time: 0.5049, average train loss: 5.4953
[09/26 05:36:32 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1672, average loss: 5.9207
[09/26 05:36:32 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 5.50	
[09/26 05:36:32 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.3960441545911204
[09/26 05:36:39 visual_prompt]: Epoch 62 / 100: avg data time: 6.00e-02, avg batch time: 0.5047, average train loss: 5.4748
[09/26 05:36:40 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.1672, average loss: 5.9269
[09/26 05:36:40 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 5.00	
[09/26 05:36:40 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.3790390522001662
[09/26 05:36:47 visual_prompt]: Epoch 63 / 100: avg data time: 5.98e-02, avg batch time: 0.5026, average train loss: 5.4710
[09/26 05:36:49 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1674, average loss: 5.8986
[09/26 05:36:49 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.00	top5: 5.00	
[09/26 05:36:49 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.36218132209150045
[09/26 05:36:56 visual_prompt]: Epoch 64 / 100: avg data time: 6.02e-02, avg batch time: 0.5048, average train loss: 5.4489
[09/26 05:36:57 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1670, average loss: 5.9260
[09/26 05:36:57 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 4.50	
[09/26 05:36:57 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.34549150281252633
[09/26 05:37:04 visual_prompt]: Epoch 65 / 100: avg data time: 5.70e-02, avg batch time: 0.5005, average train loss: 5.4485
[09/26 05:37:06 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1672, average loss: 5.9152
[09/26 05:37:06 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 5.00	
[09/26 05:37:06 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.32898992833716567
[09/26 05:37:12 visual_prompt]: Epoch 66 / 100: avg data time: 4.65e-02, avg batch time: 0.4903, average train loss: 5.4602
[09/26 05:37:14 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1669, average loss: 5.9441
[09/26 05:37:14 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.00	
[09/26 05:37:14 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.31269670329204396
[09/26 05:37:21 visual_prompt]: Epoch 67 / 100: avg data time: 4.51e-02, avg batch time: 0.4891, average train loss: 5.4693
[09/26 05:37:22 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1672, average loss: 5.9742
[09/26 05:37:22 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 4.50	
[09/26 05:37:22 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.2966316784621
[09/26 05:37:29 visual_prompt]: Epoch 68 / 100: avg data time: 4.66e-02, avg batch time: 0.4910, average train loss: 5.4851
[09/26 05:37:31 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1672, average loss: 5.9214
[09/26 05:37:31 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 5.00	
[09/26 05:37:31 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.28081442660546124
[09/26 05:37:38 visual_prompt]: Epoch 69 / 100: avg data time: 6.58e-02, avg batch time: 0.5103, average train loss: 5.4729
[09/26 05:37:39 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1673, average loss: 5.9439
[09/26 05:37:39 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 05:37:39 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.26526421860705474
[09/26 05:37:46 visual_prompt]: Epoch 70 / 100: avg data time: 4.87e-02, avg batch time: 0.4926, average train loss: 5.4774
[09/26 05:37:47 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1678, average loss: 5.9397
[09/26 05:37:47 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 5.00	
[09/26 05:37:47 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.2500000000000001
[09/26 05:37:54 visual_prompt]: Epoch 71 / 100: avg data time: 6.11e-02, avg batch time: 0.5052, average train loss: 5.4666
[09/26 05:37:56 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1676, average loss: 5.9371
[09/26 05:37:56 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 5.00	
[09/26 05:37:56 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.2350403678833976
[09/26 05:38:03 visual_prompt]: Epoch 72 / 100: avg data time: 6.70e-02, avg batch time: 0.5102, average train loss: 5.4676
[09/26 05:38:04 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1675, average loss: 5.9593
[09/26 05:38:04 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 05:38:04 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.22040354826462666
[09/26 05:38:11 visual_prompt]: Epoch 73 / 100: avg data time: 6.13e-02, avg batch time: 0.5040, average train loss: 5.4688
[09/26 05:38:13 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1674, average loss: 5.9284
[09/26 05:38:13 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 5.00	
[09/26 05:38:13 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.2061073738537635
[09/26 05:38:20 visual_prompt]: Epoch 74 / 100: avg data time: 7.27e-02, avg batch time: 0.5159, average train loss: 5.4622
[09/26 05:38:22 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1677, average loss: 5.9357
[09/26 05:38:22 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 05:38:22 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.19216926233717085
[09/26 05:38:29 visual_prompt]: Epoch 75 / 100: avg data time: 6.97e-02, avg batch time: 0.5123, average train loss: 5.4570
[09/26 05:38:30 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1674, average loss: 5.9479
[09/26 05:38:30 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 5.00	
[09/26 05:38:30 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.17860619515673032
[09/26 05:38:37 visual_prompt]: Epoch 76 / 100: avg data time: 6.62e-02, avg batch time: 0.5095, average train loss: 5.4627
[09/26 05:38:39 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1678, average loss: 5.9322
[09/26 05:38:39 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 5.00	
[09/26 05:38:39 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.16543469682057105
[09/26 05:38:46 visual_prompt]: Epoch 77 / 100: avg data time: 6.15e-02, avg batch time: 0.5054, average train loss: 5.4493
[09/26 05:38:47 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1679, average loss: 5.9443
[09/26 05:38:47 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 05:38:47 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.15267081477050132
[09/26 05:38:54 visual_prompt]: Epoch 78 / 100: avg data time: 6.34e-02, avg batch time: 0.5059, average train loss: 5.4522
[09/26 05:38:56 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1673, average loss: 5.9238
[09/26 05:38:56 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 5.00	
[09/26 05:38:56 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.14033009983067452
[09/26 05:39:02 visual_prompt]: Epoch 79 / 100: avg data time: 6.19e-02, avg batch time: 0.5044, average train loss: 5.4539
[09/26 05:39:04 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1675, average loss: 5.9103
[09/26 05:39:04 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 5.00	
[09/26 05:39:04 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.12842758726130282
[09/26 05:39:11 visual_prompt]: Epoch 80 / 100: avg data time: 5.08e-02, avg batch time: 0.4952, average train loss: 5.4518
[09/26 05:39:12 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1677, average loss: 5.9374
[09/26 05:39:12 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 4.50	
[09/26 05:39:12 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.11697777844051105
[09/26 05:39:19 visual_prompt]: Epoch 81 / 100: avg data time: 5.84e-02, avg batch time: 0.5011, average train loss: 5.4397
[09/26 05:39:21 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1673, average loss: 5.9284
[09/26 05:39:21 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.50	
[09/26 05:39:21 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.10599462319663905
[09/26 05:39:28 visual_prompt]: Epoch 82 / 100: avg data time: 6.01e-02, avg batch time: 0.5043, average train loss: 5.4583
[09/26 05:39:29 visual_prompt]: Inference (val):avg data time: 3.62e-05, avg batch time: 0.1675, average loss: 5.9262
[09/26 05:39:29 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 5.50	
[09/26 05:39:29 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.09549150281252633
[09/26 05:39:36 visual_prompt]: Epoch 83 / 100: avg data time: 5.86e-02, avg batch time: 0.5022, average train loss: 5.4317
[09/26 05:39:38 visual_prompt]: Inference (val):avg data time: 3.87e-05, avg batch time: 0.1676, average loss: 5.9151
[09/26 05:39:38 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.00	
[09/26 05:39:38 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.08548121372247919
[09/26 05:39:45 visual_prompt]: Epoch 84 / 100: avg data time: 5.61e-02, avg batch time: 0.4996, average train loss: 5.4514
[09/26 05:39:46 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1672, average loss: 5.9349
[09/26 05:39:46 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 05:39:46 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.07597595192178702
[09/26 05:39:53 visual_prompt]: Epoch 85 / 100: avg data time: 5.91e-02, avg batch time: 0.5027, average train loss: 5.4401
[09/26 05:39:55 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1668, average loss: 5.9357
[09/26 05:39:55 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 5.00	
[09/26 05:39:55 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.06698729810778065
[09/26 05:40:02 visual_prompt]: Epoch 86 / 100: avg data time: 6.01e-02, avg batch time: 0.5024, average train loss: 5.4453
[09/26 05:40:03 visual_prompt]: Inference (val):avg data time: 1.95e-05, avg batch time: 0.1671, average loss: 5.8767
[09/26 05:40:03 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.00	top5: 5.50	
[09/26 05:40:03 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.058526203570536506
[09/26 05:40:10 visual_prompt]: Epoch 87 / 100: avg data time: 5.82e-02, avg batch time: 0.5023, average train loss: 5.4094
[09/26 05:40:12 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1674, average loss: 5.9071
[09/26 05:40:12 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 6.00	
[09/26 05:40:12 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.05060297685041659
[09/26 05:40:18 visual_prompt]: Epoch 88 / 100: avg data time: 6.42e-02, avg batch time: 0.5070, average train loss: 5.3906
[09/26 05:40:20 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1680, average loss: 5.8489
[09/26 05:40:20 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 7.50	
[09/26 05:40:20 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.04322727117869951
[09/26 05:40:27 visual_prompt]: Epoch 89 / 100: avg data time: 5.86e-02, avg batch time: 0.5016, average train loss: 5.3197
[09/26 05:40:29 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1673, average loss: 5.9134
[09/26 05:40:29 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 5.50	
[09/26 05:40:29 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.03640807271660634
[09/26 05:40:35 visual_prompt]: Epoch 90 / 100: avg data time: 6.43e-02, avg batch time: 0.5078, average train loss: 5.2905
[09/26 05:40:37 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1670, average loss: 5.8006
[09/26 05:40:37 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.00	top5: 8.50	
[09/26 05:40:37 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.03015368960704584
[09/26 05:40:44 visual_prompt]: Epoch 91 / 100: avg data time: 5.74e-02, avg batch time: 0.5016, average train loss: 5.2109
[09/26 05:40:45 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1674, average loss: 5.8495
[09/26 05:40:45 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 8.00	
[09/26 05:40:45 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.024471741852423234
[09/26 05:40:52 visual_prompt]: Epoch 92 / 100: avg data time: 6.05e-02, avg batch time: 0.5039, average train loss: 5.1829
[09/26 05:40:54 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1676, average loss: 5.8708
[09/26 05:40:54 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.00	top5: 7.50	
[09/26 05:40:54 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.019369152030840553
[09/26 05:41:01 visual_prompt]: Epoch 93 / 100: avg data time: 6.08e-02, avg batch time: 0.5044, average train loss: 5.1354
[09/26 05:41:02 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1672, average loss: 5.7376
[09/26 05:41:02 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.00	top5: 8.00	
[09/26 05:41:02 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.014852136862001764
[09/26 05:41:09 visual_prompt]: Epoch 94 / 100: avg data time: 6.38e-02, avg batch time: 0.5067, average train loss: 5.0899
[09/26 05:41:11 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1670, average loss: 5.7260
[09/26 05:41:11 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.00	top5: 7.50	
[09/26 05:41:11 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.010926199633097156
[09/26 05:41:18 visual_prompt]: Epoch 95 / 100: avg data time: 6.05e-02, avg batch time: 0.5035, average train loss: 5.0605
[09/26 05:41:19 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1673, average loss: 5.7451
[09/26 05:41:19 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.00	top5: 8.00	
[09/26 05:41:19 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.00759612349389599
[09/26 05:41:26 visual_prompt]: Epoch 96 / 100: avg data time: 5.76e-02, avg batch time: 0.4995, average train loss: 5.0445
[09/26 05:41:28 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1669, average loss: 5.7262
[09/26 05:41:28 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.00	top5: 7.00	
[09/26 05:41:28 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.004865965629214819
[09/26 05:41:35 visual_prompt]: Epoch 97 / 100: avg data time: 6.22e-02, avg batch time: 0.5060, average train loss: 5.0192
[09/26 05:41:36 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1672, average loss: 5.7036
[09/26 05:41:36 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.00	top5: 8.00	
[09/26 05:41:36 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.002739052315863355
[09/26 05:41:43 visual_prompt]: Epoch 98 / 100: avg data time: 5.74e-02, avg batch time: 0.5002, average train loss: 5.0098
[09/26 05:41:45 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1669, average loss: 5.7060
[09/26 05:41:45 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.00	top5: 8.00	
[09/26 05:41:45 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.0012179748700879012
[09/26 05:41:52 visual_prompt]: Epoch 99 / 100: avg data time: 5.74e-02, avg batch time: 0.5007, average train loss: 5.0005
[09/26 05:41:53 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1669, average loss: 5.7045
[09/26 05:41:53 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.00	top5: 8.00	
[09/26 05:41:53 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.00030458649045211894
[09/26 05:42:00 visual_prompt]: Epoch 100 / 100: avg data time: 6.04e-02, avg batch time: 0.5038, average train loss: 4.9957
[09/26 05:42:02 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1669, average loss: 5.7034
[09/26 05:42:02 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.00	top5: 8.00	
[09/26 05:42:02 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 05:42:02 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              0
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 05:42:02 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-sun397', 'DATA.NUMBER_CLASSES', '397', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 05:42:02 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 05:42:02 visual_prompt]: Training with config:
[09/26 05:42:02 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-sun397/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr1.0_wd0.001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 1.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-sun397', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 397, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 05:42:02 visual_prompt]: Loading training data...
[09/26 05:42:02 visual_prompt]: Constructing vtab-sun397 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split train[:800], from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/26 05:42:03 visual_prompt]: Number of images: 800
[09/26 05:42:03 visual_prompt]: Number of classes: 309 / 397
[09/26 05:42:03 visual_prompt]: Loading validation data...
[09/26 05:42:03 visual_prompt]: Constructing vtab-sun397 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split validation[:200], from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/26 05:42:04 visual_prompt]: Number of images: 200
[09/26 05:42:04 visual_prompt]: Number of classes: 136 / 397
[09/26 05:42:04 visual_prompt]: Constructing models...
[09/26 05:42:06 visual_prompt]: Total Parameters: 86564749	 Gradient Parameters: 766093
[09/26 05:42:06 visual_prompt]: tuned percent:0.885
[09/26 05:42:06 visual_prompt]: Device used for model: 0
[09/26 05:42:06 visual_prompt]: Setting up Evaluator...
[09/26 05:42:06 visual_prompt]: Setting up Trainer...
[09/26 05:42:06 visual_prompt]: 	Setting up the optimizer...
[09/26 05:42:06 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 05:42:13 visual_prompt]: Epoch 1 / 100: avg data time: 6.20e-02, avg batch time: 0.5063, average train loss: 5.9876
[09/26 05:42:15 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1667, average loss: 6.0097
[09/26 05:42:15 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/26 05:42:15 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.1
[09/26 05:42:21 visual_prompt]: Epoch 2 / 100: avg data time: 6.07e-02, avg batch time: 0.5034, average train loss: 5.8750
[09/26 05:42:23 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1680, average loss: 5.8780
[09/26 05:42:23 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 05:42:23 visual_prompt]: Best epoch 2: best metric: 0.005
[09/26 05:42:23 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.2
[09/26 05:42:30 visual_prompt]: Epoch 3 / 100: avg data time: 6.28e-02, avg batch time: 0.5060, average train loss: 5.6682
[09/26 05:42:32 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1676, average loss: 5.7861
[09/26 05:42:32 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 5.00	
[09/26 05:42:32 visual_prompt]: Best epoch 3: best metric: 0.010
[09/26 05:42:32 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.3
[09/26 05:42:39 visual_prompt]: Epoch 4 / 100: avg data time: 6.53e-02, avg batch time: 0.5082, average train loss: 5.4632
[09/26 05:42:40 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1672, average loss: 5.6614
[09/26 05:42:40 visual_prompt]: Classification results with val_vtab-sun397: top1: 3.50	top5: 9.50	
[09/26 05:42:40 visual_prompt]: Best epoch 4: best metric: 0.035
[09/26 05:42:40 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.4
[09/26 05:42:47 visual_prompt]: Epoch 5 / 100: avg data time: 6.25e-02, avg batch time: 0.5047, average train loss: 5.0740
[09/26 05:42:49 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1670, average loss: 5.2335
[09/26 05:42:49 visual_prompt]: Classification results with val_vtab-sun397: top1: 4.50	top5: 15.50	
[09/26 05:42:49 visual_prompt]: Best epoch 5: best metric: 0.045
[09/26 05:42:49 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.5
[09/26 05:42:56 visual_prompt]: Epoch 6 / 100: avg data time: 6.29e-02, avg batch time: 0.5050, average train loss: 4.4240
[09/26 05:42:57 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1675, average loss: 4.8442
[09/26 05:42:57 visual_prompt]: Classification results with val_vtab-sun397: top1: 12.00	top5: 28.50	
[09/26 05:42:57 visual_prompt]: Best epoch 6: best metric: 0.120
[09/26 05:42:57 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.6
[09/26 05:43:04 visual_prompt]: Epoch 7 / 100: avg data time: 6.57e-02, avg batch time: 0.5087, average train loss: 3.3799
[09/26 05:43:06 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1670, average loss: 4.0928
[09/26 05:43:06 visual_prompt]: Classification results with val_vtab-sun397: top1: 19.00	top5: 44.50	
[09/26 05:43:06 visual_prompt]: Best epoch 7: best metric: 0.190
[09/26 05:43:06 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.7
[09/26 05:43:12 visual_prompt]: Epoch 8 / 100: avg data time: 5.21e-02, avg batch time: 0.4962, average train loss: 2.0370
[09/26 05:43:14 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1670, average loss: 3.4353
[09/26 05:43:14 visual_prompt]: Classification results with val_vtab-sun397: top1: 36.00	top5: 59.00	
[09/26 05:43:14 visual_prompt]: Best epoch 8: best metric: 0.360
[09/26 05:43:14 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.8
[09/26 05:43:21 visual_prompt]: Epoch 9 / 100: avg data time: 5.36e-02, avg batch time: 0.4976, average train loss: 0.9239
[09/26 05:43:22 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1676, average loss: 3.1604
[09/26 05:43:22 visual_prompt]: Classification results with val_vtab-sun397: top1: 40.00	top5: 61.50	
[09/26 05:43:22 visual_prompt]: Best epoch 9: best metric: 0.400
[09/26 05:43:23 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.9
[09/26 05:43:29 visual_prompt]: Epoch 10 / 100: avg data time: 5.87e-02, avg batch time: 0.5027, average train loss: 0.3367
[09/26 05:43:31 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1677, average loss: 2.9789
[09/26 05:43:31 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.00	top5: 66.50	
[09/26 05:43:31 visual_prompt]: Best epoch 10: best metric: 0.410
[09/26 05:43:31 visual_prompt]: Training 11 / 100 epoch, with learning rate 1.0
[09/26 05:43:38 visual_prompt]: Epoch 11 / 100: avg data time: 6.17e-02, avg batch time: 0.5054, average train loss: 0.1714
[09/26 05:43:40 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1677, average loss: 3.0129
[09/26 05:43:40 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 67.00	
[09/26 05:43:40 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.9996954135095479
[09/26 05:43:46 visual_prompt]: Epoch 12 / 100: avg data time: 6.47e-02, avg batch time: 0.5070, average train loss: 0.1359
[09/26 05:43:48 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1679, average loss: 3.0086
[09/26 05:43:48 visual_prompt]: Classification results with val_vtab-sun397: top1: 40.00	top5: 67.00	
[09/26 05:43:48 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.9987820251299121
[09/26 05:43:55 visual_prompt]: Epoch 13 / 100: avg data time: 6.30e-02, avg batch time: 0.5054, average train loss: 0.1320
[09/26 05:43:57 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.1676, average loss: 2.9791
[09/26 05:43:57 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.50	top5: 69.00	
[09/26 05:43:57 visual_prompt]: Best epoch 13: best metric: 0.425
[09/26 05:43:57 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.9972609476841366
[09/26 05:44:03 visual_prompt]: Epoch 14 / 100: avg data time: 5.86e-02, avg batch time: 0.5023, average train loss: 0.1514
[09/26 05:44:05 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1681, average loss: 3.0113
[09/26 05:44:05 visual_prompt]: Classification results with val_vtab-sun397: top1: 40.50	top5: 67.00	
[09/26 05:44:05 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.9951340343707852
[09/26 05:44:12 visual_prompt]: Epoch 15 / 100: avg data time: 5.68e-02, avg batch time: 0.5001, average train loss: 0.1580
[09/26 05:44:13 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1678, average loss: 3.0118
[09/26 05:44:13 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.00	top5: 67.00	
[09/26 05:44:13 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.9924038765061041
[09/26 05:44:20 visual_prompt]: Epoch 16 / 100: avg data time: 5.89e-02, avg batch time: 0.5023, average train loss: 0.1665
[09/26 05:44:22 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1680, average loss: 3.0461
[09/26 05:44:22 visual_prompt]: Classification results with val_vtab-sun397: top1: 44.00	top5: 66.00	
[09/26 05:44:22 visual_prompt]: Best epoch 16: best metric: 0.440
[09/26 05:44:22 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.9890738003669028
[09/26 05:44:29 visual_prompt]: Epoch 17 / 100: avg data time: 5.97e-02, avg batch time: 0.5043, average train loss: 0.1951
[09/26 05:44:30 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1677, average loss: 3.1611
[09/26 05:44:30 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.00	top5: 65.50	
[09/26 05:44:30 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.9851478631379982
[09/26 05:44:37 visual_prompt]: Epoch 18 / 100: avg data time: 5.88e-02, avg batch time: 0.5016, average train loss: 0.2045
[09/26 05:44:39 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1681, average loss: 3.0909
[09/26 05:44:39 visual_prompt]: Classification results with val_vtab-sun397: top1: 40.00	top5: 69.50	
[09/26 05:44:39 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.9806308479691594
[09/26 05:44:46 visual_prompt]: Epoch 19 / 100: avg data time: 6.02e-02, avg batch time: 0.5039, average train loss: 0.1970
[09/26 05:44:47 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1679, average loss: 3.0538
[09/26 05:44:47 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.50	top5: 69.00	
[09/26 05:44:47 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.9755282581475768
[09/26 05:44:54 visual_prompt]: Epoch 20 / 100: avg data time: 6.63e-02, avg batch time: 0.5101, average train loss: 0.1945
[09/26 05:44:56 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1676, average loss: 2.9954
[09/26 05:44:56 visual_prompt]: Classification results with val_vtab-sun397: top1: 43.00	top5: 70.00	
[09/26 05:44:56 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.9698463103929542
[09/26 05:45:03 visual_prompt]: Epoch 21 / 100: avg data time: 6.17e-02, avg batch time: 0.5059, average train loss: 0.1638
[09/26 05:45:04 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1673, average loss: 2.9980
[09/26 05:45:04 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.00	top5: 70.50	
[09/26 05:45:04 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.9635919272833937
[09/26 05:45:11 visual_prompt]: Epoch 22 / 100: avg data time: 5.83e-02, avg batch time: 0.5021, average train loss: 0.1419
[09/26 05:45:13 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1680, average loss: 3.0228
[09/26 05:45:13 visual_prompt]: Classification results with val_vtab-sun397: top1: 36.00	top5: 71.00	
[09/26 05:45:13 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.9567727288213004
[09/26 05:45:19 visual_prompt]: Epoch 23 / 100: avg data time: 5.76e-02, avg batch time: 0.4997, average train loss: 0.1301
[09/26 05:45:21 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1676, average loss: 3.0509
[09/26 05:45:21 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.50	top5: 71.50	
[09/26 05:45:21 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.9493970231495835
[09/26 05:45:28 visual_prompt]: Epoch 24 / 100: avg data time: 4.74e-02, avg batch time: 0.4936, average train loss: 0.1333
[09/26 05:45:29 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1672, average loss: 3.0615
[09/26 05:45:29 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 71.00	
[09/26 05:45:29 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.9414737964294635
[09/26 05:45:36 visual_prompt]: Epoch 25 / 100: avg data time: 5.87e-02, avg batch time: 0.5025, average train loss: 0.1406
[09/26 05:45:38 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1679, average loss: 3.0084
[09/26 05:45:38 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.00	top5: 70.00	
[09/26 05:45:38 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.9330127018922194
[09/26 05:45:45 visual_prompt]: Epoch 26 / 100: avg data time: 5.63e-02, avg batch time: 0.4993, average train loss: 0.1381
[09/26 05:45:46 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1675, average loss: 3.0591
[09/26 05:45:46 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 71.50	
[09/26 05:45:46 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.9240240480782129
[09/26 05:45:53 visual_prompt]: Epoch 27 / 100: avg data time: 4.98e-02, avg batch time: 0.4961, average train loss: 0.1455
[09/26 05:45:55 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1678, average loss: 3.0168
[09/26 05:45:55 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.50	top5: 73.00	
[09/26 05:45:55 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.9145187862775208
[09/26 05:46:02 visual_prompt]: Epoch 28 / 100: avg data time: 6.43e-02, avg batch time: 0.5079, average train loss: 0.1564
[09/26 05:46:03 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1678, average loss: 3.0512
[09/26 05:46:03 visual_prompt]: Classification results with val_vtab-sun397: top1: 40.50	top5: 69.50	
[09/26 05:46:03 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.9045084971874737
[09/26 05:46:10 visual_prompt]: Epoch 29 / 100: avg data time: 6.22e-02, avg batch time: 0.5050, average train loss: 0.1936
[09/26 05:46:12 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1675, average loss: 3.0570
[09/26 05:46:12 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.00	top5: 70.50	
[09/26 05:46:12 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.8940053768033609
[09/26 05:46:18 visual_prompt]: Epoch 30 / 100: avg data time: 4.78e-02, avg batch time: 0.4909, average train loss: 0.2542
[09/26 05:46:20 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1680, average loss: 3.1963
[09/26 05:46:20 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.00	top5: 68.00	
[09/26 05:46:20 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.883022221559489
[09/26 05:46:27 visual_prompt]: Epoch 31 / 100: avg data time: 5.91e-02, avg batch time: 0.5024, average train loss: 0.2324
[09/26 05:46:29 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1677, average loss: 2.9875
[09/26 05:46:29 visual_prompt]: Classification results with val_vtab-sun397: top1: 40.50	top5: 71.50	
[09/26 05:46:29 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.8715724127386971
[09/26 05:46:35 visual_prompt]: Epoch 32 / 100: avg data time: 5.59e-02, avg batch time: 0.4986, average train loss: 0.1535
[09/26 05:46:37 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1676, average loss: 2.9668
[09/26 05:46:37 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.00	top5: 72.00	
[09/26 05:46:37 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.8596699001693255
[09/26 05:46:44 visual_prompt]: Epoch 33 / 100: avg data time: 5.88e-02, avg batch time: 0.5026, average train loss: 0.1181
[09/26 05:46:45 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1676, average loss: 2.9272
[09/26 05:46:45 visual_prompt]: Classification results with val_vtab-sun397: top1: 40.50	top5: 73.50	
[09/26 05:46:45 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.8473291852294986
[09/26 05:46:52 visual_prompt]: Epoch 34 / 100: avg data time: 5.94e-02, avg batch time: 0.5027, average train loss: 0.1081
[09/26 05:46:54 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1678, average loss: 2.9652
[09/26 05:46:54 visual_prompt]: Classification results with val_vtab-sun397: top1: 40.50	top5: 69.50	
[09/26 05:46:54 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.8345653031794291
[09/26 05:47:01 visual_prompt]: Epoch 35 / 100: avg data time: 6.23e-02, avg batch time: 0.5060, average train loss: 0.1057
[09/26 05:47:02 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1675, average loss: 2.9499
[09/26 05:47:03 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.00	top5: 74.00	
[09/26 05:47:03 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.8213938048432696
[09/26 05:47:09 visual_prompt]: Epoch 36 / 100: avg data time: 6.10e-02, avg batch time: 0.5033, average train loss: 0.1105
[09/26 05:47:11 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1675, average loss: 2.9864
[09/26 05:47:11 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.50	top5: 73.50	
[09/26 05:47:11 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.8078307376628291
[09/26 05:47:18 visual_prompt]: Epoch 37 / 100: avg data time: 5.46e-02, avg batch time: 0.4982, average train loss: 0.1159
[09/26 05:47:19 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1676, average loss: 3.0194
[09/26 05:47:19 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.00	top5: 72.50	
[09/26 05:47:19 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.7938926261462366
[09/26 05:47:26 visual_prompt]: Epoch 38 / 100: avg data time: 5.97e-02, avg batch time: 0.5022, average train loss: 0.1206
[09/26 05:47:28 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1680, average loss: 3.0322
[09/26 05:47:28 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.00	top5: 73.00	
[09/26 05:47:28 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.7795964517353734
[09/26 05:47:35 visual_prompt]: Epoch 39 / 100: avg data time: 6.31e-02, avg batch time: 0.5065, average train loss: 0.1295
[09/26 05:47:36 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1676, average loss: 3.0514
[09/26 05:47:36 visual_prompt]: Classification results with val_vtab-sun397: top1: 40.00	top5: 74.00	
[09/26 05:47:36 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.7649596321166025
[09/26 05:47:43 visual_prompt]: Epoch 40 / 100: avg data time: 5.43e-02, avg batch time: 0.4968, average train loss: 0.1351
[09/26 05:47:45 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1678, average loss: 3.0438
[09/26 05:47:45 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.50	top5: 72.00	
[09/26 05:47:45 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.75
[09/26 05:47:52 visual_prompt]: Epoch 41 / 100: avg data time: 6.39e-02, avg batch time: 0.5095, average train loss: 0.1467
[09/26 05:47:53 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1675, average loss: 3.1353
[09/26 05:47:53 visual_prompt]: Classification results with val_vtab-sun397: top1: 40.00	top5: 70.50	
[09/26 05:47:53 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.7347357813929454
[09/26 05:48:00 visual_prompt]: Epoch 42 / 100: avg data time: 5.45e-02, avg batch time: 0.4976, average train loss: 0.1831
[09/26 05:48:02 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1678, average loss: 3.0450
[09/26 05:48:02 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.00	top5: 71.50	
[09/26 05:48:02 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.7191855733945387
[09/26 05:48:09 visual_prompt]: Epoch 43 / 100: avg data time: 4.58e-02, avg batch time: 0.4908, average train loss: 2.0704
[09/26 05:48:10 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1678, average loss: 5.0515
[09/26 05:48:10 visual_prompt]: Classification results with val_vtab-sun397: top1: 11.50	top5: 30.00	
[09/26 05:48:10 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.7033683215379002
[09/26 05:48:17 visual_prompt]: Epoch 44 / 100: avg data time: 5.92e-02, avg batch time: 0.5023, average train loss: 2.3686
[09/26 05:48:19 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1676, average loss: 3.0726
[09/26 05:48:19 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.50	top5: 68.00	
[09/26 05:48:19 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.6873032967079561
[09/26 05:48:26 visual_prompt]: Epoch 45 / 100: avg data time: 5.94e-02, avg batch time: 0.5028, average train loss: 0.5249
[09/26 05:48:27 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1675, average loss: 2.8726
[09/26 05:48:27 visual_prompt]: Classification results with val_vtab-sun397: top1: 44.00	top5: 73.00	
[09/26 05:48:27 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.6710100716628344
[09/26 05:48:34 visual_prompt]: Epoch 46 / 100: avg data time: 5.25e-02, avg batch time: 0.4960, average train loss: 0.2165
[09/26 05:48:35 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1675, average loss: 2.8154
[09/26 05:48:35 visual_prompt]: Classification results with val_vtab-sun397: top1: 44.50	top5: 73.50	
[09/26 05:48:35 visual_prompt]: Best epoch 46: best metric: 0.445
[09/26 05:48:35 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.6545084971874737
[09/26 05:48:42 visual_prompt]: Epoch 47 / 100: avg data time: 6.31e-02, avg batch time: 0.5063, average train loss: 0.1389
[09/26 05:48:44 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1678, average loss: 2.8072
[09/26 05:48:44 visual_prompt]: Classification results with val_vtab-sun397: top1: 43.50	top5: 72.50	
[09/26 05:48:44 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.6378186779084996
[09/26 05:48:51 visual_prompt]: Epoch 48 / 100: avg data time: 5.67e-02, avg batch time: 0.5005, average train loss: 0.1192
[09/26 05:48:53 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1682, average loss: 2.8210
[09/26 05:48:53 visual_prompt]: Classification results with val_vtab-sun397: top1: 45.50	top5: 75.00	
[09/26 05:48:53 visual_prompt]: Best epoch 48: best metric: 0.455
[09/26 05:48:53 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.6209609477998338
[09/26 05:48:59 visual_prompt]: Epoch 49 / 100: avg data time: 6.10e-02, avg batch time: 0.5048, average train loss: 0.1162
[09/26 05:49:01 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1679, average loss: 2.8261
[09/26 05:49:01 visual_prompt]: Classification results with val_vtab-sun397: top1: 43.00	top5: 73.00	
[09/26 05:49:01 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.6039558454088796
[09/26 05:49:08 visual_prompt]: Epoch 50 / 100: avg data time: 6.12e-02, avg batch time: 0.5044, average train loss: 0.1220
[09/26 05:49:10 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1677, average loss: 2.8404
[09/26 05:49:10 visual_prompt]: Classification results with val_vtab-sun397: top1: 43.50	top5: 74.00	
[09/26 05:49:10 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.5868240888334653
[09/26 05:49:16 visual_prompt]: Epoch 51 / 100: avg data time: 5.65e-02, avg batch time: 0.4991, average train loss: 0.1284
[09/26 05:49:18 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1671, average loss: 2.8743
[09/26 05:49:18 visual_prompt]: Classification results with val_vtab-sun397: top1: 44.50	top5: 74.50	
[09/26 05:49:18 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.5695865504800327
[09/26 05:49:25 visual_prompt]: Epoch 52 / 100: avg data time: 5.71e-02, avg batch time: 0.5005, average train loss: 0.1353
[09/26 05:49:26 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1674, average loss: 2.8758
[09/26 05:49:26 visual_prompt]: Classification results with val_vtab-sun397: top1: 44.50	top5: 73.50	
[09/26 05:49:26 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.5522642316338268
[09/26 05:49:33 visual_prompt]: Epoch 53 / 100: avg data time: 6.33e-02, avg batch time: 0.5073, average train loss: 0.1394
[09/26 05:49:35 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1676, average loss: 2.8973
[09/26 05:49:35 visual_prompt]: Classification results with val_vtab-sun397: top1: 43.00	top5: 71.50	
[09/26 05:49:35 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.5348782368720626
[09/26 05:49:42 visual_prompt]: Epoch 54 / 100: avg data time: 6.05e-02, avg batch time: 0.5041, average train loss: 0.1339
[09/26 05:49:43 visual_prompt]: Inference (val):avg data time: 1.95e-05, avg batch time: 0.1675, average loss: 2.8594
[09/26 05:49:43 visual_prompt]: Classification results with val_vtab-sun397: top1: 46.00	top5: 73.00	
[09/26 05:49:43 visual_prompt]: Best epoch 54: best metric: 0.460
[09/26 05:49:43 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.5174497483512506
[09/26 05:49:50 visual_prompt]: Epoch 55 / 100: avg data time: 6.50e-02, avg batch time: 0.5084, average train loss: 0.1329
[09/26 05:49:52 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1678, average loss: 2.8769
[09/26 05:49:52 visual_prompt]: Classification results with val_vtab-sun397: top1: 45.50	top5: 73.50	
[09/26 05:49:52 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.5
[09/26 05:49:59 visual_prompt]: Epoch 56 / 100: avg data time: 5.87e-02, avg batch time: 0.5017, average train loss: 0.1261
[09/26 05:50:00 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.1677, average loss: 2.8921
[09/26 05:50:00 visual_prompt]: Classification results with val_vtab-sun397: top1: 44.00	top5: 73.00	
[09/26 05:50:00 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.48255025164874965
[09/26 05:50:07 visual_prompt]: Epoch 57 / 100: avg data time: 6.51e-02, avg batch time: 0.5088, average train loss: 0.1263
[09/26 05:50:09 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1677, average loss: 2.8922
[09/26 05:50:09 visual_prompt]: Classification results with val_vtab-sun397: top1: 46.00	top5: 74.00	
[09/26 05:50:09 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.46512176312793735
[09/26 05:50:16 visual_prompt]: Epoch 58 / 100: avg data time: 4.53e-02, avg batch time: 0.4905, average train loss: 0.1249
[09/26 05:50:17 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1674, average loss: 2.9050
[09/26 05:50:17 visual_prompt]: Classification results with val_vtab-sun397: top1: 44.50	top5: 73.00	
[09/26 05:50:17 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.44773576836617335
[09/26 05:50:24 visual_prompt]: Epoch 59 / 100: avg data time: 5.27e-02, avg batch time: 0.4974, average train loss: 0.1237
[09/26 05:50:26 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1676, average loss: 2.8890
[09/26 05:50:26 visual_prompt]: Classification results with val_vtab-sun397: top1: 43.50	top5: 74.00	
[09/26 05:50:26 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.4304134495199674
[09/26 05:50:32 visual_prompt]: Epoch 60 / 100: avg data time: 5.33e-02, avg batch time: 0.4978, average train loss: 0.1247
[09/26 05:50:34 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1677, average loss: 2.9194
[09/26 05:50:34 visual_prompt]: Classification results with val_vtab-sun397: top1: 47.00	top5: 74.50	
[09/26 05:50:34 visual_prompt]: Best epoch 60: best metric: 0.470
[09/26 05:50:34 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.41317591116653485
[09/26 05:50:41 visual_prompt]: Epoch 61 / 100: avg data time: 5.06e-02, avg batch time: 0.4954, average train loss: 0.1232
[09/26 05:50:42 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1677, average loss: 2.9400
[09/26 05:50:42 visual_prompt]: Classification results with val_vtab-sun397: top1: 45.00	top5: 74.00	
[09/26 05:50:42 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.3960441545911204
[09/26 05:50:49 visual_prompt]: Epoch 62 / 100: avg data time: 6.27e-02, avg batch time: 0.5054, average train loss: 0.1199
[09/26 05:50:51 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1681, average loss: 2.9241
[09/26 05:50:51 visual_prompt]: Classification results with val_vtab-sun397: top1: 44.50	top5: 72.00	
[09/26 05:50:51 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.3790390522001662
[09/26 05:50:58 visual_prompt]: Epoch 63 / 100: avg data time: 6.19e-02, avg batch time: 0.5050, average train loss: 0.1162
[09/26 05:50:59 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1677, average loss: 2.9198
[09/26 05:50:59 visual_prompt]: Classification results with val_vtab-sun397: top1: 45.50	top5: 72.50	
[09/26 05:50:59 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.36218132209150045
[09/26 05:51:06 visual_prompt]: Epoch 64 / 100: avg data time: 4.65e-02, avg batch time: 0.4924, average train loss: 0.1168
[09/26 05:51:08 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1680, average loss: 2.9127
[09/26 05:51:08 visual_prompt]: Classification results with val_vtab-sun397: top1: 47.50	top5: 72.50	
[09/26 05:51:08 visual_prompt]: Best epoch 64: best metric: 0.475
[09/26 05:51:08 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.34549150281252633
[09/26 05:51:15 visual_prompt]: Epoch 65 / 100: avg data time: 5.20e-02, avg batch time: 0.4959, average train loss: 0.1158
[09/26 05:51:16 visual_prompt]: Inference (val):avg data time: 4.09e-05, avg batch time: 0.1678, average loss: 2.9458
[09/26 05:51:16 visual_prompt]: Classification results with val_vtab-sun397: top1: 45.50	top5: 75.00	
[09/26 05:51:16 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.32898992833716567
[09/26 05:51:23 visual_prompt]: Epoch 66 / 100: avg data time: 5.78e-02, avg batch time: 0.5023, average train loss: 0.1140
[09/26 05:51:25 visual_prompt]: Inference (val):avg data time: 1.94e-05, avg batch time: 0.1674, average loss: 2.9402
[09/26 05:51:25 visual_prompt]: Classification results with val_vtab-sun397: top1: 45.50	top5: 73.50	
[09/26 05:51:25 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.31269670329204396
[09/26 05:51:32 visual_prompt]: Epoch 67 / 100: avg data time: 6.13e-02, avg batch time: 0.5056, average train loss: 0.1164
[09/26 05:51:33 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1669, average loss: 2.9498
[09/26 05:51:33 visual_prompt]: Classification results with val_vtab-sun397: top1: 45.50	top5: 73.00	
[09/26 05:51:33 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.2966316784621
[09/26 05:51:40 visual_prompt]: Epoch 68 / 100: avg data time: 6.18e-02, avg batch time: 0.5056, average train loss: 0.1142
[09/26 05:51:42 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1675, average loss: 2.9268
[09/26 05:51:42 visual_prompt]: Classification results with val_vtab-sun397: top1: 46.00	top5: 73.50	
[09/26 05:51:42 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.28081442660546124
[09/26 05:51:49 visual_prompt]: Epoch 69 / 100: avg data time: 6.05e-02, avg batch time: 0.5038, average train loss: 0.1133
[09/26 05:51:50 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1673, average loss: 2.9606
[09/26 05:51:50 visual_prompt]: Classification results with val_vtab-sun397: top1: 44.50	top5: 73.50	
[09/26 05:51:50 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.26526421860705474
[09/26 05:51:57 visual_prompt]: Epoch 70 / 100: avg data time: 5.35e-02, avg batch time: 0.4975, average train loss: 0.1138
[09/26 05:51:59 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1676, average loss: 2.9242
[09/26 05:51:59 visual_prompt]: Classification results with val_vtab-sun397: top1: 46.00	top5: 74.50	
[09/26 05:51:59 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.2500000000000001
[09/26 05:52:05 visual_prompt]: Epoch 71 / 100: avg data time: 5.81e-02, avg batch time: 0.5008, average train loss: 0.1137
[09/26 05:52:07 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1675, average loss: 2.9365
[09/26 05:52:07 visual_prompt]: Classification results with val_vtab-sun397: top1: 47.00	top5: 75.00	
[09/26 05:52:07 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.2350403678833976
[09/26 05:52:14 visual_prompt]: Epoch 72 / 100: avg data time: 6.47e-02, avg batch time: 0.5076, average train loss: 0.1119
[09/26 05:52:16 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1672, average loss: 2.9275
[09/26 05:52:16 visual_prompt]: Classification results with val_vtab-sun397: top1: 45.50	top5: 75.00	
[09/26 05:52:16 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.22040354826462666
[09/26 05:52:23 visual_prompt]: Epoch 73 / 100: avg data time: 6.60e-02, avg batch time: 0.5096, average train loss: 0.1081
[09/26 05:52:24 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1671, average loss: 2.9676
[09/26 05:52:24 visual_prompt]: Classification results with val_vtab-sun397: top1: 45.00	top5: 73.50	
[09/26 05:52:24 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.2061073738537635
[09/26 05:52:31 visual_prompt]: Epoch 74 / 100: avg data time: 5.70e-02, avg batch time: 0.4999, average train loss: 0.1065
[09/26 05:52:33 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1675, average loss: 2.9500
[09/26 05:52:33 visual_prompt]: Classification results with val_vtab-sun397: top1: 44.00	top5: 74.00	
[09/26 05:52:33 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.19216926233717085
[09/26 05:52:39 visual_prompt]: Epoch 75 / 100: avg data time: 5.85e-02, avg batch time: 0.5018, average train loss: 0.1051
[09/26 05:52:41 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1679, average loss: 2.9682
[09/26 05:52:41 visual_prompt]: Classification results with val_vtab-sun397: top1: 45.00	top5: 74.00	
[09/26 05:52:41 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.17860619515673032
[09/26 05:52:48 visual_prompt]: Epoch 76 / 100: avg data time: 5.81e-02, avg batch time: 0.5017, average train loss: 0.1043
[09/26 05:52:50 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1675, average loss: 2.9616
[09/26 05:52:50 visual_prompt]: Classification results with val_vtab-sun397: top1: 47.50	top5: 74.50	
[09/26 05:52:50 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.16543469682057105
[09/26 05:52:56 visual_prompt]: Epoch 77 / 100: avg data time: 4.78e-02, avg batch time: 0.4922, average train loss: 0.1032
[09/26 05:52:58 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1682, average loss: 2.9703
[09/26 05:52:58 visual_prompt]: Classification results with val_vtab-sun397: top1: 45.50	top5: 74.00	
[09/26 05:52:58 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.15267081477050132
[09/26 05:53:05 visual_prompt]: Epoch 78 / 100: avg data time: 6.15e-02, avg batch time: 0.5060, average train loss: 0.1042
[09/26 05:53:06 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1679, average loss: 2.9858
[09/26 05:53:06 visual_prompt]: Classification results with val_vtab-sun397: top1: 47.00	top5: 74.00	
[09/26 05:53:06 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.14033009983067452
[09/26 05:53:13 visual_prompt]: Epoch 79 / 100: avg data time: 5.68e-02, avg batch time: 0.5000, average train loss: 0.1037
[09/26 05:53:15 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1678, average loss: 2.9921
[09/26 05:53:15 visual_prompt]: Classification results with val_vtab-sun397: top1: 44.50	top5: 74.00	
[09/26 05:53:15 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.12842758726130282
[09/26 05:53:22 visual_prompt]: Epoch 80 / 100: avg data time: 5.71e-02, avg batch time: 0.5021, average train loss: 0.1016
[09/26 05:53:23 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1678, average loss: 2.9889
[09/26 05:53:23 visual_prompt]: Classification results with val_vtab-sun397: top1: 44.50	top5: 74.50	
[09/26 05:53:23 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.11697777844051105
[09/26 05:53:30 visual_prompt]: Epoch 81 / 100: avg data time: 6.47e-02, avg batch time: 0.5075, average train loss: 0.1013
[09/26 05:53:32 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1679, average loss: 2.9795
[09/26 05:53:32 visual_prompt]: Classification results with val_vtab-sun397: top1: 44.50	top5: 74.00	
[09/26 05:53:32 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.10599462319663905
[09/26 05:53:39 visual_prompt]: Epoch 82 / 100: avg data time: 6.14e-02, avg batch time: 0.5040, average train loss: 0.1004
[09/26 05:53:40 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1677, average loss: 2.9950
[09/26 05:53:40 visual_prompt]: Classification results with val_vtab-sun397: top1: 45.00	top5: 73.50	
[09/26 05:53:40 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.09549150281252633
[09/26 05:53:47 visual_prompt]: Epoch 83 / 100: avg data time: 6.44e-02, avg batch time: 0.5079, average train loss: 0.0997
[09/26 05:53:49 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1676, average loss: 2.9798
[09/26 05:53:49 visual_prompt]: Classification results with val_vtab-sun397: top1: 47.00	top5: 73.50	
[09/26 05:53:49 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.08548121372247919
[09/26 05:53:56 visual_prompt]: Epoch 84 / 100: avg data time: 6.40e-02, avg batch time: 0.5077, average train loss: 0.0992
[09/26 05:53:57 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1672, average loss: 2.9658
[09/26 05:53:57 visual_prompt]: Classification results with val_vtab-sun397: top1: 45.00	top5: 73.50	
[09/26 05:53:57 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.07597595192178702
[09/26 05:54:04 visual_prompt]: Epoch 85 / 100: avg data time: 5.75e-02, avg batch time: 0.5004, average train loss: 0.0991
[09/26 05:54:06 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.1673, average loss: 2.9784
[09/26 05:54:06 visual_prompt]: Classification results with val_vtab-sun397: top1: 45.00	top5: 74.00	
[09/26 05:54:06 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.06698729810778065
[09/26 05:54:13 visual_prompt]: Epoch 86 / 100: avg data time: 5.41e-02, avg batch time: 0.4980, average train loss: 0.0985
[09/26 05:54:14 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1672, average loss: 2.9814
[09/26 05:54:14 visual_prompt]: Classification results with val_vtab-sun397: top1: 47.00	top5: 74.00	
[09/26 05:54:14 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.058526203570536506
[09/26 05:54:21 visual_prompt]: Epoch 87 / 100: avg data time: 5.95e-02, avg batch time: 0.5036, average train loss: 0.0982
[09/26 05:54:23 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1678, average loss: 2.9764
[09/26 05:54:23 visual_prompt]: Classification results with val_vtab-sun397: top1: 46.00	top5: 74.00	
[09/26 05:54:23 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.05060297685041659
[09/26 05:54:30 visual_prompt]: Epoch 88 / 100: avg data time: 6.00e-02, avg batch time: 0.5037, average train loss: 0.0974
[09/26 05:54:31 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1673, average loss: 2.9858
[09/26 05:54:31 visual_prompt]: Classification results with val_vtab-sun397: top1: 45.50	top5: 74.50	
[09/26 05:54:31 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.04322727117869951
[09/26 05:54:38 visual_prompt]: Epoch 89 / 100: avg data time: 5.60e-02, avg batch time: 0.4996, average train loss: 0.0973
[09/26 05:54:40 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1675, average loss: 2.9862
[09/26 05:54:40 visual_prompt]: Classification results with val_vtab-sun397: top1: 45.50	top5: 74.00	
[09/26 05:54:40 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.03640807271660634
[09/26 05:54:47 visual_prompt]: Epoch 90 / 100: avg data time: 6.03e-02, avg batch time: 0.5043, average train loss: 0.0971
[09/26 05:54:48 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1673, average loss: 2.9913
[09/26 05:54:48 visual_prompt]: Classification results with val_vtab-sun397: top1: 45.50	top5: 74.00	
[09/26 05:54:48 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.03015368960704584
[09/26 05:54:55 visual_prompt]: Epoch 91 / 100: avg data time: 5.51e-02, avg batch time: 0.4988, average train loss: 0.0972
[09/26 05:54:57 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1675, average loss: 2.9918
[09/26 05:54:57 visual_prompt]: Classification results with val_vtab-sun397: top1: 46.00	top5: 74.00	
[09/26 05:54:57 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.024471741852423234
[09/26 05:55:04 visual_prompt]: Epoch 92 / 100: avg data time: 6.18e-02, avg batch time: 0.5061, average train loss: 0.0971
[09/26 05:55:05 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1673, average loss: 2.9904
[09/26 05:55:05 visual_prompt]: Classification results with val_vtab-sun397: top1: 45.00	top5: 74.50	
[09/26 05:55:05 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.019369152030840553
[09/26 05:55:12 visual_prompt]: Epoch 93 / 100: avg data time: 5.95e-02, avg batch time: 0.5042, average train loss: 0.0968
[09/26 05:55:14 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1674, average loss: 2.9924
[09/26 05:55:14 visual_prompt]: Classification results with val_vtab-sun397: top1: 44.50	top5: 74.00	
[09/26 05:55:14 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.014852136862001764
[09/26 05:55:21 visual_prompt]: Epoch 94 / 100: avg data time: 6.27e-02, avg batch time: 0.5071, average train loss: 0.0968
[09/26 05:55:22 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1672, average loss: 2.9916
[09/26 05:55:22 visual_prompt]: Classification results with val_vtab-sun397: top1: 45.00	top5: 74.00	
[09/26 05:55:22 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.010926199633097156
[09/26 05:55:29 visual_prompt]: Epoch 95 / 100: avg data time: 5.21e-02, avg batch time: 0.4979, average train loss: 0.0967
[09/26 05:55:31 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1671, average loss: 2.9939
[09/26 05:55:31 visual_prompt]: Classification results with val_vtab-sun397: top1: 45.50	top5: 74.00	
[09/26 05:55:31 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.00759612349389599
[09/26 05:55:38 visual_prompt]: Epoch 96 / 100: avg data time: 6.27e-02, avg batch time: 0.5049, average train loss: 0.0965
[09/26 05:55:39 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1670, average loss: 2.9948
[09/26 05:55:39 visual_prompt]: Classification results with val_vtab-sun397: top1: 44.50	top5: 74.00	
[09/26 05:55:39 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.004865965629214819
[09/26 05:55:46 visual_prompt]: Epoch 97 / 100: avg data time: 5.97e-02, avg batch time: 0.5024, average train loss: 0.0963
[09/26 05:55:48 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.1673, average loss: 2.9956
[09/26 05:55:48 visual_prompt]: Classification results with val_vtab-sun397: top1: 44.00	top5: 74.00	
[09/26 05:55:48 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.002739052315863355
[09/26 05:55:55 visual_prompt]: Epoch 98 / 100: avg data time: 6.10e-02, avg batch time: 0.5047, average train loss: 0.0961
[09/26 05:55:56 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1672, average loss: 2.9963
[09/26 05:55:56 visual_prompt]: Classification results with val_vtab-sun397: top1: 44.50	top5: 74.00	
[09/26 05:55:56 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.0012179748700879012
[09/26 05:56:03 visual_prompt]: Epoch 99 / 100: avg data time: 6.04e-02, avg batch time: 0.5053, average train loss: 0.0963
[09/26 05:56:05 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1675, average loss: 2.9964
[09/26 05:56:05 visual_prompt]: Classification results with val_vtab-sun397: top1: 44.50	top5: 74.00	
[09/26 05:56:05 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.00030458649045211894
[09/26 05:56:12 visual_prompt]: Epoch 100 / 100: avg data time: 6.13e-02, avg batch time: 0.5041, average train loss: 0.0961
[09/26 05:56:13 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.1673, average loss: 2.9964
[09/26 05:56:13 visual_prompt]: Classification results with val_vtab-sun397: top1: 44.50	top5: 74.00	
[09/26 05:56:13 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 05:56:13 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              0
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 05:56:13 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-sun397', 'DATA.NUMBER_CLASSES', '397', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 05:56:13 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 05:56:13 visual_prompt]: Training with config:
[09/26 05:56:13 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-sun397/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr1.0_wd0.0001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 1.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-sun397', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 397, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 05:56:13 visual_prompt]: Loading training data...
[09/26 05:56:13 visual_prompt]: Constructing vtab-sun397 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split train[:800], from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/26 05:56:15 visual_prompt]: Number of images: 800
[09/26 05:56:15 visual_prompt]: Number of classes: 309 / 397
[09/26 05:56:15 visual_prompt]: Loading validation data...
[09/26 05:56:15 visual_prompt]: Constructing vtab-sun397 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split validation[:200], from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/26 05:56:15 visual_prompt]: Number of images: 200
[09/26 05:56:15 visual_prompt]: Number of classes: 136 / 397
[09/26 05:56:15 visual_prompt]: Constructing models...
[09/26 05:56:18 visual_prompt]: Total Parameters: 86564749	 Gradient Parameters: 766093
[09/26 05:56:18 visual_prompt]: tuned percent:0.885
[09/26 05:56:18 visual_prompt]: Device used for model: 0
[09/26 05:56:18 visual_prompt]: Setting up Evaluator...
[09/26 05:56:18 visual_prompt]: Setting up Trainer...
[09/26 05:56:18 visual_prompt]: 	Setting up the optimizer...
[09/26 05:56:18 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 05:56:25 visual_prompt]: Epoch 1 / 100: avg data time: 5.79e-02, avg batch time: 0.5038, average train loss: 5.9886
[09/26 05:56:26 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1666, average loss: 6.0097
[09/26 05:56:26 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/26 05:56:26 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.1
[09/26 05:56:33 visual_prompt]: Epoch 2 / 100: avg data time: 5.72e-02, avg batch time: 0.4998, average train loss: 5.8838
[09/26 05:56:35 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1669, average loss: 5.8493
[09/26 05:56:35 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 5.00	
[09/26 05:56:35 visual_prompt]: Best epoch 2: best metric: 0.005
[09/26 05:56:35 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.2
[09/26 05:56:41 visual_prompt]: Epoch 3 / 100: avg data time: 4.96e-02, avg batch time: 0.4955, average train loss: 5.6831
[09/26 05:56:43 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1669, average loss: 5.8308
[09/26 05:56:43 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 05:56:43 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.3
[09/26 05:56:50 visual_prompt]: Epoch 4 / 100: avg data time: 5.65e-02, avg batch time: 0.5002, average train loss: 5.5365
[09/26 05:56:51 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1671, average loss: 5.7544
[09/26 05:56:51 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 7.50	
[09/26 05:56:51 visual_prompt]: Best epoch 4: best metric: 0.010
[09/26 05:56:51 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.4
[09/26 05:56:58 visual_prompt]: Epoch 5 / 100: avg data time: 6.09e-02, avg batch time: 0.5037, average train loss: 5.2885
[09/26 05:57:00 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1671, average loss: 5.5287
[09/26 05:57:00 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.50	top5: 8.50	
[09/26 05:57:00 visual_prompt]: Best epoch 5: best metric: 0.025
[09/26 05:57:00 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.5
[09/26 05:57:07 visual_prompt]: Epoch 6 / 100: avg data time: 5.73e-02, avg batch time: 0.5015, average train loss: 4.6561
[09/26 05:57:08 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1670, average loss: 4.8307
[09/26 05:57:08 visual_prompt]: Classification results with val_vtab-sun397: top1: 12.50	top5: 28.00	
[09/26 05:57:08 visual_prompt]: Best epoch 6: best metric: 0.125
[09/26 05:57:08 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.6
[09/26 05:57:15 visual_prompt]: Epoch 7 / 100: avg data time: 6.41e-02, avg batch time: 0.5071, average train loss: 3.5679
[09/26 05:57:17 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1671, average loss: 4.3008
[09/26 05:57:17 visual_prompt]: Classification results with val_vtab-sun397: top1: 18.50	top5: 46.00	
[09/26 05:57:17 visual_prompt]: Best epoch 7: best metric: 0.185
[09/26 05:57:17 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.7
[09/26 05:57:24 visual_prompt]: Epoch 8 / 100: avg data time: 5.58e-02, avg batch time: 0.4988, average train loss: 2.1376
[09/26 05:57:25 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1673, average loss: 3.5622
[09/26 05:57:25 visual_prompt]: Classification results with val_vtab-sun397: top1: 34.00	top5: 55.50	
[09/26 05:57:25 visual_prompt]: Best epoch 8: best metric: 0.340
[09/26 05:57:25 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.8
[09/26 05:57:32 visual_prompt]: Epoch 9 / 100: avg data time: 6.26e-02, avg batch time: 0.5057, average train loss: 0.9459
[09/26 05:57:34 visual_prompt]: Inference (val):avg data time: 5.35e-05, avg batch time: 0.1673, average loss: 3.1482
[09/26 05:57:34 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 60.50	
[09/26 05:57:34 visual_prompt]: Best epoch 9: best metric: 0.390
[09/26 05:57:34 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.9
[09/26 05:57:41 visual_prompt]: Epoch 10 / 100: avg data time: 6.03e-02, avg batch time: 0.5032, average train loss: 0.2944
[09/26 05:57:42 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1677, average loss: 3.1434
[09/26 05:57:42 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.00	top5: 63.50	
[09/26 05:57:42 visual_prompt]: Training 11 / 100 epoch, with learning rate 1.0
[09/26 05:57:49 visual_prompt]: Epoch 11 / 100: avg data time: 5.28e-02, avg batch time: 0.4969, average train loss: 0.1048
[09/26 05:57:51 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1679, average loss: 3.0117
[09/26 05:57:51 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.50	top5: 67.50	
[09/26 05:57:51 visual_prompt]: Best epoch 11: best metric: 0.415
[09/26 05:57:51 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.9996954135095479
[09/26 05:57:58 visual_prompt]: Epoch 12 / 100: avg data time: 6.09e-02, avg batch time: 0.5048, average train loss: 0.0473
[09/26 05:57:59 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1678, average loss: 2.9827
[09/26 05:57:59 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.50	top5: 67.00	
[09/26 05:57:59 visual_prompt]: Best epoch 12: best metric: 0.425
[09/26 05:57:59 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.9987820251299121
[09/26 05:58:06 visual_prompt]: Epoch 13 / 100: avg data time: 6.19e-02, avg batch time: 0.5048, average train loss: 0.0317
[09/26 05:58:08 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1679, average loss: 2.9942
[09/26 05:58:08 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 67.00	
[09/26 05:58:08 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.9972609476841366
[09/26 05:58:15 visual_prompt]: Epoch 14 / 100: avg data time: 6.25e-02, avg batch time: 0.5068, average train loss: 0.0243
[09/26 05:58:16 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1678, average loss: 2.9835
[09/26 05:58:16 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.00	top5: 69.50	
[09/26 05:58:16 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.9951340343707852
[09/26 05:58:23 visual_prompt]: Epoch 15 / 100: avg data time: 6.25e-02, avg batch time: 0.5054, average train loss: 0.0202
[09/26 05:58:25 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.1677, average loss: 2.9641
[09/26 05:58:25 visual_prompt]: Classification results with val_vtab-sun397: top1: 40.50	top5: 70.00	
[09/26 05:58:25 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.9924038765061041
[09/26 05:58:32 visual_prompt]: Epoch 16 / 100: avg data time: 6.31e-02, avg batch time: 0.5060, average train loss: 0.0187
[09/26 05:58:33 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1680, average loss: 2.9596
[09/26 05:58:33 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.50	top5: 67.50	
[09/26 05:58:33 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.9890738003669028
[09/26 05:58:40 visual_prompt]: Epoch 17 / 100: avg data time: 5.10e-02, avg batch time: 0.4953, average train loss: 0.0176
[09/26 05:58:42 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.1680, average loss: 2.9684
[09/26 05:58:42 visual_prompt]: Classification results with val_vtab-sun397: top1: 40.50	top5: 67.00	
[09/26 05:58:42 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.9851478631379982
[09/26 05:58:49 visual_prompt]: Epoch 18 / 100: avg data time: 6.44e-02, avg batch time: 0.5089, average train loss: 0.0171
[09/26 05:58:50 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1675, average loss: 2.9674
[09/26 05:58:50 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.50	top5: 67.00	
[09/26 05:58:50 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.9806308479691594
[09/26 05:58:57 visual_prompt]: Epoch 19 / 100: avg data time: 6.26e-02, avg batch time: 0.5065, average train loss: 0.0168
[09/26 05:58:59 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1675, average loss: 2.9670
[09/26 05:58:59 visual_prompt]: Classification results with val_vtab-sun397: top1: 40.00	top5: 67.50	
[09/26 05:58:59 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.9755282581475768
[09/26 05:59:06 visual_prompt]: Epoch 20 / 100: avg data time: 6.06e-02, avg batch time: 0.5043, average train loss: 0.0165
[09/26 05:59:07 visual_prompt]: Inference (val):avg data time: 3.72e-05, avg batch time: 0.1675, average loss: 2.9646
[09/26 05:59:07 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 68.00	
[09/26 05:59:07 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.9698463103929542
[09/26 05:59:14 visual_prompt]: Epoch 21 / 100: avg data time: 5.90e-02, avg batch time: 0.5023, average train loss: 0.0165
[09/26 05:59:16 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1675, average loss: 2.9671
[09/26 05:59:16 visual_prompt]: Classification results with val_vtab-sun397: top1: 40.00	top5: 67.00	
[09/26 05:59:16 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.9635919272833937
[09/26 05:59:23 visual_prompt]: Epoch 22 / 100: avg data time: 5.94e-02, avg batch time: 0.5043, average train loss: 0.0164
[09/26 05:59:24 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1674, average loss: 2.9600
[09/26 05:59:24 visual_prompt]: Classification results with val_vtab-sun397: top1: 40.50	top5: 68.50	
[09/26 05:59:24 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.9567727288213004
[09/26 05:59:31 visual_prompt]: Epoch 23 / 100: avg data time: 5.56e-02, avg batch time: 0.4992, average train loss: 0.0162
[09/26 05:59:33 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1673, average loss: 2.9610
[09/26 05:59:33 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.00	top5: 68.50	
[09/26 05:59:33 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.9493970231495835
[09/26 05:59:40 visual_prompt]: Epoch 24 / 100: avg data time: 6.07e-02, avg batch time: 0.5043, average train loss: 0.0161
[09/26 05:59:41 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1671, average loss: 2.9653
[09/26 05:59:41 visual_prompt]: Classification results with val_vtab-sun397: top1: 40.50	top5: 68.50	
[09/26 05:59:41 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.9414737964294635
[09/26 05:59:48 visual_prompt]: Epoch 25 / 100: avg data time: 4.61e-02, avg batch time: 0.4931, average train loss: 0.0160
[09/26 05:59:50 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1671, average loss: 2.9651
[09/26 05:59:50 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.50	top5: 69.00	
[09/26 05:59:50 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.9330127018922194
[09/26 05:59:57 visual_prompt]: Epoch 26 / 100: avg data time: 6.21e-02, avg batch time: 0.5054, average train loss: 0.0159
[09/26 05:59:58 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1677, average loss: 2.9682
[09/26 05:59:58 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 69.00	
[09/26 05:59:58 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.9240240480782129
[09/26 06:00:05 visual_prompt]: Epoch 27 / 100: avg data time: 6.50e-02, avg batch time: 0.5086, average train loss: 0.0159
[09/26 06:00:07 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1674, average loss: 2.9606
[09/26 06:00:07 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 68.50	
[09/26 06:00:07 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.9145187862775208
[09/26 06:00:14 visual_prompt]: Epoch 28 / 100: avg data time: 6.07e-02, avg batch time: 0.5051, average train loss: 0.0159
[09/26 06:00:15 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1674, average loss: 2.9644
[09/26 06:00:15 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 68.00	
[09/26 06:00:15 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.9045084971874737
[09/26 06:00:22 visual_prompt]: Epoch 29 / 100: avg data time: 5.73e-02, avg batch time: 0.5014, average train loss: 0.0158
[09/26 06:00:24 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1675, average loss: 2.9732
[09/26 06:00:24 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 68.00	
[09/26 06:00:24 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.8940053768033609
[09/26 06:00:30 visual_prompt]: Epoch 30 / 100: avg data time: 5.85e-02, avg batch time: 0.5019, average train loss: 0.0158
[09/26 06:00:32 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1673, average loss: 2.9708
[09/26 06:00:32 visual_prompt]: Classification results with val_vtab-sun397: top1: 40.00	top5: 69.00	
[09/26 06:00:32 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.883022221559489
[09/26 06:00:39 visual_prompt]: Epoch 31 / 100: avg data time: 6.41e-02, avg batch time: 0.5068, average train loss: 0.0160
[09/26 06:00:41 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1675, average loss: 2.9688
[09/26 06:00:41 visual_prompt]: Classification results with val_vtab-sun397: top1: 40.00	top5: 68.00	
[09/26 06:00:41 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.8715724127386971
[09/26 06:00:47 visual_prompt]: Epoch 32 / 100: avg data time: 6.00e-02, avg batch time: 0.5034, average train loss: 0.0158
[09/26 06:00:49 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1674, average loss: 2.9705
[09/26 06:00:49 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.50	top5: 68.00	
[09/26 06:00:49 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.8596699001693255
[09/26 06:00:56 visual_prompt]: Epoch 33 / 100: avg data time: 6.21e-02, avg batch time: 0.5057, average train loss: 0.0156
[09/26 06:00:57 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1676, average loss: 2.9681
[09/26 06:00:57 visual_prompt]: Classification results with val_vtab-sun397: top1: 40.50	top5: 68.00	
[09/26 06:00:57 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.8473291852294986
[09/26 06:01:04 visual_prompt]: Epoch 34 / 100: avg data time: 5.98e-02, avg batch time: 0.5029, average train loss: 0.0157
[09/26 06:01:06 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1672, average loss: 2.9712
[09/26 06:01:06 visual_prompt]: Classification results with val_vtab-sun397: top1: 40.00	top5: 68.00	
[09/26 06:01:06 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.8345653031794291
[09/26 06:01:13 visual_prompt]: Epoch 35 / 100: avg data time: 5.76e-02, avg batch time: 0.5001, average train loss: 0.0159
[09/26 06:01:14 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1673, average loss: 2.9664
[09/26 06:01:14 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 68.50	
[09/26 06:01:14 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.8213938048432696
[09/26 06:01:21 visual_prompt]: Epoch 36 / 100: avg data time: 7.09e-02, avg batch time: 0.5153, average train loss: 0.0159
[09/26 06:01:23 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1671, average loss: 2.9670
[09/26 06:01:23 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.50	top5: 67.50	
[09/26 06:01:23 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.8078307376628291
[09/26 06:01:30 visual_prompt]: Epoch 37 / 100: avg data time: 6.37e-02, avg batch time: 0.5065, average train loss: 0.0157
[09/26 06:01:32 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1675, average loss: 2.9616
[09/26 06:01:32 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 68.00	
[09/26 06:01:32 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.7938926261462366
[09/26 06:01:38 visual_prompt]: Epoch 38 / 100: avg data time: 5.83e-02, avg batch time: 0.5011, average train loss: 0.0155
[09/26 06:01:40 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1673, average loss: 2.9619
[09/26 06:01:40 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 68.00	
[09/26 06:01:40 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.7795964517353734
[09/26 06:01:47 visual_prompt]: Epoch 39 / 100: avg data time: 6.44e-02, avg batch time: 0.5083, average train loss: 0.0157
[09/26 06:01:49 visual_prompt]: Inference (val):avg data time: 4.29e-05, avg batch time: 0.1676, average loss: 2.9615
[09/26 06:01:49 visual_prompt]: Classification results with val_vtab-sun397: top1: 40.00	top5: 69.00	
[09/26 06:01:49 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.7649596321166025
[09/26 06:01:55 visual_prompt]: Epoch 40 / 100: avg data time: 5.71e-02, avg batch time: 0.5013, average train loss: 0.0155
[09/26 06:01:57 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1678, average loss: 2.9754
[09/26 06:01:57 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 68.50	
[09/26 06:01:57 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.75
[09/26 06:02:04 visual_prompt]: Epoch 41 / 100: avg data time: 5.86e-02, avg batch time: 0.5020, average train loss: 0.0156
[09/26 06:02:05 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1671, average loss: 2.9763
[09/26 06:02:05 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 68.50	
[09/26 06:02:05 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.7347357813929454
[09/26 06:02:12 visual_prompt]: Epoch 42 / 100: avg data time: 6.27e-02, avg batch time: 0.5057, average train loss: 0.0155
[09/26 06:02:14 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1672, average loss: 2.9741
[09/26 06:02:14 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.50	top5: 67.50	
[09/26 06:02:14 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.7191855733945387
[09/26 06:02:21 visual_prompt]: Epoch 43 / 100: avg data time: 4.92e-02, avg batch time: 0.4927, average train loss: 0.0154
[09/26 06:02:22 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1674, average loss: 2.9696
[09/26 06:02:22 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 68.50	
[09/26 06:02:22 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.7033683215379002
[09/26 06:02:29 visual_prompt]: Epoch 44 / 100: avg data time: 6.29e-02, avg batch time: 0.5063, average train loss: 0.0154
[09/26 06:02:31 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1672, average loss: 2.9760
[09/26 06:02:31 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 69.50	
[09/26 06:02:31 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.6873032967079561
[09/26 06:02:38 visual_prompt]: Epoch 45 / 100: avg data time: 5.66e-02, avg batch time: 0.5010, average train loss: 0.0155
[09/26 06:02:39 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1678, average loss: 2.9759
[09/26 06:02:39 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 69.00	
[09/26 06:02:39 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.6710100716628344
[09/26 06:02:46 visual_prompt]: Epoch 46 / 100: avg data time: 4.89e-02, avg batch time: 0.4921, average train loss: 0.0154
[09/26 06:02:48 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1674, average loss: 2.9721
[09/26 06:02:48 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 69.00	
[09/26 06:02:48 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.6545084971874737
[09/26 06:02:54 visual_prompt]: Epoch 47 / 100: avg data time: 6.26e-02, avg batch time: 0.5052, average train loss: 0.0153
[09/26 06:02:56 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1676, average loss: 2.9758
[09/26 06:02:56 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 69.00	
[09/26 06:02:56 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.6378186779084996
[09/26 06:03:03 visual_prompt]: Epoch 48 / 100: avg data time: 5.84e-02, avg batch time: 0.5020, average train loss: 0.0153
[09/26 06:03:05 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1672, average loss: 2.9835
[09/26 06:03:05 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.00	top5: 69.00	
[09/26 06:03:05 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.6209609477998338
[09/26 06:03:11 visual_prompt]: Epoch 49 / 100: avg data time: 6.52e-02, avg batch time: 0.5086, average train loss: 0.0153
[09/26 06:03:13 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1671, average loss: 2.9804
[09/26 06:03:13 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 69.00	
[09/26 06:03:13 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.6039558454088796
[09/26 06:03:20 visual_prompt]: Epoch 50 / 100: avg data time: 6.01e-02, avg batch time: 0.5049, average train loss: 0.0155
[09/26 06:03:21 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1673, average loss: 2.9783
[09/26 06:03:21 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 68.50	
[09/26 06:03:21 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.5868240888334653
[09/26 06:03:28 visual_prompt]: Epoch 51 / 100: avg data time: 5.61e-02, avg batch time: 0.4999, average train loss: 0.0151
[09/26 06:03:30 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1676, average loss: 2.9763
[09/26 06:03:30 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 69.00	
[09/26 06:03:30 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.5695865504800327
[09/26 06:03:37 visual_prompt]: Epoch 52 / 100: avg data time: 6.31e-02, avg batch time: 0.5065, average train loss: 0.0150
[09/26 06:03:38 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1675, average loss: 2.9738
[09/26 06:03:38 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 68.50	
[09/26 06:03:38 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.5522642316338268
[09/26 06:03:45 visual_prompt]: Epoch 53 / 100: avg data time: 6.12e-02, avg batch time: 0.5055, average train loss: 0.0152
[09/26 06:03:47 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1678, average loss: 2.9813
[09/26 06:03:47 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 69.50	
[09/26 06:03:47 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.5348782368720626
[09/26 06:03:54 visual_prompt]: Epoch 54 / 100: avg data time: 5.07e-02, avg batch time: 0.4951, average train loss: 0.0151
[09/26 06:03:55 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1674, average loss: 2.9816
[09/26 06:03:55 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 69.00	
[09/26 06:03:55 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.5174497483512506
[09/26 06:04:02 visual_prompt]: Epoch 55 / 100: avg data time: 6.21e-02, avg batch time: 0.5055, average train loss: 0.0151
[09/26 06:04:04 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1679, average loss: 2.9936
[09/26 06:04:04 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.50	top5: 68.50	
[09/26 06:04:04 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.5
[09/26 06:04:11 visual_prompt]: Epoch 56 / 100: avg data time: 6.60e-02, avg batch time: 0.5105, average train loss: 0.0151
[09/26 06:04:13 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1677, average loss: 2.9893
[09/26 06:04:13 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 69.00	
[09/26 06:04:13 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.48255025164874965
[09/26 06:04:20 visual_prompt]: Epoch 57 / 100: avg data time: 6.74e-02, avg batch time: 0.5107, average train loss: 0.0151
[09/26 06:04:21 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1676, average loss: 2.9903
[09/26 06:04:21 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 68.00	
[09/26 06:04:21 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.46512176312793735
[09/26 06:04:28 visual_prompt]: Epoch 58 / 100: avg data time: 5.81e-02, avg batch time: 0.5008, average train loss: 0.0152
[09/26 06:04:29 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1676, average loss: 2.9859
[09/26 06:04:29 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 68.50	
[09/26 06:04:29 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.44773576836617335
[09/26 06:04:36 visual_prompt]: Epoch 59 / 100: avg data time: 4.97e-02, avg batch time: 0.4930, average train loss: 0.0149
[09/26 06:04:38 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1672, average loss: 2.9886
[09/26 06:04:38 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.50	top5: 69.50	
[09/26 06:04:38 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.4304134495199674
[09/26 06:04:45 visual_prompt]: Epoch 60 / 100: avg data time: 6.19e-02, avg batch time: 0.5057, average train loss: 0.0151
[09/26 06:04:46 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1674, average loss: 2.9825
[09/26 06:04:46 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 68.00	
[09/26 06:04:46 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.41317591116653485
[09/26 06:04:53 visual_prompt]: Epoch 61 / 100: avg data time: 5.89e-02, avg batch time: 0.5019, average train loss: 0.0150
[09/26 06:04:55 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1679, average loss: 2.9875
[09/26 06:04:55 visual_prompt]: Classification results with val_vtab-sun397: top1: 40.00	top5: 69.00	
[09/26 06:04:55 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.3960441545911204
[09/26 06:05:02 visual_prompt]: Epoch 62 / 100: avg data time: 6.17e-02, avg batch time: 0.5043, average train loss: 0.0147
[09/26 06:05:03 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1673, average loss: 2.9916
[09/26 06:05:03 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 69.00	
[09/26 06:05:03 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.3790390522001662
[09/26 06:05:10 visual_prompt]: Epoch 63 / 100: avg data time: 6.32e-02, avg batch time: 0.5062, average train loss: 0.0148
[09/26 06:05:12 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1679, average loss: 2.9897
[09/26 06:05:12 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 70.00	
[09/26 06:05:12 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.36218132209150045
[09/26 06:05:19 visual_prompt]: Epoch 64 / 100: avg data time: 5.91e-02, avg batch time: 0.5021, average train loss: 0.0148
[09/26 06:05:20 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1680, average loss: 3.0009
[09/26 06:05:20 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 68.50	
[09/26 06:05:20 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.34549150281252633
[09/26 06:05:27 visual_prompt]: Epoch 65 / 100: avg data time: 5.94e-02, avg batch time: 0.5048, average train loss: 0.0147
[09/26 06:05:29 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1672, average loss: 2.9951
[09/26 06:05:29 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 68.50	
[09/26 06:05:29 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.32898992833716567
[09/26 06:05:36 visual_prompt]: Epoch 66 / 100: avg data time: 5.00e-02, avg batch time: 0.4938, average train loss: 0.0149
[09/26 06:05:37 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1680, average loss: 2.9940
[09/26 06:05:37 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 69.00	
[09/26 06:05:37 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.31269670329204396
[09/26 06:05:44 visual_prompt]: Epoch 67 / 100: avg data time: 6.37e-02, avg batch time: 0.5068, average train loss: 0.0148
[09/26 06:05:46 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1673, average loss: 2.9890
[09/26 06:05:46 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 68.50	
[09/26 06:05:46 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.2966316784621
[09/26 06:05:53 visual_prompt]: Epoch 68 / 100: avg data time: 5.78e-02, avg batch time: 0.5015, average train loss: 0.0148
[09/26 06:05:54 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1673, average loss: 2.9874
[09/26 06:05:54 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.50	top5: 68.50	
[09/26 06:05:54 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.28081442660546124
[09/26 06:06:01 visual_prompt]: Epoch 69 / 100: avg data time: 5.86e-02, avg batch time: 0.5026, average train loss: 0.0149
[09/26 06:06:03 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1674, average loss: 2.9900
[09/26 06:06:03 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.00	top5: 69.00	
[09/26 06:06:03 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.26526421860705474
[09/26 06:06:10 visual_prompt]: Epoch 70 / 100: avg data time: 6.48e-02, avg batch time: 0.5085, average train loss: 0.0147
[09/26 06:06:11 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1671, average loss: 2.9896
[09/26 06:06:11 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 69.00	
[09/26 06:06:11 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.2500000000000001
[09/26 06:06:18 visual_prompt]: Epoch 71 / 100: avg data time: 5.32e-02, avg batch time: 0.4980, average train loss: 0.0148
[09/26 06:06:20 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1672, average loss: 2.9933
[09/26 06:06:20 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.50	top5: 68.50	
[09/26 06:06:20 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.2350403678833976
[09/26 06:06:27 visual_prompt]: Epoch 72 / 100: avg data time: 5.74e-02, avg batch time: 0.5004, average train loss: 0.0147
[09/26 06:06:28 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1673, average loss: 2.9944
[09/26 06:06:28 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 68.00	
[09/26 06:06:28 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.22040354826462666
[09/26 06:06:35 visual_prompt]: Epoch 73 / 100: avg data time: 6.19e-02, avg batch time: 0.5060, average train loss: 0.0149
[09/26 06:06:37 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1675, average loss: 2.9967
[09/26 06:06:37 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.50	top5: 69.00	
[09/26 06:06:37 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.2061073738537635
[09/26 06:06:44 visual_prompt]: Epoch 74 / 100: avg data time: 5.95e-02, avg batch time: 0.5040, average train loss: 0.0146
[09/26 06:06:45 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1672, average loss: 2.9962
[09/26 06:06:45 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.00	top5: 69.50	
[09/26 06:06:45 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.19216926233717085
[09/26 06:06:52 visual_prompt]: Epoch 75 / 100: avg data time: 5.84e-02, avg batch time: 0.5029, average train loss: 0.0147
[09/26 06:06:54 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1670, average loss: 2.9992
[09/26 06:06:54 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 69.00	
[09/26 06:06:54 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.17860619515673032
[09/26 06:07:01 visual_prompt]: Epoch 76 / 100: avg data time: 6.35e-02, avg batch time: 0.5070, average train loss: 0.0146
[09/26 06:07:02 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1670, average loss: 2.9982
[09/26 06:07:02 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.50	top5: 69.00	
[09/26 06:07:02 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.16543469682057105
[09/26 06:07:09 visual_prompt]: Epoch 77 / 100: avg data time: 6.82e-02, avg batch time: 0.5126, average train loss: 0.0145
[09/26 06:07:11 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1678, average loss: 2.9952
[09/26 06:07:11 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 69.50	
[09/26 06:07:11 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.15267081477050132
[09/26 06:07:18 visual_prompt]: Epoch 78 / 100: avg data time: 5.73e-02, avg batch time: 0.5016, average train loss: 0.0144
[09/26 06:07:19 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1677, average loss: 2.9966
[09/26 06:07:19 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 69.00	
[09/26 06:07:19 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.14033009983067452
[09/26 06:07:26 visual_prompt]: Epoch 79 / 100: avg data time: 6.08e-02, avg batch time: 0.5042, average train loss: 0.0147
[09/26 06:07:28 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1677, average loss: 2.9965
[09/26 06:07:28 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 68.50	
[09/26 06:07:28 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.12842758726130282
[09/26 06:07:35 visual_prompt]: Epoch 80 / 100: avg data time: 6.21e-02, avg batch time: 0.5070, average train loss: 0.0145
[09/26 06:07:36 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1672, average loss: 2.9959
[09/26 06:07:36 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 69.00	
[09/26 06:07:36 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.11697777844051105
[09/26 06:07:43 visual_prompt]: Epoch 81 / 100: avg data time: 5.50e-02, avg batch time: 0.5002, average train loss: 0.0146
[09/26 06:07:45 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1674, average loss: 2.9946
[09/26 06:07:45 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 68.50	
[09/26 06:07:45 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.10599462319663905
[09/26 06:07:52 visual_prompt]: Epoch 82 / 100: avg data time: 6.57e-02, avg batch time: 0.5089, average train loss: 0.0147
[09/26 06:07:53 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1677, average loss: 2.9920
[09/26 06:07:53 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 69.00	
[09/26 06:07:53 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.09549150281252633
[09/26 06:08:00 visual_prompt]: Epoch 83 / 100: avg data time: 4.99e-02, avg batch time: 0.4948, average train loss: 0.0144
[09/26 06:08:02 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1673, average loss: 2.9940
[09/26 06:08:02 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.00	top5: 69.00	
[09/26 06:08:02 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.08548121372247919
[09/26 06:08:08 visual_prompt]: Epoch 84 / 100: avg data time: 6.07e-02, avg batch time: 0.5034, average train loss: 0.0145
[09/26 06:08:10 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1671, average loss: 2.9963
[09/26 06:08:10 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.00	top5: 69.00	
[09/26 06:08:10 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.07597595192178702
[09/26 06:08:17 visual_prompt]: Epoch 85 / 100: avg data time: 6.25e-02, avg batch time: 0.5057, average train loss: 0.0144
[09/26 06:08:19 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1674, average loss: 2.9971
[09/26 06:08:19 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 68.50	
[09/26 06:08:19 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.06698729810778065
[09/26 06:08:26 visual_prompt]: Epoch 86 / 100: avg data time: 6.17e-02, avg batch time: 0.5058, average train loss: 0.0144
[09/26 06:08:27 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1677, average loss: 2.9972
[09/26 06:08:27 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 68.50	
[09/26 06:08:27 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.058526203570536506
[09/26 06:08:34 visual_prompt]: Epoch 87 / 100: avg data time: 5.01e-02, avg batch time: 0.4959, average train loss: 0.0146
[09/26 06:08:36 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1671, average loss: 2.9964
[09/26 06:08:36 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 68.50	
[09/26 06:08:36 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.05060297685041659
[09/26 06:08:42 visual_prompt]: Epoch 88 / 100: avg data time: 6.03e-02, avg batch time: 0.5028, average train loss: 0.0145
[09/26 06:08:44 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1669, average loss: 2.9977
[09/26 06:08:44 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 68.50	
[09/26 06:08:44 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.04322727117869951
[09/26 06:08:51 visual_prompt]: Epoch 89 / 100: avg data time: 4.91e-02, avg batch time: 0.4928, average train loss: 0.0145
[09/26 06:08:52 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1674, average loss: 2.9981
[09/26 06:08:52 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 69.00	
[09/26 06:08:52 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.03640807271660634
[09/26 06:08:59 visual_prompt]: Epoch 90 / 100: avg data time: 6.19e-02, avg batch time: 0.5053, average train loss: 0.0144
[09/26 06:09:01 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1673, average loss: 2.9987
[09/26 06:09:01 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 69.00	
[09/26 06:09:01 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.03015368960704584
[09/26 06:09:08 visual_prompt]: Epoch 91 / 100: avg data time: 5.79e-02, avg batch time: 0.5011, average train loss: 0.0144
[09/26 06:09:09 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1672, average loss: 2.9992
[09/26 06:09:09 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 69.00	
[09/26 06:09:09 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.024471741852423234
[09/26 06:09:16 visual_prompt]: Epoch 92 / 100: avg data time: 4.62e-02, avg batch time: 0.4925, average train loss: 0.0144
[09/26 06:09:18 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1670, average loss: 2.9991
[09/26 06:09:18 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 69.00	
[09/26 06:09:18 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.019369152030840553
[09/26 06:09:25 visual_prompt]: Epoch 93 / 100: avg data time: 6.26e-02, avg batch time: 0.5059, average train loss: 0.0144
[09/26 06:09:26 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1673, average loss: 2.9986
[09/26 06:09:26 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 69.00	
[09/26 06:09:26 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.014852136862001764
[09/26 06:09:33 visual_prompt]: Epoch 94 / 100: avg data time: 6.06e-02, avg batch time: 0.5042, average train loss: 0.0143
[09/26 06:09:35 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1669, average loss: 2.9988
[09/26 06:09:35 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 69.00	
[09/26 06:09:35 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.010926199633097156
[09/26 06:09:41 visual_prompt]: Epoch 95 / 100: avg data time: 5.61e-02, avg batch time: 0.4996, average train loss: 0.0144
[09/26 06:09:43 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1669, average loss: 2.9989
[09/26 06:09:43 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 69.00	
[09/26 06:09:43 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.00759612349389599
[09/26 06:09:50 visual_prompt]: Epoch 96 / 100: avg data time: 5.88e-02, avg batch time: 0.5022, average train loss: 0.0144
[09/26 06:09:52 visual_prompt]: Inference (val):avg data time: 1.94e-05, avg batch time: 0.1679, average loss: 2.9988
[09/26 06:09:52 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 69.00	
[09/26 06:09:52 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.004865965629214819
[09/26 06:09:58 visual_prompt]: Epoch 97 / 100: avg data time: 5.85e-02, avg batch time: 0.5019, average train loss: 0.0145
[09/26 06:10:00 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1678, average loss: 2.9986
[09/26 06:10:00 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 69.00	
[09/26 06:10:00 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.002739052315863355
[09/26 06:10:07 visual_prompt]: Epoch 98 / 100: avg data time: 5.91e-02, avg batch time: 0.5037, average train loss: 0.0145
[09/26 06:10:08 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1672, average loss: 2.9985
[09/26 06:10:08 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 69.00	
[09/26 06:10:08 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.0012179748700879012
[09/26 06:10:15 visual_prompt]: Epoch 99 / 100: avg data time: 5.52e-02, avg batch time: 0.4991, average train loss: 0.0144
[09/26 06:10:17 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1674, average loss: 2.9985
[09/26 06:10:17 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 69.00	
[09/26 06:10:17 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.00030458649045211894
[09/26 06:10:24 visual_prompt]: Epoch 100 / 100: avg data time: 6.02e-02, avg batch time: 0.5042, average train loss: 0.0143
[09/26 06:10:25 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1673, average loss: 2.9985
[09/26 06:10:25 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 69.00	
[09/26 06:10:25 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 06:10:25 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              0
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 06:10:25 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-sun397', 'DATA.NUMBER_CLASSES', '397', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 06:10:25 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 06:10:25 visual_prompt]: Training with config:
[09/26 06:10:25 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-sun397/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr1.0_wd0.0/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 1.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-sun397', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 397, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 06:10:25 visual_prompt]: Loading training data...
[09/26 06:10:25 visual_prompt]: Constructing vtab-sun397 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split train[:800], from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/26 06:10:27 visual_prompt]: Number of images: 800
[09/26 06:10:27 visual_prompt]: Number of classes: 309 / 397
[09/26 06:10:27 visual_prompt]: Loading validation data...
[09/26 06:10:27 visual_prompt]: Constructing vtab-sun397 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split validation[:200], from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/26 06:10:27 visual_prompt]: Number of images: 200
[09/26 06:10:27 visual_prompt]: Number of classes: 136 / 397
[09/26 06:10:27 visual_prompt]: Constructing models...
[09/26 06:10:30 visual_prompt]: Total Parameters: 86564749	 Gradient Parameters: 766093
[09/26 06:10:30 visual_prompt]: tuned percent:0.885
[09/26 06:10:30 visual_prompt]: Device used for model: 0
[09/26 06:10:30 visual_prompt]: Setting up Evaluator...
[09/26 06:10:30 visual_prompt]: Setting up Trainer...
[09/26 06:10:30 visual_prompt]: 	Setting up the optimizer...
[09/26 06:10:30 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 06:10:36 visual_prompt]: Epoch 1 / 100: avg data time: 4.64e-02, avg batch time: 0.4897, average train loss: 5.9890
[09/26 06:10:38 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1671, average loss: 6.0097
[09/26 06:10:38 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/26 06:10:38 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.1
[09/26 06:10:45 visual_prompt]: Epoch 2 / 100: avg data time: 6.31e-02, avg batch time: 0.5064, average train loss: 5.8990
[09/26 06:10:47 visual_prompt]: Inference (val):avg data time: 4.42e-05, avg batch time: 0.1670, average loss: 5.8811
[09/26 06:10:47 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 06:10:47 visual_prompt]: Best epoch 2: best metric: 0.005
[09/26 06:10:47 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.2
[09/26 06:10:53 visual_prompt]: Epoch 3 / 100: avg data time: 6.02e-02, avg batch time: 0.5044, average train loss: 5.6737
[09/26 06:10:55 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1672, average loss: 5.7929
[09/26 06:10:55 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.00	top5: 5.50	
[09/26 06:10:55 visual_prompt]: Best epoch 3: best metric: 0.020
[09/26 06:10:55 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.3
[09/26 06:11:02 visual_prompt]: Epoch 4 / 100: avg data time: 4.67e-02, avg batch time: 0.4898, average train loss: 5.4839
[09/26 06:11:03 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1675, average loss: 5.6729
[09/26 06:11:03 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.00	top5: 7.00	
[09/26 06:11:03 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.4
[09/26 06:11:10 visual_prompt]: Epoch 5 / 100: avg data time: 6.05e-02, avg batch time: 0.5034, average train loss: 5.1558
[09/26 06:11:12 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1671, average loss: 5.3059
[09/26 06:11:12 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 14.00	
[09/26 06:11:12 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.5
[09/26 06:11:19 visual_prompt]: Epoch 6 / 100: avg data time: 5.88e-02, avg batch time: 0.5021, average train loss: 4.5427
[09/26 06:11:20 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1670, average loss: 4.8359
[09/26 06:11:20 visual_prompt]: Classification results with val_vtab-sun397: top1: 11.50	top5: 27.50	
[09/26 06:11:20 visual_prompt]: Best epoch 6: best metric: 0.115
[09/26 06:11:20 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.6
[09/26 06:11:27 visual_prompt]: Epoch 7 / 100: avg data time: 5.91e-02, avg batch time: 0.5027, average train loss: 3.3380
[09/26 06:11:29 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1672, average loss: 4.1786
[09/26 06:11:29 visual_prompt]: Classification results with val_vtab-sun397: top1: 26.00	top5: 48.00	
[09/26 06:11:29 visual_prompt]: Best epoch 7: best metric: 0.260
[09/26 06:11:29 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.7
[09/26 06:11:36 visual_prompt]: Epoch 8 / 100: avg data time: 5.95e-02, avg batch time: 0.5034, average train loss: 1.7885
[09/26 06:11:37 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1671, average loss: 3.4742
[09/26 06:11:37 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.00	top5: 59.00	
[09/26 06:11:37 visual_prompt]: Best epoch 8: best metric: 0.380
[09/26 06:11:37 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.8
[09/26 06:11:44 visual_prompt]: Epoch 9 / 100: avg data time: 5.71e-02, avg batch time: 0.5018, average train loss: 0.6440
[09/26 06:11:46 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1671, average loss: 3.2452
[09/26 06:11:46 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.00	top5: 63.00	
[09/26 06:11:46 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.9
[09/26 06:11:53 visual_prompt]: Epoch 10 / 100: avg data time: 5.99e-02, avg batch time: 0.5032, average train loss: 0.1966
[09/26 06:11:54 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1675, average loss: 3.1227
[09/26 06:11:54 visual_prompt]: Classification results with val_vtab-sun397: top1: 36.50	top5: 67.50	
[09/26 06:11:54 visual_prompt]: Training 11 / 100 epoch, with learning rate 1.0
[09/26 06:12:01 visual_prompt]: Epoch 11 / 100: avg data time: 5.97e-02, avg batch time: 0.5032, average train loss: 0.0908
[09/26 06:12:03 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1677, average loss: 3.0402
[09/26 06:12:03 visual_prompt]: Classification results with val_vtab-sun397: top1: 36.50	top5: 66.50	
[09/26 06:12:03 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.9996954135095479
[09/26 06:12:10 visual_prompt]: Epoch 12 / 100: avg data time: 5.96e-02, avg batch time: 0.5024, average train loss: 0.0421
[09/26 06:12:11 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1672, average loss: 3.0624
[09/26 06:12:11 visual_prompt]: Classification results with val_vtab-sun397: top1: 35.50	top5: 66.50	
[09/26 06:12:11 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.9987820251299121
[09/26 06:12:18 visual_prompt]: Epoch 13 / 100: avg data time: 5.67e-02, avg batch time: 0.5004, average train loss: 0.0360
[09/26 06:12:20 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1671, average loss: 3.1259
[09/26 06:12:20 visual_prompt]: Classification results with val_vtab-sun397: top1: 35.50	top5: 65.00	
[09/26 06:12:20 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.9972609476841366
[09/26 06:12:27 visual_prompt]: Epoch 14 / 100: avg data time: 5.96e-02, avg batch time: 0.5031, average train loss: 0.0217
[09/26 06:12:28 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1673, average loss: 3.0246
[09/26 06:12:28 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 68.00	
[09/26 06:12:28 visual_prompt]: Best epoch 14: best metric: 0.390
[09/26 06:12:28 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.9951340343707852
[09/26 06:12:35 visual_prompt]: Epoch 15 / 100: avg data time: 6.33e-02, avg batch time: 0.5054, average train loss: 0.0154
[09/26 06:12:37 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1674, average loss: 3.0391
[09/26 06:12:37 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 68.50	
[09/26 06:12:37 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.9924038765061041
[09/26 06:12:44 visual_prompt]: Epoch 16 / 100: avg data time: 6.00e-02, avg batch time: 0.5037, average train loss: 0.0130
[09/26 06:12:45 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1675, average loss: 3.0625
[09/26 06:12:45 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.50	top5: 68.00	
[09/26 06:12:45 visual_prompt]: Best epoch 16: best metric: 0.395
[09/26 06:12:45 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.9890738003669028
[09/26 06:12:52 visual_prompt]: Epoch 17 / 100: avg data time: 6.11e-02, avg batch time: 0.5047, average train loss: 0.0115
[09/26 06:12:54 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1670, average loss: 3.0615
[09/26 06:12:54 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 68.50	
[09/26 06:12:54 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.9851478631379982
[09/26 06:13:01 visual_prompt]: Epoch 18 / 100: avg data time: 6.31e-02, avg batch time: 0.5077, average train loss: 0.0105
[09/26 06:13:02 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1676, average loss: 3.0582
[09/26 06:13:02 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 68.00	
[09/26 06:13:02 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.9806308479691594
[09/26 06:13:09 visual_prompt]: Epoch 19 / 100: avg data time: 6.05e-02, avg batch time: 0.5055, average train loss: 0.0096
[09/26 06:13:11 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1671, average loss: 3.0567
[09/26 06:13:11 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 68.50	
[09/26 06:13:11 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.9755282581475768
[09/26 06:13:18 visual_prompt]: Epoch 20 / 100: avg data time: 5.89e-02, avg batch time: 0.5020, average train loss: 0.0090
[09/26 06:13:19 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1673, average loss: 3.0587
[09/26 06:13:19 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 68.00	
[09/26 06:13:19 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.9698463103929542
[09/26 06:13:26 visual_prompt]: Epoch 21 / 100: avg data time: 5.18e-02, avg batch time: 0.4955, average train loss: 0.0085
[09/26 06:13:28 visual_prompt]: Inference (val):avg data time: 1.99e-05, avg batch time: 0.1676, average loss: 3.0638
[09/26 06:13:28 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 67.50	
[09/26 06:13:28 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.9635919272833937
[09/26 06:13:34 visual_prompt]: Epoch 22 / 100: avg data time: 5.63e-02, avg batch time: 0.4998, average train loss: 0.0079
[09/26 06:13:36 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1676, average loss: 3.0658
[09/26 06:13:36 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.00	top5: 67.00	
[09/26 06:13:36 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.9567727288213004
[09/26 06:13:43 visual_prompt]: Epoch 23 / 100: avg data time: 6.24e-02, avg batch time: 0.5071, average train loss: 0.0075
[09/26 06:13:45 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1678, average loss: 3.0692
[09/26 06:13:45 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 67.50	
[09/26 06:13:45 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.9493970231495835
[09/26 06:13:51 visual_prompt]: Epoch 24 / 100: avg data time: 6.49e-02, avg batch time: 0.5076, average train loss: 0.0073
[09/26 06:13:53 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1671, average loss: 3.0752
[09/26 06:13:53 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 67.00	
[09/26 06:13:53 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.9414737964294635
[09/26 06:14:00 visual_prompt]: Epoch 25 / 100: avg data time: 5.82e-02, avg batch time: 0.5027, average train loss: 0.0068
[09/26 06:14:02 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1674, average loss: 3.0738
[09/26 06:14:02 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 67.50	
[09/26 06:14:02 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.9330127018922194
[09/26 06:14:08 visual_prompt]: Epoch 26 / 100: avg data time: 6.17e-02, avg batch time: 0.5046, average train loss: 0.0064
[09/26 06:14:10 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1670, average loss: 3.0735
[09/26 06:14:10 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 67.00	
[09/26 06:14:10 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.9240240480782129
[09/26 06:14:17 visual_prompt]: Epoch 27 / 100: avg data time: 5.71e-02, avg batch time: 0.5012, average train loss: 0.0062
[09/26 06:14:18 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1677, average loss: 3.0761
[09/26 06:14:18 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 67.00	
[09/26 06:14:18 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.9145187862775208
[09/26 06:14:25 visual_prompt]: Epoch 28 / 100: avg data time: 5.97e-02, avg batch time: 0.5027, average train loss: 0.0061
[09/26 06:14:27 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1677, average loss: 3.0777
[09/26 06:14:27 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 66.50	
[09/26 06:14:27 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.9045084971874737
[09/26 06:14:34 visual_prompt]: Epoch 29 / 100: avg data time: 5.98e-02, avg batch time: 0.5021, average train loss: 0.0058
[09/26 06:14:35 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1678, average loss: 3.0817
[09/26 06:14:35 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 67.00	
[09/26 06:14:35 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.8940053768033609
[09/26 06:14:42 visual_prompt]: Epoch 30 / 100: avg data time: 6.17e-02, avg batch time: 0.5041, average train loss: 0.0055
[09/26 06:14:44 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1680, average loss: 3.0852
[09/26 06:14:44 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 66.50	
[09/26 06:14:44 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.883022221559489
[09/26 06:14:51 visual_prompt]: Epoch 31 / 100: avg data time: 5.90e-02, avg batch time: 0.5031, average train loss: 0.0053
[09/26 06:14:52 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1683, average loss: 3.0895
[09/26 06:14:52 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 66.50	
[09/26 06:14:52 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.8715724127386971
[09/26 06:14:59 visual_prompt]: Epoch 32 / 100: avg data time: 6.23e-02, avg batch time: 0.5053, average train loss: 0.0051
[09/26 06:15:01 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1676, average loss: 3.0881
[09/26 06:15:01 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 66.50	
[09/26 06:15:01 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.8596699001693255
[09/26 06:15:08 visual_prompt]: Epoch 33 / 100: avg data time: 6.29e-02, avg batch time: 0.5054, average train loss: 0.0050
[09/26 06:15:09 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1678, average loss: 3.0854
[09/26 06:15:09 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 66.50	
[09/26 06:15:09 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.8473291852294986
[09/26 06:15:16 visual_prompt]: Epoch 34 / 100: avg data time: 5.98e-02, avg batch time: 0.5030, average train loss: 0.0049
[09/26 06:15:18 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1674, average loss: 3.0824
[09/26 06:15:18 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 66.50	
[09/26 06:15:18 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.8345653031794291
[09/26 06:15:25 visual_prompt]: Epoch 35 / 100: avg data time: 6.04e-02, avg batch time: 0.5044, average train loss: 0.0047
[09/26 06:15:26 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1672, average loss: 3.0857
[09/26 06:15:26 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 66.50	
[09/26 06:15:26 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.8213938048432696
[09/26 06:15:33 visual_prompt]: Epoch 36 / 100: avg data time: 5.64e-02, avg batch time: 0.4999, average train loss: 0.0046
[09/26 06:15:35 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1675, average loss: 3.0843
[09/26 06:15:35 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 66.50	
[09/26 06:15:35 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.8078307376628291
[09/26 06:15:42 visual_prompt]: Epoch 37 / 100: avg data time: 6.01e-02, avg batch time: 0.5034, average train loss: 0.0044
[09/26 06:15:43 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1676, average loss: 3.0839
[09/26 06:15:43 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 66.50	
[09/26 06:15:43 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.7938926261462366
[09/26 06:15:50 visual_prompt]: Epoch 38 / 100: avg data time: 6.11e-02, avg batch time: 0.5034, average train loss: 0.0043
[09/26 06:15:52 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1681, average loss: 3.0846
[09/26 06:15:52 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 66.50	
[09/26 06:15:52 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.7795964517353734
[09/26 06:15:59 visual_prompt]: Epoch 39 / 100: avg data time: 6.31e-02, avg batch time: 0.5072, average train loss: 0.0042
[09/26 06:16:00 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1677, average loss: 3.0861
[09/26 06:16:00 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 66.50	
[09/26 06:16:00 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.7649596321166025
[09/26 06:16:07 visual_prompt]: Epoch 40 / 100: avg data time: 5.84e-02, avg batch time: 0.5012, average train loss: 0.0042
[09/26 06:16:09 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1676, average loss: 3.0869
[09/26 06:16:09 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 66.50	
[09/26 06:16:09 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.75
[09/26 06:16:16 visual_prompt]: Epoch 41 / 100: avg data time: 6.38e-02, avg batch time: 0.5081, average train loss: 0.0040
[09/26 06:16:17 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1676, average loss: 3.0897
[09/26 06:16:17 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 66.50	
[09/26 06:16:17 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.7347357813929454
[09/26 06:16:24 visual_prompt]: Epoch 42 / 100: avg data time: 5.89e-02, avg batch time: 0.5022, average train loss: 0.0039
[09/26 06:16:26 visual_prompt]: Inference (val):avg data time: 3.59e-05, avg batch time: 0.1678, average loss: 3.0886
[09/26 06:16:26 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 66.50	
[09/26 06:16:26 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.7191855733945387
[09/26 06:16:33 visual_prompt]: Epoch 43 / 100: avg data time: 6.40e-02, avg batch time: 0.5092, average train loss: 0.0039
[09/26 06:16:35 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1676, average loss: 3.0903
[09/26 06:16:35 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 66.50	
[09/26 06:16:35 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.7033683215379002
[09/26 06:16:41 visual_prompt]: Epoch 44 / 100: avg data time: 5.82e-02, avg batch time: 0.5005, average train loss: 0.0038
[09/26 06:16:43 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1677, average loss: 3.0924
[09/26 06:16:43 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 66.50	
[09/26 06:16:43 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.6873032967079561
[09/26 06:16:50 visual_prompt]: Epoch 45 / 100: avg data time: 6.48e-02, avg batch time: 0.5082, average train loss: 0.0037
[09/26 06:16:52 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1675, average loss: 3.0927
[09/26 06:16:52 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 66.50	
[09/26 06:16:52 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.6710100716628344
[09/26 06:16:59 visual_prompt]: Epoch 46 / 100: avg data time: 6.64e-02, avg batch time: 0.5093, average train loss: 0.0037
[09/26 06:17:00 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1677, average loss: 3.0947
[09/26 06:17:00 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 66.50	
[09/26 06:17:00 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.6545084971874737
[09/26 06:17:07 visual_prompt]: Epoch 47 / 100: avg data time: 5.96e-02, avg batch time: 0.5023, average train loss: 0.0036
[09/26 06:17:09 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1676, average loss: 3.0957
[09/26 06:17:09 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 66.50	
[09/26 06:17:09 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.6378186779084996
[09/26 06:17:16 visual_prompt]: Epoch 48 / 100: avg data time: 5.35e-02, avg batch time: 0.4957, average train loss: 0.0036
[09/26 06:17:17 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1672, average loss: 3.0948
[09/26 06:17:17 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 66.50	
[09/26 06:17:17 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.6209609477998338
[09/26 06:17:24 visual_prompt]: Epoch 49 / 100: avg data time: 5.62e-02, avg batch time: 0.4994, average train loss: 0.0035
[09/26 06:17:26 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1675, average loss: 3.0967
[09/26 06:17:26 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 66.50	
[09/26 06:17:26 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.6039558454088796
[09/26 06:17:32 visual_prompt]: Epoch 50 / 100: avg data time: 5.59e-02, avg batch time: 0.4999, average train loss: 0.0034
[09/26 06:17:34 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1673, average loss: 3.0984
[09/26 06:17:34 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 66.50	
[09/26 06:17:34 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.5868240888334653
[09/26 06:17:41 visual_prompt]: Epoch 51 / 100: avg data time: 5.98e-02, avg batch time: 0.5030, average train loss: 0.0034
[09/26 06:17:42 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1672, average loss: 3.1009
[09/26 06:17:43 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 66.50	
[09/26 06:17:43 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.5695865504800327
[09/26 06:17:49 visual_prompt]: Epoch 52 / 100: avg data time: 6.42e-02, avg batch time: 0.5078, average train loss: 0.0033
[09/26 06:17:51 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1679, average loss: 3.1017
[09/26 06:17:51 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 66.50	
[09/26 06:17:51 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.5522642316338268
[09/26 06:17:58 visual_prompt]: Epoch 53 / 100: avg data time: 5.83e-02, avg batch time: 0.5010, average train loss: 0.0033
[09/26 06:18:00 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1671, average loss: 3.1022
[09/26 06:18:00 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 66.50	
[09/26 06:18:00 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.5348782368720626
[09/26 06:18:06 visual_prompt]: Epoch 54 / 100: avg data time: 6.03e-02, avg batch time: 0.5048, average train loss: 0.0033
[09/26 06:18:08 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1670, average loss: 3.1010
[09/26 06:18:08 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 66.00	
[09/26 06:18:08 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.5174497483512506
[09/26 06:18:15 visual_prompt]: Epoch 55 / 100: avg data time: 6.42e-02, avg batch time: 0.5069, average train loss: 0.0032
[09/26 06:18:17 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1676, average loss: 3.1009
[09/26 06:18:17 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 66.00	
[09/26 06:18:17 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.5
[09/26 06:18:23 visual_prompt]: Epoch 56 / 100: avg data time: 6.02e-02, avg batch time: 0.5034, average train loss: 0.0032
[09/26 06:18:25 visual_prompt]: Inference (val):avg data time: 1.96e-05, avg batch time: 0.1677, average loss: 3.1000
[09/26 06:18:25 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 66.00	
[09/26 06:18:25 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.48255025164874965
[09/26 06:18:32 visual_prompt]: Epoch 57 / 100: avg data time: 5.87e-02, avg batch time: 0.5039, average train loss: 0.0031
[09/26 06:18:34 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1675, average loss: 3.1011
[09/26 06:18:34 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 66.00	
[09/26 06:18:34 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.46512176312793735
[09/26 06:18:40 visual_prompt]: Epoch 58 / 100: avg data time: 6.03e-02, avg batch time: 0.5034, average train loss: 0.0031
[09/26 06:18:42 visual_prompt]: Inference (val):avg data time: 1.93e-05, avg batch time: 0.1675, average loss: 3.1018
[09/26 06:18:42 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 66.50	
[09/26 06:18:42 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.44773576836617335
[09/26 06:18:49 visual_prompt]: Epoch 59 / 100: avg data time: 6.13e-02, avg batch time: 0.5040, average train loss: 0.0031
[09/26 06:18:51 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.1673, average loss: 3.1029
[09/26 06:18:51 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 66.50	
[09/26 06:18:51 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.4304134495199674
[09/26 06:18:57 visual_prompt]: Epoch 60 / 100: avg data time: 5.92e-02, avg batch time: 0.5043, average train loss: 0.0031
[09/26 06:18:59 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1677, average loss: 3.1017
[09/26 06:18:59 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 66.50	
[09/26 06:18:59 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.41317591116653485
[09/26 06:19:06 visual_prompt]: Epoch 61 / 100: avg data time: 6.13e-02, avg batch time: 0.5049, average train loss: 0.0030
[09/26 06:19:08 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1676, average loss: 3.1016
[09/26 06:19:08 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 66.50	
[09/26 06:19:08 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.3960441545911204
[09/26 06:19:14 visual_prompt]: Epoch 62 / 100: avg data time: 6.28e-02, avg batch time: 0.5060, average train loss: 0.0030
[09/26 06:19:16 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1673, average loss: 3.1030
[09/26 06:19:16 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 66.50	
[09/26 06:19:16 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.3790390522001662
[09/26 06:19:23 visual_prompt]: Epoch 63 / 100: avg data time: 6.37e-02, avg batch time: 0.5080, average train loss: 0.0030
[09/26 06:19:25 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1678, average loss: 3.1020
[09/26 06:19:25 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 66.00	
[09/26 06:19:25 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.36218132209150045
[09/26 06:19:31 visual_prompt]: Epoch 64 / 100: avg data time: 5.55e-02, avg batch time: 0.4995, average train loss: 0.0029
[09/26 06:19:33 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1677, average loss: 3.1013
[09/26 06:19:33 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 66.00	
[09/26 06:19:33 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.34549150281252633
[09/26 06:19:40 visual_prompt]: Epoch 65 / 100: avg data time: 6.16e-02, avg batch time: 0.5052, average train loss: 0.0030
[09/26 06:19:41 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1676, average loss: 3.1015
[09/26 06:19:41 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 66.00	
[09/26 06:19:41 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.32898992833716567
[09/26 06:19:48 visual_prompt]: Epoch 66 / 100: avg data time: 6.04e-02, avg batch time: 0.5040, average train loss: 0.0029
[09/26 06:19:50 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1675, average loss: 3.1019
[09/26 06:19:50 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 66.00	
[09/26 06:19:50 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.31269670329204396
[09/26 06:19:57 visual_prompt]: Epoch 67 / 100: avg data time: 5.77e-02, avg batch time: 0.5017, average train loss: 0.0029
[09/26 06:19:58 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1678, average loss: 3.1024
[09/26 06:19:58 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 66.50	
[09/26 06:19:58 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.2966316784621
[09/26 06:20:05 visual_prompt]: Epoch 68 / 100: avg data time: 5.22e-02, avg batch time: 0.4965, average train loss: 0.0029
[09/26 06:20:07 visual_prompt]: Inference (val):avg data time: 3.23e-05, avg batch time: 0.1681, average loss: 3.1027
[09/26 06:20:07 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 66.50	
[09/26 06:20:07 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.28081442660546124
[09/26 06:20:14 visual_prompt]: Epoch 69 / 100: avg data time: 6.38e-02, avg batch time: 0.5071, average train loss: 0.0028
[09/26 06:20:15 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1674, average loss: 3.1032
[09/26 06:20:15 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 66.50	
[09/26 06:20:15 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.26526421860705474
[09/26 06:20:22 visual_prompt]: Epoch 70 / 100: avg data time: 6.52e-02, avg batch time: 0.5077, average train loss: 0.0028
[09/26 06:20:24 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1676, average loss: 3.1041
[09/26 06:20:24 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 66.50	
[09/26 06:20:24 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.2500000000000001
[09/26 06:20:31 visual_prompt]: Epoch 71 / 100: avg data time: 6.58e-02, avg batch time: 0.5089, average train loss: 0.0029
[09/26 06:20:32 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1680, average loss: 3.1039
[09/26 06:20:32 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 66.50	
[09/26 06:20:32 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.2350403678833976
[09/26 06:20:39 visual_prompt]: Epoch 72 / 100: avg data time: 6.50e-02, avg batch time: 0.5080, average train loss: 0.0028
[09/26 06:20:41 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1678, average loss: 3.1039
[09/26 06:20:41 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 66.50	
[09/26 06:20:41 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.22040354826462666
[09/26 06:20:48 visual_prompt]: Epoch 73 / 100: avg data time: 5.74e-02, avg batch time: 0.5000, average train loss: 0.0028
[09/26 06:20:49 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1670, average loss: 3.1045
[09/26 06:20:49 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 66.50	
[09/26 06:20:49 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.2061073738537635
[09/26 06:20:56 visual_prompt]: Epoch 74 / 100: avg data time: 5.85e-02, avg batch time: 0.5028, average train loss: 0.0028
[09/26 06:20:58 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1672, average loss: 3.1050
[09/26 06:20:58 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 66.50	
[09/26 06:20:58 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.19216926233717085
[09/26 06:21:05 visual_prompt]: Epoch 75 / 100: avg data time: 6.31e-02, avg batch time: 0.5065, average train loss: 0.0028
[09/26 06:21:06 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1676, average loss: 3.1049
[09/26 06:21:06 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 66.50	
[09/26 06:21:06 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.17860619515673032
[09/26 06:21:13 visual_prompt]: Epoch 76 / 100: avg data time: 6.03e-02, avg batch time: 0.5038, average train loss: 0.0028
[09/26 06:21:15 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1674, average loss: 3.1048
[09/26 06:21:15 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 67.00	
[09/26 06:21:15 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.16543469682057105
[09/26 06:21:22 visual_prompt]: Epoch 77 / 100: avg data time: 6.61e-02, avg batch time: 0.5097, average train loss: 0.0027
[09/26 06:21:23 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1675, average loss: 3.1050
[09/26 06:21:23 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 67.00	
[09/26 06:21:23 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.15267081477050132
[09/26 06:21:30 visual_prompt]: Epoch 78 / 100: avg data time: 6.26e-02, avg batch time: 0.5067, average train loss: 0.0028
[09/26 06:21:32 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1673, average loss: 3.1050
[09/26 06:21:32 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 67.00	
[09/26 06:21:32 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.14033009983067452
[09/26 06:21:39 visual_prompt]: Epoch 79 / 100: avg data time: 4.37e-02, avg batch time: 0.4915, average train loss: 0.0028
[09/26 06:21:40 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1671, average loss: 3.1048
[09/26 06:21:40 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 67.00	
[09/26 06:21:40 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.12842758726130282
[09/26 06:21:47 visual_prompt]: Epoch 80 / 100: avg data time: 6.01e-02, avg batch time: 0.5051, average train loss: 0.0027
[09/26 06:21:49 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1676, average loss: 3.1051
[09/26 06:21:49 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 67.00	
[09/26 06:21:49 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.11697777844051105
[09/26 06:21:56 visual_prompt]: Epoch 81 / 100: avg data time: 5.81e-02, avg batch time: 0.5008, average train loss: 0.0027
[09/26 06:21:57 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1678, average loss: 3.1048
[09/26 06:21:57 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 67.00	
[09/26 06:21:57 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.10599462319663905
[09/26 06:22:04 visual_prompt]: Epoch 82 / 100: avg data time: 5.19e-02, avg batch time: 0.4952, average train loss: 0.0027
[09/26 06:22:06 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1677, average loss: 3.1048
[09/26 06:22:06 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 67.00	
[09/26 06:22:06 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.09549150281252633
[09/26 06:22:13 visual_prompt]: Epoch 83 / 100: avg data time: 6.03e-02, avg batch time: 0.5048, average train loss: 0.0027
[09/26 06:22:14 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1676, average loss: 3.1048
[09/26 06:22:14 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 67.00	
[09/26 06:22:14 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.08548121372247919
[09/26 06:22:21 visual_prompt]: Epoch 84 / 100: avg data time: 5.25e-02, avg batch time: 0.4971, average train loss: 0.0027
[09/26 06:22:23 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1675, average loss: 3.1048
[09/26 06:22:23 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 67.00	
[09/26 06:22:23 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.07597595192178702
[09/26 06:22:29 visual_prompt]: Epoch 85 / 100: avg data time: 5.72e-02, avg batch time: 0.5011, average train loss: 0.0027
[09/26 06:22:31 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1673, average loss: 3.1048
[09/26 06:22:31 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 67.00	
[09/26 06:22:31 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.06698729810778065
[09/26 06:22:38 visual_prompt]: Epoch 86 / 100: avg data time: 6.13e-02, avg batch time: 0.5044, average train loss: 0.0027
[09/26 06:22:39 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1674, average loss: 3.1048
[09/26 06:22:39 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 67.00	
[09/26 06:22:39 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.058526203570536506
[09/26 06:22:46 visual_prompt]: Epoch 87 / 100: avg data time: 6.61e-02, avg batch time: 0.5096, average train loss: 0.0028
[09/26 06:22:48 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1671, average loss: 3.1048
[09/26 06:22:48 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 67.00	
[09/26 06:22:48 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.05060297685041659
[09/26 06:22:55 visual_prompt]: Epoch 88 / 100: avg data time: 6.16e-02, avg batch time: 0.5043, average train loss: 0.0027
[09/26 06:22:57 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1671, average loss: 3.1049
[09/26 06:22:57 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 67.00	
[09/26 06:22:57 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.04322727117869951
[09/26 06:23:04 visual_prompt]: Epoch 89 / 100: avg data time: 6.41e-02, avg batch time: 0.5077, average train loss: 0.0027
[09/26 06:23:05 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1674, average loss: 3.1050
[09/26 06:23:05 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 67.00	
[09/26 06:23:05 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.03640807271660634
[09/26 06:23:12 visual_prompt]: Epoch 90 / 100: avg data time: 6.31e-02, avg batch time: 0.5063, average train loss: 0.0026
[09/26 06:23:14 visual_prompt]: Inference (val):avg data time: 3.60e-05, avg batch time: 0.1673, average loss: 3.1051
[09/26 06:23:14 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 67.00	
[09/26 06:23:14 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.03015368960704584
[09/26 06:23:21 visual_prompt]: Epoch 91 / 100: avg data time: 5.63e-02, avg batch time: 0.4994, average train loss: 0.0027
[09/26 06:23:22 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1675, average loss: 3.1050
[09/26 06:23:22 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 67.00	
[09/26 06:23:22 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.024471741852423234
[09/26 06:23:29 visual_prompt]: Epoch 92 / 100: avg data time: 5.78e-02, avg batch time: 0.5004, average train loss: 0.0027
[09/26 06:23:31 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1674, average loss: 3.1050
[09/26 06:23:31 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 67.00	
[09/26 06:23:31 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.019369152030840553
[09/26 06:23:38 visual_prompt]: Epoch 93 / 100: avg data time: 6.68e-02, avg batch time: 0.5104, average train loss: 0.0027
[09/26 06:23:39 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1677, average loss: 3.1050
[09/26 06:23:39 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 67.00	
[09/26 06:23:39 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.014852136862001764
[09/26 06:23:46 visual_prompt]: Epoch 94 / 100: avg data time: 5.74e-02, avg batch time: 0.5029, average train loss: 0.0027
[09/26 06:23:48 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1673, average loss: 3.1050
[09/26 06:23:48 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 67.00	
[09/26 06:23:48 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.010926199633097156
[09/26 06:23:55 visual_prompt]: Epoch 95 / 100: avg data time: 6.59e-02, avg batch time: 0.5083, average train loss: 0.0027
[09/26 06:23:56 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1676, average loss: 3.1050
[09/26 06:23:56 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 67.00	
[09/26 06:23:56 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.00759612349389599
[09/26 06:24:03 visual_prompt]: Epoch 96 / 100: avg data time: 4.52e-02, avg batch time: 0.4890, average train loss: 0.0027
[09/26 06:24:05 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1672, average loss: 3.1050
[09/26 06:24:05 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 67.00	
[09/26 06:24:05 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.004865965629214819
[09/26 06:24:11 visual_prompt]: Epoch 97 / 100: avg data time: 5.43e-02, avg batch time: 0.4987, average train loss: 0.0027
[09/26 06:24:13 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1672, average loss: 3.1050
[09/26 06:24:13 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 67.00	
[09/26 06:24:13 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.002739052315863355
[09/26 06:24:20 visual_prompt]: Epoch 98 / 100: avg data time: 5.36e-02, avg batch time: 0.4985, average train loss: 0.0027
[09/26 06:24:21 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1673, average loss: 3.1050
[09/26 06:24:21 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 67.00	
[09/26 06:24:21 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.0012179748700879012
[09/26 06:24:28 visual_prompt]: Epoch 99 / 100: avg data time: 6.33e-02, avg batch time: 0.5069, average train loss: 0.0027
[09/26 06:24:30 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1675, average loss: 3.1050
[09/26 06:24:30 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 67.00	
[09/26 06:24:30 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.00030458649045211894
[09/26 06:24:37 visual_prompt]: Epoch 100 / 100: avg data time: 6.18e-02, avg batch time: 0.5057, average train loss: 0.0027
[09/26 06:24:39 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1676, average loss: 3.1050
[09/26 06:24:39 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 67.00	
[09/26 06:24:39 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 06:24:39 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              0
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 06:24:39 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-sun397', 'DATA.NUMBER_CLASSES', '397', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 06:24:39 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 06:24:39 visual_prompt]: Training with config:
[09/26 06:24:39 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-sun397/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.5_wd0.01/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 0.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-sun397', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 397, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 06:24:39 visual_prompt]: Loading training data...
[09/26 06:24:39 visual_prompt]: Constructing vtab-sun397 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split train[:800], from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/26 06:24:40 visual_prompt]: Number of images: 800
[09/26 06:24:40 visual_prompt]: Number of classes: 309 / 397
[09/26 06:24:40 visual_prompt]: Loading validation data...
[09/26 06:24:40 visual_prompt]: Constructing vtab-sun397 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split validation[:200], from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/26 06:24:40 visual_prompt]: Number of images: 200
[09/26 06:24:40 visual_prompt]: Number of classes: 136 / 397
[09/26 06:24:40 visual_prompt]: Constructing models...
[09/26 06:24:43 visual_prompt]: Total Parameters: 86564749	 Gradient Parameters: 766093
[09/26 06:24:43 visual_prompt]: tuned percent:0.885
[09/26 06:24:43 visual_prompt]: Device used for model: 0
[09/26 06:24:43 visual_prompt]: Setting up Evaluator...
[09/26 06:24:43 visual_prompt]: Setting up Trainer...
[09/26 06:24:43 visual_prompt]: 	Setting up the optimizer...
[09/26 06:24:43 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 06:24:50 visual_prompt]: Epoch 1 / 100: avg data time: 6.47e-02, avg batch time: 0.5081, average train loss: 5.9889
[09/26 06:24:51 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1677, average loss: 6.0097
[09/26 06:24:51 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/26 06:24:51 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.05
[09/26 06:24:58 visual_prompt]: Epoch 2 / 100: avg data time: 6.12e-02, avg batch time: 0.5040, average train loss: 5.9340
[09/26 06:25:00 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1678, average loss: 5.9201
[09/26 06:25:00 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 5.00	
[09/26 06:25:00 visual_prompt]: Best epoch 2: best metric: 0.005
[09/26 06:25:00 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.1
[09/26 06:25:07 visual_prompt]: Epoch 3 / 100: avg data time: 6.39e-02, avg batch time: 0.5079, average train loss: 5.7399
[09/26 06:25:09 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1670, average loss: 5.8304
[09/26 06:25:09 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 4.50	
[09/26 06:25:09 visual_prompt]: Best epoch 3: best metric: 0.015
[09/26 06:25:09 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.15
[09/26 06:25:15 visual_prompt]: Epoch 4 / 100: avg data time: 5.89e-02, avg batch time: 0.5018, average train loss: 5.5738
[09/26 06:25:17 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1675, average loss: 5.7345
[09/26 06:25:17 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.00	top5: 7.00	
[09/26 06:25:17 visual_prompt]: Best epoch 4: best metric: 0.020
[09/26 06:25:17 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.2
[09/26 06:25:24 visual_prompt]: Epoch 5 / 100: avg data time: 6.52e-02, avg batch time: 0.5073, average train loss: 5.3577
[09/26 06:25:26 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1674, average loss: 5.5439
[09/26 06:25:26 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.50	top5: 12.00	
[09/26 06:25:26 visual_prompt]: Best epoch 5: best metric: 0.025
[09/26 06:25:26 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.25
[09/26 06:25:32 visual_prompt]: Epoch 6 / 100: avg data time: 4.48e-02, avg batch time: 0.4880, average train loss: 5.2810
[09/26 06:25:34 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1673, average loss: 5.3624
[09/26 06:25:34 visual_prompt]: Classification results with val_vtab-sun397: top1: 3.00	top5: 11.00	
[09/26 06:25:34 visual_prompt]: Best epoch 6: best metric: 0.030
[09/26 06:25:34 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.3
[09/26 06:25:41 visual_prompt]: Epoch 7 / 100: avg data time: 5.88e-02, avg batch time: 0.5021, average train loss: 4.8998
[09/26 06:25:42 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1677, average loss: 5.2239
[09/26 06:25:42 visual_prompt]: Classification results with val_vtab-sun397: top1: 4.50	top5: 17.00	
[09/26 06:25:42 visual_prompt]: Best epoch 7: best metric: 0.045
[09/26 06:25:42 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.35
[09/26 06:25:49 visual_prompt]: Epoch 8 / 100: avg data time: 5.78e-02, avg batch time: 0.5021, average train loss: 4.5689
[09/26 06:25:51 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1680, average loss: 4.9602
[09/26 06:25:51 visual_prompt]: Classification results with val_vtab-sun397: top1: 11.50	top5: 24.50	
[09/26 06:25:51 visual_prompt]: Best epoch 8: best metric: 0.115
[09/26 06:25:51 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.4
[09/26 06:25:58 visual_prompt]: Epoch 9 / 100: avg data time: 6.05e-02, avg batch time: 0.5042, average train loss: 4.1487
[09/26 06:25:59 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1680, average loss: 4.4415
[09/26 06:25:59 visual_prompt]: Classification results with val_vtab-sun397: top1: 17.50	top5: 38.50	
[09/26 06:25:59 visual_prompt]: Best epoch 9: best metric: 0.175
[09/26 06:25:59 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.45
[09/26 06:26:06 visual_prompt]: Epoch 10 / 100: avg data time: 6.62e-02, avg batch time: 0.5096, average train loss: 3.2573
[09/26 06:26:08 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1679, average loss: 4.1133
[09/26 06:26:08 visual_prompt]: Classification results with val_vtab-sun397: top1: 26.50	top5: 51.00	
[09/26 06:26:08 visual_prompt]: Best epoch 10: best metric: 0.265
[09/26 06:26:08 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.5
[09/26 06:26:15 visual_prompt]: Epoch 11 / 100: avg data time: 5.13e-02, avg batch time: 0.4959, average train loss: 2.6382
[09/26 06:26:17 visual_prompt]: Inference (val):avg data time: 4.55e-05, avg batch time: 0.1677, average loss: 3.8496
[09/26 06:26:17 visual_prompt]: Classification results with val_vtab-sun397: top1: 30.00	top5: 55.50	
[09/26 06:26:17 visual_prompt]: Best epoch 11: best metric: 0.300
[09/26 06:26:17 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.49984770675477397
[09/26 06:26:23 visual_prompt]: Epoch 12 / 100: avg data time: 6.10e-02, avg batch time: 0.5052, average train loss: 2.3163
[09/26 06:26:25 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1682, average loss: 3.7153
[09/26 06:26:25 visual_prompt]: Classification results with val_vtab-sun397: top1: 34.50	top5: 61.50	
[09/26 06:26:25 visual_prompt]: Best epoch 12: best metric: 0.345
[09/26 06:26:25 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.49939101256495605
[09/26 06:26:32 visual_prompt]: Epoch 13 / 100: avg data time: 5.52e-02, avg batch time: 0.5005, average train loss: 2.2010
[09/26 06:26:34 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1678, average loss: 3.7667
[09/26 06:26:34 visual_prompt]: Classification results with val_vtab-sun397: top1: 34.50	top5: 60.50	
[09/26 06:26:34 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.4986304738420683
[09/26 06:26:40 visual_prompt]: Epoch 14 / 100: avg data time: 6.23e-02, avg batch time: 0.5047, average train loss: 2.4916
[09/26 06:26:42 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1678, average loss: 4.2293
[09/26 06:26:42 visual_prompt]: Classification results with val_vtab-sun397: top1: 25.50	top5: 52.00	
[09/26 06:26:42 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.4975670171853926
[09/26 06:26:49 visual_prompt]: Epoch 15 / 100: avg data time: 6.77e-02, avg batch time: 0.5117, average train loss: 2.3826
[09/26 06:26:51 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1678, average loss: 4.7490
[09/26 06:26:51 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.50	top5: 43.00	
[09/26 06:26:51 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.49620193825305203
[09/26 06:26:58 visual_prompt]: Epoch 16 / 100: avg data time: 6.25e-02, avg batch time: 0.5061, average train loss: 2.9878
[09/26 06:26:59 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1677, average loss: 3.9286
[09/26 06:26:59 visual_prompt]: Classification results with val_vtab-sun397: top1: 32.50	top5: 59.00	
[09/26 06:26:59 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.4945369001834514
[09/26 06:27:06 visual_prompt]: Epoch 17 / 100: avg data time: 6.45e-02, avg batch time: 0.5082, average train loss: 2.7927
[09/26 06:27:08 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1676, average loss: 3.8882
[09/26 06:27:08 visual_prompt]: Classification results with val_vtab-sun397: top1: 30.50	top5: 60.00	
[09/26 06:27:08 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.4925739315689991
[09/26 06:27:15 visual_prompt]: Epoch 18 / 100: avg data time: 5.80e-02, avg batch time: 0.5028, average train loss: 2.5726
[09/26 06:27:16 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1676, average loss: 4.5066
[09/26 06:27:16 visual_prompt]: Classification results with val_vtab-sun397: top1: 26.50	top5: 50.50	
[09/26 06:27:16 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.4903154239845797
[09/26 06:27:23 visual_prompt]: Epoch 19 / 100: avg data time: 5.60e-02, avg batch time: 0.5000, average train loss: 3.3369
[09/26 06:27:25 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1680, average loss: 5.7353
[09/26 06:27:25 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.00	top5: 10.50	
[09/26 06:27:25 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.4877641290737884
[09/26 06:27:31 visual_prompt]: Epoch 20 / 100: avg data time: 5.28e-02, avg batch time: 0.4992, average train loss: 5.2246
[09/26 06:27:33 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1673, average loss: 5.4575
[09/26 06:27:33 visual_prompt]: Classification results with val_vtab-sun397: top1: 5.50	top5: 16.50	
[09/26 06:27:33 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.4849231551964771
[09/26 06:27:40 visual_prompt]: Epoch 21 / 100: avg data time: 6.03e-02, avg batch time: 0.5041, average train loss: 4.8477
[09/26 06:27:42 visual_prompt]: Inference (val):avg data time: 2.01e-05, avg batch time: 0.1673, average loss: 5.2547
[09/26 06:27:42 visual_prompt]: Classification results with val_vtab-sun397: top1: 9.50	top5: 22.50	
[09/26 06:27:42 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.48179596364169686
[09/26 06:27:48 visual_prompt]: Epoch 22 / 100: avg data time: 6.00e-02, avg batch time: 0.5043, average train loss: 4.3601
[09/26 06:27:50 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1672, average loss: 4.8781
[09/26 06:27:50 visual_prompt]: Classification results with val_vtab-sun397: top1: 11.00	top5: 29.50	
[09/26 06:27:50 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.4783863644106502
[09/26 06:27:57 visual_prompt]: Epoch 23 / 100: avg data time: 6.51e-02, avg batch time: 0.5079, average train loss: 3.7551
[09/26 06:27:59 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1671, average loss: 4.9860
[09/26 06:27:59 visual_prompt]: Classification results with val_vtab-sun397: top1: 12.50	top5: 27.00	
[09/26 06:27:59 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.47469851157479176
[09/26 06:28:05 visual_prompt]: Epoch 24 / 100: avg data time: 6.11e-02, avg batch time: 0.5044, average train loss: 4.1307
[09/26 06:28:07 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1672, average loss: 4.6260
[09/26 06:28:07 visual_prompt]: Classification results with val_vtab-sun397: top1: 16.00	top5: 36.00	
[09/26 06:28:07 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.47073689821473175
[09/26 06:28:14 visual_prompt]: Epoch 25 / 100: avg data time: 5.40e-02, avg batch time: 0.4976, average train loss: 3.4710
[09/26 06:28:15 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1673, average loss: 4.4697
[09/26 06:28:15 visual_prompt]: Classification results with val_vtab-sun397: top1: 18.00	top5: 39.50	
[09/26 06:28:15 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.4665063509461097
[09/26 06:28:22 visual_prompt]: Epoch 26 / 100: avg data time: 6.22e-02, avg batch time: 0.5061, average train loss: 3.5998
[09/26 06:28:24 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1673, average loss: 4.9755
[09/26 06:28:24 visual_prompt]: Classification results with val_vtab-sun397: top1: 11.50	top5: 26.50	
[09/26 06:28:24 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.46201202403910646
[09/26 06:28:31 visual_prompt]: Epoch 27 / 100: avg data time: 6.24e-02, avg batch time: 0.5068, average train loss: 3.4628
[09/26 06:28:33 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1670, average loss: 4.3594
[09/26 06:28:33 visual_prompt]: Classification results with val_vtab-sun397: top1: 20.50	top5: 42.50	
[09/26 06:28:33 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.4572593931387604
[09/26 06:28:39 visual_prompt]: Epoch 28 / 100: avg data time: 6.07e-02, avg batch time: 0.5059, average train loss: 3.0170
[09/26 06:28:41 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1673, average loss: 4.1249
[09/26 06:28:41 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.50	top5: 46.00	
[09/26 06:28:41 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.45225424859373686
[09/26 06:28:48 visual_prompt]: Epoch 29 / 100: avg data time: 5.73e-02, avg batch time: 0.5003, average train loss: 2.8259
[09/26 06:28:49 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1672, average loss: 3.9836
[09/26 06:28:49 visual_prompt]: Classification results with val_vtab-sun397: top1: 26.00	top5: 54.50	
[09/26 06:28:49 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.44700268840168045
[09/26 06:28:56 visual_prompt]: Epoch 30 / 100: avg data time: 6.00e-02, avg batch time: 0.5032, average train loss: 2.5577
[09/26 06:28:58 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1674, average loss: 4.7771
[09/26 06:28:58 visual_prompt]: Classification results with val_vtab-sun397: top1: 14.00	top5: 35.00	
[09/26 06:28:58 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.4415111107797445
[09/26 06:29:05 visual_prompt]: Epoch 31 / 100: avg data time: 6.11e-02, avg batch time: 0.5059, average train loss: 3.7333
[09/26 06:29:06 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1674, average loss: 4.3067
[09/26 06:29:06 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.00	top5: 45.50	
[09/26 06:29:06 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.43578620636934856
[09/26 06:29:13 visual_prompt]: Epoch 32 / 100: avg data time: 6.18e-02, avg batch time: 0.5062, average train loss: 2.9866
[09/26 06:29:15 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1674, average loss: 4.1714
[09/26 06:29:15 visual_prompt]: Classification results with val_vtab-sun397: top1: 24.00	top5: 48.00	
[09/26 06:29:15 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.42983495008466277
[09/26 06:29:22 visual_prompt]: Epoch 33 / 100: avg data time: 6.63e-02, avg batch time: 0.5121, average train loss: 3.1711
[09/26 06:29:24 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1674, average loss: 4.1212
[09/26 06:29:24 visual_prompt]: Classification results with val_vtab-sun397: top1: 25.00	top5: 49.50	
[09/26 06:29:24 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.4236645926147493
[09/26 06:29:31 visual_prompt]: Epoch 34 / 100: avg data time: 6.10e-02, avg batch time: 0.5041, average train loss: 2.9223
[09/26 06:29:32 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1672, average loss: 5.0370
[09/26 06:29:32 visual_prompt]: Classification results with val_vtab-sun397: top1: 7.50	top5: 23.50	
[09/26 06:29:32 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.41728265158971456
[09/26 06:29:39 visual_prompt]: Epoch 35 / 100: avg data time: 6.49e-02, avg batch time: 0.5080, average train loss: 3.2262
[09/26 06:29:41 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1676, average loss: 4.2086
[09/26 06:29:41 visual_prompt]: Classification results with val_vtab-sun397: top1: 25.00	top5: 48.00	
[09/26 06:29:41 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.4106969024216348
[09/26 06:29:48 visual_prompt]: Epoch 36 / 100: avg data time: 6.30e-02, avg batch time: 0.5062, average train loss: 2.7461
[09/26 06:29:49 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1673, average loss: 3.9794
[09/26 06:29:49 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.50	top5: 57.50	
[09/26 06:29:49 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.40391536883141455
[09/26 06:29:56 visual_prompt]: Epoch 37 / 100: avg data time: 6.55e-02, avg batch time: 0.5092, average train loss: 2.4002
[09/26 06:29:58 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1672, average loss: 3.8398
[09/26 06:29:58 visual_prompt]: Classification results with val_vtab-sun397: top1: 31.50	top5: 61.50	
[09/26 06:29:58 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.3969463130731183
[09/26 06:30:05 visual_prompt]: Epoch 38 / 100: avg data time: 6.09e-02, avg batch time: 0.5039, average train loss: 2.3433
[09/26 06:30:06 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1670, average loss: 3.8259
[09/26 06:30:06 visual_prompt]: Classification results with val_vtab-sun397: top1: 34.50	top5: 59.50	
[09/26 06:30:06 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.3897982258676867
[09/26 06:30:13 visual_prompt]: Epoch 39 / 100: avg data time: 6.60e-02, avg batch time: 0.5095, average train loss: 2.5081
[09/26 06:30:15 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1674, average loss: 3.9204
[09/26 06:30:15 visual_prompt]: Classification results with val_vtab-sun397: top1: 30.50	top5: 59.00	
[09/26 06:30:15 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.3824798160583012
[09/26 06:30:22 visual_prompt]: Epoch 40 / 100: avg data time: 6.29e-02, avg batch time: 0.5059, average train loss: 2.1939
[09/26 06:30:23 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1675, average loss: 3.9210
[09/26 06:30:23 visual_prompt]: Classification results with val_vtab-sun397: top1: 30.50	top5: 56.50	
[09/26 06:30:23 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.375
[09/26 06:30:30 visual_prompt]: Epoch 41 / 100: avg data time: 6.61e-02, avg batch time: 0.5103, average train loss: 2.0242
[09/26 06:30:32 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1673, average loss: 3.6965
[09/26 06:30:32 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.00	top5: 63.00	
[09/26 06:30:32 visual_prompt]: Best epoch 41: best metric: 0.380
[09/26 06:30:32 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.3673678906964727
[09/26 06:30:39 visual_prompt]: Epoch 42 / 100: avg data time: 6.54e-02, avg batch time: 0.5102, average train loss: 1.8854
[09/26 06:30:41 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1673, average loss: 3.6203
[09/26 06:30:41 visual_prompt]: Classification results with val_vtab-sun397: top1: 40.00	top5: 65.00	
[09/26 06:30:41 visual_prompt]: Best epoch 42: best metric: 0.400
[09/26 06:30:41 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.35959278669726935
[09/26 06:30:48 visual_prompt]: Epoch 43 / 100: avg data time: 5.57e-02, avg batch time: 0.4996, average train loss: 1.8416
[09/26 06:30:49 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.1674, average loss: 3.7119
[09/26 06:30:49 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.50	top5: 63.50	
[09/26 06:30:49 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.3516841607689501
[09/26 06:30:56 visual_prompt]: Epoch 44 / 100: avg data time: 6.04e-02, avg batch time: 0.5037, average train loss: 1.8447
[09/26 06:30:58 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1674, average loss: 3.6567
[09/26 06:30:58 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.00	top5: 65.50	
[09/26 06:30:58 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.34365164835397805
[09/26 06:31:04 visual_prompt]: Epoch 45 / 100: avg data time: 5.39e-02, avg batch time: 0.4974, average train loss: 1.8665
[09/26 06:31:06 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1672, average loss: 3.6204
[09/26 06:31:06 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.50	top5: 67.00	
[09/26 06:31:06 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.3355050358314172
[09/26 06:31:13 visual_prompt]: Epoch 46 / 100: avg data time: 6.57e-02, avg batch time: 0.5091, average train loss: 1.8604
[09/26 06:31:15 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1674, average loss: 4.0820
[09/26 06:31:15 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.00	top5: 57.00	
[09/26 06:31:15 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.32725424859373686
[09/26 06:31:21 visual_prompt]: Epoch 47 / 100: avg data time: 4.82e-02, avg batch time: 0.4933, average train loss: 1.9254
[09/26 06:31:23 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1678, average loss: 3.7861
[09/26 06:31:23 visual_prompt]: Classification results with val_vtab-sun397: top1: 34.00	top5: 63.50	
[09/26 06:31:23 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.3189093389542498
[09/26 06:31:30 visual_prompt]: Epoch 48 / 100: avg data time: 6.21e-02, avg batch time: 0.5054, average train loss: 1.9007
[09/26 06:31:32 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1676, average loss: 3.6157
[09/26 06:31:32 visual_prompt]: Classification results with val_vtab-sun397: top1: 40.00	top5: 66.00	
[09/26 06:31:32 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.3104804738999169
[09/26 06:31:39 visual_prompt]: Epoch 49 / 100: avg data time: 6.13e-02, avg batch time: 0.5059, average train loss: 1.7434
[09/26 06:31:40 visual_prompt]: Inference (val):avg data time: 5.24e-05, avg batch time: 0.1675, average loss: 3.6276
[09/26 06:31:40 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.00	top5: 63.50	
[09/26 06:31:40 visual_prompt]: Best epoch 49: best metric: 0.410
[09/26 06:31:40 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.3019779227044398
[09/26 06:31:47 visual_prompt]: Epoch 50 / 100: avg data time: 5.47e-02, avg batch time: 0.4986, average train loss: 1.7096
[09/26 06:31:49 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1674, average loss: 3.5856
[09/26 06:31:49 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.00	top5: 67.00	
[09/26 06:31:49 visual_prompt]: Best epoch 50: best metric: 0.420
[09/26 06:31:49 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.29341204441673263
[09/26 06:31:56 visual_prompt]: Epoch 51 / 100: avg data time: 6.24e-02, avg batch time: 0.5061, average train loss: 1.7840
[09/26 06:31:57 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1672, average loss: 4.0886
[09/26 06:31:57 visual_prompt]: Classification results with val_vtab-sun397: top1: 30.50	top5: 57.50	
[09/26 06:31:57 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.28479327524001635
[09/26 06:32:04 visual_prompt]: Epoch 52 / 100: avg data time: 6.00e-02, avg batch time: 0.5033, average train loss: 2.4916
[09/26 06:32:06 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1676, average loss: 3.7499
[09/26 06:32:06 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.50	top5: 64.00	
[09/26 06:32:06 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.2761321158169134
[09/26 06:32:13 visual_prompt]: Epoch 53 / 100: avg data time: 5.82e-02, avg batch time: 0.5022, average train loss: 2.3297
[09/26 06:32:14 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1675, average loss: 4.0974
[09/26 06:32:14 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.50	top5: 58.00	
[09/26 06:32:14 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.2674391184360313
[09/26 06:32:21 visual_prompt]: Epoch 54 / 100: avg data time: 4.63e-02, avg batch time: 0.4916, average train loss: 2.0274
[09/26 06:32:22 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1675, average loss: 3.6525
[09/26 06:32:22 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 63.50	
[09/26 06:32:22 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.2587248741756253
[09/26 06:32:29 visual_prompt]: Epoch 55 / 100: avg data time: 4.71e-02, avg batch time: 0.4941, average train loss: 1.8106
[09/26 06:32:31 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1674, average loss: 3.7844
[09/26 06:32:31 visual_prompt]: Classification results with val_vtab-sun397: top1: 35.50	top5: 60.00	
[09/26 06:32:31 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.25
[09/26 06:32:38 visual_prompt]: Epoch 56 / 100: avg data time: 5.56e-02, avg batch time: 0.4996, average train loss: 1.7505
[09/26 06:32:39 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1676, average loss: 5.1055
[09/26 06:32:39 visual_prompt]: Classification results with val_vtab-sun397: top1: 23.50	top5: 46.50	
[09/26 06:32:39 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.24127512582437483
[09/26 06:32:46 visual_prompt]: Epoch 57 / 100: avg data time: 5.61e-02, avg batch time: 0.5001, average train loss: 2.7732
[09/26 06:32:48 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1671, average loss: 3.7904
[09/26 06:32:48 visual_prompt]: Classification results with val_vtab-sun397: top1: 35.00	top5: 66.50	
[09/26 06:32:48 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.23256088156396867
[09/26 06:32:55 visual_prompt]: Epoch 58 / 100: avg data time: 5.27e-02, avg batch time: 0.4974, average train loss: 2.1108
[09/26 06:32:56 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1675, average loss: 3.7542
[09/26 06:32:56 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.50	top5: 64.50	
[09/26 06:32:56 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.22386788418308667
[09/26 06:33:03 visual_prompt]: Epoch 59 / 100: avg data time: 6.38e-02, avg batch time: 0.5074, average train loss: 1.8570
[09/26 06:33:05 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1677, average loss: 3.6542
[09/26 06:33:05 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.00	top5: 65.50	
[09/26 06:33:05 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.2152067247599837
[09/26 06:33:12 visual_prompt]: Epoch 60 / 100: avg data time: 6.54e-02, avg batch time: 0.5089, average train loss: 1.7422
[09/26 06:33:13 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1674, average loss: 3.6320
[09/26 06:33:13 visual_prompt]: Classification results with val_vtab-sun397: top1: 40.50	top5: 64.50	
[09/26 06:33:13 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.20658795558326742
[09/26 06:33:20 visual_prompt]: Epoch 61 / 100: avg data time: 6.14e-02, avg batch time: 0.5060, average train loss: 1.6610
[09/26 06:33:22 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1676, average loss: 3.6081
[09/26 06:33:22 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.50	top5: 65.00	
[09/26 06:33:22 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.1980220772955602
[09/26 06:33:29 visual_prompt]: Epoch 62 / 100: avg data time: 5.96e-02, avg batch time: 0.5032, average train loss: 1.5942
[09/26 06:33:30 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1676, average loss: 3.6014
[09/26 06:33:30 visual_prompt]: Classification results with val_vtab-sun397: top1: 40.50	top5: 65.00	
[09/26 06:33:30 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.1895195261000831
[09/26 06:33:37 visual_prompt]: Epoch 63 / 100: avg data time: 5.84e-02, avg batch time: 0.5024, average train loss: 1.5626
[09/26 06:33:39 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1671, average loss: 3.6371
[09/26 06:33:39 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.50	top5: 66.00	
[09/26 06:33:39 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.18109066104575022
[09/26 06:33:46 visual_prompt]: Epoch 64 / 100: avg data time: 6.11e-02, avg batch time: 0.5041, average train loss: 1.5817
[09/26 06:33:47 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1673, average loss: 3.6157
[09/26 06:33:47 visual_prompt]: Classification results with val_vtab-sun397: top1: 40.50	top5: 64.50	
[09/26 06:33:47 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.17274575140626316
[09/26 06:33:54 visual_prompt]: Epoch 65 / 100: avg data time: 5.92e-02, avg batch time: 0.5029, average train loss: 1.6206
[09/26 06:33:56 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1673, average loss: 3.5953
[09/26 06:33:56 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.00	top5: 66.00	
[09/26 06:33:56 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.16449496416858284
[09/26 06:34:02 visual_prompt]: Epoch 66 / 100: avg data time: 6.14e-02, avg batch time: 0.5056, average train loss: 1.5744
[09/26 06:34:04 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1675, average loss: 3.6546
[09/26 06:34:04 visual_prompt]: Classification results with val_vtab-sun397: top1: 44.50	top5: 64.50	
[09/26 06:34:04 visual_prompt]: Best epoch 66: best metric: 0.445
[09/26 06:34:04 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.15634835164602198
[09/26 06:34:11 visual_prompt]: Epoch 67 / 100: avg data time: 6.82e-02, avg batch time: 0.5116, average train loss: 1.5426
[09/26 06:34:13 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1670, average loss: 3.6060
[09/26 06:34:13 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.00	top5: 66.50	
[09/26 06:34:13 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.14831583923105
[09/26 06:34:19 visual_prompt]: Epoch 68 / 100: avg data time: 5.75e-02, avg batch time: 0.5016, average train loss: 1.5070
[09/26 06:34:21 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1672, average loss: 3.6053
[09/26 06:34:21 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.50	top5: 68.00	
[09/26 06:34:21 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.14040721330273062
[09/26 06:34:28 visual_prompt]: Epoch 69 / 100: avg data time: 5.81e-02, avg batch time: 0.5023, average train loss: 1.4590
[09/26 06:34:30 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1675, average loss: 3.5742
[09/26 06:34:30 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.00	top5: 66.50	
[09/26 06:34:30 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.13263210930352737
[09/26 06:34:36 visual_prompt]: Epoch 70 / 100: avg data time: 5.94e-02, avg batch time: 0.5060, average train loss: 1.4441
[09/26 06:34:38 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1673, average loss: 3.6565
[09/26 06:34:38 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.00	top5: 65.50	
[09/26 06:34:38 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.12500000000000006
[09/26 06:34:45 visual_prompt]: Epoch 71 / 100: avg data time: 5.79e-02, avg batch time: 0.5030, average train loss: 1.4408
[09/26 06:34:47 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.1674, average loss: 3.5865
[09/26 06:34:47 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.50	top5: 66.00	
[09/26 06:34:47 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.1175201839416988
[09/26 06:34:53 visual_prompt]: Epoch 72 / 100: avg data time: 5.95e-02, avg batch time: 0.5031, average train loss: 1.4013
[09/26 06:34:55 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1676, average loss: 3.6135
[09/26 06:34:55 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.50	top5: 63.50	
[09/26 06:34:55 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.11020177413231333
[09/26 06:35:02 visual_prompt]: Epoch 73 / 100: avg data time: 6.01e-02, avg batch time: 0.5035, average train loss: 1.3684
[09/26 06:35:04 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1671, average loss: 3.6032
[09/26 06:35:04 visual_prompt]: Classification results with val_vtab-sun397: top1: 40.50	top5: 65.00	
[09/26 06:35:04 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.10305368692688174
[09/26 06:35:10 visual_prompt]: Epoch 74 / 100: avg data time: 6.06e-02, avg batch time: 0.5036, average train loss: 1.3608
[09/26 06:35:12 visual_prompt]: Inference (val):avg data time: 3.41e-05, avg batch time: 0.1672, average loss: 3.5628
[09/26 06:35:12 visual_prompt]: Classification results with val_vtab-sun397: top1: 43.00	top5: 67.00	
[09/26 06:35:12 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.09608463116858543
[09/26 06:35:19 visual_prompt]: Epoch 75 / 100: avg data time: 6.27e-02, avg batch time: 0.5070, average train loss: 1.3401
[09/26 06:35:21 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1672, average loss: 3.5608
[09/26 06:35:21 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.00	top5: 67.00	
[09/26 06:35:21 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.08930309757836516
[09/26 06:35:28 visual_prompt]: Epoch 76 / 100: avg data time: 6.15e-02, avg batch time: 0.5051, average train loss: 1.3180
[09/26 06:35:29 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1671, average loss: 3.6006
[09/26 06:35:29 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.00	top5: 64.00	
[09/26 06:35:29 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.08271734841028552
[09/26 06:35:36 visual_prompt]: Epoch 77 / 100: avg data time: 5.87e-02, avg batch time: 0.5015, average train loss: 1.3067
[09/26 06:35:38 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1674, average loss: 3.5498
[09/26 06:35:38 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.50	top5: 66.50	
[09/26 06:35:38 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.07633540738525066
[09/26 06:35:44 visual_prompt]: Epoch 78 / 100: avg data time: 5.32e-02, avg batch time: 0.4971, average train loss: 1.2864
[09/26 06:35:46 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1672, average loss: 3.5606
[09/26 06:35:46 visual_prompt]: Classification results with val_vtab-sun397: top1: 43.50	top5: 64.50	
[09/26 06:35:46 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.07016504991533726
[09/26 06:35:53 visual_prompt]: Epoch 79 / 100: avg data time: 5.94e-02, avg batch time: 0.5034, average train loss: 1.2843
[09/26 06:35:54 visual_prompt]: Inference (val):avg data time: 3.94e-05, avg batch time: 0.1671, average loss: 3.5461
[09/26 06:35:54 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.50	top5: 66.50	
[09/26 06:35:54 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.06421379363065141
[09/26 06:36:01 visual_prompt]: Epoch 80 / 100: avg data time: 5.66e-02, avg batch time: 0.5010, average train loss: 1.2736
[09/26 06:36:03 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1673, average loss: 3.5656
[09/26 06:36:03 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.00	top5: 66.50	
[09/26 06:36:03 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.058488889220255524
[09/26 06:36:10 visual_prompt]: Epoch 81 / 100: avg data time: 5.40e-02, avg batch time: 0.4983, average train loss: 1.2395
[09/26 06:36:11 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1673, average loss: 3.5121
[09/26 06:36:11 visual_prompt]: Classification results with val_vtab-sun397: top1: 45.00	top5: 67.00	
[09/26 06:36:11 visual_prompt]: Best epoch 81: best metric: 0.450
[09/26 06:36:11 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.052997311598319524
[09/26 06:36:18 visual_prompt]: Epoch 82 / 100: avg data time: 6.01e-02, avg batch time: 0.5038, average train loss: 1.2171
[09/26 06:36:20 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1673, average loss: 3.5244
[09/26 06:36:20 visual_prompt]: Classification results with val_vtab-sun397: top1: 43.00	top5: 67.00	
[09/26 06:36:20 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.047745751406263165
[09/26 06:36:27 visual_prompt]: Epoch 83 / 100: avg data time: 5.02e-02, avg batch time: 0.4935, average train loss: 1.1921
[09/26 06:36:28 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1672, average loss: 3.5323
[09/26 06:36:28 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.00	top5: 68.50	
[09/26 06:36:28 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.042740606861239594
[09/26 06:36:35 visual_prompt]: Epoch 84 / 100: avg data time: 5.83e-02, avg batch time: 0.5023, average train loss: 1.1701
[09/26 06:36:37 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1676, average loss: 3.5226
[09/26 06:36:37 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.50	top5: 67.50	
[09/26 06:36:37 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.03798797596089351
[09/26 06:36:44 visual_prompt]: Epoch 85 / 100: avg data time: 6.12e-02, avg batch time: 0.5048, average train loss: 1.1595
[09/26 06:36:45 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1676, average loss: 3.5108
[09/26 06:36:45 visual_prompt]: Classification results with val_vtab-sun397: top1: 44.00	top5: 68.50	
[09/26 06:36:45 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.03349364905389032
[09/26 06:36:52 visual_prompt]: Epoch 86 / 100: avg data time: 6.37e-02, avg batch time: 0.5080, average train loss: 1.1549
[09/26 06:36:54 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1676, average loss: 3.5161
[09/26 06:36:54 visual_prompt]: Classification results with val_vtab-sun397: top1: 44.00	top5: 69.50	
[09/26 06:36:54 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.029263101785268253
[09/26 06:37:01 visual_prompt]: Epoch 87 / 100: avg data time: 6.70e-02, avg batch time: 0.5111, average train loss: 1.1455
[09/26 06:37:02 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1673, average loss: 3.4901
[09/26 06:37:02 visual_prompt]: Classification results with val_vtab-sun397: top1: 44.50	top5: 68.50	
[09/26 06:37:02 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.025301488425208296
[09/26 06:37:09 visual_prompt]: Epoch 88 / 100: avg data time: 6.58e-02, avg batch time: 0.5095, average train loss: 1.1261
[09/26 06:37:11 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1672, average loss: 3.5229
[09/26 06:37:11 visual_prompt]: Classification results with val_vtab-sun397: top1: 43.50	top5: 69.00	
[09/26 06:37:11 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.021613635589349756
[09/26 06:37:18 visual_prompt]: Epoch 89 / 100: avg data time: 6.13e-02, avg batch time: 0.5054, average train loss: 1.1122
[09/26 06:37:20 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1678, average loss: 3.5139
[09/26 06:37:20 visual_prompt]: Classification results with val_vtab-sun397: top1: 44.00	top5: 68.50	
[09/26 06:37:20 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.01820403635830317
[09/26 06:37:26 visual_prompt]: Epoch 90 / 100: avg data time: 5.94e-02, avg batch time: 0.5028, average train loss: 1.1036
[09/26 06:37:28 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1676, average loss: 3.5233
[09/26 06:37:28 visual_prompt]: Classification results with val_vtab-sun397: top1: 45.00	top5: 67.50	
[09/26 06:37:28 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.01507684480352292
[09/26 06:37:35 visual_prompt]: Epoch 91 / 100: avg data time: 4.77e-02, avg batch time: 0.4920, average train loss: 1.0957
[09/26 06:37:36 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1675, average loss: 3.5285
[09/26 06:37:36 visual_prompt]: Classification results with val_vtab-sun397: top1: 44.50	top5: 68.00	
[09/26 06:37:36 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.012235870926211617
[09/26 06:37:43 visual_prompt]: Epoch 92 / 100: avg data time: 6.54e-02, avg batch time: 0.5108, average train loss: 1.0844
[09/26 06:37:45 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1679, average loss: 3.5224
[09/26 06:37:45 visual_prompt]: Classification results with val_vtab-sun397: top1: 44.50	top5: 68.00	
[09/26 06:37:45 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.009684576015420276
[09/26 06:37:52 visual_prompt]: Epoch 93 / 100: avg data time: 6.92e-02, avg batch time: 0.5126, average train loss: 1.0761
[09/26 06:37:53 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1675, average loss: 3.5191
[09/26 06:37:53 visual_prompt]: Classification results with val_vtab-sun397: top1: 44.00	top5: 67.50	
[09/26 06:37:53 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.007426068431000882
[09/26 06:38:00 visual_prompt]: Epoch 94 / 100: avg data time: 6.35e-02, avg batch time: 0.5090, average train loss: 1.0705
[09/26 06:38:02 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1677, average loss: 3.5044
[09/26 06:38:02 visual_prompt]: Classification results with val_vtab-sun397: top1: 45.50	top5: 68.00	
[09/26 06:38:02 visual_prompt]: Best epoch 94: best metric: 0.455
[09/26 06:38:02 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.005463099816548578
[09/26 06:38:09 visual_prompt]: Epoch 95 / 100: avg data time: 6.17e-02, avg batch time: 0.5050, average train loss: 1.0648
[09/26 06:38:10 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1676, average loss: 3.5078
[09/26 06:38:10 visual_prompt]: Classification results with val_vtab-sun397: top1: 44.50	top5: 68.00	
[09/26 06:38:10 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.003798061746947995
[09/26 06:38:17 visual_prompt]: Epoch 96 / 100: avg data time: 6.28e-02, avg batch time: 0.5062, average train loss: 1.0609
[09/26 06:38:19 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1673, average loss: 3.5127
[09/26 06:38:19 visual_prompt]: Classification results with val_vtab-sun397: top1: 45.00	top5: 68.00	
[09/26 06:38:19 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.0024329828146074095
[09/26 06:38:26 visual_prompt]: Epoch 97 / 100: avg data time: 6.28e-02, avg batch time: 0.5073, average train loss: 1.0588
[09/26 06:38:28 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1676, average loss: 3.5069
[09/26 06:38:28 visual_prompt]: Classification results with val_vtab-sun397: top1: 45.50	top5: 68.00	
[09/26 06:38:28 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.0013695261579316775
[09/26 06:38:34 visual_prompt]: Epoch 98 / 100: avg data time: 6.12e-02, avg batch time: 0.5045, average train loss: 1.0566
[09/26 06:38:36 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1673, average loss: 3.5111
[09/26 06:38:36 visual_prompt]: Classification results with val_vtab-sun397: top1: 45.50	top5: 68.00	
[09/26 06:38:36 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.0006089874350439506
[09/26 06:38:43 visual_prompt]: Epoch 99 / 100: avg data time: 6.31e-02, avg batch time: 0.5066, average train loss: 1.0550
[09/26 06:38:45 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1674, average loss: 3.5103
[09/26 06:38:45 visual_prompt]: Classification results with val_vtab-sun397: top1: 45.50	top5: 68.00	
[09/26 06:38:45 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.00015229324522605947
[09/26 06:38:52 visual_prompt]: Epoch 100 / 100: avg data time: 6.15e-02, avg batch time: 0.5049, average train loss: 1.0546
[09/26 06:38:53 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1676, average loss: 3.5097
[09/26 06:38:53 visual_prompt]: Classification results with val_vtab-sun397: top1: 45.50	top5: 68.00	
[09/26 06:38:53 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 06:38:53 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              0
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 06:38:53 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-sun397', 'DATA.NUMBER_CLASSES', '397', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 06:38:53 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 06:38:53 visual_prompt]: Training with config:
[09/26 06:38:53 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-sun397/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.5_wd0.001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 0.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-sun397', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 397, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 06:38:53 visual_prompt]: Loading training data...
[09/26 06:38:53 visual_prompt]: Constructing vtab-sun397 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split train[:800], from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/26 06:38:55 visual_prompt]: Number of images: 800
[09/26 06:38:55 visual_prompt]: Number of classes: 309 / 397
[09/26 06:38:55 visual_prompt]: Loading validation data...
[09/26 06:38:55 visual_prompt]: Constructing vtab-sun397 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split validation[:200], from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/26 06:38:55 visual_prompt]: Number of images: 200
[09/26 06:38:55 visual_prompt]: Number of classes: 136 / 397
[09/26 06:38:55 visual_prompt]: Constructing models...
[09/26 06:38:57 visual_prompt]: Total Parameters: 86564749	 Gradient Parameters: 766093
[09/26 06:38:57 visual_prompt]: tuned percent:0.885
[09/26 06:38:57 visual_prompt]: Device used for model: 0
[09/26 06:38:57 visual_prompt]: Setting up Evaluator...
[09/26 06:38:57 visual_prompt]: Setting up Trainer...
[09/26 06:38:57 visual_prompt]: 	Setting up the optimizer...
[09/26 06:38:57 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 06:39:04 visual_prompt]: Epoch 1 / 100: avg data time: 6.08e-02, avg batch time: 0.5064, average train loss: 5.9887
[09/26 06:39:06 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1668, average loss: 6.0097
[09/26 06:39:06 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/26 06:39:06 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.05
[09/26 06:39:13 visual_prompt]: Epoch 2 / 100: avg data time: 5.82e-02, avg batch time: 0.5010, average train loss: 5.9340
[09/26 06:39:14 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1667, average loss: 5.9141
[09/26 06:39:14 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.00	
[09/26 06:39:14 visual_prompt]: Best epoch 2: best metric: 0.005
[09/26 06:39:14 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.1
[09/26 06:39:21 visual_prompt]: Epoch 3 / 100: avg data time: 6.68e-02, avg batch time: 0.5097, average train loss: 5.7277
[09/26 06:39:23 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1668, average loss: 5.8195
[09/26 06:39:23 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 5.00	
[09/26 06:39:23 visual_prompt]: Best epoch 3: best metric: 0.010
[09/26 06:39:23 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.15
[09/26 06:39:30 visual_prompt]: Epoch 4 / 100: avg data time: 5.98e-02, avg batch time: 0.5035, average train loss: 5.5465
[09/26 06:39:32 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1673, average loss: 5.6712
[09/26 06:39:32 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 9.50	
[09/26 06:39:32 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.2
[09/26 06:39:38 visual_prompt]: Epoch 5 / 100: avg data time: 5.49e-02, avg batch time: 0.4997, average train loss: 5.3330
[09/26 06:39:40 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1676, average loss: 5.4715
[09/26 06:39:40 visual_prompt]: Classification results with val_vtab-sun397: top1: 3.00	top5: 12.00	
[09/26 06:39:40 visual_prompt]: Best epoch 5: best metric: 0.030
[09/26 06:39:40 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.25
[09/26 06:39:47 visual_prompt]: Epoch 6 / 100: avg data time: 6.15e-02, avg batch time: 0.5047, average train loss: 4.9063
[09/26 06:39:49 visual_prompt]: Inference (val):avg data time: 2.08e-05, avg batch time: 0.1677, average loss: 5.1376
[09/26 06:39:49 visual_prompt]: Classification results with val_vtab-sun397: top1: 9.00	top5: 18.00	
[09/26 06:39:49 visual_prompt]: Best epoch 6: best metric: 0.090
[09/26 06:39:49 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.3
[09/26 06:39:55 visual_prompt]: Epoch 7 / 100: avg data time: 6.34e-02, avg batch time: 0.5061, average train loss: 4.3103
[09/26 06:39:57 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1675, average loss: 4.7928
[09/26 06:39:57 visual_prompt]: Classification results with val_vtab-sun397: top1: 11.50	top5: 29.50	
[09/26 06:39:57 visual_prompt]: Best epoch 7: best metric: 0.115
[09/26 06:39:57 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.35
[09/26 06:40:04 visual_prompt]: Epoch 8 / 100: avg data time: 6.13e-02, avg batch time: 0.5045, average train loss: 3.4924
[09/26 06:40:06 visual_prompt]: Inference (val):avg data time: 1.98e-05, avg batch time: 0.1678, average loss: 4.2391
[09/26 06:40:06 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.00	top5: 40.50	
[09/26 06:40:06 visual_prompt]: Best epoch 8: best metric: 0.210
[09/26 06:40:06 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.4
[09/26 06:40:13 visual_prompt]: Epoch 9 / 100: avg data time: 6.04e-02, avg batch time: 0.5038, average train loss: 2.4993
[09/26 06:40:14 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1675, average loss: 3.8119
[09/26 06:40:14 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.50	top5: 48.50	
[09/26 06:40:14 visual_prompt]: Best epoch 9: best metric: 0.285
[09/26 06:40:14 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.45
[09/26 06:40:21 visual_prompt]: Epoch 10 / 100: avg data time: 6.20e-02, avg batch time: 0.5056, average train loss: 1.5881
[09/26 06:40:23 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1674, average loss: 3.5235
[09/26 06:40:23 visual_prompt]: Classification results with val_vtab-sun397: top1: 30.00	top5: 58.50	
[09/26 06:40:23 visual_prompt]: Best epoch 10: best metric: 0.300
[09/26 06:40:23 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.5
[09/26 06:40:29 visual_prompt]: Epoch 11 / 100: avg data time: 5.75e-02, avg batch time: 0.5010, average train loss: 0.8937
[09/26 06:40:31 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1673, average loss: 3.2729
[09/26 06:40:31 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.00	top5: 60.00	
[09/26 06:40:31 visual_prompt]: Best epoch 11: best metric: 0.370
[09/26 06:40:31 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.49984770675477397
[09/26 06:40:38 visual_prompt]: Epoch 12 / 100: avg data time: 5.91e-02, avg batch time: 0.5019, average train loss: 0.4358
[09/26 06:40:40 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.1672, average loss: 3.2018
[09/26 06:40:40 visual_prompt]: Classification results with val_vtab-sun397: top1: 34.50	top5: 63.00	
[09/26 06:40:40 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.49939101256495605
[09/26 06:40:46 visual_prompt]: Epoch 13 / 100: avg data time: 6.40e-02, avg batch time: 0.5071, average train loss: 0.2547
[09/26 06:40:48 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1674, average loss: 3.1197
[09/26 06:40:48 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.50	top5: 63.50	
[09/26 06:40:48 visual_prompt]: Best epoch 13: best metric: 0.375
[09/26 06:40:48 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.4986304738420683
[09/26 06:40:55 visual_prompt]: Epoch 14 / 100: avg data time: 6.35e-02, avg batch time: 0.5074, average train loss: 0.1759
[09/26 06:40:57 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1672, average loss: 3.1107
[09/26 06:40:57 visual_prompt]: Classification results with val_vtab-sun397: top1: 35.00	top5: 65.50	
[09/26 06:40:57 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.4975670171853926
[09/26 06:41:04 visual_prompt]: Epoch 15 / 100: avg data time: 6.28e-02, avg batch time: 0.5070, average train loss: 0.1496
[09/26 06:41:05 visual_prompt]: Inference (val):avg data time: 4.48e-05, avg batch time: 0.1673, average loss: 3.1176
[09/26 06:41:05 visual_prompt]: Classification results with val_vtab-sun397: top1: 35.00	top5: 66.00	
[09/26 06:41:05 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.49620193825305203
[09/26 06:41:12 visual_prompt]: Epoch 16 / 100: avg data time: 4.78e-02, avg batch time: 0.4930, average train loss: 0.1388
[09/26 06:41:14 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1674, average loss: 3.1110
[09/26 06:41:14 visual_prompt]: Classification results with val_vtab-sun397: top1: 35.50	top5: 65.00	
[09/26 06:41:14 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.4945369001834514
[09/26 06:41:20 visual_prompt]: Epoch 17 / 100: avg data time: 5.88e-02, avg batch time: 0.5019, average train loss: 0.1330
[09/26 06:41:22 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1680, average loss: 3.1010
[09/26 06:41:22 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.50	top5: 64.00	
[09/26 06:41:22 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.4925739315689991
[09/26 06:41:29 visual_prompt]: Epoch 18 / 100: avg data time: 6.24e-02, avg batch time: 0.5060, average train loss: 0.1323
[09/26 06:41:31 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1676, average loss: 3.1219
[09/26 06:41:31 visual_prompt]: Classification results with val_vtab-sun397: top1: 36.00	top5: 65.00	
[09/26 06:41:31 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.4903154239845797
[09/26 06:41:38 visual_prompt]: Epoch 19 / 100: avg data time: 6.45e-02, avg batch time: 0.5078, average train loss: 0.1441
[09/26 06:41:39 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1679, average loss: 3.1407
[09/26 06:41:39 visual_prompt]: Classification results with val_vtab-sun397: top1: 35.00	top5: 61.50	
[09/26 06:41:39 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.4877641290737884
[09/26 06:41:46 visual_prompt]: Epoch 20 / 100: avg data time: 6.22e-02, avg batch time: 0.5062, average train loss: 0.1435
[09/26 06:41:48 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.1679, average loss: 3.1353
[09/26 06:41:48 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.50	top5: 65.00	
[09/26 06:41:48 visual_prompt]: Best epoch 20: best metric: 0.395
[09/26 06:41:48 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.4849231551964771
[09/26 06:41:55 visual_prompt]: Epoch 21 / 100: avg data time: 6.37e-02, avg batch time: 0.5075, average train loss: 0.1496
[09/26 06:41:56 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1676, average loss: 3.2031
[09/26 06:41:56 visual_prompt]: Classification results with val_vtab-sun397: top1: 35.50	top5: 62.50	
[09/26 06:41:56 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.48179596364169686
[09/26 06:42:03 visual_prompt]: Epoch 22 / 100: avg data time: 6.47e-02, avg batch time: 0.5088, average train loss: 0.1486
[09/26 06:42:05 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1676, average loss: 3.1588
[09/26 06:42:05 visual_prompt]: Classification results with val_vtab-sun397: top1: 35.00	top5: 64.50	
[09/26 06:42:05 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.4783863644106502
[09/26 06:42:12 visual_prompt]: Epoch 23 / 100: avg data time: 6.20e-02, avg batch time: 0.5055, average train loss: 0.1445
[09/26 06:42:14 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1678, average loss: 3.1840
[09/26 06:42:14 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.00	top5: 65.50	
[09/26 06:42:14 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.47469851157479176
[09/26 06:42:21 visual_prompt]: Epoch 24 / 100: avg data time: 6.28e-02, avg batch time: 0.5065, average train loss: 0.1437
[09/26 06:42:22 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1679, average loss: 3.2099
[09/26 06:42:22 visual_prompt]: Classification results with val_vtab-sun397: top1: 35.50	top5: 64.00	
[09/26 06:42:22 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.47073689821473175
[09/26 06:42:29 visual_prompt]: Epoch 25 / 100: avg data time: 5.71e-02, avg batch time: 0.5029, average train loss: 0.1469
[09/26 06:42:31 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1678, average loss: 3.2235
[09/26 06:42:31 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.50	top5: 63.00	
[09/26 06:42:31 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.4665063509461097
[09/26 06:42:37 visual_prompt]: Epoch 26 / 100: avg data time: 5.86e-02, avg batch time: 0.5015, average train loss: 0.1502
[09/26 06:42:39 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1676, average loss: 3.1697
[09/26 06:42:39 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 61.50	
[09/26 06:42:39 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.46201202403910646
[09/26 06:42:46 visual_prompt]: Epoch 27 / 100: avg data time: 4.78e-02, avg batch time: 0.4940, average train loss: 0.1447
[09/26 06:42:47 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1675, average loss: 3.1783
[09/26 06:42:47 visual_prompt]: Classification results with val_vtab-sun397: top1: 35.00	top5: 64.50	
[09/26 06:42:47 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.4572593931387604
[09/26 06:42:54 visual_prompt]: Epoch 28 / 100: avg data time: 6.32e-02, avg batch time: 0.5072, average train loss: 0.1418
[09/26 06:42:56 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1677, average loss: 3.1471
[09/26 06:42:56 visual_prompt]: Classification results with val_vtab-sun397: top1: 34.00	top5: 66.00	
[09/26 06:42:56 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.45225424859373686
[09/26 06:43:03 visual_prompt]: Epoch 29 / 100: avg data time: 5.61e-02, avg batch time: 0.4996, average train loss: 0.1325
[09/26 06:43:04 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1678, average loss: 3.1231
[09/26 06:43:04 visual_prompt]: Classification results with val_vtab-sun397: top1: 36.00	top5: 68.00	
[09/26 06:43:04 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.44700268840168045
[09/26 06:43:11 visual_prompt]: Epoch 30 / 100: avg data time: 6.26e-02, avg batch time: 0.5066, average train loss: 0.1256
[09/26 06:43:13 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1679, average loss: 3.1492
[09/26 06:43:13 visual_prompt]: Classification results with val_vtab-sun397: top1: 35.50	top5: 66.50	
[09/26 06:43:13 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.4415111107797445
[09/26 06:43:20 visual_prompt]: Epoch 31 / 100: avg data time: 6.27e-02, avg batch time: 0.5060, average train loss: 0.1222
[09/26 06:43:21 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1680, average loss: 3.2138
[09/26 06:43:21 visual_prompt]: Classification results with val_vtab-sun397: top1: 35.00	top5: 66.00	
[09/26 06:43:21 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.43578620636934856
[09/26 06:43:28 visual_prompt]: Epoch 32 / 100: avg data time: 6.14e-02, avg batch time: 0.5054, average train loss: 0.1306
[09/26 06:43:30 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1680, average loss: 3.2348
[09/26 06:43:30 visual_prompt]: Classification results with val_vtab-sun397: top1: 35.00	top5: 65.50	
[09/26 06:43:30 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.42983495008466277
[09/26 06:43:37 visual_prompt]: Epoch 33 / 100: avg data time: 6.23e-02, avg batch time: 0.5070, average train loss: 0.1339
[09/26 06:43:39 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1672, average loss: 3.1981
[09/26 06:43:39 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.00	top5: 66.00	
[09/26 06:43:39 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.4236645926147493
[09/26 06:43:45 visual_prompt]: Epoch 34 / 100: avg data time: 6.07e-02, avg batch time: 0.5037, average train loss: 0.1454
[09/26 06:43:47 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1672, average loss: 3.2758
[09/26 06:43:47 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.00	top5: 65.50	
[09/26 06:43:47 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.41728265158971456
[09/26 06:43:54 visual_prompt]: Epoch 35 / 100: avg data time: 4.68e-02, avg batch time: 0.4912, average train loss: 0.1665
[09/26 06:43:55 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1673, average loss: 3.2307
[09/26 06:43:55 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.00	top5: 63.50	
[09/26 06:43:55 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.4106969024216348
[09/26 06:44:02 visual_prompt]: Epoch 36 / 100: avg data time: 6.24e-02, avg batch time: 0.5065, average train loss: 0.2092
[09/26 06:44:04 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1675, average loss: 3.2252
[09/26 06:44:04 visual_prompt]: Classification results with val_vtab-sun397: top1: 36.00	top5: 67.50	
[09/26 06:44:04 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.40391536883141455
[09/26 06:44:11 visual_prompt]: Epoch 37 / 100: avg data time: 6.18e-02, avg batch time: 0.5050, average train loss: 0.2722
[09/26 06:44:12 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1674, average loss: 3.1439
[09/26 06:44:12 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 66.00	
[09/26 06:44:12 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.3969463130731183
[09/26 06:44:19 visual_prompt]: Epoch 38 / 100: avg data time: 5.92e-02, avg batch time: 0.5037, average train loss: 0.2134
[09/26 06:44:21 visual_prompt]: Inference (val):avg data time: 3.61e-05, avg batch time: 0.1673, average loss: 3.1992
[09/26 06:44:21 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.00	top5: 64.50	
[09/26 06:44:21 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.3897982258676867
[09/26 06:44:28 visual_prompt]: Epoch 39 / 100: avg data time: 6.08e-02, avg batch time: 0.5053, average train loss: 0.1671
[09/26 06:44:29 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1673, average loss: 3.1519
[09/26 06:44:29 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.00	top5: 66.00	
[09/26 06:44:29 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.3824798160583012
[09/26 06:44:36 visual_prompt]: Epoch 40 / 100: avg data time: 6.66e-02, avg batch time: 0.5092, average train loss: 0.1225
[09/26 06:44:38 visual_prompt]: Inference (val):avg data time: 4.02e-05, avg batch time: 0.1674, average loss: 3.0703
[09/26 06:44:38 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.00	top5: 65.00	
[09/26 06:44:38 visual_prompt]: Best epoch 40: best metric: 0.420
[09/26 06:44:38 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.375
[09/26 06:44:45 visual_prompt]: Epoch 41 / 100: avg data time: 6.82e-02, avg batch time: 0.5126, average train loss: 0.1003
[09/26 06:44:47 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1672, average loss: 3.0993
[09/26 06:44:47 visual_prompt]: Classification results with val_vtab-sun397: top1: 40.50	top5: 65.00	
[09/26 06:44:47 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.3673678906964727
[09/26 06:44:53 visual_prompt]: Epoch 42 / 100: avg data time: 6.31e-02, avg batch time: 0.5064, average train loss: 0.0928
[09/26 06:44:55 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1673, average loss: 3.0804
[09/26 06:44:55 visual_prompt]: Classification results with val_vtab-sun397: top1: 40.50	top5: 66.00	
[09/26 06:44:55 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.35959278669726935
[09/26 06:45:02 visual_prompt]: Epoch 43 / 100: avg data time: 6.30e-02, avg batch time: 0.5079, average train loss: 0.0936
[09/26 06:45:04 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1676, average loss: 3.1157
[09/26 06:45:04 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.50	top5: 66.50	
[09/26 06:45:04 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.3516841607689501
[09/26 06:45:11 visual_prompt]: Epoch 44 / 100: avg data time: 6.09e-02, avg batch time: 0.5038, average train loss: 0.0946
[09/26 06:45:12 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1671, average loss: 3.1053
[09/26 06:45:12 visual_prompt]: Classification results with val_vtab-sun397: top1: 40.00	top5: 68.50	
[09/26 06:45:12 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.34365164835397805
[09/26 06:45:19 visual_prompt]: Epoch 45 / 100: avg data time: 6.46e-02, avg batch time: 0.5088, average train loss: 0.0968
[09/26 06:45:21 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1675, average loss: 3.1134
[09/26 06:45:21 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.00	top5: 69.00	
[09/26 06:45:21 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.3355050358314172
[09/26 06:45:28 visual_prompt]: Epoch 46 / 100: avg data time: 6.24e-02, avg batch time: 0.5057, average train loss: 0.0997
[09/26 06:45:29 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1673, average loss: 3.1248
[09/26 06:45:29 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 69.00	
[09/26 06:45:29 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.32725424859373686
[09/26 06:45:36 visual_prompt]: Epoch 47 / 100: avg data time: 5.93e-02, avg batch time: 0.5034, average train loss: 0.1018
[09/26 06:45:38 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1678, average loss: 3.1257
[09/26 06:45:38 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.50	top5: 68.50	
[09/26 06:45:38 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.3189093389542498
[09/26 06:45:45 visual_prompt]: Epoch 48 / 100: avg data time: 6.28e-02, avg batch time: 0.5058, average train loss: 0.1039
[09/26 06:45:46 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1672, average loss: 3.1490
[09/26 06:45:46 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 67.00	
[09/26 06:45:46 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.3104804738999169
[09/26 06:45:53 visual_prompt]: Epoch 49 / 100: avg data time: 6.43e-02, avg batch time: 0.5074, average train loss: 0.1047
[09/26 06:45:55 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1670, average loss: 3.1360
[09/26 06:45:55 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 68.00	
[09/26 06:45:55 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.3019779227044398
[09/26 06:46:02 visual_prompt]: Epoch 50 / 100: avg data time: 6.00e-02, avg batch time: 0.5040, average train loss: 0.1059
[09/26 06:46:03 visual_prompt]: Inference (val):avg data time: 4.29e-05, avg batch time: 0.1672, average loss: 3.1661
[09/26 06:46:03 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.50	top5: 67.50	
[09/26 06:46:03 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.29341204441673263
[09/26 06:46:10 visual_prompt]: Epoch 51 / 100: avg data time: 6.45e-02, avg batch time: 0.5076, average train loss: 0.1075
[09/26 06:46:12 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1672, average loss: 3.1784
[09/26 06:46:12 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 67.00	
[09/26 06:46:12 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.28479327524001635
[09/26 06:46:19 visual_prompt]: Epoch 52 / 100: avg data time: 5.64e-02, avg batch time: 0.4991, average train loss: 0.1089
[09/26 06:46:20 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1673, average loss: 3.1607
[09/26 06:46:20 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 69.00	
[09/26 06:46:20 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.2761321158169134
[09/26 06:46:27 visual_prompt]: Epoch 53 / 100: avg data time: 6.21e-02, avg batch time: 0.5058, average train loss: 0.1090
[09/26 06:46:29 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1672, average loss: 3.1773
[09/26 06:46:29 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.00	top5: 68.50	
[09/26 06:46:29 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.2674391184360313
[09/26 06:46:36 visual_prompt]: Epoch 54 / 100: avg data time: 6.30e-02, avg batch time: 0.5069, average train loss: 0.1074
[09/26 06:46:37 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1676, average loss: 3.1583
[09/26 06:46:37 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 68.50	
[09/26 06:46:37 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.2587248741756253
[09/26 06:46:44 visual_prompt]: Epoch 55 / 100: avg data time: 5.65e-02, avg batch time: 0.5010, average train loss: 0.1058
[09/26 06:46:46 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1681, average loss: 3.1650
[09/26 06:46:46 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 68.00	
[09/26 06:46:46 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.25
[09/26 06:46:53 visual_prompt]: Epoch 56 / 100: avg data time: 6.22e-02, avg batch time: 0.5052, average train loss: 0.1056
[09/26 06:46:54 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1676, average loss: 3.1882
[09/26 06:46:54 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.50	top5: 67.00	
[09/26 06:46:54 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.24127512582437483
[09/26 06:47:01 visual_prompt]: Epoch 57 / 100: avg data time: 6.75e-02, avg batch time: 0.5104, average train loss: 0.1065
[09/26 06:47:03 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1677, average loss: 3.1908
[09/26 06:47:03 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.00	top5: 67.00	
[09/26 06:47:03 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.23256088156396867
[09/26 06:47:10 visual_prompt]: Epoch 58 / 100: avg data time: 5.90e-02, avg batch time: 0.5039, average train loss: 0.1068
[09/26 06:47:11 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1680, average loss: 3.1602
[09/26 06:47:11 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 68.00	
[09/26 06:47:11 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.22386788418308667
[09/26 06:47:18 visual_prompt]: Epoch 59 / 100: avg data time: 6.25e-02, avg batch time: 0.5057, average train loss: 0.1067
[09/26 06:47:20 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1674, average loss: 3.1997
[09/26 06:47:20 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 66.50	
[09/26 06:47:20 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.2152067247599837
[09/26 06:47:27 visual_prompt]: Epoch 60 / 100: avg data time: 5.94e-02, avg batch time: 0.5038, average train loss: 0.1054
[09/26 06:47:28 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1679, average loss: 3.1983
[09/26 06:47:28 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 67.00	
[09/26 06:47:28 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.20658795558326742
[09/26 06:47:35 visual_prompt]: Epoch 61 / 100: avg data time: 5.52e-02, avg batch time: 0.5008, average train loss: 0.1053
[09/26 06:47:37 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1672, average loss: 3.2001
[09/26 06:47:37 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 67.00	
[09/26 06:47:37 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.1980220772955602
[09/26 06:47:44 visual_prompt]: Epoch 62 / 100: avg data time: 6.47e-02, avg batch time: 0.5077, average train loss: 0.1039
[09/26 06:47:45 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1672, average loss: 3.2182
[09/26 06:47:45 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 69.00	
[09/26 06:47:45 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.1895195261000831
[09/26 06:47:52 visual_prompt]: Epoch 63 / 100: avg data time: 6.04e-02, avg batch time: 0.5031, average train loss: 0.1036
[09/26 06:47:54 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1673, average loss: 3.2130
[09/26 06:47:54 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.50	top5: 68.50	
[09/26 06:47:54 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.18109066104575022
[09/26 06:48:01 visual_prompt]: Epoch 64 / 100: avg data time: 5.71e-02, avg batch time: 0.5004, average train loss: 0.1042
[09/26 06:48:02 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1679, average loss: 3.2115
[09/26 06:48:02 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 67.00	
[09/26 06:48:02 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.17274575140626316
[09/26 06:48:09 visual_prompt]: Epoch 65 / 100: avg data time: 5.35e-02, avg batch time: 0.4993, average train loss: 0.1022
[09/26 06:48:11 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1680, average loss: 3.1971
[09/26 06:48:11 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 68.50	
[09/26 06:48:11 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.16449496416858284
[09/26 06:48:18 visual_prompt]: Epoch 66 / 100: avg data time: 6.09e-02, avg batch time: 0.5042, average train loss: 0.1010
[09/26 06:48:19 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1678, average loss: 3.2083
[09/26 06:48:19 visual_prompt]: Classification results with val_vtab-sun397: top1: 40.50	top5: 67.50	
[09/26 06:48:19 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.15634835164602198
[09/26 06:48:26 visual_prompt]: Epoch 67 / 100: avg data time: 6.07e-02, avg batch time: 0.5054, average train loss: 0.1007
[09/26 06:48:28 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1672, average loss: 3.1833
[09/26 06:48:28 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.50	top5: 65.00	
[09/26 06:48:28 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.14831583923105
[09/26 06:48:35 visual_prompt]: Epoch 68 / 100: avg data time: 6.15e-02, avg batch time: 0.5049, average train loss: 0.0999
[09/26 06:48:36 visual_prompt]: Inference (val):avg data time: 3.62e-05, avg batch time: 0.1672, average loss: 3.2138
[09/26 06:48:36 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.50	top5: 66.50	
[09/26 06:48:36 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.14040721330273062
[09/26 06:48:43 visual_prompt]: Epoch 69 / 100: avg data time: 5.79e-02, avg batch time: 0.5008, average train loss: 0.0992
[09/26 06:48:45 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1671, average loss: 3.2249
[09/26 06:48:45 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 66.50	
[09/26 06:48:45 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.13263210930352737
[09/26 06:48:52 visual_prompt]: Epoch 70 / 100: avg data time: 5.78e-02, avg batch time: 0.5021, average train loss: 0.0992
[09/26 06:48:53 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1669, average loss: 3.2279
[09/26 06:48:53 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 65.50	
[09/26 06:48:53 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.12500000000000006
[09/26 06:49:00 visual_prompt]: Epoch 71 / 100: avg data time: 5.27e-02, avg batch time: 0.4979, average train loss: 0.0989
[09/26 06:49:02 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1673, average loss: 3.2069
[09/26 06:49:02 visual_prompt]: Classification results with val_vtab-sun397: top1: 40.00	top5: 67.00	
[09/26 06:49:02 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.1175201839416988
[09/26 06:49:09 visual_prompt]: Epoch 72 / 100: avg data time: 6.30e-02, avg batch time: 0.5071, average train loss: 0.0983
[09/26 06:49:10 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1674, average loss: 3.2181
[09/26 06:49:10 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.50	top5: 67.00	
[09/26 06:49:10 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.11020177413231333
[09/26 06:49:17 visual_prompt]: Epoch 73 / 100: avg data time: 5.68e-02, avg batch time: 0.5008, average train loss: 0.0976
[09/26 06:49:19 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1674, average loss: 3.2468
[09/26 06:49:19 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.50	top5: 66.50	
[09/26 06:49:19 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.10305368692688174
[09/26 06:49:26 visual_prompt]: Epoch 74 / 100: avg data time: 6.13e-02, avg batch time: 0.5040, average train loss: 0.0968
[09/26 06:49:27 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1674, average loss: 3.2181
[09/26 06:49:27 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.50	top5: 66.00	
[09/26 06:49:27 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.09608463116858543
[09/26 06:49:34 visual_prompt]: Epoch 75 / 100: avg data time: 5.87e-02, avg batch time: 0.5017, average train loss: 0.0966
[09/26 06:49:36 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1674, average loss: 3.2226
[09/26 06:49:36 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 66.00	
[09/26 06:49:36 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.08930309757836516
[09/26 06:49:43 visual_prompt]: Epoch 76 / 100: avg data time: 6.12e-02, avg batch time: 0.5046, average train loss: 0.0966
[09/26 06:49:44 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1669, average loss: 3.1959
[09/26 06:49:44 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 66.00	
[09/26 06:49:44 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.08271734841028552
[09/26 06:49:51 visual_prompt]: Epoch 77 / 100: avg data time: 6.10e-02, avg batch time: 0.5043, average train loss: 0.0956
[09/26 06:49:53 visual_prompt]: Inference (val):avg data time: 4.30e-05, avg batch time: 0.1670, average loss: 3.2378
[09/26 06:49:53 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.50	top5: 66.50	
[09/26 06:49:53 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.07633540738525066
[09/26 06:50:00 visual_prompt]: Epoch 78 / 100: avg data time: 6.04e-02, avg batch time: 0.5040, average train loss: 0.0949
[09/26 06:50:01 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1671, average loss: 3.2330
[09/26 06:50:01 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 65.50	
[09/26 06:50:01 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.07016504991533726
[09/26 06:50:08 visual_prompt]: Epoch 79 / 100: avg data time: 5.43e-02, avg batch time: 0.5145, average train loss: 0.0948
[09/26 06:50:10 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1673, average loss: 3.2229
[09/26 06:50:10 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 67.00	
[09/26 06:50:10 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.06421379363065141
[09/26 06:50:17 visual_prompt]: Epoch 80 / 100: avg data time: 5.61e-02, avg batch time: 0.5004, average train loss: 0.0947
[09/26 06:50:18 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1673, average loss: 3.2149
[09/26 06:50:18 visual_prompt]: Classification results with val_vtab-sun397: top1: 40.50	top5: 66.50	
[09/26 06:50:18 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.058488889220255524
[09/26 06:50:25 visual_prompt]: Epoch 81 / 100: avg data time: 5.49e-02, avg batch time: 0.4986, average train loss: 0.0943
[09/26 06:50:27 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1678, average loss: 3.2254
[09/26 06:50:27 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.50	top5: 67.00	
[09/26 06:50:27 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.052997311598319524
[09/26 06:50:33 visual_prompt]: Epoch 82 / 100: avg data time: 5.05e-02, avg batch time: 0.4983, average train loss: 0.0939
[09/26 06:50:35 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1676, average loss: 3.2122
[09/26 06:50:35 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 67.00	
[09/26 06:50:35 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.047745751406263165
[09/26 06:50:42 visual_prompt]: Epoch 83 / 100: avg data time: 6.13e-02, avg batch time: 0.5068, average train loss: 0.0939
[09/26 06:50:44 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1680, average loss: 3.2186
[09/26 06:50:44 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 67.00	
[09/26 06:50:44 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.042740606861239594
[09/26 06:50:51 visual_prompt]: Epoch 84 / 100: avg data time: 6.06e-02, avg batch time: 0.5067, average train loss: 0.0933
[09/26 06:50:52 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1676, average loss: 3.2095
[09/26 06:50:52 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.50	top5: 67.00	
[09/26 06:50:52 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.03798797596089351
[09/26 06:50:59 visual_prompt]: Epoch 85 / 100: avg data time: 5.82e-02, avg batch time: 0.5044, average train loss: 0.0931
[09/26 06:51:01 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1678, average loss: 3.2339
[09/26 06:51:01 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 67.00	
[09/26 06:51:01 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.03349364905389032
[09/26 06:51:08 visual_prompt]: Epoch 86 / 100: avg data time: 5.65e-02, avg batch time: 0.5036, average train loss: 0.0932
[09/26 06:51:09 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1683, average loss: 3.2185
[09/26 06:51:09 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 66.50	
[09/26 06:51:09 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.029263101785268253
[09/26 06:51:16 visual_prompt]: Epoch 87 / 100: avg data time: 6.20e-02, avg batch time: 0.5091, average train loss: 0.0926
[09/26 06:51:18 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1682, average loss: 3.2237
[09/26 06:51:18 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 66.00	
[09/26 06:51:18 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.025301488425208296
[09/26 06:51:25 visual_prompt]: Epoch 88 / 100: avg data time: 6.20e-02, avg batch time: 0.5092, average train loss: 0.0927
[09/26 06:51:26 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1684, average loss: 3.2220
[09/26 06:51:26 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 66.00	
[09/26 06:51:26 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.021613635589349756
[09/26 06:51:33 visual_prompt]: Epoch 89 / 100: avg data time: 6.00e-02, avg batch time: 0.5068, average train loss: 0.0922
[09/26 06:51:35 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1685, average loss: 3.2195
[09/26 06:51:35 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 66.00	
[09/26 06:51:35 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.01820403635830317
[09/26 06:51:42 visual_prompt]: Epoch 90 / 100: avg data time: 6.26e-02, avg batch time: 0.5111, average train loss: 0.0922
[09/26 06:51:44 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1683, average loss: 3.2277
[09/26 06:51:44 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.00	top5: 67.00	
[09/26 06:51:44 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.01507684480352292
[09/26 06:51:51 visual_prompt]: Epoch 91 / 100: avg data time: 6.47e-02, avg batch time: 0.5135, average train loss: 0.0923
[09/26 06:51:52 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1686, average loss: 3.2314
[09/26 06:51:52 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 66.50	
[09/26 06:51:52 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.012235870926211617
[09/26 06:51:59 visual_prompt]: Epoch 92 / 100: avg data time: 5.40e-02, avg batch time: 0.5028, average train loss: 0.0919
[09/26 06:52:01 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1686, average loss: 3.2288
[09/26 06:52:01 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 67.00	
[09/26 06:52:01 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.009684576015420276
[09/26 06:52:08 visual_prompt]: Epoch 93 / 100: avg data time: 6.24e-02, avg batch time: 0.5117, average train loss: 0.0916
[09/26 06:52:09 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1688, average loss: 3.2291
[09/26 06:52:09 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 67.00	
[09/26 06:52:09 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.007426068431000882
[09/26 06:52:16 visual_prompt]: Epoch 94 / 100: avg data time: 6.23e-02, avg batch time: 0.5116, average train loss: 0.0919
[09/26 06:52:18 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1688, average loss: 3.2269
[09/26 06:52:18 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 67.00	
[09/26 06:52:18 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.005463099816548578
[09/26 06:52:25 visual_prompt]: Epoch 95 / 100: avg data time: 5.96e-02, avg batch time: 0.5083, average train loss: 0.0921
[09/26 06:52:27 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1685, average loss: 3.2265
[09/26 06:52:27 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 66.50	
[09/26 06:52:27 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.003798061746947995
[09/26 06:52:33 visual_prompt]: Epoch 96 / 100: avg data time: 6.07e-02, avg batch time: 0.5089, average train loss: 0.0918
[09/26 06:52:35 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1687, average loss: 3.2239
[09/26 06:52:35 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 66.50	
[09/26 06:52:35 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.0024329828146074095
[09/26 06:52:42 visual_prompt]: Epoch 97 / 100: avg data time: 5.89e-02, avg batch time: 0.5063, average train loss: 0.0915
[09/26 06:52:44 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1690, average loss: 3.2230
[09/26 06:52:44 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 66.50	
[09/26 06:52:44 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.0013695261579316775
[09/26 06:52:51 visual_prompt]: Epoch 98 / 100: avg data time: 6.31e-02, avg batch time: 0.5110, average train loss: 0.0915
[09/26 06:52:52 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1682, average loss: 3.2235
[09/26 06:52:52 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 66.50	
[09/26 06:52:52 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.0006089874350439506
[09/26 06:52:59 visual_prompt]: Epoch 99 / 100: avg data time: 5.14e-02, avg batch time: 0.4992, average train loss: 0.0915
[09/26 06:53:01 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1684, average loss: 3.2236
[09/26 06:53:01 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 66.50	
[09/26 06:53:01 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.00015229324522605947
[09/26 06:53:08 visual_prompt]: Epoch 100 / 100: avg data time: 6.40e-02, avg batch time: 0.5105, average train loss: 0.0916
[09/26 06:53:09 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1682, average loss: 3.2237
[09/26 06:53:09 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 66.50	
[09/26 06:53:09 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 06:53:09 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              0
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 06:53:09 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-sun397', 'DATA.NUMBER_CLASSES', '397', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 06:53:09 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 06:53:09 visual_prompt]: Training with config:
[09/26 06:53:09 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-sun397/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.5_wd0.0001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 0.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-sun397', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 397, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 06:53:09 visual_prompt]: Loading training data...
[09/26 06:53:09 visual_prompt]: Constructing vtab-sun397 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split train[:800], from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/26 06:53:11 visual_prompt]: Number of images: 800
[09/26 06:53:11 visual_prompt]: Number of classes: 309 / 397
[09/26 06:53:11 visual_prompt]: Loading validation data...
[09/26 06:53:11 visual_prompt]: Constructing vtab-sun397 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split validation[:200], from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/26 06:53:11 visual_prompt]: Number of images: 200
[09/26 06:53:11 visual_prompt]: Number of classes: 136 / 397
[09/26 06:53:11 visual_prompt]: Constructing models...
[09/26 06:53:14 visual_prompt]: Total Parameters: 86564749	 Gradient Parameters: 766093
[09/26 06:53:14 visual_prompt]: tuned percent:0.885
[09/26 06:53:14 visual_prompt]: Device used for model: 0
[09/26 06:53:14 visual_prompt]: Setting up Evaluator...
[09/26 06:53:14 visual_prompt]: Setting up Trainer...
[09/26 06:53:14 visual_prompt]: 	Setting up the optimizer...
[09/26 06:53:14 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 06:53:21 visual_prompt]: Epoch 1 / 100: avg data time: 6.40e-02, avg batch time: 0.5104, average train loss: 5.9880
[09/26 06:53:22 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1675, average loss: 6.0097
[09/26 06:53:22 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/26 06:53:22 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.05
[09/26 06:53:29 visual_prompt]: Epoch 2 / 100: avg data time: 5.81e-02, avg batch time: 0.5029, average train loss: 5.9341
[09/26 06:53:31 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1677, average loss: 5.9213
[09/26 06:53:31 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 5.00	
[09/26 06:53:31 visual_prompt]: Best epoch 2: best metric: 0.010
[09/26 06:53:31 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.1
[09/26 06:53:38 visual_prompt]: Epoch 3 / 100: avg data time: 6.35e-02, avg batch time: 0.5077, average train loss: 5.7352
[09/26 06:53:39 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1678, average loss: 5.8376
[09/26 06:53:39 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 06:53:39 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.15
[09/26 06:53:46 visual_prompt]: Epoch 4 / 100: avg data time: 6.09e-02, avg batch time: 0.5065, average train loss: 5.5408
[09/26 06:53:48 visual_prompt]: Inference (val):avg data time: 3.70e-05, avg batch time: 0.1673, average loss: 5.6685
[09/26 06:53:48 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 8.00	
[09/26 06:53:48 visual_prompt]: Best epoch 4: best metric: 0.015
[09/26 06:53:48 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.2
[09/26 06:53:55 visual_prompt]: Epoch 5 / 100: avg data time: 6.17e-02, avg batch time: 0.5065, average train loss: 5.2818
[09/26 06:53:56 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1675, average loss: 5.5373
[09/26 06:53:56 visual_prompt]: Classification results with val_vtab-sun397: top1: 4.50	top5: 9.50	
[09/26 06:53:56 visual_prompt]: Best epoch 5: best metric: 0.045
[09/26 06:53:56 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.25
[09/26 06:54:03 visual_prompt]: Epoch 6 / 100: avg data time: 5.87e-02, avg batch time: 0.5033, average train loss: 4.9181
[09/26 06:54:05 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1675, average loss: 5.1433
[09/26 06:54:05 visual_prompt]: Classification results with val_vtab-sun397: top1: 6.00	top5: 18.00	
[09/26 06:54:05 visual_prompt]: Best epoch 6: best metric: 0.060
[09/26 06:54:05 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.3
[09/26 06:54:12 visual_prompt]: Epoch 7 / 100: avg data time: 4.87e-02, avg batch time: 0.4935, average train loss: 4.3893
[09/26 06:54:13 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1674, average loss: 4.8481
[09/26 06:54:13 visual_prompt]: Classification results with val_vtab-sun397: top1: 13.50	top5: 27.50	
[09/26 06:54:13 visual_prompt]: Best epoch 7: best metric: 0.135
[09/26 06:54:13 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.35
[09/26 06:54:20 visual_prompt]: Epoch 8 / 100: avg data time: 5.07e-02, avg batch time: 0.4966, average train loss: 3.5438
[09/26 06:54:22 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1677, average loss: 4.3283
[09/26 06:54:22 visual_prompt]: Classification results with val_vtab-sun397: top1: 18.00	top5: 36.00	
[09/26 06:54:22 visual_prompt]: Best epoch 8: best metric: 0.180
[09/26 06:54:22 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.4
[09/26 06:54:28 visual_prompt]: Epoch 9 / 100: avg data time: 6.05e-02, avg batch time: 0.5050, average train loss: 2.5397
[09/26 06:54:30 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1672, average loss: 3.9246
[09/26 06:54:30 visual_prompt]: Classification results with val_vtab-sun397: top1: 24.00	top5: 44.00	
[09/26 06:54:30 visual_prompt]: Best epoch 9: best metric: 0.240
[09/26 06:54:30 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.45
[09/26 06:54:37 visual_prompt]: Epoch 10 / 100: avg data time: 6.19e-02, avg batch time: 0.5072, average train loss: 1.5412
[09/26 06:54:39 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1676, average loss: 3.4768
[09/26 06:54:39 visual_prompt]: Classification results with val_vtab-sun397: top1: 34.50	top5: 60.00	
[09/26 06:54:39 visual_prompt]: Best epoch 10: best metric: 0.345
[09/26 06:54:39 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.5
[09/26 06:54:46 visual_prompt]: Epoch 11 / 100: avg data time: 6.27e-02, avg batch time: 0.5070, average train loss: 0.8223
[09/26 06:54:47 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1677, average loss: 3.2937
[09/26 06:54:47 visual_prompt]: Classification results with val_vtab-sun397: top1: 34.50	top5: 62.00	
[09/26 06:54:47 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.49984770675477397
[09/26 06:54:54 visual_prompt]: Epoch 12 / 100: avg data time: 5.35e-02, avg batch time: 0.4988, average train loss: 0.3877
[09/26 06:54:56 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1675, average loss: 3.1783
[09/26 06:54:56 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.00	top5: 59.00	
[09/26 06:54:56 visual_prompt]: Best epoch 12: best metric: 0.370
[09/26 06:54:56 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.49939101256495605
[09/26 06:55:02 visual_prompt]: Epoch 13 / 100: avg data time: 6.07e-02, avg batch time: 0.5045, average train loss: 0.1722
[09/26 06:55:04 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1675, average loss: 3.1150
[09/26 06:55:04 visual_prompt]: Classification results with val_vtab-sun397: top1: 34.50	top5: 63.00	
[09/26 06:55:04 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.4986304738420683
[09/26 06:55:11 visual_prompt]: Epoch 14 / 100: avg data time: 6.24e-02, avg batch time: 0.5062, average train loss: 0.0967
[09/26 06:55:13 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1672, average loss: 3.0756
[09/26 06:55:13 visual_prompt]: Classification results with val_vtab-sun397: top1: 36.50	top5: 63.50	
[09/26 06:55:13 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.4975670171853926
[09/26 06:55:20 visual_prompt]: Epoch 15 / 100: avg data time: 6.12e-02, avg batch time: 0.5044, average train loss: 0.0668
[09/26 06:55:21 visual_prompt]: Inference (val):avg data time: 3.49e-05, avg batch time: 0.1677, average loss: 3.1149
[09/26 06:55:21 visual_prompt]: Classification results with val_vtab-sun397: top1: 36.00	top5: 62.50	
[09/26 06:55:21 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.49620193825305203
[09/26 06:55:28 visual_prompt]: Epoch 16 / 100: avg data time: 6.15e-02, avg batch time: 0.5053, average train loss: 0.0508
[09/26 06:55:30 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1674, average loss: 3.0947
[09/26 06:55:30 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.50	top5: 63.50	
[09/26 06:55:30 visual_prompt]: Best epoch 16: best metric: 0.375
[09/26 06:55:30 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.4945369001834514
[09/26 06:55:37 visual_prompt]: Epoch 17 / 100: avg data time: 6.04e-02, avg batch time: 0.5048, average train loss: 0.0426
[09/26 06:55:38 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1672, average loss: 3.0781
[09/26 06:55:38 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.50	top5: 63.00	
[09/26 06:55:38 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.4925739315689991
[09/26 06:55:45 visual_prompt]: Epoch 18 / 100: avg data time: 6.26e-02, avg batch time: 0.5070, average train loss: 0.0380
[09/26 06:55:47 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1674, average loss: 3.0740
[09/26 06:55:47 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.00	top5: 64.00	
[09/26 06:55:47 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.4903154239845797
[09/26 06:55:54 visual_prompt]: Epoch 19 / 100: avg data time: 6.25e-02, avg batch time: 0.5071, average train loss: 0.0342
[09/26 06:55:55 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1674, average loss: 3.0769
[09/26 06:55:55 visual_prompt]: Classification results with val_vtab-sun397: top1: 36.50	top5: 62.50	
[09/26 06:55:55 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.4877641290737884
[09/26 06:56:02 visual_prompt]: Epoch 20 / 100: avg data time: 5.60e-02, avg batch time: 0.5017, average train loss: 0.0319
[09/26 06:56:04 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1674, average loss: 3.0831
[09/26 06:56:04 visual_prompt]: Classification results with val_vtab-sun397: top1: 36.50	top5: 62.50	
[09/26 06:56:04 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.4849231551964771
[09/26 06:56:11 visual_prompt]: Epoch 21 / 100: avg data time: 5.80e-02, avg batch time: 0.5031, average train loss: 0.0298
[09/26 06:56:13 visual_prompt]: Inference (val):avg data time: 3.61e-05, avg batch time: 0.1672, average loss: 3.0895
[09/26 06:56:13 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.00	top5: 62.00	
[09/26 06:56:13 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.48179596364169686
[09/26 06:56:20 visual_prompt]: Epoch 22 / 100: avg data time: 5.97e-02, avg batch time: 0.5024, average train loss: 0.0283
[09/26 06:56:21 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1674, average loss: 3.0955
[09/26 06:56:21 visual_prompt]: Classification results with val_vtab-sun397: top1: 36.50	top5: 62.50	
[09/26 06:56:21 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.4783863644106502
[09/26 06:56:28 visual_prompt]: Epoch 23 / 100: avg data time: 6.15e-02, avg batch time: 0.5058, average train loss: 0.0269
[09/26 06:56:30 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1670, average loss: 3.0949
[09/26 06:56:30 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.00	top5: 62.00	
[09/26 06:56:30 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.47469851157479176
[09/26 06:56:36 visual_prompt]: Epoch 24 / 100: avg data time: 5.64e-02, avg batch time: 0.5014, average train loss: 0.0257
[09/26 06:56:38 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1669, average loss: 3.0931
[09/26 06:56:38 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.00	top5: 62.00	
[09/26 06:56:38 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.47073689821473175
[09/26 06:56:45 visual_prompt]: Epoch 25 / 100: avg data time: 5.55e-02, avg batch time: 0.4992, average train loss: 0.0250
[09/26 06:56:47 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1671, average loss: 3.1012
[09/26 06:56:47 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.50	top5: 62.00	
[09/26 06:56:47 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.4665063509461097
[09/26 06:56:53 visual_prompt]: Epoch 26 / 100: avg data time: 5.78e-02, avg batch time: 0.5010, average train loss: 0.0239
[09/26 06:56:55 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1669, average loss: 3.1020
[09/26 06:56:55 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.50	top5: 62.00	
[09/26 06:56:55 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.46201202403910646
[09/26 06:57:02 visual_prompt]: Epoch 27 / 100: avg data time: 5.28e-02, avg batch time: 0.4978, average train loss: 0.0233
[09/26 06:57:03 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1677, average loss: 3.1036
[09/26 06:57:03 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.50	top5: 61.50	
[09/26 06:57:03 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.4572593931387604
[09/26 06:57:10 visual_prompt]: Epoch 28 / 100: avg data time: 5.72e-02, avg batch time: 0.5006, average train loss: 0.0223
[09/26 06:57:12 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1670, average loss: 3.1052
[09/26 06:57:12 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.00	top5: 61.50	
[09/26 06:57:12 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.45225424859373686
[09/26 06:57:19 visual_prompt]: Epoch 29 / 100: avg data time: 6.07e-02, avg batch time: 0.5039, average train loss: 0.0221
[09/26 06:57:20 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1674, average loss: 3.1057
[09/26 06:57:20 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.00	top5: 61.50	
[09/26 06:57:20 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.44700268840168045
[09/26 06:57:27 visual_prompt]: Epoch 30 / 100: avg data time: 6.37e-02, avg batch time: 0.5075, average train loss: 0.0216
[09/26 06:57:29 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1670, average loss: 3.1074
[09/26 06:57:29 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.00	top5: 62.00	
[09/26 06:57:29 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.4415111107797445
[09/26 06:57:36 visual_prompt]: Epoch 31 / 100: avg data time: 6.07e-02, avg batch time: 0.5042, average train loss: 0.0208
[09/26 06:57:37 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1671, average loss: 3.1170
[09/26 06:57:37 visual_prompt]: Classification results with val_vtab-sun397: top1: 36.50	top5: 61.00	
[09/26 06:57:37 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.43578620636934856
[09/26 06:57:44 visual_prompt]: Epoch 32 / 100: avg data time: 6.12e-02, avg batch time: 0.5041, average train loss: 0.0208
[09/26 06:57:46 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1674, average loss: 3.1169
[09/26 06:57:46 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.00	top5: 61.50	
[09/26 06:57:46 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.42983495008466277
[09/26 06:57:53 visual_prompt]: Epoch 33 / 100: avg data time: 5.99e-02, avg batch time: 0.5026, average train loss: 0.0203
[09/26 06:57:54 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1671, average loss: 3.1069
[09/26 06:57:54 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.50	top5: 61.50	
[09/26 06:57:54 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.4236645926147493
[09/26 06:58:01 visual_prompt]: Epoch 34 / 100: avg data time: 5.15e-02, avg batch time: 0.4957, average train loss: 0.0197
[09/26 06:58:03 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1672, average loss: 3.1093
[09/26 06:58:03 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.00	top5: 61.00	
[09/26 06:58:03 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.41728265158971456
[09/26 06:58:10 visual_prompt]: Epoch 35 / 100: avg data time: 6.18e-02, avg batch time: 0.5041, average train loss: 0.0195
[09/26 06:58:11 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1669, average loss: 3.1145
[09/26 06:58:11 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.00	top5: 60.50	
[09/26 06:58:11 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.4106969024216348
[09/26 06:58:18 visual_prompt]: Epoch 36 / 100: avg data time: 6.33e-02, avg batch time: 0.5066, average train loss: 0.0192
[09/26 06:58:20 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1672, average loss: 3.1164
[09/26 06:58:20 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.00	top5: 60.00	
[09/26 06:58:20 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.40391536883141455
[09/26 06:58:27 visual_prompt]: Epoch 37 / 100: avg data time: 5.97e-02, avg batch time: 0.5031, average train loss: 0.0191
[09/26 06:58:28 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1672, average loss: 3.1186
[09/26 06:58:28 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.00	top5: 61.50	
[09/26 06:58:28 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.3969463130731183
[09/26 06:58:35 visual_prompt]: Epoch 38 / 100: avg data time: 5.94e-02, avg batch time: 0.5026, average train loss: 0.0191
[09/26 06:58:37 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1673, average loss: 3.1170
[09/26 06:58:37 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.50	top5: 62.00	
[09/26 06:58:37 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.3897982258676867
[09/26 06:58:44 visual_prompt]: Epoch 39 / 100: avg data time: 6.51e-02, avg batch time: 0.5101, average train loss: 0.0188
[09/26 06:58:45 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1671, average loss: 3.1088
[09/26 06:58:45 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.50	top5: 61.50	
[09/26 06:58:45 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.3824798160583012
[09/26 06:58:52 visual_prompt]: Epoch 40 / 100: avg data time: 6.86e-02, avg batch time: 0.5109, average train loss: 0.0184
[09/26 06:58:54 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1671, average loss: 3.1175
[09/26 06:58:54 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.50	top5: 61.50	
[09/26 06:58:54 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.375
[09/26 06:59:01 visual_prompt]: Epoch 41 / 100: avg data time: 6.12e-02, avg batch time: 0.5053, average train loss: 0.0181
[09/26 06:59:02 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1669, average loss: 3.1216
[09/26 06:59:02 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.00	top5: 61.00	
[09/26 06:59:02 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.3673678906964727
[09/26 06:59:09 visual_prompt]: Epoch 42 / 100: avg data time: 6.19e-02, avg batch time: 0.5047, average train loss: 0.0180
[09/26 06:59:11 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1671, average loss: 3.1153
[09/26 06:59:11 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.00	top5: 61.00	
[09/26 06:59:11 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.35959278669726935
[09/26 06:59:18 visual_prompt]: Epoch 43 / 100: avg data time: 4.71e-02, avg batch time: 0.4928, average train loss: 0.0181
[09/26 06:59:19 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1669, average loss: 3.1134
[09/26 06:59:19 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.00	top5: 60.50	
[09/26 06:59:19 visual_prompt]: Best epoch 43: best metric: 0.380
[09/26 06:59:19 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.3516841607689501
[09/26 06:59:26 visual_prompt]: Epoch 44 / 100: avg data time: 5.80e-02, avg batch time: 0.5014, average train loss: 0.0178
[09/26 06:59:28 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1666, average loss: 3.1161
[09/26 06:59:28 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.00	top5: 61.00	
[09/26 06:59:28 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.34365164835397805
[09/26 06:59:35 visual_prompt]: Epoch 45 / 100: avg data time: 6.18e-02, avg batch time: 0.5043, average train loss: 0.0177
[09/26 06:59:36 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1670, average loss: 3.1143
[09/26 06:59:36 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.00	top5: 61.50	
[09/26 06:59:36 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.3355050358314172
[09/26 06:59:43 visual_prompt]: Epoch 46 / 100: avg data time: 5.92e-02, avg batch time: 0.5021, average train loss: 0.0175
[09/26 06:59:45 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1677, average loss: 3.1152
[09/26 06:59:45 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.50	top5: 60.00	
[09/26 06:59:45 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.32725424859373686
[09/26 06:59:52 visual_prompt]: Epoch 47 / 100: avg data time: 6.26e-02, avg batch time: 0.5056, average train loss: 0.0172
[09/26 06:59:53 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1674, average loss: 3.1205
[09/26 06:59:53 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.50	top5: 61.00	
[09/26 06:59:53 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.3189093389542498
[09/26 07:00:00 visual_prompt]: Epoch 48 / 100: avg data time: 6.25e-02, avg batch time: 0.5057, average train loss: 0.0171
[09/26 07:00:02 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1674, average loss: 3.1239
[09/26 07:00:02 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.00	top5: 61.50	
[09/26 07:00:02 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.3104804738999169
[09/26 07:00:09 visual_prompt]: Epoch 49 / 100: avg data time: 6.12e-02, avg batch time: 0.5045, average train loss: 0.0170
[09/26 07:00:11 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1675, average loss: 3.1332
[09/26 07:00:11 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.00	top5: 60.50	
[09/26 07:00:11 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.3019779227044398
[09/26 07:00:17 visual_prompt]: Epoch 50 / 100: avg data time: 6.84e-02, avg batch time: 0.5112, average train loss: 0.0172
[09/26 07:00:19 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1673, average loss: 3.1337
[09/26 07:00:19 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.00	top5: 61.00	
[09/26 07:00:19 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.29341204441673263
[09/26 07:00:26 visual_prompt]: Epoch 51 / 100: avg data time: 6.20e-02, avg batch time: 0.5044, average train loss: 0.0171
[09/26 07:00:28 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1672, average loss: 3.1323
[09/26 07:00:28 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.00	top5: 60.50	
[09/26 07:00:28 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.28479327524001635
[09/26 07:00:34 visual_prompt]: Epoch 52 / 100: avg data time: 5.66e-02, avg batch time: 0.4990, average train loss: 0.0169
[09/26 07:00:36 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1673, average loss: 3.1297
[09/26 07:00:36 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.00	top5: 60.50	
[09/26 07:00:36 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.2761321158169134
[09/26 07:00:43 visual_prompt]: Epoch 53 / 100: avg data time: 6.01e-02, avg batch time: 0.5030, average train loss: 0.0167
[09/26 07:00:45 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1674, average loss: 3.1271
[09/26 07:00:45 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 60.50	
[09/26 07:00:45 visual_prompt]: Best epoch 53: best metric: 0.385
[09/26 07:00:45 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.2674391184360313
[09/26 07:00:51 visual_prompt]: Epoch 54 / 100: avg data time: 6.28e-02, avg batch time: 0.5059, average train loss: 0.0168
[09/26 07:00:53 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1671, average loss: 3.1268
[09/26 07:00:53 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 60.50	
[09/26 07:00:53 visual_prompt]: Best epoch 54: best metric: 0.390
[09/26 07:00:53 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.2587248741756253
[09/26 07:01:00 visual_prompt]: Epoch 55 / 100: avg data time: 5.50e-02, avg batch time: 0.5002, average train loss: 0.0165
[09/26 07:01:02 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1675, average loss: 3.1268
[09/26 07:01:02 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 60.50	
[09/26 07:01:02 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.25
[09/26 07:01:08 visual_prompt]: Epoch 56 / 100: avg data time: 6.24e-02, avg batch time: 0.5049, average train loss: 0.0168
[09/26 07:01:10 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1671, average loss: 3.1278
[09/26 07:01:10 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 60.50	
[09/26 07:01:10 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.24127512582437483
[09/26 07:01:17 visual_prompt]: Epoch 57 / 100: avg data time: 5.95e-02, avg batch time: 0.5035, average train loss: 0.0166
[09/26 07:01:18 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1670, average loss: 3.1321
[09/26 07:01:18 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.00	top5: 59.50	
[09/26 07:01:18 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.23256088156396867
[09/26 07:01:25 visual_prompt]: Epoch 58 / 100: avg data time: 6.02e-02, avg batch time: 0.5050, average train loss: 0.0163
[09/26 07:01:27 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1674, average loss: 3.1311
[09/26 07:01:27 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.50	top5: 60.50	
[09/26 07:01:27 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.22386788418308667
[09/26 07:01:34 visual_prompt]: Epoch 59 / 100: avg data time: 6.03e-02, avg batch time: 0.5043, average train loss: 0.0166
[09/26 07:01:35 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1673, average loss: 3.1294
[09/26 07:01:35 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 60.00	
[09/26 07:01:35 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.2152067247599837
[09/26 07:01:42 visual_prompt]: Epoch 60 / 100: avg data time: 6.37e-02, avg batch time: 0.5075, average train loss: 0.0165
[09/26 07:01:44 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.1678, average loss: 3.1346
[09/26 07:01:44 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.50	top5: 60.50	
[09/26 07:01:44 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.20658795558326742
[09/26 07:01:51 visual_prompt]: Epoch 61 / 100: avg data time: 6.21e-02, avg batch time: 0.5047, average train loss: 0.0165
[09/26 07:01:53 visual_prompt]: Inference (val):avg data time: 4.05e-05, avg batch time: 0.1672, average loss: 3.1341
[09/26 07:01:53 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.50	top5: 61.00	
[09/26 07:01:53 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.1980220772955602
[09/26 07:01:59 visual_prompt]: Epoch 62 / 100: avg data time: 6.13e-02, avg batch time: 0.5048, average train loss: 0.0163
[09/26 07:02:01 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1670, average loss: 3.1397
[09/26 07:02:01 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.00	top5: 60.50	
[09/26 07:02:01 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.1895195261000831
[09/26 07:02:08 visual_prompt]: Epoch 63 / 100: avg data time: 6.15e-02, avg batch time: 0.5051, average train loss: 0.0162
[09/26 07:02:10 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1673, average loss: 3.1437
[09/26 07:02:10 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.00	top5: 59.50	
[09/26 07:02:10 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.18109066104575022
[09/26 07:02:16 visual_prompt]: Epoch 64 / 100: avg data time: 5.85e-02, avg batch time: 0.5027, average train loss: 0.0162
[09/26 07:02:18 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1672, average loss: 3.1376
[09/26 07:02:18 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.00	top5: 60.50	
[09/26 07:02:18 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.17274575140626316
[09/26 07:02:25 visual_prompt]: Epoch 65 / 100: avg data time: 5.99e-02, avg batch time: 0.5042, average train loss: 0.0162
[09/26 07:02:27 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1672, average loss: 3.1371
[09/26 07:02:27 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.50	top5: 60.00	
[09/26 07:02:27 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.16449496416858284
[09/26 07:02:33 visual_prompt]: Epoch 66 / 100: avg data time: 4.88e-02, avg batch time: 0.4920, average train loss: 0.0163
[09/26 07:02:35 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1675, average loss: 3.1347
[09/26 07:02:35 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.00	top5: 60.00	
[09/26 07:02:35 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.15634835164602198
[09/26 07:02:42 visual_prompt]: Epoch 67 / 100: avg data time: 6.26e-02, avg batch time: 0.5054, average train loss: 0.0160
[09/26 07:02:44 visual_prompt]: Inference (val):avg data time: 4.79e-05, avg batch time: 0.1674, average loss: 3.1383
[09/26 07:02:44 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.00	top5: 60.00	
[09/26 07:02:44 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.14831583923105
[09/26 07:02:50 visual_prompt]: Epoch 68 / 100: avg data time: 5.89e-02, avg batch time: 0.5028, average train loss: 0.0160
[09/26 07:02:52 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1671, average loss: 3.1364
[09/26 07:02:52 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.00	top5: 60.50	
[09/26 07:02:52 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.14040721330273062
[09/26 07:02:59 visual_prompt]: Epoch 69 / 100: avg data time: 5.97e-02, avg batch time: 0.5035, average train loss: 0.0158
[09/26 07:03:01 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1670, average loss: 3.1356
[09/26 07:03:01 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.50	top5: 61.00	
[09/26 07:03:01 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.13263210930352737
[09/26 07:03:07 visual_prompt]: Epoch 70 / 100: avg data time: 6.19e-02, avg batch time: 0.5051, average train loss: 0.0159
[09/26 07:03:09 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1674, average loss: 3.1361
[09/26 07:03:09 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.50	top5: 60.50	
[09/26 07:03:09 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.12500000000000006
[09/26 07:03:16 visual_prompt]: Epoch 71 / 100: avg data time: 5.74e-02, avg batch time: 0.5011, average train loss: 0.0159
[09/26 07:03:17 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1675, average loss: 3.1338
[09/26 07:03:18 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.50	top5: 60.00	
[09/26 07:03:18 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.1175201839416988
[09/26 07:03:24 visual_prompt]: Epoch 72 / 100: avg data time: 5.99e-02, avg batch time: 0.5023, average train loss: 0.0159
[09/26 07:03:26 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1672, average loss: 3.1308
[09/26 07:03:26 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.50	top5: 60.00	
[09/26 07:03:26 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.11020177413231333
[09/26 07:03:33 visual_prompt]: Epoch 73 / 100: avg data time: 6.10e-02, avg batch time: 0.5035, average train loss: 0.0158
[09/26 07:03:34 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1674, average loss: 3.1301
[09/26 07:03:34 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.50	top5: 60.00	
[09/26 07:03:34 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.10305368692688174
[09/26 07:03:41 visual_prompt]: Epoch 74 / 100: avg data time: 6.44e-02, avg batch time: 0.5068, average train loss: 0.0158
[09/26 07:03:43 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1678, average loss: 3.1341
[09/26 07:03:43 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.50	top5: 60.00	
[09/26 07:03:43 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.09608463116858543
[09/26 07:03:50 visual_prompt]: Epoch 75 / 100: avg data time: 6.04e-02, avg batch time: 0.5021, average train loss: 0.0158
[09/26 07:03:51 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1675, average loss: 3.1366
[09/26 07:03:51 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.50	top5: 60.00	
[09/26 07:03:51 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.08930309757836516
[09/26 07:03:58 visual_prompt]: Epoch 76 / 100: avg data time: 5.87e-02, avg batch time: 0.5009, average train loss: 0.0158
[09/26 07:04:00 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1672, average loss: 3.1345
[09/26 07:04:00 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.50	top5: 60.00	
[09/26 07:04:00 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.08271734841028552
[09/26 07:04:07 visual_prompt]: Epoch 77 / 100: avg data time: 6.49e-02, avg batch time: 0.5079, average train loss: 0.0158
[09/26 07:04:08 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1672, average loss: 3.1314
[09/26 07:04:08 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.00	top5: 60.00	
[09/26 07:04:08 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.07633540738525066
[09/26 07:04:15 visual_prompt]: Epoch 78 / 100: avg data time: 6.05e-02, avg batch time: 0.5027, average train loss: 0.0157
[09/26 07:04:17 visual_prompt]: Inference (val):avg data time: 1.92e-05, avg batch time: 0.1674, average loss: 3.1297
[09/26 07:04:17 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.00	top5: 60.50	
[09/26 07:04:17 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.07016504991533726
[09/26 07:04:24 visual_prompt]: Epoch 79 / 100: avg data time: 6.40e-02, avg batch time: 0.5064, average train loss: 0.0157
[09/26 07:04:25 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1677, average loss: 3.1309
[09/26 07:04:25 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.00	top5: 60.00	
[09/26 07:04:25 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.06421379363065141
[09/26 07:04:32 visual_prompt]: Epoch 80 / 100: avg data time: 6.23e-02, avg batch time: 0.5047, average train loss: 0.0157
[09/26 07:04:34 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1672, average loss: 3.1332
[09/26 07:04:34 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.00	top5: 60.00	
[09/26 07:04:34 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.058488889220255524
[09/26 07:04:41 visual_prompt]: Epoch 81 / 100: avg data time: 5.96e-02, avg batch time: 0.5030, average train loss: 0.0157
[09/26 07:04:42 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1674, average loss: 3.1338
[09/26 07:04:42 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.00	top5: 60.00	
[09/26 07:04:42 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.052997311598319524
[09/26 07:04:49 visual_prompt]: Epoch 82 / 100: avg data time: 6.06e-02, avg batch time: 0.5029, average train loss: 0.0157
[09/26 07:04:51 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1668, average loss: 3.1352
[09/26 07:04:51 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.50	top5: 60.50	
[09/26 07:04:51 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.047745751406263165
[09/26 07:04:58 visual_prompt]: Epoch 83 / 100: avg data time: 6.11e-02, avg batch time: 0.5040, average train loss: 0.0156
[09/26 07:04:59 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1670, average loss: 3.1360
[09/26 07:04:59 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.00	top5: 60.50	
[09/26 07:04:59 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.042740606861239594
[09/26 07:05:06 visual_prompt]: Epoch 84 / 100: avg data time: 5.76e-02, avg batch time: 0.5003, average train loss: 0.0157
[09/26 07:05:08 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1669, average loss: 3.1353
[09/26 07:05:08 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.00	top5: 60.50	
[09/26 07:05:08 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.03798797596089351
[09/26 07:05:15 visual_prompt]: Epoch 85 / 100: avg data time: 6.16e-02, avg batch time: 0.5035, average train loss: 0.0155
[09/26 07:05:16 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1670, average loss: 3.1347
[09/26 07:05:16 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.50	top5: 60.50	
[09/26 07:05:16 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.03349364905389032
[09/26 07:05:23 visual_prompt]: Epoch 86 / 100: avg data time: 5.92e-02, avg batch time: 0.5029, average train loss: 0.0156
[09/26 07:05:25 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1670, average loss: 3.1347
[09/26 07:05:25 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.50	top5: 60.50	
[09/26 07:05:25 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.029263101785268253
[09/26 07:05:32 visual_prompt]: Epoch 87 / 100: avg data time: 6.14e-02, avg batch time: 0.5032, average train loss: 0.0154
[09/26 07:05:33 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1670, average loss: 3.1342
[09/26 07:05:33 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.50	top5: 60.50	
[09/26 07:05:33 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.025301488425208296
[09/26 07:05:40 visual_prompt]: Epoch 88 / 100: avg data time: 5.48e-02, avg batch time: 0.4982, average train loss: 0.0156
[09/26 07:05:42 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1674, average loss: 3.1343
[09/26 07:05:42 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.50	top5: 60.50	
[09/26 07:05:42 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.021613635589349756
[09/26 07:05:49 visual_prompt]: Epoch 89 / 100: avg data time: 6.38e-02, avg batch time: 0.5071, average train loss: 0.0155
[09/26 07:05:50 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1673, average loss: 3.1344
[09/26 07:05:50 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.50	top5: 60.50	
[09/26 07:05:50 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.01820403635830317
[09/26 07:05:57 visual_prompt]: Epoch 90 / 100: avg data time: 6.46e-02, avg batch time: 0.5072, average train loss: 0.0156
[09/26 07:05:59 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1675, average loss: 3.1341
[09/26 07:05:59 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.50	top5: 60.50	
[09/26 07:05:59 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.01507684480352292
[09/26 07:06:06 visual_prompt]: Epoch 91 / 100: avg data time: 5.64e-02, avg batch time: 0.4998, average train loss: 0.0156
[09/26 07:06:07 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1667, average loss: 3.1340
[09/26 07:06:07 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.50	top5: 60.50	
[09/26 07:06:07 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.012235870926211617
[09/26 07:06:14 visual_prompt]: Epoch 92 / 100: avg data time: 5.99e-02, avg batch time: 0.5036, average train loss: 0.0156
[09/26 07:06:16 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1671, average loss: 3.1341
[09/26 07:06:16 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.50	top5: 60.50	
[09/26 07:06:16 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.009684576015420276
[09/26 07:06:23 visual_prompt]: Epoch 93 / 100: avg data time: 6.51e-02, avg batch time: 0.5073, average train loss: 0.0156
[09/26 07:06:24 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1673, average loss: 3.1343
[09/26 07:06:24 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.50	top5: 60.50	
[09/26 07:06:24 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.007426068431000882
[09/26 07:06:31 visual_prompt]: Epoch 94 / 100: avg data time: 6.13e-02, avg batch time: 0.5044, average train loss: 0.0156
[09/26 07:06:33 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1671, average loss: 3.1343
[09/26 07:06:33 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.50	top5: 60.50	
[09/26 07:06:33 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.005463099816548578
[09/26 07:06:40 visual_prompt]: Epoch 95 / 100: avg data time: 6.44e-02, avg batch time: 0.5079, average train loss: 0.0158
[09/26 07:06:41 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1671, average loss: 3.1341
[09/26 07:06:41 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.50	top5: 60.50	
[09/26 07:06:41 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.003798061746947995
[09/26 07:06:48 visual_prompt]: Epoch 96 / 100: avg data time: 6.04e-02, avg batch time: 0.5032, average train loss: 0.0156
[09/26 07:06:50 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1676, average loss: 3.1342
[09/26 07:06:50 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.50	top5: 60.50	
[09/26 07:06:50 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.0024329828146074095
[09/26 07:06:57 visual_prompt]: Epoch 97 / 100: avg data time: 6.31e-02, avg batch time: 0.5048, average train loss: 0.0156
[09/26 07:06:58 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1671, average loss: 3.1342
[09/26 07:06:58 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.50	top5: 60.50	
[09/26 07:06:58 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.0013695261579316775
[09/26 07:07:05 visual_prompt]: Epoch 98 / 100: avg data time: 5.07e-02, avg batch time: 0.4933, average train loss: 0.0157
[09/26 07:07:07 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1672, average loss: 3.1342
[09/26 07:07:07 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.50	top5: 60.50	
[09/26 07:07:07 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.0006089874350439506
[09/26 07:07:14 visual_prompt]: Epoch 99 / 100: avg data time: 6.11e-02, avg batch time: 0.5042, average train loss: 0.0156
[09/26 07:07:15 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1673, average loss: 3.1342
[09/26 07:07:15 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.50	top5: 60.50	
[09/26 07:07:15 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.00015229324522605947
[09/26 07:07:22 visual_prompt]: Epoch 100 / 100: avg data time: 4.96e-02, avg batch time: 0.4939, average train loss: 0.0155
[09/26 07:07:24 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1674, average loss: 3.1342
[09/26 07:07:24 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.50	top5: 60.50	
[09/26 07:07:24 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 07:07:24 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              0
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 07:07:24 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-sun397', 'DATA.NUMBER_CLASSES', '397', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 07:07:24 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 07:07:24 visual_prompt]: Training with config:
[09/26 07:07:24 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-sun397/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.5_wd0.0/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 0.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-sun397', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 397, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 07:07:24 visual_prompt]: Loading training data...
[09/26 07:07:24 visual_prompt]: Constructing vtab-sun397 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split train[:800], from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/26 07:07:25 visual_prompt]: Number of images: 800
[09/26 07:07:25 visual_prompt]: Number of classes: 309 / 397
[09/26 07:07:25 visual_prompt]: Loading validation data...
[09/26 07:07:25 visual_prompt]: Constructing vtab-sun397 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split validation[:200], from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/26 07:07:26 visual_prompt]: Number of images: 200
[09/26 07:07:26 visual_prompt]: Number of classes: 136 / 397
[09/26 07:07:26 visual_prompt]: Constructing models...
[09/26 07:07:28 visual_prompt]: Total Parameters: 86564749	 Gradient Parameters: 766093
[09/26 07:07:28 visual_prompt]: tuned percent:0.885
[09/26 07:07:28 visual_prompt]: Device used for model: 0
[09/26 07:07:28 visual_prompt]: Setting up Evaluator...
[09/26 07:07:28 visual_prompt]: Setting up Trainer...
[09/26 07:07:28 visual_prompt]: 	Setting up the optimizer...
[09/26 07:07:28 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 07:07:35 visual_prompt]: Epoch 1 / 100: avg data time: 6.45e-02, avg batch time: 0.5081, average train loss: 5.9865
[09/26 07:07:37 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1669, average loss: 6.0097
[09/26 07:07:37 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/26 07:07:37 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.05
[09/26 07:07:43 visual_prompt]: Epoch 2 / 100: avg data time: 5.55e-02, avg batch time: 0.4990, average train loss: 5.9299
[09/26 07:07:45 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1668, average loss: 5.9053
[09/26 07:07:45 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 5.00	
[09/26 07:07:45 visual_prompt]: Best epoch 2: best metric: 0.005
[09/26 07:07:45 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.1
[09/26 07:07:52 visual_prompt]: Epoch 3 / 100: avg data time: 6.32e-02, avg batch time: 0.5054, average train loss: 5.7161
[09/26 07:07:53 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1675, average loss: 5.8250
[09/26 07:07:53 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 5.00	
[09/26 07:07:53 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.15
[09/26 07:08:00 visual_prompt]: Epoch 4 / 100: avg data time: 5.89e-02, avg batch time: 0.5020, average train loss: 5.5295
[09/26 07:08:02 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1671, average loss: 5.7570
[09/26 07:08:02 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.00	top5: 6.00	
[09/26 07:08:02 visual_prompt]: Best epoch 4: best metric: 0.020
[09/26 07:08:02 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.2
[09/26 07:08:09 visual_prompt]: Epoch 5 / 100: avg data time: 6.78e-02, avg batch time: 0.5108, average train loss: 5.2437
[09/26 07:08:10 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1671, average loss: 5.4147
[09/26 07:08:10 visual_prompt]: Classification results with val_vtab-sun397: top1: 4.50	top5: 16.00	
[09/26 07:08:10 visual_prompt]: Best epoch 5: best metric: 0.045
[09/26 07:08:10 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.25
[09/26 07:08:17 visual_prompt]: Epoch 6 / 100: avg data time: 5.78e-02, avg batch time: 0.5000, average train loss: 4.7729
[09/26 07:08:19 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1670, average loss: 5.0555
[09/26 07:08:19 visual_prompt]: Classification results with val_vtab-sun397: top1: 7.50	top5: 21.50	
[09/26 07:08:19 visual_prompt]: Best epoch 6: best metric: 0.075
[09/26 07:08:19 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.3
[09/26 07:08:26 visual_prompt]: Epoch 7 / 100: avg data time: 5.74e-02, avg batch time: 0.5003, average train loss: 4.1355
[09/26 07:08:27 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1670, average loss: 4.7458
[09/26 07:08:27 visual_prompt]: Classification results with val_vtab-sun397: top1: 11.50	top5: 30.00	
[09/26 07:08:27 visual_prompt]: Best epoch 7: best metric: 0.115
[09/26 07:08:27 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.35
[09/26 07:08:34 visual_prompt]: Epoch 8 / 100: avg data time: 6.45e-02, avg batch time: 0.5069, average train loss: 3.2220
[09/26 07:08:36 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1670, average loss: 4.2452
[09/26 07:08:36 visual_prompt]: Classification results with val_vtab-sun397: top1: 23.00	top5: 40.50	
[09/26 07:08:36 visual_prompt]: Best epoch 8: best metric: 0.230
[09/26 07:08:36 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.4
[09/26 07:08:43 visual_prompt]: Epoch 9 / 100: avg data time: 6.11e-02, avg batch time: 0.5037, average train loss: 2.3149
[09/26 07:08:45 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1670, average loss: 3.8779
[09/26 07:08:45 visual_prompt]: Classification results with val_vtab-sun397: top1: 26.00	top5: 47.00	
[09/26 07:08:45 visual_prompt]: Best epoch 9: best metric: 0.260
[09/26 07:08:45 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.45
[09/26 07:08:51 visual_prompt]: Epoch 10 / 100: avg data time: 6.12e-02, avg batch time: 0.5030, average train loss: 1.3982
[09/26 07:08:53 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1670, average loss: 3.4921
[09/26 07:08:53 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 58.50	
[09/26 07:08:53 visual_prompt]: Best epoch 10: best metric: 0.335
[09/26 07:08:53 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.5
[09/26 07:09:00 visual_prompt]: Epoch 11 / 100: avg data time: 6.16e-02, avg batch time: 0.5047, average train loss: 0.7076
[09/26 07:09:02 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1669, average loss: 3.3141
[09/26 07:09:02 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.50	top5: 60.50	
[09/26 07:09:02 visual_prompt]: Best epoch 11: best metric: 0.375
[09/26 07:09:02 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.49984770675477397
[09/26 07:09:08 visual_prompt]: Epoch 12 / 100: avg data time: 6.01e-02, avg batch time: 0.5028, average train loss: 0.3185
[09/26 07:09:10 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.1669, average loss: 3.2162
[09/26 07:09:10 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.50	top5: 60.00	
[09/26 07:09:10 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.49939101256495605
[09/26 07:09:17 visual_prompt]: Epoch 13 / 100: avg data time: 5.96e-02, avg batch time: 0.5025, average train loss: 0.1462
[09/26 07:09:18 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1671, average loss: 3.1550
[09/26 07:09:19 visual_prompt]: Classification results with val_vtab-sun397: top1: 36.00	top5: 63.50	
[09/26 07:09:19 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.4986304738420683
[09/26 07:09:25 visual_prompt]: Epoch 14 / 100: avg data time: 6.37e-02, avg batch time: 0.5059, average train loss: 0.0827
[09/26 07:09:27 visual_prompt]: Inference (val):avg data time: 3.56e-05, avg batch time: 0.1671, average loss: 3.1518
[09/26 07:09:27 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 62.50	
[09/26 07:09:27 visual_prompt]: Best epoch 14: best metric: 0.390
[09/26 07:09:27 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.4975670171853926
[09/26 07:09:34 visual_prompt]: Epoch 15 / 100: avg data time: 6.34e-02, avg batch time: 0.5065, average train loss: 0.0584
[09/26 07:09:36 visual_prompt]: Inference (val):avg data time: 4.01e-05, avg batch time: 0.1670, average loss: 3.1337
[09/26 07:09:36 visual_prompt]: Classification results with val_vtab-sun397: top1: 36.50	top5: 64.50	
[09/26 07:09:36 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.49620193825305203
[09/26 07:09:42 visual_prompt]: Epoch 16 / 100: avg data time: 6.06e-02, avg batch time: 0.5028, average train loss: 0.0447
[09/26 07:09:44 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1672, average loss: 3.0990
[09/26 07:09:44 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 64.50	
[09/26 07:09:44 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.4945369001834514
[09/26 07:09:51 visual_prompt]: Epoch 17 / 100: avg data time: 6.39e-02, avg batch time: 0.5063, average train loss: 0.0373
[09/26 07:09:53 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1673, average loss: 3.1285
[09/26 07:09:53 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.00	top5: 64.00	
[09/26 07:09:53 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.4925739315689991
[09/26 07:09:59 visual_prompt]: Epoch 18 / 100: avg data time: 4.98e-02, avg batch time: 0.4923, average train loss: 0.0318
[09/26 07:10:01 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1671, average loss: 3.1348
[09/26 07:10:01 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.50	top5: 64.50	
[09/26 07:10:01 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.4903154239845797
[09/26 07:10:08 visual_prompt]: Epoch 19 / 100: avg data time: 5.73e-02, avg batch time: 0.5000, average train loss: 0.0277
[09/26 07:10:09 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1674, average loss: 3.1295
[09/26 07:10:09 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.00	top5: 64.00	
[09/26 07:10:09 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.4877641290737884
[09/26 07:10:16 visual_prompt]: Epoch 20 / 100: avg data time: 6.55e-02, avg batch time: 0.5081, average train loss: 0.0256
[09/26 07:10:18 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1674, average loss: 3.1140
[09/26 07:10:18 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.00	top5: 65.50	
[09/26 07:10:18 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.4849231551964771
[09/26 07:10:25 visual_prompt]: Epoch 21 / 100: avg data time: 5.25e-02, avg batch time: 0.4950, average train loss: 0.0233
[09/26 07:10:26 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.1667, average loss: 3.1142
[09/26 07:10:26 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.50	top5: 64.50	
[09/26 07:10:26 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.48179596364169686
[09/26 07:10:33 visual_prompt]: Epoch 22 / 100: avg data time: 6.34e-02, avg batch time: 0.5064, average train loss: 0.0218
[09/26 07:10:35 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1668, average loss: 3.1207
[09/26 07:10:35 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.00	top5: 65.00	
[09/26 07:10:35 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.4783863644106502
[09/26 07:10:42 visual_prompt]: Epoch 23 / 100: avg data time: 5.87e-02, avg batch time: 0.5014, average train loss: 0.0198
[09/26 07:10:43 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1669, average loss: 3.1203
[09/26 07:10:43 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.00	top5: 64.50	
[09/26 07:10:43 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.47469851157479176
[09/26 07:10:50 visual_prompt]: Epoch 24 / 100: avg data time: 6.33e-02, avg batch time: 0.5057, average train loss: 0.0187
[09/26 07:10:52 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1669, average loss: 3.1227
[09/26 07:10:52 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.50	top5: 65.50	
[09/26 07:10:52 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.47073689821473175
[09/26 07:10:59 visual_prompt]: Epoch 25 / 100: avg data time: 5.18e-02, avg batch time: 0.4952, average train loss: 0.0175
[09/26 07:11:00 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1668, average loss: 3.1228
[09/26 07:11:00 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 65.00	
[09/26 07:11:00 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.4665063509461097
[09/26 07:11:07 visual_prompt]: Epoch 26 / 100: avg data time: 5.70e-02, avg batch time: 0.5006, average train loss: 0.0164
[09/26 07:11:09 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1667, average loss: 3.1126
[09/26 07:11:09 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 65.50	
[09/26 07:11:09 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.46201202403910646
[09/26 07:11:16 visual_prompt]: Epoch 27 / 100: avg data time: 6.25e-02, avg batch time: 0.5056, average train loss: 0.0155
[09/26 07:11:17 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.1670, average loss: 3.1121
[09/26 07:11:17 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 66.00	
[09/26 07:11:17 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.4572593931387604
[09/26 07:11:24 visual_prompt]: Epoch 28 / 100: avg data time: 5.55e-02, avg batch time: 0.4985, average train loss: 0.0148
[09/26 07:11:26 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1667, average loss: 3.1131
[09/26 07:11:26 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.00	top5: 66.00	
[09/26 07:11:26 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.45225424859373686
[09/26 07:11:33 visual_prompt]: Epoch 29 / 100: avg data time: 5.36e-02, avg batch time: 0.4963, average train loss: 0.0140
[09/26 07:11:34 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1669, average loss: 3.1089
[09/26 07:11:34 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.00	top5: 65.50	
[09/26 07:11:34 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.44700268840168045
[09/26 07:11:41 visual_prompt]: Epoch 30 / 100: avg data time: 5.86e-02, avg batch time: 0.5004, average train loss: 0.0135
[09/26 07:11:43 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1668, average loss: 3.1137
[09/26 07:11:43 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 65.50	
[09/26 07:11:43 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.4415111107797445
[09/26 07:11:49 visual_prompt]: Epoch 31 / 100: avg data time: 4.53e-02, avg batch time: 0.4889, average train loss: 0.0132
[09/26 07:11:51 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1678, average loss: 3.1161
[09/26 07:11:51 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 65.50	
[09/26 07:11:51 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.43578620636934856
[09/26 07:11:58 visual_prompt]: Epoch 32 / 100: avg data time: 5.51e-02, avg batch time: 0.4974, average train loss: 0.0125
[09/26 07:11:59 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1673, average loss: 3.1132
[09/26 07:11:59 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 66.00	
[09/26 07:11:59 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.42983495008466277
[09/26 07:12:06 visual_prompt]: Epoch 33 / 100: avg data time: 6.12e-02, avg batch time: 0.5039, average train loss: 0.0119
[09/26 07:12:08 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1671, average loss: 3.1120
[09/26 07:12:08 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.50	top5: 65.50	
[09/26 07:12:08 visual_prompt]: Best epoch 33: best metric: 0.395
[09/26 07:12:08 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.4236645926147493
[09/26 07:12:15 visual_prompt]: Epoch 34 / 100: avg data time: 6.17e-02, avg batch time: 0.5048, average train loss: 0.0118
[09/26 07:12:16 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1672, average loss: 3.1107
[09/26 07:12:16 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.50	top5: 66.00	
[09/26 07:12:16 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.41728265158971456
[09/26 07:12:23 visual_prompt]: Epoch 35 / 100: avg data time: 6.14e-02, avg batch time: 0.5040, average train loss: 0.0112
[09/26 07:12:25 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1672, average loss: 3.1135
[09/26 07:12:25 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 65.50	
[09/26 07:12:25 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.4106969024216348
[09/26 07:12:31 visual_prompt]: Epoch 36 / 100: avg data time: 5.34e-02, avg batch time: 0.4965, average train loss: 0.0108
[09/26 07:12:33 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1673, average loss: 3.1104
[09/26 07:12:33 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 65.50	
[09/26 07:12:33 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.40391536883141455
[09/26 07:12:40 visual_prompt]: Epoch 37 / 100: avg data time: 5.55e-02, avg batch time: 0.4998, average train loss: 0.0105
[09/26 07:12:42 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1671, average loss: 3.1124
[09/26 07:12:42 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 65.00	
[09/26 07:12:42 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.3969463130731183
[09/26 07:12:48 visual_prompt]: Epoch 38 / 100: avg data time: 6.30e-02, avg batch time: 0.5056, average train loss: 0.0102
[09/26 07:12:50 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1676, average loss: 3.1147
[09/26 07:12:50 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 64.50	
[09/26 07:12:50 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.3897982258676867
[09/26 07:12:57 visual_prompt]: Epoch 39 / 100: avg data time: 5.83e-02, avg batch time: 0.5002, average train loss: 0.0100
[09/26 07:12:58 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1669, average loss: 3.1168
[09/26 07:12:58 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.50	top5: 64.50	
[09/26 07:12:58 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.3824798160583012
[09/26 07:13:05 visual_prompt]: Epoch 40 / 100: avg data time: 4.72e-02, avg batch time: 0.4899, average train loss: 0.0096
[09/26 07:13:07 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1670, average loss: 3.1135
[09/26 07:13:07 visual_prompt]: Classification results with val_vtab-sun397: top1: 40.00	top5: 65.50	
[09/26 07:13:07 visual_prompt]: Best epoch 40: best metric: 0.400
[09/26 07:13:07 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.375
[09/26 07:13:14 visual_prompt]: Epoch 41 / 100: avg data time: 5.80e-02, avg batch time: 0.5014, average train loss: 0.0093
[09/26 07:13:15 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1672, average loss: 3.1082
[09/26 07:13:15 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.50	top5: 65.50	
[09/26 07:13:15 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.3673678906964727
[09/26 07:13:22 visual_prompt]: Epoch 42 / 100: avg data time: 4.75e-02, avg batch time: 0.4907, average train loss: 0.0092
[09/26 07:13:24 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1672, average loss: 3.1081
[09/26 07:13:24 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 65.50	
[09/26 07:13:24 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.35959278669726935
[09/26 07:13:30 visual_prompt]: Epoch 43 / 100: avg data time: 5.94e-02, avg batch time: 0.5012, average train loss: 0.0088
[09/26 07:13:32 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1671, average loss: 3.1090
[09/26 07:13:32 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.50	top5: 65.50	
[09/26 07:13:32 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.3516841607689501
[09/26 07:13:39 visual_prompt]: Epoch 44 / 100: avg data time: 6.33e-02, avg batch time: 0.5053, average train loss: 0.0087
[09/26 07:13:41 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1673, average loss: 3.1128
[09/26 07:13:41 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 65.50	
[09/26 07:13:41 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.34365164835397805
[09/26 07:13:47 visual_prompt]: Epoch 45 / 100: avg data time: 6.13e-02, avg batch time: 0.5034, average train loss: 0.0085
[09/26 07:13:49 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1674, average loss: 3.1115
[09/26 07:13:49 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 65.50	
[09/26 07:13:49 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.3355050358314172
[09/26 07:13:56 visual_prompt]: Epoch 46 / 100: avg data time: 6.85e-02, avg batch time: 0.5107, average train loss: 0.0082
[09/26 07:13:58 visual_prompt]: Inference (val):avg data time: 2.11e-05, avg batch time: 0.1670, average loss: 3.1139
[09/26 07:13:58 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 65.50	
[09/26 07:13:58 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.32725424859373686
[09/26 07:14:04 visual_prompt]: Epoch 47 / 100: avg data time: 5.84e-02, avg batch time: 0.5004, average train loss: 0.0081
[09/26 07:14:06 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1669, average loss: 3.1119
[09/26 07:14:06 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 65.50	
[09/26 07:14:06 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.3189093389542498
[09/26 07:14:13 visual_prompt]: Epoch 48 / 100: avg data time: 5.93e-02, avg batch time: 0.5013, average train loss: 0.0081
[09/26 07:14:15 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1671, average loss: 3.1118
[09/26 07:14:15 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.00	top5: 65.50	
[09/26 07:14:15 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.3104804738999169
[09/26 07:14:21 visual_prompt]: Epoch 49 / 100: avg data time: 5.72e-02, avg batch time: 0.4994, average train loss: 0.0080
[09/26 07:14:23 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1671, average loss: 3.1098
[09/26 07:14:23 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 66.00	
[09/26 07:14:23 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.3019779227044398
[09/26 07:14:30 visual_prompt]: Epoch 50 / 100: avg data time: 5.99e-02, avg batch time: 0.5023, average train loss: 0.0079
[09/26 07:14:32 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1671, average loss: 3.1119
[09/26 07:14:32 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.50	top5: 65.50	
[09/26 07:14:32 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.29341204441673263
[09/26 07:14:38 visual_prompt]: Epoch 51 / 100: avg data time: 6.10e-02, avg batch time: 0.5050, average train loss: 0.0077
[09/26 07:14:40 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1670, average loss: 3.1115
[09/26 07:14:40 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 65.00	
[09/26 07:14:40 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.28479327524001635
[09/26 07:14:47 visual_prompt]: Epoch 52 / 100: avg data time: 6.27e-02, avg batch time: 0.5047, average train loss: 0.0075
[09/26 07:14:49 visual_prompt]: Inference (val):avg data time: 3.96e-05, avg batch time: 0.1674, average loss: 3.1140
[09/26 07:14:49 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 64.50	
[09/26 07:14:49 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.2761321158169134
[09/26 07:14:55 visual_prompt]: Epoch 53 / 100: avg data time: 6.15e-02, avg batch time: 0.5035, average train loss: 0.0073
[09/26 07:14:57 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1668, average loss: 3.1148
[09/26 07:14:57 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 64.50	
[09/26 07:14:57 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.2674391184360313
[09/26 07:15:04 visual_prompt]: Epoch 54 / 100: avg data time: 6.29e-02, avg batch time: 0.5055, average train loss: 0.0073
[09/26 07:15:06 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1671, average loss: 3.1135
[09/26 07:15:06 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 65.50	
[09/26 07:15:06 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.2587248741756253
[09/26 07:15:13 visual_prompt]: Epoch 55 / 100: avg data time: 5.64e-02, avg batch time: 0.4997, average train loss: 0.0073
[09/26 07:15:14 visual_prompt]: Inference (val):avg data time: 4.11e-05, avg batch time: 0.1669, average loss: 3.1109
[09/26 07:15:14 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 65.00	
[09/26 07:15:14 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.25
[09/26 07:15:21 visual_prompt]: Epoch 56 / 100: avg data time: 6.19e-02, avg batch time: 0.5055, average train loss: 0.0072
[09/26 07:15:23 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1670, average loss: 3.1136
[09/26 07:15:23 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 64.50	
[09/26 07:15:23 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.24127512582437483
[09/26 07:15:30 visual_prompt]: Epoch 57 / 100: avg data time: 6.35e-02, avg batch time: 0.5057, average train loss: 0.0070
[09/26 07:15:31 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1672, average loss: 3.1156
[09/26 07:15:31 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 64.50	
[09/26 07:15:31 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.23256088156396867
[09/26 07:15:38 visual_prompt]: Epoch 58 / 100: avg data time: 4.86e-02, avg batch time: 0.4911, average train loss: 0.0070
[09/26 07:15:40 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1671, average loss: 3.1166
[09/26 07:15:40 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 64.50	
[09/26 07:15:40 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.22386788418308667
[09/26 07:15:47 visual_prompt]: Epoch 59 / 100: avg data time: 5.70e-02, avg batch time: 0.4994, average train loss: 0.0068
[09/26 07:15:48 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1670, average loss: 3.1165
[09/26 07:15:48 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 65.00	
[09/26 07:15:48 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.2152067247599837
[09/26 07:15:55 visual_prompt]: Epoch 60 / 100: avg data time: 5.83e-02, avg batch time: 0.5008, average train loss: 0.0068
[09/26 07:15:57 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1670, average loss: 3.1170
[09/26 07:15:57 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 64.50	
[09/26 07:15:57 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.20658795558326742
[09/26 07:16:04 visual_prompt]: Epoch 61 / 100: avg data time: 6.03e-02, avg batch time: 0.5046, average train loss: 0.0067
[09/26 07:16:05 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1669, average loss: 3.1179
[09/26 07:16:05 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 65.00	
[09/26 07:16:05 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.1980220772955602
[09/26 07:16:12 visual_prompt]: Epoch 62 / 100: avg data time: 6.28e-02, avg batch time: 0.5050, average train loss: 0.0067
[09/26 07:16:14 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1671, average loss: 3.1187
[09/26 07:16:14 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 64.50	
[09/26 07:16:14 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.1895195261000831
[09/26 07:16:21 visual_prompt]: Epoch 63 / 100: avg data time: 5.82e-02, avg batch time: 0.5006, average train loss: 0.0066
[09/26 07:16:22 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1669, average loss: 3.1179
[09/26 07:16:22 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 64.50	
[09/26 07:16:22 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.18109066104575022
[09/26 07:16:29 visual_prompt]: Epoch 64 / 100: avg data time: 5.69e-02, avg batch time: 0.5005, average train loss: 0.0065
[09/26 07:16:31 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1670, average loss: 3.1186
[09/26 07:16:31 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 64.50	
[09/26 07:16:31 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.17274575140626316
[09/26 07:16:38 visual_prompt]: Epoch 65 / 100: avg data time: 6.42e-02, avg batch time: 0.5073, average train loss: 0.0066
[09/26 07:16:39 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1671, average loss: 3.1193
[09/26 07:16:39 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 64.50	
[09/26 07:16:39 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.16449496416858284
[09/26 07:16:46 visual_prompt]: Epoch 66 / 100: avg data time: 5.97e-02, avg batch time: 0.5038, average train loss: 0.0065
[09/26 07:16:48 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1673, average loss: 3.1195
[09/26 07:16:48 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 65.00	
[09/26 07:16:48 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.15634835164602198
[09/26 07:16:55 visual_prompt]: Epoch 67 / 100: avg data time: 6.43e-02, avg batch time: 0.5074, average train loss: 0.0063
[09/26 07:16:56 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1675, average loss: 3.1205
[09/26 07:16:56 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 65.00	
[09/26 07:16:56 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.14831583923105
[09/26 07:17:03 visual_prompt]: Epoch 68 / 100: avg data time: 5.48e-02, avg batch time: 0.4987, average train loss: 0.0063
[09/26 07:17:05 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1671, average loss: 3.1205
[09/26 07:17:05 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 65.00	
[09/26 07:17:05 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.14040721330273062
[09/26 07:17:12 visual_prompt]: Epoch 69 / 100: avg data time: 6.25e-02, avg batch time: 0.5054, average train loss: 0.0063
[09/26 07:17:13 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1672, average loss: 3.1199
[09/26 07:17:13 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 65.00	
[09/26 07:17:13 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.13263210930352737
[09/26 07:17:20 visual_prompt]: Epoch 70 / 100: avg data time: 6.29e-02, avg batch time: 0.5060, average train loss: 0.0063
[09/26 07:17:22 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1673, average loss: 3.1203
[09/26 07:17:22 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 65.50	
[09/26 07:17:22 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.12500000000000006
[09/26 07:17:29 visual_prompt]: Epoch 71 / 100: avg data time: 5.37e-02, avg batch time: 0.4981, average train loss: 0.0063
[09/26 07:17:30 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1671, average loss: 3.1213
[09/26 07:17:30 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 65.00	
[09/26 07:17:30 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.1175201839416988
[09/26 07:17:37 visual_prompt]: Epoch 72 / 100: avg data time: 5.27e-02, avg batch time: 0.4954, average train loss: 0.0062
[09/26 07:17:39 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1676, average loss: 3.1222
[09/26 07:17:39 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 65.00	
[09/26 07:17:39 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.11020177413231333
[09/26 07:17:45 visual_prompt]: Epoch 73 / 100: avg data time: 4.82e-02, avg batch time: 0.4933, average train loss: 0.0062
[09/26 07:17:47 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1671, average loss: 3.1230
[09/26 07:17:47 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 65.50	
[09/26 07:17:47 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.10305368692688174
[09/26 07:17:54 visual_prompt]: Epoch 74 / 100: avg data time: 6.27e-02, avg batch time: 0.5052, average train loss: 0.0061
[09/26 07:17:55 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1675, average loss: 3.1233
[09/26 07:17:55 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 65.50	
[09/26 07:17:55 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.09608463116858543
[09/26 07:18:02 visual_prompt]: Epoch 75 / 100: avg data time: 6.19e-02, avg batch time: 0.5036, average train loss: 0.0061
[09/26 07:18:04 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.1671, average loss: 3.1231
[09/26 07:18:04 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 65.50	
[09/26 07:18:04 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.08930309757836516
[09/26 07:18:11 visual_prompt]: Epoch 76 / 100: avg data time: 5.81e-02, avg batch time: 0.5017, average train loss: 0.0061
[09/26 07:18:12 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.1672, average loss: 3.1230
[09/26 07:18:12 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 65.50	
[09/26 07:18:12 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.08271734841028552
[09/26 07:18:19 visual_prompt]: Epoch 77 / 100: avg data time: 5.58e-02, avg batch time: 0.4999, average train loss: 0.0061
[09/26 07:18:21 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1674, average loss: 3.1231
[09/26 07:18:21 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 65.50	
[09/26 07:18:21 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.07633540738525066
[09/26 07:18:28 visual_prompt]: Epoch 78 / 100: avg data time: 6.42e-02, avg batch time: 0.5073, average train loss: 0.0061
[09/26 07:18:29 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1674, average loss: 3.1224
[09/26 07:18:29 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.00	top5: 65.50	
[09/26 07:18:29 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.07016504991533726
[09/26 07:18:36 visual_prompt]: Epoch 79 / 100: avg data time: 6.00e-02, avg batch time: 0.5048, average train loss: 0.0060
[09/26 07:18:38 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1673, average loss: 3.1217
[09/26 07:18:38 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.00	top5: 65.50	
[09/26 07:18:38 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.06421379363065141
[09/26 07:18:45 visual_prompt]: Epoch 80 / 100: avg data time: 6.46e-02, avg batch time: 0.5066, average train loss: 0.0060
[09/26 07:18:46 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1671, average loss: 3.1213
[09/26 07:18:46 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.00	top5: 65.50	
[09/26 07:18:46 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.058488889220255524
[09/26 07:18:53 visual_prompt]: Epoch 81 / 100: avg data time: 5.21e-02, avg batch time: 0.4966, average train loss: 0.0061
[09/26 07:18:55 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1675, average loss: 3.1215
[09/26 07:18:55 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.00	top5: 65.50	
[09/26 07:18:55 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.052997311598319524
[09/26 07:19:02 visual_prompt]: Epoch 82 / 100: avg data time: 5.92e-02, avg batch time: 0.5017, average train loss: 0.0060
[09/26 07:19:03 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1669, average loss: 3.1216
[09/26 07:19:03 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.00	top5: 65.50	
[09/26 07:19:03 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.047745751406263165
[09/26 07:19:10 visual_prompt]: Epoch 83 / 100: avg data time: 6.11e-02, avg batch time: 0.5041, average train loss: 0.0060
[09/26 07:19:12 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1673, average loss: 3.1218
[09/26 07:19:12 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.00	top5: 65.50	
[09/26 07:19:12 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.042740606861239594
[09/26 07:19:19 visual_prompt]: Epoch 84 / 100: avg data time: 5.95e-02, avg batch time: 0.5030, average train loss: 0.0060
[09/26 07:19:20 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1674, average loss: 3.1220
[09/26 07:19:20 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.00	top5: 65.50	
[09/26 07:19:20 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.03798797596089351
[09/26 07:19:27 visual_prompt]: Epoch 85 / 100: avg data time: 6.36e-02, avg batch time: 0.5062, average train loss: 0.0060
[09/26 07:19:29 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1674, average loss: 3.1218
[09/26 07:19:29 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.00	top5: 65.50	
[09/26 07:19:29 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.03349364905389032
[09/26 07:19:36 visual_prompt]: Epoch 86 / 100: avg data time: 4.80e-02, avg batch time: 0.4928, average train loss: 0.0059
[09/26 07:19:37 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1671, average loss: 3.1220
[09/26 07:19:37 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.00	top5: 65.50	
[09/26 07:19:37 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.029263101785268253
[09/26 07:19:44 visual_prompt]: Epoch 87 / 100: avg data time: 5.69e-02, avg batch time: 0.5014, average train loss: 0.0060
[09/26 07:19:46 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1670, average loss: 3.1219
[09/26 07:19:46 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.00	top5: 65.50	
[09/26 07:19:46 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.025301488425208296
[09/26 07:19:53 visual_prompt]: Epoch 88 / 100: avg data time: 6.02e-02, avg batch time: 0.5026, average train loss: 0.0060
[09/26 07:19:54 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1676, average loss: 3.1218
[09/26 07:19:54 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.00	top5: 65.50	
[09/26 07:19:54 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.021613635589349756
[09/26 07:20:01 visual_prompt]: Epoch 89 / 100: avg data time: 5.93e-02, avg batch time: 0.5028, average train loss: 0.0059
[09/26 07:20:03 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1666, average loss: 3.1218
[09/26 07:20:03 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.00	top5: 65.50	
[09/26 07:20:03 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.01820403635830317
[09/26 07:20:10 visual_prompt]: Epoch 90 / 100: avg data time: 5.70e-02, avg batch time: 0.4995, average train loss: 0.0059
[09/26 07:20:11 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1673, average loss: 3.1217
[09/26 07:20:11 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.00	top5: 65.50	
[09/26 07:20:11 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.01507684480352292
[09/26 07:20:18 visual_prompt]: Epoch 91 / 100: avg data time: 5.97e-02, avg batch time: 0.5022, average train loss: 0.0059
[09/26 07:20:20 visual_prompt]: Inference (val):avg data time: 2.08e-05, avg batch time: 0.1672, average loss: 3.1217
[09/26 07:20:20 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.00	top5: 65.50	
[09/26 07:20:20 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.012235870926211617
[09/26 07:20:26 visual_prompt]: Epoch 92 / 100: avg data time: 5.55e-02, avg batch time: 0.4987, average train loss: 0.0060
[09/26 07:20:28 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1674, average loss: 3.1217
[09/26 07:20:28 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.00	top5: 65.50	
[09/26 07:20:28 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.009684576015420276
[09/26 07:20:35 visual_prompt]: Epoch 93 / 100: avg data time: 5.83e-02, avg batch time: 0.5016, average train loss: 0.0058
[09/26 07:20:37 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.1670, average loss: 3.1217
[09/26 07:20:37 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.00	top5: 65.50	
[09/26 07:20:37 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.007426068431000882
[09/26 07:20:43 visual_prompt]: Epoch 94 / 100: avg data time: 6.08e-02, avg batch time: 0.5038, average train loss: 0.0059
[09/26 07:20:45 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1670, average loss: 3.1217
[09/26 07:20:45 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.00	top5: 65.50	
[09/26 07:20:45 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.005463099816548578
[09/26 07:20:52 visual_prompt]: Epoch 95 / 100: avg data time: 6.42e-02, avg batch time: 0.5073, average train loss: 0.0058
[09/26 07:20:54 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1671, average loss: 3.1217
[09/26 07:20:54 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.00	top5: 65.50	
[09/26 07:20:54 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.003798061746947995
[09/26 07:21:00 visual_prompt]: Epoch 96 / 100: avg data time: 5.10e-02, avg batch time: 0.4954, average train loss: 0.0058
[09/26 07:21:02 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1676, average loss: 3.1217
[09/26 07:21:02 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.00	top5: 65.50	
[09/26 07:21:02 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.0024329828146074095
[09/26 07:21:09 visual_prompt]: Epoch 97 / 100: avg data time: 6.50e-02, avg batch time: 0.5092, average train loss: 0.0058
[09/26 07:21:11 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1675, average loss: 3.1217
[09/26 07:21:11 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.00	top5: 65.50	
[09/26 07:21:11 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.0013695261579316775
[09/26 07:21:17 visual_prompt]: Epoch 98 / 100: avg data time: 6.41e-02, avg batch time: 0.5067, average train loss: 0.0059
[09/26 07:21:19 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1676, average loss: 3.1217
[09/26 07:21:19 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.00	top5: 65.50	
[09/26 07:21:19 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.0006089874350439506
[09/26 07:21:26 visual_prompt]: Epoch 99 / 100: avg data time: 5.61e-02, avg batch time: 0.5004, average train loss: 0.0060
[09/26 07:21:28 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1672, average loss: 3.1217
[09/26 07:21:28 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.00	top5: 65.50	
[09/26 07:21:28 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.00015229324522605947
[09/26 07:21:34 visual_prompt]: Epoch 100 / 100: avg data time: 6.05e-02, avg batch time: 0.5039, average train loss: 0.0060
[09/26 07:21:36 visual_prompt]: Inference (val):avg data time: 5.76e-05, avg batch time: 0.1673, average loss: 3.1217
[09/26 07:21:36 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.00	top5: 65.50	
[09/26 07:21:36 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 07:21:36 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              0
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 07:21:36 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-sun397', 'DATA.NUMBER_CLASSES', '397', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 07:21:36 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 07:21:36 visual_prompt]: Training with config:
[09/26 07:21:36 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-sun397/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.25_wd0.01/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 0.25, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-sun397', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 397, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 07:21:36 visual_prompt]: Loading training data...
[09/26 07:21:36 visual_prompt]: Constructing vtab-sun397 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split train[:800], from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/26 07:21:37 visual_prompt]: Number of images: 800
[09/26 07:21:37 visual_prompt]: Number of classes: 309 / 397
[09/26 07:21:37 visual_prompt]: Loading validation data...
[09/26 07:21:37 visual_prompt]: Constructing vtab-sun397 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split validation[:200], from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/26 07:21:38 visual_prompt]: Number of images: 200
[09/26 07:21:38 visual_prompt]: Number of classes: 136 / 397
[09/26 07:21:38 visual_prompt]: Constructing models...
[09/26 07:21:40 visual_prompt]: Total Parameters: 86564749	 Gradient Parameters: 766093
[09/26 07:21:40 visual_prompt]: tuned percent:0.885
[09/26 07:21:40 visual_prompt]: Device used for model: 0
[09/26 07:21:40 visual_prompt]: Setting up Evaluator...
[09/26 07:21:40 visual_prompt]: Setting up Trainer...
[09/26 07:21:40 visual_prompt]: 	Setting up the optimizer...
[09/26 07:21:40 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 07:21:47 visual_prompt]: Epoch 1 / 100: avg data time: 6.37e-02, avg batch time: 0.5100, average train loss: 5.9886
[09/26 07:21:49 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1673, average loss: 6.0097
[09/26 07:21:49 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/26 07:21:49 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.025
[09/26 07:21:56 visual_prompt]: Epoch 2 / 100: avg data time: 5.06e-02, avg batch time: 0.4934, average train loss: 5.9599
[09/26 07:21:57 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1673, average loss: 5.9603
[09/26 07:21:57 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 2.50	
[09/26 07:21:57 visual_prompt]: Best epoch 2: best metric: 0.005
[09/26 07:21:57 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.05
[09/26 07:22:04 visual_prompt]: Epoch 3 / 100: avg data time: 6.54e-02, avg batch time: 0.5095, average train loss: 5.8344
[09/26 07:22:06 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1676, average loss: 5.8565
[09/26 07:22:06 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 07:22:06 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.075
[09/26 07:22:13 visual_prompt]: Epoch 4 / 100: avg data time: 5.34e-02, avg batch time: 0.4978, average train loss: 5.6415
[09/26 07:22:14 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1673, average loss: 5.8046
[09/26 07:22:14 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 5.00	
[09/26 07:22:14 visual_prompt]: Best epoch 4: best metric: 0.010
[09/26 07:22:14 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.1
[09/26 07:22:21 visual_prompt]: Epoch 5 / 100: avg data time: 5.94e-02, avg batch time: 0.5018, average train loss: 5.5078
[09/26 07:22:23 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1674, average loss: 5.6898
[09/26 07:22:23 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 7.00	
[09/26 07:22:23 visual_prompt]: Best epoch 5: best metric: 0.015
[09/26 07:22:23 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.125
[09/26 07:22:30 visual_prompt]: Epoch 6 / 100: avg data time: 6.00e-02, avg batch time: 0.5036, average train loss: 5.3149
[09/26 07:22:31 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1672, average loss: 5.4814
[09/26 07:22:31 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.50	top5: 13.00	
[09/26 07:22:31 visual_prompt]: Best epoch 6: best metric: 0.025
[09/26 07:22:31 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.15
[09/26 07:22:38 visual_prompt]: Epoch 7 / 100: avg data time: 6.61e-02, avg batch time: 0.5090, average train loss: 4.9280
[09/26 07:22:40 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1674, average loss: 5.1923
[09/26 07:22:40 visual_prompt]: Classification results with val_vtab-sun397: top1: 6.50	top5: 17.50	
[09/26 07:22:40 visual_prompt]: Best epoch 7: best metric: 0.065
[09/26 07:22:40 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.175
[09/26 07:22:47 visual_prompt]: Epoch 8 / 100: avg data time: 6.23e-02, avg batch time: 0.5052, average train loss: 4.5218
[09/26 07:22:48 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1675, average loss: 4.9072
[09/26 07:22:48 visual_prompt]: Classification results with val_vtab-sun397: top1: 11.00	top5: 26.50	
[09/26 07:22:48 visual_prompt]: Best epoch 8: best metric: 0.110
[09/26 07:22:48 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.2
[09/26 07:22:55 visual_prompt]: Epoch 9 / 100: avg data time: 5.39e-02, avg batch time: 0.4976, average train loss: 4.1947
[09/26 07:22:57 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1674, average loss: 4.6165
[09/26 07:22:57 visual_prompt]: Classification results with val_vtab-sun397: top1: 14.00	top5: 34.50	
[09/26 07:22:57 visual_prompt]: Best epoch 9: best metric: 0.140
[09/26 07:22:57 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.225
[09/26 07:23:04 visual_prompt]: Epoch 10 / 100: avg data time: 5.48e-02, avg batch time: 0.4990, average train loss: 3.7386
[09/26 07:23:05 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1675, average loss: 4.6638
[09/26 07:23:05 visual_prompt]: Classification results with val_vtab-sun397: top1: 11.00	top5: 30.50	
[09/26 07:23:05 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.25
[09/26 07:23:12 visual_prompt]: Epoch 11 / 100: avg data time: 6.26e-02, avg batch time: 0.5057, average train loss: 3.3731
[09/26 07:23:14 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1676, average loss: 4.8570
[09/26 07:23:14 visual_prompt]: Classification results with val_vtab-sun397: top1: 10.50	top5: 23.50	
[09/26 07:23:14 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.24992385337738698
[09/26 07:23:21 visual_prompt]: Epoch 12 / 100: avg data time: 6.03e-02, avg batch time: 0.5050, average train loss: 3.2116
[09/26 07:23:22 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1676, average loss: 4.4032
[09/26 07:23:22 visual_prompt]: Classification results with val_vtab-sun397: top1: 15.00	top5: 35.00	
[09/26 07:23:22 visual_prompt]: Best epoch 12: best metric: 0.150
[09/26 07:23:22 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.24969550628247802
[09/26 07:23:29 visual_prompt]: Epoch 13 / 100: avg data time: 6.27e-02, avg batch time: 0.5062, average train loss: 3.1408
[09/26 07:23:31 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1679, average loss: 4.2421
[09/26 07:23:31 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.50	top5: 45.00	
[09/26 07:23:31 visual_prompt]: Best epoch 13: best metric: 0.215
[09/26 07:23:31 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.24931523692103416
[09/26 07:23:38 visual_prompt]: Epoch 14 / 100: avg data time: 6.05e-02, avg batch time: 0.5032, average train loss: 2.7240
[09/26 07:23:39 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1677, average loss: 3.8649
[09/26 07:23:39 visual_prompt]: Classification results with val_vtab-sun397: top1: 30.00	top5: 57.00	
[09/26 07:23:39 visual_prompt]: Best epoch 14: best metric: 0.300
[09/26 07:23:39 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.2487835085926963
[09/26 07:23:46 visual_prompt]: Epoch 15 / 100: avg data time: 6.44e-02, avg batch time: 0.5075, average train loss: 2.3761
[09/26 07:23:48 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.1681, average loss: 3.7685
[09/26 07:23:48 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.00	top5: 55.50	
[09/26 07:23:48 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.24810096912652602
[09/26 07:23:55 visual_prompt]: Epoch 16 / 100: avg data time: 5.98e-02, avg batch time: 0.5038, average train loss: 2.1662
[09/26 07:23:56 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1678, average loss: 3.6670
[09/26 07:23:56 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 61.50	
[09/26 07:23:56 visual_prompt]: Best epoch 16: best metric: 0.335
[09/26 07:23:56 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.2472684500917257
[09/26 07:24:03 visual_prompt]: Epoch 17 / 100: avg data time: 5.82e-02, avg batch time: 0.5025, average train loss: 2.0253
[09/26 07:24:05 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1679, average loss: 3.6099
[09/26 07:24:05 visual_prompt]: Classification results with val_vtab-sun397: top1: 35.50	top5: 62.50	
[09/26 07:24:05 visual_prompt]: Best epoch 17: best metric: 0.355
[09/26 07:24:05 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.24628696578449955
[09/26 07:24:12 visual_prompt]: Epoch 18 / 100: avg data time: 5.73e-02, avg batch time: 0.5011, average train loss: 1.9770
[09/26 07:24:13 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1675, average loss: 3.6229
[09/26 07:24:13 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.50	top5: 64.00	
[09/26 07:24:13 visual_prompt]: Best epoch 18: best metric: 0.395
[09/26 07:24:13 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.24515771199228986
[09/26 07:24:20 visual_prompt]: Epoch 19 / 100: avg data time: 6.17e-02, avg batch time: 0.5048, average train loss: 1.8922
[09/26 07:24:22 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1677, average loss: 3.6215
[09/26 07:24:22 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.00	top5: 61.50	
[09/26 07:24:22 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.2438820645368942
[09/26 07:24:29 visual_prompt]: Epoch 20 / 100: avg data time: 6.03e-02, avg batch time: 0.5046, average train loss: 1.8437
[09/26 07:24:31 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1677, average loss: 3.6398
[09/26 07:24:31 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 62.00	
[09/26 07:24:31 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.24246157759823855
[09/26 07:24:37 visual_prompt]: Epoch 21 / 100: avg data time: 6.06e-02, avg batch time: 0.5039, average train loss: 1.8042
[09/26 07:24:39 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1679, average loss: 3.7108
[09/26 07:24:39 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 59.50	
[09/26 07:24:39 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.24089798182084843
[09/26 07:24:46 visual_prompt]: Epoch 22 / 100: avg data time: 5.85e-02, avg batch time: 0.5016, average train loss: 1.8508
[09/26 07:24:48 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1680, average loss: 3.5834
[09/26 07:24:48 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.00	top5: 61.50	
[09/26 07:24:48 visual_prompt]: Best epoch 22: best metric: 0.410
[09/26 07:24:48 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.2391931822053251
[09/26 07:24:55 visual_prompt]: Epoch 23 / 100: avg data time: 6.38e-02, avg batch time: 0.5069, average train loss: 1.8176
[09/26 07:24:56 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1679, average loss: 3.5649
[09/26 07:24:56 visual_prompt]: Classification results with val_vtab-sun397: top1: 40.50	top5: 64.00	
[09/26 07:24:56 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.23734925578739588
[09/26 07:25:03 visual_prompt]: Epoch 24 / 100: avg data time: 6.26e-02, avg batch time: 0.5059, average train loss: 1.7213
[09/26 07:25:05 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1677, average loss: 3.5672
[09/26 07:25:05 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.50	top5: 62.50	
[09/26 07:25:05 visual_prompt]: Best epoch 24: best metric: 0.415
[09/26 07:25:05 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.23536844910736587
[09/26 07:25:12 visual_prompt]: Epoch 25 / 100: avg data time: 5.54e-02, avg batch time: 0.4995, average train loss: 1.8522
[09/26 07:25:13 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1676, average loss: 3.6305
[09/26 07:25:13 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 62.00	
[09/26 07:25:13 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.23325317547305485
[09/26 07:25:20 visual_prompt]: Epoch 26 / 100: avg data time: 6.07e-02, avg batch time: 0.5042, average train loss: 1.7410
[09/26 07:25:22 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1680, average loss: 3.6741
[09/26 07:25:22 visual_prompt]: Classification results with val_vtab-sun397: top1: 36.00	top5: 60.50	
[09/26 07:25:22 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.23100601201955323
[09/26 07:25:29 visual_prompt]: Epoch 27 / 100: avg data time: 6.15e-02, avg batch time: 0.5050, average train loss: 1.6928
[09/26 07:25:30 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1672, average loss: 3.5431
[09/26 07:25:30 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.00	top5: 62.50	
[09/26 07:25:30 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.2286296965693802
[09/26 07:25:37 visual_prompt]: Epoch 28 / 100: avg data time: 5.72e-02, avg batch time: 0.5025, average train loss: 1.6212
[09/26 07:25:39 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1677, average loss: 3.5447
[09/26 07:25:39 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.50	top5: 66.00	
[09/26 07:25:39 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.22612712429686843
[09/26 07:25:46 visual_prompt]: Epoch 29 / 100: avg data time: 5.85e-02, avg batch time: 0.5023, average train loss: 1.6394
[09/26 07:25:47 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1682, average loss: 3.6101
[09/26 07:25:47 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 63.00	
[09/26 07:25:47 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.22350134420084022
[09/26 07:25:54 visual_prompt]: Epoch 30 / 100: avg data time: 5.16e-02, avg batch time: 0.4955, average train loss: 1.6567
[09/26 07:25:56 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1678, average loss: 3.5812
[09/26 07:25:56 visual_prompt]: Classification results with val_vtab-sun397: top1: 40.50	top5: 66.00	
[09/26 07:25:56 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.22075555538987224
[09/26 07:26:03 visual_prompt]: Epoch 31 / 100: avg data time: 5.99e-02, avg batch time: 0.5038, average train loss: 1.6323
[09/26 07:26:04 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1679, average loss: 3.4901
[09/26 07:26:04 visual_prompt]: Classification results with val_vtab-sun397: top1: 40.50	top5: 64.00	
[09/26 07:26:04 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.21789310318467428
[09/26 07:26:11 visual_prompt]: Epoch 32 / 100: avg data time: 5.18e-02, avg batch time: 0.4968, average train loss: 2.5473
[09/26 07:26:13 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1681, average loss: 3.7873
[09/26 07:26:13 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 63.00	
[09/26 07:26:13 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.21491747504233139
[09/26 07:26:20 visual_prompt]: Epoch 33 / 100: avg data time: 6.38e-02, avg batch time: 0.5062, average train loss: 1.9749
[09/26 07:26:21 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1678, average loss: 3.7311
[09/26 07:26:21 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.00	top5: 61.50	
[09/26 07:26:21 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.21183229630737466
[09/26 07:26:28 visual_prompt]: Epoch 34 / 100: avg data time: 5.63e-02, avg batch time: 0.4994, average train loss: 1.8073
[09/26 07:26:30 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1678, average loss: 3.5648
[09/26 07:26:30 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.00	top5: 64.50	
[09/26 07:26:30 visual_prompt]: Best epoch 34: best metric: 0.420
[09/26 07:26:30 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.20864132579485728
[09/26 07:26:37 visual_prompt]: Epoch 35 / 100: avg data time: 6.07e-02, avg batch time: 0.5044, average train loss: 1.6723
[09/26 07:26:38 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1675, average loss: 3.5092
[09/26 07:26:38 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.50	top5: 64.50	
[09/26 07:26:38 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.2053484512108174
[09/26 07:26:45 visual_prompt]: Epoch 36 / 100: avg data time: 6.50e-02, avg batch time: 0.5088, average train loss: 1.6190
[09/26 07:26:47 visual_prompt]: Inference (val):avg data time: 2.08e-05, avg batch time: 0.1677, average loss: 3.5012
[09/26 07:26:47 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.50	top5: 66.50	
[09/26 07:26:47 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.20195768441570727
[09/26 07:26:54 visual_prompt]: Epoch 37 / 100: avg data time: 6.91e-02, avg batch time: 0.5121, average train loss: 1.6028
[09/26 07:26:55 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1675, average loss: 3.5469
[09/26 07:26:55 visual_prompt]: Classification results with val_vtab-sun397: top1: 40.00	top5: 63.00	
[09/26 07:26:55 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.19847315653655914
[09/26 07:27:02 visual_prompt]: Epoch 38 / 100: avg data time: 4.85e-02, avg batch time: 0.4923, average train loss: 1.6154
[09/26 07:27:04 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1678, average loss: 3.5964
[09/26 07:27:04 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.00	top5: 68.00	
[09/26 07:27:04 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.19489911293384335
[09/26 07:27:11 visual_prompt]: Epoch 39 / 100: avg data time: 6.54e-02, avg batch time: 0.5080, average train loss: 1.5879
[09/26 07:27:12 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1672, average loss: 3.5494
[09/26 07:27:12 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.50	top5: 63.50	
[09/26 07:27:12 visual_prompt]: Best epoch 39: best metric: 0.425
[09/26 07:27:12 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.1912399080291506
[09/26 07:27:19 visual_prompt]: Epoch 40 / 100: avg data time: 6.52e-02, avg batch time: 0.5085, average train loss: 1.5942
[09/26 07:27:21 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1672, average loss: 3.5426
[09/26 07:27:21 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.50	top5: 63.50	
[09/26 07:27:21 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.1875
[09/26 07:27:28 visual_prompt]: Epoch 41 / 100: avg data time: 6.05e-02, avg batch time: 0.5044, average train loss: 1.5669
[09/26 07:27:29 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1674, average loss: 3.5408
[09/26 07:27:29 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 63.00	
[09/26 07:27:29 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.18368394534823634
[09/26 07:27:36 visual_prompt]: Epoch 42 / 100: avg data time: 6.52e-02, avg batch time: 0.5084, average train loss: 1.5358
[09/26 07:27:38 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1675, average loss: 3.6675
[09/26 07:27:38 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.00	top5: 62.00	
[09/26 07:27:38 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.17979639334863468
[09/26 07:27:45 visual_prompt]: Epoch 43 / 100: avg data time: 5.95e-02, avg batch time: 0.5030, average train loss: 1.5519
[09/26 07:27:46 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1674, average loss: 3.5151
[09/26 07:27:46 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.00	top5: 65.00	
[09/26 07:27:46 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.17584208038447505
[09/26 07:27:53 visual_prompt]: Epoch 44 / 100: avg data time: 6.43e-02, avg batch time: 0.5088, average train loss: 1.5077
[09/26 07:27:55 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1678, average loss: 3.5212
[09/26 07:27:55 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.50	top5: 64.00	
[09/26 07:27:55 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.17182582417698902
[09/26 07:28:02 visual_prompt]: Epoch 45 / 100: avg data time: 6.15e-02, avg batch time: 0.5051, average train loss: 1.4901
[09/26 07:28:04 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1674, average loss: 3.4700
[09/26 07:28:04 visual_prompt]: Classification results with val_vtab-sun397: top1: 43.00	top5: 67.50	
[09/26 07:28:04 visual_prompt]: Best epoch 45: best metric: 0.430
[09/26 07:28:04 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.1677525179157086
[09/26 07:28:10 visual_prompt]: Epoch 46 / 100: avg data time: 6.02e-02, avg batch time: 0.5045, average train loss: 1.5415
[09/26 07:28:12 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1675, average loss: 3.5745
[09/26 07:28:12 visual_prompt]: Classification results with val_vtab-sun397: top1: 40.50	top5: 64.50	
[09/26 07:28:12 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.16362712429686843
[09/26 07:28:19 visual_prompt]: Epoch 47 / 100: avg data time: 5.10e-02, avg batch time: 0.4943, average train loss: 1.5379
[09/26 07:28:20 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1673, average loss: 3.5373
[09/26 07:28:20 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 65.00	
[09/26 07:28:20 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.1594546694771249
[09/26 07:28:27 visual_prompt]: Epoch 48 / 100: avg data time: 5.90e-02, avg batch time: 0.5019, average train loss: 1.4766
[09/26 07:28:29 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1674, average loss: 3.5558
[09/26 07:28:29 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.50	top5: 66.50	
[09/26 07:28:29 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.15524023694995845
[09/26 07:28:36 visual_prompt]: Epoch 49 / 100: avg data time: 6.40e-02, avg batch time: 0.5070, average train loss: 1.4892
[09/26 07:28:38 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1675, average loss: 3.5518
[09/26 07:28:38 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.00	top5: 67.00	
[09/26 07:28:38 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.1509889613522199
[09/26 07:28:45 visual_prompt]: Epoch 50 / 100: avg data time: 6.36e-02, avg batch time: 0.5074, average train loss: 1.4726
[09/26 07:28:46 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1673, average loss: 3.5565
[09/26 07:28:46 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.00	top5: 64.50	
[09/26 07:28:46 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.14670602220836632
[09/26 07:28:53 visual_prompt]: Epoch 51 / 100: avg data time: 6.38e-02, avg batch time: 0.5065, average train loss: 1.4395
[09/26 07:28:55 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1672, average loss: 3.4688
[09/26 07:28:55 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.50	top5: 66.50	
[09/26 07:28:55 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.14239663762000818
[09/26 07:29:02 visual_prompt]: Epoch 52 / 100: avg data time: 6.03e-02, avg batch time: 0.5027, average train loss: 1.4356
[09/26 07:29:03 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.1677, average loss: 3.5363
[09/26 07:29:03 visual_prompt]: Classification results with val_vtab-sun397: top1: 40.50	top5: 63.00	
[09/26 07:29:03 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.1380660579084567
[09/26 07:29:10 visual_prompt]: Epoch 53 / 100: avg data time: 4.71e-02, avg batch time: 0.4924, average train loss: 1.4284
[09/26 07:29:12 visual_prompt]: Inference (val):avg data time: 5.39e-05, avg batch time: 0.1680, average loss: 3.4979
[09/26 07:29:12 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.50	top5: 67.00	
[09/26 07:29:12 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.13371955921801565
[09/26 07:29:19 visual_prompt]: Epoch 54 / 100: avg data time: 5.97e-02, avg batch time: 0.5038, average train loss: 1.4287
[09/26 07:29:20 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1676, average loss: 3.5806
[09/26 07:29:20 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.00	top5: 63.00	
[09/26 07:29:20 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.12936243708781264
[09/26 07:29:27 visual_prompt]: Epoch 55 / 100: avg data time: 5.32e-02, avg batch time: 0.4975, average train loss: 1.4235
[09/26 07:29:29 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1679, average loss: 3.4430
[09/26 07:29:29 visual_prompt]: Classification results with val_vtab-sun397: top1: 43.00	top5: 67.50	
[09/26 07:29:29 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.125
[09/26 07:29:36 visual_prompt]: Epoch 56 / 100: avg data time: 6.51e-02, avg batch time: 0.5089, average train loss: 1.3780
[09/26 07:29:37 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1680, average loss: 3.4674
[09/26 07:29:37 visual_prompt]: Classification results with val_vtab-sun397: top1: 43.50	top5: 66.00	
[09/26 07:29:37 visual_prompt]: Best epoch 56: best metric: 0.435
[09/26 07:29:37 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.12063756291218741
[09/26 07:29:44 visual_prompt]: Epoch 57 / 100: avg data time: 6.42e-02, avg batch time: 0.5074, average train loss: 1.3893
[09/26 07:29:46 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1676, average loss: 3.5211
[09/26 07:29:46 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.00	top5: 65.50	
[09/26 07:29:46 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.11628044078198434
[09/26 07:29:53 visual_prompt]: Epoch 58 / 100: avg data time: 5.79e-02, avg batch time: 0.5022, average train loss: 1.4004
[09/26 07:29:54 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1677, average loss: 3.5271
[09/26 07:29:54 visual_prompt]: Classification results with val_vtab-sun397: top1: 43.50	top5: 66.00	
[09/26 07:29:54 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.11193394209154334
[09/26 07:30:01 visual_prompt]: Epoch 59 / 100: avg data time: 5.71e-02, avg batch time: 0.5002, average train loss: 1.3673
[09/26 07:30:03 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1675, average loss: 3.4635
[09/26 07:30:03 visual_prompt]: Classification results with val_vtab-sun397: top1: 43.50	top5: 67.00	
[09/26 07:30:03 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.10760336237999185
[09/26 07:30:10 visual_prompt]: Epoch 60 / 100: avg data time: 5.23e-02, avg batch time: 0.4966, average train loss: 1.3324
[09/26 07:30:11 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1679, average loss: 3.4902
[09/26 07:30:11 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.00	top5: 66.00	
[09/26 07:30:11 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.10329397779163371
[09/26 07:30:18 visual_prompt]: Epoch 61 / 100: avg data time: 5.87e-02, avg batch time: 0.5024, average train loss: 1.3209
[09/26 07:30:20 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1678, average loss: 3.4690
[09/26 07:30:20 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.50	top5: 66.50	
[09/26 07:30:20 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.0990110386477801
[09/26 07:30:26 visual_prompt]: Epoch 62 / 100: avg data time: 6.11e-02, avg batch time: 0.5058, average train loss: 1.3033
[09/26 07:30:28 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1677, average loss: 3.4773
[09/26 07:30:28 visual_prompt]: Classification results with val_vtab-sun397: top1: 40.00	top5: 65.00	
[09/26 07:30:28 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.09475976305004155
[09/26 07:30:35 visual_prompt]: Epoch 63 / 100: avg data time: 6.56e-02, avg batch time: 0.5089, average train loss: 1.3122
[09/26 07:30:37 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1675, average loss: 3.5864
[09/26 07:30:37 visual_prompt]: Classification results with val_vtab-sun397: top1: 40.00	top5: 64.00	
[09/26 07:30:37 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.09054533052287511
[09/26 07:30:44 visual_prompt]: Epoch 64 / 100: avg data time: 5.59e-02, avg batch time: 0.5006, average train loss: 1.3553
[09/26 07:30:45 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1676, average loss: 3.5298
[09/26 07:30:45 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.00	top5: 63.00	
[09/26 07:30:45 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.08637287570313158
[09/26 07:30:52 visual_prompt]: Epoch 65 / 100: avg data time: 6.18e-02, avg batch time: 0.5047, average train loss: 1.3427
[09/26 07:30:54 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1674, average loss: 3.6626
[09/26 07:30:54 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.00	top5: 64.00	
[09/26 07:30:54 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.08224748208429142
[09/26 07:31:01 visual_prompt]: Epoch 66 / 100: avg data time: 6.04e-02, avg batch time: 0.5034, average train loss: 1.7410
[09/26 07:31:02 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1675, average loss: 3.7249
[09/26 07:31:02 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.00	top5: 64.50	
[09/26 07:31:02 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.07817417582301099
[09/26 07:31:09 visual_prompt]: Epoch 67 / 100: avg data time: 6.09e-02, avg batch time: 0.5037, average train loss: 1.7859
[09/26 07:31:11 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1674, average loss: 3.5762
[09/26 07:31:11 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.00	top5: 63.50	
[09/26 07:31:11 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.074157919615525
[09/26 07:31:18 visual_prompt]: Epoch 68 / 100: avg data time: 5.63e-02, avg batch time: 0.5007, average train loss: 1.5725
[09/26 07:31:19 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1672, average loss: 3.5738
[09/26 07:31:19 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.50	top5: 65.50	
[09/26 07:31:19 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.07020360665136531
[09/26 07:31:26 visual_prompt]: Epoch 69 / 100: avg data time: 6.24e-02, avg batch time: 0.5056, average train loss: 1.4567
[09/26 07:31:28 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1676, average loss: 3.4743
[09/26 07:31:28 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.50	top5: 67.00	
[09/26 07:31:28 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.06631605465176368
[09/26 07:31:35 visual_prompt]: Epoch 70 / 100: avg data time: 5.04e-02, avg batch time: 0.4939, average train loss: 1.3551
[09/26 07:31:36 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1673, average loss: 3.4615
[09/26 07:31:36 visual_prompt]: Classification results with val_vtab-sun397: top1: 40.50	top5: 65.50	
[09/26 07:31:36 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.06250000000000003
[09/26 07:31:43 visual_prompt]: Epoch 71 / 100: avg data time: 6.00e-02, avg batch time: 0.5027, average train loss: 1.3008
[09/26 07:31:45 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1673, average loss: 3.4540
[09/26 07:31:45 visual_prompt]: Classification results with val_vtab-sun397: top1: 43.50	top5: 66.50	
[09/26 07:31:45 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.0587600919708494
[09/26 07:31:52 visual_prompt]: Epoch 72 / 100: avg data time: 6.47e-02, avg batch time: 0.5086, average train loss: 1.2702
[09/26 07:31:53 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1674, average loss: 3.4424
[09/26 07:31:53 visual_prompt]: Classification results with val_vtab-sun397: top1: 45.00	top5: 66.00	
[09/26 07:31:53 visual_prompt]: Best epoch 72: best metric: 0.450
[09/26 07:31:53 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.055100887066156665
[09/26 07:32:00 visual_prompt]: Epoch 73 / 100: avg data time: 6.47e-02, avg batch time: 0.5074, average train loss: 1.2409
[09/26 07:32:02 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1674, average loss: 3.4654
[09/26 07:32:02 visual_prompt]: Classification results with val_vtab-sun397: top1: 43.50	top5: 64.50	
[09/26 07:32:02 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.05152684346344087
[09/26 07:32:09 visual_prompt]: Epoch 74 / 100: avg data time: 5.54e-02, avg batch time: 0.4997, average train loss: 1.2212
[09/26 07:32:10 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1676, average loss: 3.4612
[09/26 07:32:10 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.00	top5: 65.50	
[09/26 07:32:10 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.048042315584292714
[09/26 07:32:17 visual_prompt]: Epoch 75 / 100: avg data time: 5.80e-02, avg batch time: 0.5019, average train loss: 1.2092
[09/26 07:32:19 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.1675, average loss: 3.4681
[09/26 07:32:19 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.00	top5: 65.50	
[09/26 07:32:19 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.04465154878918258
[09/26 07:32:26 visual_prompt]: Epoch 76 / 100: avg data time: 6.39e-02, avg batch time: 0.5071, average train loss: 1.2031
[09/26 07:32:27 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1675, average loss: 3.4669
[09/26 07:32:27 visual_prompt]: Classification results with val_vtab-sun397: top1: 44.00	top5: 66.00	
[09/26 07:32:27 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.04135867420514276
[09/26 07:32:34 visual_prompt]: Epoch 77 / 100: avg data time: 5.57e-02, avg batch time: 0.5002, average train loss: 1.2152
[09/26 07:32:36 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1677, average loss: 3.4803
[09/26 07:32:36 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.00	top5: 65.50	
[09/26 07:32:36 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.03816770369262533
[09/26 07:32:43 visual_prompt]: Epoch 78 / 100: avg data time: 6.46e-02, avg batch time: 0.5076, average train loss: 1.1968
[09/26 07:32:44 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1675, average loss: 3.5098
[09/26 07:32:44 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.50	top5: 66.50	
[09/26 07:32:44 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.03508252495766863
[09/26 07:32:51 visual_prompt]: Epoch 79 / 100: avg data time: 5.87e-02, avg batch time: 0.5033, average train loss: 1.1825
[09/26 07:32:53 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1676, average loss: 3.4976
[09/26 07:32:53 visual_prompt]: Classification results with val_vtab-sun397: top1: 41.50	top5: 65.50	
[09/26 07:32:53 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.032106896815325706
[09/26 07:33:00 visual_prompt]: Epoch 80 / 100: avg data time: 6.44e-02, avg batch time: 0.5073, average train loss: 1.1695
[09/26 07:33:01 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1674, average loss: 3.4720
[09/26 07:33:01 visual_prompt]: Classification results with val_vtab-sun397: top1: 44.00	top5: 67.00	
[09/26 07:33:01 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.029244444610127762
[09/26 07:33:08 visual_prompt]: Epoch 81 / 100: avg data time: 6.13e-02, avg batch time: 0.5039, average train loss: 1.1544
[09/26 07:33:10 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1675, average loss: 3.4776
[09/26 07:33:10 visual_prompt]: Classification results with val_vtab-sun397: top1: 43.50	top5: 64.50	
[09/26 07:33:10 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.026498655799159762
[09/26 07:33:17 visual_prompt]: Epoch 82 / 100: avg data time: 6.46e-02, avg batch time: 0.5077, average train loss: 1.1414
[09/26 07:33:18 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1677, average loss: 3.4786
[09/26 07:33:18 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.50	top5: 65.50	
[09/26 07:33:18 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.023872875703131582
[09/26 07:33:25 visual_prompt]: Epoch 83 / 100: avg data time: 5.59e-02, avg batch time: 0.4995, average train loss: 1.1287
[09/26 07:33:27 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1674, average loss: 3.4651
[09/26 07:33:27 visual_prompt]: Classification results with val_vtab-sun397: top1: 43.00	top5: 65.00	
[09/26 07:33:27 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.021370303430619797
[09/26 07:33:34 visual_prompt]: Epoch 84 / 100: avg data time: 5.84e-02, avg batch time: 0.5034, average train loss: 1.1182
[09/26 07:33:35 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1675, average loss: 3.4657
[09/26 07:33:35 visual_prompt]: Classification results with val_vtab-sun397: top1: 43.50	top5: 65.00	
[09/26 07:33:35 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.018993987980446755
[09/26 07:33:42 visual_prompt]: Epoch 85 / 100: avg data time: 5.73e-02, avg batch time: 0.5010, average train loss: 1.1054
[09/26 07:33:44 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1672, average loss: 3.4640
[09/26 07:33:44 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.50	top5: 65.50	
[09/26 07:33:44 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.01674682452694516
[09/26 07:33:51 visual_prompt]: Epoch 86 / 100: avg data time: 5.77e-02, avg batch time: 0.5004, average train loss: 1.0969
[09/26 07:33:52 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1679, average loss: 3.4464
[09/26 07:33:52 visual_prompt]: Classification results with val_vtab-sun397: top1: 44.00	top5: 66.00	
[09/26 07:33:52 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.014631550892634126
[09/26 07:33:59 visual_prompt]: Epoch 87 / 100: avg data time: 5.84e-02, avg batch time: 0.5026, average train loss: 1.0905
[09/26 07:34:01 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1674, average loss: 3.4712
[09/26 07:34:01 visual_prompt]: Classification results with val_vtab-sun397: top1: 43.00	top5: 66.00	
[09/26 07:34:01 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.012650744212604148
[09/26 07:34:08 visual_prompt]: Epoch 88 / 100: avg data time: 6.07e-02, avg batch time: 0.5036, average train loss: 1.0800
[09/26 07:34:09 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1673, average loss: 3.4588
[09/26 07:34:09 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.00	top5: 65.00	
[09/26 07:34:09 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.010806817794674878
[09/26 07:34:16 visual_prompt]: Epoch 89 / 100: avg data time: 6.58e-02, avg batch time: 0.5089, average train loss: 1.0785
[09/26 07:34:18 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1677, average loss: 3.4568
[09/26 07:34:18 visual_prompt]: Classification results with val_vtab-sun397: top1: 44.00	top5: 65.00	
[09/26 07:34:18 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.009102018179151586
[09/26 07:34:25 visual_prompt]: Epoch 90 / 100: avg data time: 6.97e-02, avg batch time: 0.5119, average train loss: 1.0731
[09/26 07:34:26 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1681, average loss: 3.4656
[09/26 07:34:26 visual_prompt]: Classification results with val_vtab-sun397: top1: 43.00	top5: 66.00	
[09/26 07:34:26 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.00753842240176146
[09/26 07:34:33 visual_prompt]: Epoch 91 / 100: avg data time: 6.38e-02, avg batch time: 0.5062, average train loss: 1.0697
[09/26 07:34:35 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1677, average loss: 3.4534
[09/26 07:34:35 visual_prompt]: Classification results with val_vtab-sun397: top1: 42.50	top5: 65.00	
[09/26 07:34:35 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.006117935463105809
[09/26 07:34:42 visual_prompt]: Epoch 92 / 100: avg data time: 5.65e-02, avg batch time: 0.5011, average train loss: 1.0657
[09/26 07:34:43 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1676, average loss: 3.4648
[09/26 07:34:43 visual_prompt]: Classification results with val_vtab-sun397: top1: 43.00	top5: 65.00	
[09/26 07:34:43 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.004842288007710138
[09/26 07:34:50 visual_prompt]: Epoch 93 / 100: avg data time: 5.96e-02, avg batch time: 0.5036, average train loss: 1.0628
[09/26 07:34:52 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1677, average loss: 3.4580
[09/26 07:34:52 visual_prompt]: Classification results with val_vtab-sun397: top1: 43.00	top5: 65.50	
[09/26 07:34:52 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.003713034215500441
[09/26 07:34:59 visual_prompt]: Epoch 94 / 100: avg data time: 5.89e-02, avg batch time: 0.5018, average train loss: 1.0587
[09/26 07:35:00 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1678, average loss: 3.4631
[09/26 07:35:00 visual_prompt]: Classification results with val_vtab-sun397: top1: 43.50	top5: 65.00	
[09/26 07:35:00 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.002731549908274289
[09/26 07:35:07 visual_prompt]: Epoch 95 / 100: avg data time: 6.07e-02, avg batch time: 0.5035, average train loss: 1.0578
[09/26 07:35:09 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1674, average loss: 3.4620
[09/26 07:35:09 visual_prompt]: Classification results with val_vtab-sun397: top1: 43.50	top5: 65.00	
[09/26 07:35:09 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.0018990308734739975
[09/26 07:35:16 visual_prompt]: Epoch 96 / 100: avg data time: 5.51e-02, avg batch time: 0.5003, average train loss: 1.0549
[09/26 07:35:17 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1677, average loss: 3.4580
[09/26 07:35:17 visual_prompt]: Classification results with val_vtab-sun397: top1: 43.50	top5: 65.00	
[09/26 07:35:17 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.0012164914073037048
[09/26 07:35:24 visual_prompt]: Epoch 97 / 100: avg data time: 6.38e-02, avg batch time: 0.5068, average train loss: 1.0544
[09/26 07:35:26 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1674, average loss: 3.4584
[09/26 07:35:26 visual_prompt]: Classification results with val_vtab-sun397: top1: 43.50	top5: 64.50	
[09/26 07:35:26 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.0006847630789658388
[09/26 07:35:33 visual_prompt]: Epoch 98 / 100: avg data time: 6.13e-02, avg batch time: 0.5068, average train loss: 1.0520
[09/26 07:35:35 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1674, average loss: 3.4602
[09/26 07:35:35 visual_prompt]: Classification results with val_vtab-sun397: top1: 43.50	top5: 65.00	
[09/26 07:35:35 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.0003044937175219753
[09/26 07:35:42 visual_prompt]: Epoch 99 / 100: avg data time: 6.78e-02, avg batch time: 0.5114, average train loss: 1.0529
[09/26 07:35:43 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1674, average loss: 3.4605
[09/26 07:35:43 visual_prompt]: Classification results with val_vtab-sun397: top1: 43.50	top5: 65.00	
[09/26 07:35:43 visual_prompt]: Training 100 / 100 epoch, with learning rate 7.614662261302974e-05
[09/26 07:35:50 visual_prompt]: Epoch 100 / 100: avg data time: 5.85e-02, avg batch time: 0.5012, average train loss: 1.0539
[09/26 07:35:52 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.1676, average loss: 3.4606
[09/26 07:35:52 visual_prompt]: Classification results with val_vtab-sun397: top1: 43.50	top5: 65.00	
[09/26 07:35:52 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 07:35:52 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              0
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 07:35:52 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-sun397', 'DATA.NUMBER_CLASSES', '397', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 07:35:52 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 07:35:52 visual_prompt]: Training with config:
[09/26 07:35:52 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-sun397/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.25_wd0.001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 0.25, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-sun397', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 397, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 07:35:52 visual_prompt]: Loading training data...
[09/26 07:35:52 visual_prompt]: Constructing vtab-sun397 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split train[:800], from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/26 07:35:53 visual_prompt]: Number of images: 800
[09/26 07:35:53 visual_prompt]: Number of classes: 309 / 397
[09/26 07:35:53 visual_prompt]: Loading validation data...
[09/26 07:35:53 visual_prompt]: Constructing vtab-sun397 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split validation[:200], from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/26 07:35:53 visual_prompt]: Number of images: 200
[09/26 07:35:53 visual_prompt]: Number of classes: 136 / 397
[09/26 07:35:53 visual_prompt]: Constructing models...
[09/26 07:35:56 visual_prompt]: Total Parameters: 86564749	 Gradient Parameters: 766093
[09/26 07:35:56 visual_prompt]: tuned percent:0.885
[09/26 07:35:56 visual_prompt]: Device used for model: 0
[09/26 07:35:56 visual_prompt]: Setting up Evaluator...
[09/26 07:35:56 visual_prompt]: Setting up Trainer...
[09/26 07:35:56 visual_prompt]: 	Setting up the optimizer...
[09/26 07:35:56 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 07:36:03 visual_prompt]: Epoch 1 / 100: avg data time: 5.82e-02, avg batch time: 0.5022, average train loss: 5.9889
[09/26 07:36:04 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1672, average loss: 6.0097
[09/26 07:36:04 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/26 07:36:04 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.025
[09/26 07:36:11 visual_prompt]: Epoch 2 / 100: avg data time: 6.21e-02, avg batch time: 0.5039, average train loss: 5.9571
[09/26 07:36:13 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1673, average loss: 5.9616
[09/26 07:36:13 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 2.00	
[09/26 07:36:13 visual_prompt]: Best epoch 2: best metric: 0.010
[09/26 07:36:13 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.05
[09/26 07:36:20 visual_prompt]: Epoch 3 / 100: avg data time: 5.51e-02, avg batch time: 0.4978, average train loss: 5.8302
[09/26 07:36:21 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1672, average loss: 5.8667
[09/26 07:36:21 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 07:36:21 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.075
[09/26 07:36:28 visual_prompt]: Epoch 4 / 100: avg data time: 5.77e-02, avg batch time: 0.4999, average train loss: 5.6540
[09/26 07:36:30 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1668, average loss: 5.8401
[09/26 07:36:30 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 5.00	
[09/26 07:36:30 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.1
[09/26 07:36:37 visual_prompt]: Epoch 5 / 100: avg data time: 5.93e-02, avg batch time: 0.5032, average train loss: 5.4625
[09/26 07:36:38 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1673, average loss: 5.6374
[09/26 07:36:38 visual_prompt]: Classification results with val_vtab-sun397: top1: 4.00	top5: 10.00	
[09/26 07:36:38 visual_prompt]: Best epoch 5: best metric: 0.040
[09/26 07:36:38 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.125
[09/26 07:36:45 visual_prompt]: Epoch 6 / 100: avg data time: 5.87e-02, avg batch time: 0.5018, average train loss: 5.1978
[09/26 07:36:47 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1670, average loss: 5.4068
[09/26 07:36:47 visual_prompt]: Classification results with val_vtab-sun397: top1: 4.00	top5: 13.00	
[09/26 07:36:47 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.15
[09/26 07:36:54 visual_prompt]: Epoch 7 / 100: avg data time: 6.33e-02, avg batch time: 0.5065, average train loss: 4.8160
[09/26 07:36:55 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1671, average loss: 5.1590
[09/26 07:36:55 visual_prompt]: Classification results with val_vtab-sun397: top1: 8.50	top5: 22.00	
[09/26 07:36:55 visual_prompt]: Best epoch 7: best metric: 0.085
[09/26 07:36:55 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.175
[09/26 07:37:02 visual_prompt]: Epoch 8 / 100: avg data time: 6.06e-02, avg batch time: 0.5030, average train loss: 4.2747
[09/26 07:37:04 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1671, average loss: 4.7985
[09/26 07:37:04 visual_prompt]: Classification results with val_vtab-sun397: top1: 11.50	top5: 25.50	
[09/26 07:37:04 visual_prompt]: Best epoch 8: best metric: 0.115
[09/26 07:37:04 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.2
[09/26 07:37:11 visual_prompt]: Epoch 9 / 100: avg data time: 6.03e-02, avg batch time: 0.5039, average train loss: 3.6800
[09/26 07:37:12 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1672, average loss: 4.5563
[09/26 07:37:12 visual_prompt]: Classification results with val_vtab-sun397: top1: 15.00	top5: 33.00	
[09/26 07:37:12 visual_prompt]: Best epoch 9: best metric: 0.150
[09/26 07:37:12 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.225
[09/26 07:37:19 visual_prompt]: Epoch 10 / 100: avg data time: 6.08e-02, avg batch time: 0.5042, average train loss: 3.0630
[09/26 07:37:21 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1671, average loss: 4.2180
[09/26 07:37:21 visual_prompt]: Classification results with val_vtab-sun397: top1: 15.50	top5: 40.00	
[09/26 07:37:21 visual_prompt]: Best epoch 10: best metric: 0.155
[09/26 07:37:21 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.25
[09/26 07:37:28 visual_prompt]: Epoch 11 / 100: avg data time: 6.55e-02, avg batch time: 0.5075, average train loss: 2.4159
[09/26 07:37:29 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1675, average loss: 3.9863
[09/26 07:37:29 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.00	top5: 49.50	
[09/26 07:37:29 visual_prompt]: Best epoch 11: best metric: 0.210
[09/26 07:37:29 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.24992385337738698
[09/26 07:37:36 visual_prompt]: Epoch 12 / 100: avg data time: 6.49e-02, avg batch time: 0.5074, average train loss: 1.8018
[09/26 07:37:38 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1675, average loss: 3.7361
[09/26 07:37:38 visual_prompt]: Classification results with val_vtab-sun397: top1: 24.50	top5: 49.50	
[09/26 07:37:38 visual_prompt]: Best epoch 12: best metric: 0.245
[09/26 07:37:38 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.24969550628247802
[09/26 07:37:45 visual_prompt]: Epoch 13 / 100: avg data time: 5.28e-02, avg batch time: 0.4953, average train loss: 1.2985
[09/26 07:37:46 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1672, average loss: 3.7042
[09/26 07:37:46 visual_prompt]: Classification results with val_vtab-sun397: top1: 25.00	top5: 53.50	
[09/26 07:37:46 visual_prompt]: Best epoch 13: best metric: 0.250
[09/26 07:37:46 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.24931523692103416
[09/26 07:37:53 visual_prompt]: Epoch 14 / 100: avg data time: 6.10e-02, avg batch time: 0.5047, average train loss: 0.9132
[09/26 07:37:55 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1673, average loss: 3.5491
[09/26 07:37:55 visual_prompt]: Classification results with val_vtab-sun397: top1: 32.00	top5: 56.00	
[09/26 07:37:55 visual_prompt]: Best epoch 14: best metric: 0.320
[09/26 07:37:55 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.2487835085926963
[09/26 07:38:02 visual_prompt]: Epoch 15 / 100: avg data time: 6.00e-02, avg batch time: 0.5045, average train loss: 0.6323
[09/26 07:38:04 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1676, average loss: 3.4894
[09/26 07:38:04 visual_prompt]: Classification results with val_vtab-sun397: top1: 32.50	top5: 54.50	
[09/26 07:38:04 visual_prompt]: Best epoch 15: best metric: 0.325
[09/26 07:38:04 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.24810096912652602
[09/26 07:38:10 visual_prompt]: Epoch 16 / 100: avg data time: 6.11e-02, avg batch time: 0.5040, average train loss: 0.4584
[09/26 07:38:12 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1675, average loss: 3.4306
[09/26 07:38:12 visual_prompt]: Classification results with val_vtab-sun397: top1: 29.50	top5: 61.00	
[09/26 07:38:12 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.2472684500917257
[09/26 07:38:19 visual_prompt]: Epoch 17 / 100: avg data time: 6.64e-02, avg batch time: 0.5101, average train loss: 0.3371
[09/26 07:38:21 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1676, average loss: 3.3921
[09/26 07:38:21 visual_prompt]: Classification results with val_vtab-sun397: top1: 30.50	top5: 58.00	
[09/26 07:38:21 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.24628696578449955
[09/26 07:38:28 visual_prompt]: Epoch 18 / 100: avg data time: 6.27e-02, avg batch time: 0.5056, average train loss: 0.2611
[09/26 07:38:29 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1678, average loss: 3.3937
[09/26 07:38:29 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 59.00	
[09/26 07:38:29 visual_prompt]: Best epoch 18: best metric: 0.335
[09/26 07:38:29 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.24515771199228986
[09/26 07:38:36 visual_prompt]: Epoch 19 / 100: avg data time: 6.24e-02, avg batch time: 0.5048, average train loss: 0.2152
[09/26 07:38:38 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1673, average loss: 3.3539
[09/26 07:38:38 visual_prompt]: Classification results with val_vtab-sun397: top1: 32.50	top5: 60.00	
[09/26 07:38:38 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.2438820645368942
[09/26 07:38:45 visual_prompt]: Epoch 20 / 100: avg data time: 6.83e-02, avg batch time: 0.5111, average train loss: 0.1867
[09/26 07:38:47 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.1674, average loss: 3.3516
[09/26 07:38:47 visual_prompt]: Classification results with val_vtab-sun397: top1: 31.50	top5: 57.50	
[09/26 07:38:47 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.24246157759823855
[09/26 07:38:54 visual_prompt]: Epoch 21 / 100: avg data time: 6.35e-02, avg batch time: 0.5081, average train loss: 0.1712
[09/26 07:38:55 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1676, average loss: 3.3540
[09/26 07:38:55 visual_prompt]: Classification results with val_vtab-sun397: top1: 31.50	top5: 60.50	
[09/26 07:38:55 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.24089798182084843
[09/26 07:39:02 visual_prompt]: Epoch 22 / 100: avg data time: 6.45e-02, avg batch time: 0.5066, average train loss: 0.1591
[09/26 07:39:04 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1671, average loss: 3.3295
[09/26 07:39:04 visual_prompt]: Classification results with val_vtab-sun397: top1: 34.00	top5: 59.50	
[09/26 07:39:04 visual_prompt]: Best epoch 22: best metric: 0.340
[09/26 07:39:04 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.2391931822053251
[09/26 07:39:11 visual_prompt]: Epoch 23 / 100: avg data time: 5.18e-02, avg batch time: 0.4946, average train loss: 0.1530
[09/26 07:39:12 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1674, average loss: 3.3789
[09/26 07:39:12 visual_prompt]: Classification results with val_vtab-sun397: top1: 31.50	top5: 56.50	
[09/26 07:39:12 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.23734925578739588
[09/26 07:39:19 visual_prompt]: Epoch 24 / 100: avg data time: 6.12e-02, avg batch time: 0.5052, average train loss: 0.1471
[09/26 07:39:21 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1673, average loss: 3.3616
[09/26 07:39:21 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 58.00	
[09/26 07:39:21 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.23536844910736587
[09/26 07:39:28 visual_prompt]: Epoch 25 / 100: avg data time: 5.97e-02, avg batch time: 0.5038, average train loss: 0.1434
[09/26 07:39:29 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1672, average loss: 3.3475
[09/26 07:39:29 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.00	top5: 57.00	
[09/26 07:39:29 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.23325317547305485
[09/26 07:39:36 visual_prompt]: Epoch 26 / 100: avg data time: 6.03e-02, avg batch time: 0.5045, average train loss: 0.1371
[09/26 07:39:38 visual_prompt]: Inference (val):avg data time: 4.20e-05, avg batch time: 0.1675, average loss: 3.3903
[09/26 07:39:38 visual_prompt]: Classification results with val_vtab-sun397: top1: 31.50	top5: 55.50	
[09/26 07:39:38 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.23100601201955323
[09/26 07:39:45 visual_prompt]: Epoch 27 / 100: avg data time: 6.62e-02, avg batch time: 0.5087, average train loss: 0.1394
[09/26 07:39:46 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1671, average loss: 3.3541
[09/26 07:39:46 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 55.50	
[09/26 07:39:46 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.2286296965693802
[09/26 07:39:53 visual_prompt]: Epoch 28 / 100: avg data time: 6.42e-02, avg batch time: 0.5074, average train loss: 0.1368
[09/26 07:39:55 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1677, average loss: 3.3510
[09/26 07:39:55 visual_prompt]: Classification results with val_vtab-sun397: top1: 32.50	top5: 58.00	
[09/26 07:39:55 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.22612712429686843
[09/26 07:40:02 visual_prompt]: Epoch 29 / 100: avg data time: 5.46e-02, avg batch time: 0.4980, average train loss: 0.1376
[09/26 07:40:03 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1677, average loss: 3.3436
[09/26 07:40:03 visual_prompt]: Classification results with val_vtab-sun397: top1: 32.50	top5: 59.00	
[09/26 07:40:03 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.22350134420084022
[09/26 07:40:10 visual_prompt]: Epoch 30 / 100: avg data time: 6.19e-02, avg batch time: 0.5046, average train loss: 0.1369
[09/26 07:40:12 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1672, average loss: 3.3664
[09/26 07:40:12 visual_prompt]: Classification results with val_vtab-sun397: top1: 34.00	top5: 56.50	
[09/26 07:40:12 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.22075555538987224
[09/26 07:40:19 visual_prompt]: Epoch 31 / 100: avg data time: 5.66e-02, avg batch time: 0.4996, average train loss: 0.1369
[09/26 07:40:20 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1675, average loss: 3.3650
[09/26 07:40:20 visual_prompt]: Classification results with val_vtab-sun397: top1: 32.00	top5: 59.50	
[09/26 07:40:20 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.21789310318467428
[09/26 07:40:27 visual_prompt]: Epoch 32 / 100: avg data time: 6.05e-02, avg batch time: 0.5053, average train loss: 0.1337
[09/26 07:40:29 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1677, average loss: 3.3627
[09/26 07:40:29 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 58.00	
[09/26 07:40:29 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.21491747504233139
[09/26 07:40:36 visual_prompt]: Epoch 33 / 100: avg data time: 6.06e-02, avg batch time: 0.5042, average train loss: 0.1350
[09/26 07:40:37 visual_prompt]: Inference (val):avg data time: 3.52e-05, avg batch time: 0.1677, average loss: 3.3821
[09/26 07:40:37 visual_prompt]: Classification results with val_vtab-sun397: top1: 35.00	top5: 57.00	
[09/26 07:40:37 visual_prompt]: Best epoch 33: best metric: 0.350
[09/26 07:40:37 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.21183229630737466
[09/26 07:40:44 visual_prompt]: Epoch 34 / 100: avg data time: 6.79e-02, avg batch time: 0.5103, average train loss: 0.1333
[09/26 07:40:46 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1675, average loss: 3.3825
[09/26 07:40:46 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 55.50	
[09/26 07:40:46 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.20864132579485728
[09/26 07:40:53 visual_prompt]: Epoch 35 / 100: avg data time: 5.92e-02, avg batch time: 0.5022, average train loss: 0.1320
[09/26 07:40:55 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1675, average loss: 3.3625
[09/26 07:40:55 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 57.50	
[09/26 07:40:55 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.2053484512108174
[09/26 07:41:01 visual_prompt]: Epoch 36 / 100: avg data time: 5.90e-02, avg batch time: 0.5025, average train loss: 0.1298
[09/26 07:41:03 visual_prompt]: Inference (val):avg data time: 2.08e-05, avg batch time: 0.1674, average loss: 3.3698
[09/26 07:41:03 visual_prompt]: Classification results with val_vtab-sun397: top1: 36.00	top5: 58.50	
[09/26 07:41:03 visual_prompt]: Best epoch 36: best metric: 0.360
[09/26 07:41:03 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.20195768441570727
[09/26 07:41:10 visual_prompt]: Epoch 37 / 100: avg data time: 4.65e-02, avg batch time: 0.4899, average train loss: 0.1308
[09/26 07:41:11 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1673, average loss: 3.3502
[09/26 07:41:11 visual_prompt]: Classification results with val_vtab-sun397: top1: 34.50	top5: 56.50	
[09/26 07:41:11 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.19847315653655914
[09/26 07:41:18 visual_prompt]: Epoch 38 / 100: avg data time: 6.41e-02, avg batch time: 0.5062, average train loss: 0.1287
[09/26 07:41:20 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1673, average loss: 3.4007
[09/26 07:41:20 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.00	top5: 55.00	
[09/26 07:41:20 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.19489911293384335
[09/26 07:41:27 visual_prompt]: Epoch 39 / 100: avg data time: 6.18e-02, avg batch time: 0.5045, average train loss: 0.1274
[09/26 07:41:28 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1675, average loss: 3.3798
[09/26 07:41:28 visual_prompt]: Classification results with val_vtab-sun397: top1: 36.00	top5: 57.00	
[09/26 07:41:28 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.1912399080291506
[09/26 07:41:35 visual_prompt]: Epoch 40 / 100: avg data time: 6.43e-02, avg batch time: 0.5068, average train loss: 0.1269
[09/26 07:41:37 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1675, average loss: 3.3831
[09/26 07:41:37 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.00	top5: 57.00	
[09/26 07:41:37 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.1875
[09/26 07:41:44 visual_prompt]: Epoch 41 / 100: avg data time: 5.74e-02, avg batch time: 0.5006, average train loss: 0.1282
[09/26 07:41:45 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1671, average loss: 3.3748
[09/26 07:41:45 visual_prompt]: Classification results with val_vtab-sun397: top1: 34.50	top5: 57.50	
[09/26 07:41:45 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.18368394534823634
[09/26 07:41:52 visual_prompt]: Epoch 42 / 100: avg data time: 6.05e-02, avg batch time: 0.5044, average train loss: 0.1275
[09/26 07:41:54 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1677, average loss: 3.3679
[09/26 07:41:54 visual_prompt]: Classification results with val_vtab-sun397: top1: 34.50	top5: 58.00	
[09/26 07:41:54 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.17979639334863468
[09/26 07:42:01 visual_prompt]: Epoch 43 / 100: avg data time: 5.75e-02, avg batch time: 0.5016, average train loss: 0.1249
[09/26 07:42:02 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1677, average loss: 3.4032
[09/26 07:42:02 visual_prompt]: Classification results with val_vtab-sun397: top1: 34.00	top5: 59.00	
[09/26 07:42:02 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.17584208038447505
[09/26 07:42:09 visual_prompt]: Epoch 44 / 100: avg data time: 6.27e-02, avg batch time: 0.5064, average train loss: 0.1220
[09/26 07:42:11 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1679, average loss: 3.3878
[09/26 07:42:11 visual_prompt]: Classification results with val_vtab-sun397: top1: 34.50	top5: 58.00	
[09/26 07:42:11 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.17182582417698902
[09/26 07:42:18 visual_prompt]: Epoch 45 / 100: avg data time: 5.31e-02, avg batch time: 0.4977, average train loss: 0.1201
[09/26 07:42:19 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.1676, average loss: 3.4274
[09/26 07:42:19 visual_prompt]: Classification results with val_vtab-sun397: top1: 34.50	top5: 54.50	
[09/26 07:42:19 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.1677525179157086
[09/26 07:42:26 visual_prompt]: Epoch 46 / 100: avg data time: 6.32e-02, avg batch time: 0.5058, average train loss: 0.1219
[09/26 07:42:28 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1674, average loss: 3.4041
[09/26 07:42:28 visual_prompt]: Classification results with val_vtab-sun397: top1: 34.00	top5: 59.00	
[09/26 07:42:28 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.16362712429686843
[09/26 07:42:35 visual_prompt]: Epoch 47 / 100: avg data time: 7.11e-02, avg batch time: 0.5138, average train loss: 0.1184
[09/26 07:42:37 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1674, average loss: 3.4022
[09/26 07:42:37 visual_prompt]: Classification results with val_vtab-sun397: top1: 34.50	top5: 56.50	
[09/26 07:42:37 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.1594546694771249
[09/26 07:42:43 visual_prompt]: Epoch 48 / 100: avg data time: 6.10e-02, avg batch time: 0.5043, average train loss: 0.1181
[09/26 07:42:45 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1674, average loss: 3.4097
[09/26 07:42:45 visual_prompt]: Classification results with val_vtab-sun397: top1: 35.50	top5: 57.00	
[09/26 07:42:45 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.15524023694995845
[09/26 07:42:52 visual_prompt]: Epoch 49 / 100: avg data time: 6.19e-02, avg batch time: 0.5051, average train loss: 0.1160
[09/26 07:42:54 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1677, average loss: 3.3681
[09/26 07:42:54 visual_prompt]: Classification results with val_vtab-sun397: top1: 35.50	top5: 59.50	
[09/26 07:42:54 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.1509889613522199
[09/26 07:43:01 visual_prompt]: Epoch 50 / 100: avg data time: 6.48e-02, avg batch time: 0.5083, average train loss: 0.1169
[09/26 07:43:02 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1677, average loss: 3.4095
[09/26 07:43:02 visual_prompt]: Classification results with val_vtab-sun397: top1: 36.50	top5: 56.00	
[09/26 07:43:02 visual_prompt]: Best epoch 50: best metric: 0.365
[09/26 07:43:02 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.14670602220836632
[09/26 07:43:09 visual_prompt]: Epoch 51 / 100: avg data time: 6.36e-02, avg batch time: 0.5079, average train loss: 0.1161
[09/26 07:43:11 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1676, average loss: 3.4011
[09/26 07:43:11 visual_prompt]: Classification results with val_vtab-sun397: top1: 34.00	top5: 55.00	
[09/26 07:43:11 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.14239663762000818
[09/26 07:43:18 visual_prompt]: Epoch 52 / 100: avg data time: 5.92e-02, avg batch time: 0.5020, average train loss: 0.1145
[09/26 07:43:19 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1675, average loss: 3.4046
[09/26 07:43:19 visual_prompt]: Classification results with val_vtab-sun397: top1: 35.50	top5: 57.00	
[09/26 07:43:19 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.1380660579084567
[09/26 07:43:26 visual_prompt]: Epoch 53 / 100: avg data time: 6.35e-02, avg batch time: 0.5083, average train loss: 0.1155
[09/26 07:43:28 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1674, average loss: 3.3899
[09/26 07:43:28 visual_prompt]: Classification results with val_vtab-sun397: top1: 32.50	top5: 58.00	
[09/26 07:43:28 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.13371955921801565
[09/26 07:43:35 visual_prompt]: Epoch 54 / 100: avg data time: 6.24e-02, avg batch time: 0.5055, average train loss: 0.1154
[09/26 07:43:37 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1674, average loss: 3.4409
[09/26 07:43:37 visual_prompt]: Classification results with val_vtab-sun397: top1: 31.50	top5: 56.50	
[09/26 07:43:37 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.12936243708781264
[09/26 07:43:43 visual_prompt]: Epoch 55 / 100: avg data time: 5.71e-02, avg batch time: 0.5014, average train loss: 0.1139
[09/26 07:43:45 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1674, average loss: 3.3986
[09/26 07:43:45 visual_prompt]: Classification results with val_vtab-sun397: top1: 35.50	top5: 57.00	
[09/26 07:43:45 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.125
[09/26 07:43:52 visual_prompt]: Epoch 56 / 100: avg data time: 6.44e-02, avg batch time: 0.5071, average train loss: 0.1142
[09/26 07:43:54 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1679, average loss: 3.4103
[09/26 07:43:54 visual_prompt]: Classification results with val_vtab-sun397: top1: 35.00	top5: 56.50	
[09/26 07:43:54 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.12063756291218741
[09/26 07:44:01 visual_prompt]: Epoch 57 / 100: avg data time: 6.26e-02, avg batch time: 0.5052, average train loss: 0.1123
[09/26 07:44:02 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1673, average loss: 3.4189
[09/26 07:44:02 visual_prompt]: Classification results with val_vtab-sun397: top1: 35.50	top5: 58.00	
[09/26 07:44:02 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.11628044078198434
[09/26 07:44:09 visual_prompt]: Epoch 58 / 100: avg data time: 5.96e-02, avg batch time: 0.5033, average train loss: 0.1119
[09/26 07:44:11 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1673, average loss: 3.4199
[09/26 07:44:11 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 59.00	
[09/26 07:44:11 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.11193394209154334
[09/26 07:44:18 visual_prompt]: Epoch 59 / 100: avg data time: 5.93e-02, avg batch time: 0.5036, average train loss: 0.1110
[09/26 07:44:19 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.1672, average loss: 3.4192
[09/26 07:44:19 visual_prompt]: Classification results with val_vtab-sun397: top1: 35.00	top5: 58.50	
[09/26 07:44:19 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.10760336237999185
[09/26 07:44:26 visual_prompt]: Epoch 60 / 100: avg data time: 5.83e-02, avg batch time: 0.5012, average train loss: 0.1099
[09/26 07:44:28 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1672, average loss: 3.4442
[09/26 07:44:28 visual_prompt]: Classification results with val_vtab-sun397: top1: 34.00	top5: 54.00	
[09/26 07:44:28 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.10329397779163371
[09/26 07:44:35 visual_prompt]: Epoch 61 / 100: avg data time: 6.04e-02, avg batch time: 0.5026, average train loss: 0.1090
[09/26 07:44:36 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1671, average loss: 3.4298
[09/26 07:44:36 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 55.00	
[09/26 07:44:36 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.0990110386477801
[09/26 07:44:43 visual_prompt]: Epoch 62 / 100: avg data time: 5.76e-02, avg batch time: 0.4995, average train loss: 0.1090
[09/26 07:44:45 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1676, average loss: 3.4248
[09/26 07:44:45 visual_prompt]: Classification results with val_vtab-sun397: top1: 35.00	top5: 57.00	
[09/26 07:44:45 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.09475976305004155
[09/26 07:44:52 visual_prompt]: Epoch 63 / 100: avg data time: 5.59e-02, avg batch time: 0.4985, average train loss: 0.1082
[09/26 07:44:53 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1673, average loss: 3.4166
[09/26 07:44:53 visual_prompt]: Classification results with val_vtab-sun397: top1: 34.50	top5: 56.00	
[09/26 07:44:53 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.09054533052287511
[09/26 07:45:00 visual_prompt]: Epoch 64 / 100: avg data time: 5.70e-02, avg batch time: 0.4994, average train loss: 0.1078
[09/26 07:45:02 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1672, average loss: 3.4381
[09/26 07:45:02 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 58.00	
[09/26 07:45:02 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.08637287570313158
[09/26 07:45:08 visual_prompt]: Epoch 65 / 100: avg data time: 6.20e-02, avg batch time: 0.5045, average train loss: 0.1081
[09/26 07:45:10 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1675, average loss: 3.4273
[09/26 07:45:10 visual_prompt]: Classification results with val_vtab-sun397: top1: 35.00	top5: 56.50	
[09/26 07:45:10 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.08224748208429142
[09/26 07:45:17 visual_prompt]: Epoch 66 / 100: avg data time: 7.24e-02, avg batch time: 0.5154, average train loss: 0.1072
[09/26 07:45:19 visual_prompt]: Inference (val):avg data time: 1.94e-05, avg batch time: 0.1671, average loss: 3.4323
[09/26 07:45:19 visual_prompt]: Classification results with val_vtab-sun397: top1: 35.00	top5: 54.50	
[09/26 07:45:19 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.07817417582301099
[09/26 07:45:26 visual_prompt]: Epoch 67 / 100: avg data time: 5.96e-02, avg batch time: 0.5044, average train loss: 0.1065
[09/26 07:45:27 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1674, average loss: 3.4049
[09/26 07:45:27 visual_prompt]: Classification results with val_vtab-sun397: top1: 35.50	top5: 57.50	
[09/26 07:45:27 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.074157919615525
[09/26 07:45:34 visual_prompt]: Epoch 68 / 100: avg data time: 6.02e-02, avg batch time: 0.5037, average train loss: 0.1061
[09/26 07:45:36 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1673, average loss: 3.4092
[09/26 07:45:36 visual_prompt]: Classification results with val_vtab-sun397: top1: 35.50	top5: 55.50	
[09/26 07:45:36 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.07020360665136531
[09/26 07:45:43 visual_prompt]: Epoch 69 / 100: avg data time: 6.65e-02, avg batch time: 0.5093, average train loss: 0.1064
[09/26 07:45:44 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1676, average loss: 3.4173
[09/26 07:45:44 visual_prompt]: Classification results with val_vtab-sun397: top1: 35.50	top5: 56.00	
[09/26 07:45:44 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.06631605465176368
[09/26 07:45:51 visual_prompt]: Epoch 70 / 100: avg data time: 6.43e-02, avg batch time: 0.5074, average train loss: 0.1053
[09/26 07:45:53 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1670, average loss: 3.4090
[09/26 07:45:53 visual_prompt]: Classification results with val_vtab-sun397: top1: 35.50	top5: 56.00	
[09/26 07:45:53 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.06250000000000003
[09/26 07:46:00 visual_prompt]: Epoch 71 / 100: avg data time: 6.18e-02, avg batch time: 0.5046, average train loss: 0.1053
[09/26 07:46:02 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1673, average loss: 3.3917
[09/26 07:46:02 visual_prompt]: Classification results with val_vtab-sun397: top1: 36.00	top5: 55.00	
[09/26 07:46:02 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.0587600919708494
[09/26 07:46:08 visual_prompt]: Epoch 72 / 100: avg data time: 6.30e-02, avg batch time: 0.5056, average train loss: 0.1052
[09/26 07:46:10 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1672, average loss: 3.4153
[09/26 07:46:10 visual_prompt]: Classification results with val_vtab-sun397: top1: 34.50	top5: 56.50	
[09/26 07:46:10 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.055100887066156665
[09/26 07:46:17 visual_prompt]: Epoch 73 / 100: avg data time: 5.84e-02, avg batch time: 0.5015, average train loss: 0.1040
[09/26 07:46:19 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1673, average loss: 3.4260
[09/26 07:46:19 visual_prompt]: Classification results with val_vtab-sun397: top1: 35.50	top5: 54.50	
[09/26 07:46:19 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.05152684346344087
[09/26 07:46:25 visual_prompt]: Epoch 74 / 100: avg data time: 5.91e-02, avg batch time: 0.5020, average train loss: 0.1039
[09/26 07:46:27 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1674, average loss: 3.4268
[09/26 07:46:27 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.00	top5: 55.00	
[09/26 07:46:27 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.048042315584292714
[09/26 07:46:34 visual_prompt]: Epoch 75 / 100: avg data time: 5.37e-02, avg batch time: 0.4978, average train loss: 0.1027
[09/26 07:46:35 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1678, average loss: 3.4237
[09/26 07:46:35 visual_prompt]: Classification results with val_vtab-sun397: top1: 35.50	top5: 57.50	
[09/26 07:46:35 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.04465154878918258
[09/26 07:46:42 visual_prompt]: Epoch 76 / 100: avg data time: 5.79e-02, avg batch time: 0.5012, average train loss: 0.1025
[09/26 07:46:44 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.1673, average loss: 3.4320
[09/26 07:46:44 visual_prompt]: Classification results with val_vtab-sun397: top1: 35.50	top5: 55.50	
[09/26 07:46:44 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.04135867420514276
[09/26 07:46:51 visual_prompt]: Epoch 77 / 100: avg data time: 4.50e-02, avg batch time: 0.4890, average train loss: 0.1022
[09/26 07:46:52 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1672, average loss: 3.4216
[09/26 07:46:52 visual_prompt]: Classification results with val_vtab-sun397: top1: 34.50	top5: 55.50	
[09/26 07:46:52 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.03816770369262533
[09/26 07:46:59 visual_prompt]: Epoch 78 / 100: avg data time: 4.88e-02, avg batch time: 0.4938, average train loss: 0.1017
[09/26 07:47:01 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1674, average loss: 3.4316
[09/26 07:47:01 visual_prompt]: Classification results with val_vtab-sun397: top1: 34.50	top5: 54.50	
[09/26 07:47:01 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.03508252495766863
[09/26 07:47:07 visual_prompt]: Epoch 79 / 100: avg data time: 6.06e-02, avg batch time: 0.5041, average train loss: 0.1016
[09/26 07:47:09 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1676, average loss: 3.4323
[09/26 07:47:09 visual_prompt]: Classification results with val_vtab-sun397: top1: 34.00	top5: 55.50	
[09/26 07:47:09 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.032106896815325706
[09/26 07:47:16 visual_prompt]: Epoch 80 / 100: avg data time: 5.20e-02, avg batch time: 0.4952, average train loss: 0.1012
[09/26 07:47:17 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1670, average loss: 3.4341
[09/26 07:47:17 visual_prompt]: Classification results with val_vtab-sun397: top1: 34.50	top5: 57.00	
[09/26 07:47:17 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.029244444610127762
[09/26 07:47:24 visual_prompt]: Epoch 81 / 100: avg data time: 5.32e-02, avg batch time: 0.4975, average train loss: 0.1016
[09/26 07:47:26 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1679, average loss: 3.4216
[09/26 07:47:26 visual_prompt]: Classification results with val_vtab-sun397: top1: 34.50	top5: 58.00	
[09/26 07:47:26 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.026498655799159762
[09/26 07:47:33 visual_prompt]: Epoch 82 / 100: avg data time: 6.67e-02, avg batch time: 0.5091, average train loss: 0.1008
[09/26 07:47:34 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1675, average loss: 3.4277
[09/26 07:47:34 visual_prompt]: Classification results with val_vtab-sun397: top1: 35.00	top5: 56.00	
[09/26 07:47:34 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.023872875703131582
[09/26 07:47:41 visual_prompt]: Epoch 83 / 100: avg data time: 5.80e-02, avg batch time: 0.5017, average train loss: 0.1014
[09/26 07:47:43 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1674, average loss: 3.4334
[09/26 07:47:43 visual_prompt]: Classification results with val_vtab-sun397: top1: 34.50	top5: 55.50	
[09/26 07:47:43 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.021370303430619797
[09/26 07:47:50 visual_prompt]: Epoch 84 / 100: avg data time: 6.35e-02, avg batch time: 0.5081, average train loss: 0.1003
[09/26 07:47:51 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1673, average loss: 3.4227
[09/26 07:47:51 visual_prompt]: Classification results with val_vtab-sun397: top1: 35.00	top5: 56.00	
[09/26 07:47:51 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.018993987980446755
[09/26 07:47:58 visual_prompt]: Epoch 85 / 100: avg data time: 6.72e-02, avg batch time: 0.5109, average train loss: 0.1001
[09/26 07:48:00 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1676, average loss: 3.4248
[09/26 07:48:00 visual_prompt]: Classification results with val_vtab-sun397: top1: 34.50	top5: 55.00	
[09/26 07:48:00 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.01674682452694516
[09/26 07:48:07 visual_prompt]: Epoch 86 / 100: avg data time: 6.65e-02, avg batch time: 0.5095, average train loss: 0.1003
[09/26 07:48:09 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1674, average loss: 3.4344
[09/26 07:48:09 visual_prompt]: Classification results with val_vtab-sun397: top1: 35.00	top5: 56.50	
[09/26 07:48:09 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.014631550892634126
[09/26 07:48:16 visual_prompt]: Epoch 87 / 100: avg data time: 6.38e-02, avg batch time: 0.5061, average train loss: 0.1000
[09/26 07:48:17 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1673, average loss: 3.4305
[09/26 07:48:17 visual_prompt]: Classification results with val_vtab-sun397: top1: 35.00	top5: 56.00	
[09/26 07:48:17 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.012650744212604148
[09/26 07:48:24 visual_prompt]: Epoch 88 / 100: avg data time: 5.75e-02, avg batch time: 0.5001, average train loss: 0.0998
[09/26 07:48:26 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1673, average loss: 3.4255
[09/26 07:48:26 visual_prompt]: Classification results with val_vtab-sun397: top1: 34.50	top5: 55.00	
[09/26 07:48:26 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.010806817794674878
[09/26 07:48:32 visual_prompt]: Epoch 89 / 100: avg data time: 5.66e-02, avg batch time: 0.4988, average train loss: 0.0995
[09/26 07:48:34 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1671, average loss: 3.4265
[09/26 07:48:34 visual_prompt]: Classification results with val_vtab-sun397: top1: 35.50	top5: 54.00	
[09/26 07:48:34 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.009102018179151586
[09/26 07:48:41 visual_prompt]: Epoch 90 / 100: avg data time: 4.91e-02, avg batch time: 0.4932, average train loss: 0.0997
[09/26 07:48:42 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1675, average loss: 3.4273
[09/26 07:48:42 visual_prompt]: Classification results with val_vtab-sun397: top1: 35.50	top5: 55.50	
[09/26 07:48:42 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.00753842240176146
[09/26 07:48:49 visual_prompt]: Epoch 91 / 100: avg data time: 5.10e-02, avg batch time: 0.4954, average train loss: 0.0994
[09/26 07:48:51 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1673, average loss: 3.4257
[09/26 07:48:51 visual_prompt]: Classification results with val_vtab-sun397: top1: 35.50	top5: 55.00	
[09/26 07:48:51 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.006117935463105809
[09/26 07:48:58 visual_prompt]: Epoch 92 / 100: avg data time: 6.55e-02, avg batch time: 0.5085, average train loss: 0.0994
[09/26 07:48:59 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1676, average loss: 3.4286
[09/26 07:48:59 visual_prompt]: Classification results with val_vtab-sun397: top1: 35.50	top5: 55.50	
[09/26 07:48:59 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.004842288007710138
[09/26 07:49:06 visual_prompt]: Epoch 93 / 100: avg data time: 6.05e-02, avg batch time: 0.5045, average train loss: 0.0987
[09/26 07:49:08 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1673, average loss: 3.4295
[09/26 07:49:08 visual_prompt]: Classification results with val_vtab-sun397: top1: 35.00	top5: 55.00	
[09/26 07:49:08 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.003713034215500441
[09/26 07:49:15 visual_prompt]: Epoch 94 / 100: avg data time: 6.33e-02, avg batch time: 0.5068, average train loss: 0.0988
[09/26 07:49:16 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1672, average loss: 3.4303
[09/26 07:49:16 visual_prompt]: Classification results with val_vtab-sun397: top1: 35.00	top5: 54.50	
[09/26 07:49:16 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.002731549908274289
[09/26 07:49:23 visual_prompt]: Epoch 95 / 100: avg data time: 5.75e-02, avg batch time: 0.5009, average train loss: 0.0992
[09/26 07:49:25 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1678, average loss: 3.4293
[09/26 07:49:25 visual_prompt]: Classification results with val_vtab-sun397: top1: 35.00	top5: 55.00	
[09/26 07:49:25 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.0018990308734739975
[09/26 07:49:32 visual_prompt]: Epoch 96 / 100: avg data time: 6.97e-02, avg batch time: 0.5121, average train loss: 0.0991
[09/26 07:49:34 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.1678, average loss: 3.4297
[09/26 07:49:34 visual_prompt]: Classification results with val_vtab-sun397: top1: 35.00	top5: 55.00	
[09/26 07:49:34 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.0012164914073037048
[09/26 07:49:41 visual_prompt]: Epoch 97 / 100: avg data time: 5.95e-02, avg batch time: 0.5030, average train loss: 0.0986
[09/26 07:49:42 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1675, average loss: 3.4288
[09/26 07:49:42 visual_prompt]: Classification results with val_vtab-sun397: top1: 35.00	top5: 55.00	
[09/26 07:49:42 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.0006847630789658388
[09/26 07:49:49 visual_prompt]: Epoch 98 / 100: avg data time: 6.47e-02, avg batch time: 0.5072, average train loss: 0.0993
[09/26 07:49:51 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1676, average loss: 3.4285
[09/26 07:49:51 visual_prompt]: Classification results with val_vtab-sun397: top1: 35.00	top5: 55.00	
[09/26 07:49:51 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.0003044937175219753
[09/26 07:49:58 visual_prompt]: Epoch 99 / 100: avg data time: 6.41e-02, avg batch time: 0.5082, average train loss: 0.0989
[09/26 07:49:59 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1678, average loss: 3.4284
[09/26 07:49:59 visual_prompt]: Classification results with val_vtab-sun397: top1: 35.00	top5: 55.00	
[09/26 07:49:59 visual_prompt]: Training 100 / 100 epoch, with learning rate 7.614662261302974e-05
[09/26 07:50:06 visual_prompt]: Epoch 100 / 100: avg data time: 5.91e-02, avg batch time: 0.5026, average train loss: 0.0985
[09/26 07:50:08 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1676, average loss: 3.4284
[09/26 07:50:08 visual_prompt]: Classification results with val_vtab-sun397: top1: 35.00	top5: 55.00	
[09/26 07:50:08 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 07:50:08 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              0
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 07:50:08 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-sun397', 'DATA.NUMBER_CLASSES', '397', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 07:50:08 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 07:50:08 visual_prompt]: Training with config:
[09/26 07:50:08 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-sun397/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.25_wd0.0001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 0.25, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-sun397', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 397, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 07:50:08 visual_prompt]: Loading training data...
[09/26 07:50:08 visual_prompt]: Constructing vtab-sun397 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split train[:800], from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/26 07:50:09 visual_prompt]: Number of images: 800
[09/26 07:50:09 visual_prompt]: Number of classes: 309 / 397
[09/26 07:50:09 visual_prompt]: Loading validation data...
[09/26 07:50:09 visual_prompt]: Constructing vtab-sun397 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split validation[:200], from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/26 07:50:10 visual_prompt]: Number of images: 200
[09/26 07:50:10 visual_prompt]: Number of classes: 136 / 397
[09/26 07:50:10 visual_prompt]: Constructing models...
[09/26 07:50:12 visual_prompt]: Total Parameters: 86564749	 Gradient Parameters: 766093
[09/26 07:50:12 visual_prompt]: tuned percent:0.885
[09/26 07:50:12 visual_prompt]: Device used for model: 0
[09/26 07:50:12 visual_prompt]: Setting up Evaluator...
[09/26 07:50:12 visual_prompt]: Setting up Trainer...
[09/26 07:50:12 visual_prompt]: 	Setting up the optimizer...
[09/26 07:50:12 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 07:50:19 visual_prompt]: Epoch 1 / 100: avg data time: 6.31e-02, avg batch time: 0.5073, average train loss: 5.9876
[09/26 07:50:21 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1664, average loss: 6.0097
[09/26 07:50:21 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/26 07:50:21 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.025
[09/26 07:50:27 visual_prompt]: Epoch 2 / 100: avg data time: 4.52e-02, avg batch time: 0.4884, average train loss: 5.9601
[09/26 07:50:29 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1668, average loss: 5.9563
[09/26 07:50:29 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 2.00	
[09/26 07:50:29 visual_prompt]: Best epoch 2: best metric: 0.010
[09/26 07:50:29 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.05
[09/26 07:50:36 visual_prompt]: Epoch 3 / 100: avg data time: 5.13e-02, avg batch time: 0.4928, average train loss: 5.8290
[09/26 07:50:37 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1675, average loss: 5.8628
[09/26 07:50:37 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 5.00	
[09/26 07:50:37 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.075
[09/26 07:50:44 visual_prompt]: Epoch 4 / 100: avg data time: 6.16e-02, avg batch time: 0.5042, average train loss: 5.6407
[09/26 07:50:46 visual_prompt]: Inference (val):avg data time: 2.00e-05, avg batch time: 0.1673, average loss: 5.8066
[09/26 07:50:46 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 5.50	
[09/26 07:50:46 visual_prompt]: Best epoch 4: best metric: 0.015
[09/26 07:50:46 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.1
[09/26 07:50:53 visual_prompt]: Epoch 5 / 100: avg data time: 6.69e-02, avg batch time: 0.5098, average train loss: 5.4375
[09/26 07:50:55 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1674, average loss: 5.6161
[09/26 07:50:55 visual_prompt]: Classification results with val_vtab-sun397: top1: 3.00	top5: 11.50	
[09/26 07:50:55 visual_prompt]: Best epoch 5: best metric: 0.030
[09/26 07:50:55 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.125
[09/26 07:51:01 visual_prompt]: Epoch 6 / 100: avg data time: 6.21e-02, avg batch time: 0.5039, average train loss: 5.1431
[09/26 07:51:03 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1678, average loss: 5.3980
[09/26 07:51:03 visual_prompt]: Classification results with val_vtab-sun397: top1: 4.00	top5: 15.50	
[09/26 07:51:03 visual_prompt]: Best epoch 6: best metric: 0.040
[09/26 07:51:03 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.15
[09/26 07:51:10 visual_prompt]: Epoch 7 / 100: avg data time: 6.23e-02, avg batch time: 0.5067, average train loss: 4.7925
[09/26 07:51:12 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1678, average loss: 5.1774
[09/26 07:51:12 visual_prompt]: Classification results with val_vtab-sun397: top1: 7.50	top5: 17.00	
[09/26 07:51:12 visual_prompt]: Best epoch 7: best metric: 0.075
[09/26 07:51:12 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.175
[09/26 07:51:18 visual_prompt]: Epoch 8 / 100: avg data time: 5.80e-02, avg batch time: 0.5013, average train loss: 4.2607
[09/26 07:51:20 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1676, average loss: 4.8544
[09/26 07:51:20 visual_prompt]: Classification results with val_vtab-sun397: top1: 9.50	top5: 26.50	
[09/26 07:51:20 visual_prompt]: Best epoch 8: best metric: 0.095
[09/26 07:51:20 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.2
[09/26 07:51:27 visual_prompt]: Epoch 9 / 100: avg data time: 6.04e-02, avg batch time: 0.5026, average train loss: 3.6077
[09/26 07:51:29 visual_prompt]: Inference (val):avg data time: 3.83e-05, avg batch time: 0.1672, average loss: 4.5035
[09/26 07:51:29 visual_prompt]: Classification results with val_vtab-sun397: top1: 12.00	top5: 33.50	
[09/26 07:51:29 visual_prompt]: Best epoch 9: best metric: 0.120
[09/26 07:51:29 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.225
[09/26 07:51:35 visual_prompt]: Epoch 10 / 100: avg data time: 5.87e-02, avg batch time: 0.5011, average train loss: 2.9114
[09/26 07:51:37 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1672, average loss: 4.2743
[09/26 07:51:37 visual_prompt]: Classification results with val_vtab-sun397: top1: 20.50	top5: 41.00	
[09/26 07:51:37 visual_prompt]: Best epoch 10: best metric: 0.205
[09/26 07:51:37 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.25
[09/26 07:51:44 visual_prompt]: Epoch 11 / 100: avg data time: 5.63e-02, avg batch time: 0.5002, average train loss: 2.2360
[09/26 07:51:45 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1679, average loss: 4.0535
[09/26 07:51:46 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.00	top5: 43.50	
[09/26 07:51:46 visual_prompt]: Best epoch 11: best metric: 0.220
[09/26 07:51:46 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.24992385337738698
[09/26 07:51:52 visual_prompt]: Epoch 12 / 100: avg data time: 6.95e-02, avg batch time: 0.5120, average train loss: 1.5805
[09/26 07:51:54 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1670, average loss: 3.7797
[09/26 07:51:54 visual_prompt]: Classification results with val_vtab-sun397: top1: 26.50	top5: 49.50	
[09/26 07:51:54 visual_prompt]: Best epoch 12: best metric: 0.265
[09/26 07:51:54 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.24969550628247802
[09/26 07:52:01 visual_prompt]: Epoch 13 / 100: avg data time: 5.76e-02, avg batch time: 0.5006, average train loss: 1.0724
[09/26 07:52:03 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1675, average loss: 3.6123
[09/26 07:52:03 visual_prompt]: Classification results with val_vtab-sun397: top1: 32.00	top5: 52.00	
[09/26 07:52:03 visual_prompt]: Best epoch 13: best metric: 0.320
[09/26 07:52:03 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.24931523692103416
[09/26 07:52:09 visual_prompt]: Epoch 14 / 100: avg data time: 4.72e-02, avg batch time: 0.4903, average train loss: 0.6827
[09/26 07:52:11 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1672, average loss: 3.5358
[09/26 07:52:11 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 56.50	
[09/26 07:52:11 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.2487835085926963
[09/26 07:52:18 visual_prompt]: Epoch 15 / 100: avg data time: 6.02e-02, avg batch time: 0.5030, average train loss: 0.4490
[09/26 07:52:19 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1676, average loss: 3.5275
[09/26 07:52:19 visual_prompt]: Classification results with val_vtab-sun397: top1: 31.00	top5: 57.50	
[09/26 07:52:19 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.24810096912652602
[09/26 07:52:26 visual_prompt]: Epoch 16 / 100: avg data time: 6.49e-02, avg batch time: 0.5079, average train loss: 0.2916
[09/26 07:52:28 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1678, average loss: 3.5059
[09/26 07:52:28 visual_prompt]: Classification results with val_vtab-sun397: top1: 32.00	top5: 57.50	
[09/26 07:52:28 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.2472684500917257
[09/26 07:52:35 visual_prompt]: Epoch 17 / 100: avg data time: 4.97e-02, avg batch time: 0.4947, average train loss: 0.1996
[09/26 07:52:36 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1673, average loss: 3.5204
[09/26 07:52:37 visual_prompt]: Classification results with val_vtab-sun397: top1: 32.00	top5: 59.00	
[09/26 07:52:37 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.24628696578449955
[09/26 07:52:43 visual_prompt]: Epoch 18 / 100: avg data time: 5.87e-02, avg batch time: 0.5014, average train loss: 0.1471
[09/26 07:52:45 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1673, average loss: 3.4614
[09/26 07:52:45 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.00	top5: 59.00	
[09/26 07:52:45 visual_prompt]: Best epoch 18: best metric: 0.330
[09/26 07:52:45 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.24515771199228986
[09/26 07:52:52 visual_prompt]: Epoch 19 / 100: avg data time: 6.14e-02, avg batch time: 0.5043, average train loss: 0.1190
[09/26 07:52:54 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1674, average loss: 3.4820
[09/26 07:52:54 visual_prompt]: Classification results with val_vtab-sun397: top1: 32.00	top5: 59.00	
[09/26 07:52:54 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.2438820645368942
[09/26 07:53:00 visual_prompt]: Epoch 20 / 100: avg data time: 6.24e-02, avg batch time: 0.5063, average train loss: 0.0979
[09/26 07:53:02 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1675, average loss: 3.4764
[09/26 07:53:02 visual_prompt]: Classification results with val_vtab-sun397: top1: 29.50	top5: 58.50	
[09/26 07:53:02 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.24246157759823855
[09/26 07:53:09 visual_prompt]: Epoch 21 / 100: avg data time: 5.31e-02, avg batch time: 0.4972, average train loss: 0.0833
[09/26 07:53:11 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1676, average loss: 3.4830
[09/26 07:53:11 visual_prompt]: Classification results with val_vtab-sun397: top1: 31.50	top5: 57.50	
[09/26 07:53:11 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.24089798182084843
[09/26 07:53:17 visual_prompt]: Epoch 22 / 100: avg data time: 6.35e-02, avg batch time: 0.5062, average train loss: 0.0731
[09/26 07:53:19 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1677, average loss: 3.4959
[09/26 07:53:19 visual_prompt]: Classification results with val_vtab-sun397: top1: 32.50	top5: 58.00	
[09/26 07:53:19 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.2391931822053251
[09/26 07:53:26 visual_prompt]: Epoch 23 / 100: avg data time: 5.91e-02, avg batch time: 0.5026, average train loss: 0.0650
[09/26 07:53:28 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.1673, average loss: 3.4730
[09/26 07:53:28 visual_prompt]: Classification results with val_vtab-sun397: top1: 31.00	top5: 59.50	
[09/26 07:53:28 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.23734925578739588
[09/26 07:53:34 visual_prompt]: Epoch 24 / 100: avg data time: 5.95e-02, avg batch time: 0.5031, average train loss: 0.0603
[09/26 07:53:36 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1677, average loss: 3.4723
[09/26 07:53:36 visual_prompt]: Classification results with val_vtab-sun397: top1: 31.00	top5: 59.50	
[09/26 07:53:36 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.23536844910736587
[09/26 07:53:43 visual_prompt]: Epoch 25 / 100: avg data time: 5.87e-02, avg batch time: 0.5023, average train loss: 0.0557
[09/26 07:53:45 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1675, average loss: 3.4875
[09/26 07:53:45 visual_prompt]: Classification results with val_vtab-sun397: top1: 31.50	top5: 58.50	
[09/26 07:53:45 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.23325317547305485
[09/26 07:53:52 visual_prompt]: Epoch 26 / 100: avg data time: 6.73e-02, avg batch time: 0.5099, average train loss: 0.0520
[09/26 07:53:53 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1675, average loss: 3.4765
[09/26 07:53:53 visual_prompt]: Classification results with val_vtab-sun397: top1: 30.50	top5: 57.50	
[09/26 07:53:53 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.23100601201955323
[09/26 07:54:00 visual_prompt]: Epoch 27 / 100: avg data time: 5.97e-02, avg batch time: 0.5028, average train loss: 0.0479
[09/26 07:54:02 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1676, average loss: 3.4913
[09/26 07:54:02 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 57.00	
[09/26 07:54:02 visual_prompt]: Best epoch 27: best metric: 0.335
[09/26 07:54:02 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.2286296965693802
[09/26 07:54:09 visual_prompt]: Epoch 28 / 100: avg data time: 5.70e-02, avg batch time: 0.5015, average train loss: 0.0455
[09/26 07:54:10 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.1677, average loss: 3.4860
[09/26 07:54:10 visual_prompt]: Classification results with val_vtab-sun397: top1: 32.50	top5: 59.00	
[09/26 07:54:10 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.22612712429686843
[09/26 07:54:17 visual_prompt]: Epoch 29 / 100: avg data time: 6.52e-02, avg batch time: 0.5078, average train loss: 0.0431
[09/26 07:54:19 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1678, average loss: 3.4680
[09/26 07:54:19 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.00	top5: 58.50	
[09/26 07:54:19 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.22350134420084022
[09/26 07:54:26 visual_prompt]: Epoch 30 / 100: avg data time: 4.81e-02, avg batch time: 0.4935, average train loss: 0.0416
[09/26 07:54:27 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1677, average loss: 3.4817
[09/26 07:54:27 visual_prompt]: Classification results with val_vtab-sun397: top1: 32.00	top5: 59.50	
[09/26 07:54:27 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.22075555538987224
[09/26 07:54:34 visual_prompt]: Epoch 31 / 100: avg data time: 5.97e-02, avg batch time: 0.5025, average train loss: 0.0391
[09/26 07:54:36 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1677, average loss: 3.4836
[09/26 07:54:36 visual_prompt]: Classification results with val_vtab-sun397: top1: 31.50	top5: 59.50	
[09/26 07:54:36 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.21789310318467428
[09/26 07:54:43 visual_prompt]: Epoch 32 / 100: avg data time: 4.91e-02, avg batch time: 0.4927, average train loss: 0.0381
[09/26 07:54:44 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1675, average loss: 3.4849
[09/26 07:54:44 visual_prompt]: Classification results with val_vtab-sun397: top1: 30.00	top5: 59.00	
[09/26 07:54:44 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.21491747504233139
[09/26 07:54:51 visual_prompt]: Epoch 33 / 100: avg data time: 5.85e-02, avg batch time: 0.5026, average train loss: 0.0362
[09/26 07:54:53 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1677, average loss: 3.4942
[09/26 07:54:53 visual_prompt]: Classification results with val_vtab-sun397: top1: 31.00	top5: 58.00	
[09/26 07:54:53 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.21183229630737466
[09/26 07:55:00 visual_prompt]: Epoch 34 / 100: avg data time: 5.67e-02, avg batch time: 0.4999, average train loss: 0.0356
[09/26 07:55:01 visual_prompt]: Inference (val):avg data time: 4.55e-05, avg batch time: 0.1675, average loss: 3.4989
[09/26 07:55:01 visual_prompt]: Classification results with val_vtab-sun397: top1: 30.50	top5: 58.00	
[09/26 07:55:01 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.20864132579485728
[09/26 07:55:08 visual_prompt]: Epoch 35 / 100: avg data time: 6.28e-02, avg batch time: 0.5053, average train loss: 0.0342
[09/26 07:55:10 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1675, average loss: 3.4939
[09/26 07:55:10 visual_prompt]: Classification results with val_vtab-sun397: top1: 32.00	top5: 58.00	
[09/26 07:55:10 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.2053484512108174
[09/26 07:55:17 visual_prompt]: Epoch 36 / 100: avg data time: 6.03e-02, avg batch time: 0.5027, average train loss: 0.0328
[09/26 07:55:18 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1674, average loss: 3.5022
[09/26 07:55:18 visual_prompt]: Classification results with val_vtab-sun397: top1: 32.00	top5: 58.50	
[09/26 07:55:18 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.20195768441570727
[09/26 07:55:25 visual_prompt]: Epoch 37 / 100: avg data time: 6.65e-02, avg batch time: 0.5107, average train loss: 0.0326
[09/26 07:55:27 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1675, average loss: 3.4940
[09/26 07:55:27 visual_prompt]: Classification results with val_vtab-sun397: top1: 31.00	top5: 59.50	
[09/26 07:55:27 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.19847315653655914
[09/26 07:55:34 visual_prompt]: Epoch 38 / 100: avg data time: 5.57e-02, avg batch time: 0.5002, average train loss: 0.0314
[09/26 07:55:36 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1675, average loss: 3.5016
[09/26 07:55:36 visual_prompt]: Classification results with val_vtab-sun397: top1: 30.00	top5: 58.50	
[09/26 07:55:36 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.19489911293384335
[09/26 07:55:43 visual_prompt]: Epoch 39 / 100: avg data time: 6.40e-02, avg batch time: 0.5076, average train loss: 0.0309
[09/26 07:55:44 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1676, average loss: 3.4905
[09/26 07:55:44 visual_prompt]: Classification results with val_vtab-sun397: top1: 32.00	top5: 58.50	
[09/26 07:55:44 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.1912399080291506
[09/26 07:55:51 visual_prompt]: Epoch 40 / 100: avg data time: 6.12e-02, avg batch time: 0.5035, average train loss: 0.0296
[09/26 07:55:53 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1678, average loss: 3.4942
[09/26 07:55:53 visual_prompt]: Classification results with val_vtab-sun397: top1: 30.50	top5: 58.50	
[09/26 07:55:53 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.1875
[09/26 07:56:00 visual_prompt]: Epoch 41 / 100: avg data time: 5.90e-02, avg batch time: 0.5027, average train loss: 0.0298
[09/26 07:56:01 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1678, average loss: 3.4940
[09/26 07:56:01 visual_prompt]: Classification results with val_vtab-sun397: top1: 30.50	top5: 58.50	
[09/26 07:56:01 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.18368394534823634
[09/26 07:56:08 visual_prompt]: Epoch 42 / 100: avg data time: 6.12e-02, avg batch time: 0.5046, average train loss: 0.0289
[09/26 07:56:10 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1678, average loss: 3.4807
[09/26 07:56:10 visual_prompt]: Classification results with val_vtab-sun397: top1: 31.50	top5: 59.00	
[09/26 07:56:10 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.17979639334863468
[09/26 07:56:17 visual_prompt]: Epoch 43 / 100: avg data time: 6.34e-02, avg batch time: 0.5073, average train loss: 0.0281
[09/26 07:56:18 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1676, average loss: 3.4850
[09/26 07:56:18 visual_prompt]: Classification results with val_vtab-sun397: top1: 32.50	top5: 59.00	
[09/26 07:56:18 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.17584208038447505
[09/26 07:56:25 visual_prompt]: Epoch 44 / 100: avg data time: 6.05e-02, avg batch time: 0.5043, average train loss: 0.0278
[09/26 07:56:27 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1674, average loss: 3.5020
[09/26 07:56:27 visual_prompt]: Classification results with val_vtab-sun397: top1: 31.50	top5: 59.00	
[09/26 07:56:27 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.17182582417698902
[09/26 07:56:34 visual_prompt]: Epoch 45 / 100: avg data time: 6.25e-02, avg batch time: 0.5060, average train loss: 0.0268
[09/26 07:56:35 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1675, average loss: 3.4926
[09/26 07:56:35 visual_prompt]: Classification results with val_vtab-sun397: top1: 32.00	top5: 58.00	
[09/26 07:56:35 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.1677525179157086
[09/26 07:56:42 visual_prompt]: Epoch 46 / 100: avg data time: 6.23e-02, avg batch time: 0.5056, average train loss: 0.0265
[09/26 07:56:44 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1677, average loss: 3.4982
[09/26 07:56:44 visual_prompt]: Classification results with val_vtab-sun397: top1: 31.50	top5: 59.50	
[09/26 07:56:44 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.16362712429686843
[09/26 07:56:51 visual_prompt]: Epoch 47 / 100: avg data time: 6.62e-02, avg batch time: 0.5090, average train loss: 0.0258
[09/26 07:56:52 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1676, average loss: 3.5042
[09/26 07:56:52 visual_prompt]: Classification results with val_vtab-sun397: top1: 31.00	top5: 58.50	
[09/26 07:56:52 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.1594546694771249
[09/26 07:56:59 visual_prompt]: Epoch 48 / 100: avg data time: 5.73e-02, avg batch time: 0.5005, average train loss: 0.0260
[09/26 07:57:01 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1675, average loss: 3.5032
[09/26 07:57:01 visual_prompt]: Classification results with val_vtab-sun397: top1: 31.50	top5: 59.50	
[09/26 07:57:01 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.15524023694995845
[09/26 07:57:08 visual_prompt]: Epoch 49 / 100: avg data time: 6.42e-02, avg batch time: 0.5071, average train loss: 0.0256
[09/26 07:57:09 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1677, average loss: 3.4985
[09/26 07:57:09 visual_prompt]: Classification results with val_vtab-sun397: top1: 31.00	top5: 59.50	
[09/26 07:57:09 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.1509889613522199
[09/26 07:57:16 visual_prompt]: Epoch 50 / 100: avg data time: 5.78e-02, avg batch time: 0.5008, average train loss: 0.0250
[09/26 07:57:18 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1674, average loss: 3.5061
[09/26 07:57:18 visual_prompt]: Classification results with val_vtab-sun397: top1: 30.50	top5: 59.00	
[09/26 07:57:18 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.14670602220836632
[09/26 07:57:25 visual_prompt]: Epoch 51 / 100: avg data time: 6.45e-02, avg batch time: 0.5073, average train loss: 0.0250
[09/26 07:57:26 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1677, average loss: 3.5018
[09/26 07:57:26 visual_prompt]: Classification results with val_vtab-sun397: top1: 31.50	top5: 59.50	
[09/26 07:57:26 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.14239663762000818
[09/26 07:57:33 visual_prompt]: Epoch 52 / 100: avg data time: 5.72e-02, avg batch time: 0.5004, average train loss: 0.0245
[09/26 07:57:35 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1672, average loss: 3.5046
[09/26 07:57:35 visual_prompt]: Classification results with val_vtab-sun397: top1: 31.00	top5: 59.50	
[09/26 07:57:35 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.1380660579084567
[09/26 07:57:42 visual_prompt]: Epoch 53 / 100: avg data time: 6.20e-02, avg batch time: 0.5053, average train loss: 0.0242
[09/26 07:57:43 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1672, average loss: 3.5059
[09/26 07:57:43 visual_prompt]: Classification results with val_vtab-sun397: top1: 31.00	top5: 60.00	
[09/26 07:57:43 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.13371955921801565
[09/26 07:57:50 visual_prompt]: Epoch 54 / 100: avg data time: 5.99e-02, avg batch time: 0.5036, average train loss: 0.0244
[09/26 07:57:52 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1672, average loss: 3.5046
[09/26 07:57:52 visual_prompt]: Classification results with val_vtab-sun397: top1: 31.00	top5: 60.00	
[09/26 07:57:52 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.12936243708781264
[09/26 07:57:59 visual_prompt]: Epoch 55 / 100: avg data time: 6.01e-02, avg batch time: 0.5023, average train loss: 0.0240
[09/26 07:58:00 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1672, average loss: 3.5038
[09/26 07:58:00 visual_prompt]: Classification results with val_vtab-sun397: top1: 29.50	top5: 60.00	
[09/26 07:58:00 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.125
[09/26 07:58:07 visual_prompt]: Epoch 56 / 100: avg data time: 6.00e-02, avg batch time: 0.5024, average train loss: 0.0235
[09/26 07:58:09 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1676, average loss: 3.5078
[09/26 07:58:09 visual_prompt]: Classification results with val_vtab-sun397: top1: 30.00	top5: 60.50	
[09/26 07:58:09 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.12063756291218741
[09/26 07:58:16 visual_prompt]: Epoch 57 / 100: avg data time: 5.45e-02, avg batch time: 0.4978, average train loss: 0.0233
[09/26 07:58:17 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1672, average loss: 3.5008
[09/26 07:58:17 visual_prompt]: Classification results with val_vtab-sun397: top1: 31.00	top5: 60.00	
[09/26 07:58:17 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.11628044078198434
[09/26 07:58:24 visual_prompt]: Epoch 58 / 100: avg data time: 5.15e-02, avg batch time: 0.4965, average train loss: 0.0230
[09/26 07:58:26 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1675, average loss: 3.4953
[09/26 07:58:26 visual_prompt]: Classification results with val_vtab-sun397: top1: 30.50	top5: 59.50	
[09/26 07:58:26 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.11193394209154334
[09/26 07:58:33 visual_prompt]: Epoch 59 / 100: avg data time: 6.02e-02, avg batch time: 0.5021, average train loss: 0.0230
[09/26 07:58:34 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1675, average loss: 3.5021
[09/26 07:58:34 visual_prompt]: Classification results with val_vtab-sun397: top1: 31.00	top5: 58.50	
[09/26 07:58:34 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.10760336237999185
[09/26 07:58:41 visual_prompt]: Epoch 60 / 100: avg data time: 6.36e-02, avg batch time: 0.5067, average train loss: 0.0230
[09/26 07:58:43 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1676, average loss: 3.5039
[09/26 07:58:43 visual_prompt]: Classification results with val_vtab-sun397: top1: 31.00	top5: 59.00	
[09/26 07:58:43 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.10329397779163371
[09/26 07:58:50 visual_prompt]: Epoch 61 / 100: avg data time: 5.85e-02, avg batch time: 0.5021, average train loss: 0.0227
[09/26 07:58:51 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1673, average loss: 3.4986
[09/26 07:58:51 visual_prompt]: Classification results with val_vtab-sun397: top1: 30.00	top5: 59.00	
[09/26 07:58:51 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.0990110386477801
[09/26 07:58:58 visual_prompt]: Epoch 62 / 100: avg data time: 6.02e-02, avg batch time: 0.5033, average train loss: 0.0223
[09/26 07:59:00 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1674, average loss: 3.4974
[09/26 07:59:00 visual_prompt]: Classification results with val_vtab-sun397: top1: 30.00	top5: 59.00	
[09/26 07:59:00 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.09475976305004155
[09/26 07:59:07 visual_prompt]: Epoch 63 / 100: avg data time: 6.25e-02, avg batch time: 0.5053, average train loss: 0.0223
[09/26 07:59:08 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1673, average loss: 3.4975
[09/26 07:59:08 visual_prompt]: Classification results with val_vtab-sun397: top1: 30.00	top5: 60.00	
[09/26 07:59:08 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.09054533052287511
[09/26 07:59:15 visual_prompt]: Epoch 64 / 100: avg data time: 6.06e-02, avg batch time: 0.5033, average train loss: 0.0224
[09/26 07:59:17 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1677, average loss: 3.5011
[09/26 07:59:17 visual_prompt]: Classification results with val_vtab-sun397: top1: 29.50	top5: 59.50	
[09/26 07:59:17 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.08637287570313158
[09/26 07:59:24 visual_prompt]: Epoch 65 / 100: avg data time: 5.84e-02, avg batch time: 0.5002, average train loss: 0.0222
[09/26 07:59:25 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1676, average loss: 3.5023
[09/26 07:59:25 visual_prompt]: Classification results with val_vtab-sun397: top1: 29.50	top5: 60.00	
[09/26 07:59:25 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.08224748208429142
[09/26 07:59:32 visual_prompt]: Epoch 66 / 100: avg data time: 6.64e-02, avg batch time: 0.5083, average train loss: 0.0221
[09/26 07:59:34 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1674, average loss: 3.4984
[09/26 07:59:34 visual_prompt]: Classification results with val_vtab-sun397: top1: 30.00	top5: 60.00	
[09/26 07:59:34 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.07817417582301099
[09/26 07:59:41 visual_prompt]: Epoch 67 / 100: avg data time: 6.46e-02, avg batch time: 0.5083, average train loss: 0.0216
[09/26 07:59:43 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1672, average loss: 3.5003
[09/26 07:59:43 visual_prompt]: Classification results with val_vtab-sun397: top1: 31.00	top5: 60.00	
[09/26 07:59:43 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.074157919615525
[09/26 07:59:50 visual_prompt]: Epoch 68 / 100: avg data time: 7.14e-02, avg batch time: 0.5146, average train loss: 0.0216
[09/26 07:59:51 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1673, average loss: 3.4982
[09/26 07:59:51 visual_prompt]: Classification results with val_vtab-sun397: top1: 30.50	top5: 60.00	
[09/26 07:59:51 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.07020360665136531
[09/26 07:59:58 visual_prompt]: Epoch 69 / 100: avg data time: 5.81e-02, avg batch time: 0.5026, average train loss: 0.0217
[09/26 08:00:00 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1674, average loss: 3.4989
[09/26 08:00:00 visual_prompt]: Classification results with val_vtab-sun397: top1: 30.50	top5: 60.50	
[09/26 08:00:00 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.06631605465176368
[09/26 08:00:07 visual_prompt]: Epoch 70 / 100: avg data time: 5.92e-02, avg batch time: 0.5023, average train loss: 0.0215
[09/26 08:00:08 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1673, average loss: 3.4992
[09/26 08:00:08 visual_prompt]: Classification results with val_vtab-sun397: top1: 30.00	top5: 60.00	
[09/26 08:00:08 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.06250000000000003
[09/26 08:00:15 visual_prompt]: Epoch 71 / 100: avg data time: 6.12e-02, avg batch time: 0.5053, average train loss: 0.0216
[09/26 08:00:17 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1675, average loss: 3.5015
[09/26 08:00:17 visual_prompt]: Classification results with val_vtab-sun397: top1: 30.50	top5: 61.00	
[09/26 08:00:17 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.0587600919708494
[09/26 08:00:24 visual_prompt]: Epoch 72 / 100: avg data time: 6.19e-02, avg batch time: 0.5046, average train loss: 0.0213
[09/26 08:00:25 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1671, average loss: 3.5057
[09/26 08:00:25 visual_prompt]: Classification results with val_vtab-sun397: top1: 31.00	top5: 61.00	
[09/26 08:00:25 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.055100887066156665
[09/26 08:00:32 visual_prompt]: Epoch 73 / 100: avg data time: 4.90e-02, avg batch time: 0.4949, average train loss: 0.0211
[09/26 08:00:34 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1674, average loss: 3.5054
[09/26 08:00:34 visual_prompt]: Classification results with val_vtab-sun397: top1: 31.00	top5: 61.00	
[09/26 08:00:34 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.05152684346344087
[09/26 08:00:41 visual_prompt]: Epoch 74 / 100: avg data time: 6.31e-02, avg batch time: 0.5067, average train loss: 0.0213
[09/26 08:00:42 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1674, average loss: 3.5032
[09/26 08:00:42 visual_prompt]: Classification results with val_vtab-sun397: top1: 30.50	top5: 60.50	
[09/26 08:00:42 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.048042315584292714
[09/26 08:00:49 visual_prompt]: Epoch 75 / 100: avg data time: 6.19e-02, avg batch time: 0.5059, average train loss: 0.0213
[09/26 08:00:51 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1678, average loss: 3.5033
[09/26 08:00:51 visual_prompt]: Classification results with val_vtab-sun397: top1: 30.50	top5: 60.00	
[09/26 08:00:51 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.04465154878918258
[09/26 08:00:58 visual_prompt]: Epoch 76 / 100: avg data time: 5.60e-02, avg batch time: 0.4993, average train loss: 0.0210
[09/26 08:00:59 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1676, average loss: 3.5062
[09/26 08:00:59 visual_prompt]: Classification results with val_vtab-sun397: top1: 30.00	top5: 59.50	
[09/26 08:00:59 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.04135867420514276
[09/26 08:01:06 visual_prompt]: Epoch 77 / 100: avg data time: 6.29e-02, avg batch time: 0.5075, average train loss: 0.0211
[09/26 08:01:08 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1676, average loss: 3.5054
[09/26 08:01:08 visual_prompt]: Classification results with val_vtab-sun397: top1: 30.50	top5: 60.50	
[09/26 08:01:08 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.03816770369262533
[09/26 08:01:15 visual_prompt]: Epoch 78 / 100: avg data time: 5.81e-02, avg batch time: 0.5003, average train loss: 0.0210
[09/26 08:01:16 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1674, average loss: 3.5049
[09/26 08:01:16 visual_prompt]: Classification results with val_vtab-sun397: top1: 30.50	top5: 61.00	
[09/26 08:01:16 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.03508252495766863
[09/26 08:01:23 visual_prompt]: Epoch 79 / 100: avg data time: 5.88e-02, avg batch time: 0.5024, average train loss: 0.0209
[09/26 08:01:25 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1676, average loss: 3.5053
[09/26 08:01:25 visual_prompt]: Classification results with val_vtab-sun397: top1: 30.00	top5: 60.50	
[09/26 08:01:25 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.032106896815325706
[09/26 08:01:32 visual_prompt]: Epoch 80 / 100: avg data time: 6.09e-02, avg batch time: 0.5040, average train loss: 0.0209
[09/26 08:01:33 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1678, average loss: 3.5056
[09/26 08:01:33 visual_prompt]: Classification results with val_vtab-sun397: top1: 30.50	top5: 60.50	
[09/26 08:01:33 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.029244444610127762
[09/26 08:01:40 visual_prompt]: Epoch 81 / 100: avg data time: 5.79e-02, avg batch time: 0.5007, average train loss: 0.0210
[09/26 08:01:42 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1677, average loss: 3.5063
[09/26 08:01:42 visual_prompt]: Classification results with val_vtab-sun397: top1: 30.50	top5: 60.50	
[09/26 08:01:42 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.026498655799159762
[09/26 08:01:49 visual_prompt]: Epoch 82 / 100: avg data time: 5.50e-02, avg batch time: 0.4997, average train loss: 0.0207
[09/26 08:01:50 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1681, average loss: 3.5065
[09/26 08:01:50 visual_prompt]: Classification results with val_vtab-sun397: top1: 30.50	top5: 60.50	
[09/26 08:01:50 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.023872875703131582
[09/26 08:01:57 visual_prompt]: Epoch 83 / 100: avg data time: 6.09e-02, avg batch time: 0.5042, average train loss: 0.0210
[09/26 08:01:59 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1676, average loss: 3.5063
[09/26 08:01:59 visual_prompt]: Classification results with val_vtab-sun397: top1: 30.50	top5: 60.50	
[09/26 08:01:59 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.021370303430619797
[09/26 08:02:06 visual_prompt]: Epoch 84 / 100: avg data time: 5.78e-02, avg batch time: 0.5031, average train loss: 0.0207
[09/26 08:02:07 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1679, average loss: 3.5062
[09/26 08:02:07 visual_prompt]: Classification results with val_vtab-sun397: top1: 31.00	top5: 60.50	
[09/26 08:02:07 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.018993987980446755
[09/26 08:02:14 visual_prompt]: Epoch 85 / 100: avg data time: 6.15e-02, avg batch time: 0.5038, average train loss: 0.0206
[09/26 08:02:16 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1673, average loss: 3.5065
[09/26 08:02:16 visual_prompt]: Classification results with val_vtab-sun397: top1: 31.00	top5: 60.50	
[09/26 08:02:16 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.01674682452694516
[09/26 08:02:23 visual_prompt]: Epoch 86 / 100: avg data time: 6.37e-02, avg batch time: 0.5065, average train loss: 0.0208
[09/26 08:02:25 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1678, average loss: 3.5062
[09/26 08:02:25 visual_prompt]: Classification results with val_vtab-sun397: top1: 30.50	top5: 61.00	
[09/26 08:02:25 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.014631550892634126
[09/26 08:02:32 visual_prompt]: Epoch 87 / 100: avg data time: 6.06e-02, avg batch time: 0.5029, average train loss: 0.0209
[09/26 08:02:33 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1678, average loss: 3.5063
[09/26 08:02:33 visual_prompt]: Classification results with val_vtab-sun397: top1: 30.50	top5: 60.50	
[09/26 08:02:33 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.012650744212604148
[09/26 08:02:40 visual_prompt]: Epoch 88 / 100: avg data time: 6.67e-02, avg batch time: 0.5095, average train loss: 0.0205
[09/26 08:02:42 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1677, average loss: 3.5065
[09/26 08:02:42 visual_prompt]: Classification results with val_vtab-sun397: top1: 30.50	top5: 61.00	
[09/26 08:02:42 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.010806817794674878
[09/26 08:02:49 visual_prompt]: Epoch 89 / 100: avg data time: 6.51e-02, avg batch time: 0.5075, average train loss: 0.0210
[09/26 08:02:50 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1672, average loss: 3.5059
[09/26 08:02:50 visual_prompt]: Classification results with val_vtab-sun397: top1: 30.50	top5: 60.50	
[09/26 08:02:50 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.009102018179151586
[09/26 08:02:57 visual_prompt]: Epoch 90 / 100: avg data time: 5.31e-02, avg batch time: 0.4963, average train loss: 0.0206
[09/26 08:02:59 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1673, average loss: 3.5057
[09/26 08:02:59 visual_prompt]: Classification results with val_vtab-sun397: top1: 30.50	top5: 60.50	
[09/26 08:02:59 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.00753842240176146
[09/26 08:03:06 visual_prompt]: Epoch 91 / 100: avg data time: 5.01e-02, avg batch time: 0.4932, average train loss: 0.0205
[09/26 08:03:07 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1678, average loss: 3.5058
[09/26 08:03:07 visual_prompt]: Classification results with val_vtab-sun397: top1: 30.50	top5: 60.50	
[09/26 08:03:07 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.006117935463105809
[09/26 08:03:14 visual_prompt]: Epoch 92 / 100: avg data time: 6.46e-02, avg batch time: 0.5077, average train loss: 0.0204
[09/26 08:03:16 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1671, average loss: 3.5056
[09/26 08:03:16 visual_prompt]: Classification results with val_vtab-sun397: top1: 30.50	top5: 60.50	
[09/26 08:03:16 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.004842288007710138
[09/26 08:03:23 visual_prompt]: Epoch 93 / 100: avg data time: 5.67e-02, avg batch time: 0.4998, average train loss: 0.0205
[09/26 08:03:24 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1680, average loss: 3.5055
[09/26 08:03:24 visual_prompt]: Classification results with val_vtab-sun397: top1: 30.50	top5: 60.50	
[09/26 08:03:24 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.003713034215500441
[09/26 08:03:31 visual_prompt]: Epoch 94 / 100: avg data time: 6.00e-02, avg batch time: 0.5027, average train loss: 0.0208
[09/26 08:03:33 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1675, average loss: 3.5056
[09/26 08:03:33 visual_prompt]: Classification results with val_vtab-sun397: top1: 30.50	top5: 60.50	
[09/26 08:03:33 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.002731549908274289
[09/26 08:03:40 visual_prompt]: Epoch 95 / 100: avg data time: 6.37e-02, avg batch time: 0.5081, average train loss: 0.0205
[09/26 08:03:41 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1674, average loss: 3.5057
[09/26 08:03:41 visual_prompt]: Classification results with val_vtab-sun397: top1: 30.50	top5: 60.00	
[09/26 08:03:41 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.0018990308734739975
[09/26 08:03:48 visual_prompt]: Epoch 96 / 100: avg data time: 6.02e-02, avg batch time: 0.5024, average train loss: 0.0209
[09/26 08:03:50 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1678, average loss: 3.5058
[09/26 08:03:50 visual_prompt]: Classification results with val_vtab-sun397: top1: 30.50	top5: 60.00	
[09/26 08:03:50 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.0012164914073037048
[09/26 08:03:57 visual_prompt]: Epoch 97 / 100: avg data time: 6.05e-02, avg batch time: 0.5037, average train loss: 0.0205
[09/26 08:03:58 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1673, average loss: 3.5058
[09/26 08:03:58 visual_prompt]: Classification results with val_vtab-sun397: top1: 30.50	top5: 60.00	
[09/26 08:03:58 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.0006847630789658388
[09/26 08:04:05 visual_prompt]: Epoch 98 / 100: avg data time: 6.12e-02, avg batch time: 0.5049, average train loss: 0.0208
[09/26 08:04:07 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1677, average loss: 3.5058
[09/26 08:04:07 visual_prompt]: Classification results with val_vtab-sun397: top1: 30.50	top5: 60.00	
[09/26 08:04:07 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.0003044937175219753
[09/26 08:04:14 visual_prompt]: Epoch 99 / 100: avg data time: 6.95e-02, avg batch time: 0.5121, average train loss: 0.0203
[09/26 08:04:16 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1679, average loss: 3.5058
[09/26 08:04:16 visual_prompt]: Classification results with val_vtab-sun397: top1: 30.50	top5: 60.00	
[09/26 08:04:16 visual_prompt]: Training 100 / 100 epoch, with learning rate 7.614662261302974e-05
[09/26 08:04:22 visual_prompt]: Epoch 100 / 100: avg data time: 5.26e-02, avg batch time: 0.4966, average train loss: 0.0207
[09/26 08:04:24 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1674, average loss: 3.5058
[09/26 08:04:24 visual_prompt]: Classification results with val_vtab-sun397: top1: 30.50	top5: 60.00	
[09/26 08:04:24 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 08:04:24 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              0
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 08:04:24 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-sun397', 'DATA.NUMBER_CLASSES', '397', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 08:04:24 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 08:04:24 visual_prompt]: Training with config:
[09/26 08:04:24 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-sun397/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.25_wd0.0/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 0.25, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-sun397', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 397, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 08:04:24 visual_prompt]: Loading training data...
[09/26 08:04:24 visual_prompt]: Constructing vtab-sun397 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split train[:800], from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/26 08:04:26 visual_prompt]: Number of images: 800
[09/26 08:04:26 visual_prompt]: Number of classes: 309 / 397
[09/26 08:04:26 visual_prompt]: Loading validation data...
[09/26 08:04:26 visual_prompt]: Constructing vtab-sun397 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split validation[:200], from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/26 08:04:26 visual_prompt]: Number of images: 200
[09/26 08:04:26 visual_prompt]: Number of classes: 136 / 397
[09/26 08:04:26 visual_prompt]: Constructing models...
[09/26 08:04:28 visual_prompt]: Total Parameters: 86564749	 Gradient Parameters: 766093
[09/26 08:04:28 visual_prompt]: tuned percent:0.885
[09/26 08:04:28 visual_prompt]: Device used for model: 0
[09/26 08:04:28 visual_prompt]: Setting up Evaluator...
[09/26 08:04:28 visual_prompt]: Setting up Trainer...
[09/26 08:04:28 visual_prompt]: 	Setting up the optimizer...
[09/26 08:04:28 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 08:04:35 visual_prompt]: Epoch 1 / 100: avg data time: 6.24e-02, avg batch time: 0.5075, average train loss: 5.9877
[09/26 08:04:37 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1674, average loss: 6.0097
[09/26 08:04:37 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/26 08:04:37 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.025
[09/26 08:04:44 visual_prompt]: Epoch 2 / 100: avg data time: 6.53e-02, avg batch time: 0.5080, average train loss: 5.9567
[09/26 08:04:46 visual_prompt]: Inference (val):avg data time: 4.04e-05, avg batch time: 0.1673, average loss: 5.9614
[09/26 08:04:46 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 2.00	
[09/26 08:04:46 visual_prompt]: Best epoch 2: best metric: 0.010
[09/26 08:04:46 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.05
[09/26 08:04:53 visual_prompt]: Epoch 3 / 100: avg data time: 6.07e-02, avg batch time: 0.5028, average train loss: 5.8220
[09/26 08:04:54 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1676, average loss: 5.8770
[09/26 08:04:54 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 08:04:54 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.075
[09/26 08:05:01 visual_prompt]: Epoch 4 / 100: avg data time: 6.37e-02, avg batch time: 0.5067, average train loss: 5.6376
[09/26 08:05:03 visual_prompt]: Inference (val):avg data time: 3.51e-05, avg batch time: 0.1673, average loss: 5.8024
[09/26 08:05:03 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.00	
[09/26 08:05:03 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.1
[09/26 08:05:10 visual_prompt]: Epoch 5 / 100: avg data time: 5.86e-02, avg batch time: 0.5019, average train loss: 5.4775
[09/26 08:05:11 visual_prompt]: Inference (val):avg data time: 5.42e-05, avg batch time: 0.1672, average loss: 5.6470
[09/26 08:05:11 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.00	top5: 9.50	
[09/26 08:05:11 visual_prompt]: Best epoch 5: best metric: 0.020
[09/26 08:05:11 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.125
[09/26 08:05:18 visual_prompt]: Epoch 6 / 100: avg data time: 5.50e-02, avg batch time: 0.4984, average train loss: 5.2160
[09/26 08:05:20 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1672, average loss: 5.4335
[09/26 08:05:20 visual_prompt]: Classification results with val_vtab-sun397: top1: 4.00	top5: 13.50	
[09/26 08:05:20 visual_prompt]: Best epoch 6: best metric: 0.040
[09/26 08:05:20 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.15
[09/26 08:05:27 visual_prompt]: Epoch 7 / 100: avg data time: 5.98e-02, avg batch time: 0.5026, average train loss: 4.8572
[09/26 08:05:28 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1674, average loss: 5.2138
[09/26 08:05:28 visual_prompt]: Classification results with val_vtab-sun397: top1: 8.00	top5: 16.50	
[09/26 08:05:28 visual_prompt]: Best epoch 7: best metric: 0.080
[09/26 08:05:28 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.175
[09/26 08:05:35 visual_prompt]: Epoch 8 / 100: avg data time: 6.50e-02, avg batch time: 0.5094, average train loss: 4.3712
[09/26 08:05:37 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1671, average loss: 4.8968
[09/26 08:05:37 visual_prompt]: Classification results with val_vtab-sun397: top1: 10.00	top5: 25.00	
[09/26 08:05:37 visual_prompt]: Best epoch 8: best metric: 0.100
[09/26 08:05:37 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.2
[09/26 08:05:44 visual_prompt]: Epoch 9 / 100: avg data time: 6.24e-02, avg batch time: 0.5049, average train loss: 3.8210
[09/26 08:05:45 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1673, average loss: 4.6141
[09/26 08:05:45 visual_prompt]: Classification results with val_vtab-sun397: top1: 16.50	top5: 29.50	
[09/26 08:05:45 visual_prompt]: Best epoch 9: best metric: 0.165
[09/26 08:05:45 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.225
[09/26 08:05:52 visual_prompt]: Epoch 10 / 100: avg data time: 6.65e-02, avg batch time: 0.5081, average train loss: 3.1797
[09/26 08:05:54 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1675, average loss: 4.3294
[09/26 08:05:54 visual_prompt]: Classification results with val_vtab-sun397: top1: 20.00	top5: 41.00	
[09/26 08:05:54 visual_prompt]: Best epoch 10: best metric: 0.200
[09/26 08:05:54 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.25
[09/26 08:06:01 visual_prompt]: Epoch 11 / 100: avg data time: 6.25e-02, avg batch time: 0.5057, average train loss: 2.4703
[09/26 08:06:02 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1674, average loss: 3.9916
[09/26 08:06:02 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.00	top5: 48.00	
[09/26 08:06:02 visual_prompt]: Best epoch 11: best metric: 0.220
[09/26 08:06:02 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.24992385337738698
[09/26 08:06:09 visual_prompt]: Epoch 12 / 100: avg data time: 6.35e-02, avg batch time: 0.5074, average train loss: 1.8067
[09/26 08:06:11 visual_prompt]: Inference (val):avg data time: 3.51e-05, avg batch time: 0.1674, average loss: 3.7898
[09/26 08:06:11 visual_prompt]: Classification results with val_vtab-sun397: top1: 23.50	top5: 54.00	
[09/26 08:06:11 visual_prompt]: Best epoch 12: best metric: 0.235
[09/26 08:06:11 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.24969550628247802
[09/26 08:06:18 visual_prompt]: Epoch 13 / 100: avg data time: 6.48e-02, avg batch time: 0.5077, average train loss: 1.2435
[09/26 08:06:20 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1673, average loss: 3.5935
[09/26 08:06:20 visual_prompt]: Classification results with val_vtab-sun397: top1: 31.50	top5: 56.50	
[09/26 08:06:20 visual_prompt]: Best epoch 13: best metric: 0.315
[09/26 08:06:20 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.24931523692103416
[09/26 08:06:27 visual_prompt]: Epoch 14 / 100: avg data time: 5.83e-02, avg batch time: 0.5011, average train loss: 0.8108
[09/26 08:06:28 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1673, average loss: 3.5615
[09/26 08:06:28 visual_prompt]: Classification results with val_vtab-sun397: top1: 30.00	top5: 57.00	
[09/26 08:06:28 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.2487835085926963
[09/26 08:06:35 visual_prompt]: Epoch 15 / 100: avg data time: 6.13e-02, avg batch time: 0.5058, average train loss: 0.5227
[09/26 08:06:37 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1675, average loss: 3.4697
[09/26 08:06:37 visual_prompt]: Classification results with val_vtab-sun397: top1: 31.00	top5: 58.00	
[09/26 08:06:37 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.24810096912652602
[09/26 08:06:44 visual_prompt]: Epoch 16 / 100: avg data time: 6.31e-02, avg batch time: 0.5057, average train loss: 0.3385
[09/26 08:06:45 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1672, average loss: 3.4194
[09/26 08:06:45 visual_prompt]: Classification results with val_vtab-sun397: top1: 30.00	top5: 55.50	
[09/26 08:06:45 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.2472684500917257
[09/26 08:06:52 visual_prompt]: Epoch 17 / 100: avg data time: 5.67e-02, avg batch time: 0.5003, average train loss: 0.2300
[09/26 08:06:54 visual_prompt]: Inference (val):avg data time: 4.20e-05, avg batch time: 0.1675, average loss: 3.3930
[09/26 08:06:54 visual_prompt]: Classification results with val_vtab-sun397: top1: 34.50	top5: 58.50	
[09/26 08:06:54 visual_prompt]: Best epoch 17: best metric: 0.345
[09/26 08:06:54 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.24628696578449955
[09/26 08:07:01 visual_prompt]: Epoch 18 / 100: avg data time: 6.09e-02, avg batch time: 0.5043, average train loss: 0.1599
[09/26 08:07:02 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1673, average loss: 3.3920
[09/26 08:07:02 visual_prompt]: Classification results with val_vtab-sun397: top1: 30.00	top5: 57.00	
[09/26 08:07:02 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.24515771199228986
[09/26 08:07:09 visual_prompt]: Epoch 19 / 100: avg data time: 5.73e-02, avg batch time: 0.4995, average train loss: 0.1224
[09/26 08:07:11 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1675, average loss: 3.3585
[09/26 08:07:11 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 58.00	
[09/26 08:07:11 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.2438820645368942
[09/26 08:07:18 visual_prompt]: Epoch 20 / 100: avg data time: 6.04e-02, avg batch time: 0.5041, average train loss: 0.1041
[09/26 08:07:19 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1676, average loss: 3.3817
[09/26 08:07:19 visual_prompt]: Classification results with val_vtab-sun397: top1: 32.50	top5: 59.50	
[09/26 08:07:19 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.24246157759823855
[09/26 08:07:26 visual_prompt]: Epoch 21 / 100: avg data time: 6.33e-02, avg batch time: 0.5053, average train loss: 0.0873
[09/26 08:07:28 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1673, average loss: 3.4358
[09/26 08:07:28 visual_prompt]: Classification results with val_vtab-sun397: top1: 31.50	top5: 57.50	
[09/26 08:07:28 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.24089798182084843
[09/26 08:07:35 visual_prompt]: Epoch 22 / 100: avg data time: 6.52e-02, avg batch time: 0.5092, average train loss: 0.0751
[09/26 08:07:36 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1676, average loss: 3.4051
[09/26 08:07:36 visual_prompt]: Classification results with val_vtab-sun397: top1: 32.00	top5: 57.00	
[09/26 08:07:36 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.2391931822053251
[09/26 08:07:43 visual_prompt]: Epoch 23 / 100: avg data time: 5.69e-02, avg batch time: 0.4989, average train loss: 0.0672
[09/26 08:07:45 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1675, average loss: 3.3838
[09/26 08:07:45 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.00	top5: 57.50	
[09/26 08:07:45 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.23734925578739588
[09/26 08:07:52 visual_prompt]: Epoch 24 / 100: avg data time: 5.40e-02, avg batch time: 0.4987, average train loss: 0.0571
[09/26 08:07:53 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1675, average loss: 3.4075
[09/26 08:07:53 visual_prompt]: Classification results with val_vtab-sun397: top1: 31.50	top5: 57.50	
[09/26 08:07:53 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.23536844910736587
[09/26 08:08:00 visual_prompt]: Epoch 25 / 100: avg data time: 6.17e-02, avg batch time: 0.5075, average train loss: 0.0519
[09/26 08:08:02 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1676, average loss: 3.3852
[09/26 08:08:02 visual_prompt]: Classification results with val_vtab-sun397: top1: 32.00	top5: 56.50	
[09/26 08:08:02 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.23325317547305485
[09/26 08:08:09 visual_prompt]: Epoch 26 / 100: avg data time: 6.12e-02, avg batch time: 0.5043, average train loss: 0.0473
[09/26 08:08:10 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1676, average loss: 3.3875
[09/26 08:08:10 visual_prompt]: Classification results with val_vtab-sun397: top1: 30.50	top5: 56.50	
[09/26 08:08:10 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.23100601201955323
[09/26 08:08:17 visual_prompt]: Epoch 27 / 100: avg data time: 5.82e-02, avg batch time: 0.5005, average train loss: 0.0440
[09/26 08:08:19 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1674, average loss: 3.3992
[09/26 08:08:19 visual_prompt]: Classification results with val_vtab-sun397: top1: 32.50	top5: 57.50	
[09/26 08:08:19 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.2286296965693802
[09/26 08:08:26 visual_prompt]: Epoch 28 / 100: avg data time: 5.96e-02, avg batch time: 0.5033, average train loss: 0.0405
[09/26 08:08:27 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1675, average loss: 3.3920
[09/26 08:08:27 visual_prompt]: Classification results with val_vtab-sun397: top1: 32.00	top5: 58.00	
[09/26 08:08:27 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.22612712429686843
[09/26 08:08:34 visual_prompt]: Epoch 29 / 100: avg data time: 4.90e-02, avg batch time: 0.4925, average train loss: 0.0378
[09/26 08:08:36 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1676, average loss: 3.4100
[09/26 08:08:36 visual_prompt]: Classification results with val_vtab-sun397: top1: 32.00	top5: 57.00	
[09/26 08:08:36 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.22350134420084022
[09/26 08:08:42 visual_prompt]: Epoch 30 / 100: avg data time: 6.46e-02, avg batch time: 0.5083, average train loss: 0.0363
[09/26 08:08:44 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1676, average loss: 3.4000
[09/26 08:08:44 visual_prompt]: Classification results with val_vtab-sun397: top1: 32.00	top5: 58.00	
[09/26 08:08:44 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.22075555538987224
[09/26 08:08:51 visual_prompt]: Epoch 31 / 100: avg data time: 5.88e-02, avg batch time: 0.5031, average train loss: 0.0340
[09/26 08:08:52 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1675, average loss: 3.4031
[09/26 08:08:52 visual_prompt]: Classification results with val_vtab-sun397: top1: 32.00	top5: 58.00	
[09/26 08:08:52 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.21789310318467428
[09/26 08:08:59 visual_prompt]: Epoch 32 / 100: avg data time: 6.36e-02, avg batch time: 0.5063, average train loss: 0.0317
[09/26 08:09:01 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1673, average loss: 3.4205
[09/26 08:09:01 visual_prompt]: Classification results with val_vtab-sun397: top1: 32.00	top5: 58.50	
[09/26 08:09:01 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.21491747504233139
[09/26 08:09:08 visual_prompt]: Epoch 33 / 100: avg data time: 6.08e-02, avg batch time: 0.5043, average train loss: 0.0305
[09/26 08:09:10 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1672, average loss: 3.4109
[09/26 08:09:10 visual_prompt]: Classification results with val_vtab-sun397: top1: 32.00	top5: 57.50	
[09/26 08:09:10 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.21183229630737466
[09/26 08:09:16 visual_prompt]: Epoch 34 / 100: avg data time: 5.66e-02, avg batch time: 0.4994, average train loss: 0.0292
[09/26 08:09:18 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1672, average loss: 3.4035
[09/26 08:09:18 visual_prompt]: Classification results with val_vtab-sun397: top1: 32.00	top5: 57.50	
[09/26 08:09:18 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.20864132579485728
[09/26 08:09:25 visual_prompt]: Epoch 35 / 100: avg data time: 6.21e-02, avg batch time: 0.5046, average train loss: 0.0281
[09/26 08:09:27 visual_prompt]: Inference (val):avg data time: 4.09e-05, avg batch time: 0.1673, average loss: 3.4052
[09/26 08:09:27 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.00	top5: 57.00	
[09/26 08:09:27 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.2053484512108174
[09/26 08:09:33 visual_prompt]: Epoch 36 / 100: avg data time: 5.96e-02, avg batch time: 0.5029, average train loss: 0.0272
[09/26 08:09:35 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1676, average loss: 3.4074
[09/26 08:09:35 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.00	top5: 57.50	
[09/26 08:09:35 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.20195768441570727
[09/26 08:09:42 visual_prompt]: Epoch 37 / 100: avg data time: 6.33e-02, avg batch time: 0.5059, average train loss: 0.0259
[09/26 08:09:44 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1676, average loss: 3.3961
[09/26 08:09:44 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.00	top5: 57.50	
[09/26 08:09:44 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.19847315653655914
[09/26 08:09:50 visual_prompt]: Epoch 38 / 100: avg data time: 5.23e-02, avg batch time: 0.4953, average train loss: 0.0242
[09/26 08:09:52 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1670, average loss: 3.4125
[09/26 08:09:52 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.00	top5: 59.00	
[09/26 08:09:52 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.19489911293384335
[09/26 08:09:59 visual_prompt]: Epoch 39 / 100: avg data time: 5.75e-02, avg batch time: 0.5012, average train loss: 0.0237
[09/26 08:10:01 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1674, average loss: 3.4203
[09/26 08:10:01 visual_prompt]: Classification results with val_vtab-sun397: top1: 34.00	top5: 59.00	
[09/26 08:10:01 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.1912399080291506
[09/26 08:10:07 visual_prompt]: Epoch 40 / 100: avg data time: 5.77e-02, avg batch time: 0.5013, average train loss: 0.0236
[09/26 08:10:09 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1676, average loss: 3.4058
[09/26 08:10:09 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 59.00	
[09/26 08:10:09 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.1875
[09/26 08:10:16 visual_prompt]: Epoch 41 / 100: avg data time: 6.17e-02, avg batch time: 0.5057, average train loss: 0.0226
[09/26 08:10:18 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1673, average loss: 3.4126
[09/26 08:10:18 visual_prompt]: Classification results with val_vtab-sun397: top1: 32.50	top5: 59.00	
[09/26 08:10:18 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.18368394534823634
[09/26 08:10:25 visual_prompt]: Epoch 42 / 100: avg data time: 6.43e-02, avg batch time: 0.5071, average train loss: 0.0222
[09/26 08:10:26 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1671, average loss: 3.4160
[09/26 08:10:26 visual_prompt]: Classification results with val_vtab-sun397: top1: 32.50	top5: 58.50	
[09/26 08:10:26 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.17979639334863468
[09/26 08:10:33 visual_prompt]: Epoch 43 / 100: avg data time: 6.02e-02, avg batch time: 0.5024, average train loss: 0.0213
[09/26 08:10:35 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1673, average loss: 3.4259
[09/26 08:10:35 visual_prompt]: Classification results with val_vtab-sun397: top1: 32.50	top5: 59.00	
[09/26 08:10:35 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.17584208038447505
[09/26 08:10:42 visual_prompt]: Epoch 44 / 100: avg data time: 6.07e-02, avg batch time: 0.5040, average train loss: 0.0211
[09/26 08:10:43 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1680, average loss: 3.4338
[09/26 08:10:43 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 58.50	
[09/26 08:10:43 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.17182582417698902
[09/26 08:10:50 visual_prompt]: Epoch 45 / 100: avg data time: 4.99e-02, avg batch time: 0.4944, average train loss: 0.0200
[09/26 08:10:52 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1677, average loss: 3.4289
[09/26 08:10:52 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.00	top5: 59.00	
[09/26 08:10:52 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.1677525179157086
[09/26 08:10:59 visual_prompt]: Epoch 46 / 100: avg data time: 6.15e-02, avg batch time: 0.5056, average train loss: 0.0201
[09/26 08:11:00 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1675, average loss: 3.4305
[09/26 08:11:00 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.00	top5: 59.50	
[09/26 08:11:00 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.16362712429686843
[09/26 08:11:07 visual_prompt]: Epoch 47 / 100: avg data time: 6.29e-02, avg batch time: 0.5052, average train loss: 0.0195
[09/26 08:11:09 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1674, average loss: 3.4287
[09/26 08:11:09 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.00	top5: 59.50	
[09/26 08:11:09 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.1594546694771249
[09/26 08:11:16 visual_prompt]: Epoch 48 / 100: avg data time: 6.37e-02, avg batch time: 0.5060, average train loss: 0.0188
[09/26 08:11:17 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1675, average loss: 3.4277
[09/26 08:11:17 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.00	top5: 59.50	
[09/26 08:11:17 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.15524023694995845
[09/26 08:11:24 visual_prompt]: Epoch 49 / 100: avg data time: 5.74e-02, avg batch time: 0.4999, average train loss: 0.0185
[09/26 08:11:26 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1675, average loss: 3.4244
[09/26 08:11:26 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.00	top5: 60.00	
[09/26 08:11:26 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.1509889613522199
[09/26 08:11:33 visual_prompt]: Epoch 50 / 100: avg data time: 4.88e-02, avg batch time: 0.4936, average train loss: 0.0180
[09/26 08:11:34 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1675, average loss: 3.4248
[09/26 08:11:34 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.00	top5: 59.00	
[09/26 08:11:34 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.14670602220836632
[09/26 08:11:41 visual_prompt]: Epoch 51 / 100: avg data time: 6.33e-02, avg batch time: 0.5060, average train loss: 0.0176
[09/26 08:11:43 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1673, average loss: 3.4309
[09/26 08:11:43 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.00	top5: 59.50	
[09/26 08:11:43 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.14239663762000818
[09/26 08:11:50 visual_prompt]: Epoch 52 / 100: avg data time: 5.99e-02, avg batch time: 0.5036, average train loss: 0.0172
[09/26 08:11:51 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1674, average loss: 3.4392
[09/26 08:11:51 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.00	top5: 59.50	
[09/26 08:11:51 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.1380660579084567
[09/26 08:11:58 visual_prompt]: Epoch 53 / 100: avg data time: 6.24e-02, avg batch time: 0.5052, average train loss: 0.0171
[09/26 08:12:00 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1676, average loss: 3.4362
[09/26 08:12:00 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.00	top5: 59.50	
[09/26 08:12:00 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.13371955921801565
[09/26 08:12:07 visual_prompt]: Epoch 54 / 100: avg data time: 6.33e-02, avg batch time: 0.5064, average train loss: 0.0168
[09/26 08:12:08 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1677, average loss: 3.4295
[09/26 08:12:08 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.00	top5: 59.00	
[09/26 08:12:08 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.12936243708781264
[09/26 08:12:15 visual_prompt]: Epoch 55 / 100: avg data time: 6.68e-02, avg batch time: 0.5095, average train loss: 0.0168
[09/26 08:12:17 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1675, average loss: 3.4282
[09/26 08:12:17 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.00	top5: 59.50	
[09/26 08:12:17 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.125
[09/26 08:12:24 visual_prompt]: Epoch 56 / 100: avg data time: 6.26e-02, avg batch time: 0.5047, average train loss: 0.0165
[09/26 08:12:25 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1673, average loss: 3.4308
[09/26 08:12:25 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 59.50	
[09/26 08:12:25 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.12063756291218741
[09/26 08:12:32 visual_prompt]: Epoch 57 / 100: avg data time: 6.24e-02, avg batch time: 0.5062, average train loss: 0.0161
[09/26 08:12:34 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1675, average loss: 3.4324
[09/26 08:12:34 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.00	top5: 59.00	
[09/26 08:12:34 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.11628044078198434
[09/26 08:12:41 visual_prompt]: Epoch 58 / 100: avg data time: 6.42e-02, avg batch time: 0.5073, average train loss: 0.0160
[09/26 08:12:43 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1675, average loss: 3.4328
[09/26 08:12:43 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.00	top5: 58.50	
[09/26 08:12:43 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.11193394209154334
[09/26 08:12:49 visual_prompt]: Epoch 59 / 100: avg data time: 6.21e-02, avg batch time: 0.5044, average train loss: 0.0156
[09/26 08:12:51 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1676, average loss: 3.4343
[09/26 08:12:51 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.00	top5: 58.00	
[09/26 08:12:51 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.10760336237999185
[09/26 08:12:58 visual_prompt]: Epoch 60 / 100: avg data time: 5.76e-02, avg batch time: 0.5016, average train loss: 0.0153
[09/26 08:13:00 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1674, average loss: 3.4363
[09/26 08:13:00 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.00	top5: 59.50	
[09/26 08:13:00 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.10329397779163371
[09/26 08:13:06 visual_prompt]: Epoch 61 / 100: avg data time: 5.98e-02, avg batch time: 0.5035, average train loss: 0.0153
[09/26 08:13:08 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1676, average loss: 3.4348
[09/26 08:13:08 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.00	top5: 59.00	
[09/26 08:13:08 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.0990110386477801
[09/26 08:13:15 visual_prompt]: Epoch 62 / 100: avg data time: 6.03e-02, avg batch time: 0.5037, average train loss: 0.0151
[09/26 08:13:17 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1673, average loss: 3.4358
[09/26 08:13:17 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.00	top5: 58.50	
[09/26 08:13:17 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.09475976305004155
[09/26 08:13:23 visual_prompt]: Epoch 63 / 100: avg data time: 4.96e-02, avg batch time: 0.4916, average train loss: 0.0148
[09/26 08:13:25 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1673, average loss: 3.4353
[09/26 08:13:25 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.00	top5: 59.00	
[09/26 08:13:25 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.09054533052287511
[09/26 08:13:32 visual_prompt]: Epoch 64 / 100: avg data time: 5.71e-02, avg batch time: 0.5000, average train loss: 0.0146
[09/26 08:13:33 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1672, average loss: 3.4389
[09/26 08:13:33 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.00	top5: 59.00	
[09/26 08:13:33 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.08637287570313158
[09/26 08:13:40 visual_prompt]: Epoch 65 / 100: avg data time: 5.10e-02, avg batch time: 0.4954, average train loss: 0.0146
[09/26 08:13:42 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1674, average loss: 3.4436
[09/26 08:13:42 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.00	top5: 59.00	
[09/26 08:13:42 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.08224748208429142
[09/26 08:13:49 visual_prompt]: Epoch 66 / 100: avg data time: 6.28e-02, avg batch time: 0.5066, average train loss: 0.0145
[09/26 08:13:50 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1675, average loss: 3.4402
[09/26 08:13:50 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.00	top5: 59.00	
[09/26 08:13:50 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.07817417582301099
[09/26 08:13:57 visual_prompt]: Epoch 67 / 100: avg data time: 6.07e-02, avg batch time: 0.5043, average train loss: 0.0143
[09/26 08:13:59 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1678, average loss: 3.4398
[09/26 08:13:59 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.00	top5: 58.50	
[09/26 08:13:59 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.074157919615525
[09/26 08:14:06 visual_prompt]: Epoch 68 / 100: avg data time: 6.23e-02, avg batch time: 0.5049, average train loss: 0.0143
[09/26 08:14:07 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1678, average loss: 3.4428
[09/26 08:14:07 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.00	top5: 58.50	
[09/26 08:14:07 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.07020360665136531
[09/26 08:14:14 visual_prompt]: Epoch 69 / 100: avg data time: 6.02e-02, avg batch time: 0.5042, average train loss: 0.0141
[09/26 08:14:16 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1676, average loss: 3.4439
[09/26 08:14:16 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.00	top5: 58.50	
[09/26 08:14:16 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.06631605465176368
[09/26 08:14:23 visual_prompt]: Epoch 70 / 100: avg data time: 5.10e-02, avg batch time: 0.4958, average train loss: 0.0142
[09/26 08:14:24 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1674, average loss: 3.4426
[09/26 08:14:24 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.00	top5: 59.00	
[09/26 08:14:24 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.06250000000000003
[09/26 08:14:31 visual_prompt]: Epoch 71 / 100: avg data time: 6.37e-02, avg batch time: 0.5074, average train loss: 0.0139
[09/26 08:14:33 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1672, average loss: 3.4415
[09/26 08:14:33 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.00	top5: 58.50	
[09/26 08:14:33 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.0587600919708494
[09/26 08:14:40 visual_prompt]: Epoch 72 / 100: avg data time: 5.54e-02, avg batch time: 0.4985, average train loss: 0.0137
[09/26 08:14:42 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1672, average loss: 3.4406
[09/26 08:14:42 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.00	top5: 58.50	
[09/26 08:14:42 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.055100887066156665
[09/26 08:14:48 visual_prompt]: Epoch 73 / 100: avg data time: 6.00e-02, avg batch time: 0.5037, average train loss: 0.0136
[09/26 08:14:50 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1676, average loss: 3.4413
[09/26 08:14:50 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.00	top5: 58.50	
[09/26 08:14:50 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.05152684346344087
[09/26 08:14:57 visual_prompt]: Epoch 74 / 100: avg data time: 6.35e-02, avg batch time: 0.5068, average train loss: 0.0138
[09/26 08:14:59 visual_prompt]: Inference (val):avg data time: 4.36e-05, avg batch time: 0.1674, average loss: 3.4431
[09/26 08:14:59 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.00	top5: 58.50	
[09/26 08:14:59 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.048042315584292714
[09/26 08:15:06 visual_prompt]: Epoch 75 / 100: avg data time: 6.16e-02, avg batch time: 0.5050, average train loss: 0.0137
[09/26 08:15:07 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1678, average loss: 3.4433
[09/26 08:15:07 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.00	top5: 58.50	
[09/26 08:15:07 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.04465154878918258
[09/26 08:15:14 visual_prompt]: Epoch 76 / 100: avg data time: 6.12e-02, avg batch time: 0.5054, average train loss: 0.0134
[09/26 08:15:16 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1673, average loss: 3.4432
[09/26 08:15:16 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.00	top5: 58.50	
[09/26 08:15:16 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.04135867420514276
[09/26 08:15:23 visual_prompt]: Epoch 77 / 100: avg data time: 6.50e-02, avg batch time: 0.5080, average train loss: 0.0136
[09/26 08:15:24 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1674, average loss: 3.4421
[09/26 08:15:24 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.00	top5: 59.00	
[09/26 08:15:24 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.03816770369262533
[09/26 08:15:31 visual_prompt]: Epoch 78 / 100: avg data time: 6.59e-02, avg batch time: 0.5090, average train loss: 0.0134
[09/26 08:15:33 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1669, average loss: 3.4404
[09/26 08:15:33 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.00	top5: 59.00	
[09/26 08:15:33 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.03508252495766863
[09/26 08:15:40 visual_prompt]: Epoch 79 / 100: avg data time: 5.80e-02, avg batch time: 0.5038, average train loss: 0.0132
[09/26 08:15:41 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1674, average loss: 3.4398
[09/26 08:15:41 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.00	top5: 59.00	
[09/26 08:15:41 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.032106896815325706
[09/26 08:15:48 visual_prompt]: Epoch 80 / 100: avg data time: 6.31e-02, avg batch time: 0.5060, average train loss: 0.0134
[09/26 08:15:50 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1676, average loss: 3.4404
[09/26 08:15:50 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.00	top5: 59.00	
[09/26 08:15:50 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.029244444610127762
[09/26 08:15:57 visual_prompt]: Epoch 81 / 100: avg data time: 6.13e-02, avg batch time: 0.5054, average train loss: 0.0132
[09/26 08:15:58 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1672, average loss: 3.4411
[09/26 08:15:58 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.00	top5: 59.00	
[09/26 08:15:58 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.026498655799159762
[09/26 08:16:05 visual_prompt]: Epoch 82 / 100: avg data time: 6.23e-02, avg batch time: 0.5053, average train loss: 0.0132
[09/26 08:16:07 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1670, average loss: 3.4417
[09/26 08:16:07 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.00	top5: 59.00	
[09/26 08:16:07 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.023872875703131582
[09/26 08:16:14 visual_prompt]: Epoch 83 / 100: avg data time: 5.94e-02, avg batch time: 0.5026, average train loss: 0.0130
[09/26 08:16:15 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1669, average loss: 3.4419
[09/26 08:16:15 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.00	top5: 59.00	
[09/26 08:16:15 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.021370303430619797
[09/26 08:16:22 visual_prompt]: Epoch 84 / 100: avg data time: 6.19e-02, avg batch time: 0.5056, average train loss: 0.0131
[09/26 08:16:24 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1671, average loss: 3.4424
[09/26 08:16:24 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.00	top5: 59.00	
[09/26 08:16:24 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.018993987980446755
[09/26 08:16:31 visual_prompt]: Epoch 85 / 100: avg data time: 6.28e-02, avg batch time: 0.5054, average train loss: 0.0130
[09/26 08:16:32 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1672, average loss: 3.4429
[09/26 08:16:32 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.00	top5: 58.50	
[09/26 08:16:32 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.01674682452694516
[09/26 08:16:39 visual_prompt]: Epoch 86 / 100: avg data time: 6.04e-02, avg batch time: 0.5031, average train loss: 0.0131
[09/26 08:16:41 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1668, average loss: 3.4435
[09/26 08:16:41 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.00	top5: 58.50	
[09/26 08:16:41 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.014631550892634126
[09/26 08:16:48 visual_prompt]: Epoch 87 / 100: avg data time: 6.08e-02, avg batch time: 0.5031, average train loss: 0.0131
[09/26 08:16:49 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1678, average loss: 3.4435
[09/26 08:16:49 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.00	top5: 59.00	
[09/26 08:16:49 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.012650744212604148
[09/26 08:16:56 visual_prompt]: Epoch 88 / 100: avg data time: 6.02e-02, avg batch time: 0.5040, average train loss: 0.0131
[09/26 08:16:58 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1666, average loss: 3.4437
[09/26 08:16:58 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.00	top5: 59.00	
[09/26 08:16:58 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.010806817794674878
[09/26 08:17:05 visual_prompt]: Epoch 89 / 100: avg data time: 6.09e-02, avg batch time: 0.5031, average train loss: 0.0132
[09/26 08:17:06 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.1670, average loss: 3.4444
[09/26 08:17:06 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.00	top5: 59.00	
[09/26 08:17:06 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.009102018179151586
[09/26 08:17:13 visual_prompt]: Epoch 90 / 100: avg data time: 6.32e-02, avg batch time: 0.5062, average train loss: 0.0131
[09/26 08:17:15 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1672, average loss: 3.4457
[09/26 08:17:15 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.00	top5: 59.00	
[09/26 08:17:15 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.00753842240176146
[09/26 08:17:22 visual_prompt]: Epoch 91 / 100: avg data time: 6.40e-02, avg batch time: 0.5089, average train loss: 0.0131
[09/26 08:17:24 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1675, average loss: 3.4458
[09/26 08:17:24 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.00	top5: 59.00	
[09/26 08:17:24 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.006117935463105809
[09/26 08:17:31 visual_prompt]: Epoch 92 / 100: avg data time: 6.51e-02, avg batch time: 0.5071, average train loss: 0.0129
[09/26 08:17:32 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1676, average loss: 3.4460
[09/26 08:17:32 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.00	top5: 59.00	
[09/26 08:17:32 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.004842288007710138
[09/26 08:17:39 visual_prompt]: Epoch 93 / 100: avg data time: 5.42e-02, avg batch time: 0.4977, average train loss: 0.0131
[09/26 08:17:41 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1674, average loss: 3.4462
[09/26 08:17:41 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.00	top5: 59.00	
[09/26 08:17:41 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.003713034215500441
[09/26 08:17:48 visual_prompt]: Epoch 94 / 100: avg data time: 6.48e-02, avg batch time: 0.5082, average train loss: 0.0130
[09/26 08:17:49 visual_prompt]: Inference (val):avg data time: 4.61e-05, avg batch time: 0.1673, average loss: 3.4462
[09/26 08:17:49 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.00	top5: 59.00	
[09/26 08:17:49 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.002731549908274289
[09/26 08:17:56 visual_prompt]: Epoch 95 / 100: avg data time: 6.35e-02, avg batch time: 0.5063, average train loss: 0.0130
[09/26 08:17:58 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1672, average loss: 3.4462
[09/26 08:17:58 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.00	top5: 59.00	
[09/26 08:17:58 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.0018990308734739975
[09/26 08:18:05 visual_prompt]: Epoch 96 / 100: avg data time: 4.74e-02, avg batch time: 0.4904, average train loss: 0.0132
[09/26 08:18:06 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1675, average loss: 3.4462
[09/26 08:18:06 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.00	top5: 59.00	
[09/26 08:18:06 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.0012164914073037048
[09/26 08:18:13 visual_prompt]: Epoch 97 / 100: avg data time: 5.71e-02, avg batch time: 0.4993, average train loss: 0.0130
[09/26 08:18:15 visual_prompt]: Inference (val):avg data time: 4.36e-05, avg batch time: 0.1676, average loss: 3.4462
[09/26 08:18:15 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.00	top5: 59.00	
[09/26 08:18:15 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.0006847630789658388
[09/26 08:18:22 visual_prompt]: Epoch 98 / 100: avg data time: 5.80e-02, avg batch time: 0.5010, average train loss: 0.0129
[09/26 08:18:23 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1677, average loss: 3.4462
[09/26 08:18:23 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.00	top5: 59.00	
[09/26 08:18:23 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.0003044937175219753
[09/26 08:18:30 visual_prompt]: Epoch 99 / 100: avg data time: 6.19e-02, avg batch time: 0.5042, average train loss: 0.0131
[09/26 08:18:32 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1673, average loss: 3.4462
[09/26 08:18:32 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.00	top5: 59.00	
[09/26 08:18:32 visual_prompt]: Training 100 / 100 epoch, with learning rate 7.614662261302974e-05
[09/26 08:18:39 visual_prompt]: Epoch 100 / 100: avg data time: 5.79e-02, avg batch time: 0.5004, average train loss: 0.0129
[09/26 08:18:40 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1675, average loss: 3.4462
[09/26 08:18:40 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.00	top5: 59.00	
[09/26 08:18:40 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 08:18:40 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              0
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 08:18:40 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-sun397', 'DATA.NUMBER_CLASSES', '397', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 08:18:40 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 08:18:40 visual_prompt]: Training with config:
[09/26 08:18:40 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-sun397/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.1_wd0.01/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 0.1, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-sun397', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 397, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 08:18:40 visual_prompt]: Loading training data...
[09/26 08:18:40 visual_prompt]: Constructing vtab-sun397 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split train[:800], from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/26 08:18:42 visual_prompt]: Number of images: 800
[09/26 08:18:42 visual_prompt]: Number of classes: 309 / 397
[09/26 08:18:42 visual_prompt]: Loading validation data...
[09/26 08:18:42 visual_prompt]: Constructing vtab-sun397 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split validation[:200], from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/26 08:18:42 visual_prompt]: Number of images: 200
[09/26 08:18:42 visual_prompt]: Number of classes: 136 / 397
[09/26 08:18:42 visual_prompt]: Constructing models...
[09/26 08:18:44 visual_prompt]: Total Parameters: 86564749	 Gradient Parameters: 766093
[09/26 08:18:44 visual_prompt]: tuned percent:0.885
[09/26 08:18:45 visual_prompt]: Device used for model: 0
[09/26 08:18:45 visual_prompt]: Setting up Evaluator...
[09/26 08:18:45 visual_prompt]: Setting up Trainer...
[09/26 08:18:45 visual_prompt]: 	Setting up the optimizer...
[09/26 08:18:45 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 08:18:52 visual_prompt]: Epoch 1 / 100: avg data time: 6.49e-02, avg batch time: 0.5099, average train loss: 5.9908
[09/26 08:18:53 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1671, average loss: 6.0097
[09/26 08:18:53 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/26 08:18:53 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.010000000000000002
[09/26 08:19:00 visual_prompt]: Epoch 2 / 100: avg data time: 6.08e-02, avg batch time: 0.5031, average train loss: 5.9758
[09/26 08:19:02 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1675, average loss: 5.9870
[09/26 08:19:02 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/26 08:19:02 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.020000000000000004
[09/26 08:19:09 visual_prompt]: Epoch 3 / 100: avg data time: 6.17e-02, avg batch time: 0.5044, average train loss: 5.9247
[09/26 08:19:10 visual_prompt]: Inference (val):avg data time: 1.95e-05, avg batch time: 0.1673, average loss: 5.9396
[09/26 08:19:10 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 2.50	
[09/26 08:19:10 visual_prompt]: Best epoch 3: best metric: 0.010
[09/26 08:19:10 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.03
[09/26 08:19:17 visual_prompt]: Epoch 4 / 100: avg data time: 6.03e-02, avg batch time: 0.5026, average train loss: 5.8196
[09/26 08:19:19 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1675, average loss: 5.8576
[09/26 08:19:19 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 08:19:19 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.04000000000000001
[09/26 08:19:26 visual_prompt]: Epoch 5 / 100: avg data time: 6.05e-02, avg batch time: 0.5046, average train loss: 5.6744
[09/26 08:19:27 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1672, average loss: 5.8008
[09/26 08:19:27 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 5.50	
[09/26 08:19:27 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.05
[09/26 08:19:34 visual_prompt]: Epoch 6 / 100: avg data time: 6.20e-02, avg batch time: 0.5047, average train loss: 5.5155
[09/26 08:19:36 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.1678, average loss: 5.6828
[09/26 08:19:36 visual_prompt]: Classification results with val_vtab-sun397: top1: 4.50	top5: 8.00	
[09/26 08:19:36 visual_prompt]: Best epoch 6: best metric: 0.045
[09/26 08:19:36 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.06
[09/26 08:19:43 visual_prompt]: Epoch 7 / 100: avg data time: 6.36e-02, avg batch time: 0.5067, average train loss: 5.3562
[09/26 08:19:44 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1674, average loss: 5.5792
[09/26 08:19:44 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.50	top5: 10.00	
[09/26 08:19:44 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.06999999999999999
[09/26 08:19:51 visual_prompt]: Epoch 8 / 100: avg data time: 5.63e-02, avg batch time: 0.4997, average train loss: 5.1011
[09/26 08:19:53 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1674, average loss: 5.3641
[09/26 08:19:53 visual_prompt]: Classification results with val_vtab-sun397: top1: 5.00	top5: 14.00	
[09/26 08:19:53 visual_prompt]: Best epoch 8: best metric: 0.050
[09/26 08:19:53 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.08000000000000002
[09/26 08:20:00 visual_prompt]: Epoch 9 / 100: avg data time: 5.99e-02, avg batch time: 0.5034, average train loss: 4.8008
[09/26 08:20:01 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1670, average loss: 5.2569
[09/26 08:20:01 visual_prompt]: Classification results with val_vtab-sun397: top1: 4.00	top5: 13.50	
[09/26 08:20:01 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.09000000000000001
[09/26 08:20:08 visual_prompt]: Epoch 10 / 100: avg data time: 5.45e-02, avg batch time: 0.4978, average train loss: 4.4990
[09/26 08:20:10 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1671, average loss: 4.9620
[09/26 08:20:10 visual_prompt]: Classification results with val_vtab-sun397: top1: 12.00	top5: 24.00	
[09/26 08:20:10 visual_prompt]: Best epoch 10: best metric: 0.120
[09/26 08:20:10 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.1
[09/26 08:20:17 visual_prompt]: Epoch 11 / 100: avg data time: 5.70e-02, avg batch time: 0.4990, average train loss: 4.2122
[09/26 08:20:18 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1673, average loss: 4.8920
[09/26 08:20:18 visual_prompt]: Classification results with val_vtab-sun397: top1: 11.50	top5: 24.50	
[09/26 08:20:18 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0999695413509548
[09/26 08:20:25 visual_prompt]: Epoch 12 / 100: avg data time: 6.03e-02, avg batch time: 0.5037, average train loss: 3.9134
[09/26 08:20:27 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1671, average loss: 4.7429
[09/26 08:20:27 visual_prompt]: Classification results with val_vtab-sun397: top1: 14.50	top5: 29.00	
[09/26 08:20:27 visual_prompt]: Best epoch 12: best metric: 0.145
[09/26 08:20:27 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.09987820251299122
[09/26 08:20:34 visual_prompt]: Epoch 13 / 100: avg data time: 5.92e-02, avg batch time: 0.5023, average train loss: 3.6463
[09/26 08:20:35 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1673, average loss: 4.4593
[09/26 08:20:35 visual_prompt]: Classification results with val_vtab-sun397: top1: 16.50	top5: 33.50	
[09/26 08:20:35 visual_prompt]: Best epoch 13: best metric: 0.165
[09/26 08:20:35 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.09972609476841367
[09/26 08:20:42 visual_prompt]: Epoch 14 / 100: avg data time: 6.28e-02, avg batch time: 0.5058, average train loss: 3.3669
[09/26 08:20:44 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1677, average loss: 4.5493
[09/26 08:20:44 visual_prompt]: Classification results with val_vtab-sun397: top1: 15.00	top5: 33.00	
[09/26 08:20:44 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.09951340343707853
[09/26 08:20:51 visual_prompt]: Epoch 15 / 100: avg data time: 5.99e-02, avg batch time: 0.5026, average train loss: 3.1561
[09/26 08:20:52 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1672, average loss: 4.3862
[09/26 08:20:52 visual_prompt]: Classification results with val_vtab-sun397: top1: 17.00	top5: 37.50	
[09/26 08:20:52 visual_prompt]: Best epoch 15: best metric: 0.170
[09/26 08:20:52 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.09924038765061041
[09/26 08:20:59 visual_prompt]: Epoch 16 / 100: avg data time: 6.82e-02, avg batch time: 0.5111, average train loss: 2.9658
[09/26 08:21:01 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1671, average loss: 4.2862
[09/26 08:21:01 visual_prompt]: Classification results with val_vtab-sun397: top1: 18.00	top5: 40.00	
[09/26 08:21:01 visual_prompt]: Best epoch 16: best metric: 0.180
[09/26 08:21:01 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.09890738003669029
[09/26 08:21:08 visual_prompt]: Epoch 17 / 100: avg data time: 5.87e-02, avg batch time: 0.5009, average train loss: 2.7792
[09/26 08:21:09 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1674, average loss: 4.1686
[09/26 08:21:09 visual_prompt]: Classification results with val_vtab-sun397: top1: 20.00	top5: 44.00	
[09/26 08:21:09 visual_prompt]: Best epoch 17: best metric: 0.200
[09/26 08:21:09 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.09851478631379983
[09/26 08:21:16 visual_prompt]: Epoch 18 / 100: avg data time: 6.29e-02, avg batch time: 0.5067, average train loss: 2.6453
[09/26 08:21:18 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1677, average loss: 4.1410
[09/26 08:21:18 visual_prompt]: Classification results with val_vtab-sun397: top1: 24.00	top5: 46.50	
[09/26 08:21:18 visual_prompt]: Best epoch 18: best metric: 0.240
[09/26 08:21:18 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.09806308479691594
[09/26 08:21:25 visual_prompt]: Epoch 19 / 100: avg data time: 6.17e-02, avg batch time: 0.5039, average train loss: 2.5223
[09/26 08:21:26 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1679, average loss: 4.0730
[09/26 08:21:26 visual_prompt]: Classification results with val_vtab-sun397: top1: 23.00	top5: 49.00	
[09/26 08:21:26 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.09755282581475769
[09/26 08:21:33 visual_prompt]: Epoch 20 / 100: avg data time: 6.00e-02, avg batch time: 0.5030, average train loss: 2.3967
[09/26 08:21:35 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.1677, average loss: 4.1268
[09/26 08:21:35 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.00	top5: 47.50	
[09/26 08:21:35 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.09698463103929543
[09/26 08:21:42 visual_prompt]: Epoch 21 / 100: avg data time: 5.97e-02, avg batch time: 0.5031, average train loss: 2.3013
[09/26 08:21:43 visual_prompt]: Inference (val):avg data time: 4.59e-05, avg batch time: 0.1672, average loss: 4.0198
[09/26 08:21:43 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.50	top5: 47.50	
[09/26 08:21:43 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.09635919272833937
[09/26 08:21:50 visual_prompt]: Epoch 22 / 100: avg data time: 6.34e-02, avg batch time: 0.5072, average train loss: 2.2188
[09/26 08:21:52 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1674, average loss: 4.0365
[09/26 08:21:52 visual_prompt]: Classification results with val_vtab-sun397: top1: 24.00	top5: 47.50	
[09/26 08:21:52 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.09567727288213004
[09/26 08:21:59 visual_prompt]: Epoch 23 / 100: avg data time: 5.82e-02, avg batch time: 0.5009, average train loss: 2.1608
[09/26 08:22:00 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1673, average loss: 3.8818
[09/26 08:22:00 visual_prompt]: Classification results with val_vtab-sun397: top1: 29.50	top5: 54.00	
[09/26 08:22:00 visual_prompt]: Best epoch 23: best metric: 0.295
[09/26 08:22:00 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.09493970231495835
[09/26 08:22:07 visual_prompt]: Epoch 24 / 100: avg data time: 6.44e-02, avg batch time: 0.5072, average train loss: 2.0205
[09/26 08:22:09 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1678, average loss: 3.9425
[09/26 08:22:09 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.00	top5: 53.00	
[09/26 08:22:09 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.09414737964294635
[09/26 08:22:16 visual_prompt]: Epoch 25 / 100: avg data time: 6.04e-02, avg batch time: 0.5040, average train loss: 1.9646
[09/26 08:22:18 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1676, average loss: 3.9073
[09/26 08:22:18 visual_prompt]: Classification results with val_vtab-sun397: top1: 29.50	top5: 52.50	
[09/26 08:22:18 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.09330127018922195
[09/26 08:22:25 visual_prompt]: Epoch 26 / 100: avg data time: 6.29e-02, avg batch time: 0.5071, average train loss: 1.8996
[09/26 08:22:26 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1673, average loss: 3.8499
[09/26 08:22:26 visual_prompt]: Classification results with val_vtab-sun397: top1: 30.50	top5: 54.00	
[09/26 08:22:26 visual_prompt]: Best epoch 26: best metric: 0.305
[09/26 08:22:26 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.0924024048078213
[09/26 08:22:33 visual_prompt]: Epoch 27 / 100: avg data time: 6.53e-02, avg batch time: 0.5079, average train loss: 1.8241
[09/26 08:22:35 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1674, average loss: 3.8570
[09/26 08:22:35 visual_prompt]: Classification results with val_vtab-sun397: top1: 29.00	top5: 56.50	
[09/26 08:22:35 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.09145187862775209
[09/26 08:22:42 visual_prompt]: Epoch 28 / 100: avg data time: 6.24e-02, avg batch time: 0.5057, average train loss: 1.7961
[09/26 08:22:43 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1676, average loss: 3.8584
[09/26 08:22:43 visual_prompt]: Classification results with val_vtab-sun397: top1: 29.50	top5: 54.50	
[09/26 08:22:43 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.09045084971874738
[09/26 08:22:50 visual_prompt]: Epoch 29 / 100: avg data time: 6.87e-02, avg batch time: 0.5116, average train loss: 1.7647
[09/26 08:22:52 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1676, average loss: 3.8353
[09/26 08:22:52 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.50	top5: 54.50	
[09/26 08:22:52 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.0894005376803361
[09/26 08:22:59 visual_prompt]: Epoch 30 / 100: avg data time: 5.87e-02, avg batch time: 0.5040, average train loss: 1.7149
[09/26 08:23:00 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1679, average loss: 3.7665
[09/26 08:23:00 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 56.00	
[09/26 08:23:00 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.0883022221559489
[09/26 08:23:07 visual_prompt]: Epoch 31 / 100: avg data time: 6.34e-02, avg batch time: 0.5069, average train loss: 1.6860
[09/26 08:23:09 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1677, average loss: 4.5485
[09/26 08:23:09 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.50	top5: 46.50	
[09/26 08:23:09 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.08715724127386971
[09/26 08:23:16 visual_prompt]: Epoch 32 / 100: avg data time: 4.95e-02, avg batch time: 0.4919, average train loss: 1.9126
[09/26 08:23:17 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1673, average loss: 3.9213
[09/26 08:23:17 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 54.00	
[09/26 08:23:17 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.08596699001693256
[09/26 08:23:24 visual_prompt]: Epoch 33 / 100: avg data time: 6.47e-02, avg batch time: 0.5076, average train loss: 1.8348
[09/26 08:23:26 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1674, average loss: 3.8192
[09/26 08:23:26 visual_prompt]: Classification results with val_vtab-sun397: top1: 29.00	top5: 56.00	
[09/26 08:23:26 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.08473291852294987
[09/26 08:23:33 visual_prompt]: Epoch 34 / 100: avg data time: 5.95e-02, avg batch time: 0.5042, average train loss: 1.7616
[09/26 08:23:34 visual_prompt]: Inference (val):avg data time: 3.82e-05, avg batch time: 0.1672, average loss: 3.7945
[09/26 08:23:35 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.50	top5: 56.00	
[09/26 08:23:35 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.08345653031794292
[09/26 08:23:41 visual_prompt]: Epoch 35 / 100: avg data time: 6.35e-02, avg batch time: 0.5084, average train loss: 1.6515
[09/26 08:23:43 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1678, average loss: 3.7400
[09/26 08:23:43 visual_prompt]: Classification results with val_vtab-sun397: top1: 32.00	top5: 56.50	
[09/26 08:23:43 visual_prompt]: Best epoch 35: best metric: 0.320
[09/26 08:23:43 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.08213938048432697
[09/26 08:23:50 visual_prompt]: Epoch 36 / 100: avg data time: 6.49e-02, avg batch time: 0.5075, average train loss: 1.5835
[09/26 08:23:52 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1675, average loss: 3.7900
[09/26 08:23:52 visual_prompt]: Classification results with val_vtab-sun397: top1: 32.50	top5: 56.00	
[09/26 08:23:52 visual_prompt]: Best epoch 36: best metric: 0.325
[09/26 08:23:52 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.08078307376628291
[09/26 08:23:59 visual_prompt]: Epoch 37 / 100: avg data time: 5.88e-02, avg batch time: 0.5015, average train loss: 1.5371
[09/26 08:24:00 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1676, average loss: 3.7399
[09/26 08:24:00 visual_prompt]: Classification results with val_vtab-sun397: top1: 31.50	top5: 58.00	
[09/26 08:24:00 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.07938926261462366
[09/26 08:24:07 visual_prompt]: Epoch 38 / 100: avg data time: 6.44e-02, avg batch time: 0.5077, average train loss: 1.4979
[09/26 08:24:09 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1678, average loss: 3.6923
[09/26 08:24:09 visual_prompt]: Classification results with val_vtab-sun397: top1: 34.00	top5: 57.50	
[09/26 08:24:09 visual_prompt]: Best epoch 38: best metric: 0.340
[09/26 08:24:09 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.07795964517353735
[09/26 08:24:16 visual_prompt]: Epoch 39 / 100: avg data time: 5.96e-02, avg batch time: 0.5027, average train loss: 1.4674
[09/26 08:24:17 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1675, average loss: 3.7784
[09/26 08:24:17 visual_prompt]: Classification results with val_vtab-sun397: top1: 31.50	top5: 58.00	
[09/26 08:24:17 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.07649596321166025
[09/26 08:24:24 visual_prompt]: Epoch 40 / 100: avg data time: 5.63e-02, avg batch time: 0.5001, average train loss: 1.4676
[09/26 08:24:26 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1673, average loss: 3.6517
[09/26 08:24:26 visual_prompt]: Classification results with val_vtab-sun397: top1: 32.00	top5: 58.00	
[09/26 08:24:26 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.07500000000000001
[09/26 08:24:33 visual_prompt]: Epoch 41 / 100: avg data time: 6.35e-02, avg batch time: 0.5080, average train loss: 1.4421
[09/26 08:24:34 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1672, average loss: 3.6894
[09/26 08:24:34 visual_prompt]: Classification results with val_vtab-sun397: top1: 35.00	top5: 58.50	
[09/26 08:24:34 visual_prompt]: Best epoch 41: best metric: 0.350
[09/26 08:24:34 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.07347357813929455
[09/26 08:24:41 visual_prompt]: Epoch 42 / 100: avg data time: 6.56e-02, avg batch time: 0.5086, average train loss: 1.4326
[09/26 08:24:43 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1672, average loss: 3.7190
[09/26 08:24:43 visual_prompt]: Classification results with val_vtab-sun397: top1: 35.00	top5: 55.50	
[09/26 08:24:43 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.07191855733945388
[09/26 08:24:50 visual_prompt]: Epoch 43 / 100: avg data time: 5.92e-02, avg batch time: 0.5025, average train loss: 1.4456
[09/26 08:24:51 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1669, average loss: 3.7386
[09/26 08:24:51 visual_prompt]: Classification results with val_vtab-sun397: top1: 34.00	top5: 57.00	
[09/26 08:24:51 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.07033683215379002
[09/26 08:24:58 visual_prompt]: Epoch 44 / 100: avg data time: 6.10e-02, avg batch time: 0.5052, average train loss: 1.4454
[09/26 08:25:00 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1670, average loss: 3.7863
[09/26 08:25:00 visual_prompt]: Classification results with val_vtab-sun397: top1: 36.00	top5: 57.00	
[09/26 08:25:00 visual_prompt]: Best epoch 44: best metric: 0.360
[09/26 08:25:00 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.0687303296707956
[09/26 08:25:07 visual_prompt]: Epoch 45 / 100: avg data time: 5.96e-02, avg batch time: 0.5023, average train loss: 1.4552
[09/26 08:25:08 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1673, average loss: 3.7798
[09/26 08:25:08 visual_prompt]: Classification results with val_vtab-sun397: top1: 36.00	top5: 57.00	
[09/26 08:25:08 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.06710100716628345
[09/26 08:25:15 visual_prompt]: Epoch 46 / 100: avg data time: 5.72e-02, avg batch time: 0.5019, average train loss: 1.4465
[09/26 08:25:17 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1670, average loss: 3.7355
[09/26 08:25:17 visual_prompt]: Classification results with val_vtab-sun397: top1: 32.50	top5: 58.00	
[09/26 08:25:17 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.06545084971874737
[09/26 08:25:24 visual_prompt]: Epoch 47 / 100: avg data time: 5.91e-02, avg batch time: 0.5027, average train loss: 1.4060
[09/26 08:25:25 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1670, average loss: 3.7268
[09/26 08:25:25 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 58.00	
[09/26 08:25:25 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.06378186779084996
[09/26 08:25:32 visual_prompt]: Epoch 48 / 100: avg data time: 6.42e-02, avg batch time: 0.5077, average train loss: 1.3749
[09/26 08:25:34 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1672, average loss: 3.7995
[09/26 08:25:34 visual_prompt]: Classification results with val_vtab-sun397: top1: 34.50	top5: 57.50	
[09/26 08:25:34 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.06209609477998338
[09/26 08:25:41 visual_prompt]: Epoch 49 / 100: avg data time: 5.71e-02, avg batch time: 0.4998, average train loss: 1.3681
[09/26 08:25:42 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1672, average loss: 3.7539
[09/26 08:25:42 visual_prompt]: Classification results with val_vtab-sun397: top1: 30.00	top5: 58.50	
[09/26 08:25:42 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.06039558454088796
[09/26 08:25:49 visual_prompt]: Epoch 50 / 100: avg data time: 6.47e-02, avg batch time: 0.5080, average train loss: 1.3485
[09/26 08:25:51 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1670, average loss: 3.7546
[09/26 08:25:51 visual_prompt]: Classification results with val_vtab-sun397: top1: 36.00	top5: 59.00	
[09/26 08:25:51 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.058682408883346526
[09/26 08:25:58 visual_prompt]: Epoch 51 / 100: avg data time: 5.70e-02, avg batch time: 0.5006, average train loss: 1.3459
[09/26 08:25:59 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1669, average loss: 3.7521
[09/26 08:25:59 visual_prompt]: Classification results with val_vtab-sun397: top1: 32.50	top5: 57.50	
[09/26 08:25:59 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.05695865504800327
[09/26 08:26:06 visual_prompt]: Epoch 52 / 100: avg data time: 5.80e-02, avg batch time: 0.5005, average train loss: 1.3241
[09/26 08:26:08 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1676, average loss: 3.7502
[09/26 08:26:08 visual_prompt]: Classification results with val_vtab-sun397: top1: 31.50	top5: 57.50	
[09/26 08:26:08 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.05522642316338268
[09/26 08:26:15 visual_prompt]: Epoch 53 / 100: avg data time: 4.88e-02, avg batch time: 0.4937, average train loss: 1.2969
[09/26 08:26:16 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1671, average loss: 3.7670
[09/26 08:26:16 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.00	top5: 58.00	
[09/26 08:26:16 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.05348782368720626
[09/26 08:26:23 visual_prompt]: Epoch 54 / 100: avg data time: 6.08e-02, avg batch time: 0.5037, average train loss: 1.2788
[09/26 08:26:25 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1671, average loss: 3.7411
[09/26 08:26:25 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 59.00	
[09/26 08:26:25 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.05174497483512506
[09/26 08:26:32 visual_prompt]: Epoch 55 / 100: avg data time: 6.18e-02, avg batch time: 0.5053, average train loss: 1.2606
[09/26 08:26:33 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1670, average loss: 3.7278
[09/26 08:26:33 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.00	top5: 58.00	
[09/26 08:26:33 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.05
[09/26 08:26:40 visual_prompt]: Epoch 56 / 100: avg data time: 6.25e-02, avg batch time: 0.5057, average train loss: 1.2402
[09/26 08:26:42 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1672, average loss: 3.7362
[09/26 08:26:42 visual_prompt]: Classification results with val_vtab-sun397: top1: 35.50	top5: 58.50	
[09/26 08:26:42 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.04825502516487497
[09/26 08:26:49 visual_prompt]: Epoch 57 / 100: avg data time: 6.23e-02, avg batch time: 0.5052, average train loss: 1.2328
[09/26 08:26:50 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1680, average loss: 3.7165
[09/26 08:26:50 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.00	top5: 59.50	
[09/26 08:26:50 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.04651217631279374
[09/26 08:26:57 visual_prompt]: Epoch 58 / 100: avg data time: 4.68e-02, avg batch time: 0.4908, average train loss: 1.2237
[09/26 08:26:59 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1673, average loss: 3.7499
[09/26 08:26:59 visual_prompt]: Classification results with val_vtab-sun397: top1: 34.00	top5: 58.00	
[09/26 08:26:59 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.04477357683661734
[09/26 08:27:05 visual_prompt]: Epoch 59 / 100: avg data time: 5.97e-02, avg batch time: 0.5052, average train loss: 1.2207
[09/26 08:27:07 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1676, average loss: 3.7264
[09/26 08:27:07 visual_prompt]: Classification results with val_vtab-sun397: top1: 35.00	top5: 58.50	
[09/26 08:27:07 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.04304134495199674
[09/26 08:27:14 visual_prompt]: Epoch 60 / 100: avg data time: 6.40e-02, avg batch time: 0.5076, average train loss: 1.2162
[09/26 08:27:16 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1676, average loss: 3.7393
[09/26 08:27:16 visual_prompt]: Classification results with val_vtab-sun397: top1: 34.00	top5: 57.00	
[09/26 08:27:16 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.041317591116653486
[09/26 08:27:23 visual_prompt]: Epoch 61 / 100: avg data time: 5.94e-02, avg batch time: 0.5026, average train loss: 1.2132
[09/26 08:27:24 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1675, average loss: 3.7269
[09/26 08:27:24 visual_prompt]: Classification results with val_vtab-sun397: top1: 35.00	top5: 60.00	
[09/26 08:27:24 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.039604415459112044
[09/26 08:27:31 visual_prompt]: Epoch 62 / 100: avg data time: 6.30e-02, avg batch time: 0.5069, average train loss: 1.2103
[09/26 08:27:33 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1670, average loss: 3.6974
[09/26 08:27:33 visual_prompt]: Classification results with val_vtab-sun397: top1: 34.50	top5: 60.00	
[09/26 08:27:33 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.037903905220016625
[09/26 08:27:39 visual_prompt]: Epoch 63 / 100: avg data time: 4.79e-02, avg batch time: 0.4916, average train loss: 1.2038
[09/26 08:27:41 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1675, average loss: 3.7303
[09/26 08:27:41 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.50	top5: 59.00	
[09/26 08:27:41 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.036218132209150045
[09/26 08:27:48 visual_prompt]: Epoch 64 / 100: avg data time: 5.75e-02, avg batch time: 0.5030, average train loss: 1.1976
[09/26 08:27:50 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1678, average loss: 3.6982
[09/26 08:27:50 visual_prompt]: Classification results with val_vtab-sun397: top1: 36.00	top5: 58.50	
[09/26 08:27:50 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.03454915028125263
[09/26 08:27:57 visual_prompt]: Epoch 65 / 100: avg data time: 6.58e-02, avg batch time: 0.5103, average train loss: 1.1884
[09/26 08:27:58 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1670, average loss: 3.7059
[09/26 08:27:58 visual_prompt]: Classification results with val_vtab-sun397: top1: 36.00	top5: 59.00	
[09/26 08:27:58 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.03289899283371657
[09/26 08:28:05 visual_prompt]: Epoch 66 / 100: avg data time: 5.83e-02, avg batch time: 0.5018, average train loss: 1.1770
[09/26 08:28:07 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1672, average loss: 3.6603
[09/26 08:28:07 visual_prompt]: Classification results with val_vtab-sun397: top1: 36.00	top5: 59.50	
[09/26 08:28:07 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.0312696703292044
[09/26 08:28:14 visual_prompt]: Epoch 67 / 100: avg data time: 6.27e-02, avg batch time: 0.5062, average train loss: 1.1652
[09/26 08:28:15 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1673, average loss: 3.7067
[09/26 08:28:15 visual_prompt]: Classification results with val_vtab-sun397: top1: 34.00	top5: 59.00	
[09/26 08:28:15 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.02966316784621
[09/26 08:28:22 visual_prompt]: Epoch 68 / 100: avg data time: 6.11e-02, avg batch time: 0.5039, average train loss: 1.1514
[09/26 08:28:24 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1679, average loss: 3.6754
[09/26 08:28:24 visual_prompt]: Classification results with val_vtab-sun397: top1: 36.50	top5: 59.50	
[09/26 08:28:24 visual_prompt]: Best epoch 68: best metric: 0.365
[09/26 08:28:24 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.028081442660546126
[09/26 08:28:31 visual_prompt]: Epoch 69 / 100: avg data time: 6.19e-02, avg batch time: 0.5053, average train loss: 1.1427
[09/26 08:28:32 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.1676, average loss: 3.6573
[09/26 08:28:32 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.50	top5: 60.50	
[09/26 08:28:32 visual_prompt]: Best epoch 69: best metric: 0.375
[09/26 08:28:32 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.026526421860705474
[09/26 08:28:39 visual_prompt]: Epoch 70 / 100: avg data time: 5.70e-02, avg batch time: 0.5005, average train loss: 1.1397
[09/26 08:28:41 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1675, average loss: 3.6504
[09/26 08:28:41 visual_prompt]: Classification results with val_vtab-sun397: top1: 39.00	top5: 58.50	
[09/26 08:28:41 visual_prompt]: Best epoch 70: best metric: 0.390
[09/26 08:28:41 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.025000000000000012
[09/26 08:28:48 visual_prompt]: Epoch 71 / 100: avg data time: 6.25e-02, avg batch time: 0.5058, average train loss: 1.1362
[09/26 08:28:49 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1675, average loss: 3.6746
[09/26 08:28:49 visual_prompt]: Classification results with val_vtab-sun397: top1: 36.50	top5: 60.00	
[09/26 08:28:49 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.02350403678833976
[09/26 08:28:56 visual_prompt]: Epoch 72 / 100: avg data time: 6.00e-02, avg batch time: 0.5051, average train loss: 1.1274
[09/26 08:28:58 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1676, average loss: 3.6655
[09/26 08:28:58 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.00	top5: 59.50	
[09/26 08:28:58 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.022040354826462667
[09/26 08:29:05 visual_prompt]: Epoch 73 / 100: avg data time: 5.39e-02, avg batch time: 0.4974, average train loss: 1.1195
[09/26 08:29:06 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1676, average loss: 3.6864
[09/26 08:29:06 visual_prompt]: Classification results with val_vtab-sun397: top1: 35.50	top5: 59.00	
[09/26 08:29:06 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.02061073738537635
[09/26 08:29:13 visual_prompt]: Epoch 74 / 100: avg data time: 6.33e-02, avg batch time: 0.5066, average train loss: 1.1126
[09/26 08:29:15 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1672, average loss: 3.6863
[09/26 08:29:15 visual_prompt]: Classification results with val_vtab-sun397: top1: 36.50	top5: 59.50	
[09/26 08:29:15 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.019216926233717086
[09/26 08:29:22 visual_prompt]: Epoch 75 / 100: avg data time: 6.41e-02, avg batch time: 0.5074, average train loss: 1.1051
[09/26 08:29:23 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1678, average loss: 3.6818
[09/26 08:29:23 visual_prompt]: Classification results with val_vtab-sun397: top1: 34.00	top5: 59.50	
[09/26 08:29:23 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.017860619515673033
[09/26 08:29:30 visual_prompt]: Epoch 76 / 100: avg data time: 6.88e-02, avg batch time: 0.5123, average train loss: 1.0991
[09/26 08:29:32 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1675, average loss: 3.6437
[09/26 08:29:32 visual_prompt]: Classification results with val_vtab-sun397: top1: 36.00	top5: 59.00	
[09/26 08:29:32 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.016543469682057107
[09/26 08:29:39 visual_prompt]: Epoch 77 / 100: avg data time: 5.55e-02, avg batch time: 0.4998, average train loss: 1.0933
[09/26 08:29:40 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1677, average loss: 3.6649
[09/26 08:29:40 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.00	top5: 61.00	
[09/26 08:29:40 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.015267081477050132
[09/26 08:29:47 visual_prompt]: Epoch 78 / 100: avg data time: 6.01e-02, avg batch time: 0.5025, average train loss: 1.0920
[09/26 08:29:49 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1678, average loss: 3.7040
[09/26 08:29:49 visual_prompt]: Classification results with val_vtab-sun397: top1: 33.00	top5: 57.50	
[09/26 08:29:49 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.014033009983067453
[09/26 08:29:56 visual_prompt]: Epoch 79 / 100: avg data time: 6.27e-02, avg batch time: 0.5065, average train loss: 1.0877
[09/26 08:29:57 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1676, average loss: 3.6835
[09/26 08:29:57 visual_prompt]: Classification results with val_vtab-sun397: top1: 35.00	top5: 59.00	
[09/26 08:29:57 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.012842758726130284
[09/26 08:30:04 visual_prompt]: Epoch 80 / 100: avg data time: 5.93e-02, avg batch time: 0.5039, average train loss: 1.0815
[09/26 08:30:06 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1675, average loss: 3.6736
[09/26 08:30:06 visual_prompt]: Classification results with val_vtab-sun397: top1: 36.00	top5: 60.00	
[09/26 08:30:06 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.011697777844051106
[09/26 08:30:13 visual_prompt]: Epoch 81 / 100: avg data time: 6.50e-02, avg batch time: 0.5080, average train loss: 1.0782
[09/26 08:30:14 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1676, average loss: 3.6599
[09/26 08:30:14 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.50	top5: 59.50	
[09/26 08:30:14 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.010599462319663905
[09/26 08:30:21 visual_prompt]: Epoch 82 / 100: avg data time: 6.37e-02, avg batch time: 0.5065, average train loss: 1.0728
[09/26 08:30:23 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1673, average loss: 3.6782
[09/26 08:30:23 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.00	top5: 58.50	
[09/26 08:30:23 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.009549150281252633
[09/26 08:30:30 visual_prompt]: Epoch 83 / 100: avg data time: 6.34e-02, avg batch time: 0.5074, average train loss: 1.0698
[09/26 08:30:32 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1673, average loss: 3.6846
[09/26 08:30:32 visual_prompt]: Classification results with val_vtab-sun397: top1: 36.50	top5: 59.00	
[09/26 08:30:32 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.008548121372247919
[09/26 08:30:38 visual_prompt]: Epoch 84 / 100: avg data time: 5.99e-02, avg batch time: 0.5028, average train loss: 1.0684
[09/26 08:30:40 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1676, average loss: 3.6738
[09/26 08:30:40 visual_prompt]: Classification results with val_vtab-sun397: top1: 36.50	top5: 60.00	
[09/26 08:30:40 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.007597595192178702
[09/26 08:30:47 visual_prompt]: Epoch 85 / 100: avg data time: 5.31e-02, avg batch time: 0.4954, average train loss: 1.0640
[09/26 08:30:48 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1675, average loss: 3.6784
[09/26 08:30:48 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.00	top5: 59.00	
[09/26 08:30:48 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.006698729810778065
[09/26 08:30:55 visual_prompt]: Epoch 86 / 100: avg data time: 6.00e-02, avg batch time: 0.5027, average train loss: 1.0601
[09/26 08:30:57 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1673, average loss: 3.6671
[09/26 08:30:57 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.00	top5: 59.50	
[09/26 08:30:57 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.005852620357053651
[09/26 08:31:04 visual_prompt]: Epoch 87 / 100: avg data time: 5.95e-02, avg batch time: 0.5027, average train loss: 1.0585
[09/26 08:31:05 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1674, average loss: 3.6790
[09/26 08:31:05 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.00	top5: 59.00	
[09/26 08:31:05 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.00506029768504166
[09/26 08:31:12 visual_prompt]: Epoch 88 / 100: avg data time: 6.54e-02, avg batch time: 0.5095, average train loss: 1.0567
[09/26 08:31:14 visual_prompt]: Inference (val):avg data time: 4.04e-05, avg batch time: 0.1674, average loss: 3.6772
[09/26 08:31:14 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.00	top5: 59.00	
[09/26 08:31:14 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.004322727117869951
[09/26 08:31:21 visual_prompt]: Epoch 89 / 100: avg data time: 6.29e-02, avg batch time: 0.5054, average train loss: 1.0540
[09/26 08:31:23 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1675, average loss: 3.6832
[09/26 08:31:23 visual_prompt]: Classification results with val_vtab-sun397: top1: 36.50	top5: 58.50	
[09/26 08:31:23 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.0036408072716606343
[09/26 08:31:30 visual_prompt]: Epoch 90 / 100: avg data time: 5.97e-02, avg batch time: 0.5027, average train loss: 1.0530
[09/26 08:31:31 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1675, average loss: 3.6739
[09/26 08:31:31 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.00	top5: 58.50	
[09/26 08:31:31 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.0030153689607045845
[09/26 08:31:38 visual_prompt]: Epoch 91 / 100: avg data time: 5.53e-02, avg batch time: 0.4993, average train loss: 1.0501
[09/26 08:31:40 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1672, average loss: 3.6791
[09/26 08:31:40 visual_prompt]: Classification results with val_vtab-sun397: top1: 38.00	top5: 58.00	
[09/26 08:31:40 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.0024471741852423235
[09/26 08:31:46 visual_prompt]: Epoch 92 / 100: avg data time: 5.33e-02, avg batch time: 0.4975, average train loss: 1.0492
[09/26 08:31:48 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1672, average loss: 3.6744
[09/26 08:31:48 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.50	top5: 59.00	
[09/26 08:31:48 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.0019369152030840554
[09/26 08:31:55 visual_prompt]: Epoch 93 / 100: avg data time: 5.45e-02, avg batch time: 0.4998, average train loss: 1.0483
[09/26 08:31:57 visual_prompt]: Inference (val):avg data time: 4.42e-05, avg batch time: 0.1672, average loss: 3.6736
[09/26 08:31:57 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.50	top5: 59.00	
[09/26 08:31:57 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.0014852136862001765
[09/26 08:32:04 visual_prompt]: Epoch 94 / 100: avg data time: 6.36e-02, avg batch time: 0.5062, average train loss: 1.0469
[09/26 08:32:05 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1673, average loss: 3.6760
[09/26 08:32:05 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.00	top5: 59.00	
[09/26 08:32:05 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.0010926199633097156
[09/26 08:32:12 visual_prompt]: Epoch 95 / 100: avg data time: 5.80e-02, avg batch time: 0.5014, average train loss: 1.0461
[09/26 08:32:14 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1676, average loss: 3.6778
[09/26 08:32:14 visual_prompt]: Classification results with val_vtab-sun397: top1: 36.50	top5: 58.50	
[09/26 08:32:14 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.0007596123493895991
[09/26 08:32:21 visual_prompt]: Epoch 96 / 100: avg data time: 6.57e-02, avg batch time: 0.5078, average train loss: 1.0460
[09/26 08:32:22 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1677, average loss: 3.6788
[09/26 08:32:22 visual_prompt]: Classification results with val_vtab-sun397: top1: 36.50	top5: 58.50	
[09/26 08:32:22 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.00048659656292148194
[09/26 08:32:29 visual_prompt]: Epoch 97 / 100: avg data time: 6.51e-02, avg batch time: 0.5086, average train loss: 1.0452
[09/26 08:32:31 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1671, average loss: 3.6779
[09/26 08:32:31 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.50	top5: 59.00	
[09/26 08:32:31 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.0002739052315863355
[09/26 08:32:38 visual_prompt]: Epoch 98 / 100: avg data time: 6.50e-02, avg batch time: 0.5076, average train loss: 1.0454
[09/26 08:32:39 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1674, average loss: 3.6775
[09/26 08:32:39 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.00	top5: 59.00	
[09/26 08:32:39 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.00012179748700879012
[09/26 08:32:46 visual_prompt]: Epoch 99 / 100: avg data time: 5.76e-02, avg batch time: 0.5009, average train loss: 1.0444
[09/26 08:32:48 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1672, average loss: 3.6769
[09/26 08:32:48 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.00	top5: 59.00	
[09/26 08:32:48 visual_prompt]: Training 100 / 100 epoch, with learning rate 3.0458649045211895e-05
[09/26 08:32:55 visual_prompt]: Epoch 100 / 100: avg data time: 5.13e-02, avg batch time: 0.4944, average train loss: 1.0446
[09/26 08:32:56 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1677, average loss: 3.6766
[09/26 08:32:56 visual_prompt]: Classification results with val_vtab-sun397: top1: 37.00	top5: 59.00	
[09/26 08:32:56 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 08:32:56 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              0
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 08:32:56 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-sun397', 'DATA.NUMBER_CLASSES', '397', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 08:32:56 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 08:32:56 visual_prompt]: Training with config:
[09/26 08:32:56 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-sun397/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.1_wd0.001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 0.1, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-sun397', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 397, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 08:32:56 visual_prompt]: Loading training data...
[09/26 08:32:56 visual_prompt]: Constructing vtab-sun397 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split train[:800], from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/26 08:32:58 visual_prompt]: Number of images: 800
[09/26 08:32:58 visual_prompt]: Number of classes: 309 / 397
[09/26 08:32:58 visual_prompt]: Loading validation data...
[09/26 08:32:58 visual_prompt]: Constructing vtab-sun397 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split validation[:200], from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/26 08:32:58 visual_prompt]: Number of images: 200
[09/26 08:32:58 visual_prompt]: Number of classes: 136 / 397
[09/26 08:32:58 visual_prompt]: Constructing models...
[09/26 08:33:01 visual_prompt]: Total Parameters: 86564749	 Gradient Parameters: 766093
[09/26 08:33:01 visual_prompt]: tuned percent:0.885
[09/26 08:33:01 visual_prompt]: Device used for model: 0
[09/26 08:33:01 visual_prompt]: Setting up Evaluator...
[09/26 08:33:01 visual_prompt]: Setting up Trainer...
[09/26 08:33:01 visual_prompt]: 	Setting up the optimizer...
[09/26 08:33:01 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 08:33:08 visual_prompt]: Epoch 1 / 100: avg data time: 6.76e-02, avg batch time: 0.5098, average train loss: 5.9877
[09/26 08:33:09 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1672, average loss: 6.0097
[09/26 08:33:09 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/26 08:33:09 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.010000000000000002
[09/26 08:33:16 visual_prompt]: Epoch 2 / 100: avg data time: 5.90e-02, avg batch time: 0.5014, average train loss: 5.9744
[09/26 08:33:18 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1673, average loss: 5.9872
[09/26 08:33:18 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/26 08:33:18 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.020000000000000004
[09/26 08:33:25 visual_prompt]: Epoch 3 / 100: avg data time: 5.60e-02, avg batch time: 0.4997, average train loss: 5.9246
[09/26 08:33:26 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1672, average loss: 5.9367
[09/26 08:33:26 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.00	
[09/26 08:33:26 visual_prompt]: Best epoch 3: best metric: 0.005
[09/26 08:33:26 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.03
[09/26 08:33:33 visual_prompt]: Epoch 4 / 100: avg data time: 6.55e-02, avg batch time: 0.5072, average train loss: 5.8084
[09/26 08:33:35 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1671, average loss: 5.8580
[09/26 08:33:35 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 08:33:35 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.04000000000000001
[09/26 08:33:42 visual_prompt]: Epoch 5 / 100: avg data time: 6.43e-02, avg batch time: 0.5073, average train loss: 5.6610
[09/26 08:33:43 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1672, average loss: 5.8238
[09/26 08:33:43 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 5.50	
[09/26 08:33:43 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.05
[09/26 08:33:50 visual_prompt]: Epoch 6 / 100: avg data time: 6.67e-02, avg batch time: 0.5085, average train loss: 5.5523
[09/26 08:33:52 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1669, average loss: 5.7256
[09/26 08:33:52 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 7.50	
[09/26 08:33:52 visual_prompt]: Best epoch 6: best metric: 0.010
[09/26 08:33:52 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.06
[09/26 08:33:59 visual_prompt]: Epoch 7 / 100: avg data time: 6.12e-02, avg batch time: 0.5035, average train loss: 5.3841
[09/26 08:34:00 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1670, average loss: 5.6139
[09/26 08:34:00 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.50	top5: 11.00	
[09/26 08:34:00 visual_prompt]: Best epoch 7: best metric: 0.025
[09/26 08:34:00 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.06999999999999999
[09/26 08:34:07 visual_prompt]: Epoch 8 / 100: avg data time: 6.18e-02, avg batch time: 0.5046, average train loss: 5.1537
[09/26 08:34:09 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1672, average loss: 5.4336
[09/26 08:34:09 visual_prompt]: Classification results with val_vtab-sun397: top1: 3.50	top5: 13.00	
[09/26 08:34:09 visual_prompt]: Best epoch 8: best metric: 0.035
[09/26 08:34:09 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.08000000000000002
[09/26 08:34:16 visual_prompt]: Epoch 9 / 100: avg data time: 5.06e-02, avg batch time: 0.4951, average train loss: 4.8322
[09/26 08:34:17 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1671, average loss: 5.3201
[09/26 08:34:17 visual_prompt]: Classification results with val_vtab-sun397: top1: 4.50	top5: 13.00	
[09/26 08:34:17 visual_prompt]: Best epoch 9: best metric: 0.045
[09/26 08:34:17 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.09000000000000001
[09/26 08:34:24 visual_prompt]: Epoch 10 / 100: avg data time: 6.03e-02, avg batch time: 0.5028, average train loss: 4.5070
[09/26 08:34:26 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1671, average loss: 5.0249
[09/26 08:34:26 visual_prompt]: Classification results with val_vtab-sun397: top1: 9.50	top5: 22.00	
[09/26 08:34:26 visual_prompt]: Best epoch 10: best metric: 0.095
[09/26 08:34:26 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.1
[09/26 08:34:33 visual_prompt]: Epoch 11 / 100: avg data time: 6.05e-02, avg batch time: 0.5038, average train loss: 4.1258
[09/26 08:34:34 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1673, average loss: 4.9016
[09/26 08:34:34 visual_prompt]: Classification results with val_vtab-sun397: top1: 12.00	top5: 28.50	
[09/26 08:34:34 visual_prompt]: Best epoch 11: best metric: 0.120
[09/26 08:34:34 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0999695413509548
[09/26 08:34:41 visual_prompt]: Epoch 12 / 100: avg data time: 6.20e-02, avg batch time: 0.5053, average train loss: 3.7054
[09/26 08:34:43 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1674, average loss: 4.7008
[09/26 08:34:43 visual_prompt]: Classification results with val_vtab-sun397: top1: 14.00	top5: 30.00	
[09/26 08:34:43 visual_prompt]: Best epoch 12: best metric: 0.140
[09/26 08:34:43 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.09987820251299122
[09/26 08:34:50 visual_prompt]: Epoch 13 / 100: avg data time: 5.77e-02, avg batch time: 0.5010, average train loss: 3.2733
[09/26 08:34:51 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1675, average loss: 4.4396
[09/26 08:34:51 visual_prompt]: Classification results with val_vtab-sun397: top1: 18.50	top5: 32.50	
[09/26 08:34:51 visual_prompt]: Best epoch 13: best metric: 0.185
[09/26 08:34:51 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.09972609476841367
[09/26 08:34:58 visual_prompt]: Epoch 14 / 100: avg data time: 6.76e-02, avg batch time: 0.5101, average train loss: 2.8384
[09/26 08:35:00 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1675, average loss: 4.4401
[09/26 08:35:00 visual_prompt]: Classification results with val_vtab-sun397: top1: 18.50	top5: 36.00	
[09/26 08:35:00 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.09951340343707853
[09/26 08:35:07 visual_prompt]: Epoch 15 / 100: avg data time: 6.08e-02, avg batch time: 0.5031, average train loss: 2.4511
[09/26 08:35:08 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1673, average loss: 4.2434
[09/26 08:35:08 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.00	top5: 38.00	
[09/26 08:35:08 visual_prompt]: Best epoch 15: best metric: 0.220
[09/26 08:35:08 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.09924038765061041
[09/26 08:35:15 visual_prompt]: Epoch 16 / 100: avg data time: 6.44e-02, avg batch time: 0.5069, average train loss: 2.0902
[09/26 08:35:17 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1673, average loss: 4.1520
[09/26 08:35:17 visual_prompt]: Classification results with val_vtab-sun397: top1: 24.00	top5: 42.50	
[09/26 08:35:17 visual_prompt]: Best epoch 16: best metric: 0.240
[09/26 08:35:17 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.09890738003669029
[09/26 08:35:24 visual_prompt]: Epoch 17 / 100: avg data time: 6.61e-02, avg batch time: 0.5089, average train loss: 1.8145
[09/26 08:35:25 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1674, average loss: 3.9944
[09/26 08:35:25 visual_prompt]: Classification results with val_vtab-sun397: top1: 24.50	top5: 46.50	
[09/26 08:35:25 visual_prompt]: Best epoch 17: best metric: 0.245
[09/26 08:35:25 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.09851478631379983
[09/26 08:35:32 visual_prompt]: Epoch 18 / 100: avg data time: 6.13e-02, avg batch time: 0.5046, average train loss: 1.5409
[09/26 08:35:34 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1672, average loss: 3.9393
[09/26 08:35:34 visual_prompt]: Classification results with val_vtab-sun397: top1: 25.50	top5: 45.50	
[09/26 08:35:34 visual_prompt]: Best epoch 18: best metric: 0.255
[09/26 08:35:34 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.09806308479691594
[09/26 08:35:41 visual_prompt]: Epoch 19 / 100: avg data time: 6.04e-02, avg batch time: 0.5036, average train loss: 1.3268
[09/26 08:35:43 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1673, average loss: 3.9390
[09/26 08:35:43 visual_prompt]: Classification results with val_vtab-sun397: top1: 25.50	top5: 48.50	
[09/26 08:35:43 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.09755282581475769
[09/26 08:35:49 visual_prompt]: Epoch 20 / 100: avg data time: 6.31e-02, avg batch time: 0.5079, average train loss: 1.1427
[09/26 08:35:51 visual_prompt]: Inference (val):avg data time: 3.49e-05, avg batch time: 0.1675, average loss: 3.8791
[09/26 08:35:51 visual_prompt]: Classification results with val_vtab-sun397: top1: 26.00	top5: 48.50	
[09/26 08:35:51 visual_prompt]: Best epoch 20: best metric: 0.260
[09/26 08:35:51 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.09698463103929543
[09/26 08:35:58 visual_prompt]: Epoch 21 / 100: avg data time: 6.16e-02, avg batch time: 0.5042, average train loss: 0.9632
[09/26 08:36:00 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.1675, average loss: 3.9241
[09/26 08:36:00 visual_prompt]: Classification results with val_vtab-sun397: top1: 26.00	top5: 48.00	
[09/26 08:36:00 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.09635919272833937
[09/26 08:36:07 visual_prompt]: Epoch 22 / 100: avg data time: 6.15e-02, avg batch time: 0.5042, average train loss: 0.8001
[09/26 08:36:08 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1675, average loss: 3.8197
[09/26 08:36:08 visual_prompt]: Classification results with val_vtab-sun397: top1: 26.50	top5: 48.00	
[09/26 08:36:08 visual_prompt]: Best epoch 22: best metric: 0.265
[09/26 08:36:08 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.09567727288213004
[09/26 08:36:15 visual_prompt]: Epoch 23 / 100: avg data time: 6.59e-02, avg batch time: 0.5082, average train loss: 0.6950
[09/26 08:36:17 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1675, average loss: 3.8059
[09/26 08:36:17 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 50.50	
[09/26 08:36:17 visual_prompt]: Best epoch 23: best metric: 0.280
[09/26 08:36:17 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.09493970231495835
[09/26 08:36:24 visual_prompt]: Epoch 24 / 100: avg data time: 6.65e-02, avg batch time: 0.5091, average train loss: 0.5925
[09/26 08:36:25 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1676, average loss: 3.8170
[09/26 08:36:25 visual_prompt]: Classification results with val_vtab-sun397: top1: 25.00	top5: 51.00	
[09/26 08:36:25 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.09414737964294635
[09/26 08:36:32 visual_prompt]: Epoch 25 / 100: avg data time: 6.54e-02, avg batch time: 0.5091, average train loss: 0.5182
[09/26 08:36:34 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1674, average loss: 3.7985
[09/26 08:36:34 visual_prompt]: Classification results with val_vtab-sun397: top1: 26.00	top5: 51.00	
[09/26 08:36:34 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.09330127018922195
[09/26 08:36:41 visual_prompt]: Epoch 26 / 100: avg data time: 6.04e-02, avg batch time: 0.5040, average train loss: 0.4571
[09/26 08:36:42 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1679, average loss: 3.7910
[09/26 08:36:42 visual_prompt]: Classification results with val_vtab-sun397: top1: 24.50	top5: 51.50	
[09/26 08:36:42 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.0924024048078213
[09/26 08:36:49 visual_prompt]: Epoch 27 / 100: avg data time: 6.00e-02, avg batch time: 0.5043, average train loss: 0.4072
[09/26 08:36:51 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1678, average loss: 3.7978
[09/26 08:36:51 visual_prompt]: Classification results with val_vtab-sun397: top1: 26.00	top5: 49.00	
[09/26 08:36:51 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.09145187862775209
[09/26 08:36:58 visual_prompt]: Epoch 28 / 100: avg data time: 5.24e-02, avg batch time: 0.4957, average train loss: 0.3634
[09/26 08:36:59 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.1675, average loss: 3.7874
[09/26 08:36:59 visual_prompt]: Classification results with val_vtab-sun397: top1: 25.00	top5: 51.00	
[09/26 08:36:59 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.09045084971874738
[09/26 08:37:06 visual_prompt]: Epoch 29 / 100: avg data time: 6.33e-02, avg batch time: 0.5057, average train loss: 0.3286
[09/26 08:37:08 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1675, average loss: 3.7585
[09/26 08:37:08 visual_prompt]: Classification results with val_vtab-sun397: top1: 26.00	top5: 49.50	
[09/26 08:37:08 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.0894005376803361
[09/26 08:37:15 visual_prompt]: Epoch 30 / 100: avg data time: 6.21e-02, avg batch time: 0.5053, average train loss: 0.3009
[09/26 08:37:17 visual_prompt]: Inference (val):avg data time: 3.52e-05, avg batch time: 0.1678, average loss: 3.7381
[09/26 08:37:17 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 51.00	
[09/26 08:37:17 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.0883022221559489
[09/26 08:37:24 visual_prompt]: Epoch 31 / 100: avg data time: 7.09e-02, avg batch time: 0.5134, average train loss: 0.2785
[09/26 08:37:25 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1690, average loss: 3.7213
[09/26 08:37:25 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.50	top5: 50.00	
[09/26 08:37:25 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.08715724127386971
[09/26 08:37:32 visual_prompt]: Epoch 32 / 100: avg data time: 6.81e-02, avg batch time: 0.5108, average train loss: 0.2538
[09/26 08:37:34 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1676, average loss: 3.7249
[09/26 08:37:34 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.50	top5: 50.50	
[09/26 08:37:34 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.08596699001693256
[09/26 08:37:41 visual_prompt]: Epoch 33 / 100: avg data time: 5.55e-02, avg batch time: 0.4990, average train loss: 0.2397
[09/26 08:37:42 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1677, average loss: 3.7304
[09/26 08:37:42 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 51.50	
[09/26 08:37:42 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.08473291852294987
[09/26 08:37:49 visual_prompt]: Epoch 34 / 100: avg data time: 6.27e-02, avg batch time: 0.5065, average train loss: 0.2278
[09/26 08:37:51 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1672, average loss: 3.7235
[09/26 08:37:51 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 51.00	
[09/26 08:37:51 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.08345653031794292
[09/26 08:37:58 visual_prompt]: Epoch 35 / 100: avg data time: 6.27e-02, avg batch time: 0.5048, average train loss: 0.2166
[09/26 08:37:59 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1674, average loss: 3.7319
[09/26 08:38:00 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.50	top5: 49.00	
[09/26 08:38:00 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.08213938048432697
[09/26 08:38:06 visual_prompt]: Epoch 36 / 100: avg data time: 4.89e-02, avg batch time: 0.4931, average train loss: 0.2008
[09/26 08:38:08 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1674, average loss: 3.7451
[09/26 08:38:08 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.50	top5: 50.50	
[09/26 08:38:08 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.08078307376628291
[09/26 08:38:15 visual_prompt]: Epoch 37 / 100: avg data time: 6.44e-02, avg batch time: 0.5069, average train loss: 0.1955
[09/26 08:38:16 visual_prompt]: Inference (val):avg data time: 4.57e-05, avg batch time: 0.1675, average loss: 3.7363
[09/26 08:38:16 visual_prompt]: Classification results with val_vtab-sun397: top1: 29.00	top5: 48.00	
[09/26 08:38:16 visual_prompt]: Best epoch 37: best metric: 0.290
[09/26 08:38:16 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.07938926261462366
[09/26 08:38:23 visual_prompt]: Epoch 38 / 100: avg data time: 5.91e-02, avg batch time: 0.5018, average train loss: 0.1886
[09/26 08:38:25 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1673, average loss: 3.7289
[09/26 08:38:25 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.00	top5: 49.00	
[09/26 08:38:25 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.07795964517353735
[09/26 08:38:32 visual_prompt]: Epoch 39 / 100: avg data time: 5.60e-02, avg batch time: 0.4991, average train loss: 0.1813
[09/26 08:38:33 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1674, average loss: 3.7075
[09/26 08:38:33 visual_prompt]: Classification results with val_vtab-sun397: top1: 29.50	top5: 50.50	
[09/26 08:38:33 visual_prompt]: Best epoch 39: best metric: 0.295
[09/26 08:38:33 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.07649596321166025
[09/26 08:38:40 visual_prompt]: Epoch 40 / 100: avg data time: 6.68e-02, avg batch time: 0.5101, average train loss: 0.1765
[09/26 08:38:42 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1674, average loss: 3.7206
[09/26 08:38:42 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 51.50	
[09/26 08:38:42 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.07500000000000001
[09/26 08:38:49 visual_prompt]: Epoch 41 / 100: avg data time: 6.63e-02, avg batch time: 0.5088, average train loss: 0.1701
[09/26 08:38:51 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1676, average loss: 3.7220
[09/26 08:38:51 visual_prompt]: Classification results with val_vtab-sun397: top1: 29.50	top5: 51.50	
[09/26 08:38:51 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.07347357813929455
[09/26 08:38:58 visual_prompt]: Epoch 42 / 100: avg data time: 6.40e-02, avg batch time: 0.5069, average train loss: 0.1677
[09/26 08:38:59 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1672, average loss: 3.7270
[09/26 08:38:59 visual_prompt]: Classification results with val_vtab-sun397: top1: 29.50	top5: 49.00	
[09/26 08:38:59 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.07191855733945388
[09/26 08:39:06 visual_prompt]: Epoch 43 / 100: avg data time: 5.68e-02, avg batch time: 0.5004, average train loss: 0.1619
[09/26 08:39:08 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1671, average loss: 3.7089
[09/26 08:39:08 visual_prompt]: Classification results with val_vtab-sun397: top1: 29.50	top5: 51.00	
[09/26 08:39:08 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.07033683215379002
[09/26 08:39:15 visual_prompt]: Epoch 44 / 100: avg data time: 6.50e-02, avg batch time: 0.5113, average train loss: 0.1595
[09/26 08:39:16 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1670, average loss: 3.7417
[09/26 08:39:16 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 50.00	
[09/26 08:39:16 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.0687303296707956
[09/26 08:39:23 visual_prompt]: Epoch 45 / 100: avg data time: 6.51e-02, avg batch time: 0.5077, average train loss: 0.1573
[09/26 08:39:25 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1671, average loss: 3.7255
[09/26 08:39:25 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.50	top5: 51.00	
[09/26 08:39:25 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.06710100716628345
[09/26 08:39:32 visual_prompt]: Epoch 46 / 100: avg data time: 6.13e-02, avg batch time: 0.5037, average train loss: 0.1538
[09/26 08:39:33 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1674, average loss: 3.7126
[09/26 08:39:33 visual_prompt]: Classification results with val_vtab-sun397: top1: 30.50	top5: 53.50	
[09/26 08:39:33 visual_prompt]: Best epoch 46: best metric: 0.305
[09/26 08:39:33 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.06545084971874737
[09/26 08:39:40 visual_prompt]: Epoch 47 / 100: avg data time: 6.15e-02, avg batch time: 0.5046, average train loss: 0.1509
[09/26 08:39:42 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1671, average loss: 3.7464
[09/26 08:39:42 visual_prompt]: Classification results with val_vtab-sun397: top1: 29.00	top5: 51.00	
[09/26 08:39:42 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.06378186779084996
[09/26 08:39:49 visual_prompt]: Epoch 48 / 100: avg data time: 5.94e-02, avg batch time: 0.5015, average train loss: 0.1496
[09/26 08:39:50 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1673, average loss: 3.7310
[09/26 08:39:50 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 50.00	
[09/26 08:39:50 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.06209609477998338
[09/26 08:39:57 visual_prompt]: Epoch 49 / 100: avg data time: 4.95e-02, avg batch time: 0.4942, average train loss: 0.1479
[09/26 08:39:59 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1670, average loss: 3.7390
[09/26 08:39:59 visual_prompt]: Classification results with val_vtab-sun397: top1: 30.00	top5: 50.00	
[09/26 08:39:59 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.06039558454088796
[09/26 08:40:06 visual_prompt]: Epoch 50 / 100: avg data time: 5.99e-02, avg batch time: 0.5031, average train loss: 0.1448
[09/26 08:40:07 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1673, average loss: 3.7188
[09/26 08:40:07 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.50	top5: 50.50	
[09/26 08:40:07 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.058682408883346526
[09/26 08:40:14 visual_prompt]: Epoch 51 / 100: avg data time: 6.13e-02, avg batch time: 0.5039, average train loss: 0.1421
[09/26 08:40:16 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1673, average loss: 3.7217
[09/26 08:40:16 visual_prompt]: Classification results with val_vtab-sun397: top1: 29.00	top5: 51.50	
[09/26 08:40:16 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.05695865504800327
[09/26 08:40:23 visual_prompt]: Epoch 52 / 100: avg data time: 5.99e-02, avg batch time: 0.5037, average train loss: 0.1399
[09/26 08:40:24 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1673, average loss: 3.7366
[09/26 08:40:24 visual_prompt]: Classification results with val_vtab-sun397: top1: 29.50	top5: 50.00	
[09/26 08:40:24 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.05522642316338268
[09/26 08:40:31 visual_prompt]: Epoch 53 / 100: avg data time: 6.12e-02, avg batch time: 0.5031, average train loss: 0.1402
[09/26 08:40:33 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1673, average loss: 3.7285
[09/26 08:40:33 visual_prompt]: Classification results with val_vtab-sun397: top1: 30.00	top5: 52.50	
[09/26 08:40:33 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.05348782368720626
[09/26 08:40:40 visual_prompt]: Epoch 54 / 100: avg data time: 6.42e-02, avg batch time: 0.5076, average train loss: 0.1389
[09/26 08:40:41 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1675, average loss: 3.7223
[09/26 08:40:41 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.50	top5: 50.50	
[09/26 08:40:41 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.05174497483512506
[09/26 08:40:48 visual_prompt]: Epoch 55 / 100: avg data time: 5.68e-02, avg batch time: 0.4992, average train loss: 0.1386
[09/26 08:40:50 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1672, average loss: 3.7498
[09/26 08:40:50 visual_prompt]: Classification results with val_vtab-sun397: top1: 29.00	top5: 51.50	
[09/26 08:40:50 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.05
[09/26 08:40:57 visual_prompt]: Epoch 56 / 100: avg data time: 5.58e-02, avg batch time: 0.4992, average train loss: 0.1366
[09/26 08:40:58 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1671, average loss: 3.7314
[09/26 08:40:58 visual_prompt]: Classification results with val_vtab-sun397: top1: 30.00	top5: 51.50	
[09/26 08:40:58 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.04825502516487497
[09/26 08:41:05 visual_prompt]: Epoch 57 / 100: avg data time: 6.28e-02, avg batch time: 0.5053, average train loss: 0.1357
[09/26 08:41:07 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1674, average loss: 3.7410
[09/26 08:41:07 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 50.00	
[09/26 08:41:07 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.04651217631279374
[09/26 08:41:14 visual_prompt]: Epoch 58 / 100: avg data time: 5.78e-02, avg batch time: 0.5013, average train loss: 0.1332
[09/26 08:41:15 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1676, average loss: 3.7558
[09/26 08:41:15 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.50	top5: 51.00	
[09/26 08:41:15 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.04477357683661734
[09/26 08:41:22 visual_prompt]: Epoch 59 / 100: avg data time: 5.10e-02, avg batch time: 0.4932, average train loss: 0.1328
[09/26 08:41:24 visual_prompt]: Inference (val):avg data time: 4.11e-05, avg batch time: 0.1672, average loss: 3.7452
[09/26 08:41:24 visual_prompt]: Classification results with val_vtab-sun397: top1: 29.00	top5: 52.00	
[09/26 08:41:24 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.04304134495199674
[09/26 08:41:31 visual_prompt]: Epoch 60 / 100: avg data time: 6.51e-02, avg batch time: 0.5070, average train loss: 0.1335
[09/26 08:41:32 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1672, average loss: 3.7403
[09/26 08:41:32 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.00	top5: 51.00	
[09/26 08:41:32 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.041317591116653486
[09/26 08:41:39 visual_prompt]: Epoch 61 / 100: avg data time: 6.27e-02, avg batch time: 0.5061, average train loss: 0.1318
[09/26 08:41:41 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1674, average loss: 3.7598
[09/26 08:41:41 visual_prompt]: Classification results with val_vtab-sun397: top1: 26.00	top5: 51.00	
[09/26 08:41:41 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.039604415459112044
[09/26 08:41:48 visual_prompt]: Epoch 62 / 100: avg data time: 5.59e-02, avg batch time: 0.4997, average train loss: 0.1310
[09/26 08:41:49 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1673, average loss: 3.7362
[09/26 08:41:49 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.00	top5: 50.50	
[09/26 08:41:49 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.037903905220016625
[09/26 08:41:56 visual_prompt]: Epoch 63 / 100: avg data time: 5.87e-02, avg batch time: 0.5008, average train loss: 0.1285
[09/26 08:41:58 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1674, average loss: 3.7572
[09/26 08:41:58 visual_prompt]: Classification results with val_vtab-sun397: top1: 26.50	top5: 50.50	
[09/26 08:41:58 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.036218132209150045
[09/26 08:42:05 visual_prompt]: Epoch 64 / 100: avg data time: 6.27e-02, avg batch time: 0.5053, average train loss: 0.1291
[09/26 08:42:06 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1673, average loss: 3.7516
[09/26 08:42:06 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 50.00	
[09/26 08:42:06 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.03454915028125263
[09/26 08:42:13 visual_prompt]: Epoch 65 / 100: avg data time: 5.95e-02, avg batch time: 0.5025, average train loss: 0.1299
[09/26 08:42:15 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1672, average loss: 3.7433
[09/26 08:42:15 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 49.00	
[09/26 08:42:15 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.03289899283371657
[09/26 08:42:22 visual_prompt]: Epoch 66 / 100: avg data time: 6.02e-02, avg batch time: 0.5025, average train loss: 0.1297
[09/26 08:42:23 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1672, average loss: 3.7446
[09/26 08:42:23 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.50	top5: 52.00	
[09/26 08:42:23 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.0312696703292044
[09/26 08:42:30 visual_prompt]: Epoch 67 / 100: avg data time: 6.40e-02, avg batch time: 0.5071, average train loss: 0.1276
[09/26 08:42:32 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1670, average loss: 3.7457
[09/26 08:42:32 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.50	top5: 51.00	
[09/26 08:42:32 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.02966316784621
[09/26 08:42:39 visual_prompt]: Epoch 68 / 100: avg data time: 6.11e-02, avg batch time: 0.5036, average train loss: 0.1260
[09/26 08:42:40 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1671, average loss: 3.7354
[09/26 08:42:40 visual_prompt]: Classification results with val_vtab-sun397: top1: 26.50	top5: 51.50	
[09/26 08:42:40 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.028081442660546126
[09/26 08:42:47 visual_prompt]: Epoch 69 / 100: avg data time: 5.88e-02, avg batch time: 0.5016, average train loss: 0.1270
[09/26 08:42:49 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1671, average loss: 3.7489
[09/26 08:42:49 visual_prompt]: Classification results with val_vtab-sun397: top1: 26.00	top5: 49.00	
[09/26 08:42:49 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.026526421860705474
[09/26 08:42:56 visual_prompt]: Epoch 70 / 100: avg data time: 5.05e-02, avg batch time: 0.4933, average train loss: 0.1263
[09/26 08:42:57 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1671, average loss: 3.7357
[09/26 08:42:57 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.00	top5: 50.00	
[09/26 08:42:57 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.025000000000000012
[09/26 08:43:04 visual_prompt]: Epoch 71 / 100: avg data time: 6.27e-02, avg batch time: 0.5045, average train loss: 0.1256
[09/26 08:43:06 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1670, average loss: 3.7391
[09/26 08:43:06 visual_prompt]: Classification results with val_vtab-sun397: top1: 25.50	top5: 50.50	
[09/26 08:43:06 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.02350403678833976
[09/26 08:43:13 visual_prompt]: Epoch 72 / 100: avg data time: 4.92e-02, avg batch time: 0.4913, average train loss: 0.1248
[09/26 08:43:14 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1674, average loss: 3.7417
[09/26 08:43:14 visual_prompt]: Classification results with val_vtab-sun397: top1: 25.50	top5: 51.00	
[09/26 08:43:14 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.022040354826462667
[09/26 08:43:21 visual_prompt]: Epoch 73 / 100: avg data time: 6.19e-02, avg batch time: 0.5048, average train loss: 0.1253
[09/26 08:43:23 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1671, average loss: 3.7290
[09/26 08:43:23 visual_prompt]: Classification results with val_vtab-sun397: top1: 26.00	top5: 52.50	
[09/26 08:43:23 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.02061073738537635
[09/26 08:43:30 visual_prompt]: Epoch 74 / 100: avg data time: 6.43e-02, avg batch time: 0.5064, average train loss: 0.1248
[09/26 08:43:31 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1675, average loss: 3.7342
[09/26 08:43:31 visual_prompt]: Classification results with val_vtab-sun397: top1: 26.50	top5: 49.50	
[09/26 08:43:31 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.019216926233717086
[09/26 08:43:38 visual_prompt]: Epoch 75 / 100: avg data time: 6.41e-02, avg batch time: 0.5072, average train loss: 0.1248
[09/26 08:43:40 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1674, average loss: 3.7406
[09/26 08:43:40 visual_prompt]: Classification results with val_vtab-sun397: top1: 26.00	top5: 50.50	
[09/26 08:43:40 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.017860619515673033
[09/26 08:43:47 visual_prompt]: Epoch 76 / 100: avg data time: 6.60e-02, avg batch time: 0.5087, average train loss: 0.1238
[09/26 08:43:49 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1671, average loss: 3.7324
[09/26 08:43:49 visual_prompt]: Classification results with val_vtab-sun397: top1: 25.50	top5: 48.50	
[09/26 08:43:49 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.016543469682057107
[09/26 08:43:55 visual_prompt]: Epoch 77 / 100: avg data time: 4.91e-02, avg batch time: 0.4929, average train loss: 0.1229
[09/26 08:43:57 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1672, average loss: 3.7306
[09/26 08:43:57 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 49.50	
[09/26 08:43:57 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.015267081477050132
[09/26 08:44:04 visual_prompt]: Epoch 78 / 100: avg data time: 5.68e-02, avg batch time: 0.5002, average train loss: 0.1222
[09/26 08:44:05 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1676, average loss: 3.7382
[09/26 08:44:05 visual_prompt]: Classification results with val_vtab-sun397: top1: 29.00	top5: 49.50	
[09/26 08:44:05 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.014033009983067453
[09/26 08:44:12 visual_prompt]: Epoch 79 / 100: avg data time: 5.79e-02, avg batch time: 0.5014, average train loss: 0.1225
[09/26 08:44:14 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1674, average loss: 3.7401
[09/26 08:44:14 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 50.00	
[09/26 08:44:14 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.012842758726130284
[09/26 08:44:21 visual_prompt]: Epoch 80 / 100: avg data time: 6.13e-02, avg batch time: 0.5033, average train loss: 0.1230
[09/26 08:44:22 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1679, average loss: 3.7429
[09/26 08:44:22 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.50	top5: 50.50	
[09/26 08:44:22 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.011697777844051106
[09/26 08:44:29 visual_prompt]: Epoch 81 / 100: avg data time: 6.06e-02, avg batch time: 0.5030, average train loss: 0.1223
[09/26 08:44:31 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1675, average loss: 3.7371
[09/26 08:44:31 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.50	top5: 51.00	
[09/26 08:44:31 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.010599462319663905
[09/26 08:44:38 visual_prompt]: Epoch 82 / 100: avg data time: 6.40e-02, avg batch time: 0.5063, average train loss: 0.1218
[09/26 08:44:40 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1673, average loss: 3.7383
[09/26 08:44:40 visual_prompt]: Classification results with val_vtab-sun397: top1: 26.50	top5: 51.00	
[09/26 08:44:40 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.009549150281252633
[09/26 08:44:46 visual_prompt]: Epoch 83 / 100: avg data time: 6.49e-02, avg batch time: 0.5076, average train loss: 0.1217
[09/26 08:44:48 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1678, average loss: 3.7381
[09/26 08:44:48 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.50	top5: 50.50	
[09/26 08:44:48 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.008548121372247919
[09/26 08:44:55 visual_prompt]: Epoch 84 / 100: avg data time: 6.73e-02, avg batch time: 0.5102, average train loss: 0.1217
[09/26 08:44:57 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1676, average loss: 3.7371
[09/26 08:44:57 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.00	top5: 52.00	
[09/26 08:44:57 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.007597595192178702
[09/26 08:45:04 visual_prompt]: Epoch 85 / 100: avg data time: 6.67e-02, avg batch time: 0.5096, average train loss: 0.1223
[09/26 08:45:05 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1679, average loss: 3.7407
[09/26 08:45:05 visual_prompt]: Classification results with val_vtab-sun397: top1: 26.50	top5: 51.50	
[09/26 08:45:05 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.006698729810778065
[09/26 08:45:12 visual_prompt]: Epoch 86 / 100: avg data time: 5.52e-02, avg batch time: 0.4978, average train loss: 0.1217
[09/26 08:45:14 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1673, average loss: 3.7373
[09/26 08:45:14 visual_prompt]: Classification results with val_vtab-sun397: top1: 26.00	top5: 51.00	
[09/26 08:45:14 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.005852620357053651
[09/26 08:45:21 visual_prompt]: Epoch 87 / 100: avg data time: 5.54e-02, avg batch time: 0.4987, average train loss: 0.1208
[09/26 08:45:22 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1674, average loss: 3.7384
[09/26 08:45:22 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.00	top5: 51.50	
[09/26 08:45:22 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.00506029768504166
[09/26 08:45:29 visual_prompt]: Epoch 88 / 100: avg data time: 5.84e-02, avg batch time: 0.5009, average train loss: 0.1208
[09/26 08:45:31 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1674, average loss: 3.7366
[09/26 08:45:31 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.00	top5: 51.50	
[09/26 08:45:31 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.004322727117869951
[09/26 08:45:38 visual_prompt]: Epoch 89 / 100: avg data time: 6.40e-02, avg batch time: 0.5080, average train loss: 0.1210
[09/26 08:45:40 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1676, average loss: 3.7410
[09/26 08:45:40 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.00	top5: 52.50	
[09/26 08:45:40 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.0036408072716606343
[09/26 08:45:46 visual_prompt]: Epoch 90 / 100: avg data time: 6.25e-02, avg batch time: 0.5065, average train loss: 0.1202
[09/26 08:45:48 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.1675, average loss: 3.7405
[09/26 08:45:48 visual_prompt]: Classification results with val_vtab-sun397: top1: 26.50	top5: 52.00	
[09/26 08:45:48 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.0030153689607045845
[09/26 08:45:55 visual_prompt]: Epoch 91 / 100: avg data time: 6.52e-02, avg batch time: 0.5085, average train loss: 0.1211
[09/26 08:45:57 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1673, average loss: 3.7363
[09/26 08:45:57 visual_prompt]: Classification results with val_vtab-sun397: top1: 26.00	top5: 52.00	
[09/26 08:45:57 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.0024471741852423235
[09/26 08:46:04 visual_prompt]: Epoch 92 / 100: avg data time: 6.00e-02, avg batch time: 0.5041, average train loss: 0.1215
[09/26 08:46:05 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1672, average loss: 3.7340
[09/26 08:46:05 visual_prompt]: Classification results with val_vtab-sun397: top1: 26.50	top5: 51.00	
[09/26 08:46:05 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.0019369152030840554
[09/26 08:46:12 visual_prompt]: Epoch 93 / 100: avg data time: 6.23e-02, avg batch time: 0.5052, average train loss: 0.1206
[09/26 08:46:14 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1676, average loss: 3.7348
[09/26 08:46:14 visual_prompt]: Classification results with val_vtab-sun397: top1: 26.50	top5: 51.00	
[09/26 08:46:14 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.0014852136862001765
[09/26 08:46:21 visual_prompt]: Epoch 94 / 100: avg data time: 6.14e-02, avg batch time: 0.5051, average train loss: 0.1204
[09/26 08:46:22 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1676, average loss: 3.7357
[09/26 08:46:22 visual_prompt]: Classification results with val_vtab-sun397: top1: 26.50	top5: 51.50	
[09/26 08:46:22 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.0010926199633097156
[09/26 08:46:29 visual_prompt]: Epoch 95 / 100: avg data time: 5.98e-02, avg batch time: 0.5039, average train loss: 0.1203
[09/26 08:46:31 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1677, average loss: 3.7353
[09/26 08:46:31 visual_prompt]: Classification results with val_vtab-sun397: top1: 26.50	top5: 51.50	
[09/26 08:46:31 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.0007596123493895991
[09/26 08:46:38 visual_prompt]: Epoch 96 / 100: avg data time: 6.09e-02, avg batch time: 0.5039, average train loss: 0.1207
[09/26 08:46:39 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1675, average loss: 3.7357
[09/26 08:46:39 visual_prompt]: Classification results with val_vtab-sun397: top1: 26.50	top5: 51.50	
[09/26 08:46:39 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.00048659656292148194
[09/26 08:46:46 visual_prompt]: Epoch 97 / 100: avg data time: 5.92e-02, avg batch time: 0.5020, average train loss: 0.1207
[09/26 08:46:48 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1675, average loss: 3.7360
[09/26 08:46:48 visual_prompt]: Classification results with val_vtab-sun397: top1: 26.50	top5: 51.50	
[09/26 08:46:48 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.0002739052315863355
[09/26 08:46:55 visual_prompt]: Epoch 98 / 100: avg data time: 6.12e-02, avg batch time: 0.5040, average train loss: 0.1212
[09/26 08:46:56 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1674, average loss: 3.7362
[09/26 08:46:56 visual_prompt]: Classification results with val_vtab-sun397: top1: 26.50	top5: 51.50	
[09/26 08:46:56 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.00012179748700879012
[09/26 08:47:03 visual_prompt]: Epoch 99 / 100: avg data time: 5.93e-02, avg batch time: 0.5019, average train loss: 0.1212
[09/26 08:47:05 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1674, average loss: 3.7361
[09/26 08:47:05 visual_prompt]: Classification results with val_vtab-sun397: top1: 26.50	top5: 51.50	
[09/26 08:47:05 visual_prompt]: Training 100 / 100 epoch, with learning rate 3.0458649045211895e-05
[09/26 08:47:12 visual_prompt]: Epoch 100 / 100: avg data time: 5.91e-02, avg batch time: 0.5026, average train loss: 0.1223
[09/26 08:47:14 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1671, average loss: 3.7361
[09/26 08:47:14 visual_prompt]: Classification results with val_vtab-sun397: top1: 26.50	top5: 51.50	
[09/26 08:47:14 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 08:47:14 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              0
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 08:47:14 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-sun397', 'DATA.NUMBER_CLASSES', '397', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 08:47:14 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 08:47:14 visual_prompt]: Training with config:
[09/26 08:47:14 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-sun397/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.1_wd0.0001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 0.1, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-sun397', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 397, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 08:47:14 visual_prompt]: Loading training data...
[09/26 08:47:14 visual_prompt]: Constructing vtab-sun397 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split train[:800], from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/26 08:47:15 visual_prompt]: Number of images: 800
[09/26 08:47:15 visual_prompt]: Number of classes: 309 / 397
[09/26 08:47:15 visual_prompt]: Loading validation data...
[09/26 08:47:15 visual_prompt]: Constructing vtab-sun397 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split validation[:200], from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/26 08:47:15 visual_prompt]: Number of images: 200
[09/26 08:47:15 visual_prompt]: Number of classes: 136 / 397
[09/26 08:47:15 visual_prompt]: Constructing models...
[09/26 08:47:18 visual_prompt]: Total Parameters: 86564749	 Gradient Parameters: 766093
[09/26 08:47:18 visual_prompt]: tuned percent:0.885
[09/26 08:47:18 visual_prompt]: Device used for model: 0
[09/26 08:47:18 visual_prompt]: Setting up Evaluator...
[09/26 08:47:18 visual_prompt]: Setting up Trainer...
[09/26 08:47:18 visual_prompt]: 	Setting up the optimizer...
[09/26 08:47:18 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 08:47:25 visual_prompt]: Epoch 1 / 100: avg data time: 5.99e-02, avg batch time: 0.5031, average train loss: 5.9888
[09/26 08:47:26 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1665, average loss: 6.0097
[09/26 08:47:26 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/26 08:47:26 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.010000000000000002
[09/26 08:47:33 visual_prompt]: Epoch 2 / 100: avg data time: 6.55e-02, avg batch time: 0.5074, average train loss: 5.9751
[09/26 08:47:35 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1666, average loss: 5.9849
[09/26 08:47:35 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/26 08:47:35 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.020000000000000004
[09/26 08:47:42 visual_prompt]: Epoch 3 / 100: avg data time: 6.72e-02, avg batch time: 0.5102, average train loss: 5.9282
[09/26 08:47:44 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1677, average loss: 5.9444
[09/26 08:47:44 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.00	
[09/26 08:47:44 visual_prompt]: Best epoch 3: best metric: 0.005
[09/26 08:47:44 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.03
[09/26 08:47:51 visual_prompt]: Epoch 4 / 100: avg data time: 6.52e-02, avg batch time: 0.5073, average train loss: 5.8231
[09/26 08:47:52 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1666, average loss: 5.8663
[09/26 08:47:52 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 08:47:52 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.04000000000000001
[09/26 08:47:59 visual_prompt]: Epoch 5 / 100: avg data time: 6.19e-02, avg batch time: 0.5041, average train loss: 5.6682
[09/26 08:48:01 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1673, average loss: 5.8562
[09/26 08:48:01 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 5.50	
[09/26 08:48:01 visual_prompt]: Best epoch 5: best metric: 0.010
[09/26 08:48:01 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.05
[09/26 08:48:08 visual_prompt]: Epoch 6 / 100: avg data time: 6.52e-02, avg batch time: 0.5084, average train loss: 5.5234
[09/26 08:48:09 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1668, average loss: 5.7083
[09/26 08:48:09 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 6.00	
[09/26 08:48:09 visual_prompt]: Best epoch 6: best metric: 0.015
[09/26 08:48:09 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.06
[09/26 08:48:16 visual_prompt]: Epoch 7 / 100: avg data time: 5.16e-02, avg batch time: 0.4949, average train loss: 5.3156
[09/26 08:48:18 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1676, average loss: 5.5519
[09/26 08:48:18 visual_prompt]: Classification results with val_vtab-sun397: top1: 4.50	top5: 10.00	
[09/26 08:48:18 visual_prompt]: Best epoch 7: best metric: 0.045
[09/26 08:48:18 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.06999999999999999
[09/26 08:48:25 visual_prompt]: Epoch 8 / 100: avg data time: 7.00e-02, avg batch time: 0.5120, average train loss: 5.1071
[09/26 08:48:26 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1675, average loss: 5.3964
[09/26 08:48:26 visual_prompt]: Classification results with val_vtab-sun397: top1: 4.00	top5: 15.00	
[09/26 08:48:27 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.08000000000000002
[09/26 08:48:33 visual_prompt]: Epoch 9 / 100: avg data time: 6.88e-02, avg batch time: 0.5120, average train loss: 4.7967
[09/26 08:48:35 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1674, average loss: 5.1755
[09/26 08:48:35 visual_prompt]: Classification results with val_vtab-sun397: top1: 8.50	top5: 19.50	
[09/26 08:48:35 visual_prompt]: Best epoch 9: best metric: 0.085
[09/26 08:48:35 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.09000000000000001
[09/26 08:48:42 visual_prompt]: Epoch 10 / 100: avg data time: 4.99e-02, avg batch time: 0.4952, average train loss: 4.4081
[09/26 08:48:44 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1675, average loss: 4.9807
[09/26 08:48:44 visual_prompt]: Classification results with val_vtab-sun397: top1: 8.00	top5: 24.00	
[09/26 08:48:44 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.1
[09/26 08:48:50 visual_prompt]: Epoch 11 / 100: avg data time: 5.78e-02, avg batch time: 0.5001, average train loss: 3.9824
[09/26 08:48:52 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1674, average loss: 4.7971
[09/26 08:48:52 visual_prompt]: Classification results with val_vtab-sun397: top1: 12.00	top5: 29.50	
[09/26 08:48:52 visual_prompt]: Best epoch 11: best metric: 0.120
[09/26 08:48:52 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0999695413509548
[09/26 08:48:59 visual_prompt]: Epoch 12 / 100: avg data time: 6.30e-02, avg batch time: 0.5063, average train loss: 3.5881
[09/26 08:49:01 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1673, average loss: 4.6078
[09/26 08:49:01 visual_prompt]: Classification results with val_vtab-sun397: top1: 13.00	top5: 35.50	
[09/26 08:49:01 visual_prompt]: Best epoch 12: best metric: 0.130
[09/26 08:49:01 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.09987820251299122
[09/26 08:49:08 visual_prompt]: Epoch 13 / 100: avg data time: 6.03e-02, avg batch time: 0.5033, average train loss: 3.1667
[09/26 08:49:09 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1674, average loss: 4.4356
[09/26 08:49:09 visual_prompt]: Classification results with val_vtab-sun397: top1: 17.50	top5: 36.50	
[09/26 08:49:09 visual_prompt]: Best epoch 13: best metric: 0.175
[09/26 08:49:09 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.09972609476841367
[09/26 08:49:16 visual_prompt]: Epoch 14 / 100: avg data time: 6.21e-02, avg batch time: 0.5060, average train loss: 2.7691
[09/26 08:49:18 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1672, average loss: 4.2545
[09/26 08:49:18 visual_prompt]: Classification results with val_vtab-sun397: top1: 19.50	top5: 40.00	
[09/26 08:49:18 visual_prompt]: Best epoch 14: best metric: 0.195
[09/26 08:49:18 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.09951340343707853
[09/26 08:49:25 visual_prompt]: Epoch 15 / 100: avg data time: 6.47e-02, avg batch time: 0.5083, average train loss: 2.3885
[09/26 08:49:26 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1674, average loss: 4.1886
[09/26 08:49:26 visual_prompt]: Classification results with val_vtab-sun397: top1: 19.50	top5: 42.50	
[09/26 08:49:26 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.09924038765061041
[09/26 08:49:33 visual_prompt]: Epoch 16 / 100: avg data time: 6.16e-02, avg batch time: 0.5045, average train loss: 2.0388
[09/26 08:49:35 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1674, average loss: 4.0597
[09/26 08:49:35 visual_prompt]: Classification results with val_vtab-sun397: top1: 20.50	top5: 46.50	
[09/26 08:49:35 visual_prompt]: Best epoch 16: best metric: 0.205
[09/26 08:49:35 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.09890738003669029
[09/26 08:49:42 visual_prompt]: Epoch 17 / 100: avg data time: 6.64e-02, avg batch time: 0.5094, average train loss: 1.7122
[09/26 08:49:44 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1673, average loss: 4.0512
[09/26 08:49:44 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.50	top5: 45.50	
[09/26 08:49:44 visual_prompt]: Best epoch 17: best metric: 0.225
[09/26 08:49:44 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.09851478631379983
[09/26 08:49:51 visual_prompt]: Epoch 18 / 100: avg data time: 6.31e-02, avg batch time: 0.5069, average train loss: 1.4179
[09/26 08:49:52 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1674, average loss: 3.9492
[09/26 08:49:52 visual_prompt]: Classification results with val_vtab-sun397: top1: 24.00	top5: 47.00	
[09/26 08:49:52 visual_prompt]: Best epoch 18: best metric: 0.240
[09/26 08:49:52 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.09806308479691594
[09/26 08:49:59 visual_prompt]: Epoch 19 / 100: avg data time: 6.45e-02, avg batch time: 0.5073, average train loss: 1.1965
[09/26 08:50:01 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1674, average loss: 3.9022
[09/26 08:50:01 visual_prompt]: Classification results with val_vtab-sun397: top1: 23.50	top5: 47.50	
[09/26 08:50:01 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.09755282581475769
[09/26 08:50:08 visual_prompt]: Epoch 20 / 100: avg data time: 5.73e-02, avg batch time: 0.5017, average train loss: 1.0158
[09/26 08:50:09 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1676, average loss: 3.9279
[09/26 08:50:09 visual_prompt]: Classification results with val_vtab-sun397: top1: 25.00	top5: 47.50	
[09/26 08:50:09 visual_prompt]: Best epoch 20: best metric: 0.250
[09/26 08:50:09 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.09698463103929543
[09/26 08:50:16 visual_prompt]: Epoch 21 / 100: avg data time: 5.42e-02, avg batch time: 0.4981, average train loss: 0.8336
[09/26 08:50:18 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1675, average loss: 3.8932
[09/26 08:50:18 visual_prompt]: Classification results with val_vtab-sun397: top1: 25.50	top5: 47.00	
[09/26 08:50:18 visual_prompt]: Best epoch 21: best metric: 0.255
[09/26 08:50:18 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.09635919272833937
[09/26 08:50:25 visual_prompt]: Epoch 22 / 100: avg data time: 6.16e-02, avg batch time: 0.5048, average train loss: 0.6931
[09/26 08:50:26 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1675, average loss: 3.8581
[09/26 08:50:26 visual_prompt]: Classification results with val_vtab-sun397: top1: 25.50	top5: 48.50	
[09/26 08:50:26 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.09567727288213004
[09/26 08:50:33 visual_prompt]: Epoch 23 / 100: avg data time: 5.75e-02, avg batch time: 0.5005, average train loss: 0.5743
[09/26 08:50:35 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1676, average loss: 3.8723
[09/26 08:50:35 visual_prompt]: Classification results with val_vtab-sun397: top1: 26.50	top5: 48.00	
[09/26 08:50:35 visual_prompt]: Best epoch 23: best metric: 0.265
[09/26 08:50:35 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.09493970231495835
[09/26 08:50:41 visual_prompt]: Epoch 24 / 100: avg data time: 5.26e-02, avg batch time: 0.4968, average train loss: 0.4758
[09/26 08:50:43 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1674, average loss: 3.8047
[09/26 08:50:43 visual_prompt]: Classification results with val_vtab-sun397: top1: 25.50	top5: 48.00	
[09/26 08:50:43 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.09414737964294635
[09/26 08:50:50 visual_prompt]: Epoch 25 / 100: avg data time: 6.27e-02, avg batch time: 0.5059, average train loss: 0.4028
[09/26 08:50:52 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1676, average loss: 3.8370
[09/26 08:50:52 visual_prompt]: Classification results with val_vtab-sun397: top1: 25.00	top5: 48.50	
[09/26 08:50:52 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.09330127018922195
[09/26 08:50:59 visual_prompt]: Epoch 26 / 100: avg data time: 6.33e-02, avg batch time: 0.5060, average train loss: 0.3507
[09/26 08:51:00 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1678, average loss: 3.8118
[09/26 08:51:00 visual_prompt]: Classification results with val_vtab-sun397: top1: 25.00	top5: 48.00	
[09/26 08:51:00 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.0924024048078213
[09/26 08:51:07 visual_prompt]: Epoch 27 / 100: avg data time: 6.78e-02, avg batch time: 0.5117, average train loss: 0.2945
[09/26 08:51:09 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1674, average loss: 3.7750
[09/26 08:51:09 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 48.50	
[09/26 08:51:09 visual_prompt]: Best epoch 27: best metric: 0.280
[09/26 08:51:09 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.09145187862775209
[09/26 08:51:16 visual_prompt]: Epoch 28 / 100: avg data time: 6.47e-02, avg batch time: 0.5083, average train loss: 0.2617
[09/26 08:51:18 visual_prompt]: Inference (val):avg data time: 1.79e-05, avg batch time: 0.1677, average loss: 3.7780
[09/26 08:51:18 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 49.00	
[09/26 08:51:18 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.09045084971874738
[09/26 08:51:24 visual_prompt]: Epoch 29 / 100: avg data time: 4.98e-02, avg batch time: 0.4925, average train loss: 0.2322
[09/26 08:51:26 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1674, average loss: 3.8141
[09/26 08:51:26 visual_prompt]: Classification results with val_vtab-sun397: top1: 25.50	top5: 47.00	
[09/26 08:51:26 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.0894005376803361
[09/26 08:51:33 visual_prompt]: Epoch 30 / 100: avg data time: 6.22e-02, avg batch time: 0.5049, average train loss: 0.2058
[09/26 08:51:34 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1671, average loss: 3.7899
[09/26 08:51:34 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 49.00	
[09/26 08:51:34 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.0883022221559489
[09/26 08:51:41 visual_prompt]: Epoch 31 / 100: avg data time: 6.41e-02, avg batch time: 0.5078, average train loss: 0.1880
[09/26 08:51:43 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1671, average loss: 3.7773
[09/26 08:51:43 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.50	top5: 49.00	
[09/26 08:51:43 visual_prompt]: Best epoch 31: best metric: 0.285
[09/26 08:51:43 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.08715724127386971
[09/26 08:51:50 visual_prompt]: Epoch 32 / 100: avg data time: 6.05e-02, avg batch time: 0.5037, average train loss: 0.1694
[09/26 08:51:52 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1671, average loss: 3.8126
[09/26 08:51:52 visual_prompt]: Classification results with val_vtab-sun397: top1: 26.50	top5: 47.50	
[09/26 08:51:52 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.08596699001693256
[09/26 08:51:58 visual_prompt]: Epoch 33 / 100: avg data time: 5.96e-02, avg batch time: 0.5025, average train loss: 0.1577
[09/26 08:52:00 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1675, average loss: 3.7895
[09/26 08:52:00 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.50	top5: 48.50	
[09/26 08:52:00 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.08473291852294987
[09/26 08:52:07 visual_prompt]: Epoch 34 / 100: avg data time: 6.48e-02, avg batch time: 0.5072, average train loss: 0.1458
[09/26 08:52:09 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1674, average loss: 3.8113
[09/26 08:52:09 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.50	top5: 47.50	
[09/26 08:52:09 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.08345653031794292
[09/26 08:52:16 visual_prompt]: Epoch 35 / 100: avg data time: 6.16e-02, avg batch time: 0.5045, average train loss: 0.1340
[09/26 08:52:17 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1676, average loss: 3.8154
[09/26 08:52:17 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.00	top5: 50.00	
[09/26 08:52:17 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.08213938048432697
[09/26 08:52:24 visual_prompt]: Epoch 36 / 100: avg data time: 5.11e-02, avg batch time: 0.4951, average train loss: 0.1244
[09/26 08:52:26 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1676, average loss: 3.7788
[09/26 08:52:26 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 49.50	
[09/26 08:52:26 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.08078307376628291
[09/26 08:52:33 visual_prompt]: Epoch 37 / 100: avg data time: 6.82e-02, avg batch time: 0.5107, average train loss: 0.1198
[09/26 08:52:34 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1674, average loss: 3.8428
[09/26 08:52:34 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.00	top5: 49.00	
[09/26 08:52:34 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.07938926261462366
[09/26 08:52:41 visual_prompt]: Epoch 38 / 100: avg data time: 6.25e-02, avg batch time: 0.5057, average train loss: 0.1127
[09/26 08:52:43 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1676, average loss: 3.8122
[09/26 08:52:43 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.00	top5: 49.50	
[09/26 08:52:43 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.07795964517353735
[09/26 08:52:50 visual_prompt]: Epoch 39 / 100: avg data time: 6.60e-02, avg batch time: 0.5079, average train loss: 0.1047
[09/26 08:52:51 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1677, average loss: 3.8348
[09/26 08:52:51 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.00	top5: 48.00	
[09/26 08:52:51 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.07649596321166025
[09/26 08:52:58 visual_prompt]: Epoch 40 / 100: avg data time: 5.87e-02, avg batch time: 0.5024, average train loss: 0.1005
[09/26 08:53:00 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1674, average loss: 3.7979
[09/26 08:53:00 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 49.00	
[09/26 08:53:00 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.07500000000000001
[09/26 08:53:07 visual_prompt]: Epoch 41 / 100: avg data time: 6.80e-02, avg batch time: 0.5108, average train loss: 0.0971
[09/26 08:53:09 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1674, average loss: 3.8116
[09/26 08:53:09 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.50	top5: 50.00	
[09/26 08:53:09 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.07347357813929455
[09/26 08:53:16 visual_prompt]: Epoch 42 / 100: avg data time: 6.15e-02, avg batch time: 0.5054, average train loss: 0.0924
[09/26 08:53:17 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1674, average loss: 3.7916
[09/26 08:53:17 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.50	top5: 51.00	
[09/26 08:53:17 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.07191855733945388
[09/26 08:53:24 visual_prompt]: Epoch 43 / 100: avg data time: 6.69e-02, avg batch time: 0.5106, average train loss: 0.0884
[09/26 08:53:26 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1672, average loss: 3.8042
[09/26 08:53:26 visual_prompt]: Classification results with val_vtab-sun397: top1: 29.00	top5: 48.50	
[09/26 08:53:26 visual_prompt]: Best epoch 43: best metric: 0.290
[09/26 08:53:26 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.07033683215379002
[09/26 08:53:33 visual_prompt]: Epoch 44 / 100: avg data time: 6.04e-02, avg batch time: 0.5040, average train loss: 0.0855
[09/26 08:53:34 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1676, average loss: 3.8325
[09/26 08:53:34 visual_prompt]: Classification results with val_vtab-sun397: top1: 29.00	top5: 48.50	
[09/26 08:53:34 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.0687303296707956
[09/26 08:53:41 visual_prompt]: Epoch 45 / 100: avg data time: 6.84e-02, avg batch time: 0.5120, average train loss: 0.0821
[09/26 08:53:43 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1676, average loss: 3.8153
[09/26 08:53:43 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 50.50	
[09/26 08:53:43 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.06710100716628345
[09/26 08:53:50 visual_prompt]: Epoch 46 / 100: avg data time: 4.99e-02, avg batch time: 0.4935, average train loss: 0.0807
[09/26 08:53:51 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1675, average loss: 3.8365
[09/26 08:53:51 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.50	top5: 49.50	
[09/26 08:53:51 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.06545084971874737
[09/26 08:53:58 visual_prompt]: Epoch 47 / 100: avg data time: 6.82e-02, avg batch time: 0.5104, average train loss: 0.0770
[09/26 08:54:00 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1674, average loss: 3.8212
[09/26 08:54:00 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.50	top5: 50.00	
[09/26 08:54:00 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.06378186779084996
[09/26 08:54:07 visual_prompt]: Epoch 48 / 100: avg data time: 5.96e-02, avg batch time: 0.5019, average train loss: 0.0757
[09/26 08:54:09 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1673, average loss: 3.8354
[09/26 08:54:09 visual_prompt]: Classification results with val_vtab-sun397: top1: 29.00	top5: 50.00	
[09/26 08:54:09 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.06209609477998338
[09/26 08:54:16 visual_prompt]: Epoch 49 / 100: avg data time: 6.45e-02, avg batch time: 0.5082, average train loss: 0.0728
[09/26 08:54:17 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1674, average loss: 3.8427
[09/26 08:54:17 visual_prompt]: Classification results with val_vtab-sun397: top1: 29.50	top5: 50.00	
[09/26 08:54:17 visual_prompt]: Best epoch 49: best metric: 0.295
[09/26 08:54:17 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.06039558454088796
[09/26 08:54:24 visual_prompt]: Epoch 50 / 100: avg data time: 6.13e-02, avg batch time: 0.5049, average train loss: 0.0713
[09/26 08:54:26 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1677, average loss: 3.8417
[09/26 08:54:26 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.50	top5: 49.00	
[09/26 08:54:26 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.058682408883346526
[09/26 08:54:33 visual_prompt]: Epoch 51 / 100: avg data time: 5.82e-02, avg batch time: 0.5013, average train loss: 0.0705
[09/26 08:54:34 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1674, average loss: 3.8404
[09/26 08:54:34 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 50.50	
[09/26 08:54:34 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.05695865504800327
[09/26 08:54:41 visual_prompt]: Epoch 52 / 100: avg data time: 6.00e-02, avg batch time: 0.5029, average train loss: 0.0680
[09/26 08:54:43 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1669, average loss: 3.8389
[09/26 08:54:43 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 48.00	
[09/26 08:54:43 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.05522642316338268
[09/26 08:54:50 visual_prompt]: Epoch 53 / 100: avg data time: 5.32e-02, avg batch time: 0.4971, average train loss: 0.0668
[09/26 08:54:51 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1678, average loss: 3.8508
[09/26 08:54:51 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 49.50	
[09/26 08:54:51 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.05348782368720626
[09/26 08:54:58 visual_prompt]: Epoch 54 / 100: avg data time: 6.25e-02, avg batch time: 0.5066, average train loss: 0.0646
[09/26 08:55:00 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1673, average loss: 3.8591
[09/26 08:55:00 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.50	top5: 48.00	
[09/26 08:55:00 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.05174497483512506
[09/26 08:55:07 visual_prompt]: Epoch 55 / 100: avg data time: 6.86e-02, avg batch time: 0.5111, average train loss: 0.0634
[09/26 08:55:09 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1673, average loss: 3.8503
[09/26 08:55:09 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 48.50	
[09/26 08:55:09 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.05
[09/26 08:55:16 visual_prompt]: Epoch 56 / 100: avg data time: 6.34e-02, avg batch time: 0.5056, average train loss: 0.0624
[09/26 08:55:17 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1672, average loss: 3.8491
[09/26 08:55:17 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.50	top5: 47.50	
[09/26 08:55:17 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.04825502516487497
[09/26 08:55:24 visual_prompt]: Epoch 57 / 100: avg data time: 5.43e-02, avg batch time: 0.4983, average train loss: 0.0608
[09/26 08:55:26 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1676, average loss: 3.8514
[09/26 08:55:26 visual_prompt]: Classification results with val_vtab-sun397: top1: 29.00	top5: 49.50	
[09/26 08:55:26 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.04651217631279374
[09/26 08:55:33 visual_prompt]: Epoch 58 / 100: avg data time: 6.54e-02, avg batch time: 0.5084, average train loss: 0.0603
[09/26 08:55:34 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1675, average loss: 3.8399
[09/26 08:55:34 visual_prompt]: Classification results with val_vtab-sun397: top1: 29.00	top5: 49.00	
[09/26 08:55:34 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.04477357683661734
[09/26 08:55:41 visual_prompt]: Epoch 59 / 100: avg data time: 6.19e-02, avg batch time: 0.5054, average train loss: 0.0587
[09/26 08:55:43 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1677, average loss: 3.8396
[09/26 08:55:43 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.50	top5: 48.50	
[09/26 08:55:43 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.04304134495199674
[09/26 08:55:50 visual_prompt]: Epoch 60 / 100: avg data time: 6.75e-02, avg batch time: 0.5106, average train loss: 0.0587
[09/26 08:55:52 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1675, average loss: 3.8422
[09/26 08:55:52 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.50	top5: 49.50	
[09/26 08:55:52 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.041317591116653486
[09/26 08:55:58 visual_prompt]: Epoch 61 / 100: avg data time: 6.03e-02, avg batch time: 0.5032, average train loss: 0.0575
[09/26 08:56:00 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1674, average loss: 3.8374
[09/26 08:56:00 visual_prompt]: Classification results with val_vtab-sun397: top1: 29.50	top5: 49.00	
[09/26 08:56:00 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.039604415459112044
[09/26 08:56:07 visual_prompt]: Epoch 62 / 100: avg data time: 5.90e-02, avg batch time: 0.5018, average train loss: 0.0571
[09/26 08:56:09 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1676, average loss: 3.8461
[09/26 08:56:09 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.50	top5: 48.00	
[09/26 08:56:09 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.037903905220016625
[09/26 08:56:16 visual_prompt]: Epoch 63 / 100: avg data time: 6.72e-02, avg batch time: 0.5130, average train loss: 0.0557
[09/26 08:56:17 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1678, average loss: 3.8460
[09/26 08:56:17 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.50	top5: 48.50	
[09/26 08:56:17 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.036218132209150045
[09/26 08:56:24 visual_prompt]: Epoch 64 / 100: avg data time: 6.84e-02, avg batch time: 0.5125, average train loss: 0.0549
[09/26 08:56:26 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1675, average loss: 3.8478
[09/26 08:56:26 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.50	top5: 48.50	
[09/26 08:56:26 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.03454915028125263
[09/26 08:56:33 visual_prompt]: Epoch 65 / 100: avg data time: 6.67e-02, avg batch time: 0.5090, average train loss: 0.0548
[09/26 08:56:34 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.1671, average loss: 3.8470
[09/26 08:56:34 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 49.50	
[09/26 08:56:34 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.03289899283371657
[09/26 08:56:41 visual_prompt]: Epoch 66 / 100: avg data time: 6.04e-02, avg batch time: 0.5048, average train loss: 0.0538
[09/26 08:56:43 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1674, average loss: 3.8505
[09/26 08:56:43 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 49.00	
[09/26 08:56:43 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.0312696703292044
[09/26 08:56:50 visual_prompt]: Epoch 67 / 100: avg data time: 5.95e-02, avg batch time: 0.5026, average train loss: 0.0532
[09/26 08:56:52 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1674, average loss: 3.8444
[09/26 08:56:52 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.50	top5: 49.50	
[09/26 08:56:52 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.02966316784621
[09/26 08:56:59 visual_prompt]: Epoch 68 / 100: avg data time: 6.27e-02, avg batch time: 0.5058, average train loss: 0.0524
[09/26 08:57:00 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1672, average loss: 3.8467
[09/26 08:57:00 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.50	top5: 50.00	
[09/26 08:57:00 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.028081442660546126
[09/26 08:57:07 visual_prompt]: Epoch 69 / 100: avg data time: 5.59e-02, avg batch time: 0.5007, average train loss: 0.0524
[09/26 08:57:09 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1674, average loss: 3.8595
[09/26 08:57:09 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.50	top5: 50.00	
[09/26 08:57:09 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.026526421860705474
[09/26 08:57:16 visual_prompt]: Epoch 70 / 100: avg data time: 6.35e-02, avg batch time: 0.5061, average train loss: 0.0521
[09/26 08:57:17 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1675, average loss: 3.8568
[09/26 08:57:17 visual_prompt]: Classification results with val_vtab-sun397: top1: 29.00	top5: 50.00	
[09/26 08:57:17 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.025000000000000012
[09/26 08:57:24 visual_prompt]: Epoch 71 / 100: avg data time: 6.97e-02, avg batch time: 0.5122, average train loss: 0.0516
[09/26 08:57:26 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1674, average loss: 3.8492
[09/26 08:57:26 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.50	top5: 49.50	
[09/26 08:57:26 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.02350403678833976
[09/26 08:57:33 visual_prompt]: Epoch 72 / 100: avg data time: 5.03e-02, avg batch time: 0.4950, average train loss: 0.0507
[09/26 08:57:35 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1673, average loss: 3.8428
[09/26 08:57:35 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.50	top5: 50.00	
[09/26 08:57:35 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.022040354826462667
[09/26 08:57:41 visual_prompt]: Epoch 73 / 100: avg data time: 5.39e-02, avg batch time: 0.4978, average train loss: 0.0516
[09/26 08:57:43 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1674, average loss: 3.8402
[09/26 08:57:43 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 50.00	
[09/26 08:57:43 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.02061073738537635
[09/26 08:57:50 visual_prompt]: Epoch 74 / 100: avg data time: 5.92e-02, avg batch time: 0.5019, average train loss: 0.0506
[09/26 08:57:51 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1670, average loss: 3.8371
[09/26 08:57:52 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 49.50	
[09/26 08:57:52 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.019216926233717086
[09/26 08:57:58 visual_prompt]: Epoch 75 / 100: avg data time: 5.06e-02, avg batch time: 0.4941, average train loss: 0.0505
[09/26 08:58:00 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1674, average loss: 3.8398
[09/26 08:58:00 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 49.50	
[09/26 08:58:00 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.017860619515673033
[09/26 08:58:07 visual_prompt]: Epoch 76 / 100: avg data time: 6.14e-02, avg batch time: 0.5045, average train loss: 0.0501
[09/26 08:58:08 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1676, average loss: 3.8505
[09/26 08:58:08 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.50	top5: 49.00	
[09/26 08:58:08 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.016543469682057107
[09/26 08:58:15 visual_prompt]: Epoch 77 / 100: avg data time: 6.15e-02, avg batch time: 0.5045, average train loss: 0.0503
[09/26 08:58:17 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1670, average loss: 3.8526
[09/26 08:58:17 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 49.00	
[09/26 08:58:17 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.015267081477050132
[09/26 08:58:24 visual_prompt]: Epoch 78 / 100: avg data time: 5.92e-02, avg batch time: 0.5028, average train loss: 0.0493
[09/26 08:58:25 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1671, average loss: 3.8456
[09/26 08:58:25 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 50.00	
[09/26 08:58:25 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.014033009983067453
[09/26 08:58:32 visual_prompt]: Epoch 79 / 100: avg data time: 6.16e-02, avg batch time: 0.5052, average train loss: 0.0492
[09/26 08:58:34 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1672, average loss: 3.8441
[09/26 08:58:34 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.50	top5: 50.00	
[09/26 08:58:34 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.012842758726130284
[09/26 08:58:41 visual_prompt]: Epoch 80 / 100: avg data time: 6.19e-02, avg batch time: 0.5054, average train loss: 0.0487
[09/26 08:58:42 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1668, average loss: 3.8429
[09/26 08:58:42 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 50.00	
[09/26 08:58:42 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.011697777844051106
[09/26 08:58:49 visual_prompt]: Epoch 81 / 100: avg data time: 5.55e-02, avg batch time: 0.5016, average train loss: 0.0497
[09/26 08:58:51 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1672, average loss: 3.8443
[09/26 08:58:51 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 50.00	
[09/26 08:58:51 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.010599462319663905
[09/26 08:58:58 visual_prompt]: Epoch 82 / 100: avg data time: 5.98e-02, avg batch time: 0.5027, average train loss: 0.0488
[09/26 08:59:00 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1672, average loss: 3.8436
[09/26 08:59:00 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.50	top5: 50.00	
[09/26 08:59:00 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.009549150281252633
[09/26 08:59:06 visual_prompt]: Epoch 83 / 100: avg data time: 5.85e-02, avg batch time: 0.5032, average train loss: 0.0482
[09/26 08:59:08 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1673, average loss: 3.8463
[09/26 08:59:08 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.50	top5: 50.00	
[09/26 08:59:08 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.008548121372247919
[09/26 08:59:15 visual_prompt]: Epoch 84 / 100: avg data time: 5.96e-02, avg batch time: 0.5038, average train loss: 0.0488
[09/26 08:59:17 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1674, average loss: 3.8488
[09/26 08:59:17 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.50	top5: 50.00	
[09/26 08:59:17 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.007597595192178702
[09/26 08:59:23 visual_prompt]: Epoch 85 / 100: avg data time: 6.32e-02, avg batch time: 0.5063, average train loss: 0.0486
[09/26 08:59:25 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1675, average loss: 3.8492
[09/26 08:59:25 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.50	top5: 50.00	
[09/26 08:59:25 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.006698729810778065
[09/26 08:59:32 visual_prompt]: Epoch 86 / 100: avg data time: 4.78e-02, avg batch time: 0.4954, average train loss: 0.0485
[09/26 08:59:34 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.1674, average loss: 3.8487
[09/26 08:59:34 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.50	top5: 50.00	
[09/26 08:59:34 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.005852620357053651
[09/26 08:59:41 visual_prompt]: Epoch 87 / 100: avg data time: 6.48e-02, avg batch time: 0.5090, average train loss: 0.0487
[09/26 08:59:42 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1674, average loss: 3.8483
[09/26 08:59:42 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.50	top5: 50.00	
[09/26 08:59:42 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.00506029768504166
[09/26 08:59:49 visual_prompt]: Epoch 88 / 100: avg data time: 6.12e-02, avg batch time: 0.5044, average train loss: 0.0483
[09/26 08:59:51 visual_prompt]: Inference (val):avg data time: 1.81e-05, avg batch time: 0.1669, average loss: 3.8478
[09/26 08:59:51 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.50	top5: 50.00	
[09/26 08:59:51 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.004322727117869951
[09/26 08:59:58 visual_prompt]: Epoch 89 / 100: avg data time: 4.86e-02, avg batch time: 0.4946, average train loss: 0.0482
[09/26 08:59:59 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1673, average loss: 3.8485
[09/26 08:59:59 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.50	top5: 49.50	
[09/26 08:59:59 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.0036408072716606343
[09/26 09:00:06 visual_prompt]: Epoch 90 / 100: avg data time: 6.54e-02, avg batch time: 0.5096, average train loss: 0.0482
[09/26 09:00:08 visual_prompt]: Inference (val):avg data time: 1.87e-05, avg batch time: 0.1674, average loss: 3.8477
[09/26 09:00:08 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.50	top5: 49.50	
[09/26 09:00:08 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.0030153689607045845
[09/26 09:00:15 visual_prompt]: Epoch 91 / 100: avg data time: 6.80e-02, avg batch time: 0.5126, average train loss: 0.0477
[09/26 09:00:16 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1676, average loss: 3.8467
[09/26 09:00:16 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.50	top5: 50.00	
[09/26 09:00:16 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.0024471741852423235
[09/26 09:00:23 visual_prompt]: Epoch 92 / 100: avg data time: 6.45e-02, avg batch time: 0.5079, average train loss: 0.0482
[09/26 09:00:25 visual_prompt]: Inference (val):avg data time: 2.05e-05, avg batch time: 0.1676, average loss: 3.8473
[09/26 09:00:25 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.50	top5: 50.00	
[09/26 09:00:25 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.0019369152030840554
[09/26 09:00:32 visual_prompt]: Epoch 93 / 100: avg data time: 5.64e-02, avg batch time: 0.5019, average train loss: 0.0480
[09/26 09:00:33 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1675, average loss: 3.8477
[09/26 09:00:33 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.50	top5: 50.00	
[09/26 09:00:33 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.0014852136862001765
[09/26 09:00:40 visual_prompt]: Epoch 94 / 100: avg data time: 6.52e-02, avg batch time: 0.5094, average train loss: 0.0485
[09/26 09:00:42 visual_prompt]: Inference (val):avg data time: 3.97e-05, avg batch time: 0.1672, average loss: 3.8483
[09/26 09:00:42 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.50	top5: 50.00	
[09/26 09:00:42 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.0010926199633097156
[09/26 09:00:49 visual_prompt]: Epoch 95 / 100: avg data time: 6.29e-02, avg batch time: 0.5065, average train loss: 0.0479
[09/26 09:00:51 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1676, average loss: 3.8482
[09/26 09:00:51 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.50	top5: 50.00	
[09/26 09:00:51 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.0007596123493895991
[09/26 09:00:58 visual_prompt]: Epoch 96 / 100: avg data time: 6.46e-02, avg batch time: 0.5076, average train loss: 0.0482
[09/26 09:00:59 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1675, average loss: 3.8480
[09/26 09:00:59 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.50	top5: 50.00	
[09/26 09:00:59 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.00048659656292148194
[09/26 09:01:06 visual_prompt]: Epoch 97 / 100: avg data time: 6.10e-02, avg batch time: 0.5052, average train loss: 0.0479
[09/26 09:01:08 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1674, average loss: 3.8480
[09/26 09:01:08 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.50	top5: 50.00	
[09/26 09:01:08 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.0002739052315863355
[09/26 09:01:15 visual_prompt]: Epoch 98 / 100: avg data time: 6.06e-02, avg batch time: 0.5040, average train loss: 0.0479
[09/26 09:01:16 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1671, average loss: 3.8480
[09/26 09:01:16 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.50	top5: 50.00	
[09/26 09:01:16 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.00012179748700879012
[09/26 09:01:23 visual_prompt]: Epoch 99 / 100: avg data time: 5.98e-02, avg batch time: 0.5032, average train loss: 0.0478
[09/26 09:01:25 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1677, average loss: 3.8481
[09/26 09:01:25 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.50	top5: 50.00	
[09/26 09:01:25 visual_prompt]: Training 100 / 100 epoch, with learning rate 3.0458649045211895e-05
[09/26 09:01:32 visual_prompt]: Epoch 100 / 100: avg data time: 6.05e-02, avg batch time: 0.5053, average train loss: 0.0485
[09/26 09:01:33 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1672, average loss: 3.8481
[09/26 09:01:33 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.50	top5: 50.00	
[09/26 09:01:34 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 09:01:34 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              0
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 09:01:34 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-sun397', 'DATA.NUMBER_CLASSES', '397', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 09:01:34 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 09:01:34 visual_prompt]: Training with config:
[09/26 09:01:34 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-sun397/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.1_wd0.0/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 0.1, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-sun397', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 397, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 09:01:34 visual_prompt]: Loading training data...
[09/26 09:01:34 visual_prompt]: Constructing vtab-sun397 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split train[:800], from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/26 09:01:35 visual_prompt]: Number of images: 800
[09/26 09:01:35 visual_prompt]: Number of classes: 309 / 397
[09/26 09:01:35 visual_prompt]: Loading validation data...
[09/26 09:01:35 visual_prompt]: Constructing vtab-sun397 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split validation[:200], from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/26 09:01:35 visual_prompt]: Number of images: 200
[09/26 09:01:35 visual_prompt]: Number of classes: 136 / 397
[09/26 09:01:35 visual_prompt]: Constructing models...
[09/26 09:01:38 visual_prompt]: Total Parameters: 86564749	 Gradient Parameters: 766093
[09/26 09:01:38 visual_prompt]: tuned percent:0.885
[09/26 09:01:38 visual_prompt]: Device used for model: 0
[09/26 09:01:38 visual_prompt]: Setting up Evaluator...
[09/26 09:01:38 visual_prompt]: Setting up Trainer...
[09/26 09:01:38 visual_prompt]: 	Setting up the optimizer...
[09/26 09:01:38 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 09:01:45 visual_prompt]: Epoch 1 / 100: avg data time: 6.69e-02, avg batch time: 0.5099, average train loss: 5.9875
[09/26 09:01:46 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1667, average loss: 6.0097
[09/26 09:01:46 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/26 09:01:46 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.010000000000000002
[09/26 09:01:53 visual_prompt]: Epoch 2 / 100: avg data time: 6.17e-02, avg batch time: 0.5047, average train loss: 5.9741
[09/26 09:01:55 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.1672, average loss: 5.9886
[09/26 09:01:55 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/26 09:01:55 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.020000000000000004
[09/26 09:02:02 visual_prompt]: Epoch 3 / 100: avg data time: 5.85e-02, avg batch time: 0.5010, average train loss: 5.9266
[09/26 09:02:03 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1670, average loss: 5.9431
[09/26 09:02:04 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 3.50	
[09/26 09:02:04 visual_prompt]: Best epoch 3: best metric: 0.010
[09/26 09:02:04 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.03
[09/26 09:02:10 visual_prompt]: Epoch 4 / 100: avg data time: 6.28e-02, avg batch time: 0.5071, average train loss: 5.8205
[09/26 09:02:12 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1671, average loss: 5.8702
[09/26 09:02:12 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 09:02:12 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.04000000000000001
[09/26 09:02:19 visual_prompt]: Epoch 5 / 100: avg data time: 6.12e-02, avg batch time: 0.5037, average train loss: 5.6720
[09/26 09:02:21 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1674, average loss: 5.8331
[09/26 09:02:21 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.50	
[09/26 09:02:21 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.05
[09/26 09:02:27 visual_prompt]: Epoch 6 / 100: avg data time: 5.25e-02, avg batch time: 0.4947, average train loss: 5.5658
[09/26 09:02:29 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1669, average loss: 5.7771
[09/26 09:02:29 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 5.50	
[09/26 09:02:29 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.06
[09/26 09:02:36 visual_prompt]: Epoch 7 / 100: avg data time: 5.91e-02, avg batch time: 0.5021, average train loss: 5.3785
[09/26 09:02:37 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1669, average loss: 5.6144
[09/26 09:02:37 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.50	top5: 9.00	
[09/26 09:02:37 visual_prompt]: Best epoch 7: best metric: 0.025
[09/26 09:02:37 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.06999999999999999
[09/26 09:02:44 visual_prompt]: Epoch 8 / 100: avg data time: 5.76e-02, avg batch time: 0.5015, average train loss: 5.1820
[09/26 09:02:46 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1671, average loss: 5.4220
[09/26 09:02:46 visual_prompt]: Classification results with val_vtab-sun397: top1: 3.50	top5: 12.00	
[09/26 09:02:46 visual_prompt]: Best epoch 8: best metric: 0.035
[09/26 09:02:46 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.08000000000000002
[09/26 09:02:53 visual_prompt]: Epoch 9 / 100: avg data time: 6.30e-02, avg batch time: 0.5066, average train loss: 4.8716
[09/26 09:02:55 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1670, average loss: 5.2472
[09/26 09:02:55 visual_prompt]: Classification results with val_vtab-sun397: top1: 7.00	top5: 16.00	
[09/26 09:02:55 visual_prompt]: Best epoch 9: best metric: 0.070
[09/26 09:02:55 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.09000000000000001
[09/26 09:03:02 visual_prompt]: Epoch 10 / 100: avg data time: 6.28e-02, avg batch time: 0.5064, average train loss: 4.5694
[09/26 09:03:03 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1676, average loss: 5.0720
[09/26 09:03:03 visual_prompt]: Classification results with val_vtab-sun397: top1: 9.50	top5: 18.00	
[09/26 09:03:03 visual_prompt]: Best epoch 10: best metric: 0.095
[09/26 09:03:03 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.1
[09/26 09:03:10 visual_prompt]: Epoch 11 / 100: avg data time: 6.66e-02, avg batch time: 0.5100, average train loss: 4.2744
[09/26 09:03:12 visual_prompt]: Inference (val):avg data time: 3.94e-05, avg batch time: 0.1671, average loss: 4.9149
[09/26 09:03:12 visual_prompt]: Classification results with val_vtab-sun397: top1: 12.00	top5: 24.00	
[09/26 09:03:12 visual_prompt]: Best epoch 11: best metric: 0.120
[09/26 09:03:12 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0999695413509548
[09/26 09:03:19 visual_prompt]: Epoch 12 / 100: avg data time: 6.58e-02, avg batch time: 0.5091, average train loss: 3.8337
[09/26 09:03:20 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1669, average loss: 4.7285
[09/26 09:03:20 visual_prompt]: Classification results with val_vtab-sun397: top1: 15.00	top5: 27.50	
[09/26 09:03:20 visual_prompt]: Best epoch 12: best metric: 0.150
[09/26 09:03:20 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.09987820251299122
[09/26 09:03:27 visual_prompt]: Epoch 13 / 100: avg data time: 6.38e-02, avg batch time: 0.5083, average train loss: 3.4449
[09/26 09:03:29 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1674, average loss: 4.5127
[09/26 09:03:29 visual_prompt]: Classification results with val_vtab-sun397: top1: 18.50	top5: 37.00	
[09/26 09:03:29 visual_prompt]: Best epoch 13: best metric: 0.185
[09/26 09:03:29 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.09972609476841367
[09/26 09:03:36 visual_prompt]: Epoch 14 / 100: avg data time: 4.96e-02, avg batch time: 0.4945, average train loss: 3.0088
[09/26 09:03:37 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1675, average loss: 4.3579
[09/26 09:03:37 visual_prompt]: Classification results with val_vtab-sun397: top1: 17.50	top5: 36.00	
[09/26 09:03:37 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.09951340343707853
[09/26 09:03:44 visual_prompt]: Epoch 15 / 100: avg data time: 6.73e-02, avg batch time: 0.5107, average train loss: 2.5809
[09/26 09:03:46 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1675, average loss: 4.2486
[09/26 09:03:46 visual_prompt]: Classification results with val_vtab-sun397: top1: 18.50	top5: 38.50	
[09/26 09:03:46 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.09924038765061041
[09/26 09:03:53 visual_prompt]: Epoch 16 / 100: avg data time: 5.76e-02, avg batch time: 0.5009, average train loss: 2.2111
[09/26 09:03:55 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1676, average loss: 4.0923
[09/26 09:03:55 visual_prompt]: Classification results with val_vtab-sun397: top1: 23.00	top5: 46.00	
[09/26 09:03:55 visual_prompt]: Best epoch 16: best metric: 0.230
[09/26 09:03:55 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.09890738003669029
[09/26 09:04:02 visual_prompt]: Epoch 17 / 100: avg data time: 6.44e-02, avg batch time: 0.5083, average train loss: 1.8900
[09/26 09:04:03 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1673, average loss: 4.0609
[09/26 09:04:03 visual_prompt]: Classification results with val_vtab-sun397: top1: 23.00	top5: 46.00	
[09/26 09:04:03 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.09851478631379983
[09/26 09:04:10 visual_prompt]: Epoch 18 / 100: avg data time: 6.68e-02, avg batch time: 0.5097, average train loss: 1.6006
[09/26 09:04:12 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1674, average loss: 3.9162
[09/26 09:04:12 visual_prompt]: Classification results with val_vtab-sun397: top1: 26.00	top5: 50.00	
[09/26 09:04:12 visual_prompt]: Best epoch 18: best metric: 0.260
[09/26 09:04:12 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.09806308479691594
[09/26 09:04:19 visual_prompt]: Epoch 19 / 100: avg data time: 6.73e-02, avg batch time: 0.5115, average train loss: 1.3557
[09/26 09:04:20 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.1671, average loss: 3.9228
[09/26 09:04:20 visual_prompt]: Classification results with val_vtab-sun397: top1: 23.00	top5: 50.50	
[09/26 09:04:20 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.09755282581475769
[09/26 09:04:27 visual_prompt]: Epoch 20 / 100: avg data time: 6.72e-02, avg batch time: 0.5106, average train loss: 1.1210
[09/26 09:04:29 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1673, average loss: 3.8955
[09/26 09:04:29 visual_prompt]: Classification results with val_vtab-sun397: top1: 24.50	top5: 48.50	
[09/26 09:04:29 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.09698463103929543
[09/26 09:04:36 visual_prompt]: Epoch 21 / 100: avg data time: 6.24e-02, avg batch time: 0.5068, average train loss: 0.9454
[09/26 09:04:38 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1673, average loss: 3.8814
[09/26 09:04:38 visual_prompt]: Classification results with val_vtab-sun397: top1: 25.50	top5: 51.00	
[09/26 09:04:38 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.09635919272833937
[09/26 09:04:45 visual_prompt]: Epoch 22 / 100: avg data time: 6.82e-02, avg batch time: 0.5119, average train loss: 0.7740
[09/26 09:04:46 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1673, average loss: 3.7937
[09/26 09:04:46 visual_prompt]: Classification results with val_vtab-sun397: top1: 24.50	top5: 49.50	
[09/26 09:04:46 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.09567727288213004
[09/26 09:04:53 visual_prompt]: Epoch 23 / 100: avg data time: 6.71e-02, avg batch time: 0.5107, average train loss: 0.6363
[09/26 09:04:55 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1674, average loss: 3.7962
[09/26 09:04:55 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 50.00	
[09/26 09:04:55 visual_prompt]: Best epoch 23: best metric: 0.280
[09/26 09:04:55 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.09493970231495835
[09/26 09:05:02 visual_prompt]: Epoch 24 / 100: avg data time: 6.26e-02, avg batch time: 0.5057, average train loss: 0.5384
[09/26 09:05:04 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1675, average loss: 3.7478
[09/26 09:05:04 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 54.00	
[09/26 09:05:04 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.09414737964294635
[09/26 09:05:11 visual_prompt]: Epoch 25 / 100: avg data time: 6.44e-02, avg batch time: 0.5077, average train loss: 0.4512
[09/26 09:05:12 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1673, average loss: 3.7959
[09/26 09:05:12 visual_prompt]: Classification results with val_vtab-sun397: top1: 26.50	top5: 52.00	
[09/26 09:05:12 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.09330127018922195
[09/26 09:05:19 visual_prompt]: Epoch 26 / 100: avg data time: 5.68e-02, avg batch time: 0.5007, average train loss: 0.3826
[09/26 09:05:21 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1671, average loss: 3.7738
[09/26 09:05:21 visual_prompt]: Classification results with val_vtab-sun397: top1: 26.50	top5: 51.50	
[09/26 09:05:21 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.0924024048078213
[09/26 09:05:28 visual_prompt]: Epoch 27 / 100: avg data time: 5.29e-02, avg batch time: 0.4967, average train loss: 0.3249
[09/26 09:05:29 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1675, average loss: 3.7340
[09/26 09:05:29 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 53.50	
[09/26 09:05:29 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.09145187862775209
[09/26 09:05:36 visual_prompt]: Epoch 28 / 100: avg data time: 5.84e-02, avg batch time: 0.5024, average train loss: 0.2778
[09/26 09:05:38 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1675, average loss: 3.7692
[09/26 09:05:38 visual_prompt]: Classification results with val_vtab-sun397: top1: 26.00	top5: 51.00	
[09/26 09:05:38 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.09045084971874738
[09/26 09:05:45 visual_prompt]: Epoch 29 / 100: avg data time: 5.31e-02, avg batch time: 0.4988, average train loss: 0.2435
[09/26 09:05:46 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1675, average loss: 3.7665
[09/26 09:05:46 visual_prompt]: Classification results with val_vtab-sun397: top1: 26.00	top5: 53.00	
[09/26 09:05:46 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.0894005376803361
[09/26 09:05:53 visual_prompt]: Epoch 30 / 100: avg data time: 6.06e-02, avg batch time: 0.5052, average train loss: 0.2203
[09/26 09:05:55 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1671, average loss: 3.7493
[09/26 09:05:55 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.50	top5: 52.50	
[09/26 09:05:55 visual_prompt]: Best epoch 30: best metric: 0.285
[09/26 09:05:55 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.0883022221559489
[09/26 09:06:02 visual_prompt]: Epoch 31 / 100: avg data time: 6.24e-02, avg batch time: 0.5054, average train loss: 0.1950
[09/26 09:06:04 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1670, average loss: 3.7376
[09/26 09:06:04 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 52.00	
[09/26 09:06:04 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.08715724127386971
[09/26 09:06:10 visual_prompt]: Epoch 32 / 100: avg data time: 4.82e-02, avg batch time: 0.4932, average train loss: 0.1748
[09/26 09:06:12 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1676, average loss: 3.7399
[09/26 09:06:12 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.50	top5: 54.50	
[09/26 09:06:12 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.08596699001693256
[09/26 09:06:19 visual_prompt]: Epoch 33 / 100: avg data time: 6.00e-02, avg batch time: 0.5035, average train loss: 0.1610
[09/26 09:06:20 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1671, average loss: 3.7388
[09/26 09:06:20 visual_prompt]: Classification results with val_vtab-sun397: top1: 29.00	top5: 53.00	
[09/26 09:06:20 visual_prompt]: Best epoch 33: best metric: 0.290
[09/26 09:06:20 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.08473291852294987
[09/26 09:06:27 visual_prompt]: Epoch 34 / 100: avg data time: 5.83e-02, avg batch time: 0.5028, average train loss: 0.1493
[09/26 09:06:29 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1673, average loss: 3.7502
[09/26 09:06:29 visual_prompt]: Classification results with val_vtab-sun397: top1: 29.00	top5: 53.00	
[09/26 09:06:29 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.08345653031794292
[09/26 09:06:36 visual_prompt]: Epoch 35 / 100: avg data time: 5.71e-02, avg batch time: 0.5009, average train loss: 0.1371
[09/26 09:06:37 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1672, average loss: 3.7776
[09/26 09:06:37 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.50	top5: 51.00	
[09/26 09:06:37 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.08213938048432697
[09/26 09:06:44 visual_prompt]: Epoch 36 / 100: avg data time: 5.35e-02, avg batch time: 0.4990, average train loss: 0.1247
[09/26 09:06:46 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1672, average loss: 3.7419
[09/26 09:06:46 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.50	top5: 52.50	
[09/26 09:06:46 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.08078307376628291
[09/26 09:06:53 visual_prompt]: Epoch 37 / 100: avg data time: 6.36e-02, avg batch time: 0.5073, average train loss: 0.1199
[09/26 09:06:54 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1675, average loss: 3.7438
[09/26 09:06:55 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.50	top5: 52.50	
[09/26 09:06:55 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.07938926261462366
[09/26 09:07:01 visual_prompt]: Epoch 38 / 100: avg data time: 5.39e-02, avg batch time: 0.4992, average train loss: 0.1123
[09/26 09:07:03 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1673, average loss: 3.7496
[09/26 09:07:03 visual_prompt]: Classification results with val_vtab-sun397: top1: 29.50	top5: 52.00	
[09/26 09:07:03 visual_prompt]: Best epoch 38: best metric: 0.295
[09/26 09:07:03 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.07795964517353735
[09/26 09:07:10 visual_prompt]: Epoch 39 / 100: avg data time: 5.99e-02, avg batch time: 0.5035, average train loss: 0.1032
[09/26 09:07:12 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1675, average loss: 3.7506
[09/26 09:07:12 visual_prompt]: Classification results with val_vtab-sun397: top1: 29.00	top5: 52.00	
[09/26 09:07:12 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.07649596321166025
[09/26 09:07:18 visual_prompt]: Epoch 40 / 100: avg data time: 6.00e-02, avg batch time: 0.5037, average train loss: 0.0990
[09/26 09:07:20 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1671, average loss: 3.7460
[09/26 09:07:20 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.50	top5: 52.00	
[09/26 09:07:20 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.07500000000000001
[09/26 09:07:27 visual_prompt]: Epoch 41 / 100: avg data time: 6.42e-02, avg batch time: 0.5073, average train loss: 0.0940
[09/26 09:07:29 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1676, average loss: 3.7540
[09/26 09:07:29 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.50	top5: 52.50	
[09/26 09:07:29 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.07347357813929455
[09/26 09:07:36 visual_prompt]: Epoch 42 / 100: avg data time: 6.60e-02, avg batch time: 0.5110, average train loss: 0.0899
[09/26 09:07:37 visual_prompt]: Inference (val):avg data time: 2.01e-05, avg batch time: 0.1672, average loss: 3.7484
[09/26 09:07:37 visual_prompt]: Classification results with val_vtab-sun397: top1: 29.00	top5: 52.50	
[09/26 09:07:37 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.07191855733945388
[09/26 09:07:44 visual_prompt]: Epoch 43 / 100: avg data time: 6.08e-02, avg batch time: 0.5042, average train loss: 0.0864
[09/26 09:07:46 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1670, average loss: 3.7530
[09/26 09:07:46 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.50	top5: 53.00	
[09/26 09:07:46 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.07033683215379002
[09/26 09:07:53 visual_prompt]: Epoch 44 / 100: avg data time: 5.98e-02, avg batch time: 0.5034, average train loss: 0.0819
[09/26 09:07:54 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1672, average loss: 3.7586
[09/26 09:07:54 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.50	top5: 52.50	
[09/26 09:07:54 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.0687303296707956
[09/26 09:08:01 visual_prompt]: Epoch 45 / 100: avg data time: 5.41e-02, avg batch time: 0.4985, average train loss: 0.0778
[09/26 09:08:03 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1674, average loss: 3.7492
[09/26 09:08:03 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.00	top5: 53.50	
[09/26 09:08:03 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.06710100716628345
[09/26 09:08:10 visual_prompt]: Epoch 46 / 100: avg data time: 6.36e-02, avg batch time: 0.5071, average train loss: 0.0761
[09/26 09:08:11 visual_prompt]: Inference (val):avg data time: 1.96e-05, avg batch time: 0.1676, average loss: 3.7507
[09/26 09:08:11 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 52.50	
[09/26 09:08:11 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.06545084971874737
[09/26 09:08:18 visual_prompt]: Epoch 47 / 100: avg data time: 6.43e-02, avg batch time: 0.5080, average train loss: 0.0733
[09/26 09:08:20 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1669, average loss: 3.7616
[09/26 09:08:20 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.50	top5: 52.50	
[09/26 09:08:20 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.06378186779084996
[09/26 09:08:27 visual_prompt]: Epoch 48 / 100: avg data time: 5.35e-02, avg batch time: 0.4977, average train loss: 0.0711
[09/26 09:08:28 visual_prompt]: Inference (val):avg data time: 2.05e-05, avg batch time: 0.1672, average loss: 3.7744
[09/26 09:08:28 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 52.50	
[09/26 09:08:28 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.06209609477998338
[09/26 09:08:35 visual_prompt]: Epoch 49 / 100: avg data time: 6.07e-02, avg batch time: 0.5054, average train loss: 0.0681
[09/26 09:08:37 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1678, average loss: 3.7877
[09/26 09:08:37 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.50	top5: 51.00	
[09/26 09:08:37 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.06039558454088796
[09/26 09:08:44 visual_prompt]: Epoch 50 / 100: avg data time: 6.35e-02, avg batch time: 0.5080, average train loss: 0.0666
[09/26 09:08:46 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1674, average loss: 3.7705
[09/26 09:08:46 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.00	top5: 52.50	
[09/26 09:08:46 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.058682408883346526
[09/26 09:08:53 visual_prompt]: Epoch 51 / 100: avg data time: 6.35e-02, avg batch time: 0.5075, average train loss: 0.0651
[09/26 09:08:54 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1672, average loss: 3.7829
[09/26 09:08:54 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 51.50	
[09/26 09:08:54 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.05695865504800327
[09/26 09:09:01 visual_prompt]: Epoch 52 / 100: avg data time: 6.01e-02, avg batch time: 0.5035, average train loss: 0.0622
[09/26 09:09:03 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1675, average loss: 3.7708
[09/26 09:09:03 visual_prompt]: Classification results with val_vtab-sun397: top1: 29.00	top5: 51.00	
[09/26 09:09:03 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.05522642316338268
[09/26 09:09:10 visual_prompt]: Epoch 53 / 100: avg data time: 6.02e-02, avg batch time: 0.5051, average train loss: 0.0622
[09/26 09:09:11 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1673, average loss: 3.7786
[09/26 09:09:11 visual_prompt]: Classification results with val_vtab-sun397: top1: 29.50	top5: 52.50	
[09/26 09:09:11 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.05348782368720626
[09/26 09:09:18 visual_prompt]: Epoch 54 / 100: avg data time: 5.89e-02, avg batch time: 0.5035, average train loss: 0.0604
[09/26 09:09:20 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.1680, average loss: 3.7623
[09/26 09:09:20 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.50	top5: 52.00	
[09/26 09:09:20 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.05174497483512506
[09/26 09:09:27 visual_prompt]: Epoch 55 / 100: avg data time: 6.08e-02, avg batch time: 0.5036, average train loss: 0.0590
[09/26 09:09:29 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1672, average loss: 3.7613
[09/26 09:09:29 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 52.00	
[09/26 09:09:29 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.05
[09/26 09:09:35 visual_prompt]: Epoch 56 / 100: avg data time: 5.84e-02, avg batch time: 0.5023, average train loss: 0.0573
[09/26 09:09:37 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1674, average loss: 3.7709
[09/26 09:09:37 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 52.00	
[09/26 09:09:37 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.04825502516487497
[09/26 09:09:44 visual_prompt]: Epoch 57 / 100: avg data time: 5.92e-02, avg batch time: 0.5028, average train loss: 0.0567
[09/26 09:09:46 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1673, average loss: 3.7665
[09/26 09:09:46 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 52.00	
[09/26 09:09:46 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.04651217631279374
[09/26 09:09:53 visual_prompt]: Epoch 58 / 100: avg data time: 6.30e-02, avg batch time: 0.5063, average train loss: 0.0553
[09/26 09:09:54 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1673, average loss: 3.7803
[09/26 09:09:54 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.50	top5: 51.00	
[09/26 09:09:54 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.04477357683661734
[09/26 09:10:01 visual_prompt]: Epoch 59 / 100: avg data time: 6.08e-02, avg batch time: 0.5045, average train loss: 0.0540
[09/26 09:10:03 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1675, average loss: 3.7772
[09/26 09:10:03 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.50	top5: 51.00	
[09/26 09:10:03 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.04304134495199674
[09/26 09:10:10 visual_prompt]: Epoch 60 / 100: avg data time: 5.78e-02, avg batch time: 0.5025, average train loss: 0.0537
[09/26 09:10:11 visual_prompt]: Inference (val):avg data time: 2.00e-05, avg batch time: 0.1674, average loss: 3.7691
[09/26 09:10:11 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.50	top5: 52.00	
[09/26 09:10:11 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.041317591116653486
[09/26 09:10:18 visual_prompt]: Epoch 61 / 100: avg data time: 5.44e-02, avg batch time: 0.5006, average train loss: 0.0530
[09/26 09:10:20 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1675, average loss: 3.7643
[09/26 09:10:20 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.50	top5: 53.50	
[09/26 09:10:20 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.039604415459112044
[09/26 09:10:27 visual_prompt]: Epoch 62 / 100: avg data time: 7.04e-02, avg batch time: 0.5137, average train loss: 0.0519
[09/26 09:10:28 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1672, average loss: 3.7727
[09/26 09:10:28 visual_prompt]: Classification results with val_vtab-sun397: top1: 29.00	top5: 52.00	
[09/26 09:10:28 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.037903905220016625
[09/26 09:10:35 visual_prompt]: Epoch 63 / 100: avg data time: 6.47e-02, avg batch time: 0.5086, average train loss: 0.0504
[09/26 09:10:37 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1673, average loss: 3.7766
[09/26 09:10:37 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.50	top5: 53.00	
[09/26 09:10:37 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.036218132209150045
[09/26 09:10:44 visual_prompt]: Epoch 64 / 100: avg data time: 6.54e-02, avg batch time: 0.5088, average train loss: 0.0505
[09/26 09:10:46 visual_prompt]: Inference (val):avg data time: 2.01e-05, avg batch time: 0.1673, average loss: 3.7699
[09/26 09:10:46 visual_prompt]: Classification results with val_vtab-sun397: top1: 29.00	top5: 52.50	
[09/26 09:10:46 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.03454915028125263
[09/26 09:10:53 visual_prompt]: Epoch 65 / 100: avg data time: 6.47e-02, avg batch time: 0.5081, average train loss: 0.0489
[09/26 09:10:54 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1674, average loss: 3.7601
[09/26 09:10:54 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 52.50	
[09/26 09:10:54 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.03289899283371657
[09/26 09:11:01 visual_prompt]: Epoch 66 / 100: avg data time: 6.42e-02, avg batch time: 0.5082, average train loss: 0.0488
[09/26 09:11:03 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.1675, average loss: 3.7667
[09/26 09:11:03 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.50	top5: 52.00	
[09/26 09:11:03 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.0312696703292044
[09/26 09:11:10 visual_prompt]: Epoch 67 / 100: avg data time: 6.45e-02, avg batch time: 0.5095, average train loss: 0.0486
[09/26 09:11:11 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1672, average loss: 3.7764
[09/26 09:11:11 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.50	top5: 51.50	
[09/26 09:11:11 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.02966316784621
[09/26 09:11:18 visual_prompt]: Epoch 68 / 100: avg data time: 6.51e-02, avg batch time: 0.5077, average train loss: 0.0480
[09/26 09:11:20 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1673, average loss: 3.7803
[09/26 09:11:20 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 52.00	
[09/26 09:11:20 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.028081442660546126
[09/26 09:11:27 visual_prompt]: Epoch 69 / 100: avg data time: 5.20e-02, avg batch time: 0.4993, average train loss: 0.0477
[09/26 09:11:29 visual_prompt]: Inference (val):avg data time: 3.82e-05, avg batch time: 0.1672, average loss: 3.7857
[09/26 09:11:29 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.50	top5: 52.50	
[09/26 09:11:29 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.026526421860705474
[09/26 09:11:35 visual_prompt]: Epoch 70 / 100: avg data time: 5.33e-02, avg batch time: 0.4998, average train loss: 0.0462
[09/26 09:11:37 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.1675, average loss: 3.7841
[09/26 09:11:37 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.50	top5: 52.50	
[09/26 09:11:37 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.025000000000000012
[09/26 09:11:44 visual_prompt]: Epoch 71 / 100: avg data time: 6.36e-02, avg batch time: 0.5073, average train loss: 0.0469
[09/26 09:11:46 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1678, average loss: 3.7748
[09/26 09:11:46 visual_prompt]: Classification results with val_vtab-sun397: top1: 29.00	top5: 51.50	
[09/26 09:11:46 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.02350403678833976
[09/26 09:11:53 visual_prompt]: Epoch 72 / 100: avg data time: 6.18e-02, avg batch time: 0.5055, average train loss: 0.0458
[09/26 09:11:54 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1676, average loss: 3.7713
[09/26 09:11:54 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.50	top5: 51.50	
[09/26 09:11:54 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.022040354826462667
[09/26 09:12:01 visual_prompt]: Epoch 73 / 100: avg data time: 6.24e-02, avg batch time: 0.5054, average train loss: 0.0459
[09/26 09:12:03 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1674, average loss: 3.7726
[09/26 09:12:03 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 52.00	
[09/26 09:12:03 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.02061073738537635
[09/26 09:12:10 visual_prompt]: Epoch 74 / 100: avg data time: 5.72e-02, avg batch time: 0.5012, average train loss: 0.0466
[09/26 09:12:11 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1672, average loss: 3.7796
[09/26 09:12:11 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 52.00	
[09/26 09:12:11 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.019216926233717086
[09/26 09:12:18 visual_prompt]: Epoch 75 / 100: avg data time: 6.61e-02, avg batch time: 0.5090, average train loss: 0.0451
[09/26 09:12:20 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1677, average loss: 3.7882
[09/26 09:12:20 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 52.00	
[09/26 09:12:20 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.017860619515673033
[09/26 09:12:27 visual_prompt]: Epoch 76 / 100: avg data time: 6.22e-02, avg batch time: 0.5070, average train loss: 0.0444
[09/26 09:12:29 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1673, average loss: 3.7850
[09/26 09:12:29 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.50	top5: 52.00	
[09/26 09:12:29 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.016543469682057107
[09/26 09:12:36 visual_prompt]: Epoch 77 / 100: avg data time: 6.53e-02, avg batch time: 0.5079, average train loss: 0.0452
[09/26 09:12:37 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1672, average loss: 3.7809
[09/26 09:12:37 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 52.00	
[09/26 09:12:37 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.015267081477050132
[09/26 09:12:44 visual_prompt]: Epoch 78 / 100: avg data time: 6.34e-02, avg batch time: 0.5069, average train loss: 0.0445
[09/26 09:12:46 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1675, average loss: 3.7847
[09/26 09:12:46 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 52.00	
[09/26 09:12:46 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.014033009983067453
[09/26 09:12:53 visual_prompt]: Epoch 79 / 100: avg data time: 6.46e-02, avg batch time: 0.5093, average train loss: 0.0438
[09/26 09:12:54 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1674, average loss: 3.7856
[09/26 09:12:54 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.50	top5: 52.50	
[09/26 09:12:54 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.012842758726130284
[09/26 09:13:01 visual_prompt]: Epoch 80 / 100: avg data time: 6.22e-02, avg batch time: 0.5065, average train loss: 0.0440
[09/26 09:13:03 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1674, average loss: 3.7865
[09/26 09:13:03 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 52.50	
[09/26 09:13:03 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.011697777844051106
[09/26 09:13:10 visual_prompt]: Epoch 81 / 100: avg data time: 5.59e-02, avg batch time: 0.4989, average train loss: 0.0430
[09/26 09:13:12 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1680, average loss: 3.7852
[09/26 09:13:12 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.50	top5: 52.00	
[09/26 09:13:12 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.010599462319663905
[09/26 09:13:18 visual_prompt]: Epoch 82 / 100: avg data time: 5.16e-02, avg batch time: 0.4958, average train loss: 0.0434
[09/26 09:13:20 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1673, average loss: 3.7842
[09/26 09:13:20 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 51.50	
[09/26 09:13:20 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.009549150281252633
[09/26 09:13:27 visual_prompt]: Epoch 83 / 100: avg data time: 6.32e-02, avg batch time: 0.5080, average train loss: 0.0438
[09/26 09:13:29 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1678, average loss: 3.7845
[09/26 09:13:29 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 51.50	
[09/26 09:13:29 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.008548121372247919
[09/26 09:13:36 visual_prompt]: Epoch 84 / 100: avg data time: 6.01e-02, avg batch time: 0.5034, average train loss: 0.0438
[09/26 09:13:37 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1677, average loss: 3.7841
[09/26 09:13:37 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 52.00	
[09/26 09:13:37 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.007597595192178702
[09/26 09:13:44 visual_prompt]: Epoch 85 / 100: avg data time: 6.04e-02, avg batch time: 0.5042, average train loss: 0.0430
[09/26 09:13:46 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1671, average loss: 3.7845
[09/26 09:13:46 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 52.00	
[09/26 09:13:46 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.006698729810778065
[09/26 09:13:53 visual_prompt]: Epoch 86 / 100: avg data time: 6.38e-02, avg batch time: 0.5063, average train loss: 0.0434
[09/26 09:13:54 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1672, average loss: 3.7842
[09/26 09:13:54 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 52.00	
[09/26 09:13:54 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.005852620357053651
[09/26 09:14:01 visual_prompt]: Epoch 87 / 100: avg data time: 5.41e-02, avg batch time: 0.4992, average train loss: 0.0439
[09/26 09:14:03 visual_prompt]: Inference (val):avg data time: 3.50e-05, avg batch time: 0.1672, average loss: 3.7826
[09/26 09:14:03 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.50	top5: 52.00	
[09/26 09:14:03 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.00506029768504166
[09/26 09:14:10 visual_prompt]: Epoch 88 / 100: avg data time: 5.94e-02, avg batch time: 0.5027, average train loss: 0.0430
[09/26 09:14:11 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1671, average loss: 3.7828
[09/26 09:14:11 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.50	top5: 52.00	
[09/26 09:14:11 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.004322727117869951
[09/26 09:14:18 visual_prompt]: Epoch 89 / 100: avg data time: 6.37e-02, avg batch time: 0.5067, average train loss: 0.0428
[09/26 09:14:20 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1672, average loss: 3.7825
[09/26 09:14:20 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 52.00	
[09/26 09:14:20 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.0036408072716606343
[09/26 09:14:27 visual_prompt]: Epoch 90 / 100: avg data time: 6.40e-02, avg batch time: 0.5081, average train loss: 0.0430
[09/26 09:14:28 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1671, average loss: 3.7819
[09/26 09:14:28 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 52.00	
[09/26 09:14:28 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.0030153689607045845
[09/26 09:14:35 visual_prompt]: Epoch 91 / 100: avg data time: 6.44e-02, avg batch time: 0.5083, average train loss: 0.0424
[09/26 09:14:37 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1675, average loss: 3.7821
[09/26 09:14:37 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 52.00	
[09/26 09:14:37 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.0024471741852423235
[09/26 09:14:44 visual_prompt]: Epoch 92 / 100: avg data time: 6.17e-02, avg batch time: 0.5055, average train loss: 0.0435
[09/26 09:14:46 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1669, average loss: 3.7823
[09/26 09:14:46 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 52.00	
[09/26 09:14:46 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.0019369152030840554
[09/26 09:14:53 visual_prompt]: Epoch 93 / 100: avg data time: 6.26e-02, avg batch time: 0.5065, average train loss: 0.0429
[09/26 09:14:54 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1672, average loss: 3.7827
[09/26 09:14:54 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 52.00	
[09/26 09:14:54 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.0014852136862001765
[09/26 09:15:01 visual_prompt]: Epoch 94 / 100: avg data time: 6.12e-02, avg batch time: 0.5041, average train loss: 0.0424
[09/26 09:15:03 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1671, average loss: 3.7830
[09/26 09:15:03 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 52.00	
[09/26 09:15:03 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.0010926199633097156
[09/26 09:15:10 visual_prompt]: Epoch 95 / 100: avg data time: 6.24e-02, avg batch time: 0.5052, average train loss: 0.0421
[09/26 09:15:11 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1673, average loss: 3.7832
[09/26 09:15:11 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 52.00	
[09/26 09:15:11 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.0007596123493895991
[09/26 09:15:18 visual_prompt]: Epoch 96 / 100: avg data time: 6.62e-02, avg batch time: 0.5093, average train loss: 0.0427
[09/26 09:15:20 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1669, average loss: 3.7833
[09/26 09:15:20 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 52.00	
[09/26 09:15:20 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.00048659656292148194
[09/26 09:15:27 visual_prompt]: Epoch 97 / 100: avg data time: 6.05e-02, avg batch time: 0.5049, average train loss: 0.0436
[09/26 09:15:29 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1672, average loss: 3.7834
[09/26 09:15:29 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 52.00	
[09/26 09:15:29 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.0002739052315863355
[09/26 09:15:35 visual_prompt]: Epoch 98 / 100: avg data time: 6.12e-02, avg batch time: 0.5039, average train loss: 0.0425
[09/26 09:15:37 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1671, average loss: 3.7835
[09/26 09:15:37 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 52.00	
[09/26 09:15:37 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.00012179748700879012
[09/26 09:15:44 visual_prompt]: Epoch 99 / 100: avg data time: 6.11e-02, avg batch time: 0.5048, average train loss: 0.0427
[09/26 09:15:46 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1672, average loss: 3.7835
[09/26 09:15:46 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 52.00	
[09/26 09:15:46 visual_prompt]: Training 100 / 100 epoch, with learning rate 3.0458649045211895e-05
[09/26 09:15:53 visual_prompt]: Epoch 100 / 100: avg data time: 6.71e-02, avg batch time: 0.5101, average train loss: 0.0416
[09/26 09:15:54 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1672, average loss: 3.7835
[09/26 09:15:54 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 52.00	
[09/26 09:15:54 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 09:15:54 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              0
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 09:15:54 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-sun397', 'DATA.NUMBER_CLASSES', '397', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 09:15:54 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 09:15:54 visual_prompt]: Training with config:
[09/26 09:15:54 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-sun397/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.05_wd0.01/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 0.05, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-sun397', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 397, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 09:15:54 visual_prompt]: Loading training data...
[09/26 09:15:54 visual_prompt]: Constructing vtab-sun397 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split train[:800], from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/26 09:15:56 visual_prompt]: Number of images: 800
[09/26 09:15:56 visual_prompt]: Number of classes: 309 / 397
[09/26 09:15:56 visual_prompt]: Loading validation data...
[09/26 09:15:56 visual_prompt]: Constructing vtab-sun397 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split validation[:200], from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/26 09:15:56 visual_prompt]: Number of images: 200
[09/26 09:15:56 visual_prompt]: Number of classes: 136 / 397
[09/26 09:15:56 visual_prompt]: Constructing models...
[09/26 09:15:59 visual_prompt]: Total Parameters: 86564749	 Gradient Parameters: 766093
[09/26 09:15:59 visual_prompt]: tuned percent:0.885
[09/26 09:15:59 visual_prompt]: Device used for model: 0
[09/26 09:15:59 visual_prompt]: Setting up Evaluator...
[09/26 09:15:59 visual_prompt]: Setting up Trainer...
[09/26 09:15:59 visual_prompt]: 	Setting up the optimizer...
[09/26 09:15:59 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 09:16:06 visual_prompt]: Epoch 1 / 100: avg data time: 6.47e-02, avg batch time: 0.5092, average train loss: 5.9898
[09/26 09:16:07 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1676, average loss: 6.0097
[09/26 09:16:07 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/26 09:16:07 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.005000000000000001
[09/26 09:16:14 visual_prompt]: Epoch 2 / 100: avg data time: 6.65e-02, avg batch time: 0.5107, average train loss: 5.9795
[09/26 09:16:16 visual_prompt]: Inference (val):avg data time: 3.62e-05, avg batch time: 0.1676, average loss: 6.0000
[09/26 09:16:16 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.50	
[09/26 09:16:16 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.010000000000000002
[09/26 09:16:23 visual_prompt]: Epoch 3 / 100: avg data time: 6.24e-02, avg batch time: 0.5060, average train loss: 5.9534
[09/26 09:16:25 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1677, average loss: 5.9759
[09/26 09:16:25 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/26 09:16:25 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.015
[09/26 09:16:32 visual_prompt]: Epoch 4 / 100: avg data time: 6.02e-02, avg batch time: 0.5030, average train loss: 5.9053
[09/26 09:16:33 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1677, average loss: 5.9304
[09/26 09:16:33 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 5.00	
[09/26 09:16:33 visual_prompt]: Best epoch 4: best metric: 0.005
[09/26 09:16:33 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.020000000000000004
[09/26 09:16:40 visual_prompt]: Epoch 5 / 100: avg data time: 6.28e-02, avg batch time: 0.5054, average train loss: 5.8104
[09/26 09:16:42 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1675, average loss: 5.8622
[09/26 09:16:42 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 09:16:42 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.025
[09/26 09:16:49 visual_prompt]: Epoch 6 / 100: avg data time: 6.19e-02, avg batch time: 0.5042, average train loss: 5.6921
[09/26 09:16:50 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1675, average loss: 5.8316
[09/26 09:16:50 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.50	
[09/26 09:16:50 visual_prompt]: Best epoch 6: best metric: 0.010
[09/26 09:16:50 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.03
[09/26 09:16:57 visual_prompt]: Epoch 7 / 100: avg data time: 6.08e-02, avg batch time: 0.5045, average train loss: 5.5737
[09/26 09:16:59 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.1675, average loss: 5.7517
[09/26 09:16:59 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.50	top5: 6.50	
[09/26 09:16:59 visual_prompt]: Best epoch 7: best metric: 0.015
[09/26 09:16:59 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.034999999999999996
[09/26 09:17:06 visual_prompt]: Epoch 8 / 100: avg data time: 5.15e-02, avg batch time: 0.4964, average train loss: 5.4461
[09/26 09:17:07 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1674, average loss: 5.6988
[09/26 09:17:07 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.00	top5: 7.00	
[09/26 09:17:07 visual_prompt]: Best epoch 8: best metric: 0.020
[09/26 09:17:07 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.04000000000000001
[09/26 09:17:14 visual_prompt]: Epoch 9 / 100: avg data time: 5.85e-02, avg batch time: 0.5031, average train loss: 5.2886
[09/26 09:17:16 visual_prompt]: Inference (val):avg data time: 4.08e-05, avg batch time: 0.1675, average loss: 5.5633
[09/26 09:17:16 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.00	top5: 9.50	
[09/26 09:17:16 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.045000000000000005
[09/26 09:17:23 visual_prompt]: Epoch 10 / 100: avg data time: 6.15e-02, avg batch time: 0.5066, average train loss: 5.0974
[09/26 09:17:24 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1675, average loss: 5.4180
[09/26 09:17:24 visual_prompt]: Classification results with val_vtab-sun397: top1: 3.00	top5: 12.50	
[09/26 09:17:25 visual_prompt]: Best epoch 10: best metric: 0.030
[09/26 09:17:25 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.05
[09/26 09:17:31 visual_prompt]: Epoch 11 / 100: avg data time: 6.44e-02, avg batch time: 0.5065, average train loss: 4.8920
[09/26 09:17:33 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1675, average loss: 5.2697
[09/26 09:17:33 visual_prompt]: Classification results with val_vtab-sun397: top1: 6.00	top5: 15.50	
[09/26 09:17:33 visual_prompt]: Best epoch 11: best metric: 0.060
[09/26 09:17:33 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0499847706754774
[09/26 09:17:40 visual_prompt]: Epoch 12 / 100: avg data time: 6.17e-02, avg batch time: 0.5051, average train loss: 4.6316
[09/26 09:17:42 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1675, average loss: 5.1365
[09/26 09:17:42 visual_prompt]: Classification results with val_vtab-sun397: top1: 8.50	top5: 18.00	
[09/26 09:17:42 visual_prompt]: Best epoch 12: best metric: 0.085
[09/26 09:17:42 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.04993910125649561
[09/26 09:17:49 visual_prompt]: Epoch 13 / 100: avg data time: 6.20e-02, avg batch time: 0.5059, average train loss: 4.4280
[09/26 09:17:50 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1677, average loss: 4.9980
[09/26 09:17:50 visual_prompt]: Classification results with val_vtab-sun397: top1: 9.00	top5: 22.00	
[09/26 09:17:50 visual_prompt]: Best epoch 13: best metric: 0.090
[09/26 09:17:50 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.049863047384206834
[09/26 09:17:57 visual_prompt]: Epoch 14 / 100: avg data time: 6.35e-02, avg batch time: 0.5061, average train loss: 4.2043
[09/26 09:17:59 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1675, average loss: 4.9174
[09/26 09:17:59 visual_prompt]: Classification results with val_vtab-sun397: top1: 8.50	top5: 24.00	
[09/26 09:17:59 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.04975670171853926
[09/26 09:18:06 visual_prompt]: Epoch 15 / 100: avg data time: 6.30e-02, avg batch time: 0.5069, average train loss: 3.9993
[09/26 09:18:07 visual_prompt]: Inference (val):avg data time: 4.67e-05, avg batch time: 0.1680, average loss: 4.8399
[09/26 09:18:07 visual_prompt]: Classification results with val_vtab-sun397: top1: 10.50	top5: 24.50	
[09/26 09:18:07 visual_prompt]: Best epoch 15: best metric: 0.105
[09/26 09:18:07 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.049620193825305206
[09/26 09:18:14 visual_prompt]: Epoch 16 / 100: avg data time: 5.82e-02, avg batch time: 0.5015, average train loss: 3.7905
[09/26 09:18:16 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1677, average loss: 4.7407
[09/26 09:18:16 visual_prompt]: Classification results with val_vtab-sun397: top1: 13.00	top5: 29.50	
[09/26 09:18:16 visual_prompt]: Best epoch 16: best metric: 0.130
[09/26 09:18:16 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.049453690018345146
[09/26 09:18:23 visual_prompt]: Epoch 17 / 100: avg data time: 5.57e-02, avg batch time: 0.4986, average train loss: 3.6311
[09/26 09:18:25 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1675, average loss: 4.7000
[09/26 09:18:25 visual_prompt]: Classification results with val_vtab-sun397: top1: 13.50	top5: 30.00	
[09/26 09:18:25 visual_prompt]: Best epoch 17: best metric: 0.135
[09/26 09:18:25 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.04925739315689991
[09/26 09:18:31 visual_prompt]: Epoch 18 / 100: avg data time: 6.25e-02, avg batch time: 0.5059, average train loss: 3.4491
[09/26 09:18:33 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1675, average loss: 4.5398
[09/26 09:18:33 visual_prompt]: Classification results with val_vtab-sun397: top1: 15.50	top5: 31.50	
[09/26 09:18:33 visual_prompt]: Best epoch 18: best metric: 0.155
[09/26 09:18:33 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.04903154239845797
[09/26 09:18:40 visual_prompt]: Epoch 19 / 100: avg data time: 6.39e-02, avg batch time: 0.5079, average train loss: 3.2836
[09/26 09:18:42 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1675, average loss: 4.4607
[09/26 09:18:42 visual_prompt]: Classification results with val_vtab-sun397: top1: 15.00	top5: 36.00	
[09/26 09:18:42 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.048776412907378844
[09/26 09:18:49 visual_prompt]: Epoch 20 / 100: avg data time: 6.10e-02, avg batch time: 0.5035, average train loss: 3.1242
[09/26 09:18:50 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1677, average loss: 4.4211
[09/26 09:18:50 visual_prompt]: Classification results with val_vtab-sun397: top1: 15.50	top5: 35.50	
[09/26 09:18:50 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.048492315519647715
[09/26 09:18:57 visual_prompt]: Epoch 21 / 100: avg data time: 6.07e-02, avg batch time: 0.5037, average train loss: 2.9841
[09/26 09:18:59 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1674, average loss: 4.3307
[09/26 09:18:59 visual_prompt]: Classification results with val_vtab-sun397: top1: 20.00	top5: 39.00	
[09/26 09:18:59 visual_prompt]: Best epoch 21: best metric: 0.200
[09/26 09:18:59 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.048179596364169686
[09/26 09:19:06 visual_prompt]: Epoch 22 / 100: avg data time: 4.96e-02, avg batch time: 0.4953, average train loss: 2.8767
[09/26 09:19:07 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1675, average loss: 4.2728
[09/26 09:19:07 visual_prompt]: Classification results with val_vtab-sun397: top1: 18.00	top5: 40.50	
[09/26 09:19:07 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.04783863644106502
[09/26 09:19:14 visual_prompt]: Epoch 23 / 100: avg data time: 5.76e-02, avg batch time: 0.5014, average train loss: 2.7457
[09/26 09:19:16 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1675, average loss: 4.2220
[09/26 09:19:16 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.00	top5: 39.50	
[09/26 09:19:16 visual_prompt]: Best epoch 23: best metric: 0.210
[09/26 09:19:16 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.047469851157479176
[09/26 09:19:23 visual_prompt]: Epoch 24 / 100: avg data time: 6.12e-02, avg batch time: 0.5045, average train loss: 2.6438
[09/26 09:19:24 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1675, average loss: 4.1900
[09/26 09:19:24 visual_prompt]: Classification results with val_vtab-sun397: top1: 20.50	top5: 42.50	
[09/26 09:19:24 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.047073689821473176
[09/26 09:19:31 visual_prompt]: Epoch 25 / 100: avg data time: 5.99e-02, avg batch time: 0.5030, average train loss: 2.5378
[09/26 09:19:33 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1675, average loss: 4.2423
[09/26 09:19:33 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.00	top5: 40.50	
[09/26 09:19:33 visual_prompt]: Best epoch 25: best metric: 0.220
[09/26 09:19:33 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.046650635094610975
[09/26 09:19:40 visual_prompt]: Epoch 26 / 100: avg data time: 6.12e-02, avg batch time: 0.5047, average train loss: 2.4653
[09/26 09:19:41 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1675, average loss: 4.1394
[09/26 09:19:41 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.50	top5: 44.50	
[09/26 09:19:41 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.04620120240391065
[09/26 09:19:48 visual_prompt]: Epoch 27 / 100: avg data time: 5.72e-02, avg batch time: 0.5010, average train loss: 2.3785
[09/26 09:19:50 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1672, average loss: 4.1315
[09/26 09:19:50 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.00	top5: 47.00	
[09/26 09:19:50 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.04572593931387604
[09/26 09:19:57 visual_prompt]: Epoch 28 / 100: avg data time: 5.98e-02, avg batch time: 0.5025, average train loss: 2.2901
[09/26 09:19:59 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1669, average loss: 4.0262
[09/26 09:19:59 visual_prompt]: Classification results with val_vtab-sun397: top1: 23.00	top5: 45.50	
[09/26 09:19:59 visual_prompt]: Best epoch 28: best metric: 0.230
[09/26 09:19:59 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.04522542485937369
[09/26 09:20:05 visual_prompt]: Epoch 29 / 100: avg data time: 6.43e-02, avg batch time: 0.5074, average train loss: 2.1904
[09/26 09:20:07 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1671, average loss: 4.0956
[09/26 09:20:07 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.00	top5: 48.50	
[09/26 09:20:07 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.04470026884016805
[09/26 09:20:14 visual_prompt]: Epoch 30 / 100: avg data time: 6.20e-02, avg batch time: 0.5054, average train loss: 2.1292
[09/26 09:20:16 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1671, average loss: 4.0696
[09/26 09:20:16 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.50	top5: 48.50	
[09/26 09:20:16 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.04415111107797445
[09/26 09:20:23 visual_prompt]: Epoch 31 / 100: avg data time: 6.83e-02, avg batch time: 0.5111, average train loss: 2.0711
[09/26 09:20:24 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1673, average loss: 4.0591
[09/26 09:20:24 visual_prompt]: Classification results with val_vtab-sun397: top1: 23.50	top5: 47.00	
[09/26 09:20:24 visual_prompt]: Best epoch 31: best metric: 0.235
[09/26 09:20:24 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.04357862063693486
[09/26 09:20:31 visual_prompt]: Epoch 32 / 100: avg data time: 6.25e-02, avg batch time: 0.5069, average train loss: 2.0129
[09/26 09:20:33 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1673, average loss: 4.0323
[09/26 09:20:33 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.00	top5: 49.00	
[09/26 09:20:33 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.04298349500846628
[09/26 09:20:40 visual_prompt]: Epoch 33 / 100: avg data time: 6.71e-02, avg batch time: 0.5113, average train loss: 1.9728
[09/26 09:20:42 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1676, average loss: 4.0727
[09/26 09:20:42 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.00	top5: 48.00	
[09/26 09:20:42 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.042366459261474934
[09/26 09:20:49 visual_prompt]: Epoch 34 / 100: avg data time: 6.30e-02, avg batch time: 0.5061, average train loss: 1.9649
[09/26 09:20:50 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1678, average loss: 4.0503
[09/26 09:20:50 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.50	top5: 47.50	
[09/26 09:20:50 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.04172826515897146
[09/26 09:20:57 visual_prompt]: Epoch 35 / 100: avg data time: 6.20e-02, avg batch time: 0.5051, average train loss: 1.9178
[09/26 09:20:59 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1673, average loss: 4.0918
[09/26 09:20:59 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.00	top5: 46.00	
[09/26 09:20:59 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.04106969024216348
[09/26 09:21:06 visual_prompt]: Epoch 36 / 100: avg data time: 6.09e-02, avg batch time: 0.5043, average train loss: 1.8843
[09/26 09:21:07 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1676, average loss: 4.0050
[09/26 09:21:07 visual_prompt]: Classification results with val_vtab-sun397: top1: 23.00	top5: 48.00	
[09/26 09:21:07 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.040391536883141455
[09/26 09:21:14 visual_prompt]: Epoch 37 / 100: avg data time: 6.80e-02, avg batch time: 0.5135, average train loss: 1.8246
[09/26 09:21:16 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.1680, average loss: 3.9640
[09/26 09:21:16 visual_prompt]: Classification results with val_vtab-sun397: top1: 24.50	top5: 51.00	
[09/26 09:21:16 visual_prompt]: Best epoch 37: best metric: 0.245
[09/26 09:21:16 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.03969463130731183
[09/26 09:21:23 visual_prompt]: Epoch 38 / 100: avg data time: 6.87e-02, avg batch time: 0.5114, average train loss: 1.7608
[09/26 09:21:25 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1672, average loss: 3.9867
[09/26 09:21:25 visual_prompt]: Classification results with val_vtab-sun397: top1: 24.00	top5: 50.00	
[09/26 09:21:25 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.03897982258676867
[09/26 09:21:32 visual_prompt]: Epoch 39 / 100: avg data time: 6.77e-02, avg batch time: 0.5117, average train loss: 1.7302
[09/26 09:21:33 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1670, average loss: 3.9743
[09/26 09:21:33 visual_prompt]: Classification results with val_vtab-sun397: top1: 25.00	top5: 51.50	
[09/26 09:21:33 visual_prompt]: Best epoch 39: best metric: 0.250
[09/26 09:21:33 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.03824798160583012
[09/26 09:21:40 visual_prompt]: Epoch 40 / 100: avg data time: 6.51e-02, avg batch time: 0.5084, average train loss: 1.6966
[09/26 09:21:42 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1676, average loss: 4.0198
[09/26 09:21:42 visual_prompt]: Classification results with val_vtab-sun397: top1: 23.00	top5: 49.00	
[09/26 09:21:42 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.037500000000000006
[09/26 09:21:49 visual_prompt]: Epoch 41 / 100: avg data time: 6.04e-02, avg batch time: 0.5035, average train loss: 1.6553
[09/26 09:21:51 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1675, average loss: 4.0026
[09/26 09:21:51 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.00	top5: 49.50	
[09/26 09:21:51 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.03673678906964727
[09/26 09:21:57 visual_prompt]: Epoch 42 / 100: avg data time: 6.20e-02, avg batch time: 0.5053, average train loss: 1.6377
[09/26 09:21:59 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1675, average loss: 4.0181
[09/26 09:21:59 visual_prompt]: Classification results with val_vtab-sun397: top1: 24.50	top5: 49.00	
[09/26 09:21:59 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.03595927866972694
[09/26 09:22:06 visual_prompt]: Epoch 43 / 100: avg data time: 6.15e-02, avg batch time: 0.5045, average train loss: 1.6055
[09/26 09:22:08 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1676, average loss: 3.9937
[09/26 09:22:08 visual_prompt]: Classification results with val_vtab-sun397: top1: 24.00	top5: 49.50	
[09/26 09:22:08 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.03516841607689501
[09/26 09:22:15 visual_prompt]: Epoch 44 / 100: avg data time: 6.37e-02, avg batch time: 0.5071, average train loss: 1.5769
[09/26 09:22:16 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1673, average loss: 4.0020
[09/26 09:22:16 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.00	top5: 50.00	
[09/26 09:22:16 visual_prompt]: Best epoch 44: best metric: 0.270
[09/26 09:22:16 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.0343651648353978
[09/26 09:22:23 visual_prompt]: Epoch 45 / 100: avg data time: 5.91e-02, avg batch time: 0.5032, average train loss: 1.5725
[09/26 09:22:25 visual_prompt]: Inference (val):avg data time: 4.98e-05, avg batch time: 0.1670, average loss: 4.0055
[09/26 09:22:25 visual_prompt]: Classification results with val_vtab-sun397: top1: 25.50	top5: 49.00	
[09/26 09:22:25 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.033550503583141725
[09/26 09:22:32 visual_prompt]: Epoch 46 / 100: avg data time: 6.50e-02, avg batch time: 0.5094, average train loss: 1.5507
[09/26 09:22:33 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1675, average loss: 4.0186
[09/26 09:22:33 visual_prompt]: Classification results with val_vtab-sun397: top1: 25.50	top5: 48.50	
[09/26 09:22:33 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.032725424859373686
[09/26 09:22:40 visual_prompt]: Epoch 47 / 100: avg data time: 4.92e-02, avg batch time: 0.4929, average train loss: 1.5244
[09/26 09:22:42 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1674, average loss: 4.0606
[09/26 09:22:42 visual_prompt]: Classification results with val_vtab-sun397: top1: 23.00	top5: 51.00	
[09/26 09:22:42 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.03189093389542498
[09/26 09:22:49 visual_prompt]: Epoch 48 / 100: avg data time: 5.65e-02, avg batch time: 0.5003, average train loss: 1.5069
[09/26 09:22:50 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1673, average loss: 4.0032
[09/26 09:22:50 visual_prompt]: Classification results with val_vtab-sun397: top1: 24.50	top5: 50.00	
[09/26 09:22:50 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.03104804738999169
[09/26 09:22:57 visual_prompt]: Epoch 49 / 100: avg data time: 5.82e-02, avg batch time: 0.5037, average train loss: 1.4868
[09/26 09:22:59 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1674, average loss: 3.9743
[09/26 09:22:59 visual_prompt]: Classification results with val_vtab-sun397: top1: 26.50	top5: 49.00	
[09/26 09:22:59 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.03019779227044398
[09/26 09:23:06 visual_prompt]: Epoch 50 / 100: avg data time: 6.51e-02, avg batch time: 0.5085, average train loss: 1.4855
[09/26 09:23:08 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1670, average loss: 3.9813
[09/26 09:23:08 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.00	top5: 52.50	
[09/26 09:23:08 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.029341204441673263
[09/26 09:23:15 visual_prompt]: Epoch 51 / 100: avg data time: 5.94e-02, avg batch time: 0.5051, average train loss: 1.4672
[09/26 09:23:16 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1670, average loss: 3.9865
[09/26 09:23:16 visual_prompt]: Classification results with val_vtab-sun397: top1: 25.00	top5: 49.50	
[09/26 09:23:16 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.028479327524001636
[09/26 09:23:23 visual_prompt]: Epoch 52 / 100: avg data time: 6.63e-02, avg batch time: 0.5099, average train loss: 1.4491
[09/26 09:23:25 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1672, average loss: 3.9369
[09/26 09:23:25 visual_prompt]: Classification results with val_vtab-sun397: top1: 26.50	top5: 51.50	
[09/26 09:23:25 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.02761321158169134
[09/26 09:23:32 visual_prompt]: Epoch 53 / 100: avg data time: 6.74e-02, avg batch time: 0.5111, average train loss: 1.4430
[09/26 09:23:34 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1678, average loss: 4.0063
[09/26 09:23:34 visual_prompt]: Classification results with val_vtab-sun397: top1: 24.00	top5: 50.00	
[09/26 09:23:34 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.02674391184360313
[09/26 09:23:40 visual_prompt]: Epoch 54 / 100: avg data time: 4.73e-02, avg batch time: 0.4915, average train loss: 1.4211
[09/26 09:23:42 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1675, average loss: 3.9578
[09/26 09:23:42 visual_prompt]: Classification results with val_vtab-sun397: top1: 24.50	top5: 51.50	
[09/26 09:23:42 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.02587248741756253
[09/26 09:23:49 visual_prompt]: Epoch 55 / 100: avg data time: 6.53e-02, avg batch time: 0.5094, average train loss: 1.3967
[09/26 09:23:51 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1671, average loss: 4.0126
[09/26 09:23:51 visual_prompt]: Classification results with val_vtab-sun397: top1: 25.50	top5: 52.00	
[09/26 09:23:51 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.025
[09/26 09:23:57 visual_prompt]: Epoch 56 / 100: avg data time: 6.31e-02, avg batch time: 0.5066, average train loss: 1.3746
[09/26 09:23:59 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1672, average loss: 3.9476
[09/26 09:23:59 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.50	top5: 52.00	
[09/26 09:23:59 visual_prompt]: Best epoch 56: best metric: 0.285
[09/26 09:23:59 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.024127512582437484
[09/26 09:24:06 visual_prompt]: Epoch 57 / 100: avg data time: 6.26e-02, avg batch time: 0.5064, average train loss: 1.3568
[09/26 09:24:08 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1673, average loss: 3.9770
[09/26 09:24:08 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.00	top5: 53.50	
[09/26 09:24:08 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.02325608815639687
[09/26 09:24:15 visual_prompt]: Epoch 58 / 100: avg data time: 5.58e-02, avg batch time: 0.5002, average train loss: 1.3457
[09/26 09:24:16 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1670, average loss: 3.9981
[09/26 09:24:16 visual_prompt]: Classification results with val_vtab-sun397: top1: 25.50	top5: 51.00	
[09/26 09:24:16 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.02238678841830867
[09/26 09:24:23 visual_prompt]: Epoch 59 / 100: avg data time: 6.50e-02, avg batch time: 0.5091, average train loss: 1.3377
[09/26 09:24:25 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1671, average loss: 4.0185
[09/26 09:24:25 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.50	top5: 50.50	
[09/26 09:24:25 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.02152067247599837
[09/26 09:24:32 visual_prompt]: Epoch 60 / 100: avg data time: 6.24e-02, avg batch time: 0.5056, average train loss: 1.3278
[09/26 09:24:33 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1671, average loss: 3.9844
[09/26 09:24:33 visual_prompt]: Classification results with val_vtab-sun397: top1: 26.00	top5: 51.50	
[09/26 09:24:33 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.020658795558326743
[09/26 09:24:40 visual_prompt]: Epoch 61 / 100: avg data time: 6.05e-02, avg batch time: 0.5053, average train loss: 1.3087
[09/26 09:24:42 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1676, average loss: 3.9688
[09/26 09:24:42 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.50	top5: 52.50	
[09/26 09:24:42 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.019802207729556022
[09/26 09:24:49 visual_prompt]: Epoch 62 / 100: avg data time: 6.04e-02, avg batch time: 0.5030, average train loss: 1.2974
[09/26 09:24:51 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1673, average loss: 3.9770
[09/26 09:24:51 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.50	top5: 51.00	
[09/26 09:24:51 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.018951952610008312
[09/26 09:24:58 visual_prompt]: Epoch 63 / 100: avg data time: 6.40e-02, avg batch time: 0.5075, average train loss: 1.2902
[09/26 09:24:59 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1675, average loss: 3.9703
[09/26 09:24:59 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.00	top5: 52.00	
[09/26 09:24:59 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.018109066104575022
[09/26 09:25:06 visual_prompt]: Epoch 64 / 100: avg data time: 6.39e-02, avg batch time: 0.5078, average train loss: 1.2832
[09/26 09:25:08 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1672, average loss: 3.9890
[09/26 09:25:08 visual_prompt]: Classification results with val_vtab-sun397: top1: 26.50	top5: 52.50	
[09/26 09:25:08 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.017274575140626316
[09/26 09:25:15 visual_prompt]: Epoch 65 / 100: avg data time: 6.39e-02, avg batch time: 0.5082, average train loss: 1.2793
[09/26 09:25:16 visual_prompt]: Inference (val):avg data time: 4.62e-05, avg batch time: 0.1672, average loss: 3.9492
[09/26 09:25:16 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.50	top5: 53.00	
[09/26 09:25:16 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.016449496416858285
[09/26 09:25:23 visual_prompt]: Epoch 66 / 100: avg data time: 6.66e-02, avg batch time: 0.5098, average train loss: 1.2720
[09/26 09:25:25 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1674, average loss: 3.9513
[09/26 09:25:25 visual_prompt]: Classification results with val_vtab-sun397: top1: 29.00	top5: 52.00	
[09/26 09:25:25 visual_prompt]: Best epoch 66: best metric: 0.290
[09/26 09:25:25 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.0156348351646022
[09/26 09:25:32 visual_prompt]: Epoch 67 / 100: avg data time: 6.25e-02, avg batch time: 0.5051, average train loss: 1.2675
[09/26 09:25:34 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1673, average loss: 3.9786
[09/26 09:25:34 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.50	top5: 50.00	
[09/26 09:25:34 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.014831583923105
[09/26 09:25:41 visual_prompt]: Epoch 68 / 100: avg data time: 6.33e-02, avg batch time: 0.5072, average train loss: 1.2607
[09/26 09:25:42 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1672, average loss: 3.9332
[09/26 09:25:42 visual_prompt]: Classification results with val_vtab-sun397: top1: 29.00	top5: 52.00	
[09/26 09:25:42 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.014040721330273063
[09/26 09:25:49 visual_prompt]: Epoch 69 / 100: avg data time: 6.31e-02, avg batch time: 0.5070, average train loss: 1.2559
[09/26 09:25:51 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1671, average loss: 3.9317
[09/26 09:25:51 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 52.50	
[09/26 09:25:51 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.013263210930352737
[09/26 09:25:58 visual_prompt]: Epoch 70 / 100: avg data time: 6.58e-02, avg batch time: 0.5099, average train loss: 1.2472
[09/26 09:25:59 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1674, average loss: 3.9540
[09/26 09:25:59 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.50	top5: 52.50	
[09/26 09:25:59 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.012500000000000006
[09/26 09:26:06 visual_prompt]: Epoch 71 / 100: avg data time: 6.18e-02, avg batch time: 0.5062, average train loss: 1.2402
[09/26 09:26:08 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1671, average loss: 3.9472
[09/26 09:26:08 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.50	top5: 52.50	
[09/26 09:26:08 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.01175201839416988
[09/26 09:26:15 visual_prompt]: Epoch 72 / 100: avg data time: 6.50e-02, avg batch time: 0.5087, average train loss: 1.2342
[09/26 09:26:17 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1673, average loss: 3.9488
[09/26 09:26:17 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.50	top5: 51.50	
[09/26 09:26:17 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.011020177413231334
[09/26 09:26:24 visual_prompt]: Epoch 73 / 100: avg data time: 6.52e-02, avg batch time: 0.5084, average train loss: 1.2318
[09/26 09:26:25 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1675, average loss: 3.9588
[09/26 09:26:25 visual_prompt]: Classification results with val_vtab-sun397: top1: 26.00	top5: 53.50	
[09/26 09:26:25 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.010305368692688175
[09/26 09:26:32 visual_prompt]: Epoch 74 / 100: avg data time: 6.26e-02, avg batch time: 0.5058, average train loss: 1.2241
[09/26 09:26:34 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1673, average loss: 3.9493
[09/26 09:26:34 visual_prompt]: Classification results with val_vtab-sun397: top1: 29.00	top5: 52.50	
[09/26 09:26:34 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.009608463116858543
[09/26 09:26:41 visual_prompt]: Epoch 75 / 100: avg data time: 5.77e-02, avg batch time: 0.5006, average train loss: 1.2191
[09/26 09:26:42 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1670, average loss: 3.9533
[09/26 09:26:42 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.50	top5: 52.50	
[09/26 09:26:42 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.008930309757836517
[09/26 09:26:49 visual_prompt]: Epoch 76 / 100: avg data time: 6.33e-02, avg batch time: 0.5066, average train loss: 1.2158
[09/26 09:26:51 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1675, average loss: 3.9445
[09/26 09:26:51 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.50	top5: 52.00	
[09/26 09:26:51 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.008271734841028553
[09/26 09:26:58 visual_prompt]: Epoch 77 / 100: avg data time: 6.61e-02, avg batch time: 0.5094, average train loss: 1.2082
[09/26 09:27:00 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1676, average loss: 3.9671
[09/26 09:27:00 visual_prompt]: Classification results with val_vtab-sun397: top1: 29.50	top5: 52.00	
[09/26 09:27:00 visual_prompt]: Best epoch 77: best metric: 0.295
[09/26 09:27:00 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.007633540738525066
[09/26 09:27:07 visual_prompt]: Epoch 78 / 100: avg data time: 6.73e-02, avg batch time: 0.5106, average train loss: 1.2054
[09/26 09:27:08 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1679, average loss: 3.9407
[09/26 09:27:08 visual_prompt]: Classification results with val_vtab-sun397: top1: 29.00	top5: 53.00	
[09/26 09:27:08 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.0070165049915337264
[09/26 09:27:15 visual_prompt]: Epoch 79 / 100: avg data time: 6.87e-02, avg batch time: 0.5118, average train loss: 1.2020
[09/26 09:27:17 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1678, average loss: 3.9404
[09/26 09:27:17 visual_prompt]: Classification results with val_vtab-sun397: top1: 27.50	top5: 53.00	
[09/26 09:27:17 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.006421379363065142
[09/26 09:27:24 visual_prompt]: Epoch 80 / 100: avg data time: 6.59e-02, avg batch time: 0.5089, average train loss: 1.1988
[09/26 09:27:26 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1673, average loss: 3.9450
[09/26 09:27:26 visual_prompt]: Classification results with val_vtab-sun397: top1: 29.00	top5: 53.50	
[09/26 09:27:26 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.005848888922025553
[09/26 09:27:33 visual_prompt]: Epoch 81 / 100: avg data time: 6.14e-02, avg batch time: 0.5045, average train loss: 1.1951
[09/26 09:27:34 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1676, average loss: 3.9363
[09/26 09:27:34 visual_prompt]: Classification results with val_vtab-sun397: top1: 29.50	top5: 52.50	
[09/26 09:27:34 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.005299731159831953
[09/26 09:27:41 visual_prompt]: Epoch 82 / 100: avg data time: 6.38e-02, avg batch time: 0.5085, average train loss: 1.1926
[09/26 09:27:43 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1676, average loss: 3.9536
[09/26 09:27:43 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.00	top5: 52.50	
[09/26 09:27:43 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.004774575140626317
[09/26 09:27:50 visual_prompt]: Epoch 83 / 100: avg data time: 6.32e-02, avg batch time: 0.5061, average train loss: 1.1884
[09/26 09:27:51 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1675, average loss: 3.9467
[09/26 09:27:51 visual_prompt]: Classification results with val_vtab-sun397: top1: 29.50	top5: 52.50	
[09/26 09:27:51 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.004274060686123959
[09/26 09:27:58 visual_prompt]: Epoch 84 / 100: avg data time: 6.89e-02, avg batch time: 0.5133, average train loss: 1.1862
[09/26 09:28:00 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1669, average loss: 3.9413
[09/26 09:28:00 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.50	top5: 53.00	
[09/26 09:28:00 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.003798797596089351
[09/26 09:28:07 visual_prompt]: Epoch 85 / 100: avg data time: 6.90e-02, avg batch time: 0.5117, average train loss: 1.1847
[09/26 09:28:09 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1671, average loss: 3.9408
[09/26 09:28:09 visual_prompt]: Classification results with val_vtab-sun397: top1: 29.00	top5: 52.00	
[09/26 09:28:09 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.0033493649053890325
[09/26 09:28:16 visual_prompt]: Epoch 86 / 100: avg data time: 6.63e-02, avg batch time: 0.5102, average train loss: 1.1828
[09/26 09:28:17 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1671, average loss: 3.9335
[09/26 09:28:17 visual_prompt]: Classification results with val_vtab-sun397: top1: 29.50	top5: 52.50	
[09/26 09:28:17 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.0029263101785268254
[09/26 09:28:24 visual_prompt]: Epoch 87 / 100: avg data time: 7.21e-02, avg batch time: 0.5150, average train loss: 1.1815
[09/26 09:28:26 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1671, average loss: 3.9310
[09/26 09:28:26 visual_prompt]: Classification results with val_vtab-sun397: top1: 29.00	top5: 52.50	
[09/26 09:28:26 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.00253014884252083
[09/26 09:28:33 visual_prompt]: Epoch 88 / 100: avg data time: 5.22e-02, avg batch time: 0.4961, average train loss: 1.1800
[09/26 09:28:34 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1676, average loss: 3.9444
[09/26 09:28:34 visual_prompt]: Classification results with val_vtab-sun397: top1: 29.00	top5: 52.00	
[09/26 09:28:34 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.0021613635589349755
[09/26 09:28:41 visual_prompt]: Epoch 89 / 100: avg data time: 4.91e-02, avg batch time: 0.4935, average train loss: 1.1769
[09/26 09:28:43 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1676, average loss: 3.9437
[09/26 09:28:43 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.50	top5: 52.00	
[09/26 09:28:43 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.0018204036358303172
[09/26 09:28:50 visual_prompt]: Epoch 90 / 100: avg data time: 6.15e-02, avg batch time: 0.5046, average train loss: 1.1761
[09/26 09:28:51 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1676, average loss: 3.9420
[09/26 09:28:51 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.50	top5: 52.00	
[09/26 09:28:51 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.0015076844803522923
[09/26 09:28:58 visual_prompt]: Epoch 91 / 100: avg data time: 5.53e-02, avg batch time: 0.4988, average train loss: 1.1758
[09/26 09:29:00 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1670, average loss: 3.9404
[09/26 09:29:00 visual_prompt]: Classification results with val_vtab-sun397: top1: 28.50	top5: 53.00	
[09/26 09:29:00 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.0012235870926211618
[09/26 09:29:07 visual_prompt]: Epoch 92 / 100: avg data time: 6.34e-02, avg batch time: 0.5065, average train loss: 1.1738
[09/26 09:29:09 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1673, average loss: 3.9404
[09/26 09:29:09 visual_prompt]: Classification results with val_vtab-sun397: top1: 29.00	top5: 53.00	
[09/26 09:29:09 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.0009684576015420277
[09/26 09:29:16 visual_prompt]: Epoch 93 / 100: avg data time: 6.67e-02, avg batch time: 0.5097, average train loss: 1.1742
[09/26 09:29:17 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1672, average loss: 3.9404
[09/26 09:29:17 visual_prompt]: Classification results with val_vtab-sun397: top1: 29.00	top5: 52.50	
[09/26 09:29:17 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.0007426068431000883
[09/26 09:29:24 visual_prompt]: Epoch 94 / 100: avg data time: 6.44e-02, avg batch time: 0.5077, average train loss: 1.1720
[09/26 09:29:26 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1673, average loss: 3.9418
[09/26 09:29:26 visual_prompt]: Classification results with val_vtab-sun397: top1: 29.50	top5: 52.50	
[09/26 09:29:26 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.0005463099816548578
[09/26 09:29:33 visual_prompt]: Epoch 95 / 100: avg data time: 6.95e-02, avg batch time: 0.5125, average train loss: 1.1724
[09/26 09:29:34 visual_prompt]: Inference (val):avg data time: 4.64e-05, avg batch time: 0.1672, average loss: 3.9429
[09/26 09:29:34 visual_prompt]: Classification results with val_vtab-sun397: top1: 29.50	top5: 52.50	
[09/26 09:29:34 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.00037980617469479954
[09/26 09:29:41 visual_prompt]: Epoch 96 / 100: avg data time: 5.99e-02, avg batch time: 0.5048, average train loss: 1.1720
[09/26 09:29:43 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1669, average loss: 3.9430
[09/26 09:29:43 visual_prompt]: Classification results with val_vtab-sun397: top1: 29.50	top5: 53.00	
[09/26 09:29:43 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.00024329828146074097
[09/26 09:29:50 visual_prompt]: Epoch 97 / 100: avg data time: 5.93e-02, avg batch time: 0.5016, average train loss: 1.1703
[09/26 09:29:52 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1670, average loss: 3.9430
[09/26 09:29:52 visual_prompt]: Classification results with val_vtab-sun397: top1: 29.50	top5: 52.50	
[09/26 09:29:52 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.00013695261579316776
[09/26 09:29:59 visual_prompt]: Epoch 98 / 100: avg data time: 5.93e-02, avg batch time: 0.5026, average train loss: 1.1703
[09/26 09:30:00 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1675, average loss: 3.9417
[09/26 09:30:00 visual_prompt]: Classification results with val_vtab-sun397: top1: 29.50	top5: 52.50	
[09/26 09:30:00 visual_prompt]: Training 99 / 100 epoch, with learning rate 6.089874350439506e-05
[09/26 09:30:07 visual_prompt]: Epoch 99 / 100: avg data time: 6.31e-02, avg batch time: 0.5066, average train loss: 1.1697
[09/26 09:30:09 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1678, average loss: 3.9414
[09/26 09:30:09 visual_prompt]: Classification results with val_vtab-sun397: top1: 29.50	top5: 52.50	
[09/26 09:30:09 visual_prompt]: Training 100 / 100 epoch, with learning rate 1.5229324522605948e-05
[09/26 09:30:16 visual_prompt]: Epoch 100 / 100: avg data time: 6.26e-02, avg batch time: 0.5058, average train loss: 1.1712
[09/26 09:30:17 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1680, average loss: 3.9413
[09/26 09:30:17 visual_prompt]: Classification results with val_vtab-sun397: top1: 29.50	top5: 52.50	
[09/26 09:30:17 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 09:30:17 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              0
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 09:30:17 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-sun397', 'DATA.NUMBER_CLASSES', '397', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 09:30:17 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 09:30:17 visual_prompt]: Training with config:
[09/26 09:30:17 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-sun397/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.05_wd0.001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 0.05, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-sun397', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 397, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 09:30:17 visual_prompt]: Loading training data...
[09/26 09:30:17 visual_prompt]: Constructing vtab-sun397 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split train[:800], from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/26 09:30:19 visual_prompt]: Number of images: 800
[09/26 09:30:19 visual_prompt]: Number of classes: 309 / 397
[09/26 09:30:19 visual_prompt]: Loading validation data...
[09/26 09:30:19 visual_prompt]: Constructing vtab-sun397 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split validation[:200], from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/26 09:30:19 visual_prompt]: Number of images: 200
[09/26 09:30:19 visual_prompt]: Number of classes: 136 / 397
[09/26 09:30:19 visual_prompt]: Constructing models...
[09/26 09:30:22 visual_prompt]: Total Parameters: 86564749	 Gradient Parameters: 766093
[09/26 09:30:22 visual_prompt]: tuned percent:0.885
[09/26 09:30:22 visual_prompt]: Device used for model: 0
[09/26 09:30:22 visual_prompt]: Setting up Evaluator...
[09/26 09:30:22 visual_prompt]: Setting up Trainer...
[09/26 09:30:22 visual_prompt]: 	Setting up the optimizer...
[09/26 09:30:22 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 09:30:29 visual_prompt]: Epoch 1 / 100: avg data time: 6.54e-02, avg batch time: 0.5102, average train loss: 5.9885
[09/26 09:30:30 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1667, average loss: 6.0097
[09/26 09:30:30 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/26 09:30:30 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.005000000000000001
[09/26 09:30:37 visual_prompt]: Epoch 2 / 100: avg data time: 5.55e-02, avg batch time: 0.4978, average train loss: 5.9816
[09/26 09:30:39 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1665, average loss: 5.9983
[09/26 09:30:39 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.50	
[09/26 09:30:39 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.010000000000000002
[09/26 09:30:46 visual_prompt]: Epoch 3 / 100: avg data time: 6.08e-02, avg batch time: 0.5041, average train loss: 5.9577
[09/26 09:30:47 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1674, average loss: 5.9734
[09/26 09:30:47 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 2.00	
[09/26 09:30:47 visual_prompt]: Best epoch 3: best metric: 0.005
[09/26 09:30:47 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.015
[09/26 09:30:54 visual_prompt]: Epoch 4 / 100: avg data time: 5.87e-02, avg batch time: 0.5009, average train loss: 5.9066
[09/26 09:30:56 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1672, average loss: 5.9355
[09/26 09:30:56 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.00	
[09/26 09:30:56 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.020000000000000004
[09/26 09:31:03 visual_prompt]: Epoch 5 / 100: avg data time: 5.78e-02, avg batch time: 0.5011, average train loss: 5.8207
[09/26 09:31:04 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1675, average loss: 5.8723
[09/26 09:31:04 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 09:31:04 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.025
[09/26 09:31:11 visual_prompt]: Epoch 6 / 100: avg data time: 6.88e-02, avg batch time: 0.5136, average train loss: 5.7004
[09/26 09:31:13 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1670, average loss: 5.8252
[09/26 09:31:13 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.50	
[09/26 09:31:13 visual_prompt]: Best epoch 6: best metric: 0.010
[09/26 09:31:13 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.03
[09/26 09:31:20 visual_prompt]: Epoch 7 / 100: avg data time: 6.41e-02, avg batch time: 0.5064, average train loss: 5.5738
[09/26 09:31:22 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1672, average loss: 5.7903
[09/26 09:31:22 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 5.50	
[09/26 09:31:22 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.034999999999999996
[09/26 09:31:29 visual_prompt]: Epoch 8 / 100: avg data time: 6.69e-02, avg batch time: 0.5094, average train loss: 5.4911
[09/26 09:31:30 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1674, average loss: 5.6920
[09/26 09:31:30 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.00	top5: 8.00	
[09/26 09:31:30 visual_prompt]: Best epoch 8: best metric: 0.020
[09/26 09:31:30 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.04000000000000001
[09/26 09:31:37 visual_prompt]: Epoch 9 / 100: avg data time: 5.07e-02, avg batch time: 0.4954, average train loss: 5.3078
[09/26 09:31:39 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1677, average loss: 5.5551
[09/26 09:31:39 visual_prompt]: Classification results with val_vtab-sun397: top1: 3.00	top5: 10.00	
[09/26 09:31:39 visual_prompt]: Best epoch 9: best metric: 0.030
[09/26 09:31:39 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.045000000000000005
[09/26 09:31:46 visual_prompt]: Epoch 10 / 100: avg data time: 6.14e-02, avg batch time: 0.5036, average train loss: 5.0931
[09/26 09:31:47 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1675, average loss: 5.4291
[09/26 09:31:47 visual_prompt]: Classification results with val_vtab-sun397: top1: 4.50	top5: 14.50	
[09/26 09:31:47 visual_prompt]: Best epoch 10: best metric: 0.045
[09/26 09:31:47 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.05
[09/26 09:31:54 visual_prompt]: Epoch 11 / 100: avg data time: 5.95e-02, avg batch time: 0.5032, average train loss: 4.8672
[09/26 09:31:56 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1676, average loss: 5.2679
[09/26 09:31:56 visual_prompt]: Classification results with val_vtab-sun397: top1: 7.50	top5: 17.50	
[09/26 09:31:56 visual_prompt]: Best epoch 11: best metric: 0.075
[09/26 09:31:56 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0499847706754774
[09/26 09:32:03 visual_prompt]: Epoch 12 / 100: avg data time: 5.38e-02, avg batch time: 0.4996, average train loss: 4.5944
[09/26 09:32:04 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1671, average loss: 5.1143
[09/26 09:32:04 visual_prompt]: Classification results with val_vtab-sun397: top1: 8.00	top5: 18.50	
[09/26 09:32:04 visual_prompt]: Best epoch 12: best metric: 0.080
[09/26 09:32:04 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.04993910125649561
[09/26 09:32:11 visual_prompt]: Epoch 13 / 100: avg data time: 6.21e-02, avg batch time: 0.5049, average train loss: 4.3308
[09/26 09:32:13 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1676, average loss: 4.9516
[09/26 09:32:13 visual_prompt]: Classification results with val_vtab-sun397: top1: 9.00	top5: 22.50	
[09/26 09:32:13 visual_prompt]: Best epoch 13: best metric: 0.090
[09/26 09:32:13 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.049863047384206834
[09/26 09:32:20 visual_prompt]: Epoch 14 / 100: avg data time: 7.11e-02, avg batch time: 0.5144, average train loss: 4.0680
[09/26 09:32:22 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1673, average loss: 4.8806
[09/26 09:32:22 visual_prompt]: Classification results with val_vtab-sun397: top1: 11.50	top5: 25.00	
[09/26 09:32:22 visual_prompt]: Best epoch 14: best metric: 0.115
[09/26 09:32:22 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.04975670171853926
[09/26 09:32:28 visual_prompt]: Epoch 15 / 100: avg data time: 5.10e-02, avg batch time: 0.4942, average train loss: 3.8129
[09/26 09:32:30 visual_prompt]: Inference (val):avg data time: 4.00e-05, avg batch time: 0.1675, average loss: 4.7629
[09/26 09:32:30 visual_prompt]: Classification results with val_vtab-sun397: top1: 10.00	top5: 29.00	
[09/26 09:32:30 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.049620193825305206
[09/26 09:32:37 visual_prompt]: Epoch 16 / 100: avg data time: 6.67e-02, avg batch time: 0.5097, average train loss: 3.5765
[09/26 09:32:39 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.1675, average loss: 4.6564
[09/26 09:32:39 visual_prompt]: Classification results with val_vtab-sun397: top1: 12.00	top5: 31.50	
[09/26 09:32:39 visual_prompt]: Best epoch 16: best metric: 0.120
[09/26 09:32:39 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.049453690018345146
[09/26 09:32:46 visual_prompt]: Epoch 17 / 100: avg data time: 6.62e-02, avg batch time: 0.5098, average train loss: 3.3166
[09/26 09:32:47 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1674, average loss: 4.5475
[09/26 09:32:47 visual_prompt]: Classification results with val_vtab-sun397: top1: 14.50	top5: 32.00	
[09/26 09:32:47 visual_prompt]: Best epoch 17: best metric: 0.145
[09/26 09:32:47 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.04925739315689991
[09/26 09:32:54 visual_prompt]: Epoch 18 / 100: avg data time: 5.35e-02, avg batch time: 0.4976, average train loss: 3.0769
[09/26 09:32:56 visual_prompt]: Inference (val):avg data time: 4.22e-05, avg batch time: 0.1676, average loss: 4.5254
[09/26 09:32:56 visual_prompt]: Classification results with val_vtab-sun397: top1: 13.00	top5: 32.50	
[09/26 09:32:56 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.04903154239845797
[09/26 09:33:03 visual_prompt]: Epoch 19 / 100: avg data time: 6.78e-02, avg batch time: 0.5108, average train loss: 2.8452
[09/26 09:33:04 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1677, average loss: 4.3806
[09/26 09:33:04 visual_prompt]: Classification results with val_vtab-sun397: top1: 18.50	top5: 34.50	
[09/26 09:33:04 visual_prompt]: Best epoch 19: best metric: 0.185
[09/26 09:33:04 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.048776412907378844
[09/26 09:33:11 visual_prompt]: Epoch 20 / 100: avg data time: 6.87e-02, avg batch time: 0.5112, average train loss: 2.6322
[09/26 09:33:13 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1677, average loss: 4.3515
[09/26 09:33:13 visual_prompt]: Classification results with val_vtab-sun397: top1: 18.00	top5: 38.00	
[09/26 09:33:13 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.048492315519647715
[09/26 09:33:20 visual_prompt]: Epoch 21 / 100: avg data time: 6.23e-02, avg batch time: 0.5047, average train loss: 2.4402
[09/26 09:33:22 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1670, average loss: 4.2623
[09/26 09:33:22 visual_prompt]: Classification results with val_vtab-sun397: top1: 18.00	top5: 39.50	
[09/26 09:33:22 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.048179596364169686
[09/26 09:33:29 visual_prompt]: Epoch 22 / 100: avg data time: 6.15e-02, avg batch time: 0.5052, average train loss: 2.2207
[09/26 09:33:30 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1668, average loss: 4.2943
[09/26 09:33:30 visual_prompt]: Classification results with val_vtab-sun397: top1: 17.00	top5: 39.00	
[09/26 09:33:30 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.04783863644106502
[09/26 09:33:37 visual_prompt]: Epoch 23 / 100: avg data time: 6.31e-02, avg batch time: 0.5073, average train loss: 2.0242
[09/26 09:33:39 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1670, average loss: 4.2703
[09/26 09:33:39 visual_prompt]: Classification results with val_vtab-sun397: top1: 17.50	top5: 41.00	
[09/26 09:33:39 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.047469851157479176
[09/26 09:33:46 visual_prompt]: Epoch 24 / 100: avg data time: 6.14e-02, avg batch time: 0.5046, average train loss: 1.8948
[09/26 09:33:47 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1676, average loss: 4.2147
[09/26 09:33:47 visual_prompt]: Classification results with val_vtab-sun397: top1: 16.50	top5: 40.50	
[09/26 09:33:47 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.047073689821473176
[09/26 09:33:54 visual_prompt]: Epoch 25 / 100: avg data time: 6.24e-02, avg batch time: 0.5059, average train loss: 1.7280
[09/26 09:33:56 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1676, average loss: 4.1978
[09/26 09:33:56 visual_prompt]: Classification results with val_vtab-sun397: top1: 17.00	top5: 42.00	
[09/26 09:33:56 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.046650635094610975
[09/26 09:34:03 visual_prompt]: Epoch 26 / 100: avg data time: 5.99e-02, avg batch time: 0.5036, average train loss: 1.6112
[09/26 09:34:05 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1671, average loss: 4.1821
[09/26 09:34:05 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.50	top5: 44.00	
[09/26 09:34:05 visual_prompt]: Best epoch 26: best metric: 0.215
[09/26 09:34:05 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.04620120240391065
[09/26 09:34:11 visual_prompt]: Epoch 27 / 100: avg data time: 5.14e-02, avg batch time: 0.4966, average train loss: 1.4823
[09/26 09:34:13 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1674, average loss: 4.0592
[09/26 09:34:13 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.50	top5: 45.00	
[09/26 09:34:13 visual_prompt]: Best epoch 27: best metric: 0.225
[09/26 09:34:13 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.04572593931387604
[09/26 09:34:20 visual_prompt]: Epoch 28 / 100: avg data time: 6.35e-02, avg batch time: 0.5076, average train loss: 1.3600
[09/26 09:34:22 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1673, average loss: 4.1007
[09/26 09:34:22 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.50	top5: 45.00	
[09/26 09:34:22 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.04522542485937369
[09/26 09:34:29 visual_prompt]: Epoch 29 / 100: avg data time: 6.54e-02, avg batch time: 0.5102, average train loss: 1.2445
[09/26 09:34:30 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1670, average loss: 4.0468
[09/26 09:34:30 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.00	top5: 45.50	
[09/26 09:34:30 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.04470026884016805
[09/26 09:34:37 visual_prompt]: Epoch 30 / 100: avg data time: 5.69e-02, avg batch time: 0.5001, average train loss: 1.1371
[09/26 09:34:39 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1671, average loss: 4.0884
[09/26 09:34:39 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.00	top5: 45.50	
[09/26 09:34:39 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.04415111107797445
[09/26 09:34:46 visual_prompt]: Epoch 31 / 100: avg data time: 6.57e-02, avg batch time: 0.5080, average train loss: 1.0506
[09/26 09:34:47 visual_prompt]: Inference (val):avg data time: 4.17e-05, avg batch time: 0.1673, average loss: 4.0593
[09/26 09:34:47 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.00	top5: 42.50	
[09/26 09:34:47 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.04357862063693486
[09/26 09:34:54 visual_prompt]: Epoch 32 / 100: avg data time: 6.07e-02, avg batch time: 0.5031, average train loss: 0.9621
[09/26 09:34:56 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1676, average loss: 4.0964
[09/26 09:34:56 visual_prompt]: Classification results with val_vtab-sun397: top1: 23.50	top5: 44.00	
[09/26 09:34:56 visual_prompt]: Best epoch 32: best metric: 0.235
[09/26 09:34:56 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.04298349500846628
[09/26 09:35:03 visual_prompt]: Epoch 33 / 100: avg data time: 6.44e-02, avg batch time: 0.5077, average train loss: 0.9103
[09/26 09:35:05 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1672, average loss: 4.0589
[09/26 09:35:05 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.50	top5: 44.50	
[09/26 09:35:05 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.042366459261474934
[09/26 09:35:12 visual_prompt]: Epoch 34 / 100: avg data time: 6.26e-02, avg batch time: 0.5071, average train loss: 0.8444
[09/26 09:35:13 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1672, average loss: 4.0057
[09/26 09:35:13 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.50	top5: 48.00	
[09/26 09:35:13 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.04172826515897146
[09/26 09:35:20 visual_prompt]: Epoch 35 / 100: avg data time: 6.21e-02, avg batch time: 0.5047, average train loss: 0.7904
[09/26 09:35:22 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1670, average loss: 4.0271
[09/26 09:35:22 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.00	top5: 46.00	
[09/26 09:35:22 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.04106969024216348
[09/26 09:35:29 visual_prompt]: Epoch 36 / 100: avg data time: 7.16e-02, avg batch time: 0.5139, average train loss: 0.7312
[09/26 09:35:31 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1672, average loss: 4.0398
[09/26 09:35:31 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.00	top5: 46.50	
[09/26 09:35:31 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.040391536883141455
[09/26 09:35:37 visual_prompt]: Epoch 37 / 100: avg data time: 5.97e-02, avg batch time: 0.5032, average train loss: 0.6891
[09/26 09:35:39 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1674, average loss: 4.0092
[09/26 09:35:39 visual_prompt]: Classification results with val_vtab-sun397: top1: 19.50	top5: 46.00	
[09/26 09:35:39 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.03969463130731183
[09/26 09:35:46 visual_prompt]: Epoch 38 / 100: avg data time: 6.51e-02, avg batch time: 0.5079, average train loss: 0.6435
[09/26 09:35:48 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.1677, average loss: 4.0362
[09/26 09:35:48 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.50	top5: 47.50	
[09/26 09:35:48 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.03897982258676867
[09/26 09:35:55 visual_prompt]: Epoch 39 / 100: avg data time: 6.07e-02, avg batch time: 0.5039, average train loss: 0.6039
[09/26 09:35:56 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1676, average loss: 4.0456
[09/26 09:35:56 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.50	top5: 46.50	
[09/26 09:35:56 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.03824798160583012
[09/26 09:36:03 visual_prompt]: Epoch 40 / 100: avg data time: 6.84e-02, avg batch time: 0.5113, average train loss: 0.5734
[09/26 09:36:05 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1672, average loss: 4.0472
[09/26 09:36:05 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.50	top5: 46.50	
[09/26 09:36:05 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.037500000000000006
[09/26 09:36:12 visual_prompt]: Epoch 41 / 100: avg data time: 6.39e-02, avg batch time: 0.5065, average train loss: 0.5374
[09/26 09:36:13 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1675, average loss: 3.9754
[09/26 09:36:13 visual_prompt]: Classification results with val_vtab-sun397: top1: 24.00	top5: 47.00	
[09/26 09:36:13 visual_prompt]: Best epoch 41: best metric: 0.240
[09/26 09:36:13 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.03673678906964727
[09/26 09:36:20 visual_prompt]: Epoch 42 / 100: avg data time: 6.20e-02, avg batch time: 0.5046, average train loss: 0.5102
[09/26 09:36:22 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1671, average loss: 4.0306
[09/26 09:36:22 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.00	top5: 46.50	
[09/26 09:36:22 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.03595927866972694
[09/26 09:36:29 visual_prompt]: Epoch 43 / 100: avg data time: 5.94e-02, avg batch time: 0.5057, average train loss: 0.4815
[09/26 09:36:31 visual_prompt]: Inference (val):avg data time: 3.49e-05, avg batch time: 0.1670, average loss: 4.0592
[09/26 09:36:31 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.50	top5: 45.50	
[09/26 09:36:31 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.03516841607689501
[09/26 09:36:37 visual_prompt]: Epoch 44 / 100: avg data time: 6.34e-02, avg batch time: 0.5067, average train loss: 0.4604
[09/26 09:36:39 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1676, average loss: 4.0561
[09/26 09:36:39 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.50	top5: 44.50	
[09/26 09:36:39 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.0343651648353978
[09/26 09:36:46 visual_prompt]: Epoch 45 / 100: avg data time: 6.49e-02, avg batch time: 0.5097, average train loss: 0.4337
[09/26 09:36:48 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1678, average loss: 4.0295
[09/26 09:36:48 visual_prompt]: Classification results with val_vtab-sun397: top1: 19.50	top5: 46.50	
[09/26 09:36:48 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.033550503583141725
[09/26 09:36:55 visual_prompt]: Epoch 46 / 100: avg data time: 5.03e-02, avg batch time: 0.4936, average train loss: 0.4181
[09/26 09:36:56 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1669, average loss: 4.0154
[09/26 09:36:56 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.00	top5: 46.50	
[09/26 09:36:56 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.032725424859373686
[09/26 09:37:03 visual_prompt]: Epoch 47 / 100: avg data time: 6.13e-02, avg batch time: 0.5051, average train loss: 0.4003
[09/26 09:37:05 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1679, average loss: 4.0015
[09/26 09:37:05 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.50	top5: 46.00	
[09/26 09:37:05 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.03189093389542498
[09/26 09:37:12 visual_prompt]: Epoch 48 / 100: avg data time: 6.29e-02, avg batch time: 0.5058, average train loss: 0.3831
[09/26 09:37:13 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1677, average loss: 4.0034
[09/26 09:37:13 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.00	top5: 45.50	
[09/26 09:37:13 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.03104804738999169
[09/26 09:37:20 visual_prompt]: Epoch 49 / 100: avg data time: 6.55e-02, avg batch time: 0.5087, average train loss: 0.3691
[09/26 09:37:22 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1674, average loss: 4.0140
[09/26 09:37:22 visual_prompt]: Classification results with val_vtab-sun397: top1: 20.50	top5: 43.50	
[09/26 09:37:22 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.03019779227044398
[09/26 09:37:29 visual_prompt]: Epoch 50 / 100: avg data time: 5.99e-02, avg batch time: 0.5037, average train loss: 0.3563
[09/26 09:37:30 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1677, average loss: 4.0201
[09/26 09:37:30 visual_prompt]: Classification results with val_vtab-sun397: top1: 20.00	top5: 45.00	
[09/26 09:37:30 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.029341204441673263
[09/26 09:37:37 visual_prompt]: Epoch 51 / 100: avg data time: 6.12e-02, avg batch time: 0.5041, average train loss: 0.3452
[09/26 09:37:39 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1675, average loss: 3.9928
[09/26 09:37:39 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.50	top5: 44.50	
[09/26 09:37:39 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.028479327524001636
[09/26 09:37:46 visual_prompt]: Epoch 52 / 100: avg data time: 5.23e-02, avg batch time: 0.4966, average train loss: 0.3331
[09/26 09:37:47 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1676, average loss: 4.0036
[09/26 09:37:47 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.50	top5: 46.00	
[09/26 09:37:47 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.02761321158169134
[09/26 09:37:54 visual_prompt]: Epoch 53 / 100: avg data time: 6.32e-02, avg batch time: 0.5065, average train loss: 0.3255
[09/26 09:37:56 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1671, average loss: 3.9789
[09/26 09:37:56 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.50	top5: 45.00	
[09/26 09:37:56 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.02674391184360313
[09/26 09:38:03 visual_prompt]: Epoch 54 / 100: avg data time: 6.38e-02, avg batch time: 0.5078, average train loss: 0.3122
[09/26 09:38:05 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1669, average loss: 4.0120
[09/26 09:38:05 visual_prompt]: Classification results with val_vtab-sun397: top1: 20.50	top5: 44.50	
[09/26 09:38:05 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.02587248741756253
[09/26 09:38:12 visual_prompt]: Epoch 55 / 100: avg data time: 6.60e-02, avg batch time: 0.5085, average train loss: 0.3047
[09/26 09:38:13 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1676, average loss: 3.9842
[09/26 09:38:13 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.00	top5: 45.00	
[09/26 09:38:13 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.025
[09/26 09:38:20 visual_prompt]: Epoch 56 / 100: avg data time: 5.82e-02, avg batch time: 0.5030, average train loss: 0.2973
[09/26 09:38:22 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1672, average loss: 4.0082
[09/26 09:38:22 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.00	top5: 44.00	
[09/26 09:38:22 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.024127512582437484
[09/26 09:38:29 visual_prompt]: Epoch 57 / 100: avg data time: 5.44e-02, avg batch time: 0.4985, average train loss: 0.2890
[09/26 09:38:30 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1674, average loss: 3.9927
[09/26 09:38:30 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.00	top5: 45.00	
[09/26 09:38:30 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.02325608815639687
[09/26 09:38:37 visual_prompt]: Epoch 58 / 100: avg data time: 5.99e-02, avg batch time: 0.5030, average train loss: 0.2822
[09/26 09:38:39 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1673, average loss: 3.9861
[09/26 09:38:39 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.50	top5: 47.00	
[09/26 09:38:39 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.02238678841830867
[09/26 09:38:46 visual_prompt]: Epoch 59 / 100: avg data time: 5.53e-02, avg batch time: 0.4985, average train loss: 0.2767
[09/26 09:38:47 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1671, average loss: 3.9906
[09/26 09:38:47 visual_prompt]: Classification results with val_vtab-sun397: top1: 20.50	top5: 46.50	
[09/26 09:38:47 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.02152067247599837
[09/26 09:38:54 visual_prompt]: Epoch 60 / 100: avg data time: 6.47e-02, avg batch time: 0.5070, average train loss: 0.2721
[09/26 09:38:56 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1677, average loss: 4.0014
[09/26 09:38:56 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.50	top5: 44.50	
[09/26 09:38:56 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.020658795558326743
[09/26 09:39:03 visual_prompt]: Epoch 61 / 100: avg data time: 5.50e-02, avg batch time: 0.4989, average train loss: 0.2668
[09/26 09:39:04 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1674, average loss: 3.9917
[09/26 09:39:04 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.00	top5: 45.00	
[09/26 09:39:04 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.019802207729556022
[09/26 09:39:11 visual_prompt]: Epoch 62 / 100: avg data time: 6.07e-02, avg batch time: 0.5050, average train loss: 0.2631
[09/26 09:39:13 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1668, average loss: 4.0077
[09/26 09:39:13 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.50	top5: 45.00	
[09/26 09:39:13 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.018951952610008312
[09/26 09:39:20 visual_prompt]: Epoch 63 / 100: avg data time: 6.50e-02, avg batch time: 0.5091, average train loss: 0.2563
[09/26 09:39:22 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1676, average loss: 3.9961
[09/26 09:39:22 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.50	top5: 43.50	
[09/26 09:39:22 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.018109066104575022
[09/26 09:39:29 visual_prompt]: Epoch 64 / 100: avg data time: 6.12e-02, avg batch time: 0.5047, average train loss: 0.2538
[09/26 09:39:30 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1668, average loss: 3.9907
[09/26 09:39:30 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.00	top5: 45.50	
[09/26 09:39:30 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.017274575140626316
[09/26 09:39:37 visual_prompt]: Epoch 65 / 100: avg data time: 6.25e-02, avg batch time: 0.5063, average train loss: 0.2515
[09/26 09:39:39 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1669, average loss: 3.9939
[09/26 09:39:39 visual_prompt]: Classification results with val_vtab-sun397: top1: 19.50	top5: 46.00	
[09/26 09:39:39 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.016449496416858285
[09/26 09:39:46 visual_prompt]: Epoch 66 / 100: avg data time: 5.97e-02, avg batch time: 0.5036, average train loss: 0.2448
[09/26 09:39:47 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1669, average loss: 4.0132
[09/26 09:39:47 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.50	top5: 44.50	
[09/26 09:39:47 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.0156348351646022
[09/26 09:39:54 visual_prompt]: Epoch 67 / 100: avg data time: 6.13e-02, avg batch time: 0.5048, average train loss: 0.2411
[09/26 09:39:56 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1670, average loss: 3.9907
[09/26 09:39:56 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.50	top5: 46.50	
[09/26 09:39:56 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.014831583923105
[09/26 09:40:03 visual_prompt]: Epoch 68 / 100: avg data time: 6.20e-02, avg batch time: 0.5050, average train loss: 0.2415
[09/26 09:40:05 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1668, average loss: 3.9928
[09/26 09:40:05 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.50	top5: 46.00	
[09/26 09:40:05 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.014040721330273063
[09/26 09:40:11 visual_prompt]: Epoch 69 / 100: avg data time: 5.63e-02, avg batch time: 0.5005, average train loss: 0.2395
[09/26 09:40:13 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1670, average loss: 3.9931
[09/26 09:40:13 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.00	top5: 45.50	
[09/26 09:40:13 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.013263210930352737
[09/26 09:40:20 visual_prompt]: Epoch 70 / 100: avg data time: 5.84e-02, avg batch time: 0.5010, average train loss: 0.2371
[09/26 09:40:22 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1671, average loss: 3.9966
[09/26 09:40:22 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.50	top5: 46.50	
[09/26 09:40:22 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.012500000000000006
[09/26 09:40:29 visual_prompt]: Epoch 71 / 100: avg data time: 6.45e-02, avg batch time: 0.5090, average train loss: 0.2333
[09/26 09:40:30 visual_prompt]: Inference (val):avg data time: 4.07e-05, avg batch time: 0.1670, average loss: 4.0088
[09/26 09:40:30 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.50	top5: 45.00	
[09/26 09:40:30 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.01175201839416988
[09/26 09:40:37 visual_prompt]: Epoch 72 / 100: avg data time: 6.72e-02, avg batch time: 0.5107, average train loss: 0.2323
[09/26 09:40:39 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1669, average loss: 3.9939
[09/26 09:40:39 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.00	top5: 46.00	
[09/26 09:40:39 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.011020177413231334
[09/26 09:40:46 visual_prompt]: Epoch 73 / 100: avg data time: 5.46e-02, avg batch time: 0.4984, average train loss: 0.2281
[09/26 09:40:47 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1669, average loss: 3.9987
[09/26 09:40:47 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.00	top5: 45.50	
[09/26 09:40:47 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.010305368692688175
[09/26 09:40:54 visual_prompt]: Epoch 74 / 100: avg data time: 6.37e-02, avg batch time: 0.5068, average train loss: 0.2270
[09/26 09:40:56 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1667, average loss: 4.0085
[09/26 09:40:56 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.50	top5: 45.00	
[09/26 09:40:56 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.009608463116858543
[09/26 09:41:03 visual_prompt]: Epoch 75 / 100: avg data time: 6.55e-02, avg batch time: 0.5086, average train loss: 0.2256
[09/26 09:41:05 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1673, average loss: 3.9993
[09/26 09:41:05 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.00	top5: 45.50	
[09/26 09:41:05 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.008930309757836517
[09/26 09:41:11 visual_prompt]: Epoch 76 / 100: avg data time: 6.04e-02, avg batch time: 0.5038, average train loss: 0.2229
[09/26 09:41:13 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1671, average loss: 3.9913
[09/26 09:41:13 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.00	top5: 45.50	
[09/26 09:41:13 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.008271734841028553
[09/26 09:41:20 visual_prompt]: Epoch 77 / 100: avg data time: 5.86e-02, avg batch time: 0.5012, average train loss: 0.2196
[09/26 09:41:22 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1671, average loss: 3.9888
[09/26 09:41:22 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.50	top5: 46.50	
[09/26 09:41:22 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.007633540738525066
[09/26 09:41:29 visual_prompt]: Epoch 78 / 100: avg data time: 6.83e-02, avg batch time: 0.5117, average train loss: 0.2180
[09/26 09:41:30 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1673, average loss: 3.9896
[09/26 09:41:30 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.00	top5: 46.00	
[09/26 09:41:30 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.0070165049915337264
[09/26 09:41:37 visual_prompt]: Epoch 79 / 100: avg data time: 6.20e-02, avg batch time: 0.5065, average train loss: 0.2180
[09/26 09:41:39 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1671, average loss: 3.9888
[09/26 09:41:39 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.50	top5: 46.00	
[09/26 09:41:39 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.006421379363065142
[09/26 09:41:46 visual_prompt]: Epoch 80 / 100: avg data time: 6.19e-02, avg batch time: 0.5049, average train loss: 0.2149
[09/26 09:41:47 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1672, average loss: 3.9905
[09/26 09:41:47 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.50	top5: 46.00	
[09/26 09:41:47 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.005848888922025553
[09/26 09:41:54 visual_prompt]: Epoch 81 / 100: avg data time: 6.09e-02, avg batch time: 0.5030, average train loss: 0.2161
[09/26 09:41:56 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1675, average loss: 3.9970
[09/26 09:41:56 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.00	top5: 46.00	
[09/26 09:41:56 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.005299731159831953
[09/26 09:42:03 visual_prompt]: Epoch 82 / 100: avg data time: 5.86e-02, avg batch time: 0.5034, average train loss: 0.2178
[09/26 09:42:05 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.1671, average loss: 3.9905
[09/26 09:42:05 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.50	top5: 45.50	
[09/26 09:42:05 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.004774575140626317
[09/26 09:42:12 visual_prompt]: Epoch 83 / 100: avg data time: 6.40e-02, avg batch time: 0.5068, average train loss: 0.2148
[09/26 09:42:13 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1675, average loss: 3.9912
[09/26 09:42:13 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.50	top5: 45.50	
[09/26 09:42:13 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.004274060686123959
[09/26 09:42:20 visual_prompt]: Epoch 84 / 100: avg data time: 6.82e-02, avg batch time: 0.5124, average train loss: 0.2139
[09/26 09:42:22 visual_prompt]: Inference (val):avg data time: 5.29e-05, avg batch time: 0.1673, average loss: 3.9970
[09/26 09:42:22 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.00	top5: 44.50	
[09/26 09:42:22 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.003798797596089351
[09/26 09:42:29 visual_prompt]: Epoch 85 / 100: avg data time: 5.99e-02, avg batch time: 0.5043, average train loss: 0.2131
[09/26 09:42:30 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1674, average loss: 3.9985
[09/26 09:42:30 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.50	top5: 45.00	
[09/26 09:42:30 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.0033493649053890325
[09/26 09:42:37 visual_prompt]: Epoch 86 / 100: avg data time: 6.94e-02, avg batch time: 0.5126, average train loss: 0.2125
[09/26 09:42:39 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1676, average loss: 4.0021
[09/26 09:42:39 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.00	top5: 45.00	
[09/26 09:42:39 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.0029263101785268254
[09/26 09:42:46 visual_prompt]: Epoch 87 / 100: avg data time: 6.20e-02, avg batch time: 0.5053, average train loss: 0.2119
[09/26 09:42:48 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1670, average loss: 4.0020
[09/26 09:42:48 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.00	top5: 45.50	
[09/26 09:42:48 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.00253014884252083
[09/26 09:42:55 visual_prompt]: Epoch 88 / 100: avg data time: 6.31e-02, avg batch time: 0.5063, average train loss: 0.2135
[09/26 09:42:56 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1672, average loss: 3.9961
[09/26 09:42:56 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.00	top5: 45.50	
[09/26 09:42:56 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.0021613635589349755
[09/26 09:43:03 visual_prompt]: Epoch 89 / 100: avg data time: 5.03e-02, avg batch time: 0.4935, average train loss: 0.2098
[09/26 09:43:05 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1673, average loss: 3.9919
[09/26 09:43:05 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.50	top5: 45.50	
[09/26 09:43:05 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.0018204036358303172
[09/26 09:43:12 visual_prompt]: Epoch 90 / 100: avg data time: 6.25e-02, avg batch time: 0.5057, average train loss: 0.2106
[09/26 09:43:13 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1675, average loss: 3.9917
[09/26 09:43:13 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.50	top5: 46.00	
[09/26 09:43:13 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.0015076844803522923
[09/26 09:43:20 visual_prompt]: Epoch 91 / 100: avg data time: 6.18e-02, avg batch time: 0.5047, average train loss: 0.2113
[09/26 09:43:22 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1673, average loss: 3.9923
[09/26 09:43:22 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.50	top5: 46.00	
[09/26 09:43:22 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.0012235870926211618
[09/26 09:43:29 visual_prompt]: Epoch 92 / 100: avg data time: 7.02e-02, avg batch time: 0.5124, average train loss: 0.2130
[09/26 09:43:31 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1671, average loss: 3.9921
[09/26 09:43:31 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.00	top5: 45.50	
[09/26 09:43:31 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.0009684576015420277
[09/26 09:43:37 visual_prompt]: Epoch 93 / 100: avg data time: 5.64e-02, avg batch time: 0.4996, average train loss: 0.2087
[09/26 09:43:39 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1675, average loss: 3.9932
[09/26 09:43:39 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.00	top5: 45.50	
[09/26 09:43:39 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.0007426068431000883
[09/26 09:43:46 visual_prompt]: Epoch 94 / 100: avg data time: 6.11e-02, avg batch time: 0.5042, average train loss: 0.2078
[09/26 09:43:48 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1672, average loss: 3.9936
[09/26 09:43:48 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.00	top5: 46.50	
[09/26 09:43:48 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.0005463099816548578
[09/26 09:43:55 visual_prompt]: Epoch 95 / 100: avg data time: 6.45e-02, avg batch time: 0.5070, average train loss: 0.2100
[09/26 09:43:56 visual_prompt]: Inference (val):avg data time: 4.71e-05, avg batch time: 0.1675, average loss: 3.9939
[09/26 09:43:56 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.00	top5: 46.50	
[09/26 09:43:56 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.00037980617469479954
[09/26 09:44:03 visual_prompt]: Epoch 96 / 100: avg data time: 6.06e-02, avg batch time: 0.5042, average train loss: 0.2117
[09/26 09:44:05 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1672, average loss: 3.9938
[09/26 09:44:05 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.00	top5: 46.50	
[09/26 09:44:05 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.00024329828146074097
[09/26 09:44:12 visual_prompt]: Epoch 97 / 100: avg data time: 6.27e-02, avg batch time: 0.5057, average train loss: 0.2088
[09/26 09:44:13 visual_prompt]: Inference (val):avg data time: 4.21e-05, avg batch time: 0.1671, average loss: 3.9938
[09/26 09:44:13 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.00	top5: 46.50	
[09/26 09:44:13 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.00013695261579316776
[09/26 09:44:20 visual_prompt]: Epoch 98 / 100: avg data time: 5.82e-02, avg batch time: 0.5021, average train loss: 0.2099
[09/26 09:44:22 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1670, average loss: 3.9938
[09/26 09:44:22 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.00	top5: 46.50	
[09/26 09:44:22 visual_prompt]: Training 99 / 100 epoch, with learning rate 6.089874350439506e-05
[09/26 09:44:29 visual_prompt]: Epoch 99 / 100: avg data time: 6.95e-02, avg batch time: 0.5121, average train loss: 0.2102
[09/26 09:44:31 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1672, average loss: 3.9939
[09/26 09:44:31 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.00	top5: 46.50	
[09/26 09:44:31 visual_prompt]: Training 100 / 100 epoch, with learning rate 1.5229324522605948e-05
[09/26 09:44:38 visual_prompt]: Epoch 100 / 100: avg data time: 5.99e-02, avg batch time: 0.5042, average train loss: 0.2095
[09/26 09:44:39 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1675, average loss: 3.9939
[09/26 09:44:39 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.00	top5: 46.50	
[09/26 09:44:39 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 09:44:39 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              0
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 09:44:39 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-sun397', 'DATA.NUMBER_CLASSES', '397', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 09:44:39 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 09:44:39 visual_prompt]: Training with config:
[09/26 09:44:39 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-sun397/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.05_wd0.0001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 0.05, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-sun397', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 397, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 09:44:39 visual_prompt]: Loading training data...
[09/26 09:44:39 visual_prompt]: Constructing vtab-sun397 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split train[:800], from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/26 09:44:41 visual_prompt]: Number of images: 800
[09/26 09:44:41 visual_prompt]: Number of classes: 309 / 397
[09/26 09:44:41 visual_prompt]: Loading validation data...
[09/26 09:44:41 visual_prompt]: Constructing vtab-sun397 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split validation[:200], from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/26 09:44:41 visual_prompt]: Number of images: 200
[09/26 09:44:41 visual_prompt]: Number of classes: 136 / 397
[09/26 09:44:41 visual_prompt]: Constructing models...
[09/26 09:44:43 visual_prompt]: Total Parameters: 86564749	 Gradient Parameters: 766093
[09/26 09:44:43 visual_prompt]: tuned percent:0.885
[09/26 09:44:43 visual_prompt]: Device used for model: 0
[09/26 09:44:43 visual_prompt]: Setting up Evaluator...
[09/26 09:44:43 visual_prompt]: Setting up Trainer...
[09/26 09:44:43 visual_prompt]: 	Setting up the optimizer...
[09/26 09:44:43 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 09:44:50 visual_prompt]: Epoch 1 / 100: avg data time: 6.75e-02, avg batch time: 0.5094, average train loss: 5.9913
[09/26 09:44:52 visual_prompt]: Inference (val):avg data time: 3.99e-05, avg batch time: 0.1667, average loss: 6.0097
[09/26 09:44:52 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/26 09:44:52 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.005000000000000001
[09/26 09:44:59 visual_prompt]: Epoch 2 / 100: avg data time: 6.72e-02, avg batch time: 0.5090, average train loss: 5.9822
[09/26 09:45:01 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1669, average loss: 5.9978
[09/26 09:45:01 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.50	
[09/26 09:45:01 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.010000000000000002
[09/26 09:45:08 visual_prompt]: Epoch 3 / 100: avg data time: 5.96e-02, avg batch time: 0.5022, average train loss: 5.9550
[09/26 09:45:09 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1671, average loss: 5.9756
[09/26 09:45:09 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.50	
[09/26 09:45:09 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.015
[09/26 09:45:16 visual_prompt]: Epoch 4 / 100: avg data time: 6.22e-02, avg batch time: 0.5049, average train loss: 5.9095
[09/26 09:45:18 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1672, average loss: 5.9352
[09/26 09:45:18 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 3.50	
[09/26 09:45:18 visual_prompt]: Best epoch 4: best metric: 0.010
[09/26 09:45:18 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.020000000000000004
[09/26 09:45:25 visual_prompt]: Epoch 5 / 100: avg data time: 6.44e-02, avg batch time: 0.5084, average train loss: 5.8210
[09/26 09:45:27 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1669, average loss: 5.8874
[09/26 09:45:27 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 09:45:27 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.025
[09/26 09:45:34 visual_prompt]: Epoch 6 / 100: avg data time: 6.56e-02, avg batch time: 0.5087, average train loss: 5.6930
[09/26 09:45:35 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1671, average loss: 5.8426
[09/26 09:45:35 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 4.50	
[09/26 09:45:35 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.03
[09/26 09:45:42 visual_prompt]: Epoch 7 / 100: avg data time: 5.81e-02, avg batch time: 0.5021, average train loss: 5.5981
[09/26 09:45:44 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1669, average loss: 5.7953
[09/26 09:45:44 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 5.50	
[09/26 09:45:44 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.034999999999999996
[09/26 09:45:51 visual_prompt]: Epoch 8 / 100: avg data time: 6.11e-02, avg batch time: 0.5048, average train loss: 5.4999
[09/26 09:45:52 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1674, average loss: 5.6885
[09/26 09:45:52 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.00	top5: 6.50	
[09/26 09:45:52 visual_prompt]: Best epoch 8: best metric: 0.020
[09/26 09:45:52 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.04000000000000001
[09/26 09:45:59 visual_prompt]: Epoch 9 / 100: avg data time: 6.46e-02, avg batch time: 0.5080, average train loss: 5.3274
[09/26 09:46:01 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1675, average loss: 5.6081
[09/26 09:46:01 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.50	top5: 9.50	
[09/26 09:46:01 visual_prompt]: Best epoch 9: best metric: 0.025
[09/26 09:46:01 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.045000000000000005
[09/26 09:46:08 visual_prompt]: Epoch 10 / 100: avg data time: 6.17e-02, avg batch time: 0.5044, average train loss: 5.1105
[09/26 09:46:10 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1668, average loss: 5.4492
[09/26 09:46:10 visual_prompt]: Classification results with val_vtab-sun397: top1: 4.00	top5: 9.50	
[09/26 09:46:10 visual_prompt]: Best epoch 10: best metric: 0.040
[09/26 09:46:10 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.05
[09/26 09:46:17 visual_prompt]: Epoch 11 / 100: avg data time: 6.23e-02, avg batch time: 0.5059, average train loss: 4.8442
[09/26 09:46:18 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1670, average loss: 5.2872
[09/26 09:46:18 visual_prompt]: Classification results with val_vtab-sun397: top1: 6.00	top5: 16.50	
[09/26 09:46:18 visual_prompt]: Best epoch 11: best metric: 0.060
[09/26 09:46:18 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0499847706754774
[09/26 09:46:25 visual_prompt]: Epoch 12 / 100: avg data time: 5.30e-02, avg batch time: 0.4971, average train loss: 4.5928
[09/26 09:46:27 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1671, average loss: 5.1612
[09/26 09:46:27 visual_prompt]: Classification results with val_vtab-sun397: top1: 6.50	top5: 17.50	
[09/26 09:46:27 visual_prompt]: Best epoch 12: best metric: 0.065
[09/26 09:46:27 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.04993910125649561
[09/26 09:46:34 visual_prompt]: Epoch 13 / 100: avg data time: 6.63e-02, avg batch time: 0.5087, average train loss: 4.3024
[09/26 09:46:35 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.1672, average loss: 5.0022
[09/26 09:46:35 visual_prompt]: Classification results with val_vtab-sun397: top1: 6.00	top5: 22.00	
[09/26 09:46:35 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.049863047384206834
[09/26 09:46:42 visual_prompt]: Epoch 14 / 100: avg data time: 6.02e-02, avg batch time: 0.5033, average train loss: 4.0448
[09/26 09:46:44 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1671, average loss: 4.9054
[09/26 09:46:44 visual_prompt]: Classification results with val_vtab-sun397: top1: 10.00	top5: 24.50	
[09/26 09:46:44 visual_prompt]: Best epoch 14: best metric: 0.100
[09/26 09:46:44 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.04975670171853926
[09/26 09:46:51 visual_prompt]: Epoch 15 / 100: avg data time: 6.93e-02, avg batch time: 0.5132, average train loss: 3.7735
[09/26 09:46:53 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1677, average loss: 4.7730
[09/26 09:46:53 visual_prompt]: Classification results with val_vtab-sun397: top1: 9.00	top5: 27.00	
[09/26 09:46:53 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.049620193825305206
[09/26 09:47:00 visual_prompt]: Epoch 16 / 100: avg data time: 6.43e-02, avg batch time: 0.5066, average train loss: 3.5181
[09/26 09:47:01 visual_prompt]: Inference (val):avg data time: 3.80e-05, avg batch time: 0.1680, average loss: 4.6734
[09/26 09:47:01 visual_prompt]: Classification results with val_vtab-sun397: top1: 12.50	top5: 29.00	
[09/26 09:47:01 visual_prompt]: Best epoch 16: best metric: 0.125
[09/26 09:47:01 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.049453690018345146
[09/26 09:47:08 visual_prompt]: Epoch 17 / 100: avg data time: 6.38e-02, avg batch time: 0.5084, average train loss: 3.2490
[09/26 09:47:10 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1672, average loss: 4.6199
[09/26 09:47:10 visual_prompt]: Classification results with val_vtab-sun397: top1: 12.00	top5: 30.50	
[09/26 09:47:10 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.04925739315689991
[09/26 09:47:17 visual_prompt]: Epoch 18 / 100: avg data time: 6.48e-02, avg batch time: 0.5078, average train loss: 3.0213
[09/26 09:47:18 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1676, average loss: 4.5324
[09/26 09:47:18 visual_prompt]: Classification results with val_vtab-sun397: top1: 15.50	top5: 34.50	
[09/26 09:47:18 visual_prompt]: Best epoch 18: best metric: 0.155
[09/26 09:47:18 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.04903154239845797
[09/26 09:47:25 visual_prompt]: Epoch 19 / 100: avg data time: 6.18e-02, avg batch time: 0.5049, average train loss: 2.7575
[09/26 09:47:27 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1676, average loss: 4.4317
[09/26 09:47:27 visual_prompt]: Classification results with val_vtab-sun397: top1: 17.00	top5: 35.50	
[09/26 09:47:27 visual_prompt]: Best epoch 19: best metric: 0.170
[09/26 09:47:27 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.048776412907378844
[09/26 09:47:34 visual_prompt]: Epoch 20 / 100: avg data time: 6.50e-02, avg batch time: 0.5087, average train loss: 2.5235
[09/26 09:47:36 visual_prompt]: Inference (val):avg data time: 3.95e-05, avg batch time: 0.1677, average loss: 4.4026
[09/26 09:47:36 visual_prompt]: Classification results with val_vtab-sun397: top1: 16.00	top5: 36.00	
[09/26 09:47:36 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.048492315519647715
[09/26 09:47:43 visual_prompt]: Epoch 21 / 100: avg data time: 6.29e-02, avg batch time: 0.5066, average train loss: 2.3070
[09/26 09:47:44 visual_prompt]: Inference (val):avg data time: 3.59e-05, avg batch time: 0.1676, average loss: 4.3426
[09/26 09:47:44 visual_prompt]: Classification results with val_vtab-sun397: top1: 18.50	top5: 39.50	
[09/26 09:47:44 visual_prompt]: Best epoch 21: best metric: 0.185
[09/26 09:47:44 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.048179596364169686
[09/26 09:47:51 visual_prompt]: Epoch 22 / 100: avg data time: 6.24e-02, avg batch time: 0.5063, average train loss: 2.1069
[09/26 09:47:53 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1677, average loss: 4.2819
[09/26 09:47:53 visual_prompt]: Classification results with val_vtab-sun397: top1: 18.00	top5: 39.00	
[09/26 09:47:53 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.04783863644106502
[09/26 09:48:00 visual_prompt]: Epoch 23 / 100: avg data time: 6.26e-02, avg batch time: 0.5060, average train loss: 1.9098
[09/26 09:48:01 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1676, average loss: 4.2776
[09/26 09:48:01 visual_prompt]: Classification results with val_vtab-sun397: top1: 15.50	top5: 39.50	
[09/26 09:48:01 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.047469851157479176
[09/26 09:48:08 visual_prompt]: Epoch 24 / 100: avg data time: 5.90e-02, avg batch time: 0.5020, average train loss: 1.7508
[09/26 09:48:10 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1675, average loss: 4.2001
[09/26 09:48:10 visual_prompt]: Classification results with val_vtab-sun397: top1: 17.50	top5: 43.50	
[09/26 09:48:10 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.047073689821473176
[09/26 09:48:17 visual_prompt]: Epoch 25 / 100: avg data time: 5.89e-02, avg batch time: 0.5025, average train loss: 1.5981
[09/26 09:48:19 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1676, average loss: 4.2227
[09/26 09:48:19 visual_prompt]: Classification results with val_vtab-sun397: top1: 17.50	top5: 38.00	
[09/26 09:48:19 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.046650635094610975
[09/26 09:48:25 visual_prompt]: Epoch 26 / 100: avg data time: 5.91e-02, avg batch time: 0.5021, average train loss: 1.4561
[09/26 09:48:27 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1673, average loss: 4.1083
[09/26 09:48:27 visual_prompt]: Classification results with val_vtab-sun397: top1: 20.00	top5: 44.00	
[09/26 09:48:27 visual_prompt]: Best epoch 26: best metric: 0.200
[09/26 09:48:27 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.04620120240391065
[09/26 09:48:34 visual_prompt]: Epoch 27 / 100: avg data time: 6.52e-02, avg batch time: 0.5075, average train loss: 1.3300
[09/26 09:48:36 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1672, average loss: 4.1196
[09/26 09:48:36 visual_prompt]: Classification results with val_vtab-sun397: top1: 19.50	top5: 44.50	
[09/26 09:48:36 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.04572593931387604
[09/26 09:48:43 visual_prompt]: Epoch 28 / 100: avg data time: 5.70e-02, avg batch time: 0.5015, average train loss: 1.2036
[09/26 09:48:44 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1671, average loss: 4.0528
[09/26 09:48:44 visual_prompt]: Classification results with val_vtab-sun397: top1: 19.50	top5: 46.00	
[09/26 09:48:44 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.04522542485937369
[09/26 09:48:51 visual_prompt]: Epoch 29 / 100: avg data time: 6.04e-02, avg batch time: 0.5045, average train loss: 1.0957
[09/26 09:48:53 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1672, average loss: 4.0707
[09/26 09:48:53 visual_prompt]: Classification results with val_vtab-sun397: top1: 20.00	top5: 43.50	
[09/26 09:48:53 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.04470026884016805
[09/26 09:49:00 visual_prompt]: Epoch 30 / 100: avg data time: 6.19e-02, avg batch time: 0.5061, average train loss: 0.9959
[09/26 09:49:01 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1671, average loss: 4.0786
[09/26 09:49:01 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.50	top5: 45.50	
[09/26 09:49:01 visual_prompt]: Best epoch 30: best metric: 0.215
[09/26 09:49:01 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.04415111107797445
[09/26 09:49:08 visual_prompt]: Epoch 31 / 100: avg data time: 5.27e-02, avg batch time: 0.4995, average train loss: 0.9102
[09/26 09:49:10 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1671, average loss: 4.0711
[09/26 09:49:10 visual_prompt]: Classification results with val_vtab-sun397: top1: 20.50	top5: 45.50	
[09/26 09:49:10 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.04357862063693486
[09/26 09:49:17 visual_prompt]: Epoch 32 / 100: avg data time: 6.33e-02, avg batch time: 0.5065, average train loss: 0.8259
[09/26 09:49:18 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1673, average loss: 4.0341
[09/26 09:49:18 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.00	top5: 46.50	
[09/26 09:49:18 visual_prompt]: Best epoch 32: best metric: 0.220
[09/26 09:49:18 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.04298349500846628
[09/26 09:49:25 visual_prompt]: Epoch 33 / 100: avg data time: 5.98e-02, avg batch time: 0.5029, average train loss: 0.7623
[09/26 09:49:27 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1676, average loss: 4.0322
[09/26 09:49:27 visual_prompt]: Classification results with val_vtab-sun397: top1: 19.50	top5: 45.50	
[09/26 09:49:27 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.042366459261474934
[09/26 09:49:34 visual_prompt]: Epoch 34 / 100: avg data time: 6.83e-02, avg batch time: 0.5114, average train loss: 0.6935
[09/26 09:49:36 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.1674, average loss: 4.0291
[09/26 09:49:36 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.00	top5: 47.50	
[09/26 09:49:36 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.04172826515897146
[09/26 09:49:43 visual_prompt]: Epoch 35 / 100: avg data time: 6.97e-02, avg batch time: 0.5125, average train loss: 0.6401
[09/26 09:49:44 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1672, average loss: 4.0364
[09/26 09:49:44 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.00	top5: 45.00	
[09/26 09:49:44 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.04106969024216348
[09/26 09:49:51 visual_prompt]: Epoch 36 / 100: avg data time: 5.61e-02, avg batch time: 0.4998, average train loss: 0.5927
[09/26 09:49:53 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.1672, average loss: 4.0408
[09/26 09:49:53 visual_prompt]: Classification results with val_vtab-sun397: top1: 20.50	top5: 45.50	
[09/26 09:49:53 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.040391536883141455
[09/26 09:50:00 visual_prompt]: Epoch 37 / 100: avg data time: 5.35e-02, avg batch time: 0.4973, average train loss: 0.5473
[09/26 09:50:01 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1672, average loss: 4.0195
[09/26 09:50:01 visual_prompt]: Classification results with val_vtab-sun397: top1: 20.50	top5: 44.50	
[09/26 09:50:01 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.03969463130731183
[09/26 09:50:08 visual_prompt]: Epoch 38 / 100: avg data time: 5.91e-02, avg batch time: 0.5027, average train loss: 0.5113
[09/26 09:50:10 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1672, average loss: 4.0060
[09/26 09:50:10 visual_prompt]: Classification results with val_vtab-sun397: top1: 23.50	top5: 47.50	
[09/26 09:50:10 visual_prompt]: Best epoch 38: best metric: 0.235
[09/26 09:50:10 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.03897982258676867
[09/26 09:50:17 visual_prompt]: Epoch 39 / 100: avg data time: 6.70e-02, avg batch time: 0.5104, average train loss: 0.4814
[09/26 09:50:18 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1670, average loss: 3.9878
[09/26 09:50:18 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.50	top5: 49.00	
[09/26 09:50:18 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.03824798160583012
[09/26 09:50:25 visual_prompt]: Epoch 40 / 100: avg data time: 6.42e-02, avg batch time: 0.5090, average train loss: 0.4443
[09/26 09:50:27 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1670, average loss: 3.9878
[09/26 09:50:27 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.50	top5: 45.50	
[09/26 09:50:27 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.037500000000000006
[09/26 09:50:34 visual_prompt]: Epoch 41 / 100: avg data time: 6.54e-02, avg batch time: 0.5086, average train loss: 0.4158
[09/26 09:50:36 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1670, average loss: 3.9710
[09/26 09:50:36 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.50	top5: 48.00	
[09/26 09:50:36 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.03673678906964727
[09/26 09:50:42 visual_prompt]: Epoch 42 / 100: avg data time: 6.53e-02, avg batch time: 0.5094, average train loss: 0.3930
[09/26 09:50:44 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1671, average loss: 4.0155
[09/26 09:50:44 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.50	top5: 45.50	
[09/26 09:50:44 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.03595927866972694
[09/26 09:50:51 visual_prompt]: Epoch 43 / 100: avg data time: 6.59e-02, avg batch time: 0.5100, average train loss: 0.3709
[09/26 09:50:53 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1672, average loss: 3.9572
[09/26 09:50:53 visual_prompt]: Classification results with val_vtab-sun397: top1: 23.00	top5: 46.50	
[09/26 09:50:53 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.03516841607689501
[09/26 09:51:00 visual_prompt]: Epoch 44 / 100: avg data time: 5.41e-02, avg batch time: 0.4975, average train loss: 0.3445
[09/26 09:51:01 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1676, average loss: 4.0139
[09/26 09:51:01 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.50	top5: 47.00	
[09/26 09:51:01 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.0343651648353978
[09/26 09:51:08 visual_prompt]: Epoch 45 / 100: avg data time: 5.55e-02, avg batch time: 0.4988, average train loss: 0.3275
[09/26 09:51:10 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1673, average loss: 3.9719
[09/26 09:51:10 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.50	top5: 47.50	
[09/26 09:51:10 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.033550503583141725
[09/26 09:51:17 visual_prompt]: Epoch 46 / 100: avg data time: 5.78e-02, avg batch time: 0.5028, average train loss: 0.3089
[09/26 09:51:18 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1675, average loss: 3.9589
[09/26 09:51:18 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.00	top5: 48.50	
[09/26 09:51:18 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.032725424859373686
[09/26 09:51:25 visual_prompt]: Epoch 47 / 100: avg data time: 6.21e-02, avg batch time: 0.5048, average train loss: 0.2926
[09/26 09:51:27 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1675, average loss: 3.9783
[09/26 09:51:27 visual_prompt]: Classification results with val_vtab-sun397: top1: 23.00	top5: 47.00	
[09/26 09:51:27 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.03189093389542498
[09/26 09:51:34 visual_prompt]: Epoch 48 / 100: avg data time: 5.01e-02, avg batch time: 0.4970, average train loss: 0.2811
[09/26 09:51:36 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1673, average loss: 3.9659
[09/26 09:51:36 visual_prompt]: Classification results with val_vtab-sun397: top1: 23.00	top5: 48.00	
[09/26 09:51:36 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.03104804738999169
[09/26 09:51:42 visual_prompt]: Epoch 49 / 100: avg data time: 6.24e-02, avg batch time: 0.5071, average train loss: 0.2660
[09/26 09:51:44 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1672, average loss: 3.9522
[09/26 09:51:44 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.50	top5: 47.50	
[09/26 09:51:44 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.03019779227044398
[09/26 09:51:51 visual_prompt]: Epoch 50 / 100: avg data time: 5.70e-02, avg batch time: 0.5012, average train loss: 0.2539
[09/26 09:51:53 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1675, average loss: 3.9559
[09/26 09:51:53 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.50	top5: 46.50	
[09/26 09:51:53 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.029341204441673263
[09/26 09:52:00 visual_prompt]: Epoch 51 / 100: avg data time: 6.21e-02, avg batch time: 0.5060, average train loss: 0.2429
[09/26 09:52:01 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1675, average loss: 3.9577
[09/26 09:52:01 visual_prompt]: Classification results with val_vtab-sun397: top1: 24.50	top5: 49.00	
[09/26 09:52:01 visual_prompt]: Best epoch 51: best metric: 0.245
[09/26 09:52:01 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.028479327524001636
[09/26 09:52:08 visual_prompt]: Epoch 52 / 100: avg data time: 6.76e-02, avg batch time: 0.5102, average train loss: 0.2355
[09/26 09:52:10 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1671, average loss: 3.9577
[09/26 09:52:10 visual_prompt]: Classification results with val_vtab-sun397: top1: 23.00	top5: 48.00	
[09/26 09:52:10 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.02761321158169134
[09/26 09:52:17 visual_prompt]: Epoch 53 / 100: avg data time: 6.13e-02, avg batch time: 0.5048, average train loss: 0.2313
[09/26 09:52:18 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1674, average loss: 3.9820
[09/26 09:52:18 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.50	top5: 47.50	
[09/26 09:52:18 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.02674391184360313
[09/26 09:52:25 visual_prompt]: Epoch 54 / 100: avg data time: 5.70e-02, avg batch time: 0.5004, average train loss: 0.2194
[09/26 09:52:27 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1671, average loss: 3.9332
[09/26 09:52:27 visual_prompt]: Classification results with val_vtab-sun397: top1: 24.00	top5: 49.50	
[09/26 09:52:27 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.02587248741756253
[09/26 09:52:34 visual_prompt]: Epoch 55 / 100: avg data time: 6.45e-02, avg batch time: 0.5086, average train loss: 0.2144
[09/26 09:52:35 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1671, average loss: 3.9730
[09/26 09:52:35 visual_prompt]: Classification results with val_vtab-sun397: top1: 23.00	top5: 48.50	
[09/26 09:52:35 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.025
[09/26 09:52:42 visual_prompt]: Epoch 56 / 100: avg data time: 6.73e-02, avg batch time: 0.5119, average train loss: 0.2069
[09/26 09:52:44 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1673, average loss: 3.9396
[09/26 09:52:44 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.50	top5: 48.50	
[09/26 09:52:44 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.024127512582437484
[09/26 09:52:51 visual_prompt]: Epoch 57 / 100: avg data time: 6.03e-02, avg batch time: 0.5038, average train loss: 0.2030
[09/26 09:52:53 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1675, average loss: 3.9616
[09/26 09:52:53 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.00	top5: 48.50	
[09/26 09:52:53 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.02325608815639687
[09/26 09:53:00 visual_prompt]: Epoch 58 / 100: avg data time: 6.92e-02, avg batch time: 0.5129, average train loss: 0.1909
[09/26 09:53:01 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1674, average loss: 3.9362
[09/26 09:53:01 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.00	top5: 48.50	
[09/26 09:53:01 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.02238678841830867
[09/26 09:53:08 visual_prompt]: Epoch 59 / 100: avg data time: 5.78e-02, avg batch time: 0.5027, average train loss: 0.1908
[09/26 09:53:10 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1674, average loss: 3.9479
[09/26 09:53:10 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.50	top5: 49.00	
[09/26 09:53:10 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.02152067247599837
[09/26 09:53:17 visual_prompt]: Epoch 60 / 100: avg data time: 6.46e-02, avg batch time: 0.5078, average train loss: 0.1837
[09/26 09:53:18 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1673, average loss: 3.9384
[09/26 09:53:18 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.00	top5: 48.00	
[09/26 09:53:18 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.020658795558326743
[09/26 09:53:25 visual_prompt]: Epoch 61 / 100: avg data time: 6.50e-02, avg batch time: 0.5113, average train loss: 0.1813
[09/26 09:53:27 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1673, average loss: 3.9611
[09/26 09:53:27 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.50	top5: 49.00	
[09/26 09:53:27 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.019802207729556022
[09/26 09:53:34 visual_prompt]: Epoch 62 / 100: avg data time: 5.01e-02, avg batch time: 0.4957, average train loss: 0.1790
[09/26 09:53:36 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1676, average loss: 3.9513
[09/26 09:53:36 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.00	top5: 48.00	
[09/26 09:53:36 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.018951952610008312
[09/26 09:53:43 visual_prompt]: Epoch 63 / 100: avg data time: 6.44e-02, avg batch time: 0.5093, average train loss: 0.1748
[09/26 09:53:44 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1675, average loss: 3.9435
[09/26 09:53:44 visual_prompt]: Classification results with val_vtab-sun397: top1: 23.00	top5: 48.50	
[09/26 09:53:44 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.018109066104575022
[09/26 09:53:51 visual_prompt]: Epoch 64 / 100: avg data time: 6.95e-02, avg batch time: 0.5132, average train loss: 0.1698
[09/26 09:53:53 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1674, average loss: 3.9394
[09/26 09:53:53 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.50	top5: 49.50	
[09/26 09:53:53 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.017274575140626316
[09/26 09:54:00 visual_prompt]: Epoch 65 / 100: avg data time: 5.20e-02, avg batch time: 0.4954, average train loss: 0.1645
[09/26 09:54:01 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1671, average loss: 3.9452
[09/26 09:54:01 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.50	top5: 48.50	
[09/26 09:54:01 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.016449496416858285
[09/26 09:54:08 visual_prompt]: Epoch 66 / 100: avg data time: 6.58e-02, avg batch time: 0.5093, average train loss: 0.1606
[09/26 09:54:10 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1673, average loss: 3.9455
[09/26 09:54:10 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.00	top5: 48.00	
[09/26 09:54:10 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.0156348351646022
[09/26 09:54:17 visual_prompt]: Epoch 67 / 100: avg data time: 6.39e-02, avg batch time: 0.5091, average train loss: 0.1601
[09/26 09:54:19 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1672, average loss: 3.9398
[09/26 09:54:19 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.50	top5: 49.50	
[09/26 09:54:19 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.014831583923105
[09/26 09:54:26 visual_prompt]: Epoch 68 / 100: avg data time: 5.73e-02, avg batch time: 0.5004, average train loss: 0.1609
[09/26 09:54:27 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1672, average loss: 3.9475
[09/26 09:54:27 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.50	top5: 47.50	
[09/26 09:54:27 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.014040721330273063
[09/26 09:54:34 visual_prompt]: Epoch 69 / 100: avg data time: 4.92e-02, avg batch time: 0.4946, average train loss: 0.1555
[09/26 09:54:36 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1671, average loss: 3.9365
[09/26 09:54:36 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.50	top5: 49.00	
[09/26 09:54:36 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.013263210930352737
[09/26 09:54:43 visual_prompt]: Epoch 70 / 100: avg data time: 5.90e-02, avg batch time: 0.5025, average train loss: 0.1532
[09/26 09:54:44 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1676, average loss: 3.9364
[09/26 09:54:44 visual_prompt]: Classification results with val_vtab-sun397: top1: 23.50	top5: 49.00	
[09/26 09:54:44 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.012500000000000006
[09/26 09:54:51 visual_prompt]: Epoch 71 / 100: avg data time: 5.76e-02, avg batch time: 0.5020, average train loss: 0.1517
[09/26 09:54:53 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1673, average loss: 3.9501
[09/26 09:54:53 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.50	top5: 48.00	
[09/26 09:54:53 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.01175201839416988
[09/26 09:55:00 visual_prompt]: Epoch 72 / 100: avg data time: 4.89e-02, avg batch time: 0.4923, average train loss: 0.1495
[09/26 09:55:01 visual_prompt]: Inference (val):avg data time: 3.80e-05, avg batch time: 0.1673, average loss: 3.9411
[09/26 09:55:01 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.50	top5: 49.50	
[09/26 09:55:01 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.011020177413231334
[09/26 09:55:08 visual_prompt]: Epoch 73 / 100: avg data time: 6.12e-02, avg batch time: 0.5058, average train loss: 0.1454
[09/26 09:55:10 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1676, average loss: 3.9367
[09/26 09:55:10 visual_prompt]: Classification results with val_vtab-sun397: top1: 23.00	top5: 48.50	
[09/26 09:55:10 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.010305368692688175
[09/26 09:55:17 visual_prompt]: Epoch 74 / 100: avg data time: 5.82e-02, avg batch time: 0.5032, average train loss: 0.1444
[09/26 09:55:18 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1676, average loss: 3.9366
[09/26 09:55:18 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.00	top5: 48.50	
[09/26 09:55:18 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.009608463116858543
[09/26 09:55:25 visual_prompt]: Epoch 75 / 100: avg data time: 6.33e-02, avg batch time: 0.5063, average train loss: 0.1471
[09/26 09:55:27 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1674, average loss: 3.9239
[09/26 09:55:27 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.50	top5: 49.00	
[09/26 09:55:27 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.008930309757836517
[09/26 09:55:34 visual_prompt]: Epoch 76 / 100: avg data time: 6.40e-02, avg batch time: 0.5077, average train loss: 0.1434
[09/26 09:55:35 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1673, average loss: 3.9249
[09/26 09:55:36 visual_prompt]: Classification results with val_vtab-sun397: top1: 23.00	top5: 49.00	
[09/26 09:55:36 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.008271734841028553
[09/26 09:55:42 visual_prompt]: Epoch 77 / 100: avg data time: 6.21e-02, avg batch time: 0.5058, average train loss: 0.1425
[09/26 09:55:44 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1674, average loss: 3.9326
[09/26 09:55:44 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.50	top5: 48.00	
[09/26 09:55:44 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.007633540738525066
[09/26 09:55:51 visual_prompt]: Epoch 78 / 100: avg data time: 6.05e-02, avg batch time: 0.5039, average train loss: 0.1414
[09/26 09:55:53 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1674, average loss: 3.9384
[09/26 09:55:53 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.50	top5: 49.50	
[09/26 09:55:53 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.0070165049915337264
[09/26 09:56:00 visual_prompt]: Epoch 79 / 100: avg data time: 6.59e-02, avg batch time: 0.5100, average train loss: 0.1396
[09/26 09:56:01 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1677, average loss: 3.9419
[09/26 09:56:01 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.50	top5: 50.00	
[09/26 09:56:01 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.006421379363065142
[09/26 09:56:08 visual_prompt]: Epoch 80 / 100: avg data time: 4.80e-02, avg batch time: 0.4920, average train loss: 0.1387
[09/26 09:56:10 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1678, average loss: 3.9349
[09/26 09:56:10 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.50	top5: 50.00	
[09/26 09:56:10 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.005848888922025553
[09/26 09:56:17 visual_prompt]: Epoch 81 / 100: avg data time: 5.78e-02, avg batch time: 0.5008, average train loss: 0.1397
[09/26 09:56:19 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1674, average loss: 3.9269
[09/26 09:56:19 visual_prompt]: Classification results with val_vtab-sun397: top1: 23.50	top5: 50.00	
[09/26 09:56:19 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.005299731159831953
[09/26 09:56:25 visual_prompt]: Epoch 82 / 100: avg data time: 6.36e-02, avg batch time: 0.5068, average train loss: 0.1373
[09/26 09:56:27 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1674, average loss: 3.9292
[09/26 09:56:27 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.50	top5: 50.00	
[09/26 09:56:27 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.004774575140626317
[09/26 09:56:34 visual_prompt]: Epoch 83 / 100: avg data time: 6.62e-02, avg batch time: 0.5087, average train loss: 0.1385
[09/26 09:56:36 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1679, average loss: 3.9333
[09/26 09:56:36 visual_prompt]: Classification results with val_vtab-sun397: top1: 23.00	top5: 50.00	
[09/26 09:56:36 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.004274060686123959
[09/26 09:56:43 visual_prompt]: Epoch 84 / 100: avg data time: 6.43e-02, avg batch time: 0.5073, average train loss: 0.1344
[09/26 09:56:44 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1673, average loss: 3.9339
[09/26 09:56:44 visual_prompt]: Classification results with val_vtab-sun397: top1: 23.00	top5: 50.00	
[09/26 09:56:44 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.003798797596089351
[09/26 09:56:51 visual_prompt]: Epoch 85 / 100: avg data time: 5.02e-02, avg batch time: 0.4939, average train loss: 0.1374
[09/26 09:56:53 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1676, average loss: 3.9373
[09/26 09:56:53 visual_prompt]: Classification results with val_vtab-sun397: top1: 23.00	top5: 50.00	
[09/26 09:56:53 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.0033493649053890325
[09/26 09:57:00 visual_prompt]: Epoch 86 / 100: avg data time: 6.67e-02, avg batch time: 0.5094, average train loss: 0.1347
[09/26 09:57:01 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1674, average loss: 3.9427
[09/26 09:57:01 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.50	top5: 49.00	
[09/26 09:57:01 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.0029263101785268254
[09/26 09:57:09 visual_prompt]: Epoch 87 / 100: avg data time: 7.17e-02, avg batch time: 0.5158, average train loss: 0.1340
[09/26 09:57:10 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.1671, average loss: 3.9404
[09/26 09:57:10 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.50	top5: 50.00	
[09/26 09:57:10 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.00253014884252083
[09/26 09:57:17 visual_prompt]: Epoch 88 / 100: avg data time: 5.40e-02, avg batch time: 0.4990, average train loss: 0.1362
[09/26 09:57:19 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1673, average loss: 3.9381
[09/26 09:57:19 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.50	top5: 49.00	
[09/26 09:57:19 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.0021613635589349755
[09/26 09:57:26 visual_prompt]: Epoch 89 / 100: avg data time: 6.18e-02, avg batch time: 0.5046, average train loss: 0.1340
[09/26 09:57:27 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.1672, average loss: 3.9369
[09/26 09:57:27 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.50	top5: 49.50	
[09/26 09:57:27 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.0018204036358303172
[09/26 09:57:34 visual_prompt]: Epoch 90 / 100: avg data time: 6.03e-02, avg batch time: 0.5042, average train loss: 0.1350
[09/26 09:57:36 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1675, average loss: 3.9362
[09/26 09:57:36 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.00	top5: 49.50	
[09/26 09:57:36 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.0015076844803522923
[09/26 09:57:43 visual_prompt]: Epoch 91 / 100: avg data time: 6.79e-02, avg batch time: 0.5118, average train loss: 0.1337
[09/26 09:57:45 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1673, average loss: 3.9360
[09/26 09:57:45 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.00	top5: 49.50	
[09/26 09:57:45 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.0012235870926211618
[09/26 09:57:51 visual_prompt]: Epoch 92 / 100: avg data time: 5.90e-02, avg batch time: 0.5031, average train loss: 0.1367
[09/26 09:57:53 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1671, average loss: 3.9360
[09/26 09:57:53 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.00	top5: 49.50	
[09/26 09:57:53 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.0009684576015420277
[09/26 09:58:00 visual_prompt]: Epoch 93 / 100: avg data time: 5.99e-02, avg batch time: 0.5042, average train loss: 0.1323
[09/26 09:58:02 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1672, average loss: 3.9358
[09/26 09:58:02 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.00	top5: 49.50	
[09/26 09:58:02 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.0007426068431000883
[09/26 09:58:09 visual_prompt]: Epoch 94 / 100: avg data time: 6.13e-02, avg batch time: 0.5055, average train loss: 0.1325
[09/26 09:58:10 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1672, average loss: 3.9358
[09/26 09:58:10 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.00	top5: 49.50	
[09/26 09:58:10 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.0005463099816548578
[09/26 09:58:17 visual_prompt]: Epoch 95 / 100: avg data time: 6.14e-02, avg batch time: 0.5040, average train loss: 0.1319
[09/26 09:58:19 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1672, average loss: 3.9358
[09/26 09:58:19 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.00	top5: 49.50	
[09/26 09:58:19 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.00037980617469479954
[09/26 09:58:26 visual_prompt]: Epoch 96 / 100: avg data time: 6.58e-02, avg batch time: 0.5091, average train loss: 0.1347
[09/26 09:58:27 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1670, average loss: 3.9361
[09/26 09:58:27 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.00	top5: 49.50	
[09/26 09:58:27 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.00024329828146074097
[09/26 09:58:34 visual_prompt]: Epoch 97 / 100: avg data time: 5.97e-02, avg batch time: 0.5037, average train loss: 0.1339
[09/26 09:58:36 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1673, average loss: 3.9362
[09/26 09:58:36 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.00	top5: 49.50	
[09/26 09:58:36 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.00013695261579316776
[09/26 09:58:43 visual_prompt]: Epoch 98 / 100: avg data time: 5.68e-02, avg batch time: 0.5020, average train loss: 0.1333
[09/26 09:58:45 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1670, average loss: 3.9362
[09/26 09:58:45 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.00	top5: 49.50	
[09/26 09:58:45 visual_prompt]: Training 99 / 100 epoch, with learning rate 6.089874350439506e-05
[09/26 09:58:51 visual_prompt]: Epoch 99 / 100: avg data time: 5.82e-02, avg batch time: 0.5031, average train loss: 0.1326
[09/26 09:58:53 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1673, average loss: 3.9363
[09/26 09:58:53 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.00	top5: 49.50	
[09/26 09:58:53 visual_prompt]: Training 100 / 100 epoch, with learning rate 1.5229324522605948e-05
[09/26 09:59:00 visual_prompt]: Epoch 100 / 100: avg data time: 6.64e-02, avg batch time: 0.5101, average train loss: 0.1334
[09/26 09:59:02 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1673, average loss: 3.9363
[09/26 09:59:02 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.00	top5: 49.50	
[09/26 09:59:02 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 09:59:02 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              0
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 09:59:02 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-sun397', 'DATA.NUMBER_CLASSES', '397', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 09:59:02 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 09:59:02 visual_prompt]: Training with config:
[09/26 09:59:02 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-sun397/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.05_wd0.0/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 0.05, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-sun397', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 397, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 09:59:02 visual_prompt]: Loading training data...
[09/26 09:59:02 visual_prompt]: Constructing vtab-sun397 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split train[:800], from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/26 09:59:03 visual_prompt]: Number of images: 800
[09/26 09:59:03 visual_prompt]: Number of classes: 309 / 397
[09/26 09:59:03 visual_prompt]: Loading validation data...
[09/26 09:59:03 visual_prompt]: Constructing vtab-sun397 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split validation[:200], from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/26 09:59:04 visual_prompt]: Number of images: 200
[09/26 09:59:04 visual_prompt]: Number of classes: 136 / 397
[09/26 09:59:04 visual_prompt]: Constructing models...
[09/26 09:59:06 visual_prompt]: Total Parameters: 86564749	 Gradient Parameters: 766093
[09/26 09:59:06 visual_prompt]: tuned percent:0.885
[09/26 09:59:06 visual_prompt]: Device used for model: 0
[09/26 09:59:06 visual_prompt]: Setting up Evaluator...
[09/26 09:59:06 visual_prompt]: Setting up Trainer...
[09/26 09:59:06 visual_prompt]: 	Setting up the optimizer...
[09/26 09:59:06 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 09:59:13 visual_prompt]: Epoch 1 / 100: avg data time: 5.77e-02, avg batch time: 0.5023, average train loss: 5.9853
[09/26 09:59:15 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1667, average loss: 6.0097
[09/26 09:59:15 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/26 09:59:15 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.005000000000000001
[09/26 09:59:22 visual_prompt]: Epoch 2 / 100: avg data time: 6.52e-02, avg batch time: 0.5074, average train loss: 5.9819
[09/26 09:59:23 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1669, average loss: 5.9963
[09/26 09:59:23 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.50	
[09/26 09:59:23 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.010000000000000002
[09/26 09:59:30 visual_prompt]: Epoch 3 / 100: avg data time: 7.08e-02, avg batch time: 0.5131, average train loss: 5.9554
[09/26 09:59:32 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1669, average loss: 5.9701
[09/26 09:59:32 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.50	
[09/26 09:59:32 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.015
[09/26 09:59:39 visual_prompt]: Epoch 4 / 100: avg data time: 6.55e-02, avg batch time: 0.5084, average train loss: 5.9135
[09/26 09:59:41 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1680, average loss: 5.9413
[09/26 09:59:41 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 3.00	
[09/26 09:59:41 visual_prompt]: Best epoch 4: best metric: 0.005
[09/26 09:59:41 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.020000000000000004
[09/26 09:59:48 visual_prompt]: Epoch 5 / 100: avg data time: 6.38e-02, avg batch time: 0.5066, average train loss: 5.8405
[09/26 09:59:49 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1676, average loss: 5.8782
[09/26 09:59:49 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 09:59:49 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.025
[09/26 09:59:56 visual_prompt]: Epoch 6 / 100: avg data time: 6.33e-02, avg batch time: 0.5060, average train loss: 5.7120
[09/26 09:59:58 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1673, average loss: 5.8445
[09/26 09:59:58 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/26 09:59:58 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.03
[09/26 10:00:05 visual_prompt]: Epoch 7 / 100: avg data time: 6.28e-02, avg batch time: 0.5057, average train loss: 5.5986
[09/26 10:00:06 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1677, average loss: 5.7981
[09/26 10:00:06 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 5.50	
[09/26 10:00:06 visual_prompt]: Best epoch 7: best metric: 0.010
[09/26 10:00:06 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.034999999999999996
[09/26 10:00:13 visual_prompt]: Epoch 8 / 100: avg data time: 6.36e-02, avg batch time: 0.5081, average train loss: 5.4822
[09/26 10:00:15 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1673, average loss: 5.6872
[09/26 10:00:15 visual_prompt]: Classification results with val_vtab-sun397: top1: 3.50	top5: 8.50	
[09/26 10:00:15 visual_prompt]: Best epoch 8: best metric: 0.035
[09/26 10:00:15 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.04000000000000001
[09/26 10:00:22 visual_prompt]: Epoch 9 / 100: avg data time: 6.19e-02, avg batch time: 0.5040, average train loss: 5.2931
[09/26 10:00:24 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1671, average loss: 5.5510
[09/26 10:00:24 visual_prompt]: Classification results with val_vtab-sun397: top1: 3.50	top5: 12.50	
[09/26 10:00:24 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.045000000000000005
[09/26 10:00:31 visual_prompt]: Epoch 10 / 100: avg data time: 6.84e-02, avg batch time: 0.5109, average train loss: 5.0530
[09/26 10:00:32 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1678, average loss: 5.4218
[09/26 10:00:32 visual_prompt]: Classification results with val_vtab-sun397: top1: 7.00	top5: 14.50	
[09/26 10:00:32 visual_prompt]: Best epoch 10: best metric: 0.070
[09/26 10:00:32 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.05
[09/26 10:00:39 visual_prompt]: Epoch 11 / 100: avg data time: 5.94e-02, avg batch time: 0.5030, average train loss: 4.7949
[09/26 10:00:41 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1675, average loss: 5.2215
[09/26 10:00:41 visual_prompt]: Classification results with val_vtab-sun397: top1: 7.00	top5: 17.00	
[09/26 10:00:41 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0499847706754774
[09/26 10:00:48 visual_prompt]: Epoch 12 / 100: avg data time: 5.31e-02, avg batch time: 0.4980, average train loss: 4.4921
[09/26 10:00:50 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1678, average loss: 5.0682
[09/26 10:00:50 visual_prompt]: Classification results with val_vtab-sun397: top1: 9.00	top5: 19.00	
[09/26 10:00:50 visual_prompt]: Best epoch 12: best metric: 0.090
[09/26 10:00:50 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.04993910125649561
[09/26 10:00:56 visual_prompt]: Epoch 13 / 100: avg data time: 6.21e-02, avg batch time: 0.5042, average train loss: 4.2250
[09/26 10:00:58 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.1674, average loss: 4.9419
[09/26 10:00:58 visual_prompt]: Classification results with val_vtab-sun397: top1: 9.00	top5: 22.00	
[09/26 10:00:58 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.049863047384206834
[09/26 10:01:05 visual_prompt]: Epoch 14 / 100: avg data time: 5.42e-02, avg batch time: 0.4992, average train loss: 3.9360
[09/26 10:01:07 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.1677, average loss: 4.7986
[09/26 10:01:07 visual_prompt]: Classification results with val_vtab-sun397: top1: 11.00	top5: 24.50	
[09/26 10:01:07 visual_prompt]: Best epoch 14: best metric: 0.110
[09/26 10:01:07 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.04975670171853926
[09/26 10:01:13 visual_prompt]: Epoch 15 / 100: avg data time: 6.00e-02, avg batch time: 0.5027, average train loss: 3.6581
[09/26 10:01:15 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1673, average loss: 4.7088
[09/26 10:01:15 visual_prompt]: Classification results with val_vtab-sun397: top1: 14.00	top5: 27.00	
[09/26 10:01:15 visual_prompt]: Best epoch 15: best metric: 0.140
[09/26 10:01:15 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.049620193825305206
[09/26 10:01:22 visual_prompt]: Epoch 16 / 100: avg data time: 6.58e-02, avg batch time: 0.5089, average train loss: 3.3864
[09/26 10:01:24 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1675, average loss: 4.6107
[09/26 10:01:24 visual_prompt]: Classification results with val_vtab-sun397: top1: 14.00	top5: 29.00	
[09/26 10:01:24 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.049453690018345146
[09/26 10:01:31 visual_prompt]: Epoch 17 / 100: avg data time: 6.34e-02, avg batch time: 0.5074, average train loss: 3.1352
[09/26 10:01:32 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1677, average loss: 4.5775
[09/26 10:01:32 visual_prompt]: Classification results with val_vtab-sun397: top1: 12.50	top5: 26.00	
[09/26 10:01:32 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.04925739315689991
[09/26 10:01:39 visual_prompt]: Epoch 18 / 100: avg data time: 6.83e-02, avg batch time: 0.5113, average train loss: 2.9420
[09/26 10:01:41 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1673, average loss: 4.4563
[09/26 10:01:41 visual_prompt]: Classification results with val_vtab-sun397: top1: 14.50	top5: 35.00	
[09/26 10:01:41 visual_prompt]: Best epoch 18: best metric: 0.145
[09/26 10:01:41 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.04903154239845797
[09/26 10:01:48 visual_prompt]: Epoch 19 / 100: avg data time: 6.13e-02, avg batch time: 0.5048, average train loss: 2.7305
[09/26 10:01:50 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1674, average loss: 4.3462
[09/26 10:01:50 visual_prompt]: Classification results with val_vtab-sun397: top1: 19.00	top5: 36.50	
[09/26 10:01:50 visual_prompt]: Best epoch 19: best metric: 0.190
[09/26 10:01:50 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.048776412907378844
[09/26 10:01:56 visual_prompt]: Epoch 20 / 100: avg data time: 5.13e-02, avg batch time: 0.4966, average train loss: 2.4955
[09/26 10:01:58 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1676, average loss: 4.2939
[09/26 10:01:58 visual_prompt]: Classification results with val_vtab-sun397: top1: 16.50	top5: 37.50	
[09/26 10:01:58 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.048492315519647715
[09/26 10:02:05 visual_prompt]: Epoch 21 / 100: avg data time: 6.43e-02, avg batch time: 0.5063, average train loss: 2.2806
[09/26 10:02:07 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1677, average loss: 4.2480
[09/26 10:02:07 visual_prompt]: Classification results with val_vtab-sun397: top1: 18.00	top5: 39.50	
[09/26 10:02:07 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.048179596364169686
[09/26 10:02:14 visual_prompt]: Epoch 22 / 100: avg data time: 6.46e-02, avg batch time: 0.5079, average train loss: 2.0860
[09/26 10:02:15 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1678, average loss: 4.2022
[09/26 10:02:15 visual_prompt]: Classification results with val_vtab-sun397: top1: 18.50	top5: 42.00	
[09/26 10:02:15 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.04783863644106502
[09/26 10:02:22 visual_prompt]: Epoch 23 / 100: avg data time: 5.56e-02, avg batch time: 0.5002, average train loss: 1.8987
[09/26 10:02:24 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1674, average loss: 4.1385
[09/26 10:02:24 visual_prompt]: Classification results with val_vtab-sun397: top1: 19.00	top5: 42.50	
[09/26 10:02:24 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.047469851157479176
[09/26 10:02:31 visual_prompt]: Epoch 24 / 100: avg data time: 6.41e-02, avg batch time: 0.5072, average train loss: 1.7140
[09/26 10:02:32 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1674, average loss: 4.1084
[09/26 10:02:32 visual_prompt]: Classification results with val_vtab-sun397: top1: 18.50	top5: 46.00	
[09/26 10:02:32 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.047073689821473176
[09/26 10:02:39 visual_prompt]: Epoch 25 / 100: avg data time: 6.01e-02, avg batch time: 0.5039, average train loss: 1.5696
[09/26 10:02:41 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1676, average loss: 4.1396
[09/26 10:02:41 visual_prompt]: Classification results with val_vtab-sun397: top1: 17.50	top5: 44.00	
[09/26 10:02:41 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.046650635094610975
[09/26 10:02:48 visual_prompt]: Epoch 26 / 100: avg data time: 6.11e-02, avg batch time: 0.5035, average train loss: 1.4414
[09/26 10:02:50 visual_prompt]: Inference (val):avg data time: 3.75e-05, avg batch time: 0.1674, average loss: 4.0400
[09/26 10:02:50 visual_prompt]: Classification results with val_vtab-sun397: top1: 20.50	top5: 45.00	
[09/26 10:02:50 visual_prompt]: Best epoch 26: best metric: 0.205
[09/26 10:02:50 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.04620120240391065
[09/26 10:02:57 visual_prompt]: Epoch 27 / 100: avg data time: 6.06e-02, avg batch time: 0.5045, average train loss: 1.3234
[09/26 10:02:58 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1675, average loss: 4.0765
[09/26 10:02:58 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.50	top5: 43.00	
[09/26 10:02:58 visual_prompt]: Best epoch 27: best metric: 0.225
[09/26 10:02:58 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.04572593931387604
[09/26 10:03:05 visual_prompt]: Epoch 28 / 100: avg data time: 6.25e-02, avg batch time: 0.5055, average train loss: 1.2002
[09/26 10:03:07 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1674, average loss: 4.0174
[09/26 10:03:07 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.00	top5: 46.50	
[09/26 10:03:07 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.04522542485937369
[09/26 10:03:14 visual_prompt]: Epoch 29 / 100: avg data time: 5.95e-02, avg batch time: 0.5026, average train loss: 1.0847
[09/26 10:03:15 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1674, average loss: 4.0133
[09/26 10:03:15 visual_prompt]: Classification results with val_vtab-sun397: top1: 20.50	top5: 47.00	
[09/26 10:03:15 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.04470026884016805
[09/26 10:03:22 visual_prompt]: Epoch 30 / 100: avg data time: 5.53e-02, avg batch time: 0.4981, average train loss: 0.9893
[09/26 10:03:24 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1675, average loss: 4.0209
[09/26 10:03:24 visual_prompt]: Classification results with val_vtab-sun397: top1: 19.00	top5: 46.00	
[09/26 10:03:24 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.04415111107797445
[09/26 10:03:31 visual_prompt]: Epoch 31 / 100: avg data time: 6.42e-02, avg batch time: 0.5068, average train loss: 0.8923
[09/26 10:03:32 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1672, average loss: 3.9766
[09/26 10:03:32 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.50	top5: 48.00	
[09/26 10:03:32 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.04357862063693486
[09/26 10:03:39 visual_prompt]: Epoch 32 / 100: avg data time: 6.35e-02, avg batch time: 0.5056, average train loss: 0.8228
[09/26 10:03:41 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1675, average loss: 4.0182
[09/26 10:03:41 visual_prompt]: Classification results with val_vtab-sun397: top1: 19.00	top5: 43.50	
[09/26 10:03:41 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.04298349500846628
[09/26 10:03:48 visual_prompt]: Epoch 33 / 100: avg data time: 5.76e-02, avg batch time: 0.5014, average train loss: 0.7540
[09/26 10:03:49 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1672, average loss: 3.9913
[09/26 10:03:49 visual_prompt]: Classification results with val_vtab-sun397: top1: 20.50	top5: 45.50	
[09/26 10:03:49 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.042366459261474934
[09/26 10:03:56 visual_prompt]: Epoch 34 / 100: avg data time: 6.15e-02, avg batch time: 0.5051, average train loss: 0.6952
[09/26 10:03:58 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1672, average loss: 3.9976
[09/26 10:03:58 visual_prompt]: Classification results with val_vtab-sun397: top1: 19.00	top5: 45.50	
[09/26 10:03:58 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.04172826515897146
[09/26 10:04:05 visual_prompt]: Epoch 35 / 100: avg data time: 5.67e-02, avg batch time: 0.4998, average train loss: 0.6504
[09/26 10:04:06 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1671, average loss: 3.9877
[09/26 10:04:06 visual_prompt]: Classification results with val_vtab-sun397: top1: 19.50	top5: 47.50	
[09/26 10:04:06 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.04106969024216348
[09/26 10:04:13 visual_prompt]: Epoch 36 / 100: avg data time: 6.26e-02, avg batch time: 0.5070, average train loss: 0.5968
[09/26 10:04:15 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1675, average loss: 3.9475
[09/26 10:04:15 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.00	top5: 46.00	
[09/26 10:04:15 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.040391536883141455
[09/26 10:04:22 visual_prompt]: Epoch 37 / 100: avg data time: 5.00e-02, avg batch time: 0.4939, average train loss: 0.5439
[09/26 10:04:23 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1674, average loss: 3.9788
[09/26 10:04:23 visual_prompt]: Classification results with val_vtab-sun397: top1: 20.00	top5: 46.00	
[09/26 10:04:23 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.03969463130731183
[09/26 10:04:30 visual_prompt]: Epoch 38 / 100: avg data time: 5.23e-02, avg batch time: 0.4972, average train loss: 0.5070
[09/26 10:04:32 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1671, average loss: 3.9258
[09/26 10:04:32 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.00	top5: 49.00	
[09/26 10:04:32 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.03897982258676867
[09/26 10:04:39 visual_prompt]: Epoch 39 / 100: avg data time: 5.80e-02, avg batch time: 0.5014, average train loss: 0.4620
[09/26 10:04:40 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1675, average loss: 3.9430
[09/26 10:04:40 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.50	top5: 47.00	
[09/26 10:04:40 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.03824798160583012
[09/26 10:04:47 visual_prompt]: Epoch 40 / 100: avg data time: 6.83e-02, avg batch time: 0.5106, average train loss: 0.4295
[09/26 10:04:49 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1677, average loss: 3.9508
[09/26 10:04:49 visual_prompt]: Classification results with val_vtab-sun397: top1: 19.50	top5: 47.00	
[09/26 10:04:49 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.037500000000000006
[09/26 10:04:56 visual_prompt]: Epoch 41 / 100: avg data time: 6.73e-02, avg batch time: 0.5118, average train loss: 0.4104
[09/26 10:04:58 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1672, average loss: 3.9405
[09/26 10:04:58 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.00	top5: 44.50	
[09/26 10:04:58 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.03673678906964727
[09/26 10:05:05 visual_prompt]: Epoch 42 / 100: avg data time: 6.50e-02, avg batch time: 0.5073, average train loss: 0.3833
[09/26 10:05:06 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1673, average loss: 3.9433
[09/26 10:05:06 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.00	top5: 47.00	
[09/26 10:05:06 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.03595927866972694
[09/26 10:05:13 visual_prompt]: Epoch 43 / 100: avg data time: 5.98e-02, avg batch time: 0.5028, average train loss: 0.3556
[09/26 10:05:15 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1674, average loss: 3.9389
[09/26 10:05:15 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.50	top5: 45.50	
[09/26 10:05:15 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.03516841607689501
[09/26 10:05:21 visual_prompt]: Epoch 44 / 100: avg data time: 5.21e-02, avg batch time: 0.4964, average train loss: 0.3351
[09/26 10:05:23 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1675, average loss: 3.9401
[09/26 10:05:23 visual_prompt]: Classification results with val_vtab-sun397: top1: 20.00	top5: 45.50	
[09/26 10:05:23 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.0343651648353978
[09/26 10:05:30 visual_prompt]: Epoch 45 / 100: avg data time: 5.84e-02, avg batch time: 0.5011, average train loss: 0.3176
[09/26 10:05:32 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1679, average loss: 3.9492
[09/26 10:05:32 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.50	top5: 45.50	
[09/26 10:05:32 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.033550503583141725
[09/26 10:05:39 visual_prompt]: Epoch 46 / 100: avg data time: 6.73e-02, avg batch time: 0.5107, average train loss: 0.3002
[09/26 10:05:40 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1679, average loss: 3.9546
[09/26 10:05:40 visual_prompt]: Classification results with val_vtab-sun397: top1: 20.50	top5: 46.00	
[09/26 10:05:40 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.032725424859373686
[09/26 10:05:47 visual_prompt]: Epoch 47 / 100: avg data time: 5.83e-02, avg batch time: 0.5009, average train loss: 0.2889
[09/26 10:05:49 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1674, average loss: 3.9434
[09/26 10:05:49 visual_prompt]: Classification results with val_vtab-sun397: top1: 20.50	top5: 46.00	
[09/26 10:05:49 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.03189093389542498
[09/26 10:05:56 visual_prompt]: Epoch 48 / 100: avg data time: 5.87e-02, avg batch time: 0.5032, average train loss: 0.2767
[09/26 10:05:57 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1678, average loss: 3.9424
[09/26 10:05:57 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.00	top5: 45.00	
[09/26 10:05:57 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.03104804738999169
[09/26 10:06:04 visual_prompt]: Epoch 49 / 100: avg data time: 6.11e-02, avg batch time: 0.5039, average train loss: 0.2604
[09/26 10:06:06 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1675, average loss: 3.9525
[09/26 10:06:06 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.50	top5: 47.00	
[09/26 10:06:06 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.03019779227044398
[09/26 10:06:13 visual_prompt]: Epoch 50 / 100: avg data time: 6.43e-02, avg batch time: 0.5096, average train loss: 0.2468
[09/26 10:06:15 visual_prompt]: Inference (val):avg data time: 3.65e-05, avg batch time: 0.1674, average loss: 3.9337
[09/26 10:06:15 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.50	top5: 46.00	
[09/26 10:06:15 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.029341204441673263
[09/26 10:06:21 visual_prompt]: Epoch 51 / 100: avg data time: 6.09e-02, avg batch time: 0.5038, average train loss: 0.2403
[09/26 10:06:23 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1674, average loss: 3.9499
[09/26 10:06:23 visual_prompt]: Classification results with val_vtab-sun397: top1: 20.50	top5: 46.00	
[09/26 10:06:23 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.028479327524001636
[09/26 10:06:30 visual_prompt]: Epoch 52 / 100: avg data time: 5.39e-02, avg batch time: 0.4977, average train loss: 0.2309
[09/26 10:06:32 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1673, average loss: 3.9487
[09/26 10:06:32 visual_prompt]: Classification results with val_vtab-sun397: top1: 20.00	top5: 45.50	
[09/26 10:06:32 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.02761321158169134
[09/26 10:06:39 visual_prompt]: Epoch 53 / 100: avg data time: 6.50e-02, avg batch time: 0.5083, average train loss: 0.2171
[09/26 10:06:40 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1681, average loss: 3.9556
[09/26 10:06:40 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.00	top5: 45.50	
[09/26 10:06:40 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.02674391184360313
[09/26 10:06:47 visual_prompt]: Epoch 54 / 100: avg data time: 6.22e-02, avg batch time: 0.5062, average train loss: 0.2134
[09/26 10:06:49 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1672, average loss: 3.9573
[09/26 10:06:49 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.00	top5: 44.50	
[09/26 10:06:49 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.02587248741756253
[09/26 10:06:56 visual_prompt]: Epoch 55 / 100: avg data time: 5.80e-02, avg batch time: 0.5020, average train loss: 0.2056
[09/26 10:06:57 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1670, average loss: 3.9538
[09/26 10:06:57 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.00	top5: 44.50	
[09/26 10:06:57 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.025
[09/26 10:07:04 visual_prompt]: Epoch 56 / 100: avg data time: 6.06e-02, avg batch time: 0.5029, average train loss: 0.1996
[09/26 10:07:06 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1670, average loss: 3.9506
[09/26 10:07:06 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.50	top5: 45.50	
[09/26 10:07:06 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.024127512582437484
[09/26 10:07:13 visual_prompt]: Epoch 57 / 100: avg data time: 6.24e-02, avg batch time: 0.5056, average train loss: 0.1931
[09/26 10:07:14 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1667, average loss: 3.9348
[09/26 10:07:14 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.00	top5: 47.50	
[09/26 10:07:14 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.02325608815639687
[09/26 10:07:21 visual_prompt]: Epoch 58 / 100: avg data time: 5.97e-02, avg batch time: 0.5043, average train loss: 0.1864
[09/26 10:07:23 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1676, average loss: 3.9486
[09/26 10:07:23 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.00	top5: 46.00	
[09/26 10:07:23 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.02238678841830867
[09/26 10:07:30 visual_prompt]: Epoch 59 / 100: avg data time: 5.11e-02, avg batch time: 0.4956, average train loss: 0.1792
[09/26 10:07:31 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1675, average loss: 3.9426
[09/26 10:07:31 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.00	top5: 45.50	
[09/26 10:07:31 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.02152067247599837
[09/26 10:07:38 visual_prompt]: Epoch 60 / 100: avg data time: 6.61e-02, avg batch time: 0.5115, average train loss: 0.1761
[09/26 10:07:40 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1673, average loss: 3.9427
[09/26 10:07:40 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.00	top5: 45.50	
[09/26 10:07:40 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.020658795558326743
[09/26 10:07:47 visual_prompt]: Epoch 61 / 100: avg data time: 6.02e-02, avg batch time: 0.5037, average train loss: 0.1713
[09/26 10:07:49 visual_prompt]: Inference (val):avg data time: 4.21e-05, avg batch time: 0.1674, average loss: 3.9519
[09/26 10:07:49 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.50	top5: 47.00	
[09/26 10:07:49 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.019802207729556022
[09/26 10:07:55 visual_prompt]: Epoch 62 / 100: avg data time: 5.92e-02, avg batch time: 0.5028, average train loss: 0.1725
[09/26 10:07:57 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1675, average loss: 3.9350
[09/26 10:07:57 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.50	top5: 46.50	
[09/26 10:07:57 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.018951952610008312
[09/26 10:08:04 visual_prompt]: Epoch 63 / 100: avg data time: 6.40e-02, avg batch time: 0.5082, average train loss: 0.1650
[09/26 10:08:06 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1674, average loss: 3.9533
[09/26 10:08:06 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.50	top5: 45.00	
[09/26 10:08:06 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.018109066104575022
[09/26 10:08:13 visual_prompt]: Epoch 64 / 100: avg data time: 5.63e-02, avg batch time: 0.4996, average train loss: 0.1645
[09/26 10:08:14 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1678, average loss: 3.9638
[09/26 10:08:14 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.00	top5: 46.00	
[09/26 10:08:14 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.017274575140626316
[09/26 10:08:21 visual_prompt]: Epoch 65 / 100: avg data time: 6.81e-02, avg batch time: 0.5117, average train loss: 0.1593
[09/26 10:08:23 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1676, average loss: 3.9477
[09/26 10:08:23 visual_prompt]: Classification results with val_vtab-sun397: top1: 20.50	top5: 46.00	
[09/26 10:08:23 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.016449496416858285
[09/26 10:08:30 visual_prompt]: Epoch 66 / 100: avg data time: 6.53e-02, avg batch time: 0.5077, average train loss: 0.1570
[09/26 10:08:31 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1678, average loss: 3.9469
[09/26 10:08:31 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.00	top5: 46.00	
[09/26 10:08:31 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.0156348351646022
[09/26 10:08:38 visual_prompt]: Epoch 67 / 100: avg data time: 7.19e-02, avg batch time: 0.5158, average train loss: 0.1554
[09/26 10:08:40 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1673, average loss: 3.9503
[09/26 10:08:40 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.00	top5: 47.00	
[09/26 10:08:40 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.014831583923105
[09/26 10:08:47 visual_prompt]: Epoch 68 / 100: avg data time: 6.26e-02, avg batch time: 0.5063, average train loss: 0.1523
[09/26 10:08:49 visual_prompt]: Inference (val):avg data time: 3.77e-05, avg batch time: 0.1671, average loss: 3.9431
[09/26 10:08:49 visual_prompt]: Classification results with val_vtab-sun397: top1: 20.50	top5: 47.50	
[09/26 10:08:49 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.014040721330273063
[09/26 10:08:56 visual_prompt]: Epoch 69 / 100: avg data time: 5.97e-02, avg batch time: 0.5031, average train loss: 0.1504
[09/26 10:08:57 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1671, average loss: 3.9571
[09/26 10:08:57 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.50	top5: 46.50	
[09/26 10:08:57 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.013263210930352737
[09/26 10:09:04 visual_prompt]: Epoch 70 / 100: avg data time: 6.66e-02, avg batch time: 0.5095, average train loss: 0.1488
[09/26 10:09:06 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1677, average loss: 3.9424
[09/26 10:09:06 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.50	top5: 46.50	
[09/26 10:09:06 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.012500000000000006
[09/26 10:09:13 visual_prompt]: Epoch 71 / 100: avg data time: 6.14e-02, avg batch time: 0.5037, average train loss: 0.1476
[09/26 10:09:15 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1671, average loss: 3.9386
[09/26 10:09:15 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.50	top5: 45.50	
[09/26 10:09:15 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.01175201839416988
[09/26 10:09:22 visual_prompt]: Epoch 72 / 100: avg data time: 7.07e-02, avg batch time: 0.5131, average train loss: 0.1441
[09/26 10:09:23 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1673, average loss: 3.9379
[09/26 10:09:23 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.50	top5: 48.00	
[09/26 10:09:23 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.011020177413231334
[09/26 10:09:30 visual_prompt]: Epoch 73 / 100: avg data time: 5.69e-02, avg batch time: 0.5009, average train loss: 0.1419
[09/26 10:09:32 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1676, average loss: 3.9473
[09/26 10:09:32 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.50	top5: 47.00	
[09/26 10:09:32 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.010305368692688175
[09/26 10:09:39 visual_prompt]: Epoch 74 / 100: avg data time: 6.34e-02, avg batch time: 0.5056, average train loss: 0.1425
[09/26 10:09:40 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1673, average loss: 3.9449
[09/26 10:09:40 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.00	top5: 48.00	
[09/26 10:09:40 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.009608463116858543
[09/26 10:09:47 visual_prompt]: Epoch 75 / 100: avg data time: 5.54e-02, avg batch time: 0.4983, average train loss: 0.1400
[09/26 10:09:49 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1671, average loss: 3.9465
[09/26 10:09:49 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.50	top5: 47.50	
[09/26 10:09:49 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.008930309757836517
[09/26 10:09:56 visual_prompt]: Epoch 76 / 100: avg data time: 6.46e-02, avg batch time: 0.5085, average train loss: 0.1357
[09/26 10:09:58 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1674, average loss: 3.9447
[09/26 10:09:58 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.50	top5: 48.00	
[09/26 10:09:58 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.008271734841028553
[09/26 10:10:04 visual_prompt]: Epoch 77 / 100: avg data time: 5.94e-02, avg batch time: 0.5021, average train loss: 0.1386
[09/26 10:10:06 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1673, average loss: 3.9501
[09/26 10:10:06 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.50	top5: 47.00	
[09/26 10:10:06 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.007633540738525066
[09/26 10:10:13 visual_prompt]: Epoch 78 / 100: avg data time: 5.83e-02, avg batch time: 0.5039, average train loss: 0.1363
[09/26 10:10:15 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1673, average loss: 3.9519
[09/26 10:10:15 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.00	top5: 46.50	
[09/26 10:10:15 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.0070165049915337264
[09/26 10:10:22 visual_prompt]: Epoch 79 / 100: avg data time: 6.39e-02, avg batch time: 0.5080, average train loss: 0.1356
[09/26 10:10:23 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1675, average loss: 3.9469
[09/26 10:10:23 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.50	top5: 47.00	
[09/26 10:10:23 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.006421379363065142
[09/26 10:10:30 visual_prompt]: Epoch 80 / 100: avg data time: 5.82e-02, avg batch time: 0.5034, average train loss: 0.1355
[09/26 10:10:32 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1670, average loss: 3.9451
[09/26 10:10:32 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.50	top5: 47.00	
[09/26 10:10:32 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.005848888922025553
[09/26 10:10:39 visual_prompt]: Epoch 81 / 100: avg data time: 6.01e-02, avg batch time: 0.5031, average train loss: 0.1331
[09/26 10:10:41 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1675, average loss: 3.9492
[09/26 10:10:41 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.00	top5: 48.00	
[09/26 10:10:41 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.005299731159831953
[09/26 10:10:48 visual_prompt]: Epoch 82 / 100: avg data time: 6.52e-02, avg batch time: 0.5091, average train loss: 0.1332
[09/26 10:10:49 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1675, average loss: 3.9532
[09/26 10:10:49 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.50	top5: 47.00	
[09/26 10:10:49 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.004774575140626317
[09/26 10:10:56 visual_prompt]: Epoch 83 / 100: avg data time: 6.24e-02, avg batch time: 0.5056, average train loss: 0.1334
[09/26 10:10:58 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1672, average loss: 3.9546
[09/26 10:10:58 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.00	top5: 48.00	
[09/26 10:10:58 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.004274060686123959
[09/26 10:11:05 visual_prompt]: Epoch 84 / 100: avg data time: 6.82e-02, avg batch time: 0.5104, average train loss: 0.1306
[09/26 10:11:06 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1670, average loss: 3.9525
[09/26 10:11:06 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.50	top5: 48.00	
[09/26 10:11:06 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.003798797596089351
[09/26 10:11:13 visual_prompt]: Epoch 85 / 100: avg data time: 6.53e-02, avg batch time: 0.5080, average train loss: 0.1297
[09/26 10:11:15 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1671, average loss: 3.9531
[09/26 10:11:15 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.50	top5: 47.00	
[09/26 10:11:15 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.0033493649053890325
[09/26 10:11:22 visual_prompt]: Epoch 86 / 100: avg data time: 6.33e-02, avg batch time: 0.5071, average train loss: 0.1289
[09/26 10:11:24 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1679, average loss: 3.9559
[09/26 10:11:24 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.50	top5: 47.00	
[09/26 10:11:24 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.0029263101785268254
[09/26 10:11:31 visual_prompt]: Epoch 87 / 100: avg data time: 6.44e-02, avg batch time: 0.5087, average train loss: 0.1315
[09/26 10:11:32 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1674, average loss: 3.9542
[09/26 10:11:32 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.50	top5: 47.00	
[09/26 10:11:32 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.00253014884252083
[09/26 10:11:39 visual_prompt]: Epoch 88 / 100: avg data time: 5.06e-02, avg batch time: 0.4941, average train loss: 0.1293
[09/26 10:11:41 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1678, average loss: 3.9558
[09/26 10:11:41 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.50	top5: 47.00	
[09/26 10:11:41 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.0021613635589349755
[09/26 10:11:48 visual_prompt]: Epoch 89 / 100: avg data time: 5.99e-02, avg batch time: 0.5032, average train loss: 0.1294
[09/26 10:11:49 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1681, average loss: 3.9559
[09/26 10:11:49 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.00	top5: 47.50	
[09/26 10:11:49 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.0018204036358303172
[09/26 10:11:56 visual_prompt]: Epoch 90 / 100: avg data time: 6.49e-02, avg batch time: 0.5085, average train loss: 0.1294
[09/26 10:11:58 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1672, average loss: 3.9570
[09/26 10:11:58 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.00	top5: 47.50	
[09/26 10:11:58 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.0015076844803522923
[09/26 10:12:05 visual_prompt]: Epoch 91 / 100: avg data time: 4.82e-02, avg batch time: 0.4922, average train loss: 0.1290
[09/26 10:12:07 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1673, average loss: 3.9556
[09/26 10:12:07 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.00	top5: 47.50	
[09/26 10:12:07 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.0012235870926211618
[09/26 10:12:13 visual_prompt]: Epoch 92 / 100: avg data time: 6.08e-02, avg batch time: 0.5033, average train loss: 0.1300
[09/26 10:12:15 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1673, average loss: 3.9544
[09/26 10:12:15 visual_prompt]: Classification results with val_vtab-sun397: top1: 22.00	top5: 47.00	
[09/26 10:12:15 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.0009684576015420277
[09/26 10:12:22 visual_prompt]: Epoch 93 / 100: avg data time: 4.75e-02, avg batch time: 0.4917, average train loss: 0.1291
[09/26 10:12:24 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1675, average loss: 3.9544
[09/26 10:12:24 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.50	top5: 47.50	
[09/26 10:12:24 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.0007426068431000883
[09/26 10:12:30 visual_prompt]: Epoch 94 / 100: avg data time: 6.28e-02, avg batch time: 0.5063, average train loss: 0.1289
[09/26 10:12:32 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1676, average loss: 3.9546
[09/26 10:12:32 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.50	top5: 47.50	
[09/26 10:12:32 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.0005463099816548578
[09/26 10:12:39 visual_prompt]: Epoch 95 / 100: avg data time: 5.53e-02, avg batch time: 0.4995, average train loss: 0.1291
[09/26 10:12:41 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1671, average loss: 3.9542
[09/26 10:12:41 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.50	top5: 48.00	
[09/26 10:12:41 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.00037980617469479954
[09/26 10:12:47 visual_prompt]: Epoch 96 / 100: avg data time: 5.12e-02, avg batch time: 0.4972, average train loss: 0.1277
[09/26 10:12:49 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1672, average loss: 3.9537
[09/26 10:12:49 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.50	top5: 48.00	
[09/26 10:12:49 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.00024329828146074097
[09/26 10:12:56 visual_prompt]: Epoch 97 / 100: avg data time: 5.21e-02, avg batch time: 0.4961, average train loss: 0.1275
[09/26 10:12:58 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1674, average loss: 3.9534
[09/26 10:12:58 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.50	top5: 48.00	
[09/26 10:12:58 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.00013695261579316776
[09/26 10:13:04 visual_prompt]: Epoch 98 / 100: avg data time: 5.44e-02, avg batch time: 0.4992, average train loss: 0.1289
[09/26 10:13:06 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1673, average loss: 3.9533
[09/26 10:13:06 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.50	top5: 48.00	
[09/26 10:13:06 visual_prompt]: Training 99 / 100 epoch, with learning rate 6.089874350439506e-05
[09/26 10:13:13 visual_prompt]: Epoch 99 / 100: avg data time: 5.12e-02, avg batch time: 0.4942, average train loss: 0.1278
[09/26 10:13:15 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.1674, average loss: 3.9533
[09/26 10:13:15 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.50	top5: 48.00	
[09/26 10:13:15 visual_prompt]: Training 100 / 100 epoch, with learning rate 1.5229324522605948e-05
[09/26 10:13:21 visual_prompt]: Epoch 100 / 100: avg data time: 5.01e-02, avg batch time: 0.4938, average train loss: 0.1296
[09/26 10:13:23 visual_prompt]: Inference (val):avg data time: 4.57e-05, avg batch time: 0.1676, average loss: 3.9533
[09/26 10:13:23 visual_prompt]: Classification results with val_vtab-sun397: top1: 21.50	top5: 48.00	
Traceback (most recent call last):
  File "/home/s1952889/final-project/implementation/visual_prompt_tuning/tune_vtab.py", line 289, in <module>
    main(args)
  File "/home/s1952889/final-project/implementation/visual_prompt_tuning/tune_vtab.py", line 284, in main
    train(cfg, args)
  File "/home/s1952889/final-project/implementation/visual_prompt_tuning/tune_vtab.py", line 113, in train
    seed(cfg)
  File "/home/s1952889/final-project/implementation/visual_prompt_tuning/tune_vtab.py", line 136, in seed
    torch.manual_seed(SEED)
  File "/home/s1952889/miniconda3/envs/prompt/lib/python3.11/site-packages/torch/random.py", line 36, in manual_seed
    seed = int(seed)
           ^^^^^^^^^
TypeError: int() argument must be a string, a bytes-like object or a real number, not 'tuple'
